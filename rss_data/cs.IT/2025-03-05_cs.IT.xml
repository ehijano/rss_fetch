<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 05:01:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>New Construction of Locally q-ary Sequential Recoverable Codes: Parity-check Matrix Approach</title>
      <link>https://arxiv.org/abs/2503.02001</link>
      <description>arXiv:2503.02001v1 Announce Type: new 
Abstract: This paper develops a new family of locally recoverable codes for distributed storage systems, Sequential Locally Recoverable Codes (SLRCs) constructed to handle multiple erasures in a sequential recovery approach. We propose a new connection between parallel and sequential recovery, which leads to a general construction of q-ary linear codes with information $(r, t_i, \delta)$-sequential-locality where each of the $i$-th information symbols is contained in $t_i$ punctured subcodes with length $(r+\delta-1)$ and minimum distance $\delta$. We prove that such codes are $(r, t)_q$-SLRC ($t \geq \delta t_i+1$), which implies that they permit sequential recovery for up to $t$ erasures each one by $r$ other code symbols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02001v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Akram Baghban, Mehdi Ghiyasvand</dc:creator>
    </item>
    <item>
      <title>Integrated Communication and Learned Recognizer with Customized RIS Phases and Sensing Durations</title>
      <link>https://arxiv.org/abs/2503.02244</link>
      <description>arXiv:2503.02244v1 Announce Type: new 
Abstract: Future wireless communication networks are expected to be smarter and more aware of their surroundings, enabling a wide range of context-aware applications. Reconfigurable intelligent surfaces (RISs) are set to play a critical role in supporting various sensing tasks, such as target recognition. However, current methods typically use RIS configurations optimized once and applied over fixed sensing durations, limiting their ability to adapt to different targets and reducing sensing accuracy. To overcome these limitations, this study proposes an advanced wireless communication system that multiplexes downlink signals for environmental sensing and introduces an intelligent recognizer powered by deep learning techniques. Specifically, we design a novel neural network based on the long short-term memory architecture and the physical channel model. This network iteratively captures and fuses information from previous measurements, adaptively customizing RIS phases to gather the most relevant information for the recognition task at subsequent moments. These configurations are dynamically adjusted according to scene, task, target, and quantization priors. Furthermore, the recognizer includes a decision-making module that dynamically allocates different sensing durations, determining whether to continue or terminate the sensing process based on the collected measurements. This approach maximizes resource utilization efficiency. Simulation results demonstrate that the proposed method significantly outperforms state-of-the-art techniques while minimizing the impact on communication performance, even when sensing and communication occur simultaneously. Part of the source code for this paper can be accessed at https://github.com/kiwi1944/CRISense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02244v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Huang, Jie Yang, Chao-Kai Wen, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Minimizing Age of Detection for a Markov Source over a Lossy Channel</title>
      <link>https://arxiv.org/abs/2503.02285</link>
      <description>arXiv:2503.02285v1 Announce Type: new 
Abstract: Monitoring a process/phenomenon of specific interest is prevalent in Cyber-Physical Systems (CPS), remote healthcare, smart buildings, intelligent transport, industry 4.0, etc. A key building block of the monitoring system is a sensor sampling the process and communicating the status updates to a monitor for detecting events of interest. Measuring the freshness of the status updates is essential for the timely detection of events, and it has received significant research interest in recent times. In this paper, we propose a new freshness metric, Age of Detection (AoD), for monitoring the state transitions of a Discrete Time Markov Chain (DTMC) source over a lossy wireless channel. We consider the pull model where the sensor samples DTMC state whenever the monitor requests a status update. We formulate a Constrained Markov Decision Problem (CMDP) for optimising the AoD subject to a constraint on the average sampling frequency and solve it using the Lagrangian MDP formulation and Relative Value Iteration (RVI) algorithm. Our numerical results show interesting trade-offs between AoD, sampling frequency, and transmission success probability. Further, the AoD minimizing policy provides a lower estimation error than the Age of Information (AoI) minimizing policy, thus demonstrating the utility of AoD for monitoring DTMC sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02285v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivang Garde, Jaya Prakash Champati, Arpan Chattopadhyay</dc:creator>
    </item>
    <item>
      <title>Sparse Orthogonal Matching Pursuit-based Parameter Estimation for Integrated Sensing and Communications</title>
      <link>https://arxiv.org/abs/2503.02293</link>
      <description>arXiv:2503.02293v1 Announce Type: new 
Abstract: Accurate parameter estimation such as angle of arrival (AOA) is essential to enhance the performance of integrated sensing and communication (ISAC) in mmWave multiple-input multiple-output (MIMO) systems. This work presents a sensing-aided communication channel estimation mechanism, where the sensing channel shares the same AOA with the uplink communication channel. First, we propose a novel orthogonal matching pursuit (OMP)-based method for coarsely estimating the AOA in a sensing channel, offering improved accuracy compared to conventional methods that rely on rotational invariance techniques. Next, we refine the coarse estimates obtained in the first step by modifying the Space-Alternating Generalized Expectation Maximization algorithm for fine parameter estimation. Through simulations and mathematical analysis, we demonstrate that scenarios with shared AOA achieve a better Cramer-Rao lower bound (CRLB) than those without sharing. This finding highlights the potential of leveraging joint sensing and communication channels to enhance parameter estimation accuracy, particularly in channel or location estimation applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02293v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ngoc-Son Duong, Khac-Hoang Ngo, Thai-Mai Dinh, Van-Linh Nguyen</dc:creator>
    </item>
    <item>
      <title>Characterization of Deletion/Substitution Channel Capacity for Small Deletion and Substitution Probabilities</title>
      <link>https://arxiv.org/abs/2503.02545</link>
      <description>arXiv:2503.02545v1 Announce Type: new 
Abstract: In this paper, we consider binary input deletion/substitution channels, which model certain channels with synchronization errors encountered in practice. Specifically, we focus on the regimen of small deletion and substitution probabilities, and by extending an approach developed for the deletion-only channel, we obtain an asymptotic characterization of the channel capacity for independent and identically distributed deletion/substitution channels. We first present an upper bound on the capacity for an arbitrary but fixed number of deletions and substitutions, and then we extend the result to the case of random deletions and substitutions. Our final result is as follows: the i.i.d. deletion/substitution channel capacity is approximately $1 - H(p_d) - H(p_s)$, where $p_d$ is the deletion probability, and $p_s$ is the substitution probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02545v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Kazemi, Tolga M. Duman</dc:creator>
    </item>
    <item>
      <title>A Framework for Uplink ISAC Receiver Designs: Performance Analysis and Algorithm Development</title>
      <link>https://arxiv.org/abs/2503.02647</link>
      <description>arXiv:2503.02647v1 Announce Type: new 
Abstract: Uplink integrated sensing and communication (ISAC) systems have recently emerged as a promising research direction, enabling simultaneous uplink signal detection and target sensing. In this paper, we propose flexible projection (FP)-type receivers that unify the projection-type receivers and the successive interference cancellation (SIC)-type receivers by using a flexible tradeoff factor to adapt to dynamically changing uplink ISAC scenarios. The FP-type receivers address the joint signal detection and target response estimation problem through two coordinated phases: 1) Communication signal detection using a reconstructed signal whose composition is controlled by the tradeoff factor, followed by 2) Target response estimation performed through subtraction of the detected communication signal from the received signal. With adjustable tradeoff factors, the FP-type receivers can balance the enhancement of the signal-to-interference-plus-noise ratio (SINR) with the reduction of correlation in the reconstructed signal for communication signal detection. The pairwise error probabilities (PEPs) are analyzed for both maximum likelihood (ML) and zero-forcing (ZF) detectors, revealing that the optimal tradeoff factor should be determined based on the adopted detection algorithm and the relative power of the sensing and communication (S&amp;C) signal. A homotopy optimization framework is first applied for the FP-type receivers with a fixed trade-off factor. This framework is then extended to develop dynamic FP (DFP)-type receivers, which iteratively adjust the trade-off factor for improved algorithm performance and environmental adaptability. Subsequently, two extensions are explored to further enhance the receivers' performance: parallel DFP (PDFP)-type receivers and a block-structured receiver design. Finally, the effectiveness of the proposed receiver designs is verified via simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02647v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan Yu, Hong Ren, Cunhua Pan, Gui Zhou, Dongming Wang, Chau Yuen, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>Undetected Error Probability in the Short Blocklength Regime: Approaching Finite-Blocklength Bounds with Polar Codes</title>
      <link>https://arxiv.org/abs/2503.02782</link>
      <description>arXiv:2503.02782v1 Announce Type: new 
Abstract: We analyze the trade-off between the undetected error probability (i.e., the probability that the channel decoder outputs an erroneous message without detecting the error) and the total error probability in the short blocklength regime. We address the problem by developing two new finite blocklength achievability bounds, which we use to benchmark the performance of two coding schemes based on polar codes with outer cyclic redundancy check (CRC) codes -- also referred to as CRC-aided (CA) polar codes. The first bound is obtained by considering an outer detection code, whereas the second bound relies on a threshold test applied to the generalized information density. Similarly, in the first CA polar code scheme, we reserve a fraction of the outer CRC parity bits for error detection, whereas in the second scheme, we apply a threshold test (specifically, Forney's optimal rule) to the output of the successive cancellation list decoder. Numerical simulations performed on the binary-input AWGN channel reveal that, in the short-blocklength regime, the threshold-based approach is superior to the CRC-based approach, both in terms of bounds and performance of CA polar code schemes. We also consider the case of decoding with noisy channel-state information, which leads to a mismatched decoding setting. Our results illustrate that, differently from the previous case, in this scenario, the CRC-based approach outperforms the threshold-based approach, which is more sensitive to the mismatch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02782v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Sauter, A. Oguz Kislal, Giuseppe Durisi, Gianluigi Liva, Balazs Matuz, Erik G. Str\"om</dc:creator>
    </item>
    <item>
      <title>Quantum Geometry insights in Deep Learning</title>
      <link>https://arxiv.org/abs/2503.02655</link>
      <description>arXiv:2503.02655v1 Announce Type: cross 
Abstract: In this paper, we explore the fundamental role of the Monge-Amp\`ere equation in deep learning, particularly in the context of Boltzmann machines and energy-based models. We first review the structure of Boltzmann learning and its relation to free energy minimization. We then establish a connection between optimal transport theory and deep learning, demonstrating how the Monge-Amp\`ere equation governs probability transformations in generative models. Additionally, we provide insights from quantum geometry, showing that the space of covariance matrices arising in the learning process coincides with the Connes-Araki-Haagerup (CAH) cone in von Neumann algebra theory. Furthermore, we introduce an alternative approach based on renormalization group (RG) flow, which, while distinct from the optimal transport perspective, reveals another manifestation of the Monge-Amp\`ere domain in learning dynamics. This dual perspective offers a deeper mathematical understanding of hierarchical feature learning, bridging concepts from statistical mechanics, quantum geometry, and deep learning theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02655v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.DG</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>No\'emie C. Combe</dc:creator>
    </item>
    <item>
      <title>Measurement noise scaling laws for cellular representation learning</title>
      <link>https://arxiv.org/abs/2503.02726</link>
      <description>arXiv:2503.02726v1 Announce Type: cross 
Abstract: Deep learning scaling laws predict how performance improves with increased model and dataset size. Here we identify measurement noise in data as another performance scaling axis, governed by a distinct logarithmic law. We focus on representation learning models of biological single cell genomic data, where a dominant source of measurement noise is due to molecular undersampling. We introduce an information-theoretic metric for cellular representation model quality, and find that it scales with sampling depth. A single quantitative relationship holds across several model types and across several datasets. We show that the analytical form of this relationship can be derived from a simple Gaussian noise model, which in turn provides an intuitive interpretation for the scaling law. Finally, we show that the same relationship emerges in image classification models with respect to two types of imaging noise, suggesting that measurement noise scaling may be a general phenomenon. Scaling with noise can serve as a guide in generating and curating data for deep learning models, particularly in fields where measurement quality can vary dramatically between datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02726v1</guid>
      <category>q-bio.QM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gokul Gowri, Peng Yin, Allon M. Klein</dc:creator>
    </item>
    <item>
      <title>Protograph-Based Batched Network Codes</title>
      <link>https://arxiv.org/abs/2408.16365</link>
      <description>arXiv:2408.16365v2 Announce Type: replace 
Abstract: Batched network codes (BNCs) are a low-complexity solution for communication through networks with packet loss. Although their belief propagation (BP) performance is proved to approach capacity in the asymptotic regime, there is no evidence indicating that their BP performance is equally good in the finite-length regime. In this paper, we propose a protograph-based construction for BNCs, referred to as protograph-based BNCs (P-BNCs), which significantly differs from existing BNCs in three aspects: 1) The vast majority of existing construction methods mainly focus on the degree distribution of check nodes (CNs), whereas P-BNCs not only specify the degree distributions of CNs and variable nodes (VNs) but also partially constrain the connectivity between CNs and VNs. 2) Traditional BNCs use a fixed degree distribution to generate all batches, making their performance highly sensitive to channel conditions, but P-BNCs achieve good performance under varying channel conditions due to their rate-compatible structures. 3) The construction of PBNCs takes into account joint BP decoding with a sparse precode, whereas traditional constructions typically do not consider a precode, or assume the presence of a precode that can recover a certain fraction of erasures. Thanks to these three improvements, P-BNCs not only have higher achievable rates under varying channel conditions, but more importantly, their BP performance is significantly improved at practical lengths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16365v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingyang Zhu, Ming Jiang, Chunming Zhao</dc:creator>
    </item>
    <item>
      <title>Beamforming Optimization for Continuous Aperture Array (CAPA)-based Communications</title>
      <link>https://arxiv.org/abs/2410.13677</link>
      <description>arXiv:2410.13677v3 Announce Type: replace 
Abstract: The beamforming optimization in continuous aperture array (CAPA)-based multi-user communications is studied. In contrast to conventional spatially discrete antenna arrays, CAPAs can exploit the full spatial degrees of freedom (DoFs) by emitting information-bearing electromagnetic (EM) waves through continuous source current distributed across the aperture. Nevertheless, such an operation renders the beamforming optimization problem as a non-convex integral-based functional programming problem, which is challenging for conventional discrete optimization methods. A couple of low-complexity approaches are proposed to solve the functional programming problem. 1) Calculus of variations (CoV)-based approach: Closed-form structure of the optimal continuous source patterns are derived based on CoV, inspiring a low-complexity integral-free iterative algorithm for solving the functional programming problem. 2) Correlation-based zero-forcing (Corr-ZF) approach: Closed-form ZF source current patterns that completely eliminate the inter-user interference are derived based on the channel correlations. By using these patterns, the original functional programming problem is transformed to a simple power allocation problem, which can be solved using the classical water-filling approach with reduced complexity. Our numerical results validate the effectiveness of the proposed designs and reveal that: i) compared to the state-of-the-art Fourier-based discretization approach, the proposed CoV-based approach not only improves communication performance but also reduces computational complexity by up to hundreds of times for large CAPA apertures and high frequencies, and ii) the proposed Corr-ZF approach achieves asymptotically optimal performance compared to the CoV-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13677v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Wang, Chongjun Ouyang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Structured IB: Improving Information Bottleneck with Structured Feature Learning</title>
      <link>https://arxiv.org/abs/2412.08222</link>
      <description>arXiv:2412.08222v2 Announce Type: replace 
Abstract: The Information Bottleneck (IB) principle has emerged as a promising approach for enhancing the generalization, robustness, and interpretability of deep neural networks, demonstrating efficacy across image segmentation, document clustering, and semantic communication. Among IB implementations, the IB Lagrangian method, employing Lagrangian multipliers, is widely adopted. While numerous methods for the optimizations of IB Lagrangian based on variational bounds and neural estimators are feasible, their performance is highly dependent on the quality of their design, which is inherently prone to errors. To address this limitation, we introduce Structured IB, a framework for investigating potential structured features. By incorporating auxiliary encoders to extract missing informative features, we generate more informative representations. Our experiments demonstrate superior prediction accuracy and task-relevant information preservation compared to the original IB Lagrangian method, even with reduced network size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08222v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanzhe Yang, Youlong Wu, Dingzhu Wen, Yong Zhou, Yuanming Shi</dc:creator>
    </item>
    <item>
      <title>Rate-Distortion Theory in Coding for Machines and its Application</title>
      <link>https://arxiv.org/abs/2305.17295</link>
      <description>arXiv:2305.17295v2 Announce Type: replace-cross 
Abstract: Recent years have seen a tremendous growth in both the capability and popularity of automatic machine analysis of images and video. As a result, a growing need for efficient compression methods optimized for machine vision, rather than human vision, has emerged. To meet this growing demand, several methods have been developed for image and video coding for machines. Unfortunately, while there is a substantial body of knowledge regarding rate-distortion theory for human vision, the same cannot be said of machine analysis. In this paper, we extend the current rate-distortion theory for machines, providing insight into important design considerations of machine-vision codecs. We then utilize this newfound understanding to improve several methods for learnable image coding for machines. Our proposed methods achieve state-of-the-art rate-distortion performance on several computer vision tasks such as classification, instance segmentation, and object detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17295v2</guid>
      <category>eess.IV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alon Harell, Yalda Foroutan, Nilesh Ahuja, Parual Datta, Bhavya Kanzariya, V. Srinivasa Somayazulu, Omesh Tickoo, Anderson de Andrade, Ivan V. Bajic</dc:creator>
    </item>
    <item>
      <title>Partition function approach to non-Gaussian likelihoods: information theory and state variables for Bayesian inference</title>
      <link>https://arxiv.org/abs/2411.13625</link>
      <description>arXiv:2411.13625v2 Announce Type: replace-cross 
Abstract: The significance of statistical physics concepts such as entropy extends far beyond classical thermodynamics. We interpret the similarity between partitions in statistical mechanics and partitions in Bayesian inference as an articulation of a result by Jaynes (1957), who clarified that thermodynamics is in essence a theory of information. In this, every sampling process has a mechanical analogue. Consequently, the divide between ensembles of samplers in parameter space and sampling from a mechanical system in thermodynamic equilibrium would be artificial. Based on this realisation, we construct a continuous modelling of a Bayes update akin to a transition between thermodynamic ensembles. This leads to an information theoretic interpretation of Jazinsky's equality, relating the expenditure of work to the influence of data via the likelihood. We propose one way to transfer the vocabulary and the formalism of thermodynamics (energy, work, heat) and statistical mechanics (partition functions) to statistical inference, starting from Bayes' law. Different kinds of inference processes are discussed and relative entropies are shown to follow from suitably constructed partitions as an analytical formulation of sampling processes. Lastly, we propose an effective dimension as a measure of system complexity. A numerical example from cosmology is put forward to illustrate these results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13625v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>astro-ph.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rebecca Maria Kuntz, Heinrich von Campe, Tobias R\"ospel, Maximilian Philipp Herzog, Bj\"orn Malte Sch\"afer</dc:creator>
    </item>
    <item>
      <title>Privacy Preservation in MIMO-OFDM Localization Systems: A Beamforming Approach</title>
      <link>https://arxiv.org/abs/2501.01353</link>
      <description>arXiv:2501.01353v2 Announce Type: replace-cross 
Abstract: We investigate an uplink MIMO-OFDM localization scenario where a legitimate base station (BS) aims to localize a user equipment (UE) using pilot signals transmitted by the UE, while an unauthorized BS attempts to localize the UE by eavesdropping on these pilots, posing a risk to the UE's location privacy. To enhance legitimate localization performance while protecting the UE's privacy, we formulate an optimization problem regarding the beamformers at the UE, aiming to minimize the Cram\'er-Rao bound (CRB) for legitimate localization while constraining the CRB for unauthorized localization above a threshold. A penalty dual decomposition optimization framework is employed to solve the problem, leading to a novel beamforming approach for location privacy preservation. Numerical results confirm the effectiveness of the proposed approach and demonstrate its superiority over existing benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01353v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Zhang, Hui Chen, Musa Furkan Keskin, Alireza Pourafzal, Pinjun Zheng, Henk Wymeersch, Tareq Y. Al-Naffouri</dc:creator>
    </item>
    <item>
      <title>Projection Head is Secretly an Information Bottleneck</title>
      <link>https://arxiv.org/abs/2503.00507</link>
      <description>arXiv:2503.00507v2 Announce Type: replace-cross 
Abstract: Recently, contrastive learning has risen to be a promising paradigm for extracting meaningful data representations. Among various special designs, adding a projection head on top of the encoder during training and removing it for downstream tasks has proven to significantly enhance the performance of contrastive learning. However, despite its empirical success, the underlying mechanism of the projection head remains under-explored. In this paper, we develop an in-depth theoretical understanding of the projection head from the information-theoretic perspective. By establishing the theoretical guarantees on the downstream performance of the features before the projector, we reveal that an effective projector should act as an information bottleneck, filtering out the information irrelevant to the contrastive objective. Based on theoretical insights, we introduce modifications to projectors with training and structural regularizations. Empirically, our methods exhibit consistent improvement in the downstream performance across various real-world datasets, including CIFAR-10, CIFAR-100, and ImageNet-100. We believe our theoretical understanding on the role of the projection head will inspire more principled and advanced designs in this field. Code is available at https://github.com/PKU-ML/Projector_Theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00507v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuo Ouyang, Kaiwen Hu, Qi Zhang, Yifei Wang, Yisen Wang</dc:creator>
    </item>
  </channel>
</rss>
