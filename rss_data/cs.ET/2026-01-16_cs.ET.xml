<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Forward-only learning in memristor arrays with month-scale stability</title>
      <link>https://arxiv.org/abs/2601.09903</link>
      <description>arXiv:2601.09903v1 Announce Type: new 
Abstract: Turning memristor arrays from efficient inference engines into systems capable of on-chip learning has proved difficult. Weight updates have a high energy cost and cause device wear, analog states drift, and backpropagation requires a backward pass with reversed signal flow. Here we experimentally demonstrate learning on standard filamentary HfOx/Ti arrays that addresses these challenges with two design choices. First, we realize that standard filamentary HfOx/Ti memristors support sub-1 V reset-only pulses that cut energy, improve endurance, and yield stable analog states. Second, we rely on forward-only training algorithms derived from Hinton's Forward-Forward that use only inference-style operations. We train two-layer classifiers on an ImageNet-resolution four-class task using arrays up to 8,064 devices. Two forward-only variants, the double-pass supervised Forward-Forward and a single-pass competitive rule, achieve test accuracies of 89.5% and 89.6%, respectively; a reference experiment using backpropagation reaches 90.0%. Across five independent runs per method, these accuracies match within statistical uncertainty. Trained models retain accuracy for at least one month under ambient conditions, consistent with the stability of reset-only states. Sub-1 V reset updates use 460 times less energy than conventional program-and-verify programming and require just 46% more energy than inference-only operation. Together, these results establish forward-only, sub-1 V learning on standard filamentary stacks at array scale, outlining a practical, pulse-aware route to adaptive edge intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09903v1</guid>
      <category>cs.ET</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrien Renaudineau, Mamadou Hawa Diallo, Th\'eo Dupuis, Bastien Imbert, Mohammed Akib Iftakher, Kamel-Eddine Harabi, Cl\'ement Turck, Tifenn Hirtzlin, Djohan Bonnet, Franck Melul, Jorge-Daniel Aguirre-Morales, Elisa Vianello, Marc Bocquet, Jean-Michel Portal, Damien Querlioz</dc:creator>
    </item>
    <item>
      <title>Resistive Memory based Efficient Machine Unlearning and Continual Learning</title>
      <link>https://arxiv.org/abs/2601.10037</link>
      <description>arXiv:2601.10037v1 Announce Type: new 
Abstract: Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10037v1</guid>
      <category>cs.ET</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Lin, Jichang Yang, Yangu He, Zijian Ye, Kwun Hang Wong, Xinyuan Zhang, Songqi Wang, Yi Li, Kemi Xu, Leo Yu Zhang, Xiaoming Chen, Dashan Shang, Han Wang, Xiaojuan Qi, Zhongrui Wang</dc:creator>
    </item>
    <item>
      <title>Instalaci\'on, configuraci\'on y utilizaci\'on de un nodo Bitcoin en Linux</title>
      <link>https://arxiv.org/abs/2601.09748</link>
      <description>arXiv:2601.09748v1 Announce Type: cross 
Abstract: This paper documents the installation, configuration, and operation of a full Bitcoin node in a Linux environment, from manual compilation of the source code to complete synchronization with the network. The technical phases of the process are described, the main files generated by Bitcoin Core are analyzed, and the effects of the parameters txindex, prune, dbcache, maxmempool, and maxconnections are empirically studied. System resources during the block download (IBD) mechanism are also documented, and the operational importance of each resource is explained. This paper provides a solid foundation for future research proposals on Bitcoin node performance or for the development of blockchain data query tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09748v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Eduardo Ulloa, Diego R. Llanos</dc:creator>
    </item>
    <item>
      <title>Starfield: Demand-Aware Satellite Topology Design for Low-Earth Orbit Mega Constellations</title>
      <link>https://arxiv.org/abs/2601.10083</link>
      <description>arXiv:2601.10083v1 Announce Type: cross 
Abstract: Low-Earth orbit (LEO) mega-constellations are emerging as high-capacity backbones for next-generation Internet. Deployment of laser terminals enables high-bandwidth, low-latency inter-satellite links (ISLs); however, their limited number, slow acquisition, and instability make forming a stable satellite topology difficult. Existing patterns like +Grid and Motif ignore regional traffic, ground station placement, and constellation geometry. Given sparse population distribution on Earth and the isolation of rural areas, traffic patterns are inherently non-uniform, providing an opportunity to orient inter-satellite links (ISLs) according to these traffic patterns. In this paper, we propose Starfield, a novel demand-aware satellite topology design heuristic algorithm supported by mathematical analysis. We first formulate a vector field on the constellation's shell according to traffic flows and define a corresponding Riemannian metric on the spherical manifold of the shell. The metric, combined with the spatial geometry, is used to assign a distance to each potential ISL, which we then aggregate over all demand flows to generate a heuristic for each satellite's link selection. Inspired by +Grid, each satellite selects the link with the minimum Riemannian heuristic along with its corresponding angular links. To evaluate Starfield, we developed a custom, link-aware, and link-configurable packet-level simulator, comparing it against +Grid and Random topologies. For the Phase 1 Starlink, simulation results show up to a 30% reduction in hop count and a 15% improvement in stretch factor across multiple traffic distributions. Moreover, static Starfield, an inter-orbital link matching modification of Starfield, achieves a 20% improvement in stretch factor under realistic traffic patterns compared to +Grid. Experiments further demonstrate Starfield's robustness under traffic demand perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10083v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <category>math.DG</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shayan Hamidi Dehshali, Tzu-Hsuan Liao, Shaileshh Bojja Venkatakrishnan</dc:creator>
    </item>
    <item>
      <title>MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging</title>
      <link>https://arxiv.org/abs/2601.10154</link>
      <description>arXiv:2601.10154v1 Announce Type: cross 
Abstract: Artificial intelligence (AI) has the potential to transform medical imaging by automating image analysis and accelerating clinical research. However, research and clinical use are limited by the wide variety of AI implementations and architectures, inconsistent documentation, and reproducibility issues. Here, we introduce MHub.ai, an open-source, container-based platform that standardizes access to AI models with minimal configuration, promoting accessibility and reproducibility in medical imaging. MHub.ai packages models from peer-reviewed publications into standardized containers that support direct processing of DICOM and other formats, provide a unified application interface, and embed structured metadata. Each model is accompanied by publicly available reference data that can be used to confirm model operation. MHub.ai includes an initial set of state-of-the-art segmentation, prediction, and feature extraction models for different modalities. The modular framework enables adaptation of any model and supports community contributions. We demonstrate the utility of the platform in a clinical use case through comparative evaluation of lung segmentation models. To further strengthen transparency and reproducibility, we publicly release the generated segmentations and evaluation metrics and provide interactive dashboards that allow readers to inspect individual cases and reproduce or extend our analysis. By simplifying model use, MHub.ai enables side-by-side benchmarking with identical execution commands and standardized outputs, and lowers the barrier to clinical translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10154v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonard N\"urnberg, Dennis Bontempi, Suraj Pai, Curtis Lisle, Steve Pieper, Ron Kikinis, Sil van de Leemput, Rahul Soni, Gowtham Murugesan, Cosmin Ciausu, Miriam Groeneveld, Felix J. Dorfner, Jue Jiang, Aneesh Rangnekar, Harini Veeraraghavan, Joeran S. Bosma, Keno Bressem, Raymond Mak, Andrey Fedorov, Hugo JWL Aerts</dc:creator>
    </item>
    <item>
      <title>SDN-Driven Innovations in MANETs and IoT: A Path to Smarter Networks</title>
      <link>https://arxiv.org/abs/2601.10544</link>
      <description>arXiv:2601.10544v1 Announce Type: cross 
Abstract: Mobile Ad Hoc Networks (MANETs) and Internet of Things (IoT) networks operate in decentralized and dynamic environments, making them ideal for scenarios lacking traditional infrastructure. However, these networks face challenges such as inefficient routing, limited scalability, and security vulnerabilities due to their decentralized nature and resource constraints. This paper explores the integration of Software-Defined Networking (SDN) as a unified solution that leverages its centralized control and network programmability to improve routing, resource management, and security. A mathematical model evaluates the impact of SDN integration on Capital Expenditure (CAPEX), Operational Expenditure (OPEX), and performance metrics. Results demonstrate that SDN-enhanced MANETs and IoT networks offer superior scalability, reduced latency, increased throughput, and lower packet loss, especially in dynamic and large-scale environments. While SDN introduces computational overhead, it significantly enhances routing efficiency, resource optimization, and adaptability. The proposed framework provides a robust and scalable solution, enabling the development of network architectures that efficiently manage growing node densities, dynamic topologies, and high data traffic. This approach ensures resilience, making it well-suited to meet the performance and reliability demands of modern, large-scale applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10544v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.12720/jait.16.3.411-425</arxiv:DOI>
      <arxiv:journal_reference>Journal of Advances in Information Technology, Vol. 16, No. 3, pp. 411-425, 2025</arxiv:journal_reference>
      <dc:creator>Andrea Piroddi, Riccardo Fonti</dc:creator>
    </item>
    <item>
      <title>Enhancing Mobile Ad Hoc Networks (MANETs) with Software-Defined Networking (SDN): A Balanced Approach</title>
      <link>https://arxiv.org/abs/2601.10556</link>
      <description>arXiv:2601.10556v1 Announce Type: cross 
Abstract: Mobile Ad Hoc Networks (MANETs) are decentralized wireless networks, characterized by their dynamic topologies and node mobility. In the era of cutting-edge technologies, integrating Software-Defined Networking (SDN) with MANETs offers a promising solution to manage these challenges more efficiently. This paper presents a balanced discussion of MANETs and SDN, demonstrating how SDN principles, such as centralized control and network virtualization, can optimize MANET performance in terms of scalability, cost-efficiency, and security. A mathematical model is developed to analyze Capital Expenditures (CAPEX), Operational Expenditures (OPEX), and network efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10556v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.18178/jacn.2025.13.1.293</arxiv:DOI>
      <arxiv:journal_reference>Journal of Advances in Computer Networks, vol. 13, no. 1, pp. 7-14, 2025</arxiv:journal_reference>
      <dc:creator>Riccardo Fonti, Andrea Piroddi</dc:creator>
    </item>
    <item>
      <title>Sneak Path Current Modeling in Memristor Crossbar Arrays for Analog In-Memory Computing</title>
      <link>https://arxiv.org/abs/2511.21796</link>
      <description>arXiv:2511.21796v3 Announce Type: replace 
Abstract: Memristor crossbar arrays have emerged as a key component for next-generation non-volatile memories, artificial neural networks, and analog in-memory computing (IMC) systems. By minimizing data transfer between the processor and memory, they offer substantial energy savings. However, a major design challenge in memristor crossbar arrays is the presence of sneak path currents, which degrade electrical performance, reduce noise margins, and limit reliable operations. This work presents a closed-form analytical framework based on 1.4nm technology for accurately estimating sneak path currents in memristor crossbar arrays. The proposed model captures the interdependence of key design parameters in memristor crossbar arrays, including array size, ON/OFF ratio of memristors, read voltage, and interconnect conditions, through mathematically derived relationships. It supports various practical configurations, such as different data patterns and connection strategies, enabling rapid and comprehensive sneak path current modeling. The sensitivity analysis includes how design parameters influence sneak path current and noise margin loss, underscoring the trade-offs involved in scaling crossbar arrays. Validation through SPICE simulations shows that the model achieves an error of less than 10.9% while being up to 4784 times faster than full circuit simulations. This analytical framework offers a powerful tool for quantitative assessment and pre-design/real-time optimization of memristor-based analog in-memory computing (IMC) architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21796v3</guid>
      <category>cs.ET</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shah Zayed Riam, Zhenlin Pei, Kyle Mooney, Chenyun Pan, Na Gong, Jinhui Wang</dc:creator>
    </item>
  </channel>
</rss>
