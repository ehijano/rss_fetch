<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 04:01:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Nowcasting R&amp;D Expenditures: A Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2407.11765</link>
      <description>arXiv:2407.11765v1 Announce Type: new 
Abstract: Macroeconomic data are crucial for monitoring countries' performance and driving policy. However, traditional data acquisition processes are slow, subject to delays, and performed at a low frequency. We address this 'ragged-edge' problem with a two-step framework. The first step is a supervised learning model predicting observed low-frequency figures. We propose a neural-network-based nowcasting model that exploits mixed-frequency, high-dimensional data. The second step uses the elasticities derived from the previous step to interpolate unobserved high-frequency figures. We apply our method to nowcast countries' yearly research and development (R&amp;D) expenditure series. These series are collected through infrequent surveys, making them ideal candidates for this task. We exploit a range of predictors, chiefly Internet search volume data, and document the relevance of these data in improving out-of-sample predictions. Furthermore, we leverage the high frequency of our data to derive monthly estimates of R&amp;D expenditures, which are currently unobserved. We compare our results with those obtained from the classical regression-based and the sparse temporal disaggregation methods. Finally, we validate our results by reporting a strong correlation with monthly R&amp;D employment data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11765v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atin Aboutorabi, Ga\'etan de Rassenfosse</dc:creator>
    </item>
    <item>
      <title>Generalized Difference-in-Differences</title>
      <link>https://arxiv.org/abs/2407.11937</link>
      <description>arXiv:2407.11937v1 Announce Type: cross 
Abstract: In many social science applications, researchers use the difference-in-differences (DID) estimator to establish causal relationships, exploiting cross-sectional variation in a baseline factor and temporal variation in exposure to an event that presumably may affect all units. This approach, often referred to as generalized DID (GDID), differs from canonical DID in that it lacks a "clean control group" unexposed to the event after the event occurs. In this paper, we clarify GDID as a research design in terms of its data structure, feasible estimands, and identifying assumptions that allow the DID estimator to recover these estimands. We frame GDID as a factorial design with two factors: the baseline factor, denoted by $G$, and the exposure level to the event, denoted by $Z$, and define effect modification and causal interaction as the associative and causal effects of $G$ on the effect of $Z$, respectively. We show that under the canonical no anticipation and parallel trends assumptions, the DID estimator identifies only the effect modification of $G$ in GDID, and propose an additional generalized parallel trends assumption to identify causal interaction. Moreover, we show that the canonical DID research design can be framed as a special case of the GDID research design with an additional exclusion restriction assumption, thereby reconciling the two approaches. We illustrate these findings with empirical examples from economics and political science, and provide recommendations for improving practice and interpretation under GDID.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11937v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yiqing Xu, Anqi Zhao, Peng Ding</dc:creator>
    </item>
    <item>
      <title>Linear multidimensional regression with interactive fixed-effects</title>
      <link>https://arxiv.org/abs/2209.11691</link>
      <description>arXiv:2209.11691v3 Announce Type: replace 
Abstract: This paper studies a linear and additively separable model for multidimensional panel data of three or more dimensions with unobserved interactive fixed effects. Two approaches are considered to account for these unobserved interactive fixed-effects when estimating coefficients on the observed covariates. First, the model is embedded within the standard two dimensional panel framework and restrictions are formed under which the factor structure methods in Bai (2009) lead to consistent estimation of model parameters, but at slow rates of convergence. The second approach develops a kernel weighted fixed-effects method that is more robust to the multidimensional nature of the problem and can achieve the parametric rate of consistency under certain conditions. Theoretical results and simulations show some benefits to standard two-dimensional panel methods when the structure of the interactive fixed-effect term is known, but also highlight how the kernel weighted method performs well without knowledge of this structure. The methods are implemented to estimate the demand elasticity for beer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11691v3</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Freeman</dc:creator>
    </item>
    <item>
      <title>Hierarchical DCC-HEAVY Model for High-Dimensional Covariance Matrices</title>
      <link>https://arxiv.org/abs/2305.08488</link>
      <description>arXiv:2305.08488v2 Announce Type: replace 
Abstract: We introduce a HD DCC-HEAVY class of hierarchical-type factor models for high-dimensional covariance matrices, employing the realized measures built from higher-frequency data. The modelling approach features straightforward estimation and forecasting schemes, independent of the cross-sectional dimension of the assets under consideration, and accounts for sophisticated asymmetric dynamics in the covariances. Empirical analyses suggest that the HD DCC-HEAVY models have a better in-sample fit and deliver statistically and economically significant out-of-sample gains relative to the existing hierarchical factor model and standard benchmarks. The results are robust under different frequencies and market conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08488v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emilija Dzuverovic, Matteo Barigozzi</dc:creator>
    </item>
    <item>
      <title>Variable Selection in High Dimensional Linear Regressions with Parameter Instability</title>
      <link>https://arxiv.org/abs/2312.15494</link>
      <description>arXiv:2312.15494v2 Announce Type: replace 
Abstract: This paper considers the problem of variable selection allowing for parameter instability. It distinguishes between signal and pseudo-signal variables that are correlated with the target variable, and noise variables that are not, and investigate the asymptotic properties of the One Covariate at a Time Multiple Testing (OCMT) method proposed by Chudik et al. (2018) under parameter insatiability. It is established that OCMT continues to asymptotically select an approximating model that includes all the signals and none of the noise variables. Properties of post selection regressions are also investigated, and in-sample fit of the selected regression is shown to have the oracle property. The theoretical results support the use of unweighted observations at the selection stage of OCMT, whilst applying down-weighting of observations only at the forecasting stage. Monte Carlo and empirical applications show that OCMT without down-weighting at the selection stage yields smaller mean squared forecast errors compared to Lasso, Adaptive Lasso, and boosting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15494v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Chudik, M. Hashem Pesaran, Mahrad Sharifvaghefi</dc:creator>
    </item>
  </channel>
</rss>
