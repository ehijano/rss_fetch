<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 05:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Forecasting Seasonal Peaks of Pediatric Respiratory Infections Using an Alert-Based Model Combining SIR Dynamics and Historical Trends in Santiago, Chile</title>
      <link>https://arxiv.org/abs/2601.09821</link>
      <description>arXiv:2601.09821v1 Announce Type: new 
Abstract: Acute respiratory infections (ARI) are a major cause of pediatric hospitalization in Chile, producing marked winter increases in demand that challenge hospital planning. This study presents an alert-based forecasting model to predict the timing and magnitude of ARI hospitalization peaks in Santiago. The approach integrates a seasonal SIR model with a historical mobile predictor, activated by a derivative-based alert system that detects early epidemic growth. Daily hospitalization data from DEIS were smoothed using a 15-day moving average and Savitzky-Golay filtering, and parameters were estimated using a penalized loss function to reduce sensitivity to noise. Retrospective evaluation and real-world implementation in major Santiago pediatric hospitals during 2023 and 2024 show that peak date can be anticipated about one month before the event and predicted with high accuracy two weeks in advance. Peak magnitude becomes informative roughly ten days before the peak and stabilizes one week prior. The model provides a practical and interpretable tool for hospital preparedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09821v1</guid>
      <category>stat.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gloria Henr\'iquez, Jhoan B\'aez, V\'ictor Riquelme, Pedro Gajardo, Michel Royer, H\'ector Ram\'irez</dc:creator>
    </item>
    <item>
      <title>The Knowable Future: Mapping the Decay of Past-Future Mutual Information Across Forecast Horizons</title>
      <link>https://arxiv.org/abs/2601.10006</link>
      <description>arXiv:2601.10006v1 Announce Type: new 
Abstract: The ability to assess ex-ante whether a time series is likely to be accurately forecast is important for forecasting practice because it informs the degree of modelling effort warranted. We define forecastability as a property of a time series (given a declared information set), and measure horizon-specific forecastability as the reduction in uncertainty provided by the past, using auto-mutual information (AMI) at lag h. AMI is estimated from training data using a k-nearest-neighbour estimator and evaluated against out-of-sample forecast error (sMAPE) on a filtered, balanced sample of 1,350 M4 series across six sampling frequencies. Seasonal Naive, ETS, and N-BEATS are used as probes of out-of-sample forecast performance. Training-only AMI provides a frequency-conditional diagnostic for forecast difficulty: for Hourly, Weekly, Quarterly, and Yearly series, AMI exhibits consistently negative rank correlation with sMAPE across probes. Under N-BEATS, the correlation is strongest for Hourly (p= -0.52) and Weekly (p= -0.51), with Quarterly (p= -0.42) and Yearly (p = -0.36) also substantial. Monthly is probe-dependent (Seasonal Naive p= -0.12; ETS p = -0.26; N-BEATS p = -0.24). Daily shows notably weaker AMI-sMAPE correlation under this protocol, suggesting limited ability to discriminate between series despite the presence of temporal dependence. The findings support within-frequency triage and effort allocation based on measurable signal content prior to forecasting, rather than between-frequency comparisons of difficulty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10006v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Maurice Catt</dc:creator>
    </item>
    <item>
      <title>Modeling mental health trajectories during the COVID-19 pandemic using UK-wide data in the presence of sociodemographic variables</title>
      <link>https://arxiv.org/abs/2601.10445</link>
      <description>arXiv:2601.10445v1 Announce Type: new 
Abstract: Background: The negative effects of the COVID-19 pandemic on the mental health and well-being of populations are an important public health issue. Our study aims to determine the underlying factors shaping mental health trajectories during the COVID-19 pandemic in the UK. Methods: Data from the Understanding Society COVID-19 Study were utilized and the core analysis focussed on GHQ36 scores as the outcome variable. We used GAMs to evaluate trends over time and the role of sociodemographic variables, i.e., age, sex, ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness, on the variation of mental health during the study period. Results: Statistically significant differences in mental health were observed for age, sex,ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness. Women experienced higher GHQ36 scores relative to men with the GHQ36 score expected to increase by 1.260 (95%CI: 1.176, 1.345). Individuals living without a partner were expected to have higher GHQ36 scores, of 1.050 (95%CI: 0.949, 1.148) more than those living with a partner, and age groups 16-34, 35-44, 45-54, 55-64 experienced higher GHQ36 scores relative to those who were 65+. Individuals with relatively lower household income were likely to have poorer mental health relative to those who were more well off. Conclusion: This study identifies key demographic determinants shaping mental health trajectories during the COVID-19 pandemic in the UK. Policies aiming to reduce mental health inequalities should target women, youth, individuals living without a partner, individuals living with children under 16, individuals with a long-term illness, and lower income families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10445v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Glenna Nightingale, Karthik Mohan, Eloi Ribe, Valentin Popov, Shakes Wang, Clara Calia, Luciana Brondi, Sohan Seth</dc:creator>
    </item>
    <item>
      <title>MitoFREQ: A Novel Approach for Mitogenome Frequency Estimation from Top-level Haplogroups and Single Nucleotide Variants</title>
      <link>https://arxiv.org/abs/2601.10464</link>
      <description>arXiv:2601.10464v1 Announce Type: new 
Abstract: Lineage marker population frequencies can serve as one way to express evidential value in forensic genetics. However, for high-quality whole mitochondrial DNA genome sequences (mitogenomes), population data remain limited. In this paper, we offer a new method, MitoFREQ, for estimating the population frequencies of mitogenomes. MitoFREQ uses the mitogenome resources HelixMTdb and gnomAD, harbouring information from 195,983 and 56,406 mitogenomes, respectively. Neither HelixMTdb nor gnomAD can be queried directly for individual mitogenome frequencies, but offers single nucleotide variant (SNV) allele frequencies for each of 30 "top-level" haplogroups (TLHG). We propose using the HelixMTdb and gnomAD resources by classifying a given mitogenome within the TLHG scheme and subsequently using the frequency of its rarest SNV within that TLHG weighted by the TLHG frequency. We show that this method is guaranteed to provide a higher population frequency estimate than if a refined haplogroup and its SNV frequencies were used. Further, we show that top-level haplogrouping can be achieved by using only 227 specific positions for 99.9% of the tested mitogenomes, potentially making the method available for low-quality samples. The method was tested on two types of datasets: high-quality forensic reference datasets and a diverse collection of scrutinised mitogenomes from GenBank. This dual evaluation demonstrated that the approach is robust across both curated forensic data and broader population-level sequences. This method produced likelihood ratios in the range of 100-100,000, demonstrating its potential to strengthen the statistical evaluation of forensic mtDNA evidence. We have developed an open-source R package `mitofreq` that implements our method, including a Shiny app where custom TLHG frequencies can be supplied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10464v1</guid>
      <category>stat.AP</category>
      <category>q-bio.GN</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikkel Meyer Andersen, Nicole Huber, Kimberly S Andreaggi, T\'ora Oluffa Stenberg Olsen, Walther Parson, Charla Marshall</dc:creator>
    </item>
    <item>
      <title>Topological Percolation in Urban Dengue Transmission: A Multi-Scale Analysis of Spatial Connectivity</title>
      <link>https://arxiv.org/abs/2601.09747</link>
      <description>arXiv:2601.09747v1 Announce Type: cross 
Abstract: We investigate the spatial organization of dengue cases in the city of Recife, Brazil, from 2015 to 2024, using tools from statistical physics and topological data analysis. Reported cases are modeled as point clouds in a metric space, and their spatial connectivity is studied through Vietoris-Rips filtrations and zero-dimensional persistent homology, which captures the emergence and collapse of connected components across spatial scales. By parametrizing the filtration using percentiles of the empirical distance distribution, we identify critical percolation thresholds associated with abrupt growth of the largest connected component. These thresholds define distinct geometric regimes, ranging from fragmented spatial patterns to highly concentrated, percolated structures. Remarkably, years with similar incidence levels exhibit qualitatively different percolation behavior, demonstrating that case counts alone do not determine the spatial organization of transmission. Our analysis further reveals pronounced temporal heterogeneity in the percolation properties of dengue spread, including a structural rupture in 2020 characterized by delayed or absent spatial percolation. These findings highlight percolation-based topological observables as physically interpretable and sensitive descriptors of urban epidemic structure, offering a complementary perspective to traditional spatial and epidemiological analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09747v1</guid>
      <category>q-bio.PE</category>
      <category>math.GT</category>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc\'ilio Ferreira dos Santos, Cleiton de Lima Ricardo</dc:creator>
    </item>
    <item>
      <title>Derivations for the Cumulative Standardized Binomial EWMA (CSB-EWMA) Control Chart</title>
      <link>https://arxiv.org/abs/2601.09968</link>
      <description>arXiv:2601.09968v1 Announce Type: cross 
Abstract: This paper presents the exact mathematical derivation of the mean and variance properties for the Exponentially Weighted Moving Average (EWMA) statistic applied to binomial proportion monitoring in Multiple Stream Processes (MSPs). We develop a Cumulative Standardized Binomial EWMA (CSB-EWMA) formulation that provides adaptive control limits based on exact time-varying variance calculations, overcoming the limitations of asymptotic approximations during early-phase monitoring. The derivations are rigorously validated through Monte Carlo simulations, demonstrating remarkable agreement between theoretical predictions and empirical results. This work establishes a theoretical foundation for distribution-free monitoring of binary outcomes across parallel data streams, with applications in statistical process control across diverse domains including manufacturing, healthcare, and cybersecurity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09968v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Faruk Muritala, Austin Brown, Dhrubajyoti Ghosh, Sherry Ni</dc:creator>
    </item>
    <item>
      <title>Selecting and Testing Asset Pricing Models: A Stepwise Approach</title>
      <link>https://arxiv.org/abs/2601.10279</link>
      <description>arXiv:2601.10279v1 Announce Type: cross 
Abstract: The asset pricing literature emphasizes factor models that minimize pricing errors but overlooks unselected candidate factors that could enhance the performance of test assets. This paper proposes a framework for factor model selection and testing by (i) selecting the optimal model that spans the joint efficient frontier of test assets and all candidate factors, and (ii) testing pricing performance on both test assets and unselected candidate factors. Our framework updates a baseline model (e.g., CAPM) sequentially by adding or removing factors based on asset pricing tests. Ensuring model selection consistency, our framework utilizes the asset pricing duality: minimizing cross-sectionally unexplained pricing errors aligns with maximizing the Sharpe ratio of the selected factor model. Empirical evidence shows that workhorse factor models fail asset pricing tests, whereas our proposed 8-factor model is not rejected and exhibits robust out-of-sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10279v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanhao Feng, Wei Lan, Hansheng Wang, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>A Bayesian Discrete Framework for Enhancing Decision-Making Processes in Clinical Trial Designs and Evaluations</title>
      <link>https://arxiv.org/abs/2601.10615</link>
      <description>arXiv:2601.10615v1 Announce Type: cross 
Abstract: This study examines the application of Bayesian approach in the context of clinical trials, emphasizing their increasing importance in contemporary biomedical research. While conventional frequentist approach provides a foundational basis for analysis, it often lacks the flexibility to integrate prior knowledge, which can constrain its effectiveness in adaptive settings. In contrast, Bayesian methods enable continual refinement of statistical inferences through the assimilation of accumulating evidence, thereby supporting more informed decision-making and improving the reliability of trial findings. This paper also considers persistent challenges in clinical investigations, including replication difficulties and the misinterpretation of statistical results, suggesting that Bayesian strategies may offer a path toward enhanced analytical robustness. Moreover, discrete probability models, specifically the Binomial, Poisson, and Negative Binomial distributions are explored for their suitability in modeling clinical endpoints, particularly in trials involving binary responses or data with overdispersion. The discussion further incorporates Bayesian networks and Bayesian estimation techniques, with a comparative evaluation against maximum likelihood estimation to elucidate differences in inferential behavior and practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10615v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paramahansa Pramanik, Arnab Kumar Maity, Anjan Mandal, Haley Kate Robinson</dc:creator>
    </item>
    <item>
      <title>Machine Learning-based Unfolding for Cross Section Measurements in the Presence of Nuisance Parameters</title>
      <link>https://arxiv.org/abs/2512.07074</link>
      <description>arXiv:2512.07074v2 Announce Type: replace 
Abstract: Statistically correcting measured cross sections for detector effects is an important step across many applications. In particle physics, this inverse problem is known as unfolding. In cases with complex instruments, the distortions they introduce are often known only implicitly through simulations of the detector. Modern machine learning has enabled efficient simulation-based approaches for unfolding high-dimensional data. Among these, one of the first methods successfully deployed on experimental data is the OmniFold algorithm, a classifier-based Expectation-Maximization procedure. In practice, however, the forward model is only approximately specified, and the corresponding uncertainty is encoded through nuisance parameters. Building on the well-studied OmniFold algorithm, we show how to extend machine learning-based unfolding to incorporate nuisance parameters. Our new algorithm, called Profile OmniFold, is demonstrated using a Gaussian example as well as a particle physics case study using simulated data from the CMS Experiment at the Large Hadron Collider.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07074v2</guid>
      <category>stat.AP</category>
      <category>hep-ex</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huanbiao Zhu, Krish Desai, Mikael Kuusela, Vinicius Mikuni, Benjamin Nachman, Larry Wasserman</dc:creator>
    </item>
    <item>
      <title>Local-Polynomial Estimation for Multivariate Regression Discontinuity Designs</title>
      <link>https://arxiv.org/abs/2402.08941</link>
      <description>arXiv:2402.08941v3 Announce Type: replace-cross 
Abstract: We study a multivariate regression discontinuity design in which treatment is assigned by crossing a boundary in the space of multiple running variables. We document that the existing bandwidth selector is suboptimal for a multivariate regression discontinuity design when the distance to a boundary point is used for its running variable, and introduce a multivariate local-linear estimator for multivariate regression discontinuity designs. Our estimator is asymptotically valid and can capture heterogeneous treatment effects over the boundary. We demonstrate that our estimator exhibits smaller root mean squared errors and often shorter confidence intervals in numerical simulations. We illustrate our estimator in our empirical applications of multivariate designs of a Colombian scholarship study and a U.S. House of representative voting study and demonstrate that our estimator reveals richer heterogeneous treatment effects with often shorter confidence intervals than the existing estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08941v3</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masayuki Sawada, Takuya Ishihara, Daisuke Kurisu, Yasumasa Matsuda</dc:creator>
    </item>
    <item>
      <title>A response-adaptive multi-arm design for continuous endpoints based on a weighted information measure</title>
      <link>https://arxiv.org/abs/2409.04970</link>
      <description>arXiv:2409.04970v2 Announce Type: replace-cross 
Abstract: Multi-arm trials are gaining interest in practice given the statistical and logistical advantages they can offer. The standard approach uses a fixed allocation ratio, but there is a call for making it adaptive and skewing the allocation of patients towards better-performing arms. However, it is well-known that these approaches might suffer from lower statistical power. We present a response-adaptive design for continuous endpoints which explicitly allows to control the trade-off between the number of patients allocated to the "optimal" arm and the statistical power. Such a balance is achieved through the calibration of a tuning parameter, and we explore robust procedures to select it. The proposed criterion is based on a context-dependent information measure which gives greater weight to treatment arms with characteristics close to a pre-specified clinical target. We establish conditions under which the procedure consistently selects the target arm and derive the corresponding limiting allocation ratios. We also introduce a simulation-based hypothesis testing procedure which focuses on selecting the target arm and discuss strategies to effectively control the type-I error rate. The practical implementation of the proposed criterion and its potential advantage over currently used alternatives are illustrated in the context of early Phase IIa proof-of-concept oncology trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04970v2</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianmarco Caruso, Pavel Mozgunov</dc:creator>
    </item>
  </channel>
</rss>
