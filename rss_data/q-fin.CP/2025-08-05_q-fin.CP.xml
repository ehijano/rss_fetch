<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Aug 2025 01:34:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Financial Connectome: A Brain-Inspired Framework for Modeling Latent Market Dynamics</title>
      <link>https://arxiv.org/abs/2508.02012</link>
      <description>arXiv:2508.02012v1 Announce Type: new 
Abstract: We propose the Financial Connectome, a new scientific discipline that models financial markets through the lens of brain functional architecture. Inspired by the foundational work of group independent component analysis (groupICA) in neuroscience, we reimagine markets not as collections of assets, but as high-dimensional dynamic systems composed of latent market modules. Treating stocks as functional nodes and their co-fluctuations as expressions of collective cognition, we introduce dynamic Market Network Connectivity (dMNC), the financial analogue of dynamic functional connectivity (dFNC). This biologically inspired framework reveals structurally persistent market subnetworks, captures regime shifts, and uncovers systemic early warning signals all without reliance on predictive labels. Our results suggest that markets, like brains, exhibit modular, self-organizing, and temporally evolving architectures. This work inaugurates the field of financial connectomics, a principled synthesis of systems neuroscience and quantitative finance aimed at uncovering the hidden logic of complex economies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02012v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuda Bi, Vince D Calhoun</dc:creator>
    </item>
    <item>
      <title>ByteGen: A Tokenizer-Free Generative Model for Orderbook Events in Byte Space</title>
      <link>https://arxiv.org/abs/2508.02247</link>
      <description>arXiv:2508.02247v1 Announce Type: new 
Abstract: Generative modeling of high-frequency limit order book (LOB) dynamics is a critical yet unsolved challenge in quantitative finance, essential for robust market simulation and strategy backtesting. Existing approaches are often constrained by simplifying stochastic assumptions or, in the case of modern deep learning models like Transformers, rely on tokenization schemes that affect the high-precision, numerical nature of financial data through discretization and binning. To address these limitations, we introduce ByteGen, a novel generative model that operates directly on the raw byte streams of LOB events. Our approach treats the problem as an autoregressive next-byte prediction task, for which we design a compact and efficient 32-byte packed binary format to represent market messages without information loss. The core novelty of our work is the complete elimination of feature engineering and tokenization, enabling the model to learn market dynamics from its most fundamental representation. We achieve this by adapting the H-Net architecture, a hybrid Mamba-Transformer model that uses a dynamic chunking mechanism to discover the inherent structure of market messages without predefined rules. Our primary contributions are: 1) the first end-to-end, byte-level framework for LOB modeling; 2) an efficient packed data representation; and 3) a comprehensive evaluation on high-frequency data. Trained on over 34 million events from CME Bitcoin futures, ByteGen successfully reproduces key stylized facts of financial markets, generating realistic price distributions, heavy-tailed returns, and bursty event timing. Our findings demonstrate that learning directly from byte space is a promising and highly flexible paradigm for modeling complex financial systems, achieving competitive performance on standard market quality metrics without the biases of tokenization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02247v1</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Li, Zhi Chen</dc:creator>
    </item>
    <item>
      <title>Neural Network-Based Algorithmic Trading Systems: Multi-Timeframe Analysis and High-Frequency Execution in Cryptocurrency Markets</title>
      <link>https://arxiv.org/abs/2508.02356</link>
      <description>arXiv:2508.02356v1 Announce Type: new 
Abstract: This paper explores neural network-based approaches for algorithmic trading in cryptocurrency markets. Our approach combines multi-timeframe trend analysis with high-frequency direction prediction networks, achieving positive risk-adjusted returns through statistical modeling and systematic market exploitation. The system integrates diverse data sources including market data, on-chain metrics, and orderbook dynamics, translating these into unified buy/sell pressure signals. We demonstrate how machine learning models can effectively capture cross-timeframe relationships, enabling sub-second trading decisions with statistical confidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02356v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>W\v{e}i Zh\=ang</dc:creator>
    </item>
    <item>
      <title>An Enhanced Focal Loss Function to Mitigate Class Imbalance in Auto Insurance Fraud Detection with Explainable AI</title>
      <link>https://arxiv.org/abs/2508.02283</link>
      <description>arXiv:2508.02283v1 Announce Type: cross 
Abstract: In insurance fraud prediction, handling class imbalance remains a critical challenge. This paper presents a novel multistage focal loss function designed to enhance the performance of machine learning models in such imbalanced settings by helping to escape local minima and converge to a good solution. Building upon the foundation of the standard focal loss, our proposed approach introduces a dynamic, multi-stage convex and nonconvex mechanism that progressively adjusts the focus on hard-to-classify samples across training epochs. This strategic refinement facilitates more stable learning and improved discrimination between fraudulent and legitimate cases. Through extensive experimentation on a real-world insurance dataset, our method achieved better performance than the traditional focal loss, as measured by accuracy, precision, F1-score, recall and Area Under the Curve (AUC) metrics on the auto insurance dataset. These results demonstrate the efficacy of the multistage focal loss in boosting model robustness and predictive accuracy in highly skewed classification tasks, offering significant implications for fraud detection systems in the insurance industry. An explainable model is included to interpret the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02283v1</guid>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francis Boabang, Samuel Asante Gyamerah</dc:creator>
    </item>
    <item>
      <title>Towards Temporal-Aware Multi-Modal Retrieval Augmented Generation in Finance</title>
      <link>https://arxiv.org/abs/2503.05185</link>
      <description>arXiv:2503.05185v2 Announce Type: replace 
Abstract: Finance decision-making often relies on in-depth data analysis across various data sources, including financial tables, news articles, stock prices, etc. In this work, we introduce FinTMMBench, the first comprehensive benchmark for evaluating temporal-aware multi-modal Retrieval-Augmented Generation (RAG) systems in finance. Built from heterologous data of NASDAQ 100 companies, FinTMMBench offers three significant advantages. 1) Multi-modal Corpus: It encompasses a hybrid of financial tables, news articles, daily stock prices, and visual technical charts as the corpus. 2) Temporal-aware Questions: Each question requires the retrieval and interpretation of its relevant data over a specific time period, including daily, weekly, monthly, quarterly, and annual periods. 3) Diverse Financial Analysis Tasks: The questions involve 10 different financial analysis tasks designed by domain experts, including information extraction, trend analysis, sentiment analysis and event detection, etc. We further propose a novel TMMHybridRAG method, which first leverages LLMs to convert data from other modalities (e.g., tabular, visual and time-series data) into textual format and then incorporates temporal information in each node when constructing graphs and dense indexes. Its effectiveness has been validated in extensive experiments, but notable gaps remain, highlighting the challenges presented by our FinTMMBench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05185v2</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <category>cs.MM</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fengbin Zhu, Junfeng Li, Liangming Pan, Wenjie Wang, Fuli Feng, Chao Wang, Huanbo Luan, Tat-Seng Chua</dc:creator>
    </item>
    <item>
      <title>No Tick-Size Too Small: A General Method for Modelling Small Tick Limit Order Books</title>
      <link>https://arxiv.org/abs/2410.08744</link>
      <description>arXiv:2410.08744v3 Announce Type: replace-cross 
Abstract: Tick-sizes not only influence the granularity of the price formation process but also affect market agents' behavior. We investigate the disparity in the microstructural properties of the Limit Order Book (LOB) across a basket of assets with different relative tick-sizes. A key contribution of this study is the identification of several stylized facts, which are used to differentiate between large, medium, and small-tick assets, along with clear metrics for their measurement. We provide cross-asset visualizations to illustrate how these attributes vary with relative tick-size. Further, we propose a Hawkes Process model that {\color{black}not only fits well for large-tick assets, but also accounts for }sparsity, multi-tick level price moves, and the shape of the LOB in small-tick assets. Through simulation studies, we demonstrate the {\color{black} versatility} of the model and identify key variables that determine whether a simulated LOB resembles a large-tick or small-tick asset. Our tests show that stylized facts like sparsity, shape, and relative returns distribution can be smoothly transitioned from a large-tick to a small-tick asset using our model. We test this model's assumptions, showcase its challenges and propose questions for further directions in this area of research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08744v3</guid>
      <category>q-fin.TR</category>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konark Jain, Jean-Fran\c{c}ois Muzy, Jonathan Kochems, Emmanuel Bacry</dc:creator>
    </item>
  </channel>
</rss>
