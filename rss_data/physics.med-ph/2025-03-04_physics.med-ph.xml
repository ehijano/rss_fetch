<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Mar 2025 05:10:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Redefining spectral unmixing for in-vivo brain tissue analysis from hyperspectral imaging</title>
      <link>https://arxiv.org/abs/2503.00198</link>
      <description>arXiv:2503.00198v1 Announce Type: new 
Abstract: In this paper, we propose a methodology for extracting molecular tumor biomarkers from hyperspectral imaging (HSI), an emerging technology for intraoperative tissue assessment. To achieve this, we employ spectral unmixing, allowing to decompose the spectral signals recorded by the HSI camera into their constituent molecular components. Traditional unmixing approaches are based on physical models that establish a relationship between tissue molecules and the recorded spectra. However, these methods commonly assume a linear relationship between the spectra and molecular content, which does not capture the whole complexity of light-matter interaction. To address this limitation, we introduce a novel unmixing procedure that allows to take into account non-linear optical effects while preserving the computational benefits of linear spectral unmixing. We validate our methodology on an in-vivo brain tissue HSI dataset and demonstrate that the extracted molecular information leads to superior classification performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00198v1</guid>
      <category>physics.med-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Hartenberger, Huzeyfe Ayaz, Fatih Ozlugedik, Charly Caredda, Luca Giannoni, Fred Langle, Laurin Lux, Jonas Weidner, Alex Berger, Florian Kofler, Martin Menten, Bruno Montcel, Ilias Tachtsidis, Daniel Rueckert, Ivan Ezhov</dc:creator>
    </item>
    <item>
      <title>AI-Augmented Thyroid Scintigraphy for Robust Classification</title>
      <link>https://arxiv.org/abs/2503.00366</link>
      <description>arXiv:2503.00366v1 Announce Type: new 
Abstract: Thyroid scintigraphy is a key imaging modality for diagnosing thyroid disorders. Deep learning models for thyroid scintigraphy classification often face challenges due to limited and imbalanced datasets, leading to suboptimal generalization. In this study, we investigate the effectiveness of different data augmentation techniques including Stable Diffusion (SD), Flow Matching (FM), and Conventional Augmentation (CA) to enhance the performance of a ResNet18 classifier for thyroid condition classification. Our results showed that FM-based augmentation consistently outperforms SD-based approaches, particularly when combined with original (O) data and CA (O+FM+CA), achieving both high accuracy and fair classification across Diffuse Goiter (DG), Nodular Goiter (NG), Normal (NL), and Thyroiditis (TI) cases. The Wilcoxon statistical analysis further validated the superiority of O+FM and its variants (O+FM+CA) over SD-based augmentations in most scenarios. These findings highlight the potential of FM-based augmentation as a superior approach for generating high-quality synthetic thyroid scintigraphy images and improving model generalization in medical image classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00366v1</guid>
      <category>physics.med-ph</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maziar Sabouri, Ghasem Hajianfar, Alireza Rafiei Sardouei, Milad Yazdani, Azin Asadzadeh, Soroush Bagheri, Mohsen Arabi, Seyed Rasoul Zakavi, Emran Askari, Atena Aghaee, Dena Shahriari, Habib Zaidi, Arman Rahmim</dc:creator>
    </item>
    <item>
      <title>Dual-Input Dynamic Convolution for Positron Range Correction in PET Image Reconstruction</title>
      <link>https://arxiv.org/abs/2503.00587</link>
      <description>arXiv:2503.00587v1 Announce Type: new 
Abstract: Positron range (PR) blurring degrades positron emission tomography (PET) image resolution, particularly for high-energy emitters like gallium-68 (68Ga). We introduce Dual-Input Dynamic Convolution (DDConv), a novel computationally efficient approach trained with voxel-specific PR point spread functions (PSFs) from Monte Carlo (MC) simulations and designed to be utilized within an iterative reconstruction algorithm to perform PR correction (PRC). By dynamically inferring local blurring kernels through a trained convolutional neural network (CNN), DDConv captures complex tissue interfaces more accurately than prior methods. Crucially, it also computes the transpose of the PR operator, ensuring consistency within iterative PET reconstruction. Comparisons with a state-of-the-art, tissue-dependent correction confirm the advantages of DDConv in recovering higher-resolution details in heterogeneous regions, including bone-soft tissue and lung-soft tissue boundaries. Experiments across digital phantoms, MC-simulated data, and patient scans verify that DDConv remains clinically practical through GPU-accelerated convolutions, offering near-MC accuracy while significantly reducing computation times. These results underline DDConv's potential as a routine tool in PET imaging, improving both resolution and fidelity without placing excessive demands on reconstruction resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00587v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youness Mellak, Alexandre Bousse, Thibaut Merlin, \'Elise \'Emond, Dimitris Visvikis</dc:creator>
    </item>
    <item>
      <title>High-Q non-invasive Glucose Sensor using MicrostripLine Main Field and Split Ring Resonator</title>
      <link>https://arxiv.org/abs/2503.00920</link>
      <description>arXiv:2503.00920v1 Announce Type: new 
Abstract: A high-Q sensor integrating microstrip line (MLIN) main field and split ring resonators is presented for non-invasive glucose sensing. The proposed sensor combines the field-focusing effects of split ring resonators with the enhanced field substrate interaction properties of the MLIN main field, using the reflection coefficient (S11) of an open-ended MLIN with the finger as the substrate and operating at 750 MHz and 1.5 GHz. The permittivity of blood inside the finger depends on the glucose concentration, which in turn affects the S11 of the system. Sensor geometry was optimized using Method-of-Moments simulation before the sensor was fabricated and validated on standard solutions of glucose concentrations between 0 to 126 mg/dL within the physiological range, and a human test subject. In both experiments, a near inverse-linear relationship between the S11 peak magnitude and the glucose concentration was observed, demonstrating the sensitivity of the proposed sensor for detecting changes in blood glucose concentration at physiological conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00920v1</guid>
      <category>physics.med-ph</category>
      <category>eess.SP</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Kaiheng Tay, Saumitra Kapoor, Wenwei Yu, Shao Ying Huang</dc:creator>
    </item>
    <item>
      <title>MR-WAVES: MR Water-diffusion And Vascular Effects Simulations</title>
      <link>https://arxiv.org/abs/2503.01318</link>
      <description>arXiv:2503.01318v1 Announce Type: new 
Abstract: Accurate MR signal simulation, including microvascular structures and water diffusion, is crucial for MRI techniques like fMRI BOLD modeling and MR vascular Fingerprinting (MRF), which use susceptibility effects on MR signals for tissue characterization. However, integrating microvascular features and diffusion remains computationally challenging, limiting the accuracy of the estimates. Using advanced modeling and deep neural networks, we propose a novel simulation tool that efficiently accounts for susceptibility and diffusion effects. We used dimension reduction of magnetic field inhomogeneity matrices combined with deep learning method to accelerate the simulations while maintaining their accuracy. We validated our results through an in silico study against a reference method and in vivo MRF experiments. This approach accelerates MR signal generation by a factor of almost 13,000 compared to previously used simulation methods while preserving accuracy. The MR-WAVES method allows fast generation of MR signals accounting for microvascular structures and water-diffusion contribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01318v1</guid>
      <category>physics.med-ph</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Coudert, Mait\^e Silva Martins Mar\c{c}al, Aur\'elien Delphin, Antoine Barrier, Lila Cunge, Lo\"ic Legris, Jan M Warnking, Benjamin Lemasson, Emmanuel L Barbier, Thomas Christen</dc:creator>
    </item>
    <item>
      <title>Development of an Unpaired Deep Neural Network for Synthesizing X-ray Fluoroscopic Images from Digitally Reconstructed Tomography in Image Guided Radiotherapy</title>
      <link>https://arxiv.org/abs/2503.00665</link>
      <description>arXiv:2503.00665v1 Announce Type: cross 
Abstract: Purpose The purpose of this study was to develop and evaluate a deep neural network (DNN) capable of generating flat-panel detector (FPD) images from digitally reconstructed radiography (DRR) images in lung cancer treatment, with the aim of improving clinical workflows in image-guided radiotherapy.
  Methods A modified CycleGAN architecture was trained on paired DRR-FPD image data obtained from patients with lung tumors. The training dataset consisted of over 400 DRR-FPD image pairs, and the final model was evaluated on an independent set of 100 FPD images. Mean absolute error (MAE), peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), and Kernel Inception Distance (KID) were used to quantify the similarity between synthetic and ground-truth FPD images. Computation time for generating synthetic images was also measured.
  Results Despite some positional mismatches in the DRR-FPD pairs, the synthetic FPD images closely resembled the ground-truth FPD images. The proposed DNN achieved notable improvements over both input DRR images and a U-Net-based method in terms of MAE, PSNR, SSIM, and KID. The average image generation time was on the order of milliseconds per image, indicating its potential for real-time application. Qualitative evaluations showed that the DNN successfully reproduced image noise patterns akin to real FPD images, reducing the need for manual noise adjustments.
  Conclusions The proposed DNN effectively converted DRR images into realistic FPD images for thoracic cases, offering a fast and practical method that could streamline patient setup verification and enhance overall clinical workflow. Future work should validate the model across different imaging systems and address remaining challenges in marker visualization, thereby fostering broader clinical adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00665v1</guid>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chisako Hayashi, Shinichiro Mori, Yasukuni Mori, Lim Taehyeung, Hiroki Suyari, Hitoshi Ishikawa</dc:creator>
    </item>
    <item>
      <title>From Claims to Evidence: A Unified Framework and Critical Analysis of CNN vs. Transformer vs. Mamba in Medical Image Segmentation</title>
      <link>https://arxiv.org/abs/2503.01306</link>
      <description>arXiv:2503.01306v1 Announce Type: cross 
Abstract: While numerous architectures for medical image segmentation have been proposed, achieving competitive performance with state-of-the-art models networks such as nnUNet, still leave room for further innovation. In this work, we introduce nnUZoo, an open source benchmarking framework built upon nnUNet, which incorporates various deep learning architectures, including CNNs, Transformers, and Mamba-based models. Using this framework, we provide a fair comparison to demystify performance claims across different medical image segmentation tasks. Additionally, in an effort to enrich the benchmarking, we explored five new architectures based on Mamba and Transformers, collectively named X2Net, and integrated them into nnUZoo for further evaluation. The proposed models combine the features of conventional U2Net, nnUNet, CNN, Transformer, and Mamba layers and architectures, called X2Net (UNETR2Net (UNETR), SwT2Net (SwinTransformer), SS2D2Net (SwinUMamba), Alt1DM2Net (LightUMamba), and MambaND2Net (MambaND)). We extensively evaluate the performance of different models on six diverse medical image segmentation datasets, including microscopy, ultrasound, CT, MRI, and PET, covering various body parts, organs, and labels. We compare their performance, in terms of dice score and computational efficiency, against their baseline models, U2Net, and nnUNet. CNN models like nnUNet and U2Net demonstrated both speed and accuracy, making them effective choices for medical image segmentation tasks. Transformer-based models, while promising for certain imaging modalities, exhibited high computational costs. Proposed Mamba-based X2Net architecture (SS2D2Net) achieved competitive accuracy with no significantly difference from nnUNet and U2Net, while using fewer parameters. However, they required significantly longer training time, highlighting a trade-off between model efficiency and computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01306v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Pooya Mohammadi Kazaj, Giovanni Baj, Yazdan Salimi, Anselm W. Stark, Waldo Valenzuela, George CM. Siontis, Habib Zaidi, Mauricio Reyes, Christoph Graeni, Isaac Shiri</dc:creator>
    </item>
    <item>
      <title>MRI super-resolution reconstruction using efficient diffusion probabilistic model with residual shifting</title>
      <link>https://arxiv.org/abs/2503.01576</link>
      <description>arXiv:2503.01576v1 Announce Type: cross 
Abstract: Objective:This study introduces a residual error-shifting mechanism that drastically reduces sampling steps while preserving critical anatomical details, thus accelerating MRI reconstruction. Approach:We propose a novel diffusion-based SR framework called Res-SRDiff, which integrates residual error shifting into the forward diffusion process. This enables efficient HR image reconstruction by aligning the degraded HR and LR distributions.We evaluated Res-SRDiff on ultra-high-field brain T1 MP2RAGE maps and T2-weighted prostate images, comparing it with Bicubic, Pix2pix, CycleGAN, and a conventional denoising diffusion probabilistic model with vision transformer backbone (TM-DDPM), using quantitative metrics such as peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), gradient magnitude similarity deviation (GMSD), and learned perceptual image patch similarity (LPIPS). Main results: Res-SRDiff significantly outperformed all comparative methods in terms of PSNR, SSIM, and GMSD across both datasets, with statistically significant improvements (p-values&lt;&lt;0.05). The model achieved high-fidelity image restoration with only four sampling steps, drastically reducing computational time to under one second per slice, which is substantially faster than conventional TM-DDPM with around 20 seconds per slice. Qualitative analyses further demonstrated that Res-SRDiff effectively preserved fine anatomical details and lesion morphology in both brain and pelvic MRI images. Significance: Our findings show that Res-SRDiff is an efficient and accurate MRI SR method, markedly improving computational efficiency and image quality. Integrating residual error shifting into the diffusion process allows for rapid and robust HR image reconstruction, enhancing clinical MRI workflows and advancing medical imaging research. The source at:https://github.com/mosaf/Res-SRDiff</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01576v1</guid>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mojtaba Safari, Shansong Wang, Zach Eidex, Qiang Li, Erik H. Middlebrooks, David S. Yu, Xiaofeng Yang</dc:creator>
    </item>
    <item>
      <title>Hemodynamic analysis of the Pulsatile Flow in Tubes of Bipolar Cross Sections</title>
      <link>https://arxiv.org/abs/2407.15035</link>
      <description>arXiv:2407.15035v3 Announce Type: replace 
Abstract: Pulsatile flow through compressed or defective blood vessels is a topic of fundamental importance in hemodynamics, particularly in cardiovascular research. This study examines flow dynamics within a tube with a bipolar cross section, possibly representing the geometry of bicuspid aortic valves (BAV), aortic bifurcations, and the aortic arch regions where non-uniform vessel shapes significantly influence hemodynamic behavior. An analytical solution is derived for the governing equations of pulsatile and poiseuille flow in a bipolar cross-sectional tube. The analysis focuses on the velocity field, flow rate, and wall shear stress (WSS) across different pulsation frequencies and geometric parameters, highlighting how these factors interact to shape flow characteristics. At low frequencies, the velocity profile remains smooth, with gradual acceleration and deceleration phases. In contrast, at higher frequencies, oscillatory effects become more pronounced, and the peak volume flow, initially occurring near ${\omega}t=0$ and ${\omega}t$=${\pi}$, shifts toward an earlier phase in the cycle ${\omega}t=0$ to ${\omega}t={\pi}/2)$ before stabilizing at very high frequencies. Shear stress behavior also exhibits frequency-dependent variations. At low frequencies, the fluid responds smoothly to pressure gradients, producing a shear stress distribution similar to steady flow. However, as frequency increases, inertial and unsteady effects introduce phase lags, leading to more complex shear stress patterns. These findings provide valuable insights into the interplay between vessel geometry and pulsatile forces, with implications for understanding disease progression and refining diagnostic models in cardiovascular medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15035v3</guid>
      <category>physics.med-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Doyeol (David),  Ahn</dc:creator>
    </item>
    <item>
      <title>Application of autoresonance in rapid beam extraction of synchrotrons</title>
      <link>https://arxiv.org/abs/2502.13911</link>
      <description>arXiv:2502.13911v2 Announce Type: replace-cross 
Abstract: In recent years, ultra-high dose rate (FLASH) radiotherapy has become a novel cancer treatment technique because of its similar tumor-killing efficacy as conventional particle therapy while significantly protecting normal tissues. However, due to the limitation of particle number, achieving FLASH condition in a compact heavy-ion synchrotron requires a short extraction time of tens of milliseconds, which is challenging for the conventional RF-KO method. To tackle this challenge, we introduce autoresonance into the third-order resonant extraction for the first time, offering an alternative to the conventional approach of merely increasing the excitation strength. By leveraging a strong detuning effect, a frequency sweeping excitation with small amplitude can drive the entire beam into the autoresonant state, thus enabling rapid beam extraction within a single sweeping period. Compared with the conventional method, this innovative method requires only the addition of an octupole magnet. At the same time, it shows that the conventional RF-KO method has a high autoresonance threshold, so that only a small number of particles that meet the threshold can be excited to large amplitude and be extracted in each sweeping period. In this paper, the autoresonance threshold of a particle in the presence of sextupole and octupole magnetic fields is analyzed, and the single particle simulation shows good agreement with the theoretical formula. Furthermore, the autoresonance based rapid extraction process is simulated and studied, revealing the possibility of millisecond scale beam extraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13911v2</guid>
      <category>physics.acc-ph</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>X. Ding, S. Ruan, H. Ren, G. Wang, R. H. Zhu, J. C. Yang, H. Zhao</dc:creator>
    </item>
  </channel>
</rss>
