<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 Aug 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Mobilisation to Radicalisation: Probing the Persistence and Radicalisation of Social Movements Using an Agent-Based Model</title>
      <link>https://arxiv.org/abs/2408.12795</link>
      <description>arXiv:2408.12795v1 Announce Type: new 
Abstract: We are living in an age of protest. Although we have an excellent understanding of the factors that predict participation in protest, we understand little about the conditions that foster a sustained (versus transient) movement. How do interactions between supporters and authorities combine to influence whether and how people engage (i.e., using conventional or radical tactics)? This paper introduces a novel, theoretically-founded and empirically-informed agent-based model (DIMESim) to address these questions. We model the complex interactions between the psychological attributes of the protester (agents), the authority to whom the protests are targeted, and the environment that allows protesters to coordinate with each other -- over time, and at a population scale. Where an authority is responsive and failure is contested, a modest sized conventional movement endured. Where authorities repeatedly and incontrovertibly fail the movement, the population disengaged from action but evidenced an ongoing commitment to radicalism (latent radicalism).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12795v1</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emma F. Thomas, Mengbin Ye, Simon D. Angus, Tony J. Mathew, Winnifred Louis, Liam Walsh, Silas Ellery, Morgana Lizzio-Wilson, Craig McGarty</dc:creator>
    </item>
    <item>
      <title>Large-scale Collective Dynamics in the Three Iterations of the Reddit r/place Experiment</title>
      <link>https://arxiv.org/abs/2408.13236</link>
      <description>arXiv:2408.13236v1 Announce Type: new 
Abstract: The Reddit r/place experiments were a series of online social experiments hosted by Reddit in 2017, 2022, and 2023, where users were allowed to update the colors of pixels in a large shared canvas. The largest of these experiments (in 2022) has attracted over 100 million users who collaborated and competed to produce elaborate artworks that together provide a unique view of the shared interests connecting the diverse communities on Reddit. The user activity traces resulting from these experiments enable us to analyze how online users engage, collaborate, and compete online at an unprecedented scale. However, this requires labeling millions of updates made during the experiments according to their intended artwork.
  This paper characterizes large-scale activity traces from r/place with a focus on dynamics around successful and failed artworks. To achieve this goal, we propose a dynamic graph clustering algorithm to label artworks by leveraging visual and user-level features. %In the first phase of the algorithm, updates within a snapshot of the experiment are grouped based on proximity, color, and user embeddings. In the second phase, clusters across snapshots are merged via an efficient approximation for the set cover problem. We apply the proposed algorithm to the 2017 edition of r/place and show that it outperforms an existing baseline in terms of accuracy and running time. Moreover, we use our algorithm to identify key factors that distinguish successful from failed artworks in terms of user engagement, collaboration, and competition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13236v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutong Wu, Arlei Silva</dc:creator>
    </item>
    <item>
      <title>Can GPT-4 Models Detect Misleading Visualizations?</title>
      <link>https://arxiv.org/abs/2408.12617</link>
      <description>arXiv:2408.12617v1 Announce Type: cross 
Abstract: The proliferation of misleading visualizations online, particularly during critical events like public health crises and elections, poses a significant risk. This study investigates the capability of GPT-4 models (4V, 4o, and 4o mini) to detect misleading visualizations. Utilizing a dataset of tweet-visualization pairs containing various visual misleaders, we test these models under four experimental conditions with different levels of guidance. We show that GPT-4 models can detect misleading visualizations with moderate accuracy without prior training (naive zero-shot) and that performance notably improves when provided with definitions of misleaders (guided zero-shot). However, a single prompt engineering technique does not yield the best results for all misleader types. Specifically, providing the models with misleader definitions and examples (guided few-shot) proves more effective for reasoning misleaders, while guided zero-shot performs better for design misleaders. This study underscores the feasibility of using large vision-language models to detect visual misinformation and the importance of prompt engineering for optimized detection accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12617v1</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Alexander, Priyal Nanda, Kai-Cheng Yang, Ali Sarvghad</dc:creator>
    </item>
    <item>
      <title>Disentangling, Amplifying, and Debiasing: Learning Disentangled Representations for Fair Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2408.12875</link>
      <description>arXiv:2408.12875v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) have become essential tools for graph representation learning in various domains, such as social media and healthcare. However, they often suffer from fairness issues due to inherent biases in node attributes and graph structure, leading to unfair predictions. To address these challenges, we propose a novel GNN framework, DAB-GNN, that Disentangles, Amplifies, and deBiases attribute, structure, and potential biases in the GNN mechanism. DAB-GNN employs a disentanglement and amplification module that isolates and amplifies each type of bias through specialized disentanglers, followed by a debiasing module that minimizes the distance between subgroup distributions to ensure fairness. Extensive experiments on five datasets demonstrate that DAB-GNN significantly outperforms ten state-of-the-art competitors in terms of achieving an optimal balance between accuracy and fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12875v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeon-Chang Lee, Hojung Shin, Sang-Wook Kim</dc:creator>
    </item>
    <item>
      <title>Fair Pairs: Fairness-Aware Ranking Recovery from Pairwise Comparisons</title>
      <link>https://arxiv.org/abs/2408.13034</link>
      <description>arXiv:2408.13034v1 Announce Type: cross 
Abstract: Pairwise comparisons based on human judgements are an effective method for determining rankings of items or individuals. However, as human biases perpetuate from pairwise comparisons to recovered rankings, they affect algorithmic decision making. In this paper, we introduce the problem of fairness-aware ranking recovery from pairwise comparisons. We propose a group-conditioned accuracy measure which quantifies fairness of rankings recovered from pairwise comparisons. We evaluate the impact of state-of-the-art ranking recovery algorithms and sampling approaches on accuracy and fairness of the recovered rankings, using synthetic and empirical data. Our results show that Fairness-Aware PageRank and GNNRank with FA*IR post-processing effectively mitigate existing biases in pairwise comparisons and improve the overall accuracy of recovered rankings. We highlight limitations and strengths of different approaches, and provide a Python package to facilitate replication and future work on fair ranking recovery from pairwise comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13034v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georg Ahnert, Antonio Ferrara, Claudia Wagner</dc:creator>
    </item>
    <item>
      <title>Spectral Recovery in the Labeled SBM</title>
      <link>https://arxiv.org/abs/2408.13075</link>
      <description>arXiv:2408.13075v1 Announce Type: cross 
Abstract: We consider the problem of exact community recovery in the Labeled Stochastic Block Model (LSBM) with $k$ communities, where each pair of vertices is associated with a label from the set $\{0,1, \dots, L\}$. A pair of vertices from communities $i,j$ is given label $\ell$ with probability $p_{ij}^{(\ell)}$, and the goal is to recover the community partition. We propose a simple spectral algorithm for exact community recovery, and show that it achieves the information-theoretic threshold in the logarithmic-degree regime, under the assumption that the eigenvalues of certain parameter matrices are distinct and nonzero. Our results generalize recent work of Dhara, Gaudio, Mossel, and Sandon (2023), who showed that a spectral algorithm achieves the information-theoretic threshold in the Censored SBM, which is equivalent to the LSBM with $L = 2$. Interestingly, their algorithm uses eigenvectors from two matrix representations of the graph, while our algorithm uses eigenvectors from $L$ matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13075v1</guid>
      <category>math.ST</category>
      <category>cs.SI</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Gaudio, Heming Liu</dc:creator>
    </item>
    <item>
      <title>Did the Roll-Out of Community Notes Reduce Engagement With Misinformation on X/Twitter?</title>
      <link>https://arxiv.org/abs/2307.07960</link>
      <description>arXiv:2307.07960v2 Announce Type: replace 
Abstract: Developing interventions that successfully reduce engagement with misinformation on social media is challenging. One intervention that has recently gained great attention is X/Twitter's Community Notes (previously known as "Birdwatch"). Community Notes is a crowdsourced fact-checking approach that allows users to write textual notes to inform others about potentially misleading posts on X/Twitter. Yet, empirical evidence regarding its effectiveness in reducing engagement with misinformation on social media is missing. In this paper, we perform a large-scale empirical study to analyze whether the introduction of the Community Notes feature and its roll-out to users in the U.S. and around the world have reduced engagement with misinformation on X/Twitter in terms of retweet volume and likes. We employ Difference-in-Differences (DiD) models and Regression Discontinuity Design (RDD) to analyze a comprehensive dataset consisting of all fact-checking notes and corresponding source tweets since the launch of Community Notes in early 2021. Although we observe a significant increase in the volume of fact-checks carried out via Community Notes, particularly for tweets from verified users with many followers, we find no evidence that the introduction of Community Notes significantly reduced engagement with misleading tweets on X/Twitter. Rather, our findings suggest that Community Notes might be too slow to effectively reduce engagement with misinformation in the early (and most viral) stage of diffusion. Our work emphasizes the importance of evaluating fact-checking interventions in the field and offers important implications to enhance crowdsourced fact-checking strategies on social media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07960v2</guid>
      <category>cs.SI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3686967</arxiv:DOI>
      <dc:creator>Yuwei Chuai, Haoye Tian, Nicolas Pr\"ollochs, Gabriele Lenzini</dc:creator>
    </item>
    <item>
      <title>Reconstructing networks from simple and complex contagions</title>
      <link>https://arxiv.org/abs/2405.00129</link>
      <description>arXiv:2405.00129v2 Announce Type: replace 
Abstract: Network scientists often use complex dynamic processes to describe network contagions, but tools for fitting contagion models typically assume simple dynamics. Here, we address this gap by developing a nonparametric method to reconstruct a network and dynamics from a series of node states, using a model that breaks the dichotomy between simple pairwise and complex neighborhood-based contagions. We then show that a network is more easily reconstructed when observed through the lens of complex contagions if it is dense or the dynamic saturates, and that simple contagions are better otherwise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00129v2</guid>
      <category>cs.SI</category>
      <category>q-bio.PE</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas W. Landry, William Thompson, Laurent H\'ebert-Dufresne, Jean-Gabriel Young</dc:creator>
    </item>
    <item>
      <title>Enhancing Community Detection in Networks: A Comparative Analysis of Local Metrics and Hierarchical Algorithms</title>
      <link>https://arxiv.org/abs/2408.09072</link>
      <description>arXiv:2408.09072v2 Announce Type: replace 
Abstract: The analysis and detection of communities in network structures are becoming increasingly relevant for understanding social behavior. One of the principal challenges in this field is the complexity of existing algorithms. The Girvan-Newman algorithm, which uses the betweenness metric as a measure of node similarity, is one of the most representative algorithms in this area. This study employs the same method to evaluate the relevance of using local similarity metrics for community detection. A series of local metrics were tested on a set of networks constructed using the Girvan-Newman basic algorithm. The efficacy of these metrics was evaluated by applying the base algorithm to several real networks with varying community sizes, using modularity and NMI. The results indicate that approaches based on local similarity metrics have significant potential for community detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09072v2</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julio-Omar Palacio-Ni\~no, Fernando Berzal</dc:creator>
    </item>
    <item>
      <title>Adaptability and the Pivot Penalty in Science and Technology</title>
      <link>https://arxiv.org/abs/2107.06476</link>
      <description>arXiv:2107.06476v2 Announce Type: replace-cross 
Abstract: Scientists and inventors set the direction of their work amidst an evolving landscape of questions, opportunities, and challenges. This paper introduces a measurement framework to quantify how far researchers move from their existing research when producing new works. We apply this framework to millions of scientific publications and patents and uncover a pervasive "pivot penalty", where the impact of new research steeply declines the further a researcher moves from their prior work. The pivot penalty applies nearly universally across scientific publishing and patenting and has been growing in magnitude over the past five decades. While creativity frameworks suggest a benefit to exploratory search by researchers and often emphasize outsider advantages in driving breakthroughs, we find little evidence for such an advantage. The pivot penalty is consistent with increasingly narrow specializations of researchers, and when researchers undertake large pivots, a signature of their work is weak engagement with established mixtures of prior knowledge. Unexpected shocks to the research landscape, which may push researchers away from existing areas or pull them into new ones, further demonstrate substantial pivot penalties. COVID-19 provides a high-scale case study, where many researchers engaged the pandemic, yet the pivot penalty remains severe. The pivot penalty generalizes across fields, career stage, productivity, collaboration, and funding contexts, highlighting both the breadth and depth of the adaptive challenge. Overall, the findings point to large and increasing challenges in adapting to new opportunities and threats. The results have implications for individual researchers, research organizations, science policy, and the capacity of science and society as a whole to confront emergent demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.06476v2</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryan Hill, Yian Yin, Carolyn Stein, Xizhao Wang, Dashun Wang, Benjamin F. Jones</dc:creator>
    </item>
    <item>
      <title>The News Comment Gap and Algorithmic Agenda Setting in Online Forums</title>
      <link>https://arxiv.org/abs/2408.07052</link>
      <description>arXiv:2408.07052v2 Announce Type: replace-cross 
Abstract: The disparity between news stories valued by journalists and those preferred by readers, known as the "News Gap", is well-documented. However, the difference in expectations regarding news related user-generated content is less studied. Comment sections, hosted by news websites, are popular venues for reader engagement, yet still subject to editorial decisions. It is thus important to understand journalist vs reader comment preferences and how these are served by various comment ranking algorithms that represent discussions differently. We analyse 1.2 million comments from Austrian newspaper Der Standard to understand the "News Comment Gap" and the effects of different ranking algorithms. We find that journalists prefer positive, timely, complex, direct responses, while readers favour comments similar to article content from elite authors. We introduce the versatile Feature-Oriented Ranking Utility Metric (FORUM) to assess the impact of different ranking algorithms and find dramatic differences in how they prioritise the display of comments by sentiment, topical relevance, lexical diversity, and readability. Journalists can exert substantial influence over the discourse through both curatorial and algorithmic means. Understanding these choices' implications is vital in fostering engaging and civil discussions while aligning with journalistic objectives, especially given the increasing legal scrutiny and societal importance of online discourse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07052v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flora B\"owing, Patrick Gildersleve</dc:creator>
    </item>
  </channel>
</rss>
