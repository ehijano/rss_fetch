<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2024 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Language Model-Guided Framework for Mining Time Series with Distributional Shifts</title>
      <link>https://arxiv.org/abs/2406.05249</link>
      <description>arXiv:2406.05249v1 Announce Type: new 
Abstract: Effective utilization of time series data is often constrained by the scarcity of data quantity that reflects complex dynamics, especially under the condition of distributional shifts. Existing datasets may not encompass the full range of statistical properties required for robust and comprehensive analysis. And privacy concerns can further limit their accessibility in domains such as finance and healthcare. This paper presents an approach that utilizes large language models and data source interfaces to explore and collect time series datasets. While obtained from external sources, the collected data share critical statistical properties with primary time series datasets, making it possible to model and adapt to various scenarios. This method enlarges the data quantity when the original data is limited or lacks essential properties. It suggests that collected datasets can effectively supplement existing datasets, especially involving changes in data distribution. We demonstrate the effectiveness of the collected datasets through practical examples and show how time series forecasting foundation models fine-tuned on these datasets achieve comparable performance to those models without fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05249v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haibei Zhu, Yousef El-Laham, Elizabeth Fons, Svitlana Vyetrenko</dc:creator>
    </item>
    <item>
      <title>Fast assessment of non-Gaussian inputs in structural dynamics exploiting modal solutions</title>
      <link>https://arxiv.org/abs/2406.05269</link>
      <description>arXiv:2406.05269v1 Announce Type: new 
Abstract: In various technical applications, assessing the impact of non-Gaussian processes on responses of dynamic systems is crucial. While simulating time-domain realizations offers an efficient solution for linear dynamic systems, this method proves time-consuming for finite element (FE) models, which may contain thousands to millions of degrees-of-freedom (DOF). Given the central role of kurtosis in describing non-Gaussianity - owing to its concise, parametric-free and easily interpretable nature - this paper introduces a highly efficient approach for deriving response kurtosis and other related statistical descriptions. This approach makes use of the modal solution of dynamic systems, which allows to reduce DOFs and responses analysis to a minimum number in the modal domain. This computational advantage enables fast assessments of non-Gaussian effects for entire FE models. Our approach is illustrated using a simple FE model that has found regular use in the field of random vibration fatigue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05269v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arvid Trapp, Peter Wolfsteiner</dc:creator>
    </item>
    <item>
      <title>Micromechanically motivated finite-strain phase-field fracture model to investigate damage in crosslinked elastomers</title>
      <link>https://arxiv.org/abs/2406.05511</link>
      <description>arXiv:2406.05511v1 Announce Type: new 
Abstract: A micromechanically motivated phase-field damage model is proposed to investigate the fracture behaviour in crosslinked polyurethane adhesive. The crosslinked polyurethane adhesive typically show viscoelastic behaviour with geometric nonlinearity. The finite-strain viscoelastic behaviour is modelled using a micromechanical network model considering shorter and longer chain length distribution. The micromechanical viscoelastic network model also consider the softening due to breakage/debonding of the short chains with increase in deformation. The micromechanical model is coupled with the phase-field damage model to investigate the crack initiation and propagation. Critical energy release rate is needed as a material property to solve phase-field equation. The energy release rate is formulated based on the polymer chain network. The numerical investigation is performed using finite element method. The force-displacement curves from the numerical analysis and experiments are compared to validate the proposed material model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05511v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. P. Josyula, M. Brede, O. Hesebeck, K. Koschek, W. Possart, A. Wulf, B. Zimmer, S. Diebels</dc:creator>
    </item>
    <item>
      <title>Mastering truss structure optimization with tree search</title>
      <link>https://arxiv.org/abs/2406.06145</link>
      <description>arXiv:2406.06145v1 Announce Type: new 
Abstract: This study investigates the combined use of generative grammar rules and Monte Carlo Tree Search (MCTS) for optimizing truss structures. Our approach accommodates intermediate construction stages characteristic of progressive construction settings. We demonstrate the significant robustness and computational efficiency of our approach compared to alternative reinforcement learning frameworks from previous research activities, such as Q-learning or deep Q-learning. These advantages stem from the ability of MCTS to strategically navigate large state spaces, leveraging the upper confidence bound for trees formula to effectively balance exploitation-exploration trade-offs. We also emphasize the importance of early decision nodes in the search tree, reflecting design choices crucial for identifying the global optimum. Additionally, we show how MCTS dynamically adapts to complex and extensive state spaces without significantly affecting solution quality. While the focus of this paper is on truss optimization, our findings suggest MCTS as a powerful tool for addressing other increasingly complex engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06145v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel E. Garayalde, Luca Rosafalco, Matteo Torzoni, Alberto Corigliano</dc:creator>
    </item>
    <item>
      <title>FinVerse: An Autonomous Agent System for Versatile Financial Analysis</title>
      <link>https://arxiv.org/abs/2406.06379</link>
      <description>arXiv:2406.06379v1 Announce Type: new 
Abstract: With the significant advancements in cognitive intelligence driven by LLMs, autonomous agent systems have attracted extensive attention. Despite this growing interest, the development of stable and efficient agent systems poses substantial practical challenges. In this paper, we introduce FinVerse, a meticulously crafted agent system designed for a broad range of financial topics. FinVerse integrates over 600 financial APIs, enabling access to more accurate and extensive financial information compared to generalist agents. To enhance financial information processing capabilities, FinVerse is equipped with an embedded code interpreter, enabling the execution of complex data analysis tasks with precision and efficiency. Our work includes an empirical comparison of several LLMs in driving FinVerse. Specifically, we propose our own scheme for training LLMs using SFT to optimize LLM performance within FinVerse. Recognizing the scarcity of specialized datasets to build LLMs for agents, we have constructed a dataset and plan to make it open-source, providing a valuable resource for peer application developers. The demo video has been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06379v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu An, Qin Li, Junru Lu, Di Yin, Xing Sun</dc:creator>
    </item>
    <item>
      <title>Extremization to Fine Tune Physics Informed Neural Networks for Solving Boundary Value Problems</title>
      <link>https://arxiv.org/abs/2406.05290</link>
      <description>arXiv:2406.05290v1 Announce Type: cross 
Abstract: We propose a novel method for fast and accurate training of physics-informed neural networks (PINNs) to find solutions to boundary value problems (BVPs) and initial boundary value problems (IBVPs). By combining the methods of training deep neural networks (DNNs) and Extreme Learning Machines (ELMs), we develop a model which has the expressivity of DNNs with the fine-tuning ability of ELMs. We showcase the superiority of our proposed method by solving several BVPs and IBVPs which include linear and non-linear ordinary differential equations (ODEs), partial differential equations (PDEs) and coupled PDEs. The examples we consider include a stiff coupled ODE system where traditional numerical methods fail, a 3+1D non-linear PDE, Kovasznay flow and Taylor-Green vortex solutions to incompressible Navier-Stokes equations and pure advection solution of 1+1 D compressible Euler equation.
  The Theory of Functional Connections (TFC) is used to exactly impose initial and boundary conditions (IBCs) of (I)BVPs on PINNs. We propose a modification to the TFC framework named Reduced TFC and show a significant improvement in the training and inference time of PINNs compared to IBCs imposed using TFC. Furthermore, Reduced TFC is shown to be able to generalize to more complex boundary geometries which is not possible with TFC. We also introduce a method of applying boundary conditions at infinity for BVPs and numerically solve the pure advection in 1+1 D Euler equations using these boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05290v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhiram Anand Thiruthummal, Sergiy Shelyag, Eun-jin Kim</dc:creator>
    </item>
    <item>
      <title>3D-MolT5: Towards Unified 3D Molecule-Text Modeling with 3D Molecular Tokenization</title>
      <link>https://arxiv.org/abs/2406.05797</link>
      <description>arXiv:2406.05797v1 Announce Type: cross 
Abstract: The integration of molecule and language has garnered increasing attention in molecular science. Recent advancements in Language Models (LMs) have demonstrated potential for the comprehensive modeling of molecule and language. However, existing works exhibit notable limitations. Most existing works overlook the modeling of 3D information, which is crucial for understanding molecular structures and also functions. While some attempts have been made to leverage external structure encoding modules to inject the 3D molecular information into LMs, there exist obvious difficulties that hinder the integration of molecular structure and language text, such as modality alignment and separate tuning. To bridge this gap, we propose 3D-MolT5, a unified framework designed to model both 1D molecular sequence and 3D molecular structure. The key innovation lies in our methodology for mapping fine-grained 3D substructure representations (based on 3D molecular fingerprints) to a specialized 3D token vocabulary for 3D-MolT5. This 3D structure token vocabulary enables the seamless combination of 1D sequence and 3D structure representations in a tokenized format, allowing 3D-MolT5 to encode molecular sequence (SELFIES), molecular structure, and text sequences within a unified architecture. Alongside, we further introduce 1D and 3D joint pre-training to enhance the model's comprehension of these diverse modalities in a joint representation space and better generalize to various tasks for our foundation model. Through instruction tuning on multiple downstream datasets, our proposed 3D-MolT5 shows superior performance than existing methods in molecular property prediction, molecule captioning, and text-based molecule generation tasks. Our code will be available on GitHub soon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05797v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qizhi Pei, Lijun Wu, Kaiyuan Gao, Jinhua Zhu, Rui Yan</dc:creator>
    </item>
    <item>
      <title>Probabilistic Approach to Black-Box Binary Optimization with Budget Constraints: Application to Sensor Placement</title>
      <link>https://arxiv.org/abs/2406.05830</link>
      <description>arXiv:2406.05830v1 Announce Type: cross 
Abstract: We present a fully probabilistic approach for solving binary optimization problems with black-box objective functions and with budget constraints. In the probabilistic approach, the optimization variable is viewed as a random variable and is associated with a parametric probability distribution. The original optimization problem is replaced with an optimization over the expected value of the original objective, which is then optimized over the probability distribution parameters. The resulting optimal parameter (optimal policy) is used to sample the binary space to produce estimates of the optimal solution(s) of the original binary optimization problem. The probability distribution is chosen from the family of Bernoulli models because the optimization variable is binary. The optimization constraints generally restrict the feasibility region. This can be achieved by modeling the random variable with a conditional distribution given satisfiability of the constraints. Thus, in this work we develop conditional Bernoulli distributions to model the random variable conditioned by the total number of nonzero entries, that is, the budget constraint. This approach (a) is generally applicable to binary optimization problems with nonstochastic black-box objective functions and budget constraints; (b) accounts for budget constraints by employing conditional probabilities that sample only the feasible region and thus considerably reduces the computational cost compared with employing soft constraints; and (c) does not employ soft constraints and thus does not require tuning of a regularization parameter, for example to promote sparsity, which is challenging in sensor placement optimization problems. The proposed approach is verified numerically by using an idealized bilinear binary optimization problem and is validated by using a sensor placement experiment in a parameter identification setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05830v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Attia</dc:creator>
    </item>
    <item>
      <title>Tx-LLM: A Large Language Model for Therapeutics</title>
      <link>https://arxiv.org/abs/2406.06316</link>
      <description>arXiv:2406.06316v1 Announce Type: cross 
Abstract: Developing therapeutics is a lengthy and expensive process that requires the satisfaction of many different criteria, and AI models capable of expediting the process would be invaluable. However, the majority of current AI approaches address only a narrowly defined set of tasks, often circumscribed within a particular domain. To bridge this gap, we introduce Tx-LLM, a generalist large language model (LLM) fine-tuned from PaLM-2 which encodes knowledge about diverse therapeutic modalities. Tx-LLM is trained using a collection of 709 datasets that target 66 tasks spanning various stages of the drug discovery pipeline. Using a single set of weights, Tx-LLM simultaneously processes a wide variety of chemical or biological entities(small molecules, proteins, nucleic acids, cell lines, diseases) interleaved with free-text, allowing it to predict a broad range of associated properties, achieving competitive with state-of-the-art (SOTA) performance on 43 out of 66 tasks and exceeding SOTA on 22. Among these, Tx-LLM is particularly powerful and exceeds best-in-class performance on average for tasks combining molecular SMILES representations with text such as cell line names or disease names, likely due to context learned during pretraining. We observe evidence of positive transfer between tasks with diverse drug types (e.g.,tasks involving small molecules and tasks involving proteins), and we study the impact of model size, domain finetuning, and prompting strategies on performance. We believe Tx-LLM represents an important step towards LLMs encoding biochemical knowledge and could have a future role as an end-to-end tool across the drug discovery development pipeline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06316v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Manuel Zambrano Chaves, Eric Wang, Tao Tu, Eeshit Dhaval Vaishnav, Byron Lee, S. Sara Mahdavi, Christopher Semturs, David Fleet, Vivek Natarajan, Shekoofeh Azizi</dc:creator>
    </item>
    <item>
      <title>Automated Market Maker on the XRP Ledger</title>
      <link>https://arxiv.org/abs/2312.13749</link>
      <description>arXiv:2312.13749v3 Announce Type: replace 
Abstract: Decentralized Finance (DeFi) has emerged as a transformative force in the financial sector, with Automated Market Makers (AMMs) playing a crucial role in facilitating asset exchange and liquidity provision. However, most AMMs operate on the Ethereum blockchain and face challenges such as high transaction fees and price synchronization issues mainly due to Ethereum scalability issues.
  This paper addresses these limitations by investigating the performance of an Automated Market Maker (AMM) integrated at the protocol level of the XRP Ledger. Using game-theoretic simulations, we compared the XRPL-AMM to a Generic CPMM-based AMM (G-AMM) on Ethereum, akin to established players like Uniswap's V2 AMM implementation. The results demonstrate that the XRPL-AMM outperforms in terms of price synchronization with external markets, lower slippage, reduced impermanent loss, and improved returns for liquidity providers, particularly under volatile market conditions. The unique Continuous Auction Mechanism (CAM) of the XRPL-AMM further enhances its efficiency by incentivizing beneficial arbitrage. These findings highlight the potential of protocol-level AMM integration.
  To the best of our knowledge, the XRPL-AMM is one of the first AMMs built directly at the protocol level of a blockchain. Therefore, this inaugural study ventures into the unexplored domain of evaluating AMMs with protocol-level integration compared to traditional smart contracts implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13749v3</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Firas Dahi, Walter Hernandez Cruz, Yebo Feng, Jiahua Xu, Aanchal Malhotra, Paolo Tasca</dc:creator>
    </item>
    <item>
      <title>DiffDA: a Diffusion Model for Weather-scale Data Assimilation</title>
      <link>https://arxiv.org/abs/2401.05932</link>
      <description>arXiv:2401.05932v3 Announce Type: replace 
Abstract: The generation of initial conditions via accurate data assimilation is crucial for weather forecasting and climate modeling. We propose DiffDA as a denoising diffusion model capable of assimilating atmospheric variables using predicted states and sparse observations. Acknowledging the similarity between a weather forecast model and a denoising diffusion model dedicated to weather applications, we adapt the pretrained GraphCast neural network as the backbone of the diffusion model. Through experiments based on simulated observations from the ERA5 reanalysis dataset, our method can produce assimilated global atmospheric data consistent with observations at 0.25 deg (~30km) resolution globally. This marks the highest resolution achieved by ML data assimilation models. The experiments also show that the initial conditions assimilated from sparse observations (less than 0.96% of gridded data) and 48-hour forecast can be used for forecast models with a loss of lead time of at most 24 hours compared to initial conditions from state-of-the-art data assimilation in ERA5. This enables the application of the method to real-world applications, such as creating reanalysis datasets with autoregressive data assimilation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05932v3</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Langwen Huang, Lukas Gianinazzi, Yuejiang Yu, Peter D. Dueben, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>Guided Diffusion for Fast Inverse Design of Density-based Mechanical Metamaterials</title>
      <link>https://arxiv.org/abs/2401.13570</link>
      <description>arXiv:2401.13570v2 Announce Type: replace 
Abstract: Mechanical metamaterial is a synthetic material that can possess extraordinary physical characteristics, such as abnormal elasticity, stiffness, and stability, by carefully designing its internal structure. To make metamaterials contain delicate local structures with unique mechanical properties, it is a potential method to represent them through high-resolution voxels. However, it brings a substantial computational burden. To this end, this paper proposes a fast inverse design method, whose core is an advanced deep generative AI algorithm, to generate voxel-based mechanical metamaterials. Specifically, we use the self-conditioned diffusion model, capable of generating a microstructure with a resolution of $128^3$ to approach the specified homogenized tensor matrix in just 3 seconds. Accordingly, this rapid reverse design tool facilitates the exploration of extreme metamaterials, the sequence interpolation in metamaterials, and the generation of diverse microstructures for multi-scale design. This flexible and adaptive generative tool is of great value in structural engineering or other mechanical systems and can stimulate more subsequent research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13570v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanyan Yang, Lili Wang, Xiaoya Zhai, Kai Chen, Wenming Wu, Yunkai Zhao, Ligang Liu, Xiao-Ming Fu</dc:creator>
    </item>
    <item>
      <title>Predicting Open-Hole Laminates Failure Using Support Vector Machines With Classical and Quantum Kernels</title>
      <link>https://arxiv.org/abs/2405.02903</link>
      <description>arXiv:2405.02903v2 Announce Type: replace 
Abstract: Modeling open hole failure of composites is a complex task, consisting in a highly nonlinear response with interacting failure modes. Numerical modeling of this phenomenon has traditionally been based on the finite element method, but requires to tradeoff between high fidelity and computational cost. To mitigate this shortcoming, recent work has leveraged machine learning to predict the strength of open hole composite specimens. Here, we also propose using data-based models but to tackle open hole composite failure from a classification point of view. More specifically, we show how to train surrogate models to learn the ultimate failure envelope of an open hole composite plate under in-plane loading. To achieve this, we solve the classification problem via support vector machine (SVM) and test different classifiers by changing the SVM kernel function. The flexibility of kernel-based SVM also allows us to integrate the recently developed quantum kernels in our algorithm and compare them with the standard radial basis function (RBF) kernel. Finally, thanks to kernel-target alignment optimization, we tune the free parameters of all kernels to best separate safe and failure-inducing loading states. The results show classification accuracies higher than 90% for RBF, especially after alignment, followed closely by the quantum kernel classifiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02903v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giorgio Tosti Balducci, Boyang Chen, Matthias M\"oller, Marc Gerritsma, Roeland De Breuker</dc:creator>
    </item>
    <item>
      <title>CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification</title>
      <link>https://arxiv.org/abs/2306.10649</link>
      <description>arXiv:2306.10649v4 Announce Type: replace-cross 
Abstract: In the investment industry, it is often essential to carry out fine-grained company similarity quantification for a range of purposes, including market mapping, competitor analysis, and mergers and acquisitions. We propose and publish a knowledge graph, named CompanyKG, to represent and learn diverse company features and relations. Specifically, 1.17 million companies are represented as nodes enriched with company description embeddings; and 15 different inter-company relations result in 51.06 million weighted edges. To enable a comprehensive assessment of methods for company similarity quantification, we have devised and compiled three evaluation tasks with annotated test sets: similarity prediction, competitor retrieval and similarity ranking. We present extensive benchmarking results for 11 reproducible predictive methods categorized into three groups: node-only, edge-only, and node+edge. To the best of our knowledge, CompanyKG is the first large-scale heterogeneous graph dataset originating from a real-world investment platform, tailored for quantifying inter-company similarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10649v4</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TBDATA.2024.3407573</arxiv:DOI>
      <dc:creator>Lele Cao, Vilhelm von Ehrenheim, Mark Granroth-Wilding, Richard Anselmo Stahl, Andrew McCornack, Armin Catovic, Dhiana Deva Cavacanti Rocha</dc:creator>
    </item>
    <item>
      <title>Beyond Gut Feel: Using Time Series Transformers to Find Investment Gems</title>
      <link>https://arxiv.org/abs/2309.16888</link>
      <description>arXiv:2309.16888v2 Announce Type: replace-cross 
Abstract: This paper addresses the growing application of data-driven approaches within the Private Equity (PE) industry, particularly in sourcing investment targets (i.e., companies) for Venture Capital (VC) and Growth Capital (GC). We present a comprehensive review of the relevant approaches and propose a novel approach leveraging a Transformer-based Multivariate Time Series Classifier (TMTSC) for predicting the success likelihood of any candidate company. The objective of our research is to optimize sourcing performance for VC and GC investments by formally defining the sourcing problem as a multivariate time series classification task. We consecutively introduce the key components of our implementation which collectively contribute to the successful application of TMTSC in VC/GC sourcing: input features, model architecture, optimization target, and investor-centric data processing. Our extensive experiments on two real-world investment tasks, benchmarked towards three popular baselines, demonstrate the effectiveness of our approach in improving decision making within the VC and GC industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16888v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lele Cao, Gustaf Halvardsson, Andrew McCornack, Vilhelm von Ehrenheim, Pawel Herman</dc:creator>
    </item>
    <item>
      <title>Physics-Enhanced Machine Learning: a position paper for dynamical systems investigations</title>
      <link>https://arxiv.org/abs/2405.05987</link>
      <description>arXiv:2405.05987v2 Announce Type: replace-cross 
Abstract: This position paper takes a broad look at Physics-Enhanced Machine Learning (PEML) -- also known as Scientific Machine Learning -- with particular focus to those PEML strategies developed to tackle dynamical systems' challenges. The need to go beyond Machine Learning (ML) strategies is driven by: (i) limited volume of informative data, (ii) avoiding accurate-but-wrong predictions; (iii) dealing with uncertainties; (iv) providing Explainable and Interpretable inferences. A general definition of PEML is provided by considering four physics and domain knowledge biases, and three broad groups of PEML approaches are discussed: physics-guided, physics-encoded and physics-informed. The advantages and challenges in developing PEML strategies for guiding high-consequence decision making in engineering applications involving complex dynamical systems, are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05987v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alice Cicirello</dc:creator>
    </item>
  </channel>
</rss>
