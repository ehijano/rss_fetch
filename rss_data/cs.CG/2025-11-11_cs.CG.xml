<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Nov 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Apictorial Jigsaw Puzzle Reconstruction Based on Curve Matching via a Corotational Beam Spline</title>
      <link>https://arxiv.org/abs/2511.06114</link>
      <description>arXiv:2511.06114v1 Announce Type: new 
Abstract: Automatic assembly of apictorial jigsaw puzzles presents a classic curve matching problem, fundamentally challenged by discrete and noisy contour data obtained from digitization. Conventional smoothing methods, which are required to process these data, often distort the curvature-based criteria used for matching and cause a loss of critical information. This paper proposes a method to overcome these issues, demonstrated on the automatic reconstruction of a 54-piece puzzle.
  We reconstruct each piece's contour using a novel corotational beam spline, which models the boundary as a flexible beam with compliant spring supports at the measured data points. A distinctive feature is the dynamic re-indexing of these points; as their calculated positions are refined, they are re-numbered based on their projection onto the computed contour.
  Another contribution is a method for determining spring compliance in proportion to the distance between the point projections. This approach uniquely ensures a uniform degree of smoothing for corresponding curves, making the matching process robust to variations in point density and dependent only on measurement accuracy. Practical computations and the successful automatic reconstruction of the puzzle demonstrate the proposed method's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06114v1</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Igor Orynyak, Dmytro Koltsov, Danylo Tavrov</dc:creator>
    </item>
    <item>
      <title>On Subexponential Parameterized Algorithms for Steiner Tree on Intersection Graphs of Geometric Objects</title>
      <link>https://arxiv.org/abs/2511.07346</link>
      <description>arXiv:2511.07346v1 Announce Type: new 
Abstract: We study the Steiner Tree problem on the intersection graph of most natural families of geometric objects, e.g., disks, squares, polygons, etc. Given a set of $n$ objects in the plane and a subset $T$ of $t$ terminal objects, the task is to find a subset $S$ of $k$ objects such that the intersection graph of $S\cup T$ is connected. Given how typical parameterized problems behave on planar graphs and geometric intersection graphs, we would expect that exact algorithms with some form of subexponential dependence on the solution size or the number of terminals exist. Contrary to this expectation, we show that, assuming the Exponential-Time Hypothesis (ETH), there is no $2^{o(k+t)}\cdot n^{O(1)}$ time algorithm even for unit disks or unit squares, that is, there is no FPT algorithm subexponential in the size of the Steiner tree. However, subexponential dependence can appear in a different form: we show that Steiner Tree can be solved in time $n^{O(\sqrt{t})}$ for many natural classes of objects, including: Disks of arbitrary size. Axis-parallel squares of arbitrary size. Similarly-sized fat polygons.
  This in particular significantly improves and generalizes two recent results: (1) Steiner Tree on unit disks can be solved in time $n^{\Oh(\sqrt{k + t})}$ (Bhore, Carmi, Kolay, and Zehavi, Algorithmica 2023) and (2) Steiner Tree on planar graphs can be solved in time $n^{O(\sqrt{t})}$ (Marx, Pilipczuk, and Pilipczuk, FOCS 2018). We complement our algorithms with lower bounds that demonstrate that the class of objects cannot be significantly extended, even if we allow the running time to be $n^{o(k+t)/\log(k+t)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07346v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sujoy Bhore, Baris Can Esmer, Daniel Marx, Karol Wegrzycki</dc:creator>
    </item>
    <item>
      <title>Fast Queries of Fibered Barcodes</title>
      <link>https://arxiv.org/abs/2511.05837</link>
      <description>arXiv:2511.05837v1 Announce Type: cross 
Abstract: The fibered barcode $\mathcal{F}(M)$ of a bipersistence module $M$ is the map sending each non-negatively sloped affine line $\ell \subset \mathbb{R}^2$ to the barcode of the restriction of $M$ along $\ell$. The simplicity, computability, and stability of $\mathcal{F}(M)$ make it a natural choice of invariant for data analysis applications. In an earlier preprint [arXiv:1512.00180], we introduced a framework for real-time interactive visualization of $\mathcal{F}(M)$, which allows the user to select a single line $\ell$ via a GUI and then plots the associated barcode. This visualization is a key feature of our software RIVET for the visualization and analysis of bipersistent homology. Such interactive visualization requires a framework for efficient queries of $\mathcal{F}(M)$, i.e., for quickly obtaining the barcode along a given line $\ell$. To enable such queries, we introduced a novel data structure based on planar line arrangements, called an augmented arrangement. The aim of the present paper is to give an updated and improved exposition of the parts of our preprint [arXiv:1512.00180] concerning the mathematics of the augmented arrangement and its computation. Notably, by taking the input to be a minimal presentation rather than a chain complex, we are able to substantially simplify our main algorithm and its complexity analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05837v1</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lesnick, Matthew Wright</dc:creator>
    </item>
    <item>
      <title>Revisiting Chazelle's Implementation of the Bottom-Left Heuristic: A Corrected and Rigorous Analysis</title>
      <link>https://arxiv.org/abs/2511.07008</link>
      <description>arXiv:2511.07008v1 Announce Type: cross 
Abstract: The Strip Packing Problem is a classical optimization problem in which a given set of rectangles must be packed, without overlap, into a strip of fixed width and infinite height, while minimizing the total height of the packing. A straightforward and widely studied approach to this problem is the Bottom-Left Heuristic. It consists of iteratively placing each rectangle in the given order at the lowest feasible position in the strip and, in case of ties, at the leftmost of those. Due to its simplicity and good empirical performance, this heuristic is widely used in practical applications. The most efficient implementation of this heuristic was proposed by Chazelle in 1983, requiring $O(n^2)$ time and $O(n)$ space to place $n$ rectangles. However, although Chazelle's original description was largely correct, it omitted several formal details. Furthermore, our analysis revealed a critical flaw in the original runtime analysis, which, in certain cases, results in $\Omega(n^3)$ running time. Motivated by this finding, this paper provides a rigorous and corrected presentation of the implementation, addressing the imprecise arguments and resolving the identified flaw. The resulting analysis establishes a formally verified version of Chazelle's implementation and confirms its quadratic time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07008v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Michel</dc:creator>
    </item>
    <item>
      <title>Stability of 0-dimensional persistent homology in enriched and sparsified point clouds</title>
      <link>https://arxiv.org/abs/2511.07093</link>
      <description>arXiv:2511.07093v1 Announce Type: cross 
Abstract: We give bounds for dimension 0 persistent homology and codimension 1 homology of Vietoris--Rips, alpha, and cubical complex filtrations from finite sets related by enrichment (adding new elements), sparsification (removing elements), and aligning to a grid (uniformly discretizing elements). For enrichment we use barycentric subdivision, for sparsification we use an iterative minimum separating distance procedure, and for aligning to a grid we take the quotient when dividing each coordinate value by a fixed step size. We are motivated by applications to biology, in which the state of a species is inferred through its ``hypervolume'', a high-dimensional space with environmental variables as dimensions. The hypervolume has geometry (volume, convexity) and topology (connectedness, homology), which are known to be related to the current and potentially future status of the species. We offer an approach with topological guarantees that is complementary to modern methods for computing the hypervolume, giving precise bounds between persistence diagrams of Vietoris--Rips and alpha complexes, and a duality identity for cubical complexes. Implementation of our methods, called TopoAware, is made available in C++, Python, and R, building upon the GUDHI library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07093v1</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>J\=anis Lazovskis, Ran Levi, Juliano Morimoto</dc:creator>
    </item>
    <item>
      <title>Geometric implicit neural representations for signed distance functions</title>
      <link>https://arxiv.org/abs/2511.07206</link>
      <description>arXiv:2511.07206v1 Announce Type: cross 
Abstract: \textit{Implicit neural representations} (INRs) have emerged as a promising framework for representing signals in low-dimensional spaces. This survey reviews the existing literature on the specialized INR problem of approximating \textit{signed distance functions} (SDFs) for surface scenes, using either oriented point clouds or a set of posed images. We refer to neural SDFs that incorporate differential geometry tools, such as normals and curvatures, in their loss functions as \textit{geometric} INRs. The key idea behind this 3D reconstruction approach is to include additional \textit{regularization} terms in the loss function, ensuring that the INR satisfies certain global properties that the function should hold -- such as having unit gradient in the case of SDFs. We explore key methodological components, including the definition of INR, the construction of geometric loss functions, and sampling schemes from a differential geometry perspective. Our review highlights the significant advancements enabled by geometric INRs in surface reconstruction from oriented point clouds and posed images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07206v1</guid>
      <category>cs.CV</category>
      <category>cs.CG</category>
      <category>cs.GR</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cag.2024.104085</arxiv:DOI>
      <dc:creator>Luiz Schirmer, Tiago Novello, Vin\'icius da Silva, Guilherme Schardong, Daniel Perazzo, H\'elio Lopes, Nuno Gon\c{c}alves, Luiz Velho</dc:creator>
    </item>
    <item>
      <title>A Polynomial-Time Algorithm for Computing the Exact Convex Hull in High-Dimensional Spaces</title>
      <link>https://arxiv.org/abs/2508.14407</link>
      <description>arXiv:2508.14407v3 Announce Type: replace 
Abstract: This study presents a novel algorithm for identifying the set of extreme points that constitute the exact convex hull of a point set in high-dimensional Euclidean space. The proposed method iteratively solves a sequence of dynamically updated quadratic programming (QP) problems for each point and exploits their solutions to provide theoretical guarantees for exact convex hull identification. For a dataset of \( n \) points in an \( m \)-dimensional space, the algorithm achieves a dimension-independent worst-case time complexity of \( O(n^{p+2} \log(1/\epsilon)) \), where \( p \) depends on the choice of QP solver (e.g., \( p = 4 \) corresponds to the worst-case bound when using an interior-point method), and \( \epsilon \) denotes the target numerical precision (i.e., the optimality tolerance of the QP solver).
  The proposed method is applicable to spaces of arbitrary dimensionality and exhibits particular efficiency in high-dimensional settings, owing to its polynomial-time complexity, whereas existing exponential-time algorithms become computationally impractical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14407v3</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianwei Zhuang</dc:creator>
    </item>
  </channel>
</rss>
