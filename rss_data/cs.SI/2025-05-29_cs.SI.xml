<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 May 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Recovering Fairness Directly from Modularity: a New Way for Fair Community Partitioning</title>
      <link>https://arxiv.org/abs/2505.22684</link>
      <description>arXiv:2505.22684v1 Announce Type: new 
Abstract: Community partitioning is crucial in network analysis, with modularity optimization being the prevailing technique. However, traditional modularity-based methods often overlook fairness, a critical aspect in real-world applications. To address this, we introduce protected group networks and propose a novel fairness-modularity metric. This metric extends traditional modularity by explicitly incorporating fairness, and we prove that minimizing it yields naturally fair partitions for protected groups while maintaining theoretical soundness. We develop a general optimization framework for fairness partitioning and design the efficient Fair Fast Newman (FairFN) algorithm, enhancing the Fast Newman (FN) method to optimize both modularity and fairness. Experiments show FairFN achieves significantly improved fairness and high-quality partitions compared to state-of-the-art methods, especially on unbalanced datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22684v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufeng Wang, Yiguang Bai, Tianqing Zhu, Ismail Ben Ayed, Jing Yuan</dc:creator>
    </item>
    <item>
      <title>BLUE: Bi-layer Heterogeneous Graph Fusion Network for Avian Influenza Forecasting</title>
      <link>https://arxiv.org/abs/2505.22692</link>
      <description>arXiv:2505.22692v1 Announce Type: new 
Abstract: Accurate forecasting of avian influenza outbreaks within wild bird populations requires models that account for complex, multi-scale transmission patterns driven by various factors. Spatio-temporal GNN-based models have recently gained traction for infection forecasting due to their ability to capture relations and flow between spatial regions, but most existing frameworks rely solely on spatial connections and their connections. This overlooks valuable genetic information at the case level, such as cases in one region being genetically descended from strains in another, which is essential for understanding how infectious diseases spread through epidemiological linkages beyond geography. We address this gap with BLUE, a B}i-Layer heterogeneous graph fUsion nEtwork designed to integrate genetic, spatial, and ecological data for accurate outbreak forecasting. The framework 1) builds heterogeneous graphs from multiple information sources and multiple layers, 2) smooths across relation types, 3) performs fusion while retaining structural patterns, and 4) predicts future outbreaks via an autoregressive graph sequence model that captures transmission dynamics over time. To facilitate further research, we introduce \textbf{Avian-US} dataset, the dataset for avian influenza outbreak forecasting in the United States, incorporating genetic, spatial, and ecological data across locations. BLUE achieves superior performance over existing baselines, highlighting the value of incorporating multi-layer information into infectious disease forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22692v1</guid>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing Du, Haley Stone, Yang Yang, Ashna Desai, Hao Xue, Andreas Z\"ufle, Chandini Raina MacIntyre, Flora D. Salim</dc:creator>
    </item>
    <item>
      <title>Offline Map Matching Based on Localization Error Distribution Modeling</title>
      <link>https://arxiv.org/abs/2505.23123</link>
      <description>arXiv:2505.23123v1 Announce Type: new 
Abstract: Offline map matching involves aligning historical trajectories of mobile objects, which may have positional errors, with digital maps. This is essential for applications in intelligent transportation systems (ITS), such as route analysis and traffic pattern mining. Existing methods have two main limitations: (i) they assume a uniform Localization Error Distribution (LED) across urban areas, neglecting environmental factors that lead to suboptimal path search ranges, and (ii) they struggle to efficiently handle local non-shortest paths and detours. To address these issues, we propose a novel offline map matching method for sparse trajectories, called LNSP, which integrates LED modeling and non-shortest path detection. Key innovations include: (i) leveraging public transit trajectories with fixed routes to model LED in finer detail across different city regions, optimizing path search ranges, and (ii) scoring paths using sub-region dependency LED and a sliding window, which reduces global map matching errors. Experimental results using real-world bus and taxi trajectory datasets demonstrate that the LNSP algorithm significantly outperforms existing methods in both efficiency and matching accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23123v1</guid>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruilin Xu, Yuchen Song, Kaijie Li, Xitong Gao, Kejiang Ye, Fan Zhang, Juanjuan Zhao</dc:creator>
    </item>
    <item>
      <title>Homologous nodes in annotated complex networks</title>
      <link>https://arxiv.org/abs/2505.23668</link>
      <description>arXiv:2505.23668v1 Announce Type: new 
Abstract: Many real-world networks have associated metadata that assigns categorical labels to nodes. Analysis of these annotations can complement the topological analysis of complex networks. Annotated networks have typically been used to evaluate community detection approaches. Here, we introduce an approach that combines the quantitative analysis of annotations and network structure, which groups nodes according to similar distributions of node annotations in their neighbourhoods. Importantly the nodes that are grouped together, which we call homologues may not be connected to each other at all. By applying our approach to three very different real-world networks we show that these groupings identify common functional roles and properties of nodes in the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23668v1</guid>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sung Soo Moon, Sebastian E. Ahnert</dc:creator>
    </item>
    <item>
      <title>Representing Higher-Order Networks with Spectral Moments</title>
      <link>https://arxiv.org/abs/2505.23691</link>
      <description>arXiv:2505.23691v1 Announce Type: new 
Abstract: The spectral properties of traditional (dyadic) graphs, where an edge connects exactly two vertices, are widely studied in different applications. These spectral properties are closely connected to the structural properties of dyadic graphs. We generalize such connections and characterize higher-order networks by their spectral information. We first split the higher-order graphs by their ``edge orders" into several uniform hypergraphs. For each uniform hypergraph, we extract the corresponding spectral information from the transition matrices of carefully designed random walks. From each spectrum, we compute the first few spectral moments and use all such spectral moments across different ``edge orders" as the higher-order graph representation. We show that these moments not only clearly indicate the return probabilities of random walks but are also closely related to various higher-order network properties such as degree distribution and clustering coefficient. Extensive experiments show the utility of this new representation in various settings. For instance, graph classification on higher-order graphs shows that this representation significantly outperforms other techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23691v1</guid>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Tian, Shengmin Jin, Reza Zafarani</dc:creator>
    </item>
    <item>
      <title>From Signed Networks to Group Graphs</title>
      <link>https://arxiv.org/abs/2505.22802</link>
      <description>arXiv:2505.22802v1 Announce Type: cross 
Abstract: I show that when there is a symmetry in a process defined on the nodes of a network, this can be captured by a new structure, the ``group graph'', in which group elements label the links of a network. I show that group graphs are a generalisation of signed networks which are an example of a $Z_2$ group graph. I also show that the concept of balance in signed networks can be generalised to group graphs. Finally, I show how the dynamics of processes on a consistent group graph are completely controlled by the topology of the underlying network, not by the symmetry group. This generalises recent results on signed networks (Tian and Lambiotte, 2024a) and complex networks (Tian and Lambiotte, 2024b).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22802v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim S. Evans</dc:creator>
    </item>
    <item>
      <title>Security Benefits and Side Effects of Labeling AI-Generated Images</title>
      <link>https://arxiv.org/abs/2505.22845</link>
      <description>arXiv:2505.22845v1 Announce Type: cross 
Abstract: Generative artificial intelligence is developing rapidly, impacting humans' interaction with information and digital media. It is increasingly used to create deceptively realistic misinformation, so lawmakers have imposed regulations requiring the disclosure of AI-generated content. However, only little is known about whether these labels reduce the risks of AI-generated misinformation.
  Our work addresses this research gap. Focusing on AI-generated images, we study the implications of labels, including the possibility of mislabeling. Assuming that simplicity, transparency, and trust are likely to impact the successful adoption of such labels, we first qualitatively explore users' opinions and expectations of AI labeling using five focus groups. Second, we conduct a pre-registered online survey with over 1300 U.S. and EU participants to quantitatively assess the effect of AI labels on users' ability to recognize misinformation containing either human-made or AI-generated images. Our focus groups illustrate that, while participants have concerns about the practical implementation of labeling, they consider it helpful in identifying AI-generated images and avoiding deception. However, considering security benefits, our survey revealed an ambiguous picture, suggesting that users might over-rely on labels. While inaccurate claims supported by labeled AI-generated images were rated less credible than those with unlabeled AI-images, the belief in accurate claims also decreased when accompanied by a labeled AI-generated image. Moreover, we find the undesired side effect that human-made images conveying inaccurate claims were perceived as more credible in the presence of labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22845v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandra H\"oltervennhoff, Jonas Ricker, Maike M. Raphael, Charlotte Schwedes, Rebecca Weil, Asja Fischer, Thorsten Holz, Lea Sch\"onherr, Sascha Fahl</dc:creator>
    </item>
    <item>
      <title>Seeing the Politics of Decentralized Social Media Protocols</title>
      <link>https://arxiv.org/abs/2505.22962</link>
      <description>arXiv:2505.22962v1 Announce Type: cross 
Abstract: Calls to decentralize feed-based social media have been driven by concerns about the concentrated power of centralized platforms and their societal impact. In response, numerous decentralized social media protocols have emerged, each interpreting "decentralization" in different ways. We analyze four such protocols -- ActivityPub, AT Protocol, Nostr, and Farcaster -- to develop a novel conceptual framework for understanding how protocols operationalize decentralization. Drawing from protocol documentation, media coverage, and first-hand interviews with protocol developers and experts, we contextualize each protocol's approach within their respective socio-technical goals. Our framework highlights how control over key components is distributed differently across each protocol, shaping who holds power over what kinds of decisions. How components are arranged in relation to one another further impacts how component owners might offset each other's power in shaping social media. We argue that examining protocols as artifacts reveals how values shape infrastructure and power dynamics -- and that with a holistic framework as a guide, we can more effectively evaluate and design decentralized platforms aligned with the social and political futures we envision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22962v1</guid>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tolulope Oshinowo, Sohyeon Hwang, Amy X. Zhang, Andr\'es Monroy-Hern\'andez</dc:creator>
    </item>
    <item>
      <title>Evaluating AI capabilities in detecting conspiracy theories on YouTube</title>
      <link>https://arxiv.org/abs/2505.23570</link>
      <description>arXiv:2505.23570v1 Announce Type: cross 
Abstract: As a leading online platform with a vast global audience, YouTube's extensive reach also makes it susceptible to hosting harmful content, including disinformation and conspiracy theories. This study explores the use of open-weight Large Language Models (LLMs), both text-only and multimodal, for identifying conspiracy theory videos shared on YouTube. Leveraging a labeled dataset of thousands of videos, we evaluate a variety of LLMs in a zero-shot setting and compare their performance to a fine-tuned RoBERTa baseline. Results show that text-based LLMs achieve high recall but lower precision, leading to increased false positives. Multimodal models lag behind their text-only counterparts, indicating limited benefits from visual data integration. To assess real-world applicability, we evaluate the most accurate models on an unlabeled dataset, finding that RoBERTa achieves performance close to LLMs with a larger number of parameters. Our work highlights the strengths and limitations of current LLM-based approaches for online harmful content detection, emphasizing the need for more precise and robust systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23570v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo La Rocca, Francesco Corso, Francesco Pierri</dc:creator>
    </item>
    <item>
      <title>PureRank: A Parameter-Free Recursive Importance Measure for Network Nodes</title>
      <link>https://arxiv.org/abs/2501.00417</link>
      <description>arXiv:2501.00417v3 Announce Type: replace 
Abstract: Classical parameter-free centrality measures based on the recursive definition of importance (RDI), such as eigenvector centrality and Seeley centrality, are limited to strongly connected networks, while widely used methods like Katz centrality and PageRank rely on free parameters, such as the damping factor, to handle general networks. This motivates our central question: can an RDI-based importance (centrality) measure be defined for arbitrary networks without any tunable parameters? We answer this by introducing $PureRank$, a parameter-free recursive importance measure that faithfully reflects intrinsic network structure. PureRank classifies nodes into recurrent, transient, and dangling classes using strongly connected component (SCC) decomposition, computes local importance vectors for these classes, and aggregates them globally via the RDI principle. This modular, RDI-based design enables parallel and incremental computation -- ensuring scalability even for large or dynamic networks -- and, crucially, reduces to Seeley centrality (a classical and $pure$ RDI-based measure) on strongly connected networks. Furthermore, PureRank admits a probabilistic interpretation via a random-surfer model. Our numerical experiments illustrate that, unlike PageRank, PureRank yields unique and consistent importance scores for any input network. We also present theoretical extensions to signed networks. These results indicate that PureRank is a robust and transparent alternative to classical RDI-based centralities including PageRank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00417v3</guid>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroyuki Masuyama</dc:creator>
    </item>
    <item>
      <title>Burger: Robust Graph Denoising-augmentation Fusion and Multi-semantic Modeling in Social Recommendation</title>
      <link>https://arxiv.org/abs/2505.06612</link>
      <description>arXiv:2505.06612v2 Announce Type: replace 
Abstract: In the era of rapid development of social media, social recommendation systems as hybrid recommendation systems have been widely applied. Existing methods capture interest similarity between users to filter out interest-irrelevant relations in social networks that inevitably decrease recommendation accuracy, however, limited research has a focus on the mutual influence of semantic information between the social network and the user-item interaction network for further improving social recommendation. To address these issues, we introduce a social \underline{r}ecommendation model with ro\underline{bu}st g\underline{r}aph denoisin\underline{g}-augmentation fusion and multi-s\underline{e}mantic Modeling(Burger). Specifically, we firstly propose to construct a social tensor in order to smooth the training process of the model. Then, a graph convolutional network and a tensor convolutional network are employed to capture user's item preference and social preference, respectively. Considering the different semantic information in the user-item interaction network and the social network, a bi-semantic coordination loss is proposed to model the mutual influence of semantic information. To alleviate the interference of interest-irrelevant relations on multi-semantic modeling, we further use Bayesian posterior probability to mine potential social relations to replace social noise. Finally, the sliding window mechanism is utilized to update the social tensor as the input for the next iteration. Extensive experiments on three real datasets show Burger has a superior performance compared with the state-of-the-art models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06612v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqin Lan, Laurence T. Yang</dc:creator>
    </item>
    <item>
      <title>DeSocial: Blockchain-based Decentralized Social Networks</title>
      <link>https://arxiv.org/abs/2505.21388</link>
      <description>arXiv:2505.21388v2 Announce Type: replace 
Abstract: Web 2.0 social platforms are inherently centralized, with user data and algorithmic decisions controlled by the platform. However, users can only passively receive social predictions without being able to choose the underlying algorithm, which limits personalization. Fortunately, with the emergence of blockchain, users are allowed to choose algorithms that are tailored to their local situation, improving prediction results in a personalized way. In a blockchain environment, each user possesses its own model to perform the social prediction, capturing different perspectives on social interactions. In our work, we propose DeSocial, a decentralized social network learning framework deployed on an Ethereum (ETH) local development chain that integrates distributed data storage, node-level consensus, and user-driven model selection through Ganache. In the first stage, each user leverages DeSocial to evaluate multiple backbone models on their local subgraph. DeSocial coordinates the execution and returns model-wise prediction results, enabling the user to select the most suitable backbone for personalized social prediction. Then, DeSocial uniformly selects several validation nodes that possess the algorithm specified by each user, and aggregates the prediction results by majority voting, to prevent errors caused by any single model's misjudgment. Extensive experiments show that DeSocial has an evident improvement compared to the five classical centralized social network learning models, promoting user empowerment in blockchain-based decentralized social networks, showing the importance of multi-node validation and personalized algorithm selection based on blockchain. Our implementation is available at: https://github.com/agiresearch/DeSocial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21388v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyuan Huang, Xi Zhu, Minghao Guo, Yongfeng Zhang</dc:creator>
    </item>
    <item>
      <title>TINED: GNNs-to-MLPs by Teacher Injection and Dirichlet Energy Distillation</title>
      <link>https://arxiv.org/abs/2412.11180</link>
      <description>arXiv:2412.11180v3 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) are pivotal in graph-based learning, particularly excelling in node classification. However, their scalability is hindered by the need for multi-hop data during inference, limiting their application in latency-sensitive scenarios. Recent efforts to distill GNNs into multi-layer perceptrons (MLPs) for faster inference often underutilize the layer-level insights of GNNs. In this paper, we present TINED, a novel approach that distills GNNs to MLPs on a layer-by-layer basis using Teacher Injection and Dirichlet Energy Distillation techniques. We focus on two key operations in GNN layers: feature transformation (FT) and graph propagation (GP). We recognize that FT is computationally equivalent to a fully-connected (FC) layer in MLPs. Thus, we propose directly transferring teacher parameters from an FT in a GNN to an FC layer in the student MLP, enhanced by fine-tuning. In TINED, the FC layers in an MLP replicate the sequence of FTs and GPs in the GNN. We also establish a theoretical bound for GP approximation. Furthermore, we note that FT and GP operations in GNN layers often exhibit opposing smoothing effects: GP is aggressive, while FT is conservative. Using Dirichlet energy, we develop a DE ratio to measure these effects and propose Dirichlet Energy Distillation to convey these characteristics from GNN layers to MLP layers. Extensive experiments show that TINED outperforms GNNs and leading distillation methods across various settings and seven datasets. Source code are available at https://github.com/scottjiao/TINED_ICML25/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11180v3</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziang Zhou, Zhihao Ding, Jieming Shi, Qing Li, Shiqi Shen</dc:creator>
    </item>
    <item>
      <title>Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms</title>
      <link>https://arxiv.org/abs/2501.13977</link>
      <description>arXiv:2501.13977v3 Announce Type: replace-cross 
Abstract: Social media platforms utilize Machine Learning (ML) and Artificial Intelligence (AI) powered recommendation algorithms to maximize user engagement, which can result in inadvertent exposure to harmful content. Current moderation efforts, reliant on classifiers trained with extensive human-annotated data, struggle with scalability and adapting to new forms of harm. To address these challenges, we propose a novel re-ranking approach using Large Language Models (LLMs) in zero-shot and few-shot settings. Our method dynamically assesses and re-ranks content sequences, effectively mitigating harmful content exposure without requiring extensive labeled data. Alongside traditional ranking metrics, we also introduce two new metrics to evaluate the effectiveness of re-ranking in reducing exposure to harmful content. Through experiments on three datasets, three models and across three configurations, we demonstrate that our LLM-based approach significantly outperforms existing proprietary moderation approaches, offering a scalable and adaptable solution for harm mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13977v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajvardhan Oak, Muhammad Haroon, Claire Jo, Magdalena Wojcieszak, Anshuman Chhabra</dc:creator>
    </item>
  </channel>
</rss>
