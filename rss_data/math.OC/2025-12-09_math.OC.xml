<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Dec 2025 02:44:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unifying Entropy Regularization in Optimal Control: From and Back to Classical Objectives via Iterated Soft Policies and Path Integral Solutions</title>
      <link>https://arxiv.org/abs/2512.06109</link>
      <description>arXiv:2512.06109v2 Announce Type: new 
Abstract: This paper develops a unified perspective on several stochastic optimal control formulations through the lens of Kullback-Leibler regularization. We propose a central problem that separates the KL penalties on policies and transitions, assigning them independent weights, thereby generalizing the standard trajectory-level KL-regularization commonly used in probabilistic and KL-regularized control. This generalized formulation acts as a generative structure allowing to recover various control problems. These include the classical Stochastic Optimal Control (SOC), Risk-Sensitive Optimal Control (RSOC), and their policy-based KL-regularized counterparts. The latter we refer to as soft-policy SOC and RSOC, facilitating alternative problems with tractable solutions. Beyond serving as regularized variants, we show that these soft-policy formulations majorize the original SOC and RSOC problem. This means that the regularized solution can be iterated to retrieve the original solution. Furthermore, we identify a structurally synchronized case of the risk-seeking soft-policy RSOC formulation, wherein the policy and transition KL-regularization weights coincide. Remarkably, this specific setting gives rise to several powerful properties such as a linear Bellman equation, path integral solution, and, compositionality, thereby extending these computationally favourable properties to a broad class of control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06109v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Bhole, Mohammad Mahmoudi Filabadi, Guillaume Crevecoeur, Tom Lefebvre</dc:creator>
    </item>
    <item>
      <title>A note on Johnson's rule for minimizing makespan in the Two-Machine Flow Shop scheduling problem</title>
      <link>https://arxiv.org/abs/2512.06119</link>
      <description>arXiv:2512.06119v2 Announce Type: new 
Abstract: We consider Johnson's rule for minimizing the makespan in the two-machine flow shop scheduling problem. We show that although the worst-case complexity of Johnson's rule is O(n log n), since it requires a complete sorting of the jobs, it is possible to detect in linear time whenever a full sort can be avoided and the optimal solution can be computed in linear time. Computational testing indicates that the linear time complexity always occurs in practice on standard benchmark instances with uniform distribution of the processing times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06119v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Federico Della Croce, Quentin Schau</dc:creator>
    </item>
    <item>
      <title>Data-driven Synchronization for Network Systems with Noiseless Data</title>
      <link>https://arxiv.org/abs/2512.06136</link>
      <description>arXiv:2512.06136v1 Announce Type: new 
Abstract: For a collection of homogeneous LTI systems that is interconnected by a protocol, given the network topology and the system model, one may obtain a feedback gain to synchronize the network. However, the model-based methods cannot be applied in case the system model is unknown. Therefore, in this paper, we study the data-driven synchronization problem for homogeneous networks. In particular, given a collection of LTI systems, we collect the input-state data from one individual system. Then, given the network topology, we provide data-based necessary and sufficient conditions for synchronizability. Once the conditions are satisfied, one can also obtain a feedback gain directly from data to synchronize the network with the corresponding design method provided in this paper. Finally, we illustrate our results with a numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06136v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongzhang Li, M. Kanat Camlibel</dc:creator>
    </item>
    <item>
      <title>A geometric view of formation control with application to directed sensing</title>
      <link>https://arxiv.org/abs/2512.06195</link>
      <description>arXiv:2512.06195v1 Announce Type: new 
Abstract: We propose a geometric approach to distance-based formation control modeled on a minimum-norm lifting of Riemannian gradient descent in edge-space to node-space. This yields a unified family of controllers, including the classical gradient controller and its directed variant. For the directed case, we give a simple numerical test for local convergence that applies to any directed graph and target. We show that persistence is neither necessary nor sufficient for local convergence of our directed controller and propose an alternative that is necessary and more easily checked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06195v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis Theran, Daniel Zelazo, Jessica Sidman</dc:creator>
    </item>
    <item>
      <title>New Results on the Polyak Stepsize: Tight Convergence Analysis and Universal Function Classes</title>
      <link>https://arxiv.org/abs/2512.06231</link>
      <description>arXiv:2512.06231v1 Announce Type: new 
Abstract: In this paper, we revisit a classical adaptive stepsize strategy for gradient descent: the Polyak stepsize (\texttt{PolyakGD}), originally proposed in \cite{polyak1969minimization}. We study the convergence behavior of \texttt{PolyakGD} from two perspectives: tight worst-case analysis and universality across function classes. As our first main result, we establish the tightness of the known convergence rates of \texttt{PolyakGD} by explicitly constructing worst-case functions. In particular, we show that the $\mathcal{O}((1-\frac{1}{\kappa})^K)$ rate for smooth strongly convex functions and the $\mathcal{O}(1/K)$ rate for smooth convex functions are both tight. Moreover, we theoretically show that \texttt{PolyakGD} automatically exploits floating-point errors to escape the worst-case behavior. Our second main result provides new convergence guarantees for \texttt{PolyakGD} under both H\"older smoothness and H\"older growth conditions. These findings show that the Polyak stepsize is universal, automatically adapting to various function classes without requiring prior knowledge of problem parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06231v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang He, Wenzhi Gao, Bo Jiang, Madeleine Udell, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Stabilizing Rate of Stochastic Control Systems with Multiplicative Noise</title>
      <link>https://arxiv.org/abs/2512.06349</link>
      <description>arXiv:2512.06349v1 Announce Type: new 
Abstract: This paper develops a quantitative framework for analyzing the mean-square exponential stabilization of stochastic linear systems with multiplicative noise, focusing specifically on the optimal stabilizing rate, which characterizes the fastest exponential stabilization achievable under admissible control policies. 
Our contributions are twofold. First, we extend norm-based techniques from deterministic switched systems to the stochastic setting, deriving a verifiable necessary and sufficient condition for the exact attainability of the optimal stabilizing rate, together with computable upper and lower bounds. Second, by restricting attention to state-feedback policies, we reformulate the optimal stabilizing rate problem as an optimal control problem with a nonlinear cost function and derive a Bellman-type equation. Since this Bellman-type equation is not directly tractable, we recast it as a nonlinear matrix eigenvalue problem whose valid solutions require strictly positive-definite matrices. To ensure the existence of such solutions, we introduce a regularization scheme and develop a Regularized Normalized Value Iteration (RNVI) algorithm, which in turn generates strictly positive-definite fixed points for a perturbed version of original nonlinear matrix eigenvalue problem while producing feedback controllers. Evaluating these regularized solutions further yields certified lower and upper bounds for the optimal stabilizing rate, resulting in a constructive and verifiable framework for determining the fastest achievable mean-square stabilization under multiplicative noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06349v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Jia, Yuan-Hua Ni, Guangchen Wang</dc:creator>
    </item>
    <item>
      <title>A Low-rank Augmented Lagrangian Method for Polyhedral-SDP and Moment-SOS Relaxations of Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2512.06359</link>
      <description>arXiv:2512.06359v1 Announce Type: new 
Abstract: Polynomial optimization problems (POPs) can be reformulated as geometric convex conic programs, as shown by Kim, Kojima, and Toh (SIOPT 30:1251-1273, 2020), though such formulations remain NP-hard. In this work, we prove that several well-known relaxations can be unified under a common polyhedral-SDP framework, which arises by approximating the intractable cone by tractable intersections of polyhedral cones with the positive semidefinite matrix cone. Although effective in providing tight lower bounds, these relaxations become computationally expensive as the number of variables and constraints grows at the rate of $\Omega(n^{2\tau})$ with the relaxation order $\tau$. To address this challenge, we propose RiNNAL-POP, a low-rank augmented Lagrangian method (ALM) tailored to solve large-scale polyhedral-SDP relaxations of POPs. To efficiently handle the $\Omega(n^{2\tau})$ nonnegativity and consistency constraints, we design a tailored projection scheme whose computational cost scales linearly with the number of variables. In addition, we identify a hidden facial structure in the polyhedral-SDP relaxation, which enables us to eliminate a large number of linear constraints by restricting the matrix variable to affine subspaces corresponding to exposed faces of the semidefinite cone. The latter enables us to efficiently solve the factorized ALM subproblems over the affine subspaces. At each ALM iteration, we additionally carry out a single projected gradient step with respect to the original matrix variable to automatically adjust the rank and escape from spurious local minima when necessary. We also extend our RiNNAL-POP algorithmic framework to solve moment-SOS relaxations of POPs. Extensive numerical experiments on various benchmark problems demonstrate the robustness and efficiency of RiNNAL-POP in solving large-scale polyhedral-SDP relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06359v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Di Hou, Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Compressed Momentum-based Single-Point Zero-Order Algorithm for Stochastic Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2512.06366</link>
      <description>arXiv:2512.06366v1 Announce Type: new 
Abstract: This paper studies a compressed momentum-based single-point zeroth-order algorithm for stochastic distributed nonconvex optimization, aiming to alleviate communication overhead and address the unavailability of explicit gradient information. In the developed framework, each agent has access only to stochastic zeroth-order information of its local objective function, performs local stochastic updates with momentum, and exchanges compressed updates with its neighbors. We theoretically prove that the proposed algorithm can achieve the exact solution with diminishing step sizes and can achieve a sublinear convergence rate towards a neighborhood of the stationary point with fixed step sizes. Numerical experiments validate the effectiveness and communication efficiency of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06366v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linjing Chen, Antai Xie, Xinlei Yi, Xiaoqiang Ren, Xiaofan Wang</dc:creator>
    </item>
    <item>
      <title>The Joint Range of Quadratic Mapping on Hilbert Space</title>
      <link>https://arxiv.org/abs/2512.06437</link>
      <description>arXiv:2512.06437v1 Announce Type: new 
Abstract: We present a novel technical method for analyzing the hidden convex structure embedded in the joint range of a quadratic mapping defined on a Hilbert space. Our approach stands out by relying exclusively on elementary mathematical principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06437v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huu-Quang Nguyen</dc:creator>
    </item>
    <item>
      <title>An Approach to the Joint Rapid and Slow Transit Network Design Problem</title>
      <link>https://arxiv.org/abs/2512.06540</link>
      <description>arXiv:2512.06540v1 Announce Type: new 
Abstract: The increase in congestion in surface traffic, airborne pollution, and other environmental issues have motivated the transit authorities to promote public transit worldwide. In big cities and large metropolitan areas, adding new rapid transit lines attracts more commuters to the public system, as they frequently allow saving travel time as compared to the private mode (car) that faces high congestion. In addition, the travel time has less variability with respect to preset schedules, and rapid lines are more efficient than slow modes operated by buses. When a new rapid transit line is constructed, it partially replaces the traffic of existing slow transit lines. As a consequence, some of the slow-mode lines have to be either canceled or their routes modified to collaborate properly with the new rapid transit line. This process is usually carried out in a sequential way, thus leading to suboptimal solutions.
  In this paper, we consider an integrated model for simultaneously designing rapid and redesigning slow networks. The aim of the model is community-oriented, that is, to maximize the demand covered (or captured) by both modes. We present a mathematical programming formulation that is solved by using a specially improved Benders decomposition. For this purpose, we include a partial decomposition to speed up the computation. The computational experiments are done on a case study based on real data obtained from a survey of mobility among transportation zones in the city of Seville.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06540v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Natividad Gonz\'alez-Blanco, Antonio J. Lozano, Vladimir Marianov, Juan A. Mesa</dc:creator>
    </item>
    <item>
      <title>Semidefinite hierarchies for diagonal unitary invariant bipartite quantum states</title>
      <link>https://arxiv.org/abs/2512.06551</link>
      <description>arXiv:2512.06551v1 Announce Type: new 
Abstract: We investigate questions about the cone $\mathrm{SEP}_n$ of separable bipartite states, consisting of the Hermitian matrices acting on $\mathbb{C}^n\otimes\mathbb{C}^n$ that can be written as conic combinations of rank one matrices of the form $xx^*\otimes yy^*$ with $x,y\in\mathbb{C}^n$. Bipartite states that are not separable are said to be entangled. Detecting quantum entanglement is a fundamental task in quantum information and a hard computational problem. We explore the Doherty-Parrilo-Spedaglieri (DPS) hierarchy of semidefinite conic approximations for $\mathrm{SEP}_n$ when the bipartite states have some additional structural properties: first, (i) for states with diagonal unitary invariance, and second (ii) for states with Bose symmetry. In case (i) we show that the DPS hierarchy can be block diagonalized, which, combining with its moment reformulation, leads to a substantially more efficient implementation. In case (ii), we give a characterization of the dual hierarchy, in terms of sums of squares of Hermitian complex polynomials, extending a known result in the generic case. It turns out that the completely positive cone $\mathrm{CP}_n$, its dual cone $\mathrm{COP}_n$, and their sums-of-squares based conic approximations $\mathcal{K}^{(t)}_n$, play a central role in these two settings (i),(ii). We clarify these connections and test the block diagonal relaxations on classes of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06551v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Britz, Monique Laurent</dc:creator>
    </item>
    <item>
      <title>Switched Linear Ensemble Systems and Structural Controllability</title>
      <link>https://arxiv.org/abs/2512.06561</link>
      <description>arXiv:2512.06561v1 Announce Type: new 
Abstract: This paper introduces and solves a structural controllability problem for ensembles of switched linear systems. All individual subsystems in the ensemble are sparse, governed by the same sparsity pattern, and undergo switching at the same sequence of time instants. The controllability of an ensemble system describes the ability to use a common control input to simultaneously steer every individual system. A sparsity pattern is called structurally controllable for pair \((k,q)\) if it admits a controllable ensemble of \(q\) individual systems with at most \(k\) switches. We derive a necessary and sufficient condition for a sparsity pattern to be structurally controllable for a given \((k,q)\), and characterize when a sparsity pattern admits a finite \(k\) that guarantees structural controllability for \((k,q)\) for arbitrary $q$. Compared with the linear time-invariant ensemble case, this second condition is strictly weaker. We further show that these conditions have natural connections with maximum flow, and hence can be checked by polynomial algorithms. Specifically, the time complexity of deciding structural controllability is \(O(n^3)\) and the complexity of computing the smallest number of switches needed is \(O(n^3 \log n)\), with \(n\) the dimension of each individual subsystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06561v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Yin, Yi Li, Ouyang Du, Bruno Sinopoli, Xudong Chen</dc:creator>
    </item>
    <item>
      <title>Optimal Preconditioning is a Geodesically Convex Optimization Problem</title>
      <link>https://arxiv.org/abs/2512.06618</link>
      <description>arXiv:2512.06618v1 Announce Type: new 
Abstract: We introduce a unified framework for computing approximately-optimal preconditioners for solving linear and non-linear systems of equations. We demonstrate that the condition number minimization problem, under structured transformations such as diagonal and block-diagonal preconditioners, is geodesically convex with respect to unitarily invariant norms, including the Frobenius and Bombieri--Weyl norms. This allows us to introduce efficient first-order algorithms with precise convergence guarantees. 
For linear systems, we analyze the action of symmetric Lie subgroups $G \subseteq \GL_m(\CC) \times \GL_n(\CC)$ on the input matrix and prove that the logarithm of the condition number is a smooth geodesically convex function on the associated Riemannian quotient manifold. We obtain explicit gradient formulas, show Lipschitz continuity, and prove convergence rates for computing the optimal Frobenius condition number: $\widetilde{O}(1/\eps^2)$ iterations for general two-sided preconditioners and $\widetilde{O}(\kappa_F^2 \log(1/\eps))$ for strongly convex cases such as left preconditioning. We extend our framework to consider preconditioning of polynomial systems $\f(x) = 0$, where $\f$ is a system of multivariate polynomials. We analyze the local condition number $\mu(\f, \xi)$, at a root $\xi$ and prove that it also admits a geodesically convex formulation under appropriate group actions. We deduce explicit formulas for the Riemannian gradients and present convergence bounds for the corresponding optimization algorithms. To the best of our knowledge, this is the first preconditioning algorithm with theoretical guarantees for polynomial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06618v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Levent Do\u{g}an, Alperen Erg\"ur, Elias Tsigaridas</dc:creator>
    </item>
    <item>
      <title>PG-Flow: Deterministic implicit policy gradients for geometric product-form queueing networks</title>
      <link>https://arxiv.org/abs/2512.06633</link>
      <description>arXiv:2512.06633v1 Announce Type: new 
Abstract: Product-form queueing networks (PFQNs) admit steady-state distributions that factorize into local terms, and in many classical PFQNs including Jackson, BCMP, G-networks, and Energy Packet Networks, these marginals are geometric and parametrized by local flow variables satisfying balance equations. While this structure yields closed-form expressions for key performance metrics, its use for deterministic steady-state optimization remains limited. We introduce PG-Flow, a deterministic policy-gradient framework that differentiates through the steady-state flow fixed-point equations, providing exact gradients via implicit differentiation and a local adjoint system while avoiding trajectory sampling and Poisson equations. We establish global convergence under structural assumptions (affine flow operators and convex local costs), and show that acyclic networks admit linear-time computation of both flows and gradients. Numerical experiments on routing control in Jackson networks and energy-arrival control in Energy Packet Networks demonstrate that PG-Flow provides a principled and computationally efficient approach to deterministic steady-state optimization in geometric product-form networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06633v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Youssef Ait El Mahjoub</dc:creator>
    </item>
    <item>
      <title>GPU-Accelerated Optimization Solver for Unit Commitment in Large-Scale Power Grids</title>
      <link>https://arxiv.org/abs/2512.06715</link>
      <description>arXiv:2512.06715v1 Announce Type: new 
Abstract: This work presents a GPU-accelerated solver for the unit commitment (UC) problem in large-scale power grids. The solver uses the Primal-Dual Hybrid Gradient (PDHG) algorithm to efficiently solve the relaxed linear subproblem, achieving faster bound estimation and improved crossover and branch-and-bound convergence compared to conventional CPU-based methods. These improvements significantly reduce the total computation time for the mixed-integer linear UC problem. The proposed approach is validated on large-scale systems, including 4224-, 6049-, and 6717-bus networks with long control horizons and computationally intensive problems, demonstrating substantial speed-ups while maintaining solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06715v1</guid>
      <category>math.OC</category>
      <category>cs.AR</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hussein Sharadga, Javad Mohammadi</dc:creator>
    </item>
    <item>
      <title>On the Monotonicity and Rate of Convergence of the Markovian Persuasion Value</title>
      <link>https://arxiv.org/abs/2512.06794</link>
      <description>arXiv:2512.06794v1 Announce Type: new 
Abstract: We study a dynamic Bayesian persuasion model called Markovian persuasion. In such a model, the belief of the receiver regarding the current state of a Markov chain $(X_n)_{n\geq 1}$, over a finite state space $K$, is controlled through signals she obtains from a sender, who observes $(X_n)_{n\geq 1}$ in real time. At each stage $n\geq 1$, the receiver takes an action based on his current belief, which together with the realized state of $X_n$, determines the $n$'th stage payoff of the sender. The sender's goal in a Markovian persuasion game is to find a signaling policy that maximizes her expected $\delta$-discounted sum of stage payoffs for a discount factor $\delta \in [0,1)$. We show that starting from any invariant distribution $(X_n)_{n\geq 1}$ the trajectory of the $\delta$-discounted value is a monotone decreasing in $\delta$. By combining this result with the opposite increasing monotone trajectories found in Lehrer and S.\ (2025, GEB), we are able to derive an upper bound on the rate of convergence of the $\delta$-discounted values (as $\delta \to 1^-$) in the case where $(X_n)_{n\geq 1}$ is ergodic. The results for the Markovian persuasion model are then extended to the Markov chain games model of Renault (2006, MOR).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06794v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitry Shaiderman</dc:creator>
    </item>
    <item>
      <title>Optimal and Diffusion Transports in Machine Learning</title>
      <link>https://arxiv.org/abs/2512.06797</link>
      <description>arXiv:2512.06797v1 Announce Type: new 
Abstract: Several problems in machine learning are naturally expressed as the design and analysis of time-evolving probability distributions. This includes sampling via diffusion methods, optimizing the weights of neural networks, and analyzing the evolution of token distributions across layers of large language models. While the targeted applications differ (samples, weights, tokens), their mathematical descriptions share a common structure. A key idea is to switch from the Eulerian representation of densities to their Lagrangian counterpart through vector fields that advect particles. This dual view introduces challenges, notably the non-uniqueness of Lagrangian vector fields, but also opportunities to craft density evolutions and flows with favorable properties in terms of regularity, stability, and computational tractability. This survey presents an overview of these methods, with emphasis on two complementary approaches: diffusion methods, which rely on stochastic interpolation processes and underpin modern generative AI, and optimal transport, which defines interpolation by minimizing displacement cost. We illustrate how both approaches appear in applications ranging from sampling, neural network optimization, to modeling the dynamics of transformers for large language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06797v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Peyr\'e</dc:creator>
    </item>
    <item>
      <title>Urgent Samples in Clinical Laboratories: Stochastic Batching to Minimize Patient Turnaround Time</title>
      <link>https://arxiv.org/abs/2512.06820</link>
      <description>arXiv:2512.06820v1 Announce Type: new 
Abstract: This paper addresses the problem of batching laboratory samples in hospital laboratories where samples of different priorities are received continuously with uncertain transportation times. The focus is on optimizing the control strategy for loading a centrifuge to minimize patient turnaround time (TAT). While focusing on samples of patients in life-threatening situations (i.e., vital samples), we propose several online and offline methods, including a stochastic mixed-integer quadratic programming model integrated within a discrete-event system simulation. This paper aims to enhance patient care by providing timely laboratory results through improved batching strategies. The case study, which uses real data from a university hospital, demonstrates that incorporating distributional knowledge of transport times into our decision policy can reduce the median patient TAT of vital samples by 4.9 minutes and the 0.95 quantile by 9.7 minutes, but has no significant effect on low-priority samples. In addition, we show that this is essentially an optimal result by comparison with the upper bound obtained by a perfect-knowledge offline algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06820v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonin Novak, Andrzej Gnatowski, Premysl Sucha</dc:creator>
    </item>
    <item>
      <title>OEF (Proximal) Newton-type Method with Inexact Derivatives for Unconstrained Optimization</title>
      <link>https://arxiv.org/abs/2512.06825</link>
      <description>arXiv:2512.06825v1 Announce Type: new 
Abstract: In this paper, we propose objective-evaluation-free (OEF) variants of the proximal Newton method for nonconvex composite optimization problems and the regularized Newton method for unconstrained optimization problems, respectively, using inexact evaluations of gradients and Hessians. Theoretical analysis demonstrates that the global/local convergence rates of the proposed algorithms are consistent with those achieved when both objective function and derivatives are evaluated exactly. Additionally, we present an OEF regularized Newton and negative curvature algorithm that uses inexact derivatives to find approximate second-order stationary points for unconstrained optimization problems. The worst-case iteration/(sample) operation complexity of the proposed algorithm matches the optimal results reported in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06825v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Zhu</dc:creator>
    </item>
    <item>
      <title>Inverse problems for infinite-dimensional transport PDEs on Wasserstein space</title>
      <link>https://arxiv.org/abs/2512.06871</link>
      <description>arXiv:2512.06871v1 Announce Type: new 
Abstract: We develop a foundational framework for inverse problems governed by evolutionary partial differential equations (PDEs) on the Wasserstein space of probability measures. While the forward problems for such transport-type PDEs have been extensively and intensively studied, their corresponding inverse problems--which aim to reconstruct unknown operators, cost functions, or interaction kernels from observed solution data--remain largely unexplored at this level of generality.
  The cornerstone of our theory is a systematic approach featuring high-order calculus on the Wasserstein space and a progressive variational scheme. This methodology is specifically designed to address the challenges inherent in inverse problems for infinite-dimensional, nonlinear, and nonlocal transport PDEs.
  We demonstrate the power and versatility of our theory through two canonical examples: inverse problems for both the Mean Field Control (MFC) Dynamic Programming Equation and the Mean Field Game (MFG) Master Equation. Our work provides, for the first time, a unified foundation for identifying cost functions and interaction kernels from value function data. This establishes a new and fertile field of mathematical research with significant implications for both theory and applications in stochastic control and mean field games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06871v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Liu, Jianliang Qian, Shen Zhang</dc:creator>
    </item>
    <item>
      <title>Set-based Optimal, Robust, and Resilient Control with Applications to Autonomous Precision Landing</title>
      <link>https://arxiv.org/abs/2512.07043</link>
      <description>arXiv:2512.07043v1 Announce Type: new 
Abstract: We present a real-time-capable set-based framework for closed-loop predictive control of autonomous systems using tools from computational geometry, dynamic programming, and convex optimization. The control architecture relies on the offline precomputation of the controllable tube, i.e, a time-indexed sequence of controllable sets. Sets are represented using constrained zonotopes (CZs), which are efficient encodings of convex polytopes that support fast set operations and enable tractable dynamic programming in high dimensions. Online, we obtain a globally optimal control profile by solving a series of one-step optimal control problems. Our key contributions are: (1) free-final-time optimality: we devise an optimal horizon computation algorithm to achieve global optimality; (2) robustness: we handle stochastic uncertainty in both the state and control, with probabilistic guarantees, by constructing bounded disturbance sets; (3) resilience: we develop (i) an optimization-free approach to computing the instantaneous reachable set, i.e., the reachable set from the current state, to enable, for example, large/maximal divert maneuvers, and (ii) an approach to achieving maximal decision-deferral, i.e., maintaining reachability/divert-feasibility to multiple targets for as long as possible. By means of an autonomous precision landing case study, we demonstrate globally optimal free-final-time guidance, robustness to navigation and actuation uncertainties, instantaneous divert envelope computation, and maximal decision-deferral.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07043v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhinav G. Kamath, Abraham P. Vinod, Purnanand Elango, Stefano Di Cairano, Avishai Weiss</dc:creator>
    </item>
    <item>
      <title>Minimizing Control Attention:The Linear Gauss-Markov paradigm</title>
      <link>https://arxiv.org/abs/2512.07046</link>
      <description>arXiv:2512.07046v1 Announce Type: new 
Abstract: We revisit the concept of `attention' as a technical term to quantify the effort in calibrating control action based on available data. While Wiener, in his work on Cybernetics, anticipated key principles on prioritizing task-relevant signals, it was not until the late 1990's when Brockett first formulated pertinent optimization problems that have inspired subsequent as well as the present work. `Attention,' as a technical term, is defined so as to quantify the dependence of the control law on the time and space/state coordinate; a control law that is independent of time and space, assuming it meets specifications, requires vanishing attention. In the present work we focus on Linear-Markovian dynamics with Gaussian state uncertainty so as to analyze the structure of minimal-attention control schemes that steer the dynamics between terminal states with Gaussian uncertainty profile.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07046v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ralph Sabbagh, Asmaa Eldesoukey, Mahmoud Abdelgalil, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>An Accelerated Primal Dual Algorithm with Backtracking for Decentralized Constrained Optimization</title>
      <link>https://arxiv.org/abs/2512.07085</link>
      <description>arXiv:2512.07085v1 Announce Type: new 
Abstract: We propose a distributed accelerated primal-dual method with backtracking (D-APDB) for cooperative multi-agent constrained consensus optimization problems over an undirected network of agents, where only those agents connected by an edge can directly communicate to exchange large-volume data vectors using a high-speed, short-range communication protocol, e.g., WiFi, and we also assume that the network allows for one-hop simple information exchange beyond immediate neighbors as in LoRaWAN protocol. The objective is to minimize the sum of agent-specific composite convex functions over agent-specific private constraint sets. Unlike existing decentralized primal-dual methods that require knowledge of the Lipschitz constants, D-APDB automatically adapts to local smoothness by employing a distributed backtracking step-size search. Each agent relies only on first-order oracles associated with its own objective and constraint functions and on local communications with the neighboring agents, without any prior knowledge of Lipschitz constants. We establish $\mathcal{O}(1/K)$ convergence guarantees for sub-optimality, infeasibility and consensus violation, under standard assumptions on smoothness and on the connectivity of the communication graph. To our knowledge, when nodes have private constraints, especially when they are nonlinear convex constraints onto which projections are not cheap to compute, D-APDB is the first distributed method with backtracking that achieves the optimal convergence rate for the class of constrained composite convex optimization problems. We also provide numerical results for D-APDB on a distributed QCQP problem illustrating the potential performance gains that can be achieved by D-APDB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07085v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushui Xu, Necdet Serhat Aybat, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>Iterative Switching Time Optimization for Mixed-integer Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2512.07213</link>
      <description>arXiv:2512.07213v1 Announce Type: new 
Abstract: This paper proposes an iterative method to solve Mixed-Integer Optimal Control Problems arising from systems with switched dynamics. The so-called relaxed problem plays a central role within this context. Through a numerical example, it is shown why relying on the relaxed problem can lead the solution astray. As an alternative, an iterative Switching Time Optimization method is proposed. The method consists of two components that iteratively interact: a Switching Time Optimization (STO) problem and a sequence optimization. Each component is explained in detail, and the numerical example is resolved, the results of which shows the efficiency of the proposed algorithm. Finally, the advantages and disadvantages of the method are discussed and future lines of research are sketched.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07213v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/ECC57647.2023.10178419</arxiv:DOI>
      <dc:creator>Ramin Abbasi-Esfeden, Wim Van Roy, Jan Swevers</dc:creator>
    </item>
    <item>
      <title>Nash Equilibrium of Bi-objective Optimal Control of Fractional Space-Time Parabolic PDE</title>
      <link>https://arxiv.org/abs/2512.07327</link>
      <description>arXiv:2512.07327v1 Announce Type: new 
Abstract: This work investigates the existence and uniqueness of the Nash equilibrium (solutions to competitive problems in which individual controls aim at separate desired states) for a bi-objective optimal control problem governed by a fractional space-time parabolic partial differential equation. The governing equation involves a Caputo fractional derivative with respect to time of order $\gamma$ in (0,1) and a fractional Laplacian in the spatial variables of order $s$ in (0,1). The system is associated with two independent controls, each aiming at different targets. The problem is formulated as a distributed optimal control system with quadratic cost functionals. Existence and uniqueness of the Nash equilibrium are established under convexity and coercivity assumptions. The solution is computed using conjugate gradient algorithms applied iteratively to the discretized optimal control problems. The numerical experiments agree with the theoretical estimates and demonstrate the efficiency of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07327v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kedarnath Buda, B. V. Rathish Kumar, Anil Rathi</dc:creator>
    </item>
    <item>
      <title>Control and Reinforcement Learning through the Lens of Optimization: An Algorithmic Perspective</title>
      <link>https://arxiv.org/abs/2512.07377</link>
      <description>arXiv:2512.07377v1 Announce Type: new 
Abstract: The connection between control algorithms for Markov decision processes and optimization algorithms has been implicitly and explicitly exploited since the introduction of dynamic programming algorithm by Bellman in the 1950s. Recently, this connection has attracted a lot of attention for developing new control algorithms inspired by well-established optimization algorithms. In this paper, we make this analogy explicit across four problem classes with a unified solution characterization. This novel framework, in turn, allows for a systematic transformation of algorithms from one domain to the other. In particular, we identify equivalent optimization and control algorithms that have already been pointed out in the existing literature, but mostly in a scattered way. We also discuss the issues arising in providing theoretical convergence guarantees for these new control algorithms and provide simple yet effective techniques to solve them. The provided framework and techniques then lay out a concrete methodology for developing new convergent control algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07377v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tolga Ok, Arman Sharifi Kolarijani, Mohamad Amin Sharif Kolarijani, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Open qubit parameter identification with bounded pulses</title>
      <link>https://arxiv.org/abs/2512.07409</link>
      <description>arXiv:2512.07409v1 Announce Type: new 
Abstract: We address the problem of parameter identification for a single open qubit subjected to relaxation and dephasing. Our approach is based on selecting a minimal set of carefully chosen qubit configurations that can be reliably prepared and measured in order to provide an interpretable methodology of parameter identification while potentially minimizing experimental overhead. The protocol relies on saturating control pulses to generate these configurations. In an idealized regime of infinite-amplitude pulses, we demonstrate that the parameters can be reconstructed analytically from the measured observables. We then consider large but finite pulses as a perturbation of this ideal regime and provide bounds on the estimation error introduced by the practical implementation. This framework allows us to separate the sources of uncertainty in the estimation procedure, distinguishing between statistical fluctuations arising from repeated measurements and modeling errors due to deviations from the ideal pulse regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07409v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ghaieth Aloui (McTAO), Ivan Beschastnyi (McTAO), Ludovic Sacchelli (McTAO)</dc:creator>
    </item>
    <item>
      <title>Recovery of the optimal control value function in reproducing kernel Hilbert spaces from verification conditions</title>
      <link>https://arxiv.org/abs/2512.07477</link>
      <description>arXiv:2512.07477v1 Announce Type: new 
Abstract: Approximating the optimal value function $v^*$ for infinite-horizon, nonlinear, autonomous optimal control problems is both challenging and essential for synthesizing real-time optimal feedback. We develop an abstract optimal recovery framework in reproducing kernel Hilbert spaces (RKHS) for reconstructing unknown target functions from mixed equality and inequality functional constraints. Within this framework, the approximation of $v^*$ is cast as a collocation-type problem derived from verification conditions for optimality -- most prominently, the Hamilton-Jacobi-Bellman (HJB) equation -- that uniquely characterizes $v^*$. As the set of collocation points becomes dense in the ambient domain $\Omega$, we establish convergence of the RKHS approximants to $v^*$: globally on $\Omega$ in the RKHS norm when $v^*$ is analytic, and locally (in a neighborhood of the origin) in the RKHS norm when $v^*$ is bounded from above and below by quadratic functions. Furthermore, we show that a practical numerical realization of the abstract scheme reduces to the classical policy iteration algorithm. Numerical experiments support the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07477v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Ehring, Behzad Azmi, Bernard Haasdonk</dc:creator>
    </item>
    <item>
      <title>Energy-Aware Aggregation of Input Data for the Optimisation of Heat Supply of Municipal Districts</title>
      <link>https://arxiv.org/abs/2512.07646</link>
      <description>arXiv:2512.07646v1 Announce Type: new 
Abstract: In the context of municipal heat planning, it is imperative to consider the numerous buildings, numbering in the hundreds or thousands, that are involved. This poses particular challenges for model-based energy system optimization, as the number of variables increases with the number of buildings under consideration. In the worst case, the computational complexity of the models experiences an exponential increase with the number of variables. Furthermore, within the context of heat transition, it is often necessary to map extended periods of time (i.e., the service life of systems) with high resolution (particularly in the case of load peaks that occur at the onset of the day). In response to these challenges, the aggregation of input data is a common practice. In general, building blocks or other geographical and urban formations, such as neighbourhoods, are combined. This article explores the potential of incorporating energy performance indicators into the grouping of buildings. The case study utilizes authentic data from the Neu-Schwachhausen district, grouped based on geographical location, building geometry, and energy performance indicators. The selection of energy indicators includes the annual heat consumption as well as the potential for solar energy generation. To this end, a methodology is hereby presented that considers not only the anticipated annual energy quantity, but also its progression over time. We present a full workflow from geodata to a set of techno-socio-economically Pareto-optimal heat supply options. Our findings suggest that it is beneficial to find a balance between geographical position and energy properties when grouping buildings for the use in energy system models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07646v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrik Sch\"onfeldt, Elif Turhan</dc:creator>
    </item>
    <item>
      <title>Optimal Control of a Higher-Order Cahn-Hilliard Equation Coupled with Brinkman Equation</title>
      <link>https://arxiv.org/abs/2512.07682</link>
      <description>arXiv:2512.07682v1 Announce Type: new 
Abstract: In this work, we investigate optimal control of a Brinkman equation couple with sixth-order Cahn-Hilliard equation. The Cahn-Hilliard equation is endowed with a source term accounting for mass exchange and the velocity equation contains a non divergence-free forcing term, which act as distributed control variable. We consider the aforementioned system with constant mobility, viscosity and nonlinearity of double-well shape is regular. The cost functional of the optimal control problem contains a nondifferentiable term like the $L^1$-norm with sparsity constant $\kappa$, which leads to sparsity of optimal controls. We study the first order necessary optimality condition for both the case $\kappa=0$ and $\kappa&gt;0.$ When the cost functional is differentiable, first order necessary optimality conditions are characterized by Lagrange multiplier method and for nondifferentiable case we have used the idea of Casas and Tr\"oltzsch from the paper (Math. control Relat. Fields, 10(3):527-546, 2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07682v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manika Bag</dc:creator>
    </item>
    <item>
      <title>Strategic Experimentation with Private Payoffs</title>
      <link>https://arxiv.org/abs/2512.06180</link>
      <description>arXiv:2512.06180v1 Announce Type: cross 
Abstract: We study a strategic experimentation game with exponential bandits, in which experiment outcomes are private. The equilibrium amount of experimentation is always higher than in the benchmark case where experiment outcomes are publicly observed. In addition, for pure equilibria, the equilibrium amount of experimentation is at least socially optimal, and possibly higher. We provide a tight bound on the degree of over-experimentation. The analysis rests on a new form of encouragement effect, according to which a player may hide the absence of a success to encourage future experimentation by the other player, which incentivizes current experimentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06180v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\'er\^ome Renault, Eilon Solan, Nicolas Vieille</dc:creator>
    </item>
    <item>
      <title>Diffusion bridge with misspecification: theory construction and application to high-resolution fish count data</title>
      <link>https://arxiv.org/abs/2512.06216</link>
      <description>arXiv:2512.06216v1 Announce Type: cross 
Abstract: Stochastic processes of bridge types having pinned initial and terminal conditions have been widely used in applied research areas, but they all have a common drawback in that the model at hand is possibly misspecified owing to its stochastic nature; namely, parameter values and coefficients are distorted compared to the ground truth. We consider a pair of novel exactly-solvable optimization problems that provide both the lower and upper bounds of the performance index of a diffusion bridge. Our formulation is based on the Girsanov transformation, in which the model uncertainty is measured through relative entropy. We provide a sufficient condition under which these optimization problems are well-posed, and hence admit the corresponding maximizer/minimizer that achieves the worst-case lower and upper bounds given the ambiguity aversion or uncertainty size. We apply the proposed method to the latest 10-min, high-resolution fish count data of a migratory fish in a river and discuss the influence of model uncertainty on the estimation of the total fish count, which is an important problem in resource and environmental management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06216v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka</dc:creator>
    </item>
    <item>
      <title>Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration</title>
      <link>https://arxiv.org/abs/2512.06218</link>
      <description>arXiv:2512.06218v1 Announce Type: cross 
Abstract: This paper applies the authors' recent results on asynchronous stochastic approximation (SA) in the Borkar-Meyn framework to reinforcement learning in average-reward semi-Markov decision processes (SMDPs). We establish the convergence of an asynchronous SA analogue of Schweitzer's classical relative value iteration algorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs. In particular, we show that the algorithm converges almost surely to a compact, connected subset of solutions to the average-reward optimality equation, with convergence to a unique, sample path-dependent solution under additional stepsize and asynchrony conditions. Moreover, to make full use of the SA framework, we introduce new monotonicity conditions for estimating the optimal reward rate in RVI Q-learning. These conditions substantially expand the previously considered algorithmic framework and are addressed through novel arguments in the stability and convergence analysis of RVI Q-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06218v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huizhen Yu, Yi Wan, Richard S. Sutton</dc:creator>
    </item>
    <item>
      <title>Auto-exploration for online reinforcement learning</title>
      <link>https://arxiv.org/abs/2512.06244</link>
      <description>arXiv:2512.06244v1 Announce Type: cross 
Abstract: The exploration-exploitation dilemma in reinforcement learning (RL) is a fundamental challenge to efficient RL algorithms. Existing algorithms for finite state and action discounted RL problems address this by assuming sufficient exploration over both state and action spaces. However, this yields non-implementable algorithms and sub-optimal performance. To resolve these limitations, we introduce a new class of methods with auto-exploration, or methods that automatically explore both state and action spaces in a parameter-free way, i.e.,~without a priori knowledge of problem-dependent parameters. We present two variants: one for the tabular setting and one for linear function approximation. Under algorithm-independent assumptions on the existence of an exploring optimal policy, both methods attain $O(\epsilon^{-2})$ sample complexity to solve to $\epsilon$ error. Crucially, these complexities are novel since they are void of algorithm-dependent parameters seen in prior works, which may be arbitrarily large. The methods are also simple to implement because they are parameter-free and do not directly estimate the unknown parameters. These feats are achieved by new algorithmic innovations for RL, including a dynamic mixing time, a discounted state distribution for sampling, a simple robust gradient estimator, and a recent advantage gap function to certify convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06244v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Kalman Filter</title>
      <link>https://arxiv.org/abs/2512.06286</link>
      <description>arXiv:2512.06286v1 Announce Type: cross 
Abstract: In this work, we propose a noise-centric formulation of the distributionally robust Kalman filter (DRKF) for discrete-time linear stochastic systems with uncertain noise statistics. By placing Wasserstein ambiguity sets directly on the process and measurement noise distributions, the proposed DRKF preserves the analytical structure of the classical Kalman filter while providing a priori spectral bounds on all feasible covariances. In the time-invariant setting, we derive a steady-state DRKF from a single stationary semidefinite program, yielding a constant-gain estimator with the same per-step computational complexity as the standard Kalman filter. We establish conditions guaranteeing the existence, uniqueness, and convergence of this steady-state solution, and we prove its asymptotic minimax optimality with respect to the worst-case mean-square error. Numerical experiments validate the theory and demonstrate that the proposed DRKF improves estimation accuracy under unknown or uncertain noise models while offering computational advantages over existing robust and distributionally robust filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06286v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minhyuk Jang, Astghik Hakobyan, Insoon Yang</dc:creator>
    </item>
    <item>
      <title>Control-Oriented System Identification: Classical, Learning, and Physics-Informed Approaches</title>
      <link>https://arxiv.org/abs/2512.06315</link>
      <description>arXiv:2512.06315v1 Announce Type: cross 
Abstract: We survey classical, machine learning, and data-driven system identification approaches to learn control-relevant and physics-informed models of dynamical systems. Recently, machine learning approaches have enabled system identification from noisy, high-dimensional, and complex data. However, their utility is limited by their ability to provide provable guarantees on control-relevant properties. Meanwhile, control theory has identified several properties that are useful in analysis and control synthesis, such as dissipativity, monotonicity, energy conservation, and symmetry-preserving structures. We posit that merging system identification with such control-relevant or physics-informed properties can provide useful inductive bias, enhance explainability, enable control synthesis with provable guarantees, and improve sample complexity. We formulate system identification as an optimization problem where control-relevant properties can be enforced through direct parameterization (constraining the model structure to satisfy a desired property by construction), soft constraints (encouraging control-relevant properties through regularization or penalty terms), and hard constraints (imposing control-relevant properties as constraints in the optimization problem). Through this lens, we survey methods to learn physics-informed and control-relevant models spanning classical linear and nonlinear system identification, machine learning approaches, and direct identification through data-driven and behavioral representations. We also provide several expository examples that are accompanied by code and brief tutorials on a public Github repository. We also describe challenging directions for future research, including identification in networked, switched, and time-varying systems, experiment design, and bridging the gaps between data-driven, learning-based, and control-oriented approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06315v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Sivaranjani, Yuanyuan Shi, Nikolay Atanasov, Thai Duong, Jie Feng, Tim Martin, Yuezhu Xu, Vijay Gupta, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Learning Reachability of Energy Storage Arbitrage</title>
      <link>https://arxiv.org/abs/2512.06600</link>
      <description>arXiv:2512.06600v1 Announce Type: cross 
Abstract: Power systems face increasing weather-driven variability and, therefore, increasingly rely on flexible but energy-limited storage resources. Energy storage can buffer this variability, but its value depends on intertemporal decisions under uncertain prices. Without accounting for the future reliability value of stored energy, batteries may act myopically, discharging too early or failing to preserve reserves during critical hours. This paper introduces a stopping-time reward that, together with a state-of-charge (SoC) range target penalty, aligns arbitrage incentives with system reliability by rewarding storage that maintains sufficient SoC before critical hours. We formulate the problem as an online optimization with a chance-constrained terminal SoC and embed it in an end-to-end (E2E) learning framework, jointly training the price predictor and control policy. The proposed design enhances reachability of target SoC ranges, improves profit under volatile conditions, and reduces its standard deviation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06600v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom\'as Tapia, Agustin Castellano, Enrique Mallada, Yury Dvorkin</dc:creator>
    </item>
    <item>
      <title>Symmetry-Based Formation Control on Cycle Graphs Using Dihedral Point Groups</title>
      <link>https://arxiv.org/abs/2512.06733</link>
      <description>arXiv:2512.06733v2 Announce Type: cross 
Abstract: This work develops a symmetry-based framework for formation control on cycle graphs using Dihedral point-group constraints. We show that enforcing inter-agent reflection symmetries, together with anchoring a single designated agent to its prescribed mirror axis, is sufficient to realize every $\mathcal{C}_{nv}$-symmetric configuration using only $n-1$ communication links. The resulting control laws have a matrix-weighted Laplacian structure and guarantee exponential convergence to the desired symmetric configuration. Furthermore, we extend the method to enable coordinated maneuvers along a time-varying reference trajectory. Simulation results are provided to support the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06733v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zamir Martinez, Daniel Zelazo</dc:creator>
    </item>
    <item>
      <title>Small-Gain Nash: Certified Contraction to Nash Equilibria in Differentiable Games</title>
      <link>https://arxiv.org/abs/2512.06791</link>
      <description>arXiv:2512.06791v1 Announce Type: cross 
Abstract: Classical convergence guarantees for gradient-based learning in games require the pseudo-gradient to be (strongly) monotone in Euclidean geometry as shown by rosen(1965), a condition that often fails even in simple games with strong cross-player couplings. We introduce Small-Gain Nash (SGN), a block small-gain condition in a custom block-weighted geometry. SGN converts local curvature and cross-player Lipschitz coupling bounds into a tractable certificate of contraction. It constructs a weighted block metric in which the pseudo-gradient becomes strongly monotone on any region where these bounds hold, even when it is non-monotone in the Euclidean sense. The continuous flow is exponentially contracting in this designed geometry, and projected Euler and RK4 discretizations converge under explicit step-size bounds derived from the SGN margin and a local Lipschitz constant. Our analysis reveals a certified ``timescale band'', a non-asymptotic, metric-based certificate that plays a TTUR-like role: rather than forcing asymptotic timescale separation via vanishing, unequal step sizes, SGN identifies a finite band of relative metric weights for which a single-step-size dynamics is provably contractive. We validate the framework on quadratic games where Euclidean monotonicity analysis fails to predict convergence, but SGN successfully certifies it, and extend the construction to mirror/Fisher geometries for entropy-regularized policy gradient in Markov games. The result is an offline certification pipeline that estimates curvature, coupling, and Lipschitz parameters on compact regions, optimizes block weights to enlarge the SGN margin, and returns a structural, computable convergence certificate consisting of a metric, contraction rate, and safe step-sizes for non-monotone games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06791v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vedansh Sharma</dc:creator>
    </item>
    <item>
      <title>Bridging Abstraction-Based Hierarchical Control and Moment Matching: A Conceptual Unification</title>
      <link>https://arxiv.org/abs/2512.06875</link>
      <description>arXiv:2512.06875v1 Announce Type: cross 
Abstract: In this paper, we establish a relation between approximate-simulation-based hierarchical control (ASHC) and moment matching techniques, and build a conceptual bridge between these two frameworks. To this end, we study the two key requirements of the ASHC technique, namely the bounded output discrepancy and the $M$-relation, through the lens of moment matching. We show that, in the linear time-invariant case, both requirements can be interpreted in the moment matching perspective through certain system interconnection structures. Building this conceptual bridge provides a foundation for cross-pollination of ideas between these two frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06875v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Niu, Mohammad Fahim Shakib, Giordano Scarciotti</dc:creator>
    </item>
    <item>
      <title>Numerical Algebraic Geometry for Energy Computations on Tensor Train Varieties</title>
      <link>https://arxiv.org/abs/2512.06939</link>
      <description>arXiv:2512.06939v1 Announce Type: cross 
Abstract: We study energy minimization problems in quantum chemistry through the lens of computational algebraic geometry. We focus on minimizing the Rayleigh quotient of a Hamiltonian over a tensor train variety. The complex critical points of this problem approximate eigenstates of the quantum system, with the global minimum approximating the ground state. We call the number of critical points the Rayleigh-Ritz degree.
  After introducing tensor train varieties, we identify instances when they are Segre products of projective spaces. We also report what we know about the defining ideals of tensor trains. We present a birational parametrization of them from products of Grassmannians. Along the way, we study the Rayleigh-Ritz degree, and we introduce the Rayleigh-Ritz discriminant, which describes Hamiltonians that lead to deficient number of critical points. We use homotopy continuation to compute all critical points of this optimization problem over various tensor train and determinantal varieties. Finally, we use these results to benchmark state-of-the-art methods, the Alternating Linear Scheme and Density Matrix Renormalization Group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06939v1</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktoriia Borovik, Hannah Friedman, Serkan Ho\c{s}ten, Max Pfeffer</dc:creator>
    </item>
    <item>
      <title>Learning Paths to Multi-Sector Equilibrium: Belief Dynamics Under Uncertain Returns to Scale</title>
      <link>https://arxiv.org/abs/2512.07013</link>
      <description>arXiv:2512.07013v1 Announce Type: cross 
Abstract: This paper explores the dynamics of learning in a multi-sector general equilibrium model where firms operate under incomplete information about their production returns to scale. Firms iteratively update their beliefs using maximum a-posteriori estimation, derived from observed production outcomes, to refine their knowledge of their returns to scale. The implications of these learning dynamics for market equilibrium and the conditions under which firms can effectively learn their true returns to scale are the key objects of this study. Our results shed light on how idiosyncratic shocks influence the learning process and demonstrate that input decisions encode all pertinent information for belief updates. Additionally, we show that a long-memory (path-dependent) learning which keeps track of all past estimations ends up having a worse performance than a short-memory (path-independent) approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07013v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Nasini, Rabia Nessah, Bertrand Wigniolle</dc:creator>
    </item>
    <item>
      <title>Copositivity, discriminants and nonseparable signed supports</title>
      <link>https://arxiv.org/abs/2512.07373</link>
      <description>arXiv:2512.07373v2 Announce Type: cross 
Abstract: In this work we establish a connection between copositivity, that is, nonnegativity on the positive orthant, of sparse real Laurent polynomials and discriminants. Specifically, we consider Laurent polynomials in the positive orthant with fixed support and fixed coefficient signs. We provide a criterion to decide whether a given polynomial is copositive that is based in determining the intersection points of the signed discriminant and a path going through the coefficients of the polynomial. If the signed support satisfies a combinatorial condition termed nonseparability, we show additionally that this intersection consists of one point, and that tracking one path in homotopy continuation methods suffices to decide upon copositivity.
  Building on these results, we show that any copositive polynomial with nonseparable signed support can be decomposed into a sum of nonnegative circuit polynomials, generalising thereby previously known supports having this property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07373v2</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisenda Feliu, Joan Ferrer, M\'at\'e L. Telek</dc:creator>
    </item>
    <item>
      <title>From sparse recovery to plug-and-play priors, understanding trade-offs for stable recovery with generalized projected gradient descent</title>
      <link>https://arxiv.org/abs/2512.07397</link>
      <description>arXiv:2512.07397v1 Announce Type: cross 
Abstract: We consider the problem of recovering an unknown low-dimensional vector from noisy, underdetermined observations. We focus on the Generalized Projected Gradient Descent (GPGD) framework, which unifies traditional sparse recovery methods and modern approaches using learned deep projective priors. We extend previous convergence results to robustness to model and projection errors. We use these theoretical results to explore ways to better control stability and robustness constants. To reduce recovery errors due to measurement noise, we consider generalized back-projection strategies to adapt GPGD to structured noise, such as sparse outliers. To improve the stability of GPGD, we propose a normalized idempotent regularization for the learning of deep projective priors. We provide numerical experiments in the context of sparse recovery and image inverse problems, highlighting the trade-offs between identifiability and stability that can be achieved with such methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07397v1</guid>
      <category>eess.IV</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Joundi (IMB), Yann Traonmilin (IMB), Jean-Fran\c{c}ois Aujol (UB, IMB)</dc:creator>
    </item>
    <item>
      <title>Social welfare optimisation in well-mixed and structured populations</title>
      <link>https://arxiv.org/abs/2512.07453</link>
      <description>arXiv:2512.07453v1 Announce Type: cross 
Abstract: Research on promoting cooperation among autonomous, self-regarding agents has often focused on the bi-objective optimisation problem: minimising the total incentive cost while maximising the frequency of cooperation. However, the optimal value of social welfare under such constraints remains largely unexplored. In this work, we hypothesise that achieving maximal social welfare is not guaranteed at the minimal incentive cost required to drive agents to a desired cooperative state. To address this gap, we adopt to a single-objective approach focused on maximising social welfare, building upon foundational evolutionary game theory models that examined cost efficiency in finite populations, in both well-mixed and structured population settings. Our analytical model and agent-based simulations show how different interference strategies, including rewarding local versus global behavioural patterns, affect social welfare and dynamics of cooperation. Our results reveal a significant gap in the per-individual incentive cost between optimising for pure cost efficiency or cooperation frequency and optimising for maximal social welfare. Overall, our findings indicate that incentive design, policy, and benchmarking in multi-agent systems and human societies should prioritise welfare-centric objectives over proxy targets of cost or cooperation frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07453v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Van An Nguyen, Vuong Khang Huynh, Ho Nam Duong, Huu Loi Bui, Hai Anh Ha, Quang Dung Le, Le Quoc Dung Ngo, Tan Dat Nguyen, Ngoc Ngu Nguyen, Hoai Thuong Nguyen, Zhao Song, Le Hong Trang, The Anh Han</dc:creator>
    </item>
    <item>
      <title>Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent</title>
      <link>https://arxiv.org/abs/2512.07490</link>
      <description>arXiv:2512.07490v1 Announce Type: cross 
Abstract: The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07490v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Liu, Zhi Han, Yandong Tang, Jun Fan, Yao Wang</dc:creator>
    </item>
    <item>
      <title>Control of Discrete-Time Linear Systems with Charge-Balanced Inputs</title>
      <link>https://arxiv.org/abs/2512.07506</link>
      <description>arXiv:2512.07506v1 Announce Type: cross 
Abstract: Electrical brain stimulation relies on externally applied currents to modulate neural activity, but safety constraints require each stimulation cycle to be charge-balanced, enforcing a zero net injected charge. However, how such charge-balanced stimulation works remains poorly understood. This paper investigates the ability of charge-balanced inputs to steer state trajectories in discrete-time linear systems. Motivated by both open-loop and adaptive neurostimulation protocols, we study two practically relevant input structures: periodic (repetitive) charge-balanced inputs and non-repetitive charge-balanced inputs. For each case, we derive novel reachability and controllability conditions. The theoretical results are further validated through numerical demonstrations of minimum-energy control input design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07506v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuzhen Qin, Zonglin Liu, Marcel van Gerven</dc:creator>
    </item>
    <item>
      <title>Context-Adaptive Color Optimization for Web Accessibility: Balancing Perceptual Fidelity and Functional Requirements</title>
      <link>https://arxiv.org/abs/2512.07623</link>
      <description>arXiv:2512.07623v1 Announce Type: cross 
Abstract: We extend our OKLCH-based accessibility optimization with context-adaptive constraint strategies that achieve near-universal success rates across diverse use cases. Our original strict algorithm reached 66-77% success by prioritizing minimal perceptual change ($\Delta E \leq 5.0$), optimizing for enterprise contexts where brand fidelity is paramount. However, this one-size-fits-all approach fails to serve the broader ecosystem of web developers who need accessible solutions even when strict perceptual constraints cannot be satisfied. We introduce recursive optimization (Mode~1) that compounds small adjustments across iterations, achieving 93.68% success on all color pairs and 100% success on reasonable pairs (contrast ratio $\rho &gt; 2.0$), representing a +27.23 percentage point improvement. A relaxed fallback mode (Mode~2) handles pathological edge cases, reaching 98.73% overall success. Evaluation on 10,000 realistic web color pairs demonstrates that context-aware constraint relaxation, combined with absolute hue preservation, enables practical accessibility compliance while maintaining brand color identity. The median perceptual change remains zero across all modes (most pairs already comply), while the 90th percentile reaches $\Delta E_{2000} = 15.55$ in Mode~1 -- perceptually acceptable when hue invariance preserves the essential character of the original color. The approach is deployed in CM-Colors v0.5.0 (800+ monthly downloads), providing developers with explicit control over the accessibility-fidelity trade-off appropriate to their context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07623v1</guid>
      <category>cs.HC</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lalitha A R</dc:creator>
    </item>
    <item>
      <title>Robust pointwise second order necessary conditions for singular stochastic optimal control with model uncertainty</title>
      <link>https://arxiv.org/abs/2403.15703</link>
      <description>arXiv:2403.15703v3 Announce Type: replace 
Abstract: We study the singular stochastic optimal control problem with model uncertainty, where the necessary conditions determined by the corresponding maximum principle are trivial. Robust integral form and pointwise second order necessary optimality conditions under certain compactness conditions are derived. Both the drift and diffusion terms are control dependent but the control region are assumed to be convex. The convex variational method is employed, because linear structure is essential in deriving the weak limit of uncertainty measures. Other main technical ingredients in obtaining the integral type conditions are compact analysis and minimax theorem, while for the pointwise ones it is Clark-Ocone formula and Lebesgue differentiation type theorem. Besides, a compendious example is given to illustrate the motivation and effectiveness of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15703v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00245-025-10297-9</arxiv:DOI>
      <arxiv:journal_reference>Volume 92, article number 66, (2025)https://link.springer.com/article/10.1007/s00245-025-10297-9</arxiv:journal_reference>
      <dc:creator>Guangdong Jing</dc:creator>
    </item>
    <item>
      <title>Properties for transposition solutions to operator-valued BSEEs, and applications to robust second order necessary conditions for controlled SEEs</title>
      <link>https://arxiv.org/abs/2403.15710</link>
      <description>arXiv:2403.15710v2 Announce Type: replace 
Abstract: This article is concerned with the second order necessary conditions for the stochastic optimal control problem of stochastic evolution equation with model uncertainty when the traditional Pontryagin-type maximum principle holds trivially and do not provide any information depicting the optimal control. The diffusion term of the state equation is allowed to be control dependent with convex control constraints. Transposition method is adopted to deal with the adjoint operator-valued backward stochastic evolution equations, especially the correction terms. Besides, weak convergence arguments are performed to obtain the optimal uncertainty measure, among which the regularities of the state processes, variational processes, and adjoint processes (in the transposition sense) are carefully characterized. Malliavin calculus is applied to pave the way for Lebesgue differentiation theorem to deduce the pointwise robust optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15710v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmaa.2025.129445</arxiv:DOI>
      <arxiv:journal_reference>Journal of Mathematical Analysis and Applications. Volume 549, Issue 1, 1 September 2025, 129445</arxiv:journal_reference>
      <dc:creator>Guangdong Jing</dc:creator>
    </item>
    <item>
      <title>Zero-sum Dynkin games under common and independent Poisson constraints</title>
      <link>https://arxiv.org/abs/2411.07134</link>
      <description>arXiv:2411.07134v2 Announce Type: replace 
Abstract: Zero-sum Dynkin games under Poisson constraints, where players can only stop at the event times of a Poisson process, have been studied widely in the recent literature. The constraint can be modelled in two ways: either both players share the same Poisson process (the common constraint) or each player has their own Poisson process (the independent constraint). In a Markovian framework, where payoffs are functions of an underlying diffusion, we establish necessary and sufficient conditions for the equivalence of the game's solution--comprising the value function and optimal stopping sets--under the common and independent constraints. Specifically, if the stopping sets of the maximiser and minimiser in the game under the common constraint are disjoint, then the solution to the game is the same under both the common and the independent constraint. However, the fact that the stopping sets are disjoint in the game under the independent constraint is not sufficient to guarantee that the solution of the game under the independent constraint is also the solution under the common constraint. To demonstrate the broad applicability of our results, we solve infinite-horizon Dynkin games satisfying the assumptions of our main theorems, using backward stochastic differential equation (BSDE) techniques. This requires extending standard BSDE results from the finite-horizon setting to the infinite-horizon case, allowing for unbounded solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07134v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Hobson, Gechun Liang, Edward Wang</dc:creator>
    </item>
    <item>
      <title>A Variable Smoothing for Weakly Convex Composite Minimization with Manifold Constraint</title>
      <link>https://arxiv.org/abs/2412.04225</link>
      <description>arXiv:2412.04225v3 Announce Type: replace 
Abstract: In this paper, we address a manifold constrained nonsmooth optimization problem involving the composition of a weakly convex function and a smooth mapping. To find a stationary point of the target problem, we propose a variable smoothing-type algorithm by combining the ideas of (i) translating the constrained problem into a Euclidean optimization problem with a smooth parametrization of the constraint set; (ii) exploiting a sequence of smoothed surrogate functions, of the cost function, given with the Moreau envelope of a weakly convex function. The proposed algorithm produces a vector sequence by the gradient descent update of a smoothed surrogate function at each iteration. In a case where the proximity operator of the weakly convex function is available, the proposed algorithm does not require any iterative solver for subproblems therein. By leveraging tools in the variational analysis, we show the so-called {\em gradient consistency property}, which is a key ingredient for smoothing-type algorithms, of the smoothed surrogate function used in this paper. Based on the gradient consistency property, we also establish an asymptotic convergence analysis for the proposed algorithm together with convergence rate analysis. Numerical experiments demonstrate the efficacy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04225v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Sum-of-Squares Hierarchy for the Gromov Wasserstein Problem</title>
      <link>https://arxiv.org/abs/2502.09102</link>
      <description>arXiv:2502.09102v3 Announce Type: replace 
Abstract: The Gromov-Wasserstein (GW) problem is a variant of the classical optimal transport problem that allows one to compute meaningful transportation plans between incomparable spaces. At an intuitive level, it seeks plans that minimize the discrepancy between metric evaluations of pairs of points. The GW problem is typically cast as an instance of a non-convex quadratic program that is, unfortunately, intractable to solve. In this paper, we describe tractable semidefinite relaxations of the GW problem based on the Sum-of-Squares (SOS) hierarchy. We describe how the Putinar-type and the Schm\"udgen-type moment hierarchies can be simplified using marginal constraints, and we prove convergence rates for these hierarchies towards computing global optimal solutions to the GW problem. The proposed SOS hierarchies naturally induce a distance measure analogous to the distortion metrics, and we show that these are genuine distances in that they satisfy the triangle inequality. In particular, the proposed SOS hierarchies provide computationally tractable proxies of the GW distance and the associated distortion distances (over metric measure spaces) that are otherwise intractable to compute.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09102v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoang Anh Tran, Binh Tuan Nguyen, Yong Sheng Soh</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Partially Observed Mean Field Stackelberg Stochastic Differential Game with Applications</title>
      <link>https://arxiv.org/abs/2503.15803</link>
      <description>arXiv:2503.15803v2 Announce Type: replace 
Abstract: This paper is concerned with a linear-quadratic partially observed mean field Stackelberg stochastic differential game, which contains a leader and a large number of followers. Specifically, the followers confront a large-population Nash game subsequent to the leader's initial announcement of his strategy. In turn, the leader optimizes his own cost functional, taking into account the anticipated reactions of the followers. The state equations of both the leader and the followers are general stochastic differential equations, where the drift terms contain both the state average term and the state expectation term. However, the followers' state average terms enter into the drift term of the leader's state equation and the state expectation term of the leader enters into the state equation of the follower, reflecting the mutual influence between the leader and the followers. By utilizing the techniques of state decomposition and backward separation principle, we deduce the open-loop adapted decentralized strategies and feedback decentralized strategies of this leader-followers system, and demonstrate that the decentralized strategies are the corresponding $\varepsilon$-Stackelberg-Nash equilibrium. Finally, we apply the theoretical result to a product planning problem with sticky prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15803v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yu Si, Yueyang Zheng, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Constrained Parameter Update Law for Adaptive Control</title>
      <link>https://arxiv.org/abs/2504.19412</link>
      <description>arXiv:2504.19412v2 Announce Type: replace 
Abstract: In this paper, a constrained parameter update law is derived in the context of adaptive control. The parameter update law is based on constrained optimization technique where a Lagrangian is formulated to incorporate the constraints on the parameters using inverse Barrier function. The constrained parameter update law is used to develop a adaptive tracking controller and the overall stability of the adaptive controller along with the constrained parameter update law is shown using Lyapunov analysis and development in stability of constrained primal-dual dynamics. The performance of the constrained parameter update law is tested in simulation for keeping the parameters within constraints and convergence to true parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19412v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ashwin P. Dani</dc:creator>
    </item>
    <item>
      <title>A Branch-and-Cut Algorithm for the Optimal Design of Parking Lots with One-way and Two-way Lanes</title>
      <link>https://arxiv.org/abs/2506.09961</link>
      <description>arXiv:2506.09961v2 Announce Type: replace 
Abstract: We address the problem of maximizing the number of stalls in parking lots where vehicles park perpendicular to the driveways. Building on recent research on two-way driving lanes, we first formulate a mixed integer program to maximize the number of parking stalls using a flow-based approach. Parking lots are rasterized into a grid, and the proposed MIP model optimizes them in a generic manner, adapting to the grid resolution and stall size without requiring custom formulations. The constraints ensure the connectivity of parking stalls and driveways to the entrance/exit. This formulation is then extended to the case of one-way driving lanes. We then propose valid inequalities and a branch-and-cut algorithm for the one-way and two-way lane configurations. This approach eliminates flow variables, big-M type constraints, and improves solution times for medium-sized instances. The effectiveness of the suggested models is showcased on 325 parking lots from New York City. For instances in which the flow version could be solved in 15 minutes, the branch-and-cut algorithm improved the median runtimes by 87.43% for the one-way case and by 79.36% for the two-way case and resulted in better optimality gaps for the other instances, compared to the baseline flow-based formulation. Similar advantages were observed when run with a time budget of two hours. One-way configurations accommodated, on average, 18.63% more vehicles on average than their two-way counterparts across all instances. Modifications to the proposed formulations that consider the turning characteristics of vehicles and the presence of multiple entrances and exits are also examined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09961v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Helen Thomas, Tarun Rambha</dc:creator>
    </item>
    <item>
      <title>Stochastic Approximation with Block Coordinate Optimal Stepsizes</title>
      <link>https://arxiv.org/abs/2507.08963</link>
      <description>arXiv:2507.08963v2 Announce Type: replace 
Abstract: We consider stochastic approximation with block-coordinate stepsizes and propose adaptive stepsize rules that aim to minimize the expected distance from the next iterate to an (unknown) target point. These stepsize rules employ online estimates of the second moment of the search direction along each block coordinate. The popular Adam algorithm can be interpreted as a variant with a specific estimator. By leveraging a simple conditional estimator, we derive a new method that obtains competitive performance against Adam but requires less memory and fewer hyper-parameters. We prove that this family of methods converges almost surely to a small neighborhood of the target point, and the radius of the neighborhood depends on the bias and variance of the second-moment estimator. Our analysis relies on a simple aiming condition that assumes neither convexity nor smoothness, thus has broad applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08963v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Jiang, Lin Xiao</dc:creator>
    </item>
    <item>
      <title>Non-negative polynomials without hyperbolic certificates of non-negativity</title>
      <link>https://arxiv.org/abs/2508.04027</link>
      <description>arXiv:2508.04027v2 Announce Type: replace 
Abstract: In this paper we study the relationship between the set of all non-negative multivariate homogeneous polynomials and those, which we call hyperwrons, whose non-negativity can be deduced from an identity involving the Wronskians of hyperbolic polynomials. We give a sufficient condition on positive integers $m$ and $2y$ such that there are non-negative polynomials of degree $2y$ in $m$ variables that are not hyperwrons. Furthermore, we give an explicit example of a non-negative quartic form that is not a sum of hyperwrons. We partially extend our results to hyperzouts, which are polynomials whose non-negativity can be deduced from an identity involving the B\'ezoutians of hyperbolic polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04027v2</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. L. Brian Ng, James Saunderson</dc:creator>
    </item>
    <item>
      <title>DualHash: A Stochastic Primal-Dual Algorithm with Theoretical Guarantee for Deep Hashing</title>
      <link>https://arxiv.org/abs/2510.18218</link>
      <description>arXiv:2510.18218v2 Announce Type: replace 
Abstract: Deep hashing converts high-dimensional feature vectors into compact binary codes, enabling efficient large-scale retrieval. A fundamental challenge in deep hashing stems from the discrete nature of quantization in generating the codes. W-type regularizations, such as $||z|-1|$, have been proven effective as they encourage variables toward binary values. However, existing methods often directly optimize these regularizations without convergence guarantees. While proximal gradient methods offer a promising solution, the coupling between W-type regularizers and neural network outputs results in composite forms that generally lack closed-form proximal solutions. In this paper, we present a stochastic primal-dual hashing algorithm, referred to as DualHash, that provides rigorous complexity bounds. Using Fenchel duality, we partially transform the nonconvex W-type regularization optimization into the dual space, which results in a proximal operator that admits closed-form solutions. We derive two algorithm instances: a momentum-accelerated version with $\mathcal{O}(\varepsilon^{-4})$ complexity and an improved $\mathcal{O}(\varepsilon^{-3})$ version using variance reduction. Experiments on three image retrieval databases demonstrate the superior performance of DualHash.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18218v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luxuan Li, Xiao Wang, Chunfeng Cui</dc:creator>
    </item>
    <item>
      <title>A Retraction-free Method for Nonsmooth Minimax Optimization over a Compact Manifold</title>
      <link>https://arxiv.org/abs/2510.22065</link>
      <description>arXiv:2510.22065v2 Announce Type: replace 
Abstract: We study the minimax problem $\min_{x\in M} \max_y f_r(x,y):=f(x,y)-h(y)$, where $M$ is a compact submanifold, $f$ is continuously differentiable in $(x, y)$, $h$ is a closed, weakly-convex (possibly non-smooth) function and we assume that the regularized coupling function $-f_r(x,\cdot)$ is either $\mu$-PL for some $\mu&gt;0$ or concave ($\mu = 0$) for any fixed $x$ in the vicinity of $M$. To address the nonconvexity due to the manifold constraint, we use an exact penalty for the constraint $x \in M$, and enforcing a convex constraint $x\in X$ for some $X \supset M$, onto which projections can be computed efficiently. Building upon this new formulation for the manifold minimax problem in question, a single-loop smoothed manifold gradient descent-ascent (sm-MGDA) algorithm is proposed. Theoretically, any limit point of sm-MGDA sequence is a stationary point of the manifold minimax problem and sm-MGDA can generate an $O(\epsilon)$-stationary point of the original problem with $O(1/\epsilon^2)$ and $\tilde{O}(1/\epsilon^4)$ complexity for $\mu &gt; 0$ and $\mu = 0$ scenarios, respectively. Moreover, for the $\mu = 0$ setting, through adopting Tikhonov regularization of the dual, one can improve the complexity to $O(1/\epsilon^3)$ at the expense of asymptotic stationarity. The key component, common in the analysis of all cases, is to connect $\epsilon$-stationary points between the penalized problem and the original problem by showing that the constraint $x \in X$ becomes inactive and the penalty term tends to $0$ along any convergent subsequence. To our knowledge, sm-MGDA is the first retraction-free algorithm for minimax problems over compact submanifolds, and this is a very desirable algorithmic property since through avoiding retractions, one can get away with matrix orthogonalization subroutines required for computing retractions to manifolds arising in practice, which are not GPU friendly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22065v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Necdet Serhat Aybat, Jiang Hu, Zhanwang Deng</dc:creator>
    </item>
    <item>
      <title>A Dual-Mode Framework for Mean-Field Systems: Model-Based $H_2/H_\infty$ Control with Jump Diffusions and Model-Free Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.01000</link>
      <description>arXiv:2512.01000v2 Announce Type: replace 
Abstract: Two methods for solving the robust control of mean-field systems are investigated in this paper. For the stochastic $H_2/H_\infty$ control problem of continuous-time mean-field stochastic differential equations with Poisson jumps over a finite horizon, the continuous and jump diffusion terms in the system depend not only on the state but also on the control input, external disturbance, and mean-field components. By employing the quasi-linear technique and the method of completing the square, a mean-field stochastic jump bounded real lemma for the system is derived. The feasibility of the stochastic $H_2/H_\infty$ control problem is demonstrated to be equivalent to the solvability of four sets of cross-coupled generalized differential Riccati equations. Based on this conclusion, a model-based numerical method is presented. Furthermore, this paper proposes a data-driven, model-free, off-policy reinforcement learning approach, which can be utilized to solve the $H_\infty$ control problem for the mean-field systems discussed herein. The findings establish a systematic framework for designing robust controllers for interacting particle systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01000v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huimin Han, Shaolin Ji, Weihai Zhang</dc:creator>
    </item>
    <item>
      <title>Parameter Optimization in Trajectory Planning via Differentiable Convex Programming</title>
      <link>https://arxiv.org/abs/2512.03557</link>
      <description>arXiv:2512.03557v2 Announce Type: replace 
Abstract: Sequential convex programming has been established as an effective framework for solving nonconvex trajectory planning problems. However, its performance is highly sensitive to problem parameters, including trajectory variables, algorithmic hyperparameters, and physical vehicle parameters. This paper introduces a differentiable sequential convex programming framework that integrates differentiable convex optimization with sequential convex programming to enable end-to-end parameter optimization. By deriving first-order sensitivity relations of second-order cone programming solutions with respect to problem data, exact gradients of trajectory performance metrics with respect to arbitrary parameters are obtained and propagated through iterations. The effectiveness of the proposed framework is validated through three representative applications: optimal terminal-time prediction for powered landing, trust-region penalty optimization in subproblems, and surface-to-mass ratio optimization for hypersonic gliding vehicles. Simulation results show that the proposed framework enables reliable gradient-based parameter learning and significantly improves numerical performance, convergence behavior, and design efficiency. These results indicate that the differentiable sequential convex programming framework provides a powerful and general tool for vehicle design, mission optimization, and hyperparameter selection in aerospace trajectory planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03557v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziqi Xu, Lin Cheng, Di Wu, Shengping Gong</dc:creator>
    </item>
    <item>
      <title>Hidden Minima in Two-Layer ReLU Networks</title>
      <link>https://arxiv.org/abs/2312.16819</link>
      <description>arXiv:2312.16819v3 Announce Type: replace-cross 
Abstract: We consider the optimization problem arising from fitting two-layer ReLU networks with $d$ inputs under the square loss, where labels are generated by a target network. Two infinite families of spurious minima have recently been identified: one whose loss vanishes as $d \to \infty$, and another whose loss remains bounded away from zero. The latter are nevertheless avoided by vanilla SGD, and thus hidden, motivating the search for analytic properties distinguishing the two types. Perhaps surprisingly, the Hessian spectra of hidden and non-hidden minima agree up to terms of order $O(d^{-1/2})$, providing limited explanatory power. Consequently, our analysis of hidden minima proceeds instead via curves along which the loss is minimized or maximized. The main result is that arcs emanating from hidden minima differ, characteristically, by their structure and symmetry, precisely on account of the $O(d^{-1/2})$-eigenvalue terms absent from previous analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16819v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yossi Arjevani</dc:creator>
    </item>
    <item>
      <title>Kinodynamic Motion Planning for Collaborative Object Transportation by Multiple Mobile Manipulators</title>
      <link>https://arxiv.org/abs/2409.14910</link>
      <description>arXiv:2409.14910v2 Announce Type: replace-cross 
Abstract: This work proposes a kinodynamic motion planning technique for collaborative object transportation by multiple mobile manipulators in dynamic environments. A global path planner computes a linear piecewise path from start to goal. A novel algorithm detects the narrow regions between the static obstacles and aids in defining the obstacle-free region to enhance the feasibility of the global path. We then formulate a local online motion planning technique for trajectory generation that minimizes the control efforts in a receding horizon manner. It plans the trajectory for finite time horizons, considering the kinodynamic constraints and the static and dynamic obstacles. The planning technique jointly plans for the mobile bases and the arms to utilize the locomotion capability of the mobile base and the manipulation capability of the arm efficiently. We use a convex cone approach to avoid self-collision of the formation by modifying the mobile manipulators admissible state without imposing additional constraints. Numerical simulations and hardware experiments showcase the efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14910v2</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1115/1.4069407</arxiv:DOI>
      <arxiv:journal_reference>J. Mechanisms Robotics. Dec 2025, 17(12)</arxiv:journal_reference>
      <dc:creator>Keshab Patra, Arpita Sinha, Anirban Guha</dc:creator>
    </item>
    <item>
      <title>A Particle Algorithm for Mean-Field Variational Inference</title>
      <link>https://arxiv.org/abs/2412.20385</link>
      <description>arXiv:2412.20385v3 Announce Type: replace-cross 
Abstract: Variational inference is a fast and scalable alternative to Markov chain Monte Carlo and has been widely applied to posterior inference tasks in statistics and machine learning. A traditional approach for implementing mean-field variational inference (MFVI) is coordinate ascent variational inference (CAVI), which relies crucially on parametric assumptions on complete conditionals. We introduce a novel particle-based algorithm for MFVI, named PArticle VI (PAVI), for nonparametric mean-field approximation. We obtain non-asymptotic error bounds for our algorithm. To our knowledge, this is the first end-to-end guarantee for particle-based MFVI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20385v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Du, Kaizheng Wang, Edith Zhang, Chenyang Zhong</dc:creator>
    </item>
    <item>
      <title>Dynamically optimal portfolios for monotone mean--variance preferences</title>
      <link>https://arxiv.org/abs/2503.08272</link>
      <description>arXiv:2503.08272v2 Announce Type: replace-cross 
Abstract: Monotone mean-variance (MMV) utility is the minimal modification of the classical Markowitz utility that respects rational ordering of investment opportunities. This paper provides, for the first time, a complete characterization of optimal dynamic portfolio choice for the MMV utility in asset price models with independent returns. The task is performed under minimal assumptions, weaker than the existence of an equivalent martingale measure and with no restrictions on the moments of asset returns. We interpret the maximal MMV utility in terms of the monotone Sharpe ratio (MSR) and show that the global squared MSR arises as the nominal yield from continuously compounding at the rate equal to the maximal local squared MSR. The paper gives simple necessary and sufficient conditions for mean-variance (MV) efficient portfolios to be MMV efficient. Several illustrative examples contrasting the MV and MMV criteria are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08272v2</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ale\v{s} \v{C}ern\'y, Johannes Ruf, Martin Schweizer</dc:creator>
    </item>
    <item>
      <title>Certifying Stability of Reinforcement Learning Policies using Generalized Lyapunov Functions</title>
      <link>https://arxiv.org/abs/2505.10947</link>
      <description>arXiv:2505.10947v3 Announce Type: replace-cross 
Abstract: Establishing stability certificates for closed-loop systems under reinforcement learning (RL) policies is essential to move beyond empirical performance and offer guarantees of system behavior. Classical Lyapunov methods require a strict stepwise decrease in the Lyapunov function but such certificates are difficult to construct for learned policies. The RL value function is a natural candidate but it is not well understood how it can be adapted for this purpose. To gain intuition, we first study the linear quadratic regulator (LQR) problem and make two key observations. First, a Lyapunov function can be obtained from the value function of an LQR policy by augmenting it with a residual term related to the system dynamics and stage cost. Second, the classical Lyapunov decrease requirement can be relaxed to a generalized Lyapunov condition requiring only decrease on average over multiple time steps. Using this intuition, we consider the nonlinear setting and formulate an approach to learn generalized Lyapunov functions by augmenting RL value functions with neural network residual terms. Our approach successfully certifies the stability of RL policies trained on Gymnasium and DeepMind Control benchmarks. We also extend our method to jointly train neural controllers and stability certificates using a multi-step Lyapunov loss, resulting in larger certified inner approximations of the region of attraction compared to the classical Lyapunov approach. Overall, our formulation enables stability certification for a broad class of systems with learned policies by making certificates easier to construct, thereby bridging classical control theory and modern learning-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10947v3</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehan Long, Jorge Cort\'es, Nikolay Atanasov</dc:creator>
    </item>
    <item>
      <title>Stochastic Orthogonal Regularization for deep projective priors</title>
      <link>https://arxiv.org/abs/2505.13078</link>
      <description>arXiv:2505.13078v3 Announce Type: replace-cross 
Abstract: Many crucial tasks of image processing and computer vision are formulated as inverse problems. Thus, it is of great importance to design fast and robust algorithms to solve these problems. In this paper, we focus on generalized projected gradient descent (GPGD) algorithms where generalized projections are realized with learned neural networks and provide state-of-the-art results for imaging inverse problems. Indeed, neural networks allow for projections onto unknown low-dimensional sets that model complex data, such as images. We call these projections deep projective priors. In generic settings, when the orthogonal projection onto a lowdimensional model set is used, it has been shown, under a restricted isometry assumption, that the corresponding orthogonal PGD converges with a linear rate, yielding near-optimal convergence (within the class of GPGD methods) in the classical case of sparse recovery. However, for deep projective priors trained with classical mean squared error losses, there is little guarantee that the hypotheses for linear convergence are satisfied. In this paper, we propose a stochastic orthogonal regularization of the training loss for deep projective priors. This regularization is motivated by our theoretical results: a sufficiently good approximation of the orthogonal projection guarantees linear stable recovery with performance close to orthogonal PGD. We show experimentally, using two different deep projective priors (based on autoencoders and on denoising networks), that our stochastic orthogonal regularization yields projections that improve convergence speed and robustness of GPGD in challenging inverse problem settings, in accordance with our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13078v3</guid>
      <category>eess.IV</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Joundi (UB), Yann Traonmilin (UB), Alasdair Newson (ISIR)</dc:creator>
    </item>
    <item>
      <title>Learning where to learn: Training data distribution optimization for scientific machine learning</title>
      <link>https://arxiv.org/abs/2505.21626</link>
      <description>arXiv:2505.21626v3 Announce Type: replace-cross 
Abstract: In scientific machine learning, models are routinely deployed with parameter values or boundary conditions far from those used in training. This paper studies the learning-where-to-learn problem of designing a training data distribution that minimizes average prediction error across a family of deployment regimes. A theoretical analysis shows how the training distribution shapes deployment accuracy. This motivates two adaptive algorithms based on bilevel or alternating optimization in the space of probability measures. Discretized implementations using parametric distribution classes or nonparametric particle-based gradient flows deliver optimized training distributions that outperform nonadaptive designs. Once trained, the resulting models exhibit improved sample complexity and robustness to distribution shift. This framework unlocks the potential of principled data acquisition for learning functions and solution operators of partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21626v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Guerra, Nicholas H. Nelsen, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent</title>
      <link>https://arxiv.org/abs/2508.08222</link>
      <description>arXiv:2508.08222v2 Announce Type: replace-cross 
Abstract: Transformers have demonstrated remarkable capabilities in multi-step reasoning tasks. However, understandings of the underlying mechanisms by which they acquire these abilities through training remain limited, particularly from a theoretical standpoint. This work investigates how transformers learn to solve symbolic multi-step reasoning problems through chain-of-thought processes, focusing on path-finding in trees. We analyze two intertwined tasks: a backward reasoning task, where the model outputs a path from a goal node to the root, and a more complex forward reasoning task, where the model implements two-stage reasoning by first identifying the goal-to-root path and then reversing it to produce the root-to-goal path. Our theoretical analysis, grounded in the dynamics of gradient descent, shows that trained one-layer transformers can provably solve both tasks with generalization guarantees to unseen trees. In particular, our multi-phase training dynamics for forward reasoning elucidate how different attention heads learn to specialize and coordinate autonomously to solve the two subtasks in a single autoregressive path. These results provide a mechanistic explanation of how trained transformers can implement sequential algorithmic procedures. Moreover, they offer insights into the emergence of reasoning abilities, suggesting that when tasks are structured to take intermediate chain-of-thought steps, even shallow multi-head transformers can effectively solve problems that would otherwise require deeper architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08222v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tong Yang, Yu Huang, Yingbin Liang, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Extended parameter shift rules with minimal derivative variance for parameterized quantum circuits</title>
      <link>https://arxiv.org/abs/2508.08802</link>
      <description>arXiv:2508.08802v2 Announce Type: replace-cross 
Abstract: Parameter shift rules (PSRs) are useful methods for computing arbitrary-order derivatives of the cost function in parameterized quantum circuits. The basic idea of PSRs is to evaluate the cost function at different parameter shifts, then use specific coefficients to combine them linearly to obtain the exact derivatives. In this work, we propose an extended parameter shift rule (EPSR) which generalizes a broad range of existing PSRs and has the following two advantages. First, EPSR offers an infinite number of possible parameter shifts, allowing the selection of the optimal parameter shifts to minimize the final derivative variance and thereby obtaining the more accurate derivative estimates with limited quantum resources. Second, EPSR extends the scope of the PSRs in the sense that EPSR can handle arbitrary Hermitian operator $H$ in gate $U(x) = \exp (iHx)$ in the parameterized quantum circuits, while existing PSRs are valid only for simple Hermitian generators $H$ such as simple Pauli words. Additionally, we show that the widely used ``general PSR'', introduced by Wierichs et al. (2022), is a special case of our EPSR, and we prove that it yields globally optimal shifts for minimizing the derivative variance under the weighted-shot scheme. Finally, through numerical simulations, we demonstrate the effectiveness of EPSR and show that the usage of the optimal parameter shifts indeed leads to more accurate derivative estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08802v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/f57b-q28w</arxiv:DOI>
      <dc:creator>Zhijian Lai, Jiang Hu, Dong An, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Jointly Computation- and Communication-Efficient Distributed Learning</title>
      <link>https://arxiv.org/abs/2508.15509</link>
      <description>arXiv:2508.15509v2 Announce Type: replace-cross 
Abstract: We address distributed learning problems over undirected networks. Specifically, we focus on designing a novel ADMM-based algorithm that is jointly computation- and communication-efficient. Our design guarantees computational efficiency by allowing agents to use stochastic gradients during local training. Moreover, communication efficiency is achieved as follows: i) the agents perform multiple training epochs between communication rounds, and ii) compressed transmissions are used. We prove exact linear convergence of the algorithm in the strongly convex setting. We corroborate our theoretical results by numerical comparisons with state of the art techniques on a classification task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15509v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxing Ren, Nicola Bastianello, Karl H. Johansson, Thomas Parisini</dc:creator>
    </item>
    <item>
      <title>Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems</title>
      <link>https://arxiv.org/abs/2508.15695</link>
      <description>arXiv:2508.15695v2 Announce Type: replace-cross 
Abstract: We present several key advances to the Physics and Equality Constrained Artificial Neural Networks (PECANN) framework, substantially improving its capacity to solve challenging partial differential equations (PDEs). Our enhancements broaden the framework's applicability and improve efficiency. First, we generalize the Augmented Lagrangian Method (ALM) to support multiple, independent penalty parameters for enforcing heterogeneous constraints. Second, we introduce a constraint aggregation technique to address inefficiencies associated with point-wise enforcement. Third, we incorporate a single Fourier feature mapping to capture highly oscillatory solutions with multi-scale features, where alternative methods often require multiple mappings or costlier architectures. Fourth, a novel time-windowing strategy enables seamless long-time evolution without relying on discrete time models. Fifth, and critically, we propose a conditionally adaptive penalty update (CAPU) strategy for ALM that accelerates the growth of Lagrange multipliers for constraints with larger violations, while enabling coordinated updates of multiple penalty parameters. CAPU accelerates the growth of Lagrange multipliers for selectively challenging constraints, enhancing constraint enforcement during training. We demonstrate the effectiveness of PECANN-CAPU across diverse problems, including the transonic rarefaction problem, reversible scalar advection by a vortex, high-wavenumber Helmholtz and Poisson's equations, and inverse heat source identification. The framework achieves competitive accuracy across all cases when compared with established methods and recent approaches based on Kolmogorov-Arnold networks. Collectively, these advances improve the robustness, computational efficiency, and applicability of PECANN to demanding problems in scientific computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15695v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qifeng Hu, Shamsulhaq Basir, Inanc Senocak</dc:creator>
    </item>
    <item>
      <title>Revealing POMDPs: Qualitative and Quantitative Analysis for Parity Objectives</title>
      <link>https://arxiv.org/abs/2511.13134</link>
      <description>arXiv:2511.13134v2 Announce Type: replace-cross 
Abstract: Partially observable Markov decision processes (POMDPs) are a central model for uncertainty in sequential decision making. The most basic objective is the reachability objective, where a target set must be eventually visited, and the more general parity objectives can model all omega-regular specifications. For such objectives, the computational analysis problems are the following: (a) qualitative analysis that asks whether the objective can be satisfied with probability 1 (almost-sure winning) or probability arbitrarily close to 1 (limit-sure winning); and (b) quantitative analysis that asks for the approximation of the optimal probability of satisfying the objective. For general POMDPs, almost-sure analysis for reachability objectives is EXPTIME-complete, but limit-sure and quantitative analyses for reachability objectives are undecidable; almost-sure, limit-sure, and quantitative analyses for parity objectives are all undecidable. A special class of POMDPs, called revealing POMDPs, has been studied recently in several works, and for this subclass the almost-sure analysis for parity objectives was shown to be EXPTIME-complete. In this work, we show that for revealing POMDPs the limit-sure analysis for parity objectives is EXPTIME-complete, and even the quantitative analysis for parity objectives can be achieved in EXPTIME.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13134v2</guid>
      <category>cs.CC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ali Asadi, Krishnendu Chatterjee, David Lurie, Raimundo Saona</dc:creator>
    </item>
    <item>
      <title>Enhanced Single-Photon Detector: A framework for Superconducting-Level Performance without cryogenic cooling</title>
      <link>https://arxiv.org/abs/2512.01328</link>
      <description>arXiv:2512.01328v2 Announce Type: replace-cross 
Abstract: High-performance single-photon detectors (SPDs) are indispensable components for a wide range of quantum optical applications. However, the reliance of state-of-the-art devices on superconducting materials imposes severe technological demands and necessitates challenging operational conditions, such as cryogenics, thereby hindering scalable implementation. To address this, we propose the Enhanced Single-Photon Detector (ESPD) framework, a novel paradigm for achieving high-performance SPDs through the iterative enhancement of conventional room-temperature SPDs. Relying entirely on non-superconducting components and eliminating cryogenic cooling requirements, the ESPD scheme can upgrade a legacy SPD, with detection efficiency (DE) about $59\%$ and dark count rate (DCR) of $10^{-2}$, to a device with superior performance metrics, achieving DE exceeding $93\%$ and DCR below $10^{-9}$. This performance rivals or even surpasses that of state-of-the-art superconducting SPDs, allowing the minimal tolerable channel transmission rate for quantum key distribution (QKD) protocols to be reduced by several orders of magnitude. Although the architecture requires substantial integration effort, the scheme can provide superconducting-level performance without cryogenic cooling, offering a clear path toward the widespread deployment of high-performance SPDs as well as related quantum technologies in infrastructure-constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01328v2</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Shu</dc:creator>
    </item>
    <item>
      <title>An Information Theory of Finite Abstractions and their Fundamental Scalability Limits</title>
      <link>https://arxiv.org/abs/2512.03977</link>
      <description>arXiv:2512.03977v3 Announce Type: replace-cross 
Abstract: Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And yet, after decades of research on abstractions, there are no formal results on their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the information theory of lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems. Rate measures abstraction size, while distortion describes accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum achievable abstraction distortion, given the system dynamics and the abstraction size; and vice-versa a lower bound on the minimum size, for given distortion. The bound depends on the complexity of the dynamics, through trajectory entropy. We demonstrate its tightness on some dynamical systems. Finally, we showcase how this new theory enables constructing minimal abstractions, optimizing the size-accuracy tradeoff, through an example on a chaotic system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03977v3</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giannis Delimpaltadakis, Gabriel Gleizer</dc:creator>
    </item>
    <item>
      <title>AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Soccer Substitutions</title>
      <link>https://arxiv.org/abs/2512.04480</link>
      <description>arXiv:2512.04480v2 Announce Type: replace-cross 
Abstract: In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system's ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the "FAGNER Paradox" - a maximum priority defensive risk - minutes before a critical yellow card, and detected the "Lukaku Paradox", where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04480v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pedro Passos</dc:creator>
    </item>
  </channel>
</rss>
