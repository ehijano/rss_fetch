<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Sep 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the computational power of $C$-random strings</title>
      <link>https://arxiv.org/abs/2409.04448</link>
      <description>arXiv:2409.04448v1 Announce Type: new 
Abstract: Denote by $H$ the Halting problem. Let $R_U: = \{ x | C_U(x) \ge |x|\}$, where $C_U(x)$ is the plain Kolmogorov complexity of $x$ under a universal decompressor $U$. We prove that there exists a universal $U$ such that $H \in P^{R_U}$, solving the problem posted by Eric Allender.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04448v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexey Milovanov</dc:creator>
    </item>
    <item>
      <title>Two-Sided Lossless Expanders in the Unbalanced Setting</title>
      <link>https://arxiv.org/abs/2409.04549</link>
      <description>arXiv:2409.04549v1 Announce Type: new 
Abstract: We present the first explicit construction of two-sided lossless expanders in the unbalanced setting (bipartite graphs that have many more nodes on the left than on the right). Prior to our work, all known explicit constructions in the unbalanced setting achieved only one-sided lossless expansion.
  Specifically, we show that the one-sided lossless expanders constructed by Kalev and Ta-Shma (RANDOM'22) -- that are based on multiplicity codes introduced by Kopparty, Saraf, and Yekhanin (STOC'11) -- are, in fact, two-sided lossless expanders.
  Using our unbalanced bipartite expander, we easily obtain lossless (non-bipartite) expander graphs with high degree and a free group action. As far as we know, this is the first explicit construction of lossless (non-bipartite) expanders with $N$ vertices and degree $\ll N$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04549v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eshan Chattopadhyay, Mohit Gurumukhani, Noam Ringach, Yunya Zhao</dc:creator>
    </item>
    <item>
      <title>A Quantum Pigeonhole Principle and Two Semidefinite Relaxations of Communication Complexity</title>
      <link>https://arxiv.org/abs/2409.04592</link>
      <description>arXiv:2409.04592v1 Announce Type: new 
Abstract: We study semidefinite relaxations of $\Pi_1$ combinatorial statements. By relaxing the pigeonhole principle, we obtain a new "quantum" pigeonhole principle which is a stronger statement. By relaxing statements of the form "the communication complexity of $f$ is $&gt; k$", we obtain new communication models, which we call "$\gamma_2$ communication" and "quantum-lab protocols". We prove, via an argument from proof complexity, that any natural model obtained by such a relaxation must solve all Karchmer--Wigderson games efficiently. However, the argument is not constructive, so we work to explicitly construct such protocols in these two models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04592v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Dvo\v{r}\'ak, Bruno Loff, Suhail Sherif</dc:creator>
    </item>
    <item>
      <title>Fully Characterizing Lossy Catalytic Computation</title>
      <link>https://arxiv.org/abs/2409.05046</link>
      <description>arXiv:2409.05046v1 Announce Type: new 
Abstract: A catalytic machine is a model of computation where a traditional space-bounded machine is augmented with an additional, significantly larger, "catalytic" tape, which, while being available as a work tape, has the caveat of being initialized with an arbitrary string, which must be preserved at the end of the computation. Despite this restriction, catalytic machines have been shown to have surprising additional power; a logspace machine with a polynomial length catalytic tape, known as catalytic logspace ($CL$), can compute problems which are believed to be impossible for $L$.
  A fundamental question of the model is whether the catalytic condition, of leaving the catalytic tape in its exact original configuration, is robust to minor deviations. This study was initialized by Gupta et al. (2024), who defined lossy catalytic logspace ($LCL[e]$) as a variant of $CL$ where we allow up to $e$ errors when resetting the catalytic tape. They showed that $LCL[e] = CL$ for any $e = O(1)$, which remains the frontier of our understanding.
  In this work we completely characterize lossy catalytic space ($LCSPACE[s,c,e]$) in terms of ordinary catalytic space ($CSPACE[s,c]$). We show that $$LCSPACE[s,c,e] = CSPACE[\Theta(s + e \log c), \Theta(c)]$$ In other words, allowing $e$ errors on a catalytic tape of length $c$ is equivalent, up to a constant stretch, to an equivalent errorless catalytic machine with an additional $e \log c$ bits of ordinary working memory.
  As a consequence, we show that for any $e$, $LCL[e] = CL$ implies $SPACE[e \log n] \subseteq ZPP$, thus giving a barrier to any improvement beyond $LCL[O(1)] = CL$. We also show equivalent results for non-deterministic and randomized catalytic space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05046v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marten Folkertsma, Ian Mertz, Florian Speelman, Quinten Tupker</dc:creator>
    </item>
    <item>
      <title>Nearest Neighbor CCP-Based Molecular Sequence Analysis</title>
      <link>https://arxiv.org/abs/2409.04922</link>
      <description>arXiv:2409.04922v1 Announce Type: cross 
Abstract: Molecular sequence analysis is crucial for comprehending several biological processes, including protein-protein interactions, functional annotation, and disease classification. The large number of sequences and the inherently complicated nature of protein structures make it challenging to analyze such data. Finding patterns and enhancing subsequent research requires the use of dimensionality reduction and feature selection approaches. Recently, a method called Correlated Clustering and Projection (CCP) has been proposed as an effective method for biological sequencing data. The CCP technique is still costly to compute even though it is effective for sequence visualization. Furthermore, its utility for classifying molecular sequences is still uncertain. To solve these two problems, we present a Nearest Neighbor Correlated Clustering and Projection (CCP-NN)-based technique for efficiently preprocessing molecular sequence data. To group related molecular sequences and produce representative supersequences, CCP makes use of sequence-to-sequence correlations. As opposed to conventional methods, CCP doesn't rely on matrix diagonalization, therefore it can be applied to a range of machine-learning problems. We estimate the density map and compute the correlation using a nearest-neighbor search technique. We performed molecular sequence classification using CCP and CCP-NN representations to assess the efficacy of our proposed approach. Our findings show that CCP-NN considerably improves classification task accuracy as well as significantly outperforms CCP in terms of computational runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04922v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sarwan Ali, Prakash Chourasia, Bipin Koirala, Murray Patterson</dc:creator>
    </item>
    <item>
      <title>QBF Merge Resolution is powerful but unnatural</title>
      <link>https://arxiv.org/abs/2205.13428</link>
      <description>arXiv:2205.13428v5 Announce Type: replace 
Abstract: The Merge Resolution proof system (M-Res) for QBFs, proposed by Beyersdorff et al. in 2019, explicitly builds partial strategies inside refutations. The original motivation for this approach was to overcome the limitations encountered in long-distance Q-Resolution proof system (LD-Q-Res), where the syntactic side-conditions, while prohibiting all unsound resolutions, also end up prohibiting some sound resolutions. However, while the advantage of M-Res over many other resolution-based QBF proof systems was already demonstrated, a comparison with LD-Q-Res itself had remained open. In this paper, we settle this question. We show that M-Res has an exponential advantage over not only LD-Q-Res, but even over LQU$^+$-Res and IRM, the most powerful among currently known resolution-based QBF proof systems. Combining this with results from Beyersdorff et al. 2020, we conclude that M-Res is incomparable with LQU-Res and LQU$^+$-Res. Our proof method reveals two additional and curious features about M-Res: (i) M-Res is not closed under restrictions, and is hence not a natural proof system, and (ii) weakening axiom clauses with existential variables provably yields an exponential advantage over M-Res without weakening. We further show that in the context of regular derivations, weakening axiom clauses with universal variables provably yields an exponential advantage over M-Res without weakening. These results suggest that M-Res is better used with weakening, though whether M-Res with weakening is closed under restrictions remains open. We note that even with weakening, M-Res continues to be simulated by eFrege $+$ $\forall$red (the simulation of ordinary M-Res was shown recently by Chew and Slivovsky).</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13428v5</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meena Mahajan, Gaurav Sood</dc:creator>
    </item>
    <item>
      <title>On the power of counting the total number of computation paths of NPTMs</title>
      <link>https://arxiv.org/abs/2306.11614</link>
      <description>arXiv:2306.11614v4 Announce Type: replace 
Abstract: In this paper, we define and study variants of several complexity classes of decision problems that are defined via some criteria on the number of accepting paths of an NPTM. In these variants, we modify the acceptance criteria so that they concern the total number of computation paths instead of the number of accepting ones. This direction reflects the relationship between the counting classes #P and TotP, which are the classes of functions that count the number of accepting paths and the total number of paths of NPTMs, respectively. The former is the well-studied class of counting versions of NP problems introduced by Valiant (1979). The latter contains all self-reducible counting problems in #P whose decision version is in P, among them prominent #P-complete problems such as Non-negative Permanent, #PerfMatch, and #DNF-Sat, thus playing a significant role in the study of approximable counting problems. We show that almost all classes introduced in this work coincide with their `#accepting paths'-definable counterparts, thus providing an alternative model of computation for them. Moreover, for each of these classes, we present a novel family of complete problems, which are defined via TotP-complete problems. This way, we show that all the aforementioned classes have complete problems that are defined via counting problems whose existence version is in P, in contrast to the standard way of obtaining completeness results via counting versions of NP-complete problems. To the best of our knowledge, prior to this work, such results were known only for parity-P and C=P.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.11614v4</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eleni Bakali, Aggeliki Chalki, Sotiris Kanellopoulos, Aris Pagourtzis, Stathis Zachos</dc:creator>
    </item>
    <item>
      <title>Pseudorandom Permutations from Random Reversible Circuits</title>
      <link>https://arxiv.org/abs/2404.14648</link>
      <description>arXiv:2404.14648v3 Announce Type: replace 
Abstract: We study pseudorandomness properties of permutations on $\{0,1\}^n$ computed by random circuits made from reversible $3$-bit gates (permutations on $\{0,1\}^3$). Our main result is that a random circuit of depth $n \cdot \tilde{O}(k^2)$, with each layer consisting of $\approx n/3$ random gates in a fixed nearest-neighbor architecture, yields almost $k$-wise independent permutations. The main technical component is showing that the Markov chain on $k$-tuples of $n$-bit strings induced by a single random $3$-bit nearest-neighbor gate has spectral gap at least $1/n \cdot \tilde{O}(k)$. This improves on the original work of Gowers [Gowers96], who showed a gap of $1/\mathrm{poly}(n,k)$ for one random gate (with non-neighboring inputs); and, on subsequent work [HMMR05,BH08] improving the gap to $\Omega(1/n^2k)$ in the same setting.
  From the perspective of cryptography, our result can be seen as a particularly simple/practical block cipher construction that gives provable statistical security against attackers with access to $k$~input-output pairs within few rounds. We also show that the Luby--Rackoff construction of pseudorandom permutations from pseudorandom functions can be implemented with reversible circuits. From this, we make progress on the complexity of the Minimum Reversible Circuit Size Problem (MRCSP), showing that block ciphers of fixed polynomial size are computationally secure against arbitrary polynomial-time adversaries, assuming the existence of one-way functions (OWFs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14648v3</guid>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William He, Ryan O'Donnell</dc:creator>
    </item>
    <item>
      <title>Limits of Sequential Local Algorithms on the Random $k$-XORSAT Problem</title>
      <link>https://arxiv.org/abs/2404.17775</link>
      <description>arXiv:2404.17775v2 Announce Type: replace 
Abstract: The random $k$-XORSAT problem is a random constraint satisfaction problem of $n$ Boolean variables and $m=rn$ clauses, which a random instance can be expressed as a $G\mathbb{F}(2)$ linear system of the form $Ax=b$, where $A$ is a random $m \times n$ matrix with $k$ ones per row, and $b$ is a random vector. It is known that there exist two distinct thresholds $r_{core}(k) &lt; r_{sat}(k)$ such that as $n \rightarrow \infty$ for $r &lt; r_{sat}(k)$ the random instance has solutions with high probability, while for $r_{core} &lt; r &lt; r_{sat}(k)$ the solution space shatters into an exponential number of clusters. Sequential local algorithms are a natural class of algorithms which assign values to variables one by one iteratively. In each iteration, the algorithm runs some heuristics, called local rules, to decide the value assigned, based on the local neighborhood of the selected variables under the factor graph representation of the instance.
  We prove that for any $r &gt; r_{core}(k)$ the sequential local algorithms with certain local rules fail to solve the random $k$-XORSAT with high probability. They include (1) the algorithm using the Unit Clause Propagation as local rule for $k \ge 9$, and (2) the algorithms using any local rule that can calculate the exact marginal probabilities of variables in instances with factor graphs that are trees, for $k\ge 13$. The well-known Belief Propagation and Survey Propagation are included in (2). Meanwhile, the best known linear-time algorithm succeeds with high probability for $r &lt; r_{core}(k)$. Our results support the intuition that $r_{core}(k)$ is the sharp threshold for the existence of a linear-time algorithm for random $k$-XORSAT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17775v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ICALP.2024.123</arxiv:DOI>
      <dc:creator>Kingsley Yung</dc:creator>
    </item>
    <item>
      <title>Complexity and Enumeration in Models of Genome Rearrangement</title>
      <link>https://arxiv.org/abs/2305.01851</link>
      <description>arXiv:2305.01851v4 Announce Type: replace-cross 
Abstract: In this paper, we examine the computational complexity of enumeration in certain genome rearrangement models. We first show that the Pairwise Rearrangement problem in the Single Cut-and-Join model (Bergeron, Medvedev, &amp; Stoye, J. Comput. Biol. 2010) is $\#\textsf{P}$-complete under polynomial-time Turing reductions. Next, we show that in the Single Cut or Join model (Feijao &amp; Meidanis, IEEE ACM Trans. Comp. Biol. Bioinf. 2011), the problem of enumerating all medians ($\#$Median) is logspace-computable ($\textsf{FL}$), improving upon the previous polynomial-time ($\textsf{FP}$) bound of Mikl\'os &amp; Smith (RECOMB 2015).</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01851v4</guid>
      <category>q-bio.GN</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lora Bailey, Heather Smith Blake, Garner Cochran, Nathan Fox, Michael Levet, Reem Mahmoud, Elizabeth Matson, Inne Singgih, Grace Stadnyk, Xinyi Wang, Alexander Wiedemann</dc:creator>
    </item>
    <item>
      <title>Polynomial Logical Zonotope: A Set Representation for Reachability Analysis of Logical Systems</title>
      <link>https://arxiv.org/abs/2306.12508</link>
      <description>arXiv:2306.12508v3 Announce Type: replace-cross 
Abstract: In this paper, we introduce a set representation called polynomial logical zonotopes for performing exact and computationally efficient reachability analysis on logical systems. We prove that through this polynomial-like construction, we are able to perform all of the fundamental logical operations (XOR, NOT, XNOR, AND, NAND, OR, NOR) between sets of points exactly in a reduced space, i.e., generator space with reduced complexity. Polynomial logical zonotopes are a generalization of logical zonotopes, which are able to represent up to $2^n$ binary vectors using only $n$ generators. Due to their construction, logical zonotopes are only able to support exact computations of some logical operations (XOR, NOT, XNOR), while other operations (AND, NAND, OR, NOR) result in over-approximations in the generator space. In order to perform all fundamental logical operations exactly, we formulate a generalization of logical zonotopes that is constructed by dependent generators and exponent matrices. While we are able to perform all of the logical operations exactly, this comes with a slight increase in computational complexity compared to logical zonotopes. To illustrate and showcase the computational benefits of polynomial logical zonotopes, we present the results of performing reachability analysis on two use cases: (1) safety verification of an intersection crossing protocol and (2) reachability analysis on a high-dimensional Boolean function. Moreover, to highlight the extensibility of logical zonotopes, we include an additional use case where we perform a computationally tractable exhaustive search for the key of a linear feedback shift register.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12508v3</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amr Alanwar, Frank J. Jiang, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Tight (Double) Exponential Bounds for Identification Problems: Locating-Dominating Set and Test Cover</title>
      <link>https://arxiv.org/abs/2402.08346</link>
      <description>arXiv:2402.08346v3 Announce Type: replace-cross 
Abstract: We investigate fine-grained algorithmic aspects of identification problems in graphs and set systems, with a focus on Locating-Dominating Set and Test Cover. We prove the (tight) conditional lower bounds for these problems when parameterized by treewidth and solution as. Formally, \textsc{Locating-Dominating Set} (respectively, \textsc{Test Cover}) parameterized by the treewidth of the input graph (respectively, of the natural auxiliary graph) does not admit an algorithm running in time $2^{2^{o(tw)}} \cdot poly(n)$ (respectively, $2^{2^{o(tw)}} \cdot poly(|U| + |\mathcal{F}|))$. This result augments the small list of NP-Complete problems that admit double exponential lower bounds when parameterized by treewidth. Then, we first prove that \textsc{Locating-Dominating Set} does not admit an algorithm running in time $2^{o(k^2)} \cdot poly(n)$, nor a polynomial time kernelization algorithm that reduces the solution size and outputs a kernel with $2^{o(k)}$ vertices, unless the \ETH\ fails. To the best of our knowledge, \textsc{Locating-Dominating Set} is the first problem that admits such an algorithmic lower-bound (with a quadratic function in the exponent) when parameterized by the solution size. Finally, we prove that \textsc{Test Cover} does not admit an algorithm running in time $2^{2^{o(k)}} \cdot poly(|U| + |\mathcal{F}|)$. This is also a rare example of the problem that admits a double exponential lower bound when parameterized by the solution size.
  We also present algorithms whose running times match the above lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08346v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dipayan Chakraborty, Florent Foucaud, Diptapriyo Majumdar, Prafullkumar Tale</dc:creator>
    </item>
  </channel>
</rss>
