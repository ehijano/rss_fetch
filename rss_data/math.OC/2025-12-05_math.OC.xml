<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Dec 2025 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Probabilistic Safety under Arbitrary Disturbance Distributions using Piecewise-Affine Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2512.04194</link>
      <description>arXiv:2512.04194v1 Announce Type: new 
Abstract: We propose a simple safety filter design for stochastic discrete-time systems based on piecewise affine probabilistic control barrier functions, providing an appealing balance between modeling flexibility and computational complexity. Exact evaluation of the safety filter consists of solving a mixed-integer quadratic program (MIQP) if the dynamics are control-affine (or a mixed-integer nonlinear program in general). We propose a heuristic search method that replaces this by a small number of small-scale quadratic programs (QPs), or nonlinear programs (NLPs) respectively. The proposed approach provides a flexible framework in which arbitrary (data-driven) quantile estimators can be used to bound the probability of safety violations. Through extensive numerical experiments, we demonstrate improvements in conservatism and computation time with respect to existing methods, and we illustrate the flexibility of the method for modeling complex safety sets. Supplementary material can be found at https://mathijssch.github.io/ecc26-supplementary/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04194v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matisse Teuwen, Mathijs Schuurmans, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Undiscounted Equilibrium in Positive Recursive Absorbing Games with Non-Rectangular Absorption Structure</title>
      <link>https://arxiv.org/abs/2512.04306</link>
      <description>arXiv:2512.04306v1 Announce Type: new 
Abstract: An absorbing game is a stochastic game with a single nonabsorbing state. Such a game is called recursive if all players receive a payoff of 0 in the nonabsorbing state, and positive if all payoffs in absorbing states are positive. An action profile is nonabsorbing if, when it is played, the game remains in the nonabsorbing state with probability 1. The set of nonabsorbing action profiles can be partitioned into the connected components of an undirected graph, whose vertices are these profiles, with two vertices joined by an edge whenever the corresponding profiles differ in the action of a single player. A connected component is said to be rectangular if it is the Cartesian product of subsets of the players' action sets.
  We prove that every positive recursive absorbing game whose nonabsorbing components are all non-rectangular admits an undiscounted equilibrium payoff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04306v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eilon Solan, Nicolas Vieille</dc:creator>
    </item>
    <item>
      <title>A Dual Riemannian ADMM Algorithm for Low-Rank SDPs with Unit Diagonal</title>
      <link>https://arxiv.org/abs/2512.04406</link>
      <description>arXiv:2512.04406v1 Announce Type: new 
Abstract: This paper proposes a dual Riemannian alternating direction method of multipliers (ADMM) for solving low-rank semidefinite programs with unit diagonal constraints. We recast the ADMM subproblem as a Riemannian optimization problem over the oblique manifold by performing the Burer-Monteiro factorization. Global convergence of the algorithm is established assuming that the subproblem is solved to certain optimality. Numerical experiments demonstrate the excellent performance of the algorithm. It outperforms, by a significant margin, a few advanced SDP solvers (MOSEK, COPT, SDPNAL+, ManiSDP) in terms of accuracy, efficiency, and scalability on second-order SDP relaxations of dense and sparse binary quadratic programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04406v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Wang, Liangbing Hu, Bican Xia</dc:creator>
    </item>
    <item>
      <title>An accelerated proximal bundle method for convex optimization</title>
      <link>https://arxiv.org/abs/2512.04523</link>
      <description>arXiv:2512.04523v1 Announce Type: new 
Abstract: The proximal bundle method (PBM) is a powerful and widely used approach for minimizing nonsmooth convex functions. However, for smooth objectives, its best-known convergence rate remains suboptimal, and whether PBM can be accelerated remains open. In this work, we present the first accelerated proximal bundle method that achieves the optimal $\mathscr{O}(1/\sqrt{\epsilon})$ iteration complexity for obtaining an $\epsilon$-accurate solution in smooth convex optimization. The proposed method is conceptually simple, which differs from Nesterov's accelerated gradient descent by only a single line and retains all key structural properties of the classical PBM. In particular, it relies on the same minimal assumptions on model approximations and preserves the standard bundle testing criterion. Numerical experiments confirm the accelerated $\mathscr{O}(1/\sqrt{\epsilon})$ convergence rate predicted by our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04523v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng-Yi Liao, Thomas Madden, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>Research on the descent direction of prediction correction algorithms for pseudo-convex/convex optimization problems</title>
      <link>https://arxiv.org/abs/2512.04575</link>
      <description>arXiv:2512.04575v1 Announce Type: new 
Abstract: Prediction-correction algorithms are a highly effective class of methods for solving pseudo-convex optimization problems. The descent direction of these algorithms can be viewed as an adjustment to the gradient direction based on the prediction step. This paper investigates the adjustment coefficients of these descent directions and offers explanations from the perspective of differential equations. Unlike existing algorithms where the adjustment coefficient is always set to 1, we establish that the range of the adjustment coefficient lies within (1/2,1] for pseudo-convex optimization problems, and [0,1] for convex optimization problems. We also provide rigorous convergence proofs for these proposed algorithms. Numerical experiment results show that the algorithms perform best when the value of the adjustment coefficient makes the algorithm approach or equal to those in differential equations with higher-order global discrete error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04575v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ting Li, Deren Han, Tanxing Wang, Xingju Cai</dc:creator>
    </item>
    <item>
      <title>Temporal and Spatial Decomposition for Prospective Studies in Energy Systems under Uncertainty</title>
      <link>https://arxiv.org/abs/2512.04622</link>
      <description>arXiv:2512.04622v1 Announce Type: new 
Abstract: The increasing penetration of renewable energy requires greater use of storage resources to manage system intermittency. As a result, there is growing interest in evaluating the opportunity cost of stored energy, or usage values, which can be derived by solving a multistage stochastic optimization problem. Stochasticity arises from net demand (the aggregation of demand and non-dispatchable generation), the availability of dispatchable generation, and inflows when the storage facilities considered are hydroelectric dams. We aim to compute these usage values for each market zone of the interconnected European electricity system, in the context of prospective studies currently conducted by RTE, the French TSO. The energy system is mathematically modelled as a directed graph, where nodes represent market zones and arcs represent interconnection links. In large energy systems, spatial complexity (thirty nodes in the system, each with at most one aggregated storage unit) compounds temporal complexity (a one-year horizon modelled with two timescales: weekly subproblems with hourly time steps). This work addresses three main sources of complexity: temporal, spatial, and stochastic. We tackle the multinode multistage stochastic optimisation problem by incorporating a spatio-temporal decomposition scheme. To efficiently compute usage values, we apply Dual Approximate Dynamic Programming (DADP), which enables tractable decomposition across both time and space. This approach yields nodal usage values that depend solely on the local state of each node, independently of the others. We conduct numerical studies on a realistic system composed of thirty nodes (modelling part of Europe) and show that DADP obtains competitive results when comparing with traditional methods like Stochastic Dual Dynamic Programming (SDDP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04622v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Camila Martinez Parra (RTE, CERMICS), Michel de Lara (CERMICS), Jean-Philippe Chancelier (CERMICS), Pierre Carpentier (UMA), Jean-Marc Janin (RTE)</dc:creator>
    </item>
    <item>
      <title>The $\Lambda$-Set and Its Role in Local Controllability and Necessary Conditions for Free-Time Optimal Control</title>
      <link>https://arxiv.org/abs/2512.04651</link>
      <description>arXiv:2512.04651v1 Announce Type: new 
Abstract: This paper establishes a unified framework connecting local controllability, necessary conditions for optimality, and attainability in free-time optimal control problems. The central object of our investigation is the $\Lambda$-set, which governs the relationship between original control systems and their convexifications. Our main results demonstrate that emptiness of the $\Lambda$-set implies local controllability and guarantees the existence of minimizing sequences achieving the target in reduced time. We derive strengthened necessary conditions for time-optimal control and provide explicit constructive procedures for approximating generalized controls by ordinary trajectories. These results resolve longstanding questions about relaxation phenomena while extending classical theory to address modern challenges in non-convex optimization, establishing foundations for higher-order analysis in free-time problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04651v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohammad H. M. Rashid</dc:creator>
    </item>
    <item>
      <title>Continuous-time reinforcement learning for optimal switching over multiple regimes</title>
      <link>https://arxiv.org/abs/2512.04697</link>
      <description>arXiv:2512.04697v1 Announce Type: new 
Abstract: This paper studies the continuous-time reinforcement learning (RL) for optimal switching problems across multiple regimes. We consider a type of exploratory formulation under entropy regularization where the agent randomizes both the timing of switches and the selection of regimes through the generator matrix of an associated continuous-time finite-state Markov chain. We establish the well-posedness of the associated system of Hamilton-Jacobi-Bellman (HJB) equations and provide a characterization of the optimal policy. The policy improvement and the convergence of the policy iterations are rigorously established by analyzing the system of equations. We also show the convergence of the value function in the exploratory formulation towards the value function in the classical formulation as the temperature parameter vanishes. Finally, a reinforcement learning algorithm is devised and implemented by invoking the policy evaluation based on the martingale characterization. Our numerical examples with the aid of neural networks illustrate the effectiveness of the proposed RL algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04697v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijie Huang, Mengge Li, Xiang Yu, Zhou Zhou</dc:creator>
    </item>
    <item>
      <title>Coordinated Mean-Field Control for Systemic Risk</title>
      <link>https://arxiv.org/abs/2512.04704</link>
      <description>arXiv:2512.04704v1 Announce Type: new 
Abstract: We develop a robust linear-quadratic mean-field control framework for systemic risk under model uncertainty, in which a central bank jointly optimizes interest rate policy and supervisory monitoring intensity against adversarial distortions. Our model features multiple policy instruments with interactive dynamics, implemented via a variance weight that depends on the policy rate, generating coupling effects absent in single-instrument models. We establish viscosity solutions for the associated HJB--Isaacs equation, prove uniqueness via comparison principles, and provide verification theorems. The linear-quadratic structure yields explicit feedback controls derived from a coupled Riccati system, preserving analytical tractability despite adversarial uncertainty. Simulations reveal distinct loss-of-control regimes driven by robustness-breakdown and control saturation, alongside a pronounced asymmetry in sensitivity between the mean and variance channels. These findings demonstrate the importance of instrument complementarity in systemic risk modeling and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04704v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshiaki Yamanaka</dc:creator>
    </item>
    <item>
      <title>Neural Policy Composition from Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2512.04745</link>
      <description>arXiv:2512.04745v1 Announce Type: new 
Abstract: The ability to compose acquired skills to plan and execute behaviors is a hallmark of natural intelligence. Yet, despite remarkable cross-disciplinary efforts, a principled account of how task structure shapes gating and how such computations could be delivered in neural circuits, remains elusive. Here we introduce GateMod, an interpretable theoretically grounded computational model linking the emergence of gating to the underlying decision-making task, and to a neural circuit architecture. We first develop GateFrame, a normative framework casting policy gating into the minimization of the free energy. This framework, relating gating rules to task, applies broadly across neuroscience, cognitive and computational sciences. We then derive GateFlow, a continuous-time energy based dynamics that provably converges to GateFrame optimal solution. Convergence, exponential and global, follows from a contractivity property that also yields robustness and other desirable properties. Finally, we derive a neural circuit from GateFlow, GateNet. This is a soft-competitive recurrent circuit whose components perform local and contextual computations consistent with known dendritic and neural processing motifs. We evaluate GateMod across two different settings: collective behaviors in multi-agent systems and human decision-making in multi-armed bandits. In all settings, GateMod provides interpretable mechanistic explanations of gating and quantitatively matches or outperforms established models. GateMod offers a unifying framework for neural policy gating, linking task objectives, dynamical computation, and circuit-level mechanisms. It provides a framework to understand gating in natural agents beyond current explanations and to equip machines with this ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04745v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesca Rossi, Veronica Centorrino, Francesco Bullo, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Adaptive Online Optimization for Microgrids with Renewable Energy Sources</title>
      <link>https://arxiv.org/abs/2512.04778</link>
      <description>arXiv:2512.04778v1 Announce Type: new 
Abstract: In this paper we propose a novel adaptive online optimization algorithm tailored to the management of microgrids with high renewable energy penetration, which can be formulated as a constrained, online optimization problem. The proposed algorithm is characterized by a control-based design that applies the internal model principle, and a system identification routine tasked with identifying such internal model. In addition, in order to ensure the constraints are verified, we integrate a projection onto the constraint set. We showcase promising numerical results for the microgrid use case, highlighting in particular the enhanced adaptability of the proposed algorithm to changes in the internal model. The performance of the proposed algorithm is shown to outperform state-of-the-art alternative in the long-term, ensuring efficient management of the grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04778v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wouter J. A. van Weerelt, Angela Fontan, Nicola Bastianello</dc:creator>
    </item>
    <item>
      <title>Configuration-Constrained Tube MPC for Periodic Operation</title>
      <link>https://arxiv.org/abs/2512.04239</link>
      <description>arXiv:2512.04239v1 Announce Type: cross 
Abstract: Periodic operation often emerges as the economically optimal mode in industrial processes, particularly under varying economic or environmental conditions. This paper proposes a robust model predictive control (MPC) framework for uncertain systems modeled as polytopic linear differential inclusions (LDIs), where the dynamics evolve as convex combinations of finitely many affine control systems with additive disturbances. The robust control problem is reformulated as a convex optimization program by optimizing over configuration-constrained polytopic tubes and tracks a periodic trajectory that is optimal for a given economic criterion. Artificial variables embedded in the formulation ensure recursive feasibility and robust constraint satisfaction when the economic criterion is updated online, while guaranteeing convergence to the corresponding optimal periodic tube when the criterion remains constant. To improve computational efficiency, we introduce a quadratic over-approximation of the periodic cost under a Lipschitz continuity assumption, yielding a Quadratic Program (QP) formulation that preserves the above theoretical guarantees. The effectiveness and scalability of the approach are demonstrated on a benchmark example and a ball-plate system with eight states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04239v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filippo Badalamenti, Jose A. Borja-Conde, Sampath Kumar Mulagaleti, Boris Houska, Alberto Bemporad, Mario Eduardo Villanueva</dc:creator>
    </item>
    <item>
      <title>Stability of Lyapunov redesign trajectory tracking control with unbounded perturbations -- A tube-based stability analysis</title>
      <link>https://arxiv.org/abs/2512.04247</link>
      <description>arXiv:2512.04247v1 Announce Type: cross 
Abstract: Considering a nonlinear system in Byrnes-Isidori form that is subject to unbounded perturbations, we apply Lyapunov redesign via feedback linearisation for trajectory tracking. Leveraging the ideas of tube-based geometric characterisation of the invariance properties of the closed loop, we generalise the classical stability criterion from the~literature from constant to nonconstant reference trajectories. The proposed analysis is tailored to the Lyapunov redesign and the tracking problem insofar as we incorporate the reference trajectory and the transient decrease of the tracking error enforced by the controller. In particular, we exploit that the Lyapunov function of the tracking error satisfies a differential inequality, thereby guaranteeing that the solution of the closed loop remains in a contracting tube along the reference trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04247v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Niclas Titze, Kai Wulff, Johann Reger</dc:creator>
    </item>
    <item>
      <title>When do spectral gradient updates help in deep learning?</title>
      <link>https://arxiv.org/abs/2512.04299</link>
      <description>arXiv:2512.04299v1 Announce Type: cross 
Abstract: Spectral gradient methods, such as the recently popularized Muon optimizer, are a promising alternative to standard Euclidean gradient descent for training deep neural networks and transformers, but it is still unclear in which regimes they are expected to perform better. We propose a simple layerwise condition that predicts when a spectral update yields a larger decrease in the loss than a Euclidean gradient step. This condition compares, for each parameter block, the squared nuclear-to-Frobenius ratio of the gradient to the stable rank of the incoming activations. To understand when this condition may be satisfied, we first prove that post-activation matrices have low stable rank at Gaussian initialization in random feature regression, feedforward networks, and transformer blocks. In spiked random feature models we then show that, after a short burn-in, the Euclidean gradient's nuclear-to-Frobenius ratio grows with the data dimension while the stable rank of the activations remains bounded, so the predicted advantage of spectral updates scales with dimension. We validate these predictions in synthetic regression experiments and in NanoGPT-scale language model training, where we find that intermediate activations have low-stable-rank throughout training and the corresponding gradients maintain large nuclear-to-Frobenius ratios. Together, these results identify conditions for spectral gradient methods, such as Muon, to be effective in training deep networks and transformers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04299v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damek Davis, Dmitriy Drusvyatskiy</dc:creator>
    </item>
    <item>
      <title>AI-Assisted Game Management Decisions: A Fuzzy Logic Approach to Real-Time Substituitions</title>
      <link>https://arxiv.org/abs/2512.04480</link>
      <description>arXiv:2512.04480v1 Announce Type: cross 
Abstract: In elite soccer, substitution decisions entail significant financial and sporting consequences yet remain heavily reliant on intuition or predictive models that merely mimic historical biases. This paper introduces a Fuzzy Logic based Decision Support System (DSS) designed for real time, prescriptive game management. Unlike traditional Machine Learning approaches that encounter a predictive ceiling by attempting to replicate human behavior, our system audits performance through an objective, rule based inference engine. We propose a methodological advancement by reformulating the PlayeRank metric into a Cumulative Mean with Role Aware Normalization, eliminating the play time exposure bias inherent in cumulative sum models to enable accurate intra match comparison. The system integrates this refined metric with physiological proxies (fatigue) and contextual variables (disciplinary risk modulated by tactical role) to calculate a dynamic Substitution Priority (P final). Validation via a case study of the 2018 FIFA World Cup match between Brazil and Belgium demonstrates the system's ecological validity: it not only aligned with expert consensus on executed substitutions (for example Gabriel Jesus) but, crucially, identified high risk scenarios ignored by human decision makers. Specifically, the model flagged the "FAGNER Paradox" - a maximum priority defensive risk - minutes before a critical yellow card, and detected the "Lukaku Paradox", where an isolated assist masked a severe drop in participation. These results confirm that Fuzzy Logic offers a transparent, explainable, and superior alternative to black box models for optimizing real time tactical decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04480v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pedro Passos</dc:creator>
    </item>
    <item>
      <title>A Note on Restricted Selection Set from Random Interval</title>
      <link>https://arxiv.org/abs/2512.04539</link>
      <description>arXiv:2512.04539v1 Announce Type: cross 
Abstract: We study restricted selection sets of random intervals in $\R^1$ defined on a non-atomic probability space. Given a random interval $Y=[y_L,y_U]$ and scalar constraints on the expectation or the median of admissible selections, we define the restricted selection set and establish its existence, basic structure and influence on bounding moments and quantiles. In particular, we give conditions under which any mean (or quantile) in the Aumann expectation range can be attained by a measurable selection. We characterize the induced ranges of means, medians, and event probabilities. The analysis is carried out in a minimal one-dimensional random-set framework inspired by the classical theory of Aumann integrals. We also outline extensions to higher-order moment and general quantile restrictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04539v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arie Beresteanu, Behrooz Moosavi Rameznzadeh</dc:creator>
    </item>
    <item>
      <title>Adapt and Stabilize, Then Learn and Optimize: A New Approach to Adaptive LQR</title>
      <link>https://arxiv.org/abs/2512.04565</link>
      <description>arXiv:2512.04565v1 Announce Type: cross 
Abstract: This paper focuses on adaptive control of the discrete-time linear quadratic regulator (adaptive LQR). Recent literature has made significant contributions in proving non-asymptotic convergence rates, but existing approaches have a few drawbacks that pose barriers for practical implementation. These drawbacks include (i) a requirement of an initial stabilizing controller, (ii) a reliance on exploration for closed-loop stability, and/or (iii) computationally intensive algorithms. This paper proposes a new algorithm that overcomes these drawbacks for a particular class of discrete-time systems. This algorithm leverages direct Model-Reference Adaptive Control (direct MRAC) and combines it with an epoch-based approach in order to address the drawbacks (i)-(iii) with a provable high-probability regret bound comparable to existing literature. Simulations demonstrate that the proposed approach yields regrets that are comparable to those from existing methods when the conditions (i) and (ii) are met, and yields regrets that are significantly smaller when either of these two conditions is not met.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04565v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter A. Fisher, Anuradha M. Annaswamy</dc:creator>
    </item>
    <item>
      <title>Optimal cost for the null controllability of the Stokes system with controls having $n-1$ components and applications</title>
      <link>https://arxiv.org/abs/2512.04721</link>
      <description>arXiv:2512.04721v1 Announce Type: cross 
Abstract: In this work, we investigate the optimal cost of null controllability for the $n$-dimensional Stokes system when the control acts on $n-1$ scalar components. We establish a novel spectral estimate for low frequencies of the Stokes operator, involving solely $n-1$ components, and use it to show that the cost of controllability with controls having $n-1$ components remains of the same order in time as in the case of controls with $n$ components, namely $O(e^{C/T})$, i.e. the cost of null controllability is not affected by the absence of one component of the control. We also give several applications of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04721v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe W. Chaves-Silva, Diego A. Souza, Marcos G. Ferreira-Silva</dc:creator>
    </item>
    <item>
      <title>Side-by-side first-price auctions with imperfect bidders</title>
      <link>https://arxiv.org/abs/2512.04850</link>
      <description>arXiv:2512.04850v1 Announce Type: cross 
Abstract: We model a procurement scenario in which two \textit{imperfect} bidders act simultaneously on behalf of a single buyer, a configuration common in display advertising and referred to as \textit{side-by-side bidding} but largely unexplored in theory. We prove that the iterated best response algorithm converges to an equilibrium under standard distributional assumptions and provide sufficient condition for uniqueness. Beyond establishing existence and convergence, our analysis provides a tractable numerical method for quantitative studies of side-by-side procurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04850v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Heymann</dc:creator>
    </item>
    <item>
      <title>Quantitative rigidity of the Wasserstein contraction under convolution</title>
      <link>https://arxiv.org/abs/2512.04928</link>
      <description>arXiv:2512.04928v1 Announce Type: cross 
Abstract: The aim of this paper is to investigate the contraction properties of $p$-Wasserstein distances with respect to convolution in Euclidean spaces both qualitatively and quantitatively. We connect this question to the question of uniform convexity of the Kantorovich functional on which there was substantial recent progress (mostly for $p=2$ and partially for $p&gt;1$). Motivated by this connection we extend these uniform convexity results to the case $p=1$, which is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04928v1</guid>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Max Fathi, Michael Goldman, Daniel Tsodyks</dc:creator>
    </item>
    <item>
      <title>A tangential low-rank ADI method for solving indefinite Lyapunov equations</title>
      <link>https://arxiv.org/abs/2512.04983</link>
      <description>arXiv:2512.04983v1 Announce Type: cross 
Abstract: Continuous-time algebraic Lyapunov equations have become an essential tool in various applications. In the case of large-scale sparse coefficient matrices and indefinite constant terms, indefinite low-rank factorizations have successfully been used to allow methods like the alternating direction implicit (ADI) iteration to efficiently compute accurate approximations to the solution of the Lyapunov equation. However, classical block-type approaches quickly increase in computational costs when the rank of the constant term grows. In this paper, we propose a novel tangential reformulation of the ADI iteration that allows for the efficient construction of low-rank approximations to the solution of Lyapunov equations with indefinite right-hand sides even in the case of constant terms with higher ranks. We provide adaptive methods for the selection of the corresponding ADI parameters, namely shifts and tangential directions, which allow for the automatic application of the method to any relevant problem setting. The effectiveness of the developed algorithms is illustrated by several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04983v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rudi Smith, Steffen W. R. Werner</dc:creator>
    </item>
    <item>
      <title>Perceptually-Minimal Color Optimization for Web Accessibility: A Multi-Phase Constrained Approach</title>
      <link>https://arxiv.org/abs/2512.05067</link>
      <description>arXiv:2512.05067v1 Announce Type: cross 
Abstract: Web accessibility guidelines require sufficient color contrast between text and backgrounds; yet, manually adjusting colors often necessitates significant visual deviation, compromising vital brand aesthetics. We present a novel, multi-phase optimization approach for automatically generating WCAG-compliant colors while minimizing perceptual change to original design choices.
  Our method treats this as a constrained, non-linear optimization problem, utilizing the modern perceptually uniform OKLCH color space. Crucially, the optimization is constrained to preserve the original hue ($\text{H}$) of the color, ensuring that modifications are strictly limited to necessary adjustments in lightness ($\text{L}$) and chroma ($\text{C}$). This is achieved through a three-phase sequence: binary search, gradient descent, and progressive constraint relaxation.
  Evaluation on a dataset of 10,000 procedurally generated color pairs demonstrates that the algorithm successfully resolves accessibility violations in $77.22\%$ of cases, with $88.51\%$ of successful corrections exhibiting imperceptible color difference ($\Delta E_{2000} &lt; 2.0$) as defined by standard perceptibility thresholds. The median perceptual change for successful adjustments is only $0.76\ \Delta E_{2000}$, and the algorithm achieves this with a median processing time of $0.876\text{ms}$ per color pair.
  The approach demonstrates that accessibility compliance and visual design integrity can be achieved simultaneously through a computationally efficient, perceptually-aware optimization that respects brand identity. The algorithm is publicly implemented in the open-source cm-colors Python library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05067v1</guid>
      <category>cs.HC</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lalitha A R</dc:creator>
    </item>
    <item>
      <title>The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception</title>
      <link>https://arxiv.org/abs/2512.05089</link>
      <description>arXiv:2512.05089v1 Announce Type: cross 
Abstract: Real-world physical processes do not generate arbitrary variability: their signals concentrate on compact and low-variability subsets of functional space. This geometric structure enables rapid generalization from a few examples in both biological and artificial systems.
  This work develops a deterministic functional-topological framework in which the set of valid realizations of a physical phenomenon forms a compact perceptual manifold with stable invariants and a finite Hausdorff radius. We show that the boundaries of this manifold can be discovered in a fully self-supervised manner through Monte Carlo sampling, even when the governing equations of the system are unknown.
  We provide theoretical guarantees, practical estimators of knowledge boundaries, and empirical validations across three domains: electromechanical railway point machines, electrochemical battery discharge curves, and physiological ECG signals.
  Our results demonstrate that deterministic functional topology offers a unified mathematical foundation for perception, representation, and world-model construction, explaining why biological learners and self-supervised AI models can generalize from limited observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05089v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo Di Santi</dc:creator>
    </item>
    <item>
      <title>Convergence Rates of the Regularized Optimal Transport : Disentangling Suboptimality and Entropy</title>
      <link>https://arxiv.org/abs/2306.06940</link>
      <description>arXiv:2306.06940v3 Announce Type: replace 
Abstract: We study the convergence of the transport plans $\gamma_\epsilon$ towards $\gamma_0$ as well as the cost of the entropy-regularized optimal transport $(c,\gamma_\epsilon)$ towards $(c,\gamma_0)$ as the regularization parameter $\epsilon$ vanishes in the setting of finite entropy marginals. We show that under the assumption of infinitesimally twisted cost and compactly supported marginals the distance $W_2(\gamma_\epsilon,\gamma_0)$ is asymptotically greater than $C\sqrt{\epsilon}$ and the suboptimality $(c,\gamma_\epsilon)-(c,\gamma_0)$ is of order $\epsilon$. In the quadratic cost case the compactness assumption is relaxed into a moment of order $2+\delta$ assumption. Moreover, in the case of a Lipschitz transport map for the non-regularized problem, the distance $W_2(\gamma_\epsilon,\gamma_0)$ converges to $0$ at rate $\sqrt{\epsilon}$. Finally, if in addition the marginals have finite Fisher information, we prove $(c,\gamma_\epsilon)-(c,\gamma_0) \sim d\epsilon/2$ and we provide a companion expansion of $H(\gamma_\epsilon)$. These results are achieved by disentangling the role of the cost and the entropy in the regularized problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06940v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1591554</arxiv:DOI>
      <dc:creator>Hugo Malamut (CEREMADE), Maxime Sylvestre (CEREMADE)</dc:creator>
    </item>
    <item>
      <title>Well-posedness and stability of boundary delay equations</title>
      <link>https://arxiv.org/abs/2503.11156</link>
      <description>arXiv:2503.11156v4 Announce Type: replace 
Abstract: In this paper, we introduce the notion of boundary delay equations, establishing a unified framework for analyzing linear time-invariant systems with pure time-delayed boundary conditions. We establish mild sufficient conditions for the existence, uniqueness, and positivity of solutions. Furthermore, we derive spectral criteria for exponential stability. The conditions on the perturbation generalize well-known criteria for the generation of domain perturbations of positive semigroup generators. As an application, we present necessary and sufficient conditions for the exponential stability of positive hyperbolic systems with time-delayed boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11156v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yassine El Gantouh, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Risk-Aware Adaptive Control Barrier Functions for Safe Control of Nonlinear Systems under Stochastic Uncertainty</title>
      <link>https://arxiv.org/abs/2503.19205</link>
      <description>arXiv:2503.19205v4 Announce Type: replace 
Abstract: This paper addresses the challenge of ensuring safety in stochastic control systems with high-relative-degree constraints, while maintaining feasibility and mitigating conservatism in risk evaluation. Control Barrier Functions (CBFs) provide an effective framework for enforcing safety constraints in nonlinear systems. However, existing methods struggle with feasibility issues and multi-step uncertainties. To address these challenges, we introduce Risk-aware Adaptive CBFs (RACBFs), which integrate Discrete-time Auxiliary-Variable adaptive CBFs (DAVCBFs) with coherent risk measures. DAVCBFs introduce auxiliary variables to improve the feasibility of the optimal control problem, while RACBFs incorporate risk-aware formulations to balance safety and risk evaluation performance. By extending discrete-time high-order CBF constraints over multiple steps, RACBFs effectively handle multi-step uncertainties that propagate through the system dynamics. We demonstrate the effectiveness of our approach on a stochastic unicycle system, showing that RACBFs maintain safety and feasibility while reducing unnecessary conservatism compared to standard robust formulations of discrete-time CBF methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19205v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>Mean Field Game of Optimal Tracking Portfolio</title>
      <link>https://arxiv.org/abs/2505.01858</link>
      <description>arXiv:2505.01858v2 Announce Type: replace 
Abstract: This paper studies the mean field game (MFG) problem arising from a large population competition in fund management, featuring a new type of relative performance via the benchmark tracking constraint. In the n-agent model, each agent can strategically inject capital to ensure that the total wealth outperforms the benchmark process, which is modeled as a linear combination of the population's average wealth process and a market index process. That is, each agent is concerned about the performance of her competitors captured by the floor constraint. With a continuum of agents, we formulate the constrained MFG problem and transform it into an equivalent unconstrained MFG problem with a reflected state process. We establish the existence of the mean field equilibrium (MFE) using the partial differential equation (PDE) approach. Firstly, by applying the dual transform, the best response control of the representative agent can be characterized in analytical form in terms of a dual reflected diffusion process. As a novel contribution, we verify the consistency condition of the MFE in separated domains with the help of the duality relationship and properties of the dual process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01858v2</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Yijie Huang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Discrete-time LQG Mean Field Social Control Problems with Unknown Dynamics</title>
      <link>https://arxiv.org/abs/2507.01420</link>
      <description>arXiv:2507.01420v2 Announce Type: replace 
Abstract: This paper studies the discrete-time linear-quadratic-Gaussian mean field (MF) social control problem in an infinite horizon, where the dynamics of all agents are unknown. The objective is to design a reinforcement learning (RL) algorithm to approximate the decentralized asymptotic optimal social control in terms of two algebraic Riccati equations (AREs). In this problem, a coupling term is introduced into the system dynamics to capture the interactions among agents. This causes the equivalence between model-based and model-free methods to be invalid, which makes it difficult to directly apply traditional model-free algorithms. Firstly, under the assumptions of system stabilizability and detectability, a model-based policy iteration algorithm is proposed to approximate the stabilizing solution of the AREs. The algorithm is proven to be convergent in both cases of semi-positive definite and indefinite weight matrices. Subsequently, by adopting the method of system transformation, a model-free RL algorithm is designed to solve for asymptotic optimal social control. During the iteration process, the updates are performed using data collected from any two agents and MF state. Finally, a numerical case is provided to verify the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01420v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanfang Zhang, Bing-Chang Wang, Shuo Chen</dc:creator>
    </item>
    <item>
      <title>Value Function Approximation for Nonlinear MPC: Learning a Terminal Cost Function with a Descent Property</title>
      <link>https://arxiv.org/abs/2508.05804</link>
      <description>arXiv:2508.05804v2 Announce Type: replace 
Abstract: We present a novel method to synthesize a terminal cost function for a nonlinear model predictive controller (MPC) through value function approximation using supervised learning. Existing methods enforce a descent property on the terminal cost function by construction, thereby restricting the class of terminal cost functions, which in turn can limit the performance and applicability of the MPC. We present a method to approximate the true cost-to-go with a general function approximator that is convex in its parameters, and impose the descent condition on a finite number of states. Through the scenario approach, we provide probabilistic guarantees on the descent condition of the terminal cost function over the continuous state space. We demonstrate and empirically verify our method in a numerical example. By learning a terminal cost function, the prediction horizon of the MPC can be significantly reduced, resulting in reduced online computational complexity while maintaining good closed-loop performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05804v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. M. J. T. Baltussen, C. A. Orrico, A. Katriniok, W. P. M. H. Heemels, D. Krishnamoorthy</dc:creator>
    </item>
    <item>
      <title>Mean Field Games of Controls with Boundary Conditions &amp; Invariance Constraints</title>
      <link>https://arxiv.org/abs/2508.21642</link>
      <description>arXiv:2508.21642v2 Announce Type: replace 
Abstract: In a mean field game of controls, a large population of identical players seek to minimize a cost that depends on the joint distribution of the states of the players and their controls. We first consider the classes of mean field games of controls in which the value function and the distribution of player states satisfy either Dirichlet or Neumann boundary conditions. We prove that such systems are well-posed either with sufficient smallness conditions or in the case of monotone couplings. Next, we consider mean field games of controls under invariance constraints imposed on the state space. We prove the existence and uniqueness of weak solutions to our mean field game system, and then we prove higher regularity of solutions under some additional assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21642v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Jameson Graber, Kyle Rosengartner</dc:creator>
    </item>
    <item>
      <title>Improved Stochastic Optimization of LogSumExp</title>
      <link>https://arxiv.org/abs/2509.24894</link>
      <description>arXiv:2509.24894v2 Announce Type: replace 
Abstract: The LogSumExp function, also known as the free energy, plays a central role in many important optimization problems, including entropy-regularized optimal transport and distributionally robust optimization (DRO). It is also the dual to the Kullback-Leibler (KL) divergence, which is widely used in machine learning. In practice, when the number of exponential terms inside the logarithm is large or infinite, optimization becomes challenging since computing the gradient requires differentiating every term. Previous approaches that replace the full sum with a small batch introduce significant bias. We propose a novel approximation to LogSumExp that can be efficiently optimized using stochastic gradient methods. This approximation is rooted in a sound modification of the KL divergence in the dual, resulting in a new $f$-divergence called the safe KL divergence. The accuracy of the approximation is controlled by a tunable parameter and can be made arbitrarily small. Like the LogSumExp, our approximation preserves convexity. Moreover, when applied to an $L$-smooth function bounded from below, the smoothness constant of the resulting objective scales linearly with $L$. Experiments in DRO and continuous optimal transport demonstrate the advantages of our approach over state-of-the-art baselines and the effective treatment of numerical issues associated with the standard LogSumExp and KL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24894v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egor Gladin, Alexey Kroshnin, Jia-Jie Zhu, Pavel Dvurechensky</dc:creator>
    </item>
    <item>
      <title>Quantum Alternating Direction Method of Multipliers for Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2510.10056</link>
      <description>arXiv:2510.10056v3 Announce Type: replace 
Abstract: Semidefinite programming (SDP) is a fundamental convex optimization problem with wide-ranging applications. However, solving large-scale instances remains computationally challenging due to the high cost of solving linear systems and performing eigenvalue decompositions. In this paper, we present a quantum alternating direction method of multipliers (QADMM) for SDPs, building on recent advances in quantum computing. An inexact ADMM framework is developed, which tolerates errors in the iterates arising from block-encoding approximation and quantum measurement. Within this robust scheme, we design a polynomial proximal operator to address the semidefinite conic constraints and apply the quantum singular value transformation to accelerate the most costly projection updates. We prove that the scheme converges to an $\epsilon$-optimal solution of the SDP problem under the strong duality assumption. A detailed complexity analysis shows that the QADMM algorithm achieves favorable scaling with respect to dimension compared to the classical ADMM algorithm and quantum interior point methods, highlighting its potential for solving large-scale SDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10056v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hantao Nie, Dong An, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Computational Hardness of Static Distributionally Robust Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2511.02224</link>
      <description>arXiv:2511.02224v2 Announce Type: replace 
Abstract: We present some hardness results on finding the optimal policy for the static formulation of distributionally robust Markov decision processes. We construct problem instances such that when the considered policy class is Markovian and non-randomized, finding the optimal policy is NP-hard, and when the considered policy class is Markovian and randomized, the robust value function possesses sub-optimal strict local minima. The considered hard instances involve an ambiguity set with only two transition kernels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02224v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yan Li</dc:creator>
    </item>
    <item>
      <title>An Accelerated Distributed Optimization with Equality and Inequality Coupling Constraints</title>
      <link>https://arxiv.org/abs/2511.19708</link>
      <description>arXiv:2511.19708v2 Announce Type: replace 
Abstract: This paper studies distributed convex optimization with both affine equality and nonlinear inequality couplings through the duality analysis. We first formulate the dual of the coupling-constraint problem and reformulate it as a consensus optimization problem over a connected network. To efficiently solve this dual problem and hence the primal problem, we design an accelerated linearized algorithm that, at each round, a look-ahead linearization of the separable objective is combined with a quadratic penalty on the Laplacian constraint, a proximal step, and an aggregation of iterations. On the theory side, we prove non-ergodic rates for both the primal optimality error and the feasibility error. On the other hand, numerical experiments show a faster decrease of optimality error and feasibility residual than augmented-Lagrangian tracking and distributed subgradient baselines under the same communication budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19708v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyang Qiu, Yangyang Qian, Zongli Lin, Yacov A. Shamash</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models</title>
      <link>https://arxiv.org/abs/2512.03915</link>
      <description>arXiv:2512.03915v2 Announce Type: replace 
Abstract: In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03915v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>X. Y. Han, Yuan Zhong</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Problems with Deep Linear Neural Networks: Global Convergence Guarantees for Gradient Descent with Weight Decay</title>
      <link>https://arxiv.org/abs/2502.15522</link>
      <description>arXiv:2502.15522v3 Announce Type: replace-cross 
Abstract: Machine learning methods are commonly used to solve inverse problems, wherein an unknown signal must be estimated from few indirect measurements generated via a known acquisition procedure. In particular, neural networks perform well empirically but have limited theoretical guarantees. In this work, we study an underdetermined linear inverse problem that admits several possible solution operators that map measurements to estimates of the target signal. A standard remedy (e.g., in compressed sensing) for establishing the uniqueness of the solution mapping is to assume the existence of a latent low-dimensional structure in the source signal. We ask the following question: do deep linear neural networks adapt to unknown low-dimensional structure when trained by gradient descent with weight decay regularization? We prove that mildly overparameterized deep linear networks trained in this manner converge to an approximate solution mapping that accurately solves the inverse problem while implicitly encoding latent subspace structure. We show rigorously that deep linear networks trained with weight decay automatically adapt to latent subspace structure in the data under practical stepsize and weight initialization schemes. Our work highlights that regularization and overparameterization improve generalization, while overparameterization also accelerates convergence during training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15522v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah Laus, Suzanna Parkinson, Vasileios Charisopoulos, Felix Krahmer, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>Bant: Byzantine Antidote via Trial Function and Trust Scores</title>
      <link>https://arxiv.org/abs/2505.07614</link>
      <description>arXiv:2505.07614v5 Announce Type: replace-cross 
Abstract: Recent advancements in machine learning have improved performance while also increasing computational demands. While federated and distributed setups address these issues, their structures remain vulnerable to malicious influences. In this paper, we address a specific threat: Byzantine attacks, wherein compromised clients inject adversarial updates to derail global convergence. We combine the concept of trust scores with trial function methodology to dynamically filter outliers. Our methods address the critical limitations of previous approaches, allowing operation even when Byzantine nodes are in the majority. Moreover, our algorithms adapt to widely used scaled methods such as Adam and RMSProp, as well as practical scenarios, including local training and partial participation. We validate the robustness of our methods by conducting extensive experiments on both public datasets and private ECG data collected from medical institutions. Furthermore, we provide a broad theoretical analysis of our algorithms and their extensions to the aforementioned practical setups. The convergence guaranties of our methods are comparable to those of classical algorithms developed without Byzantine interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07614v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gleb Molodtsov, Daniil Medyakov, Sergey Skorik, Nikolas Khachaturov, Shahane Tigranyan, Vladimir Aletov, Aram Avetisyan, Martin Tak\'a\v{c}, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime</title>
      <link>https://arxiv.org/abs/2510.21245</link>
      <description>arXiv:2510.21245v2 Announce Type: replace-cross 
Abstract: Continuous-time models provide important insights into the training dynamics of optimization algorithms in deep learning. In this work, we establish a non-asymptotic convergence analysis of stochastic gradient Langevin dynamics (SGLD), which is an It\^o stochastic differential equation (SDE) approximation of stochastic gradient descent in continuous time, in the lazy training regime. We show that, under regularity conditions on the Hessian of the loss function, SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate kernel throughout the training process with high probability, and (ii) achieves exponential convergence to the empirical risk minimizer in expectation, and we establish finite-time and finite-width bounds on the optimality gap. We corroborate our theoretical findings with numerical examples in the regression setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21245v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Oberweis, Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Bilevel Models for Adversarial Learning and A Case Study</title>
      <link>https://arxiv.org/abs/2510.25121</link>
      <description>arXiv:2510.25121v2 Announce Type: replace-cross 
Abstract: Adversarial learning has been attracting more and more attention thanks to the fast development of machine learning and artificial intelligence. However, due to the complicated structure of most machine learning models, the mechanism of adversarial attacks is not well interpreted. How to measure the effect of attacks is still not quite clear.
  In this paper, we investigate the adversarial learning from the perturbation analysis point of view.
  We characterize the robustness of learning models through the calmness of the solution mapping.
  In the case of convex clustering models, we identify the conditions under which the clustering results remain the same under perturbations.
  When the noise level is large, it leads to an attack.
  Therefore, we propose two bilevel models for adversarial learning where the effect of adversarial learning is measured
  by some deviation function.
  Specifically, we systematically study the so-called $\delta$-measure and show that under certain conditions, it can be used as a deviation function in adversarial learning for convex clustering models.
  Finally, we conduct numerical tests to verify the above theoretical results as well as the efficiency of the two proposed bilevel models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25121v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Zheng, Qingna Li</dc:creator>
    </item>
    <item>
      <title>N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory</title>
      <link>https://arxiv.org/abs/2511.18723</link>
      <description>arXiv:2511.18723v2 Announce Type: replace-cross 
Abstract: Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&amp;B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&amp;B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18723v2</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Longfei Wang, Junyan Liu, Fan Zhang, Jiangwen Wei, Yuanhua Tang, Jie Sun, Xiaodong Luo</dc:creator>
    </item>
    <item>
      <title>Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics</title>
      <link>https://arxiv.org/abs/2512.03807</link>
      <description>arXiv:2512.03807v2 Announce Type: replace-cross 
Abstract: Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03807v2</guid>
      <category>cs.IR</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christos Kolomvakis, Thomas Bobille, Arnaud Vandaele, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>An Information Theory of Finite Abstractions and their Fundamental Scalability Limits</title>
      <link>https://arxiv.org/abs/2512.03977</link>
      <description>arXiv:2512.03977v2 Announce Type: replace-cross 
Abstract: Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03977v2</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 05 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giannis Delimpaltadakis, Gabriel Gleizer</dc:creator>
    </item>
  </channel>
</rss>
