<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Apr 2025 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Distribution-Free Approach to Testing Models for Angular Power Spectra</title>
      <link>https://arxiv.org/abs/2504.16079</link>
      <description>arXiv:2504.16079v1 Announce Type: new 
Abstract: A novel goodness-of-fit strategy is introduced for testing models for angular power spectra characterized by unknown parameters. Using this strategy, it is possible to assess the validity of such models without specifying the distribution of the estimators of the angular power spectrum being used. This holds under general conditions, ensuring the applicability of the method across diverse scenarios. Moreover, the proposed solution overcomes the need for case-by-case simulations when testing different models -- leading to notable computational advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16079v1</guid>
      <category>physics.data-an</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara Algeri, Xiangyu Zhang, Erik Floden, Hongru Zhao, Galin L. Jones, Vuk Mandic, Jesse Miller</dc:creator>
    </item>
    <item>
      <title>Cluster and statistical analysis of spatial earthquake patterns in the South Caucasus region</title>
      <link>https://arxiv.org/abs/2504.15297</link>
      <description>arXiv:2504.15297v1 Announce Type: cross 
Abstract: The Caucasus region is characterized by heterogeneous and strong seismicity as a result of collision between Arabian and Eurasian tectonic plates. A rich variety of seismic events also distinguishes Azerbaijan, located in its south part. In this research, we consider the earthquakes, specifically spatial earthquake patterns that occurred in Azerbaijan and adjacent areas from 2010 to 2023. Applying density-based clustering algorithms to the earthquake catalog, the proper partitions of spatial earthquake distributions were obtained. The statistical properties of the catalog's partition into 7 clusters are studied in more detail. In particular, we consider the random variable, which is the distance from the fixed point of the earth's surface to earthquake epicenters. The analytical approximation of the cumulative distribution function is constructed for the case when the fixed point coincides with the cluster center and epicenters in the cluster are distributed by the bi-variate normal distribution. For comparison, the numerical distribution functions are evaluated on the basis of Johnson curves and good agreement is observed. Another case is also considered when the fixed point lies outside of a cluster. Under the assumption that a cluster is a circle and epicenters in it are distributed uniformly, the cumulative and probability distribution functions are derived. Applying these functions to the approximation of histograms for the distances from the Shamkir hydroelectric power station to the clusters shows that satisfactory agreement can be achieved. These results are promising for performing the seismic risk assessment for the Shamkir station or other objects of Azerbaijan's critical infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15297v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergii Skurativskyi, Sergiy Mykulyak, Yuliya Semenova, Kateryna Skurativska</dc:creator>
    </item>
    <item>
      <title>Shannon invariants: A scalable approach to information decomposition</title>
      <link>https://arxiv.org/abs/2504.15779</link>
      <description>arXiv:2504.15779v1 Announce Type: cross 
Abstract: Distributed systems, such as biological and artificial neural networks, process information via complex interactions engaging multiple subsystems, resulting in high-order patterns with distinct properties across scales. Investigating how these systems process information remains challenging due to difficulties in defining appropriate multivariate metrics and ensuring their scalability to large systems. To address these challenges, we introduce a novel framework based on what we call "Shannon invariants" -- quantities that capture essential properties of high-order information processing in a way that depends only on the definition of entropy and can be efficiently calculated for large systems. Our theoretical results demonstrate how Shannon invariants can be used to resolve long-standing ambiguities regarding the interpretation of widely used multivariate information-theoretic measures. Moreover, our practical results reveal distinctive information-processing signatures of various deep learning architectures across layers, which lead to new insights into how these systems process information and how this evolves during training. Overall, our framework resolves fundamental limitations in analyzing high-order phenomena and offers broad opportunities for theoretical developments and empirical analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15779v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>nlin.AO</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron J. Gutknecht, Fernando E. Rosas, David A. Ehrlich, Abdullah Makkeh, Pedro A. M. Mediano, Michael Wibral</dc:creator>
    </item>
    <item>
      <title>Maximum Information Extraction From Noisy Data Via Shannon Entropy Minimization</title>
      <link>https://arxiv.org/abs/2504.12990</link>
      <description>arXiv:2504.12990v3 Announce Type: replace 
Abstract: Granting maximum information extraction in the analysis of noisy data is non-trivial. We introduce a general, data-driven approach that employs Shannon entropy as a transferable metric to quantify the maximum information extractable from noisy data via their clustering into statistically-relevant micro-domains. We demonstrate the method's efficiency by analyzing, as a first example, time-series data extracted from molecular dynamics simulations of water and ice coexisting at the solid/liquid transition temperature. The method allows quantifying the information contained in the data distributions (time-independent component) and the additional information gain attainable by analyzing data as time-series (i.e., accounting for the information contained in data time-correlations). A second test case shows how the MInE approach is also highly effective for high-dimensional datasets, providing clear demonstrations of how, e.g., considering components/data that are little informative, but noisy, may be not only useless but even detrimental to maximum information extraction. This provides a general and robust parameter-free approach and quantitative metrics for data-analysis, and for the study of any type of system from its data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12990v3</guid>
      <category>physics.data-an</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Becchi (Politecnico di Torino, Dipartimento di Scienze Applicate e Tecnologia), Giovanni Maria Pavan (Politecnico di Torino, Dipartimento di Scienze Applicate e Tecnologia)</dc:creator>
    </item>
    <item>
      <title>Computing well-balanced spanning trees of unweighted networks</title>
      <link>https://arxiv.org/abs/2205.06628</link>
      <description>arXiv:2205.06628v2 Announce Type: replace-cross 
Abstract: A spanning tree of a network or graph is a subgraph that connects all nodes with the least number or weight of edges. The spanning tree is one of the most straightforward techniques for network simplification and sampling, and for discovering its backbone or skeleton. Prim's algorithm and Kruskal's algorithm are well-known algorithms for computing a spanning tree of a weighted network, and are therefore also the default procedure for unweighted networks in the most popular network libraries. In this paper, we empirically study the performance of these algorithms on unweighted networks and compare them with different priority-first search algorithms. We show that the structure of a network, such as the distances between the nodes, is better preserved by a simpler algorithm based on breadth-first search. The spanning trees are also most compact and well-balanced as measured by classical graph indices. We support our findings with experiments on synthetic graphs and more than a thousand real networks, and demonstrate practical applications of the computed spanning trees. We conclude that if a spanning tree is to maintain the structure of an unweighted network, the breadth-first search algorithm should be the preferred choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.06628v2</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lovro \v{S}ubelj</dc:creator>
    </item>
    <item>
      <title>ParquetDB: A Lightweight Python Parquet-Based Database</title>
      <link>https://arxiv.org/abs/2502.05311</link>
      <description>arXiv:2502.05311v2 Announce Type: replace-cross 
Abstract: Traditional data storage formats and databases often introduce complexities and inefficiencies that hinder rapid iteration and adaptability. To address these challenges, we introduce ParquetDB, a Python-based database framework that leverages the Parquet file format's optimized columnar storage. ParquetDB offers efficient serialization and deserialization, native support for complex and nested data types, reduced dependency on indexing through predicate pushdown filtering, and enhanced portability due to its file-based storage system. Benchmarks show that ParquetDB outperforms traditional databases like SQLite and MongoDB in managing large volumes of data, especially when using data formats compatible with PyArrow. We validate ParquetDB's practical utility by applying it to the Alexandria 3D Materials Database, efficiently handling approximately 4.8 million complex and nested records. By addressing the inherent limitations of existing data storage systems and continuously evolving to meet future demands, ParquetDB has the potential to significantly streamline data management processes and accelerate research development in data-driven fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05311v2</guid>
      <category>cs.DB</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Lang, Eduardo Hernandez, Kamal Choudhary, Aldo H. Romero</dc:creator>
    </item>
    <item>
      <title>Topological Time Frequency Analysis of Functional Brain Signals</title>
      <link>https://arxiv.org/abs/2502.05814</link>
      <description>arXiv:2502.05814v2 Announce Type: replace-cross 
Abstract: We present a novel topological framework for analyzing functional brain signals using time-frequency analysis. By integrating persistent homology with time-frequency representations, we capture multi-scale topological features that characterize the dynamic behavior of brain activity. This approach identifies 0D (connected components) and 1D (loops) topological structures in the signal's time-frequency domain, enabling robust extraction of features invariant to noise and temporal misalignments. The proposed method is demonstrated on resting-state functional magnetic resonance imaging (fMRI) data, showcasing its ability to discern critical topological patterns and provide insights into functional connectivity. This topological approach opens new avenues for analyzing complex brain signals, offering potential applications in neuroscience and clinical diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05814v2</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moo K. Chung, Aaron F. Struck</dc:creator>
    </item>
  </channel>
</rss>
