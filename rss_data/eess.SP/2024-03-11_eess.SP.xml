<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Clustering Interval Load with Weather to Create Scenarios of Behind-the-Meter Solar Penetration</title>
      <link>https://arxiv.org/abs/2403.05009</link>
      <description>arXiv:2403.05009v1 Announce Type: new 
Abstract: Forecasting load at the feeder level has become increasingly challenging with the penetration of behind-the-meter solar, as this self-generation (also called total generation) is only visible to the utility as aggregated net-load. This work proposes a methodology for creation of scenarios of solar penetration at the feeder level for use by forecasters to test the robustness of their algorithm to progressively higher penetrations of solar. The algorithm draws on publicly available observations of weather \emph{condition} (e.g., rainy/cloudy/fair) for use as proxies to sky clearness. These observations are used to mask and weight the interval deviations of similar native usage profiles from which average interval usage is calculated and subsequently added to interval net generation to reconstruct interval total generation. This approach improves the estimate of annual energy generation by 23\%; where the net generation signal currently only reflects 52\% of total annual generation, now 75\% is captured via the proposed algorithm. This proposed methodology is data driven and extensible to service territories which lack information on irradiance measurements and geo-coordinates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05009v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allison M. Campbell, Soumya Kundu, Andrew P. Reiman, Orestis Vasios, Ian Beil, Andy Eiden</dc:creator>
    </item>
    <item>
      <title>A Decoupled Approach for Composite Sparse-plus-Smooth Penalized Optimization</title>
      <link>https://arxiv.org/abs/2403.05204</link>
      <description>arXiv:2403.05204v1 Announce Type: new 
Abstract: We consider a linear inverse problem whose solution is expressed as a sum of two components, one of them being smooth while the other presents sparse properties. This problem is solved by minimizing an objective function with a least square data-fidelity term and a different regularization term applied to each of the components. Sparsity is promoted with a $\ell_1$ norm, while the other component is penalized by means of a $\ell_2$ norm. We characterize the solution set of this composite optimization problem by stating a Representer Theorem. Consequently, we identify that solving the optimization problem can be decoupled, first identifying the sparse solution as a solution of a modified single-variable problem, then deducing the smooth component. We illustrate that this decoupled solving method can lead to significant computational speedups in applications, considering the problem of Dirac recovery over a smooth background with two-dimensional partial Fourier measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05204v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adrian Jarret, Val\'erie Costa, Julien Fageot</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Problems with Model Mismatch using Untrained Neural Networks within Model-based Architectures</title>
      <link>https://arxiv.org/abs/2403.04847</link>
      <description>arXiv:2403.04847v1 Announce Type: cross 
Abstract: Model-based deep learning methods such as \emph{loop unrolling} (LU) and \emph{deep equilibrium model} (DEQ) extensions offer outstanding performance in solving inverse problems (IP). These methods unroll the optimization iterations into a sequence of neural networks that in effect learn a regularization function from data. While these architectures are currently state-of-the-art in numerous applications, their success heavily relies on the accuracy of the forward model. This assumption can be limiting in many physical applications due to model simplifications or uncertainties in the apparatus. To address forward model mismatch, we introduce an untrained forward model residual block within the model-based architecture to match the data consistency in the measurement domain for each instance. We propose two variants in well-known model-based architectures (LU and DEQ) and prove convergence under mild conditions. The experiments show significant quality improvement in removing artifacts and preserving details across three distinct applications, encompassing both linear and nonlinear inverse problems. Moreover, we highlight reconstruction effectiveness in intermediate steps and showcase robustness to random initialization of the residual block and a higher number of iterations during evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04847v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peimeng Guan, Naveed Iqbal, Mark A. Davenport, Mudassir Masood</dc:creator>
    </item>
    <item>
      <title>Near Field Communications for DMA-NOMA Networks</title>
      <link>https://arxiv.org/abs/2403.04925</link>
      <description>arXiv:2403.04925v1 Announce Type: cross 
Abstract: A novel near-field transmission framework is proposed for dynamic metasurface antenna (DMA)-enabled non-orthogonal multiple access (NOMA) networks. The base station (BS) exploits the hybrid beamforming to communicate with multiple near users (NUs) and far users (FUs) using the NOMA principle. Based on this framework, two novel beamforming schemes are proposed. 1) For the case of the grouped users distributed in the same direction, a beam-steering scheme is developed. The metric of beam pattern error (BPE) is introduced for the characterization of the gap between the hybrid beamformers and the desired ideal beamformers, where a two-layer algorithm is proposed to minimize BPE by optimizing hybrid beamformers. Then, the optimal power allocation strategy is obtained to maximize the sum achievable rate of the network. 2) For the case of users randomly distributed, a beam-splitting scheme is proposed, where two sub-beamformers are extracted from the single beamformer to serve different users in the same group. An alternating optimization (AO) algorithm is proposed for hybrid beamformer optimization, and the optimal power allocation is also derived. Numerical results validate that: 1) the proposed beamforming schemes exhibit superior performance compared with the existing imperfect-resolution-based beamforming scheme; 2) the communication rate of the proposed transmission framework is sensitive to the imperfect distance knowledge of NUs but not to that of FUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04925v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Zhang, Yuanwei Liu, Zhaolin Wang, Jian Chen, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>Electrocardiogram Instruction Tuning for Report Generation</title>
      <link>https://arxiv.org/abs/2403.04945</link>
      <description>arXiv:2403.04945v1 Announce Type: cross 
Abstract: Electrocardiogram (ECG) serves as the primary non-invasive diagnostic tool for cardiac conditions monitoring, are crucial in assisting clinicians. Recent studies have concentrated on classifying cardiac conditions using ECG data but have overlooked ECG report generation, which is not only time-consuming but also requires clinical expertise. To automate ECG report generation and ensure its versatility, we propose the Multimodal ECG Instruction Tuning (MEIT) framework, the \textit{first} attempt to tackle ECG report generation with LLMs and multimodal instructions. To facilitate future research, we establish a benchmark to evaluate MEIT with various LLMs backbones across two large-scale ECG datasets. Our approach uniquely aligns the representations of the ECG signal and the report, and we conduct extensive experiments to benchmark MEIT with nine open source LLMs, using more than 800,000 ECG reports. MEIT's results underscore the superior performance of instruction-tuned LLMs, showcasing their proficiency in quality report generation, zero-shot capabilities, and resilience to signal perturbation. These findings emphasize the efficacy of our MEIT framework and its potential for real-world clinical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04945v1</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongwei Wan, Che Liu, Xin Wang, Chaofan Tao, Hui Shen, Zhenwu Peng, Jie Fu, Rossella Arcucci, Huaxiu Yao, Mi Zhang</dc:creator>
    </item>
    <item>
      <title>Lightator: An Optical Near-Sensor Accelerator with Compressive Acquisition Enabling Versatile Image Processing</title>
      <link>https://arxiv.org/abs/2403.05037</link>
      <description>arXiv:2403.05037v1 Announce Type: cross 
Abstract: This paper proposes a high-performance and energy-efficient optical near-sensor accelerator for vision applications, called Lightator. Harnessing the promising efficiency offered by photonic devices, Lightator features innovative compressive acquisition of input frames and fine-grained convolution operations for low-power and versatile image processing at the edge for the first time. This will substantially diminish the energy consumption and latency of conversion, transmission, and processing within the established cloud-centric architecture as well as recently designed edge accelerators. Our device-to-architecture simulation results show that with favorable accuracy, Lightator achieves 84.4 Kilo FPS/W and reduces power consumption by a factor of ~24x and 73x on average compared with existing photonic accelerators and GPU baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05037v1</guid>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mehrdad Morsali, Brendan Reidy, Deniz Najafi, Sepehr Tabrizchi, Mohsen Imani, Mahdi Nikdast, Arman Roohi, Ramtin Zand, Shaahin Angizi</dc:creator>
    </item>
    <item>
      <title>User Connection and Resource Allocation Optimization in Blockchain Empowered Metaverse over 6G Wireless Communications</title>
      <link>https://arxiv.org/abs/2403.05116</link>
      <description>arXiv:2403.05116v1 Announce Type: cross 
Abstract: The convergence of blockchain, Metaverse, and non-fungible tokens (NFTs) brings transformative digital opportunities alongside challenges like privacy and resource management. Addressing these, we focus on optimizing user connectivity and resource allocation in an NFT-centric and blockchain-enabled Metaverse in this paper. Through user work-offloading, we optimize data tasks, user connection parameters, and server computing frequency division. In the resource allocation phase, we optimize communication-computation resource distributions, including bandwidth, transmit power, and computing frequency. We introduce the trust-cost ratio (TCR), a pivotal measure combining trust scores from users' resources and server history with delay and energy costs. This balance ensures sustained user engagement and trust. The DASHF algorithm, central to our approach, encapsulates the Dinkelbach algorithm, alternating optimization, semidefinite relaxation (SDR), the Hungarian method, and a novel fractional programming technique from a recent IEEE JSAC paper [2]. The most challenging part of DASHF is to rewrite an optimization problem as Quadratically Constrained Quadratic Programming (QCQP) via carefully designed transformations, in order to be solved by SDR and the Hungarian algorithm. Extensive simulations validate the DASHF algorithm's efficacy, revealing critical insights for enhancing blockchain-Metaverse applications, especially with NFTs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05116v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liangxin Qian, Chang Liu, Jun Zhao</dc:creator>
    </item>
    <item>
      <title>DeRO: Dead Reckoning Based on Radar Odometry With Accelerometers Aided for Robot Localization</title>
      <link>https://arxiv.org/abs/2403.05136</link>
      <description>arXiv:2403.05136v1 Announce Type: cross 
Abstract: In this paper, we propose a radar odometry structure that directly utilizes radar velocity measurements for dead reckoning while maintaining its ability to update estimations within the Kalman filter framework. Specifically, we employ the Doppler velocity obtained by a 4D Frequency Modulated Continuous Wave (FMCW) radar in conjunction with gyroscope data to calculate poses. This approach helps mitigate high drift resulting from accelerometer biases and double integration. Instead, tilt angles measured by gravitational force are utilized alongside relative distance measurements from radar scan matching for the filter's measurement update. Additionally, to further enhance the system's accuracy, we estimate and compensate for the radar velocity scale factor. The performance of the proposed method is verified through five real-world open-source datasets. The results demonstrate that our approach reduces position error by 47% and rotation error by 52% on average compared to the state-of-the-art radar-inertial fusion method in terms of absolute trajectory error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05136v1</guid>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoang Viet Do, Yong Hun Kim, Joo Han Lee, Min Ho Lee, Jin Woo Song</dc:creator>
    </item>
    <item>
      <title>Sparse Wearable Sonomyography Sensor-based Proprioceptive Proportional Control Across Multiple Gestures</title>
      <link>https://arxiv.org/abs/2403.05308</link>
      <description>arXiv:2403.05308v1 Announce Type: cross 
Abstract: Sonomyography (SMG) is a non-invasive technique that uses ultrasound imaging to detect the dynamic activity of muscles. Wearable SMG systems have recently gained popularity due to their potential as human-computer interfaces for their superior performance compared to conventional methods. This paper demonstrates real-time positional proportional control of multiple gestures using a multiplexed 8-channel wearable SMG system. The amplitude-mode ultrasound signals from the SMG system were utilized to detect muscle activity from the forearm of 8 healthy individuals. The derived signals were used to control the on-screen movement of the cursor. A target achievement task was performed to analyze the performance of our SMG-based human-machine interface. Our wearable SMG system provided accurate, stable, and intuitive control in real-time by achieving an average success rate greater than 80% with all gestures. Furthermore, the wearable SMG system's abilities to detect volitional movement and decode movement kinematic information from SMG trajectories using standard performance metrics were evaluated. Our results provide insights to validate SMG as an intuitive human-machine interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05308v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anne Tryphosa Kamatham, Kavita Sharma, Srikumar Venkataraman, Biswarup Mukherjee</dc:creator>
    </item>
    <item>
      <title>GAN-based Massive MIMO Channel Model Trained on Measured Data</title>
      <link>https://arxiv.org/abs/2403.05321</link>
      <description>arXiv:2403.05321v1 Announce Type: cross 
Abstract: Wireless channel models are a commonly used tool for the development of wireless telecommunication systems and standards. The currently prevailing geometry-based stochastic channel models (GSCMs) were manually specified for certain environments in a manual process requiring extensive domain knowledge, on the basis of channel measurement campaigns. By taking into account the stochastic distribution of certain channel properties like Rician k-factor, path loss or delay spread, they model the distribution of channel realizations. Instead of this manual process, a generative machine learning model like a generative adversarial network (GAN) may be used to automatically learn the distribution of channel statistics. Subsequently, the GAN's generator may be viewed as a channel model that can replace conventional stochastic or raytracer-based models. We propose a GAN architecture for a massive MIMO channel model, and train it on measurement data produced by a distributed massive MIMO channel sounder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05321v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian Euchner, Janina Sanzi, Marcus Henninger, Stephan ten Brink</dc:creator>
    </item>
    <item>
      <title>Degradation Resilient LiDAR-Radar-Inertial Odometry</title>
      <link>https://arxiv.org/abs/2403.05332</link>
      <description>arXiv:2403.05332v1 Announce Type: cross 
Abstract: Enabling autonomous robots to operate robustly in challenging environments is necessary in a future with increased autonomy. For many autonomous systems, estimation and odometry remains a single point of failure, from which it can often be difficult, if not impossible, to recover. As such robust odometry solutions are of key importance. In this work a method for tightly-coupled LiDAR-Radar-Inertial fusion for odometry is proposed, enabling the mitigation of the effects of LiDAR degeneracy by leveraging a complementary perception modality while preserving the accuracy of LiDAR in well-conditioned environments. The proposed approach combines modalities in a factor graph-based windowed smoother with sensor information-specific factor formulations which enable, in the case of degeneracy, partial information to be conveyed to the graph along the non-degenerate axes. The proposed method is evaluated in real-world tests on a flying robot experiencing degraded conditions including geometric self-similarity as well as obscurant occlusion. For the benefit of the community we release the datasets presented: https://github.com/ntnu-arl/lidar_degeneracy_datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05332v1</guid>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morten Nissov, Nikhil Khedekar, Kostas Alexis</dc:creator>
    </item>
    <item>
      <title>OmniCount: Multi-label Object Counting with Semantic-Geometric Priors</title>
      <link>https://arxiv.org/abs/2403.05435</link>
      <description>arXiv:2403.05435v1 Announce Type: cross 
Abstract: Object counting is pivotal for understanding the composition of scenes. Previously, this task was dominated by class-specific methods, which have gradually evolved into more adaptable class-agnostic strategies. However, these strategies come with their own set of limitations, such as the need for manual exemplar input and multiple passes for multiple categories, resulting in significant inefficiencies. This paper introduces a new, more practical approach enabling simultaneous counting of multiple object categories using an open vocabulary framework. Our solution, OmniCount, stands out by using semantic and geometric insights from pre-trained models to count multiple categories of objects as specified by users, all without additional training. OmniCount distinguishes itself by generating precise object masks and leveraging point prompts via the Segment Anything Model for efficient counting. To evaluate OmniCount, we created the OmniCount-191 benchmark, a first-of-its-kind dataset with multi-label object counts, including points, bounding boxes, and VQA annotations. Our comprehensive evaluation in OmniCount-191, alongside other leading benchmarks, demonstrates OmniCount's exceptional performance, significantly outpacing existing solutions and heralding a new era in object counting technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05435v1</guid>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anindya Mondal, Sauradip Nag, Xiatian Zhu, Anjan Dutta</dc:creator>
    </item>
    <item>
      <title>Blind Source Separation of Single-Channel Mixtures via Multi-Encoder Autoencoders</title>
      <link>https://arxiv.org/abs/2309.07138</link>
      <description>arXiv:2309.07138v3 Announce Type: replace 
Abstract: The task of blind source separation (BSS) involves separating sources from a mixture without prior knowledge of the sources or the mixing system. Single-channel mixtures and non-linear mixtures are a particularly challenging problem in BSS. In this paper, we propose a novel method for addressing BSS with single-channel non-linear mixtures by leveraging the natural feature subspace specialization ability of multi-encoder autoencoders. During the training phase, our method unmixes the input into the separate encoding spaces of the multi-encoder network and then remixes these representations within the decoder for a reconstruction of the input. Then to perform source inference, we introduce a novel encoding masking technique whereby masking out all but one of the encodings enables the decoder to estimate a source signal. To this end, we also introduce a sparse mixing loss that encourages sparse remixing of source encodings throughout the decoder and a so-called zero reconstruction loss on the decoder for coherent source estimations. To analyze and evaluate our method, we conduct experiments on a toy dataset, designed to demonstrate this property of feature subspace specialization, and with real-world biosignal recordings from a polysomnography sleep study for extracting respiration from electrocardiogram and photoplethysmography signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07138v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Matthew B. Webster, Joonnyong Lee</dc:creator>
    </item>
    <item>
      <title>Explainable Gated Bayesian Recurrent Neural Network for Non-Markov State Estimation</title>
      <link>https://arxiv.org/abs/2310.17187</link>
      <description>arXiv:2310.17187v2 Announce Type: replace 
Abstract: The optimality of Bayesian filtering relies on the completeness of prior models, while deep learning holds a distinct advantage in learning models from offline data. Nevertheless, the current fusion of these two methodologies remains largely ad hoc, lacking a theoretical foundation. This paper presents a novel solution, namely an explainable gated Bayesian recurrent neural network specifically designed to state estimation under model mismatches. Firstly, we transform the non-Markov state-space model into an equivalent first-order Markov model with memory. It is a generalized transformation that overcomes the limitations of the first-order Markov property and enables recursive filtering. Secondly, by deriving a data-assisted joint state-memory-mismatch Bayesian filtering, we design a Bayesian gated framework that includes a memory update gate for capturing the temporal regularities in state evolution, a state prediction gate with the evolution mismatch compensation, and a state update gate with the observation mismatch compensation. The Gaussian approximation implementation of the filtering process within the gated framework is derived, taking into account the computational efficiency. Finally, the corresponding internal neural network structures and end-to-end training methods are designed. The Bayesian filtering theory enhances the interpretability of the proposed gated network, enabling the effective integration of offline data and prior models within functionally explicit gated units. In comprehensive experiments, including simulations and real-world datasets, the proposed gated network demonstrates superior estimation performance compared to benchmark filters and state-of-the-art deep learning filtering methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17187v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shi Yan, Yan Liang, Le Zheng, Mingyang Fan, Xiaoxu Wang, Binglu Wang</dc:creator>
    </item>
    <item>
      <title>Bistatic Reflectivity and Micro-Doppler Signatures of Drones for Integrated Communication and Sensing</title>
      <link>https://arxiv.org/abs/2401.14448</link>
      <description>arXiv:2401.14448v2 Announce Type: replace 
Abstract: The integration of wireless communication and radar sensing is gaining the interest of researchers from wireless communication and radar societies. Sensing in Integrated Communication and Sensing (ICAS) systems differs from the traditional radar system in the configuration of transmitter-target-receiver, the operating frequency bands, and the transmitting waveform. It is necessary to understand how target electromagnetic signatures behave in this context. Therefore, this paper presents measurements and analysis of two important target signatures, reflectivity and micro-Doppler, for sensing in ICAS. These target signatures are measured in the state-of-the-art measurement system, Bistatische-Radar-Messeinrichtung (BiRa).</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14448v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heraldo Cesar Alves Costa, Saw James Myint, Carsten Andrich, Sebastian W. Giehl, Christian Schneider, Reiner S. Thom\"a</dc:creator>
    </item>
    <item>
      <title>SzCORE: A Seizure Community Open-source Research Evaluation framework for the validation of EEG-based automated seizure detection algorithms</title>
      <link>https://arxiv.org/abs/2402.13005</link>
      <description>arXiv:2402.13005v3 Announce Type: replace 
Abstract: The need for high-quality automated seizure detection algorithms based on electroencephalography (EEG) becomes ever more pressing with the increasing use of ambulatory and long-term EEG monitoring. Heterogeneity in validation methods of these algorithms influences the reported results and makes comprehensive evaluation and comparison challenging. This heterogeneity concerns in particular the choice of datasets, evaluation methodologies, and performance metrics. In this paper, we propose a unified framework designed to establish standardization in the validation of EEG-based seizure detection algorithms. Based on existing guidelines and recommendations, the framework introduces a set of recommendations and standards related to datasets, file formats, EEG data input content, seizure annotation input and output, cross-validation strategies, and performance metrics. We also propose the 10-20 seizure detection benchmark, a machine-learning benchmark based on public datasets converted to a standardized format. This benchmark defines the machine-learning task as well as reporting metrics. We illustrate the use of the benchmark by evaluating a set of existing seizure detection algorithms. The SzCORE (Seizure Community Open-source Research Evaluation) framework and benchmark are made publicly available along with an open-source software library to facilitate research use, while enabling rigorous evaluation of the clinical significance of the algorithms, fostering a collective effort to more optimally detect seizures to improve the lives of people with epilepsy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13005v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Dan, Una Pale, Alireza Amirshahi, William Cappelletti, Thorir Mar Ingolfsson, Xiaying Wang, Andrea Cossettini, Adriano Bernini, Luca Benini, S\'andor Beniczky, David Atienza, Philippe Ryvlin</dc:creator>
    </item>
    <item>
      <title>Multistatic-Radar RCS-Signature Recognition of Aerial Vehicles: A Bayesian Fusion Approach</title>
      <link>https://arxiv.org/abs/2402.17987</link>
      <description>arXiv:2402.17987v2 Announce Type: replace 
Abstract: Radar Automated Target Recognition (RATR) for Unmanned Aerial Vehicles (UAVs) involves transmitting Electromagnetic Waves (EMWs) and performing target type recognition on the received radar echo, crucial for defense and aerospace applications. Previous studies highlighted the advantages of multistatic radar configurations over monostatic ones in RATR. However, fusion methods in multistatic radar configurations often suboptimally combine classification vectors from individual radars probabilistically. To address this, we propose a fully Bayesian RATR framework employing Optimal Bayesian Fusion (OBF) to aggregate classification probability vectors from multiple radars. OBF, based on expected 0-1 loss, updates a Recursive Bayesian Classification (RBC) posterior distribution for target UAV type, conditioned on historical observations across multiple time steps. We evaluate the approach using simulated random walk trajectories for seven drones, correlating target aspect angles to Radar Cross Section (RCS) measurements in an anechoic chamber. Comparing against single radar Automated Target Recognition (ATR) systems and suboptimal fusion methods, our empirical results demonstrate that the OBF method integrated with RBC significantly enhances classification accuracy compared to other fusion methods and single radar configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17987v2</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Potter, Murat Akcakaya, Marius Necsoiu, Gunar Schirner, Deniz Erdogmus, Tales Imbiriba</dc:creator>
    </item>
    <item>
      <title>Near Field Computational Imaging with RIS Generated Virtual Masks</title>
      <link>https://arxiv.org/abs/2304.11510</link>
      <description>arXiv:2304.11510v2 Announce Type: replace-cross 
Abstract: Near field computational imaging has been recognized as a promising technique for non-destructive and highly accurate detection of the target. Meanwhile, reconfigurable intelligent surface (RIS) can flexibly control the scattered electromagnetic (EM) fields for sensing the target and can thus help computational imaging in the near field. In this paper, we propose a near-field imaging scheme based on holograghic aperture RIS. Specifically, we first establish an end-to-end EM propagation model from the perspective of Maxwell equations. To mitigate the inherent ill conditioning of the inverse problem in the imaging system, we design the EM field patterns as masks that help translate the inverse problem into a forward problem. Next, we utilize RIS to generate different virtual EM masks on the target surface and calculate the cross-correlation between the mask patterns and the electric field strength at the receiver. We then provide a RIS design scheme for virtual EM masks by employing a regularization technique. The cross-range resolution of the proposed method is analyzed based on the spatial spectrum of the generated masks. Simulation results demonstrate that the proposed method can achieve high-quality imaging. Moreover, the imaging quality can be improved by generating more virtual EM masks, by increasing the signal-to-noise ratio (SNR) at the receiver, or by placing the target closer to the RIS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.11510v2</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhua Jiang, Feifei Gao, Yimin Liu, Shi Jin, Tiejun Cui</dc:creator>
    </item>
    <item>
      <title>User Association and Resource Allocation in Large Language Model Based Mobile Edge Computing System over 6G Wireless Communications</title>
      <link>https://arxiv.org/abs/2310.17872</link>
      <description>arXiv:2310.17872v3 Announce Type: replace-cross 
Abstract: In the rapidly evolving landscape of large language models (LLMs) and mobile edge computing for 6G, the need for efficient service delivery to mobile users with constrained computational resources has become paramount. Addressing this, our paper delves into a collaborative framework for model training where user data and model adapters are shared with servers to optimize performance. Within this framework, users initially update the first several layers of the adapters while freezing the other layers of them, leveraging their local datasets. Once this step is complete, these partially trained parameters are transmitted to servers. The servers, equipped with more robust computational capabilities, then update the subsequent layers. After this training, they send the enhanced parameters back to the users. This collaborative training approach ensures that mobile users with limited computational capacities can still benefit from advanced LLM services without being burdened by exhaustive computations. Central to our methodology is the DASHF algorithm, which encapsulates the Dinkelbach algorithm, alternating optimization, semidefinite relaxation (SDR), the Hungarian method, and a pioneering fractional programming technique from a recent IEEE JSAC paper [1]. The crux of DASHF is its capability to reformulate an optimization problem as Quadratically Constrained Quadratic Programming (QCQP) via meticulously crafted transformations, making it solvable by SDR and the Hungarian algorithm. Through extensive simulations, we demonstrate the effectiveness of the DASHF algorithm, offering significant insights for the advancement of collaborative LLM service deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17872v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liangxin Qian, Jun Zhao</dc:creator>
    </item>
    <item>
      <title>Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2310.18882</link>
      <description>arXiv:2310.18882v2 Announce Type: replace-cross 
Abstract: This paper investigates efficient deep neural networks (DNNs) to replace dense unstructured weight matrices with structured ones that possess desired properties. The challenge arises because the optimal weight matrix structure in popular neural network models is obscure in most cases and may vary from layer to layer even in the same network. Prior structured matrices proposed for efficient DNNs were mostly hand-crafted without a generalized framework to systematically learn them. To address this issue, we propose a generalized and differentiable framework to learn efficient structures of weight matrices by gradient descent. We first define a new class of structured matrices that covers a wide range of structured matrices in the literature by adjusting the structural parameters. Then, the frequency-domain differentiable parameterization scheme based on the Gaussian-Dirichlet kernel is adopted to learn the structural parameters by proximal gradient descent. On the image and language tasks, our method learns efficient DNNs with structured matrices, achieving lower complexity and/or higher performance than prior approaches that employ low-rank, block-sparse, or block-low-rank matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18882v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changwoo Lee, Hun-Seok Kim</dc:creator>
    </item>
    <item>
      <title>Eigenmatrix for unstructured sparse recovery</title>
      <link>https://arxiv.org/abs/2311.16609</link>
      <description>arXiv:2311.16609v4 Announce Type: replace-cross 
Abstract: This note considers the unstructured sparse recovery problems in a general form. Examples include rational approximation, spectral function estimation, Fourier inversion, Laplace inversion, and sparse deconvolution. The main challenges are the noise in the sample values and the unstructured nature of the sample locations. This note proposes the eigenmatrix, a data-driven construction with desired approximate eigenvalues and eigenvectors. The eigenmatrix offers a new way for these sparse recovery problems. Numerical results are provided to demonstrate the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16609v4</guid>
      <category>math.NA</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lexing Ying</dc:creator>
    </item>
  </channel>
</rss>
