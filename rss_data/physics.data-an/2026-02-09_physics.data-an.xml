<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Feb 2026 05:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Relativity of Observation: Operational Intensive Variables in Nonequilibrium Thermodynamics</title>
      <link>https://arxiv.org/abs/2602.06455</link>
      <description>arXiv:2602.06455v1 Announce Type: cross 
Abstract: We formulate nonequilibrium thermodynamics in which intensive variables acquire operational meaning through measurement protocols consistent with local reciprocity. Using physical equilibrium as a reference, conjugate observables are constructed by continuously adjusting devices along the local tangent space of the statistical manifold. In this relativity of observation, Onsager reciprocity holds locally, allowing inference-based Lagrange multipliers to be directly measured. This provides a systematic method to extend operational definitions of intensive variables to nonequilibrium states, highlighting their context-dependent nature and offering a concrete experimental strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06455v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akihisa Ichiki</dc:creator>
    </item>
    <item>
      <title>Disentanglement by means of action-induced representations</title>
      <link>https://arxiv.org/abs/2602.06741</link>
      <description>arXiv:2602.06741v1 Announce Type: cross 
Abstract: Learning interpretable representations with variational autoencoders (VAEs) is a major goal of representation learning. The main challenge lies in obtaining disentangled representations, where each latent dimension corresponds to a distinct generative factor. This difficulty is fundamentally tied to the inability to perform nonlinear independent component analysis. Here, we introduce the framework of action-induced representations (AIRs) which models representations of physical systems given experiments (or actions) that can be performed on them. We show that, in this framework, we can provably disentangle degrees of freedom w.r.t. their action dependence. We further introduce a variational AIR architecture (VAIR) that can extract AIRs and therefore achieve provable disentanglement where standard VAEs fail. Beyond state representation, VAIR also captures the action dependence of the underlying generative factors, directly linking experiments to the degrees of freedom they influence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06741v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>quant-ph</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gorka Mu\~noz-Gil, Hendrik Poulsen Nautrup, Arunava Majumder, Paulin de Schoulepnikoff, Florian F\"urrutter, Marius Krumm, Hans J. Briegel</dc:creator>
    </item>
    <item>
      <title>Breakthrough Asymmetries across Disciplines and Countries: A Network approach to Structural Complexity of Scientific Progress</title>
      <link>https://arxiv.org/abs/2506.18804</link>
      <description>arXiv:2506.18804v3 Announce Type: replace-cross 
Abstract: Science is driven by community endeavors across diverse fields and specializations, forming a complex structure that renders conventional performance evaluation methods inadequate. Using established indicators, the network-based normalized citation score, and the disruptive index, combined with the GENEPY algorithm, we evaluate the complexity rank of countries based on their breakthrough performance across 89 subfields of physical sciences, drawing on nearly 60 million articles (1900-2023). This quality-focused integrated approach reveals pronounced asymmetries: while countries such as the United States, Israel, and several in Europe sustain long-term structural advantages, emerging nations show rapid gains in later decades. A power-law relationship between aggregated breakthrough performance and countries' R&amp;D expenditure underscores the unequal and scale-dependent nature of global science. These results demonstrate that scientific advancement arises not from uniform growth but from asymmetric complexity, offering actionable insights for policymakers and funding agencies aiming to foster sustainable, high-quality research ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18804v3</guid>
      <category>cs.DL</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adarsh Raghuvanshi, Hrishidev Unni,  Vinayak, Anirban Chakraborti</dc:creator>
    </item>
    <item>
      <title>Learnability Window in Gated Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2512.05790</link>
      <description>arXiv:2512.05790v4 Announce Type: replace-cross 
Abstract: We develop a theoretical framework that explains how gating mechanisms determine the learnability window $\mathcal{H}_N$ of recurrent neural networks, defined as the largest temporal horizon over which gradient information remains statistically recoverable. While classical analyses emphasize numerical stability of Jacobian products, we show that stability alone is insufficient: learnability is governed instead by the effective learning rates $\mu_{t,\ell}$, per-lag and per-neuron quantities obtained from first-order expansions of gate-induced Jacobian products in Backpropagation Through Time. These effective learning rates act as multiplicative filters that control both the magnitude and anisotropy of gradient transport. Under heavy-tailed ($\alpha$-stable) gradient noise, we prove that the minimal sample size required to detect a dependency at lag~$\ell$ scales as $N(\ell)\propto f(\ell)^{-\kappa_\alpha}$, where $f(\ell)=\|\mu_{t,\ell}\|_1$ is the effective learning rate envelope and $\kappa_\alpha=\alpha/(\alpha-1)$ is the concentration exponent governing empirical averages. This yields an explicit characterization of $\mathcal{H}_N$ and closed-form scaling laws for logarithmic, polynomial, and exponential decay of $f(\ell)$. The theory shows that the time-scale spectra induced by the effective learning rates are the dominant determinants of learnability: broader or more heterogeneous spectra slow the decay of $f(\ell)$, enlarging the learnability window, while heavy-tailed noise uniformly compresses $\mathcal{H}_N$ by slowing statistical concentration to $N^{-1/\kappa_{\alpha}}$. By integrating gate-induced time-scale geometry with gradient noise and sample complexity, the framework identifies effective learning rates as the primary objects that determine whether, when, and over what horizons recurrent networks can learn long-range temporal dependencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05790v4</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 09 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Livi</dc:creator>
    </item>
  </channel>
</rss>
