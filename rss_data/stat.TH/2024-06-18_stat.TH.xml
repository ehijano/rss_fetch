<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jun 2024 01:59:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Fine-grained Analysis of Fitted Q-evaluation: Beyond Parametric Models</title>
      <link>https://arxiv.org/abs/2406.10438</link>
      <description>arXiv:2406.10438v1 Announce Type: new 
Abstract: In this paper, we delve into the statistical analysis of the fitted Q-evaluation (FQE) method, which focuses on estimating the value of a target policy using offline data generated by some behavior policy. We provide a comprehensive theoretical understanding of FQE estimators under both parameteric and nonparametric models on the $Q$-function. Specifically, we address three key questions related to FQE that remain largely unexplored in the current literature: (1) Is the optimal convergence rate for estimating the policy value regarding the sample size $n$ ($n^{-1/2}$) achievable for FQE under a non-parametric model with a fixed horizon ($T$)? (2) How does the error bound depend on the horizon $T$? (3) What is the role of the probability ratio function in improving the convergence of FQE estimators? Specifically, we show that under the completeness assumption of $Q$-functions, which is mild in the non-parametric setting, the estimation errors for policy value using both parametric and non-parametric FQE estimators can achieve an optimal rate in terms of $n$. The corresponding error bounds in terms of both $n$ and $T$ are also established. With an additional realizability assumption on ratio functions, the rate of estimation errors can be improved from $T^{1.5}/\sqrt{n}$ to $T/\sqrt{n}$, which matches the sharpest known bound in the current literature under the tabular setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10438v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Wang, Zhengling Qi, Raymond K. W. Wong</dc:creator>
    </item>
    <item>
      <title>Some theoretical foundations for the design and analysis of randomized experiments</title>
      <link>https://arxiv.org/abs/2406.10444</link>
      <description>arXiv:2406.10444v1 Announce Type: new 
Abstract: Neyman[106]'s seminal work in 1923 has been a milestone in statistics over the century, which has motivated many fundamental statistical concepts and methodology. In this review, we delve into Neyman[106]'s groundbreaking contribution and offer technical insights into the design and analysis of randomized experiments. We shall review the basic setup of completely randomized experiments and the classical approaches for inferring the average treatment effects. We shall in particular review more efficient design and analysis of randomized experiments by utilizing pretreatment covariates, which move beyond Neyman's original work without involving any covariate. We then summarize several technical ingredients regarding randomizations and permutations that have been developed over the century, such as permutational central limit theorems and Berry-Esseen bounds, and elaborate on how these technical results facilitate the understanding of randomized experiments. The discussion is also extended to other randomized experiments including rerandomization, stratified randomized experiments, matched pair experiments, cluster randomized experiments, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10444v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lei Shi, Xinran Li</dc:creator>
    </item>
    <item>
      <title>The skew-symmetric-Laplace-uniform distribution</title>
      <link>https://arxiv.org/abs/2406.10805</link>
      <description>arXiv:2406.10805v1 Announce Type: new 
Abstract: Laplace distribution is popular in the field of economics and finance. Still, data sets often show a lack of symmetry and a tendency of being bounded from either side of their support. In view of this, we introduce a new family of skew distribution using the skewing mechanism of Azzalini (1985), namely, skew-symmetric-Laplace-uniform distribution (SSLUD). Here uniform distribution is used not only to introduce skewness in Laplace distribution but also to restrict distribution support on one side of the real line. This paper provides a comprehensive description of the essential distributional properties of SSLUD. Estimators of the parameter are obtained using the method of moments and the method of maximum likelihood. The finite sample and asymptotic properties of these estimators are studied using simulation. It is observed that the maximum likelihood estimator is better than the moment estimator through a simulation study. Finally, an application of SSLUD to real-life data on the daily percentage change in the price of NIFTY 50, an Indian stock market index, is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10805v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Raju. K. Lohot, V. U. Dixit</dc:creator>
    </item>
    <item>
      <title>Asymptotic properties of a multicolored random reinforced urn model with an application to multi-armed bandits</title>
      <link>https://arxiv.org/abs/2406.10854</link>
      <description>arXiv:2406.10854v1 Announce Type: new 
Abstract: The random self-reinforcement mechanism, characterized by the principle of ``the rich get richer'', has demonstrated significant utility across various domains. One prominent model embodying this mechanism is the random reinforcement urn model. This paper investigates a multicolored, multiple-drawing variant of the random reinforced urn model. We establish the limiting behavior of the normalized urn composition and demonstrate strong convergence upon scaling the counts of each color. Additionally, we derive strong convergence estimators for the reinforcement means, i.e., for the expectations of the replacement matrix's diagonal elements, and prove their joint asymptotic normality. It is noteworthy that the estimators of the largest reinforcement mean are asymptotically independent of the estimators of the other smaller reinforcement means. Additionally, if a reinforcement mean is not the largest, the estimators of these smaller reinforcement means will also demonstrate asymptotic independence among themselves. Furthermore, we explore the parallels between the reinforced mechanisms in random reinforced urn models and multi-armed bandits, addressing hypothesis testing for expected payoffs in the latter context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10854v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Yang, Jiang Hu, Jianghao Li, Zhidong Bai</dc:creator>
    </item>
    <item>
      <title>Limit Results for Estimation of Connectivity Matrix in Multi-layer Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2406.11152</link>
      <description>arXiv:2406.11152v1 Announce Type: new 
Abstract: Multi-layer networks arise naturally in various domains including biology, finance and sociology, among others. The multi-layer stochastic block model (multi-layer SBM) is commonly used for community detection in the multi-layer networks. Most of current literature focuses on statistical consistency of community detection methods under multi-layer SBMs. However, the asymptotic distributional properties are also indispensable which play an important role in statistical inference. In this work, we aim to study the estimation and asymptotic properties of the layer-wise scaled connectivity matrices in the multi-layer SBMs. We develop a novel and efficient method to estimate the scaled connectivity matrices. Under the multi-layer SBM and its variant multi-layer degree-corrected SBM, we establish the asymptotic normality of the estimated matrices under mild conditions, which can be used for interval estimation and hypothesis testing. Simulations show the superior performance of proposed method over existing methods in two considered statistical inference tasks. We also apply the method to a real dataset and obtain interpretable results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11152v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Su, Xiao Guo, Ying Yang</dc:creator>
    </item>
    <item>
      <title>Ergodic Estimation and Model Assessment for Dynamic Exceedance Times</title>
      <link>https://arxiv.org/abs/2406.11347</link>
      <description>arXiv:2406.11347v1 Announce Type: new 
Abstract: This article concerns the estimation of hitting time statistics for potentially non-stationary processes. The main focus is exceedance times of environmental processes.
  To this end we consider an empirical estimator based on ergodic theory under the assumption that the considered process is a deterministic transformation of some ergodic process. This estimator is empirically analysed and rigorous convergence results, including a central limit theorem, are covered.
  Using our estimator, we compute confidence intervals for mean exceedance times of empirical wind data. This serves as a baseline for assessing the performance of several models in terms of predicted mean exceedance time. Special attention is given to the model class known as Gaussian copula processes, which models the environmental process as a deterministic, possibly time-dependent, transformation of a stationary parent Gaussian process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11347v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>{\AA}smund Hausken Sande</dc:creator>
    </item>
    <item>
      <title>Bayesian composite confidence interval for the tail index under randomly right-censored data</title>
      <link>https://arxiv.org/abs/2406.11484</link>
      <description>arXiv:2406.11484v1 Announce Type: new 
Abstract: Bayesian composite likelihood estimation of the tail index of a heavy-tailed distribution is addressed when data are randomly right-censored. Maximum a posteriori and mean posterior estimators are constructed under Jeffrey's prior distribution of the tail index. Based on asymptotic results, some confidence regions (CR) for the tail index are constructed using posterior distribution and log-posterior ratio statistic. The proposed confidence regions are investigated via Finite-sample simulations. Finally, the proposed confidence regions are outperformed through two real datasets</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11484v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdelkader Ameraoui (INSA), Jean-Fran\c{c}ois Dupuy (INSA), Kamal Boukhetala (USTHB)</dc:creator>
    </item>
    <item>
      <title>ROTI-GCV: Generalized Cross-Validation for right-ROTationally Invariant Data</title>
      <link>https://arxiv.org/abs/2406.11666</link>
      <description>arXiv:2406.11666v1 Announce Type: new 
Abstract: Two key tasks in high-dimensional regularized regression are tuning the regularization strength for good predictions and estimating the out-of-sample risk. It is known that the standard approach -- $k$-fold cross-validation -- is inconsistent in modern high-dimensional settings. While leave-one-out and generalized cross-validation remain consistent in some high-dimensional cases, they become inconsistent when samples are dependent or contain heavy-tailed covariates. To model structured sample dependence and heavy tails, we use right-rotationally invariant covariate distributions - a crucial concept from compressed sensing. In the common modern proportional asymptotics regime where the number of features and samples grow comparably, we introduce a new framework, ROTI-GCV, for reliably performing cross-validation. Along the way, we propose new estimators for the signal-to-noise ratio and noise variance under these challenging conditions. We conduct extensive experiments that demonstrate the power of our approach and its superiority over existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11666v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Luo, Yufan Li, Pragya Sur</dc:creator>
    </item>
    <item>
      <title>Review and Prospect of Algebraic Research in Equivalent Framework between Statistical Mechanics and Machine Learning Theory</title>
      <link>https://arxiv.org/abs/2406.10234</link>
      <description>arXiv:2406.10234v2 Announce Type: cross 
Abstract: Mathematical equivalence between statistical mechanics and machine learning theory has been known since the 20th century, and researches based on such equivalence have provided novel methodology in both theoretical physics and statistical learning theory. For example, algebraic approach in statistical mechanics such as operator algebra enables us to analyze phase transition phenomena mathematically. In this paper, for theoretical physicists who are interested in artificial intelligence, we review and prospect algebraic researches in machine learning theory. If a learning machine has hierarchical structure or latent variables, then the random Hamiltonian cannot be expressed by any quadratic perturbation because it has singularities. To study an equilibrium state defined by such a singular random Hamiltonian, algebraic approach is necessary to derive asymptotic form of the free energy and the generalization error. We also introduce the most recent advance, in fact, theoretical foundation for alignment of artificial intelligence is now being constructed based on algebraic learning theory. This paper is devoted to the memory of Professor Huzihiro Araki who is a pioneer founder of algebraic research in both statistical mechanics and quantum field theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10234v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumio Watanabe</dc:creator>
    </item>
    <item>
      <title>Generalized FGM dependence: Geometrical representation and convex bounds on sums</title>
      <link>https://arxiv.org/abs/2406.10648</link>
      <description>arXiv:2406.10648v1 Announce Type: cross 
Abstract: Building on the one-to-one relationship between generalized FGM copulas and multivariate Bernoulli distributions, we prove that the class of multivariate distributions with generalized FGM copulas is a convex polytope. Therefore, we find sharp bounds in this class for many aggregate risk measures, such as value-at-risk, expected shortfall, and entropic risk measure, by enumerating their values on the extremal points of the convex polytope. This is infeasible in high dimensions. We overcome this limitation by considering the aggregation of identically distributed risks with generalized FGM copula specified by a common parameter $p$. In this case, the analogy with the geometrical structure of the class of Bernoulli distribution allows us to provide sharp analytical bounds for convex risk measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10648v1</guid>
      <category>q-fin.MF</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H\'el\`ene Cossette, Etienne Marceau, Alessandro Mutti, Patrizia Semeraro</dc:creator>
    </item>
    <item>
      <title>Joint parameter estimations for spin glasses</title>
      <link>https://arxiv.org/abs/2406.10760</link>
      <description>arXiv:2406.10760v1 Announce Type: cross 
Abstract: Spin glass models with quadratic-type Hamiltonians are disordered statistical physics systems with competing ferromagnetic and anti-ferromagnetic spin interactions. The corresponding Gibbs measures belong to the exponential family parametrized by (inverse) temperature $\beta&gt;0$ and external field $h\in\mathbb{R}$. Given a sample from these Gibbs measures, a statistically fundamental question is to infer the temperature and external field parameters. In 2007, Chatterjee (Ann. Statist. 35 (2007), no.5, 1931-1946) first proved that in the absence of external field $h=0$, the maximum pseudolikelihood estimator for $\beta$ is $\sqrt{N}$-consistent under some mild assumptions on the disorder matrices. It was left open whether the same method can be used to estimate the temperature and external field simultaneously. In this paper, under some easily verifiable conditions, we prove that the bivariate maximum pseudolikelihood estimator is indeed jointly $\sqrt{N}$-consistent for the temperature and external field parameters. The examples cover the classical Sherrington-Kirkpatrick model and its diluted variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10760v1</guid>
      <category>math.PR</category>
      <category>cond-mat.dis-nn</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei-Kuo Chen, Arnab Sen, Qiang Wu</dc:creator>
    </item>
    <item>
      <title>HEDE: Heritability estimation in high dimensions by Ensembling Debiased Estimators</title>
      <link>https://arxiv.org/abs/2406.11184</link>
      <description>arXiv:2406.11184v1 Announce Type: cross 
Abstract: Estimating heritability remains a significant challenge in statistical genetics. Diverse approaches have emerged over the years that are broadly categorized as either random effects or fixed effects heritability methods. In this work, we focus on the latter. We propose HEDE, an ensemble approach to estimate heritability or the signal-to-noise ratio in high-dimensional linear models where the sample size and the dimension grow proportionally. Our method ensembles post-processed versions of the debiased lasso and debiased ridge estimators, and incorporates a data-driven strategy for hyperparameter selection that significantly boosts estimation performance. We establish rigorous consistency guarantees that hold despite adaptive tuning. Extensive simulations demonstrate our method's superiority over existing state-of-the-art methods across various signal structures and genetic architectures, ranging from sparse to relatively dense and from evenly to unevenly distributed signals. Furthermore, we discuss the advantages of fixed effects heritability estimation compared to random effects estimation. Our theoretical guarantees hold for realistic genotype distributions observed in genetic studies, where genotypes typically take on discrete values and are often well-modeled by sub-Gaussian distributed random variables. We establish our theoretical results by deriving uniform bounds, built upon the convex Gaussian min-max theorem, and leveraging universality results. Finally, we showcase the efficacy of our approach in estimating height and BMI heritability using the UK Biobank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11184v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanke Song, Xihong Lin, Pragya Sur</dc:creator>
    </item>
    <item>
      <title>Plugin Estimation of Smooth Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2107.12364</link>
      <description>arXiv:2107.12364v3 Announce Type: replace 
Abstract: We analyze a number of natural estimators for the optimal transport map between two distributions and show that they are minimax optimal. We adopt the plugin approach: our estimators are simply optimal couplings between measures derived from our observations, appropriately extended so that they define functions on $\mathbb{R}^d$. When the underlying map is assumed to be Lipschitz, we show that computing the optimal coupling between the empirical measures, and extending it using linear smoothers, already gives a minimax optimal estimator. When the underlying map enjoys higher regularity, we show that the optimal coupling between appropriate nonparametric density estimates yields faster rates. Our work also provides new bounds on the risk of corresponding plugin estimators for the quadratic Wasserstein distance, and we show how this problem relates to that of estimating optimal transport maps using stability arguments for smooth and strongly convex Brenier potentials. As an application of our results, we derive central limit theorems for plugin estimators of the squared Wasserstein distance, which are centered at their population counterpart when the underlying distributions have sufficiently smooth densities. In contrast to known central limit theorems for empirical estimators, this result easily lends itself to statistical inference for the quadratic Wasserstein distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.12364v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tudor Manole, Sivaraman Balakrishnan, Jonathan Niles-Weed, Larry Wasserman</dc:creator>
    </item>
    <item>
      <title>A geometric framework for asymptotic inference of principal subspaces in PCA</title>
      <link>https://arxiv.org/abs/2209.02025</link>
      <description>arXiv:2209.02025v2 Announce Type: replace 
Abstract: In this article, we develop an asymptotic method for constructing confidence regions for the set of all linear subspaces arising from PCA, from which we derive hypothesis tests on this set. Our method is based on the geometry of Riemannian manifolds with which some sets of linear subspaces are endowed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.02025v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimbihery Rabenoro, Xavier Pennec</dc:creator>
    </item>
    <item>
      <title>Spectral co-Clustering in Multi-layer Directed Networks</title>
      <link>https://arxiv.org/abs/2307.10572</link>
      <description>arXiv:2307.10572v2 Announce Type: replace 
Abstract: Modern network analysis often involves multi-layer network data in which the nodes are aligned, and the edges on each layer represent one of the multiple relations among the nodes. Current literature on multi-layer network data is mostly limited to undirected relations. However, direct relations are more common and may introduce extra information. This study focuses on community detection (or clustering) in multi-layer directed networks. To take into account the asymmetry, a novel spectral-co-clustering-based algorithm is developed to detect co-clusters, which capture the sending patterns and receiving patterns of nodes, respectively. Specifically, the eigendecomposition of the debiased sum of Gram matrices over the layer-wise adjacency matrices is computed, followed by the k-means, where the sum of Gram matrices is used to avoid possible cancellation of clusters caused by direct summation. Theoretical analysis of the algorithm under the multi-layer stochastic co-block model is provided, where the common assumption that the cluster number is coupled with the rank of the model is relaxed. After a systematic analysis of the eigenvectors of the population version algorithm, the misclassification rates are derived, which show that multi-layers would bring benefits to the clustering performance. The experimental results of simulated data corroborate the theoretical predictions, and the analysis of a real-world trade network dataset provides interpretable results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10572v2</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.csda.2024.107987</arxiv:DOI>
      <arxiv:journal_reference>Computational Statistics &amp; Data Analysis (2024) 107987</arxiv:journal_reference>
      <dc:creator>Wenqing Su, Xiao Guo, Xiangyu Chang, Ying Yang</dc:creator>
    </item>
    <item>
      <title>A Dimension-Independent Bound on the Wasserstein Contraction Rate of a Geodesic Random Walk on the Sphere</title>
      <link>https://arxiv.org/abs/2309.09097</link>
      <description>arXiv:2309.09097v2 Announce Type: replace 
Abstract: We theoretically analyze the properties of a geodesic random walk on the Euclidean $d$-sphere. Specifically, we prove that the random walk's transition kernel is Wasserstein contractive with a contraction rate which can be bounded from above independently of the dimension $d$. Our result is of particular interest due to its implications regarding the potential for dimension-independent performance of both geodesic slice sampling on the sphere and Gibbsian polar slice sampling, which are Markov chain Monte Carlo methods for approximate sampling from essentially arbitrary distributions on their respective state spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09097v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Sch\"ar, Thilo D. Stier</dc:creator>
    </item>
    <item>
      <title>Stein's method of moments for truncated multivariate distributions</title>
      <link>https://arxiv.org/abs/2312.09344</link>
      <description>arXiv:2312.09344v2 Announce Type: replace 
Abstract: We use Stein characterisations to derive new moment-type estimators for the parameters of several truncated multivariate distributions in the i.i.d. case; we also derive the asymptotic properties of these estimators. Our examples include the truncated multivariate normal distribution and truncated products of independent univariate distributions. The estimators are explicit and therefore provide an interesting alternative to the maximum-likelihood estimator (MLE). The quality of these estimators is assessed through competitive simulation studies, in which we compare their behaviour to the performance of the MLE and the score matching approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09344v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Fischer, Robert E. Gaunt, Yvik Swan</dc:creator>
    </item>
    <item>
      <title>Theory for adaptive designs in regression</title>
      <link>https://arxiv.org/abs/2312.13387</link>
      <description>arXiv:2312.13387v3 Announce Type: replace 
Abstract: There exist multiple regression applications in engineering, industry and medicine where the outcomes are not conditionally independent given the covariates, but where instead the covariates follow an adaptive experimental design in which the next measurement depends on the previous observations, introducing dependence. Such designs are commonly employed for example for choosing test values when estimating the sensitivity of a material under physical stimulus. In addition to estimating the regression parameters, we are also interested in tasks such as hypothesis testing and constructing confidence intervals, both of which rely on asymptotic normality of the maximum likelihood estimator. When adaptive designs are employed, however, the large-sample theory of the maximum likelihood estimator is more involved than in the standard regression setting, where the outcomes are assumed conditionally independent given the covariates. Hence, asymptotic normality must be verified explicitly case by case. For some classic adaptive designs like the Bruceton up-and-down designs, this issue has been resolved. However, general results for adaptive designs relying on minimal assumptions are to a large extent lacking. In this paper we establish a general large-sample theory for a wide selection of adaptive designs. Motivated by the theory, we propose a new Markovian version of the Langlie design and verify asymptotic normality for this proposal. Our simulations indicate that the Markovian design is more stable and yields better confidence intervals than the original Langlie design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13387v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dennis Christensen, Emil Aas Stoltenberg, Nils Lid Hjort</dc:creator>
    </item>
    <item>
      <title>Sampling and estimation on manifolds using the Langevin diffusion</title>
      <link>https://arxiv.org/abs/2312.14882</link>
      <description>arXiv:2312.14882v2 Announce Type: replace 
Abstract: Error bounds are derived for sampling and estimation using a discretization of an intrinsically defined Langevin diffusion with invariant measure $\text{d}\mu_\phi \propto e^{-\phi} \mathrm{dvol}_g $ on a compact Riemannian manifold. Two estimators of linear functionals of $\mu_\phi $ based on the discretized Markov process are considered: a time-averaging estimator based on a single trajectory and an ensemble-averaging estimator based on multiple independent trajectories. Imposing no restrictions beyond a nominal level of smoothness on $\phi$, first-order error bounds, in discretization step size, on the bias and variance/mean-square error of both estimators are derived. The order of error matches the optimal rate in Euclidean and flat spaces, and leads to a first-order bound on distance between the invariant measure $\mu_\phi$ and a stationary measure of the discretized Markov process. This order is preserved even upon using retractions when exponential maps are unavailable in closed form, thus enhancing practicality of the proposed algorithms. Generality of the proof techniques, which exploit links between two partial differential equations and the semigroup of operators corresponding to the Langevin diffusion, renders them amenable for the study of a more general class of sampling algorithms related to the Langevin diffusion. Conditions for extending analysis to the case of non-compact manifolds are discussed. Numerical illustrations with distributions, log-concave and otherwise, on the manifolds of positive and negative curvature elucidate on the derived bounds and demonstrate practical utility of the sampling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14882v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Bharath, Alexander Lewis, Akash Sharma, Michael V Tretyakov</dc:creator>
    </item>
    <item>
      <title>Dimension-free Structured Covariance Estimation</title>
      <link>https://arxiv.org/abs/2402.10032</link>
      <description>arXiv:2402.10032v2 Announce Type: replace 
Abstract: Given a sample of i.i.d. high-dimensional centered random vectors, we consider a problem of estimation of their covariance matrix $\Sigma$ with an additional assumption that $\Sigma$ can be represented as a sum of a few Kronecker products of smaller matrices. Under mild conditions, we derive the first non-asymptotic dimension-free high-probability bound on the Frobenius distance between $\Sigma$ and a widely used penalized permuted least squares estimate. Because of the hidden structure, the established rate of convergence is faster than in the standard covariance estimation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10032v2</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Puchkin, Maxim Rakhuba</dc:creator>
    </item>
    <item>
      <title>Generative Invariance</title>
      <link>https://arxiv.org/abs/2402.15502</link>
      <description>arXiv:2402.15502v2 Announce Type: replace 
Abstract: We introduce a novel estimator for predicting outcomes in the presence of hidden confounding across different distributional settings without relying on regularization or a known causal structure. Our approach is based on parametrizing the dependence of the covariates with response noise, ensuring optimal prediction and favorable asymptotic properties. We achieve identifiability under lean assumptions that have direct empirical translation, enabling the incorporation of causal parameters into a generative model that replicates the true conditional distribution of a test environment. This method achieves probabilistic alignment with test distributions uniformly across interventions, offering robust predictions without the need for worst-case optimization or specific assumptions about the strength of perturbations at test. Our findings represent a significant advancement in the statistical understanding of causality, providing a robust and flexible framework for predictive modeling in varied domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15502v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Garc\'ia Meixide, David R\'ios Insua</dc:creator>
    </item>
    <item>
      <title>Conditional uncorrelation equals independence</title>
      <link>https://arxiv.org/abs/2406.01849</link>
      <description>arXiv:2406.01849v2 Announce Type: replace 
Abstract: It is well known that the independent random variables $X$ and $Y$ are uncorrelated in the sense $E[XY]=E[X]\cdot E[Y]$ and that the implication may be reversed in very specific cases only. This paper proves that under general assumptions the conditional uncorrelation of random variables, where the conditioning takes place over the suitable class of test sets, is equivalent to the independence. It is also shown that the mutual independence of $X_1,\dots,X_n$ is equivalent to the fact that any conditional correlation matrix equals to the identity matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01849v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dawid Tar{\l}owski</dc:creator>
    </item>
    <item>
      <title>A connection between Tempering and Entropic Mirror Descent</title>
      <link>https://arxiv.org/abs/2310.11914</link>
      <description>arXiv:2310.11914v3 Announce Type: replace-cross 
Abstract: This paper explores the connections between tempering (for Sequential Monte Carlo; SMC) and entropic mirror descent to sample from a target probability distribution whose unnormalized density is known. We establish that tempering SMC corresponds to entropic mirror descent applied to the reverse Kullback-Leibler (KL) divergence and obtain convergence rates for the tempering iterates. Our result motivates the tempering iterates from an optimization point of view, showing that tempering can be seen as a descent scheme of the KL divergence with respect to the Fisher-Rao geometry, in contrast to Langevin dynamics that perform descent of the KL with respect to the Wasserstein-2 geometry. We exploit the connection between tempering and mirror descent iterates to justify common practices in SMC and derive adaptive tempering rules that improve over other alternative benchmarks in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11914v3</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Chopin, Francesca R. Crucinio, Anna Korba</dc:creator>
    </item>
    <item>
      <title>Data integration of non-probability and probability samples with predictive mean matching</title>
      <link>https://arxiv.org/abs/2403.13750</link>
      <description>arXiv:2403.13750v2 Announce Type: replace-cross 
Abstract: In this paper we study predictive mean matching mass imputation estimators to integrate data from probability and non-probability samples. We consider two approaches: matching predicted to predicted ($\hat{y}-\hat{y}$~matching; PMM A) and predicted to observed ($\hat{y}-y$~matching; PMM B) values. We prove the consistency of two semi-parametric mass imputation estimators based on these approaches and derive their variance and estimators of variance. We underline the differences of our approach with the nearest neighbour approach proposed by Yang et al. (2021) and prove consistency of the PMM A estimator under model mis-specification. Our approach can be employed with non-parametric regression techniques, such as kernel regression, and the analytical expression for variance can also be applied in nearest neighbour matching for non-probability samples. We conduct extensive simulation studies in order to compare the properties of this estimator with existing approaches, discuss the selection of $k$-nearest neighbours, and study the effects of model mis-specification. The paper finishes with empirical study in integration of job vacancy survey and vacancies submitted to public employment offices (admin and online data). Open source software is available for the proposed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13750v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piotr Chlebicki, {\L}ukasz Chrostowski, Maciej Ber\k{e}sewicz</dc:creator>
    </item>
    <item>
      <title>On the Sequence Evaluation based on Stochastic Processes</title>
      <link>https://arxiv.org/abs/2405.17764</link>
      <description>arXiv:2405.17764v2 Announce Type: replace-cross 
Abstract: Modeling and analyzing long sequences of text is an essential task for Natural Language Processing. Success in capturing long text dynamics using neural language models will facilitate many downstream tasks such as coherence evaluation, text generation, machine translation and so on. This paper presents a novel approach to model sequences through a stochastic process. We introduce a likelihood-based training objective for the text encoder and design a more thorough measurement (score) for long text evaluation compared to the previous approach. The proposed training objective effectively preserves the sequence coherence, while the new score comprehensively captures both temporal and spatial dependencies. Theoretical properties of our new score show its advantages in sequence evaluation. Experimental results show superior performance in various sequence evaluation tasks, including global and local discrimination within and between documents of different lengths. We also demonstrate the encoder achieves competitive results on discriminating human and AI written text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17764v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianhao Zhang, Zhexiao Lin, Zhecheng Sheng, Chen Jiang, Dongyeop Kang</dc:creator>
    </item>
    <item>
      <title>Benign overfitting in Fixed Dimension via Physics-Informed Learning with Smooth Inductive Bias</title>
      <link>https://arxiv.org/abs/2406.09194</link>
      <description>arXiv:2406.09194v2 Announce Type: replace-cross 
Abstract: Recent advances in machine learning have inspired a surge of research into reconstructing specific quantities of interest from measurements that comply with certain physical laws. These efforts focus on inverse problems that are governed by partial differential equations (PDEs). In this work, we develop an asymptotic Sobolev norm learning curve for kernel ridge(less) regression when addressing (elliptical) linear inverse problems. Our results show that the PDE operators in the inverse problem can stabilize the variance and even behave benign overfitting for fixed-dimensional problems, exhibiting different behaviors from regression problems. Besides, our investigation also demonstrates the impact of various inductive biases introduced by minimizing different Sobolev norms as a form of implicit regularization. For the regularized least squares estimator, we find that all considered inductive biases can achieve the optimal convergence rate, provided the regularization parameter is appropriately chosen. The convergence rate is actually independent to the choice of (smooth enough) inductive bias for both ridge and ridgeless regression. Surprisingly, our smoothness requirement recovered the condition found in Bayesian setting and extend the conclusion to the minimum norm interpolation estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09194v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Honam Wong, Wendao Wu, Fanghui Liu, Yiping Lu</dc:creator>
    </item>
    <item>
      <title>When Pearson $\chi^2$ and other divisible statistics are not goodness-of-fit tests</title>
      <link>https://arxiv.org/abs/2406.09195</link>
      <description>arXiv:2406.09195v2 Announce Type: replace-cross 
Abstract: Thousands of experiments are analyzed and papers are published each year involving the statistical analysis of grouped data. While this area of statistics is often perceived - somewhat naively - as saturated, several misconceptions still affect everyday practice, and new frontiers have so far remained unexplored. Researchers must be aware of the limitations affecting their analyses and what are the new possibilities in their hands.
  Motivated by this need, the article introduces a unifying approach to the analysis of grouped data which allows us to study the class of divisible statistics - that includes Pearson's $\chi^2$, the likelihood ratio as special cases - with a fresh perspective. The contributions collected in this manuscript span from modeling and estimation to distribution-free goodness-of-fit tests.
  Perhaps the most surprising result presented here is that, in a sparse regime, all tests proposed in the literature are dominated by a class of weighted linear statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09195v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara Algeri, Estate V. Khmaladze</dc:creator>
    </item>
  </channel>
</rss>
