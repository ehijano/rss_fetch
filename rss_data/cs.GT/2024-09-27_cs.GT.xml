<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Sep 2024 04:00:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Stackelberg Attack on Protocol Fee Governance</title>
      <link>https://arxiv.org/abs/2409.17756</link>
      <description>arXiv:2409.17756v1 Announce Type: new 
Abstract: We establish a Stackelberg attack by Liquidity Providers against Governance of an AMM, leveraging forking and commitments through a Grim Forker smart contract. We produce a dynamic, block-by-block model of AMM reserves and trading volume in the presence of competing forks, derive equilibrium conditions in the presence of protocol fees, and analyze Stackelberg equilibria with smart contract moves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17756v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Hajjar</dc:creator>
    </item>
    <item>
      <title>Auction-based Adaptive Resource Allocation Optimization in Dense IoT Networks</title>
      <link>https://arxiv.org/abs/2409.17843</link>
      <description>arXiv:2409.17843v1 Announce Type: new 
Abstract: The rapid pervasivity of the Internet of Things (IoT) calls for an autonomous and efficient resource management framework to seamlessly register and discover facilities and services. Cloud-Fog-Automation (CFA) standards provide a robust foundation for multi-tiered wireless architectures, enhancing cyber-physical system performance with advanced abstractions. This work is for resource allocation optimization in IoT networks, particularly in power management and time-frequency spreading techniques, ensuring deterministic connectivity, networked computing, and intelligent control systems. Auction game theory is pivotal in managing resource allocation in densely populated, high-demand IoT networks. By employing sealed-bid auctions based on Bayesian game theory, the uncertainties in individual hypotheses and channel states among IoT entities are effectively mitigated. A novel dispersion metric optimization further enhances the coordination of layer-specific IoT uplinks, enabling ultra-reliable, low-latency (URLLC) communication. Numerical results demonstrate the superior performance of this resilient architecture, achieving fair resource allocation with minimal power consumption and robust performance in unsecured scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17843v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nirmal D. Wickramasinghe, John Dooley, Dirk Pesch, Indrakshi Dey</dc:creator>
    </item>
    <item>
      <title>Grounded Predictions of Teamwork as a One-Shot Game: A Multiagent Multi-Armed Bandits Approach</title>
      <link>https://arxiv.org/abs/2409.17214</link>
      <description>arXiv:2409.17214v1 Announce Type: cross 
Abstract: Humans possess innate collaborative capacities. However, effective teamwork often remains challenging. This study delves into the feasibility of collaboration within teams of rational, self-interested agents who engage in teamwork without the obligation to contribute. Drawing from psychological and game theoretical frameworks, we formalise teamwork as a one-shot aggregative game, integrating insights from Steiner's theory of group productivity. We characterise this novel game's Nash equilibria and propose a multiagent multi-armed bandit system that learns to converge to approximations of such equilibria. Our research contributes value to the areas of game theory and multiagent systems, paving the way for a better understanding of voluntary collaborative dynamics. We examine how team heterogeneity, task typology, and assessment difficulty influence agents' strategies and resulting teamwork outcomes. Finally, we empirically study the behaviour of work teams under incentive systems that defy analytical treatment. Our agents demonstrate human-like behaviour patterns, corroborating findings from social psychology research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17214v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandra L\'opez de Aberasturi G\'omez, Carles Sierra, Jordi Sabater-Mir</dc:creator>
    </item>
    <item>
      <title>Stackelberg-Pareto Synthesis with Quantitative Reachability Objectives</title>
      <link>https://arxiv.org/abs/2308.09443</link>
      <description>arXiv:2308.09443v2 Announce Type: replace 
Abstract: In this paper, we deepen the study of two-player Stackelberg games played on graphs in which Player $0$ announces a strategy and Player $1$, having several objectives, responds rationally by following plays providing him Pareto-optimal payoffs given the strategy of Player $0$. The Stackelberg-Pareto synthesis problem, asking whether Player $0$ can announce a strategy which satisfies his objective, whatever the rational response of Player $1$, has been recently investigated for $\omega$-regular objectives. We solve this problem for weighted graph games and quantitative reachability objectives such that Player $0$ wants to reach his target set with a total cost less than some given upper bound. We show that it is NEXPTIME-complete, as for Boolean reachability objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09443v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Brihaye, V\'eronique Bruy\`ere, Gaspard Reghem</dc:creator>
    </item>
    <item>
      <title>Randomized Strategic Facility Location with Predictions</title>
      <link>https://arxiv.org/abs/2409.07142</link>
      <description>arXiv:2409.07142v2 Announce Type: replace 
Abstract: We revisit the canonical problem of strategic facility location and study the power and limitations of randomization in the design of truthful mechanisms augmented with machine-learned predictions. In the strategic facility location problem, a set of agents are asked to report their locations in some metric space and the goal is to use these reported locations to determine where to open a new facility, aiming to optimize some aggregate measure of distance of the agents from that facility. However, the agents are strategic and can misreport their locations if this may lead to a facility location choice that they prefer. The goal is to design truthful mechanisms, which ensure the agents cannot benefit by misreporting. A lot of prior work has studied this problem from a worst-case perspective, but a recent line of work proposed a framework to refine these results when the designer is provided with some, potentially very inaccurate, predictions regarding the agents' true locations. The goal is to simultaneously provide strong consistency guarantees (i.e., guarantees when the predictions provided to the mechanism are correct) and near-optimal robustness guarantees (i.e., guarantees that hold irrespective of how inaccurate the predictions may be). In this work we focus on the power of randomization in this problem and analyze the best approximation guarantees achievable with respect to the egalitarian social cost measure for one- and two-dimensional Euclidean spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07142v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Balkanski, Vasilis Gkatzelis, Golnoosh Shahkarami</dc:creator>
    </item>
    <item>
      <title>Solidago: A Modular Collaborative Scoring Pipeline</title>
      <link>https://arxiv.org/abs/2211.01179</link>
      <description>arXiv:2211.01179v3 Announce Type: replace-cross 
Abstract: This paper presents Solidago, an end-to-end modular pipeline to allow any community of users to collaboratively score any number of entities. Solidago proposes a six-module decomposition. First, it uses pretrust and peer-to-peer vouches to assign trust scores to users. Second, based on participation, trust scores are turned into voting rights per user per entity. Third, for each user, a preference model is learned from the user's evaluation data. Fourth, users' models are put on a similar scale. Fifth, these models are securely aggregated. Sixth, models are post-processed to yield human-readable global scores. We also propose default implementations of the six modules, including a novel trust propagation algorithm, and adaptations of state-of-the-art scaling and aggregation solutions. Our pipeline has been successfully deployed on the open-source platform tournesol.app. We thereby lay an appealing foundation for the collaborative, effective, scalable, fair, interpretable and secure scoring of any set of entities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01179v3</guid>
      <category>cs.SI</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\^e Nguy\^en Hoang, Romain Beylerian, B\'erang\`ere Colbois, Julien Fageot, Louis Faucon, Aidan Jungo, Alain Le Noac'h, Adrien Matissart, Oscar Villemaud</dc:creator>
    </item>
    <item>
      <title>Implementing Evidence Acquisition: Time Dependence in Contracts for Advice</title>
      <link>https://arxiv.org/abs/2310.19147</link>
      <description>arXiv:2310.19147v2 Announce Type: replace-cross 
Abstract: An expert with no inherent interest in an unknown binary state can exert effort to acquire a piece of falsifiable evidence informative of it. A designer can incentivize learning using a mechanism that provides state-dependent rewards within fixed bounds. We show that eliciting a single report maximizes information acquisition if the evidence is revealing or its content predictable. This conclusion fails when the evidence is sufficiently imprecise, the failure to find it is informative, and its contents could support either state. Our findings shed light on incentive design for consultation and forecasting by showing how learning dynamics qualitatively shape effort-maximizing contracts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19147v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingkai Li, Jonathan Libgober</dc:creator>
    </item>
    <item>
      <title>Strategic Linear Contextual Bandits</title>
      <link>https://arxiv.org/abs/2406.00551</link>
      <description>arXiv:2406.00551v2 Announce Type: replace-cross 
Abstract: Motivated by the phenomenon of strategic agents gaming a recommender system to maximize the number of times they are recommended to users, we study a strategic variant of the linear contextual bandit problem, where the arms can strategically misreport privately observed contexts to the learner. We treat the algorithm design problem as one of mechanism design under uncertainty and propose the Optimistic Grim Trigger Mechanism (OptGTM) that incentivizes the agents (i.e., arms) to report their contexts truthfully while simultaneously minimizing regret. We also show that failing to account for the strategic nature of the agents results in linear regret. However, a trade-off between mechanism design and regret minimization appears to be unavoidable. More broadly, this work aims to provide insight into the intersection of online learning and mechanism design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00551v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Kleine Buening, Aadirupa Saha, Christos Dimitrakakis, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>Opponent Shaping for Antibody Development</title>
      <link>https://arxiv.org/abs/2409.10588</link>
      <description>arXiv:2409.10588v5 Announce Type: replace-cross 
Abstract: Anti-viral therapies are typically designed to target the current strains of a virus. Game theoretically, this corresponds to a short-sighted, or myopic, response. However, therapy-induced selective pressures act on viral antigens to drive the emergence of mutated strains, against which initial therapies have reduced efficacy. Building on a computational model of binding between antibodies and viral antigens (the Absolut! framework), we design and implement a genetic simulation of such viral evolutionary escape. Crucially, this allows our antibody optimisation algorithm to consider and influence the entire escape curve of the virus, i.e. to guide (or ''shape'') the viral evolution. This is inspired by opponent shaping which, in general-sum learning, accounts for the adaptation of the co-player rather than playing a myopic best response. Hence we call the optimised antibodies shapers. Within our simulations, we demonstrate that our shapers target both current and simulated future viral variants, outperforming the antibodies chosen in a myopic way. Furthermore, we show that shapers exert specific evolutionary pressure on the virus compared to myopic antibodies. Altogether, shapers modify the evolutionary trajectories of viral strains and minimise the viral escape compared to their myopic counterparts. While this is a simplified model, we hope that our proposed paradigm will enable the discovery of better long-lived vaccines and antibody therapies in the future, enabled by rapid advancements in the capabilities of simulation tools. Our code is available at https://github.com/olakalisz/antibody-shapers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10588v5</guid>
      <category>q-bio.PE</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Towers, Aleksandra Kalisz, Philippe A. Robert, Alicia Higueruelo, Francesca Vianello, Ming-Han Chloe Tsai, Harrison Steel, Jakob N. Foerster</dc:creator>
    </item>
  </channel>
</rss>
