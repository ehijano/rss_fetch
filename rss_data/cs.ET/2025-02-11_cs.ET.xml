<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Cost-Benefit Analysis of Additive Manufacturing as a Service</title>
      <link>https://arxiv.org/abs/2502.05586</link>
      <description>arXiv:2502.05586v1 Announce Type: new 
Abstract: The global manufacturing landscape is undergoing a fundamental shift from resource-intensive mass production to sustainable, localised manufacturing. This paper presents a comprehensive analysis of a Cloud Crafting Platform that enables Manufacturing as a Service (MaaS) through additive manufacturing technologies. The platform connects web shops with local three-dimensional (3D) printing facilities, allowing customers to purchase products that are manufactured on-demand in their vicinity. We present the platform's Service-Oriented Architecture (SOA), deployment on the Microsoft Azure cloud, and integration with three different 3D printer models in a testbed environment. A detailed cost-benefit analysis demonstrates the economic viability of the approach, which generates significant profit margins. The platform implements a weighted profit-sharing model that fairly compensates all stakeholders based on their investment and operational responsibilities. Our results show that on-demand, localised manufacturing through MaaS is not only technically feasible but also economically viable, while reducing environmental impact through shortened supply chains and elimination of inventory waste. The platform's extensible architecture allows for future integration of additional manufacturing technologies beyond 3D printing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05586v1</guid>
      <category>cs.ET</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Ivki\'c, Tobias Buhmann, Burkhard List</dc:creator>
    </item>
    <item>
      <title>TAP-CAM: A Tunable Approximate Matching Engine based on Ferroelectric Content Addressable Memory</title>
      <link>https://arxiv.org/abs/2502.05787</link>
      <description>arXiv:2502.05787v1 Announce Type: new 
Abstract: Pattern search is crucial in numerous analytic applications for retrieving data entries akin to the query. Content Addressable Memories (CAMs), an in-memory computing fabric, directly compare input queries with stored entries through embedded comparison logic, facilitating fast parallel pattern search in memory. While conventional CAM designs offer exact match functionality, they are inadequate for meeting the approximate search needs of emerging data-intensive applications. Some recent CAM designs propose approximate matching functions, but they face limitations such as excessively large cell area or the inability to precisely control the degree of approximation. In this paper, we propose TAP-CAM, a novel ferroelectric field effect transistor (FeFET) based ternary CAM (TCAM) capable of both exact and tunable approximate matching. TAP-CAM employs a compact 2FeFET-2R cell structure as the entry storage unit, and similarities in Hamming distances between input queries and stored entries are measured using an evaluation transistor associated with the matchline of CAM array. The operation, robustness and performance of the proposed design at array level have been discussed and evaluated, respectively. We conduct a case study of K-nearest neighbor (KNN) search to benchmark the proposed TAP-CAM at application level. Results demonstrate that compared to 16T CMOS CAM with exact match functionality, TAP-CAM achieves a 16.95x energy improvement, along with a 3.06% accuracy enhancement. Compared to 2FeFET TCAM with approximate match functionality, TAP-CAM achieves a 6.78x energy improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05787v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Ni, Sijie Chen, Che-Kai Liu, Liu Liu, Mohsen Imani, Thomas Kampfe, Kai Ni, Michael Niemier, Xiaobo Sharon Hu, Cheng Zhuo, Xunzhao Yin</dc:creator>
    </item>
    <item>
      <title>Characterization and Mitigation of ADC Noise by Reference Tuning in RRAM-Based Compute-In-Memory</title>
      <link>https://arxiv.org/abs/2502.05948</link>
      <description>arXiv:2502.05948v1 Announce Type: new 
Abstract: With the escalating demand for power-efficient neural network architectures, non-volatile compute-in-memory designs have garnered significant attention. However, owing to the nature of analog computation, susceptibility to noise remains a critical concern. This study confronts this challenge by introducing a detailed model that incorporates noise factors arising from both ADCs and RRAM devices. The experimental data is derived from a 40nm foundry RRAM test-chip, wherein different reference voltage configurations are applied, each tailored to its respective module. The mean and standard deviation values of HRS and LRS cells are derived through a randomized vector, forming the foundation for noise simulation within our analytical framework. Additionally, the study examines the read-disturb effects, shedding light on the potential for accuracy deterioration in neural networks due to extended exposure to high-voltage stress. This phenomenon is mitigated through the proposed low-voltage read mode. Leveraging our derived comprehensive fault model from the RRAM test-chip, we evaluate CIM noise impact on both supervised learning (time-independent) and reinforcement learning (time-dependent) tasks, and demonstrate the effectiveness of reference tuning to mitigate noise impacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05948v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying-Hao Wei, Zishen Wan, Brian Crafton, Samuel Spetalnick, Arijit Raychowdhury</dc:creator>
    </item>
    <item>
      <title>Explicit Solution Equation for Every Combinatorial Problem via Tensor Networks: MeLoCoToN</title>
      <link>https://arxiv.org/abs/2502.05981</link>
      <description>arXiv:2502.05981v1 Announce Type: new 
Abstract: In this paper we show that every combinatorial problem has an exact explicit equation that returns its solution. We present a method to obtain an equation that solves exactly any combinatorial problem, both inversion, constraint satisfaction and optimization, by obtaining its equivalent tensor network. This formulation only requires a basic knowledge of classical logical operators, at a first year level of any computer science degree. These equations are not necessarily computable in a reasonable time, nor do they allow to surpass the state of the art in computational complexity, but they allow to have a new perspective for the mathematical analysis of these problems. These equations computation can be approximated by different methods such as Matrix Product State compression. We also present the equations for numerous combinatorial problems. This work proves that, if there is a physical system capable of contracting in polynomial time the tensor networks presented, every NP-Hard problem can be solved in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05981v1</guid>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Mata Ali</dc:creator>
    </item>
    <item>
      <title>Low-power Spike-based Wearable Analytics on RRAM Crossbars</title>
      <link>https://arxiv.org/abs/2502.06736</link>
      <description>arXiv:2502.06736v1 Announce Type: new 
Abstract: This work introduces a spike-based wearable analytics system utilizing Spiking Neural Networks (SNNs) deployed on an In-memory Computing engine based on RRAM crossbars, which are known for their compactness and energy-efficiency. Given the hardware constraints and noise characteristics of the underlying RRAM crossbars, we propose online adaptation of pre-trained SNNs in real-time using Direct Feedback Alignment (DFA) against traditional backpropagation (BP). Direct Feedback Alignment (DFA) learning, that allows layer-parallel gradient computations, acts as a fast, energy &amp; area-efficient method for online adaptation of SNNs on RRAM crossbars, unleashing better algorithmic performance against those adapted using BP. Through extensive simulations using our in-house hardware evaluation engine called DFA_Sim, we find that DFA achieves upto 64.1% lower energy consumption, 10.1% lower area overhead, and a 2.1x reduction in latency compared to BP, while delivering upto 7.55% higher inference accuracy on human activity recognition (HAR) tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06736v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE International Symposium on Circuits and Systems (ISCAS), 2025</arxiv:journal_reference>
      <dc:creator>Abhiroop Bhattacharjee, Jinquan Shi, Wei-Chen Chen, Xinxin Wang, Priyadarshini Panda</dc:creator>
    </item>
    <item>
      <title>MindCraft: Revolutionizing Education through AI-Powered Personalized Learning and Mentorship for Rural India</title>
      <link>https://arxiv.org/abs/2502.05826</link>
      <description>arXiv:2502.05826v1 Announce Type: cross 
Abstract: MindCraft is a modern platform designed to revolutionize education in rural India by leveraging Artificial Intelligence (AI) to create personalized learning experiences, provide mentorship, and foster resource-sharing. In a country where access to quality education is deeply influenced by geography and socio economic status, rural students often face significant barriers in their educational journeys. MindCraft aims to bridge this gap by utilizing AI to create tailored learning paths, connect students with mentors, and enable a collaborative network of educational resources that transcends both physical and digital divides. This paper explores the challenges faced by rural students, the transformative potential of AI, and how MindCraft offers a scalable, sustainable solution for equitable education system. By focusing on inclusivity, personalized learning, and mentorship, MindCraft seeks to empower rural students, equipping them with the skills, knowledge, and opportunities needed to thrive in an increasingly digital world. Ultimately, MindCraft envisions a future in which technology not only bridges educational gaps but also becomes the driving force for a more inclusive and empowered society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05826v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arihant Bardia, Aayush Agrawal</dc:creator>
    </item>
    <item>
      <title>Hamiltonian formulations of centroid-based clustering</title>
      <link>https://arxiv.org/abs/2502.06542</link>
      <description>arXiv:2502.06542v1 Announce Type: cross 
Abstract: Clustering is a fundamental task in data science that aims to group data based on their similarities. However, defining similarity is often ambiguous, making it challenging to determine the most appropriate objective function for a given dataset. Traditional clustering methods, such as the $k$-means algorithm and weighted maximum $k$-cut, focus on specific objectives -- typically relying on average or pairwise characteristics of the data -- leading to performance that is highly data-dependent. Moreover, incorporating practical constraints into clustering objectives is not straightforward, and these problems are known to be NP-hard. In this study, we formulate the clustering problem as a search for the ground state of a Hamiltonian, providing greater flexibility in defining clustering objectives and incorporating constraints. This approach enables the application of various quantum simulation techniques, including both circuit-based quantum computation and quantum annealing, thereby opening a path toward quantum advantage in solving clustering problems. We propose various Hamiltonians to accommodate different clustering objectives, including the ability to combine multiple objectives and incorporate constraints. We evaluate the clustering performance through numerical simulations and implementations on the D-Wave quantum annealer. The results demonstrate the broad applicability of our approach to a variety of clustering problems on current quantum devices. Furthermore, we find that Hamiltonians designed for specific clustering objectives and constraints impose different requirements for qubit connectivity, indicating that certain clustering tasks are better suited to specific quantum hardware. Our experimental results highlight this by identifying the Hamiltonian that optimally utilizes the physical qubits available in the D-Wave System.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06542v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Myeonghwan Seong, Daniel K. Park</dc:creator>
    </item>
    <item>
      <title>On the Reliability of Information Retrieval From MDS Coded Data in DNA Storage</title>
      <link>https://arxiv.org/abs/2502.06618</link>
      <description>arXiv:2502.06618v1 Announce Type: cross 
Abstract: This work presents a theoretical analysis of the probability of successfully retrieving data encoded with MDS codes (e.g., Reed-Solomon codes) in DNA storage systems. We study this probability under independent and identically distributed (i.i.d.) substitution errors, focusing on a common code design strategy that combines inner and outer MDS codes. Our analysis demonstrates how this probability depends on factors such as the total number of sequencing reads, their distribution across strands, the rates of the inner and outer codes, and the substitution error probabilities. These results provide actionable insights into optimizing DNA storage systems under reliability constraints, including determining the minimum number of sequencing reads needed for reliable data retrieval and identifying the optimal balance between the rates of inner and outer MDS codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06618v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Kas Hanna</dc:creator>
    </item>
    <item>
      <title>Unsupervised Particle Tracking with Neuromorphic Computing</title>
      <link>https://arxiv.org/abs/2502.06771</link>
      <description>arXiv:2502.06771v1 Announce Type: cross 
Abstract: We study the application of a neural network architecture for identifying charged particle trajectories via unsupervised learning of delays and synaptic weights using a spike-time-dependent plasticity rule. In the considered model, the neurons receive time-encoded information on the position of particle hits in a tracking detector for a particle collider, modeled according to the geometry of the Compact Muon Solenoid Phase II detector. We show how a spiking neural network is capable of successfully identifying in a completely unsupervised way the signal left by charged particles in the presence of conspicuous noise from accidental or combinatorial hits. These results open the way to applications of neuromorphic computing to particle tracking, motivating further studies into its potential for real-time, low-power particle tracking in future high-energy physics experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06771v1</guid>
      <category>hep-ex</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuele Coradin (INFN, Sezione di Padova, Italy), Fabio Cufino (Universit\`a di Bologna, Dipartimento di Fisica, Italy), Muhammad Awais (INFN, Sezione di Padova, Italy), Tommaso Dorigo (INFN, Sezione di Padova, Italy), Enrico Lupi (INFN, Sezione di Padova, Italy), Eleonora Porcu (Universit\`a di Bologna, Dipartimento di Fisica, Italy), Jinu Raj (Central University of Tamil Nadu, India), Fredrik Sandin (Lule{\aa} University of Technology, Sweden), Mia Tosi (INFN, Sezione di Padova, Italy)</dc:creator>
    </item>
    <item>
      <title>Enhanced Low-Complexity Receiver Design for Short Block Transmission Systems</title>
      <link>https://arxiv.org/abs/2404.10065</link>
      <description>arXiv:2404.10065v2 Announce Type: replace-cross 
Abstract: This paper presents a comprehensive analysis and performance enhancement of short block length channel detection incorporating training information. The current communication systems' short block length channel detection typically consists of least squares channel estimation followed by quasi-coherent detection. By investigating the receiver structure, specifically the estimator-correlator, we show that the non-coherent term, often disregarded in conventional detection metrics, results in significant losses in performance and sensitivity in typical operating regimes of 5G and 6G systems. A comparison with the fully non-coherent receiver in multi-antenna configurations reveals substantial losses in low spectral efficiency operating areas. Additionally, we demonstrate that by employing an adaptive DMRS-data power adjustment, it is possible to reduce the performance loss gap, which is amenable to a more sensitive quasi-coherent receiver. However, both of the aforementioned ML detection strategies can result in substantial computational complexity when processing long bit-length codes. We propose an approach to tackle this challenge by introducing the principle of block or segment coding using First-Order RM Codes, which is amenable to low-cost decoding through block-based fast Hadamard transforms. The Block-based FHT has demonstrated to be cost-efficient with regards to decoding time, as it evolves from quadric to quasi-linear complexity with a manageable decline in performance. Additionally, by incorporating an adaptive DMRS-data power adjustment technique, we are able to bridge/reduce the performance gap with respect to the conventional maximum likelihood receiver and attain high sensitivity, leading to a good trade-off between performance and complexity to efficiently handle small payloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10065v2</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/PIMRC56721.2023.10293994</arxiv:DOI>
      <dc:creator>Mody Sy, Raymond Knopp</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Block-Based Decoding Algorithms for Short Block Channels</title>
      <link>https://arxiv.org/abs/2404.10798</link>
      <description>arXiv:2404.10798v2 Announce Type: replace-cross 
Abstract: This paper presents low-complexity block-based encoding and decoding algorithms for short block length channels. In terms of the precise use-case, we are primarily concerned with the baseline 3GPP Short block transmissions in which payloads are encoded by Reed-Muller codes and paired with orthogonal DMRS. In contemporary communication systems, the short block decoding often employs the utilization of DMRS-based least squares channel estimation, followed by maximum likelihood decoding. However, this methodology can incur substantial computational complexity when processing long bit length codes. We propose an innovative approach to tackle this challenge by introducing the principle of block/segment encoding using First-Order RM Codes which is amenable to low-cost decoding through block-based fast Hadamard transforms. The Block-based FHT has demonstrated to be cost-efficient with regards to decoding time, as it evolves from quadric to quasi-linear complexity with a manageable decline in performance. Additionally, by incorporating an adaptive DMRS/data power adjustment technique, we can bridge/reduce the performance gap and attain high sensitivity, leading to a good trade-off between performance and complexity to efficiently handle small payloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10798v2</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/AFRICON55910.2023.10293604</arxiv:DOI>
      <dc:creator>Mody Sy, Raymond Knopp</dc:creator>
    </item>
    <item>
      <title>ImmerseDiffusion: A Generative Spatial Audio Latent Diffusion Model</title>
      <link>https://arxiv.org/abs/2410.14945</link>
      <description>arXiv:2410.14945v2 Announce Type: replace-cross 
Abstract: We introduce ImmerseDiffusion, an end-to-end generative audio model that produces 3D immersive soundscapes conditioned on the spatial, temporal, and environmental conditions of sound objects. ImmerseDiffusion is trained to generate first-order ambisonics (FOA) audio, which is a conventional spatial audio format comprising four channels that can be rendered to multichannel spatial output. The proposed generative system is composed of a spatial audio codec that maps FOA audio to latent components, a latent diffusion model trained based on various user input types, namely, text prompts, spatial, temporal and environmental acoustic parameters, and optionally a spatial audio and text encoder trained in a Contrastive Language and Audio Pretraining (CLAP) style. We propose metrics to evaluate the quality and spatial adherence of the generated spatial audio. Finally, we assess the model performance in terms of generation quality and spatial conformance, comparing the two proposed modes: ``descriptive", which uses spatial text prompts) and ``parametric", which uses non-spatial text prompts and spatial parameters. Our evaluations demonstrate promising results that are consistent with the user conditions and reflect reliable spatial fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14945v2</guid>
      <category>cs.SD</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mojtaba Heydari, Mehrez Souden, Bruno Conejo, Joshua Atkins</dc:creator>
    </item>
    <item>
      <title>Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems</title>
      <link>https://arxiv.org/abs/2501.11613</link>
      <description>arXiv:2501.11613v5 Announce Type: replace-cross 
Abstract: This study introduces Conversation Routines (CR), a structured prompt engineering framework for developing task-oriented dialog systems using Large Language Models (LLMs). While LLMs demonstrate remarkable natural language understanding capabilities, engineering them to reliably execute complex business workflows remains challenging. The proposed CR framework enables the development of Conversation Agentic Systems (CAS) through natural language specifications, embedding task-oriented logic within LLM prompts. This approach provides a systematic methodology for designing and implementing complex conversational workflows while maintaining behavioral consistency. We demonstrate the framework's effectiveness through two proof-of-concept implementations: a Train Ticket Booking System and an Interactive Troubleshooting Copilot. These case studies validate CR's capability to encode sophisticated behavioral patterns and decision logic while preserving natural conversational flexibility. Results show that CR enables domain experts to design conversational workflows in natural language while leveraging custom functions (tools) developed by software engineers, creating an efficient division of responsibilities where developers focus on core API implementation and domain experts handle conversation design. While the framework shows promise in accessibility and adaptability, we identify key challenges including computational overhead, non-deterministic behavior, and domain-specific logic optimization. Future research directions include CR evaluation methods based on prompt engineering frameworks driven by goal-oriented grading criteria, improving scalability for complex multi-agent interactions, and enhancing system robustness to address the identified limitations across diverse business applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11613v5</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.PL</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giorgio Robino</dc:creator>
    </item>
    <item>
      <title>Scalable intensity-based photonic matrix-vector multiplication processor using single-wavelength time-division-multiplexed signals</title>
      <link>https://arxiv.org/abs/2501.18194</link>
      <description>arXiv:2501.18194v2 Announce Type: replace-cross 
Abstract: Photonic integrated circuits provide a compact platform for ultrafast and energy-efficient matrix-vector multiplications (MVMs) in the optical domain. Recently, schemes based on time-division multiplexing (TDM) have been proposed as scalable approaches for realizing large-scale photonic MVM processors. However, existing demonstrations rely on coherent detection or multiple wavelengths, both of which complicate their operations. In this work, we demonstrate a scalable TDM-based photonic MVM processor that uses only single-wavelength intensity-modulated optical signals, thereby avoiding coherent detection and enabling simplified operations. A 32-channel processor is fabricated on a Si-on-insulator (SOI) platform and used to experimentally perform convolution operations in a convolutional neural network (CNN) for handwritten digit recognition, achieving a classification accuracy of 93.47% for 1500 images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18194v2</guid>
      <category>physics.optics</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengli Chai, Rui Tang, Makoto Okano, Kasidit Toprasertpong, Shinichi Takagi, Mitsuru Takenaka</dc:creator>
    </item>
  </channel>
</rss>
