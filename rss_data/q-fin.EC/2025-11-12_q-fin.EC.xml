<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Nov 2025 02:37:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Misaligned by Design: Incentive Failures in Machine Learning</title>
      <link>https://arxiv.org/abs/2511.07699</link>
      <description>arXiv:2511.07699v1 Announce Type: new 
Abstract: The cost of error in many high-stakes settings is asymmetric: misdiagnosing pneumonia when absent is an inconvenience, but failing to detect it when present can be life-threatening. Because of this, artificial intelligence (AI) models used to assist such decisions are frequently trained with asymmetric loss functions that incorporate human decision-makers' trade-offs between false positives and false negatives. In two focal applications, we show that this standard alignment practice can backfire. In both cases, it would be better to train the machine learning model with a loss function that ignores the human's objective and then adjust predictions ex post according to that objective. We rationalize this result using an economic model of incentive design with endogenous information acquisition. The key insight from our theoretical framework is that machine classifiers perform not one but two incentivized tasks: choosing how to classify and learning how to classify. We show that while the adjustments engineers use correctly incentivize choosing, they can simultaneously reduce the incentives to learn. Our formal treatment of the problem reveals that methods embraced for their intuitive appeal can in fact misalign human and machine objectives in predictable ways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07699v1</guid>
      <category>econ.GN</category>
      <category>cs.LG</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Autor, Andrew Caplin, Daniel Martin, Philip Marx</dc:creator>
    </item>
    <item>
      <title>Who benefits from increases in military spending? An empirical analysis</title>
      <link>https://arxiv.org/abs/2511.08218</link>
      <description>arXiv:2511.08218v1 Announce Type: new 
Abstract: This paper investigates the heterogeneous effects of military spending news shocks on household income and wealth inequality for a large, panel of advanced and emerging economies. Confirming prior literature, we find that military spending news shocks lead to persistent increases in aggregate output and Total Factor Productivity. Our primary contribution is documenting contrasting distributional impacts. We find that expansionary military spending is associated with a mitigation of income inequality, as income gains are disproportionately larger at the left tail of the distribution, primarily driven by a rise in labour income and employment in industry. Conversely, the shock is found to increase wealth inequality, particularly in high-income countries, by raising the wealth share of the top decile via effects on business asset holdings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08218v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Beirne, Haroon Mumtaz, Donghyun Park, Gazi Salah Uddin, Angeliki Theophilopoulou</dc:creator>
    </item>
    <item>
      <title>From Double to Triple Burden: Gender Stratification in the Latin American Data Annotation Gig Economy</title>
      <link>https://arxiv.org/abs/2511.07652</link>
      <description>arXiv:2511.07652v1 Announce Type: cross 
Abstract: This paper examines gender stratification in the Latin American data annotation gig economy, with a particular focus on the "triple burden" shouldered by women: unpaid care responsibilities, economic precarity, and the volatility of platform-mediated labor. Data annotation, once lauded as a democratizing force within the global gig economy, has evolved into a segmented labor market characterized by low wages, limited protections, and unequal access to higher-skilled annotation tasks. Drawing on an exploratory survey of 30 Latin American data annotators, supplemented by qualitative accounts and comparative secondary literature, this study situates female annotators within broader debates in labor economics, including segmentation theory, monopsony power in platform labor, and the reserve army of labor. Findings indicate that women are disproportionately drawn into annotation due to caregiving obligations and political-economic instability in countries such as Venezuela, Colombia, and Peru. Respondents highlight low pay, irregular access to tasks, and lack of benefits as central challenges, while also expressing ambivalence about whether their work is valued relative to male counterparts. By framing annotation as both a gendered survival strategy and a critical input in the global artificial intelligence supply chain, this paper argues for the recognition of annotation as skilled labor and for regulatory interventions that address platform accountability, wage suppression, and regional inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07652v1</guid>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>indl-8:644104 (2025)</arxiv:journal_reference>
      <dc:creator>Lauren Benjamin Mushro</dc:creator>
    </item>
    <item>
      <title>Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency</title>
      <link>https://arxiv.org/abs/2511.08082</link>
      <description>arXiv:2511.08082v1 Announce Type: cross 
Abstract: This paper develops a prudential framework for assessing the reliability of large language models (LLMs) in reinsurance. A five-pillar architecture--governance, data lineage, assurance, resilience, and regulatory alignment--translates supervisory expectations from Solvency II, SR 11-7, and guidance from EIOPA (2025), NAIC (2023), and IAIS (2024) into measurable lifecycle controls. The framework is implemented through the Reinsurance AI Reliability and Assurance Benchmark (RAIRAB), which evaluates whether governance-embedded LLMs meet prudential standards for grounding, transparency, and accountability. Across six task families, retrieval-grounded configurations achieved higher grounding accuracy (0.90), reduced hallucination and interpretive drift by roughly 40%, and nearly doubled transparency. These mechanisms lower informational frictions in risk transfer and capital allocation, showing that existing prudential doctrines already accommodate reliable AI when governance is explicit, data are traceable, and assurance is verifiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08082v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stella C. Dong</dc:creator>
    </item>
    <item>
      <title>How Fixed-Amount Transactions and Liquidity Constraints Amplify Wealth Inequality: A Kinetic Model Deviating from the Maximum Entropy Benchmark</title>
      <link>https://arxiv.org/abs/2511.08202</link>
      <description>arXiv:2511.08202v1 Announce Type: cross 
Abstract: This paper investigates the emergence of wealth inequality through a minimalist kinetic exchange model that incorporates two fundamental economic features: fixed-amount transactions and hard budget constraints. In contrast to the maximum entropy principle, which predicts an exponential Boltzmann-Gibbs distribution with moderate inequality for unconstrained wealth exchange, we demonstrate that these realistic trading rules drive the system toward a highly unequal steady state. We develop a self-consistent mean-field theory, deriving a master equation where agent income follows a Poisson process coupled to the poverty rate. Numerical solution reveals a stationary distribution characterized by a substantial pauper class, high Gini coefficient, and exponential tail--significantly deviating from the maximum entropy benchmark. Agent-based simulations confirm these findings. We identify the poverty trap as the key mechanism: the liquidity constraint creates asymmetric economic agency, where zero-wealth agents become passive recipients, unable to participate in wealth circulation. This work establishes that substantial inequality can emerge spontaneously from equal-opportunity exchanges under basic economic constraints, without requiring agent heterogeneity or multiplicative advantage, providing a mechanistic foundation for understanding poverty as an emergent property of exchange rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08202v1</guid>
      <category>physics.soc-ph</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihyuan Liuh</dc:creator>
    </item>
    <item>
      <title>The Power of Linear Programming in Sponsored Listings Ranking: Evidence from a Large-Scale Field Experiment</title>
      <link>https://arxiv.org/abs/2403.14862</link>
      <description>arXiv:2403.14862v4 Announce Type: replace 
Abstract: Sponsored product advertisements constitute a major revenue source for online marketplaces such as Amazon, Walmart, and Alibaba. A key operational challenge in these systems lies in the Sponsored Listings Ranking (SLR) problem, that is, determining which items to include and how to rank them to balance short-term revenue with long-term relevance and user experience. Industry practice predominantly relies on score-based algorithms, which construct heuristic composite scores to rank items efficiently within strict real-time latency constraints. However, such methods offer limited control over objective trade-offs and cannot readily accommodate additional operational constraints. We propose and evaluate a Linear Programming (LP)-based algorithm as a principled alternative to score-based approaches. We first formulate the SLR problem as a constrained mixed integer programming (MIP) model and develop a dual-based algorithm that approximately solves its LP relaxation within 0.1 second, satisfying production-level latency requirements. In collaboration with a leading online marketplace, we conduct a 19-day field experiment encompassing approximately 329 million impressions. The LP-based algorithm significantly outperforms the industry-standard benchmark in key marketplace metrics, demonstrating both higher revenue and maintained relevance. Mechanism analyses reveal that the performance gains are most pronounced when the revenue-relevance tradeoff is stronger. Our framework also generalizes to settings with inventory, sales, or fairness constraints, offering a flexible and deployable optimization paradigm. The LP-based algorithm was deployed in production at our partner marketplace in January 2023, marking a rare large-scale implementation of a mathematically grounded ranking algorithm in real-world online advertising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14862v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haihao Lu, Luyang Zhang, Yuting Zhu</dc:creator>
    </item>
    <item>
      <title>Potato Potahto in the FAO-GAEZ Productivity Measures? Nonclassical Measurement Error with Multiple Proxies</title>
      <link>https://arxiv.org/abs/2502.12141</link>
      <description>arXiv:2502.12141v5 Announce Type: replace 
Abstract: The FAO-GAEZ productivity data are widely used in Economics. However, the empirical literature rarely discusses measurement error. We use two proxies to derive novel analytical bounds around the effect of agricultural productivity in a setting with nonclassical measurement error. These bounds rely on assumptions that are weaker than the ones imposed in empirical studies and exhaust the information contained in the first two moments of the data. We reevaluate three influential studies, documenting that measurement error matters and that the impact of agricultural productivity may be smaller than previously reported. Our methodology has broad applications in empirical research involving mismeasured variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12141v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rafael Araujo, Vitor Possebom</dc:creator>
    </item>
    <item>
      <title>Trade Policy and Structural Change</title>
      <link>https://arxiv.org/abs/2508.01360</link>
      <description>arXiv:2508.01360v3 Announce Type: replace 
Abstract: We examine how tariffs affect sectoral composition and welfare in an economy with nonhomothetic preferences and sectors being complements -- two drivers of structural change. Beyond their conventional role in trade protection, tariffs influence industrial structure by altering relative prices and income levels. We qualitatively characterize these mechanisms and use a quantitative dynamic model to show that a counterfactual 20-percentage-point increase in U.S. manufacturing tariffs since 2001 would have raised the manufacturing value-added share by one percentage point and increased welfare by 0.36 percent. However, if all the U.S. trading partners responded reciprocally, U.S. welfare would have declined by 0.12 percent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01360v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hayato Kato, Kensuke Suzuki, Motoaki Takahashi</dc:creator>
    </item>
    <item>
      <title>The Value of Personalized Recommendations: Evidence from Netflix</title>
      <link>https://arxiv.org/abs/2511.07280</link>
      <description>arXiv:2511.07280v2 Announce Type: replace 
Abstract: Personalized recommendation systems shape much of user choice online, yet their targeted nature makes separating out the value of recommendation and the underlying goods challenging. We build a discrete choice model that embeds recommendation-induced utility, low-rank heterogeneity, and flexible state dependence and apply the model to viewership data at Netflix. We exploit idiosyncratic variation introduced by the recommendation algorithm to identify and separately value these components as well as to recover model-free diversion ratios that we can use to validate our structural model. We use the model to evaluate counterfactuals that quantify the incremental engagement generated by personalized recommendations. First, we show that replacing the current recommender system with a matrix factorization or popularity-based algorithm would lead to 4% and 12% reduction in engagement, respectively, and decreased consumption diversity. Second, most of the consumption increase from recommendations comes from effective targeting, not mechanical exposure, with the largest gains for mid-popularity goods (as opposed to broadly appealing or very niche goods).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07280v2</guid>
      <category>econ.GN</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Zielnicki, Guy Aridor, Aur\'elien Bibaut, Allen Tran, Winston Chou, Nathan Kallus</dc:creator>
    </item>
  </channel>
</rss>
