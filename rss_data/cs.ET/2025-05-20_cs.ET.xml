<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 01:48:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Leveraging Large Reconfigurable Intelligent Surfaces as Anchors for Near-Field Positioning</title>
      <link>https://arxiv.org/abs/2505.12730</link>
      <description>arXiv:2505.12730v1 Announce Type: new 
Abstract: In this work, we present a recent investigation on leveraging large reconfigurable intelligent surfaces (RIS) as anchors for positioning in wireless communication systems. Unlike existing approaches, we explicitly address the uncertainty arising from the substantial physical size of the RIS, particularly relevant when a user equipment resides in the near field, and propose a method that ensures accurate positioning under these conditions. We derive the corresponding Cramer-Rao bound for our scheme and validate the effectiveness of our scheme through numerical experiments, highlighting both the feasibility and potential of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12730v1</guid>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Huang, Markus Rupp, Stefan Schwarz</dc:creator>
    </item>
    <item>
      <title>2T1R Regulated Memristor Conductance Control Array Architecture for Neuromorphic Computing using 28nm CMOS Technology</title>
      <link>https://arxiv.org/abs/2505.12830</link>
      <description>arXiv:2505.12830v1 Announce Type: new 
Abstract: Memristors are promising devices for scalable and low power, in-memory computing to improve the energy efficiency of a rising computational demand. The crossbar array architecture with memristors is used for vector matrix multiplication (VMM) and acts as kernels in neuromorphic computing. The analog conductance control in a memristor is achieved by applying voltage or current through it. A basic 1T1R array is suitable to avoid sneak path issues but suffer from wire resistances, which affects the read and write procedures. A conductance control scheme with a regulated voltage source will improve the architecture and reduce the possible potential divider effects. A change in conductance is also possible with the provision of a regulated current source and measuring the voltage across the memristors. A regulated 2T1R memristor conductance control architecture is proposed in this work, which avoids the potential divider effect and virtual ground scenario in a regular crossbar scheme, as well as conductance control by passing a regulated current through memristors. The sneak path current is not allowed to pass by the provision of ground potential to both terminals of memristors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12830v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neethu Kuriakose (Central Institute of Engineering, Electronics and Analytics -- Electronic Systems), Arun Ashok (Central Institute of Engineering, Electronics and Analytics -- Electronic Systems), Christian Grewing (Central Institute of Engineering, Electronics and Analytics -- Electronic Systems), Andr\'e Zambanini (Central Institute of Engineering, Electronics and Analytics -- Electronic Systems), Stefan van Waasen (Central Institute of Engineering, Electronics and Analytics -- Electronic Systems, Faculty of Engineering, Communication Systems, University of Duisburg-Essen, 47057 Duisburg, Germany)</dc:creator>
    </item>
    <item>
      <title>Towards Sustainability in 6G Network Slicing with Energy-Saving and Optimization Methods</title>
      <link>https://arxiv.org/abs/2505.12132</link>
      <description>arXiv:2505.12132v1 Announce Type: cross 
Abstract: The 6G mobile network is the next evolutionary step after 5G, with a prediction of an explosive surge in mobile traffic. It provides ultra-low latency, higher data rates, high device density, and ubiquitous coverage, positively impacting services in various areas. Energy saving is a major concern for new systems in the telecommunications sector because all players are expected to reduce their carbon footprints to contribute to mitigating climate change. Network slicing is a fundamental enabler for 6G/5G mobile networks and various other new systems, such as the Internet of Things (IoT), Internet of Vehicles (IoV), and Industrial IoT (IIoT). However, energy-saving methods embedded in network slicing architectures are still a research gap. This paper discusses how to embed energy-saving methods in network-slicing architectures that are a fundamental enabler for nearly all new innovative systems being deployed worldwide. This paper's main contribution is a proposal to save energy in network slicing. That is achieved by deploying ML-native agents in NS architectures to dynamically orchestrate and optimize resources based on user demands. The SFI2 network slicing reference architecture is the concrete use case scenario in which contrastive learning improves energy saving for resource allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12132v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.15449843</arxiv:DOI>
      <dc:creator>Rodrigo Moreira, Tereza C. M. Carvalho, Fl\'avio de Oliveira Silva, Nazim Agoulmine, Joberto S. B. Martins</dc:creator>
    </item>
    <item>
      <title>Hardware-Adaptive and Superlinear-Capacity Memristor-based Associative Memory</title>
      <link>https://arxiv.org/abs/2505.12960</link>
      <description>arXiv:2505.12960v1 Announce Type: cross 
Abstract: Brain-inspired computing aims to mimic cognitive functions like associative memory, the ability to recall complete patterns from partial cues. Memristor technology offers promising hardware for such neuromorphic systems due to its potential for efficient in-memory analog computing. Hopfield Neural Networks (HNNs) are a classic model for associative memory, but implementations on conventional hardware suffer from efficiency bottlenecks, while prior memristor-based HNNs faced challenges with vulnerability to hardware defects due to offline training, limited storage capacity, and difficulty processing analog patterns. Here we introduce and experimentally demonstrate on integrated memristor hardware a new hardware-adaptive learning algorithm for associative memories that significantly improves defect tolerance and capacity, and naturally extends to scalable multilayer architectures capable of handling both binary and continuous patterns. Our approach achieves 3x effective capacity under 50% device faults compared to state-of-the-art methods. Furthermore, its extension to multilayer architectures enables superlinear capacity scaling (\(\propto N^{1.49}\ for binary patterns) and effective recalling of continuous patterns (\propto N^{1.74}\ scaling), as compared to linear capacity scaling for previous HNNs. It also provides flexibility to adjust capacity by tuning hidden neurons for the same-sized patterns. By leveraging the massive parallelism of the hardware enabled by synchronous updates, it reduces energy by 8.8x and latency by 99.7% for 64-dimensional patterns over asynchronous schemes, with greater improvements at scale. This promises the development of more reliable memristor-based associative memory systems and enables new applications research due to the significantly improved capacity, efficiency, and flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12960v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengping He, Mingrui Jiang, Keyi Shan, Szu-Hao Yang, Zefan Li, Shengbo Wang, Giacomo Pedretti, Jim Ignowski, Can Li</dc:creator>
    </item>
    <item>
      <title>Physics-Aware Compilation for Parallel Quantum Circuit Execution on Neutral Atom Arrays</title>
      <link>https://arxiv.org/abs/2505.13049</link>
      <description>arXiv:2505.13049v1 Announce Type: cross 
Abstract: Neutral atom quantum computers are one of the most promising quantum architectures, offering advantages in scalability, dynamic reconfigurability, and potential for large-scale implementations. These characteristics create unique compilation challenges, especially regarding compilation efficiency while adapting to hardware flexibility. However, existing methods encounter significant performance bottlenecks at scale, hindering practical applications. We propose Physics-Aware Compilation (PAC), a method that improves compilation efficiency while preserving the inherent flexibility of neutral atom systems. PAC introduces physics-aware hardware plane partitioning that strategically allocates hardware resources based on physical device characteristics like AOD and SLM trap properties and qubit mobility constraints. Additionally, it implements parallel quantum circuit division with an improved Kernighan-Lin algorithm that enables simultaneous execution across independent regions while maintaining circuit fidelity. Our experimental evaluation compares PAC with state-of-the-art methods across increasingly larger array sizes ranging from 16x16 to 64x64 qubits. Results demonstrate that PAC achieves up to 78.5x speedup on 16x16 arrays while maintaining comparable circuit quality. PAC's compilation efficiency advantage increases with system scale, demonstrating scalability for practical quantum applications on larger arrays. PAC explores a viable path for practical applications of neutral atom quantum computers by effectively addressing the tension between compilation efficiency and hardware flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13049v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Chen, Guowu Yang, Wenjie Sun, Lianhui Yu, Guangwei Deng, Desheng Zheng, Xiaoyu Li</dc:creator>
    </item>
    <item>
      <title>A Path to Universal Neural Cellular Automata</title>
      <link>https://arxiv.org/abs/2505.13058</link>
      <description>arXiv:2505.13058v1 Announce Type: cross 
Abstract: Cellular automata have long been celebrated for their ability to generate complex behaviors from simple, local rules, with well-known discrete models like Conway's Game of Life proven capable of universal computation. Recent advancements have extended cellular automata into continuous domains, raising the question of whether these systems retain the capacity for universal computation. In parallel, neural cellular automata have emerged as a powerful paradigm where rules are learned via gradient descent rather than manually designed. This work explores the potential of neural cellular automata to develop a continuous Universal Cellular Automaton through training by gradient descent. We introduce a cellular automaton model, objective functions and training strategies to guide neural cellular automata toward universal computation in a continuous setting. Our experiments demonstrate the successful training of fundamental computational primitives - such as matrix multiplication and transposition - culminating in the emulation of a neural network solving the MNIST digit classification task directly within the cellular automata state. These results represent a foundational step toward realizing analog general-purpose computers, with implications for understanding universal computation in continuous dynamics and advancing the automated discovery of complex cellular automata behaviors via machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13058v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3712255.3734310</arxiv:DOI>
      <dc:creator>Gabriel B\'ena, Maxence Faldor, Dan F. M. Goodman, Antoine Cully</dc:creator>
    </item>
    <item>
      <title>Learning Driven Elastic Task Multi-Connectivity Immersive Computing Systems</title>
      <link>https://arxiv.org/abs/2505.13331</link>
      <description>arXiv:2505.13331v1 Announce Type: cross 
Abstract: In virtual reality (VR) environments, computational tasks exhibit an elastic nature, meaning they can dynamically adjust based on various user and system constraints. This elasticity is essential for maintaining immersive experiences; however, it also introduces challenges for communication and computing in VR systems. In this paper, we investigate elastic task offloading for multi-user edge-computing-enabled VR systems with multi-connectivity, aiming to maximize the computational energy-efficiency (computational throughput per unit of energy consumed). To balance the induced communication, computation, energy consumption, and quality of experience trade-offs due to the elasticity of VR tasks, we formulate a constrained stochastic computational energy-efficiency optimization problem that integrates the multi-connectivity/multi-user action space and the elastic nature of VR computational tasks. We formulate a centralized phasic policy gradient (CPPG) framework to solve the problem of interest online, using only prior elastic task offloading statistics (energy consumption, response time, and transmission time), and task information (i.e., task size and computational intensity), while observing the induced system performance (energy consumption and latency). We further extend our approach to decentralized learning by formulating an independent phasic policy gradient (IPPG) method and a decentralized shared multi-armed bandit (DSMAB) method. We train our methods with real-world 4G, 5G, and WiGig network traces and 360 video datasets to evaluate their performance in terms of response time, energy efficiency, scalability, and delivered quality of experience. We also provide a comprehensive analysis of task size and its effect on offloading policy and system performance. In particular, we show that CPPG reduces latency by 28% and energy consumption by 78% compared to IPPG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13331v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <category>cs.MM</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Babak Badnava, Jacob Chakareski, Morteza Hashemi</dc:creator>
    </item>
    <item>
      <title>Neural-Enhanced Rate Adaptation and Computation Distribution for Emerging mmWave Multi-User 3D Video Streaming Systems</title>
      <link>https://arxiv.org/abs/2505.13337</link>
      <description>arXiv:2505.13337v1 Announce Type: cross 
Abstract: We investigate multitask edge-user communication-computation resource allocation for $360^\circ$ video streaming in an edge-computing enabled millimeter wave (mmWave) multi-user virtual reality system. To balance the communication-computation trade-offs that arise herein, we formulate a video quality maximization problem that integrates interdependent multitask/multi-user action spaces and rebuffering time/quality variation constraints. We formulate a deep reinforcement learning framework for \underline{m}ulti-\underline{t}ask \underline{r}ate adaptation and \underline{c}omputation distribution (MTRC) to solve the problem of interest. Our solution does not rely on a priori knowledge about the environment and uses only prior video streaming statistics (e.g., throughput, decoding time, and transmission delay), and content information, to adjust the assigned video bitrates and computation distribution, as it observes the induced streaming performance online. Moreover, to capture the task interdependence in the environment, we leverage neural network cascades to extend our MTRC method to two novel variants denoted as R1C2 and C1R2. We train all three methods with real-world mmWave network traces and $360^\circ$ video datasets to evaluate their performance in terms of expected quality of experience (QoE), viewport peak signal-to-noise ratio (PSNR), rebuffering time, and quality variation. We outperform state-of-the-art rate adaptation algorithms, with C1R2 showing best results and achieving $5.21-6.06$ dB PSNR gains, $2.18-2.70$x rebuffering time reduction, and $4.14-4.50$ dB quality variation reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13337v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>cs.MM</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Babak Badnava, Jacob Chakareski, Morteza Hashemi</dc:creator>
    </item>
    <item>
      <title>Pipelining Kruskal's: A Neuromorphic Approach for Minimum Spanning Tree</title>
      <link>https://arxiv.org/abs/2505.10771</link>
      <description>arXiv:2505.10771v2 Announce Type: replace 
Abstract: Neuromorphic computing, characterized by its event-driven computation and massive parallelism, is particularly effective for handling data-intensive tasks in low-power environments, such as computing the minimum spanning tree (MST) for large-scale graphs. The introduction of dynamic synaptic modifications provides new design opportunities for neuromorphic algorithms. Building on this foundation, we propose an SNN-based union-sort routine and a pipelined version of Kruskal's algorithm for MST computation. The event-driven nature of our method allows for the concurrent execution of two completely decoupled stages: neuromorphic sorting and union-find. Our approach demonstrates superior performance compared to state-of-the-art Prim 's-based methods on large-scale graphs from the DIMACS10 dataset, achieving speedups by 269.67x to 1283.80x, with a median speedup of 540.76x. We further evaluate the pipelined implementation against two serial variants of Kruskal's algorithm, which rely on neuromorphic sorting and neuromorphic radix sort, showing significant performance advantages in most scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10771v2</guid>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yee Hin Chong, Peng Qu, Yuchen Li, Youhui Zhang</dc:creator>
    </item>
    <item>
      <title>Accelerating Simulation of Quantum Circuits under Noise via Computational Reuse</title>
      <link>https://arxiv.org/abs/2203.13892</link>
      <description>arXiv:2203.13892v2 Announce Type: replace-cross 
Abstract: To realize the full potential of quantum computers, we must mitigate qubit errors by developing noise-aware algorithms, compilers, and architectures. Thus, simulating quantum programs on high-performance computing (HPC) systems with different noise models is a de facto tool researchers use. Unfortunately, noisy simulators iteratively execute a similar circuit for thousands of trials, thereby incurring significant performance overheads.
  To address this, we propose a noisy simulation technique called Tree-Based Quantum Circuit Simulation (TQSim). TQSim exploits the reusability of intermediate results during the noisy simulation, reducing computation. TQSim dynamically partitions a circuit into several subcircuits. It then reuses the intermediate results from these subcircuits during computation. Compared to a noisy Qulacs-based baseline simulator, TQSim achieves a speedup of up to 3.89x for noisy simulations. TQSim is designed to be efficient with multi-node setups while also maintaining tight fidelity bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.13892v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3695053.3730992</arxiv:DOI>
      <dc:creator>Meng Wang, Swamit Tannu, Prashant J. Nair</dc:creator>
    </item>
    <item>
      <title>DAOs of Collective Intelligence? Unraveling the Complexity of Blockchain Governance in Decentralized Autonomous Organizations</title>
      <link>https://arxiv.org/abs/2409.01823</link>
      <description>arXiv:2409.01823v2 Announce Type: replace-cross 
Abstract: Decentralized autonomous organizations (DAOs) have transformed organizational structures by shifting from traditional hierarchical control to decentralized approaches, leveraging blockchain and cryptoeconomics. Despite managing significant funds and building global networks, DAOs face challenges like declining participation, increasing centralization, and inabilities to adapt to changing environments, which stifle innovation. This paper explores DAOs as complex systems and applies complexity science to explain their inefficiencies. In particular, we discuss DAO challenges, their complex nature, and introduce the self-organization mechanisms of collective intelligence, digital democracy, and adaptation. By applying these mechanisms to refine DAO design and construction, a conceptual framework for assessing a DAO's viability is created. This contribution lays the foundation for future research at the intersection of complexity science, digital democracy and DAOs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01823v2</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark C. Ballandies, Dino Carpentras, Evangelos Pournaras</dc:creator>
    </item>
    <item>
      <title>Cross-Chain Options: A Bridgeless, Universal, and Efficient Approach</title>
      <link>https://arxiv.org/abs/2410.15724</link>
      <description>arXiv:2410.15724v3 Announce Type: replace-cross 
Abstract: Options are fundamental to blockchain-based financial services, offering essential tools for risk management and price speculation, which enhance liquidity, flexibility, and market efficiency in decentralized finance (DeFi). Despite the growing interest in options for blockchain-resident assets, such as cryptocurrencies, current option mechanisms face significant challenges, including a high reliance on trusted third parties, limited asset support, high trading delays, and the requirement for option holders to provide upfront collateral.
  In this paper, we present a protocol that addresses the aforementioned issues. Our protocol is the first to eliminate the need for holders to post collateral when establishing options in trustless service environments (i.e. without a cross-chain bridge), which is achieved by introducing a guarantee from the option writer. Its universality allows for cross-chain options involving nearly \textit{any} assets on \textit{any} two different blockchains, provided the chains' programming languages can enforce and execute the necessary contract logic. Another key innovation is reducing option position transfer latency, which uses Double-Authentication-Preventing Signatures (DAPS). Our evaluation demonstrates that the proposed scheme reduces option transfer latency to less than half of that in existing methods. Rigorous security analysis proves that our protocol achieves secure option trading, even when facing adversarial behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15724v3</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zifan Peng, Yingjie Xue, Jingyu Liu</dc:creator>
    </item>
  </channel>
</rss>
