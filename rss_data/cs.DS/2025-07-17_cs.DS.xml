<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Jul 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Finite Pinwheel Scheduling: the k-Visits Problem</title>
      <link>https://arxiv.org/abs/2507.11681</link>
      <description>arXiv:2507.11681v1 Announce Type: new 
Abstract: Pinwheel Scheduling is a fundamental scheduling problem, in which each task $i$ is associated with a positive integer $d_i$, and the objective is to schedule one task per time slot, ensuring each task perpetually appears at least once in every $d_i$ time slots. Although conjectured to be PSPACE-complete, it remains open whether Pinwheel Scheduling is NP-hard (unless a compact input encoding is used) or even contained in NP.
  We introduce k-Visits, a finite version of Pinwheel Scheduling, where given n deadlines, the goal is to schedule each task exactly k times. While we observe that the 1-Visit problem is trivial, we prove that 2-Visits is strongly NP-complete through a surprising reduction from Numerical 3-Dimensional Matching (N3DM). As intermediate steps in the reduction, we define NP-complete variants of N3DM which may be of independent interest. We further extend our strong NP-hardness result to a generalization of k-Visits $k\geq 2$ in which the deadline of each task may vary throughout the schedule, as well as to a similar generalization of Pinwheel Scheduling, thus making progress towards settling the complexity of Pinwheel Scheduling.
  Additionally, we prove that 2-Visits can be solved in linear time if all deadlines are distinct, rendering it one of the rare natural problems which exhibit the interesting dichotomy of being in P if their input is a set and NP-complete if the input is a multiset. We achieve this through a Turing reduction from 2-Visits to a variation of N3DM, which we call Position Matching. Based on this reduction, we also show an FPT algorithm for 2-Visits parameterized by a value related to how close the input deadlines are to each other, as well as a linear-time algorithm for instances with up to two distinct deadlines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11681v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sotiris Kanellopoulos, Christos Pergaminelis, Maria Kokkou, Euripides Markou, Aris Pagourtzis</dc:creator>
    </item>
    <item>
      <title>Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure</title>
      <link>https://arxiv.org/abs/2507.11724</link>
      <description>arXiv:2507.11724v1 Announce Type: new 
Abstract: We provide new high-accuracy randomized algorithms for solving linear systems and regression problems that are well-conditioned except for $k$ large singular values. For solving such $d \times d$ positive definite system our algorithms succeed whp. and run in time $\tilde O(d^2 + k^\omega)$. For solving such regression problems in a matrix $\mathbf{A} \in \mathbb{R}^{n \times d}$ our methods succeed whp. and run in time $\tilde O(\mathrm{nnz}(\mathbf{A}) + d^2 + k^\omega)$ where $\omega$ is the matrix multiplication exponent and $\mathrm{nnz}(\mathbf{A})$ is the number of non-zeros in $\mathbf{A}$. Our methods nearly-match a natural complexity limit under dense inputs for these problems and improve upon a trade-off in prior approaches that obtain running times of either $\tilde O(d^{2.065}+k^\omega)$ or $\tilde O(d^2 + dk^{\omega-1})$ for $d\times d$ systems. Moreover, we show how to obtain these running times even under the weaker assumption that all but $k$ of the singular values have a suitably bounded generalized mean. Consequently, we give the first nearly-linear time algorithm for computing a multiplicative approximation to the nuclear norm of an arbitrary dense matrix. Our algorithms are built on three general recursive preconditioning frameworks, where matrix sketching and low-rank update formulas are carefully tailored to the problems' structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11724v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Pathfinding in Self-Deleting Graphs</title>
      <link>https://arxiv.org/abs/2507.12047</link>
      <description>arXiv:2507.12047v1 Announce Type: new 
Abstract: In this paper, we study the problem of pathfinding on traversal-dependent graphs, i.e., graphs whose edges change depending on the previously visited vertices. In particular, we study \emph{self-deleting graphs}, introduced by Carmesin et al. (Sarah Carmesin, David Woller, David Parker, Miroslav Kulich, and Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson problems with traversal-dependent edge deletion. J. Comput. Sci.), which consist of a graph $G=(V, E)$ and a function $f\colon V\rightarrow 2^E$, where $f(v)$ is the set of edges that will be deleted after visiting the vertex $v$. In the \textsc{(Shortest) Self-Deleting $s$-$t$-path} problem we are given a self-deleting graph and its vertices $s$ and $t$, and we are asked to find a (shortest) path from $s$ to $t$, such that it does not traverse an edge in $f(v)$ after visiting $v$ for any vertex $v$.
  We prove that \textsc{Self-Deleting $s$-$t$-path} is NP-hard even if the given graph is outerplanar, bipartite, has maximum degree $3$, bandwidth $2$ and $|f(v)|\leq 1$ for each vertex $v$. We show that \textsc{Shortest Self-Deleting $s$-$t$-path} is W[1]-complete parameterized by the length of the sought path and that \textsc{Self-Deleting $s$-$t$-path} is \W{1}-complete parameterized by the vertex cover number, feedback vertex set number and treedepth. We also show that the problem becomes FPT when we parameterize by the maximum size of $f(v)$ and several structural parameters. Lastly, we show that the problem does not admit a polynomial kernel even for parameterization by the vertex cover number and the maximum size of $f(v)$ combined already on 2-outerplanar graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12047v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Dvo\v{r}\'ak, Du\v{s}an Knop, Michal Opler, Jan Pokorn\'y, Ond\v{r}ej Such\'y, Krisztina Szil\'agyi</dc:creator>
    </item>
    <item>
      <title>Weighted $k$-Server Admits an Exponentially Competitive Algorithm</title>
      <link>https://arxiv.org/abs/2507.12130</link>
      <description>arXiv:2507.12130v1 Announce Type: new 
Abstract: The weighted $k$-server is a variant of the $k$-server problem, where the cost of moving a server is the server's weight times the distance through which it moves. The problem is famous for its intriguing properties and for evading standard techniques for designing and analyzing online algorithms. Even on uniform metric spaces with sufficiently many points, the deterministic competitive ratio of weighted $k$-server is known to increase doubly exponentially with respect to $k$, while the behavior of its randomized competitive ratio is not fully understood. Specifically, no upper bound better than doubly exponential is known, while the best known lower bound is singly exponential in $k$. In this paper, we close the exponential gap between these bounds by giving an $\exp(O(k^2))$-competitive randomized online algorithm for the weighted $k$-server problem on uniform metrics, thus breaking the doubly exponential barrier for deterministic algorithms for the first time. This is achieved by a recursively defined notion of a phase which, on the one hand, forces a lower bound on the cost of any offline solution, while, on the other hand, also admits a randomized online algorithm with bounded expected cost. The algorithm is also recursive; it involves running several algorithms virtually and in parallel and following the decisions of one of them in a random order. We also show that our techniques can be lifted to construct an $\exp(O(k^2))$-competitive randomized online algorithm for the generalized $k$-server problem on weighted uniform metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12130v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adithya Bijoy, Ankit Mondal, Ashish Chiplunkar</dc:creator>
    </item>
    <item>
      <title>A near-complete resolution of the exponential-time complexity of k-opt for the traveling salesman problem</title>
      <link>https://arxiv.org/abs/2507.12304</link>
      <description>arXiv:2507.12304v1 Announce Type: new 
Abstract: The $k$-opt algorithm is one of the simplest and most widely used heuristics for solving the traveling salesman problem. Starting from an arbitrary tour, the $k$-opt algorithm improves the current tour in each iteration by exchanging up to $k$ edges. The algorithm continues until no further improvement of this kind is possible. For a long time, it remained an open question how many iterations the $k$-opt algorithm might require for small values of $k$, assuming the use of an optimal pivot rule. In this paper, we resolve this question for the cases $k = 3$ and $k = 4$ by proving that in both these cases an exponential number of iterations may be needed even if an optimal pivot rule is used. Combined with a recent result from Heimann, Hoang, and Hougardy (ICALP 2024), this provides a complete answer for all $k \geq 3$ regarding the number of iterations the $k$-opt algorithm may require under an optimal pivot rule. In addition we establish an analogous exponential lower bound for the 2.5-opt algorithm, a variant that generalizes 2-opt and is a restricted version of 3-opt. All our results hold for both the general and the metric traveling salesman problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12304v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sophia Heimann, Hung P. Hoang, Stefan Hougardy</dc:creator>
    </item>
    <item>
      <title>Online Block Packing</title>
      <link>https://arxiv.org/abs/2507.12357</link>
      <description>arXiv:2507.12357v1 Announce Type: new 
Abstract: We consider the algorithmic challenge that is faced by blockchains that have multidimensional block constraints and serve quasi-patient bidders. We provide online approximation algorithms for this problem, thus solving open problems left by [Babaioff and Nisan, EC 2025].</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12357v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Ben Eliezer, Noam Nisan</dc:creator>
    </item>
    <item>
      <title>Kernelization for list $H$-coloring for graphs with small vertex cover</title>
      <link>https://arxiv.org/abs/2507.12005</link>
      <description>arXiv:2507.12005v1 Announce Type: cross 
Abstract: For a fixed graph $H$, in the List $H$-Coloring problem, we are given a graph $G$ along with list $L(v) \subseteq V(H)$ for every $v \in V(G)$, and we have to determine if there exists a list homomorphism $\varphi$ from $(G,L)$ to $H$, i.e., an edge preserving mapping $\varphi: V(G)\to V(H)$ that satisfies $\varphi(v)\in L(v)$ for every $v\in V(G)$. Note that if $H$ is the complete graph on $q$ vertices, the problem is equivalent to List $q$-Coloring. We investigate the kernelization properties of List $H$-Coloring parameterized by the vertex cover number of $G$: given an instance $(G,L)$ and a vertex cover of $G$ of size $k$, can we reduce $(G,L)$ to an equivalent instance $(G',L')$ of List $H$-Coloring where the size of $G'$ is bounded by a low-degree polynomial $p(k)$ in $k$? This question has been investigated previously by Jansen and Pieterse [Algorithmica 2019], who provided an upper bound, which turns out to be optimal if $H$ is a complete graph, i.e., for List $q$-Coloring. This result was one of the first applications of the method of kernelization via bounded-degree polynomials. We define two new integral graph invariants, $c^*(H)$ and $d^*(H)$, with $d^*(H) \leq c^*(H) \leq d^*(H)+1$, and show that for every graph $H$, List $H$-Coloring
  -- has a kernel with $\mathcal{O}(k^{c^*(H)})$ vertices,
  -- admits no kernel of size $\mathcal{O}(k^{d^*(H)-\varepsilon})$ for any $\varepsilon &gt; 0$, unless the polynomial hierarchy collapses.
  -- Furthermore, if $c^*(H) &gt; d^*(H)$, then there is a kernel with $\mathcal{O}(k^{c^*(H)-\varepsilon})$ vertices where $\varepsilon \geq 2^{1-c^*(H)}$.
  Additionally, we show that for some classes of graphs, including powers of cycles and graphs $H$ where $\Delta(H) \leq c^*(H)$ (which in particular includes cliques), the bound $d^*(H)$ is tight, using the polynomial method. We conjecture that this holds in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12005v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Piecyk, Astrid Pieterse, Pawe{\l} Rz\k{a}\.zewski, Magnus Wahlstr\"om</dc:creator>
    </item>
    <item>
      <title>FastReChain: Highly Responsive and Low-Overhead Centralized Route Scheduling in Clos Datacenter Networks</title>
      <link>https://arxiv.org/abs/2507.12265</link>
      <description>arXiv:2507.12265v1 Announce Type: cross 
Abstract: Ever since Clos topologies were used in datacenter networks (DCNs), a practical centralized scheduling algorithm that supports dynamic scheduling has been absent. The introduction of optical switches in DCNs as a future-proof solution exacerbates this problem due to several properties of optical switches, such as the fact that they are generally bufferless and therefore rely on centralized scheduling, and that they have long switching times and therefore require the number of rearrangements to be minimized.
  In this paper, we propose a centralized scheduling algorithm that achieves theoretical maximum throughput even in one-rate bidirectional Clos networks, while producing schemes with near-minimal numbers of rearrangements. It is the only algorithm that directly supports bidirectional Clos networks and has a time efficiency high enough to support dynamic scheduling to date. For static minimal rewiring, its running time ranges from a fraction to a few hundredths of other algorithms, and the number of rearrangements has also been steadily improved, allowing for more frequent adjustments and less impact on ongoing communications. In addition, the algorithm is very flexible and can support various functional requirements in real-world environments. We achieve this result through the replacement chain concept and bitset optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12265v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Zihan Zhu, Dongchao Wu, Zhanbang Zhang, Jian Yang</dc:creator>
    </item>
    <item>
      <title>Matroid-Based TSP Rounding for Half-Integral Solutions</title>
      <link>https://arxiv.org/abs/2111.09290</link>
      <description>arXiv:2111.09290v2 Announce Type: replace 
Abstract: We show how to round any half-integral solution to the subtour-elimination relaxation for the TSP, while losing a less-than-1.5 factor. Such a rounding algorithm was recently given by Karlin, Klein, and Oveis Gharan based on sampling from max-entropy distributions. We build on an approach of Haddadan and Newman to show how sampling from the matroid intersection polytope, and a new use of max-entropy sampling, can give better guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.09290v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupam Gupta, Euiwoong Lee, Jason Li, Marcin Mucha, Heather Newman, Sherry Sarkar</dc:creator>
    </item>
    <item>
      <title>Minimizing Tardy Processing Time on a Single Machine in Near-Linear Time</title>
      <link>https://arxiv.org/abs/2402.13357</link>
      <description>arXiv:2402.13357v3 Announce Type: replace 
Abstract: In this work we revisit the elementary scheduling problem $1||\sum p_j U_j$. The goal is to select, among $n$ jobs with processing times and due dates, a subset of jobs with maximum total processing time that can be scheduled in sequence without violating their due dates. This problem is NP-hard, but a classical algorithm by Lawler and Moore from the 60s solves this problem in pseudo-polynomial time $O(nP)$, where $P$ is the total processing time of all jobs. With the aim to develop best-possible pseudo-polynomial-time algorithms, a recent wave of results has improved Lawler and Moore's algorithm for $1||\sum p_j U_j$: First to time $\tilde O(P^{7/4})$ [Bringmann, Fischer, Hermelin, Shabtay, Wellnitz; ICALP'20], then to time $\tilde O(P^{5/3})$ [Klein, Polak, Rohwedder; SODA'23], and finally to time $\tilde O(P^{7/5})$ [Schieber, Sitaraman; WADS'23]. It remained an exciting open question whether these works can be improved further.
  In this work we develop an algorithm in near-linear time $\tilde O(P)$ for the $1||\sum p_j U_j$ problem. This running time not only significantly improves upon the previous results, but also matches conditional lower bounds based on the Strong Exponential Time Hypothesis or the Set Cover Hypothesis and is therefore likely optimal (up to subpolynomial factors). Our new algorithm also extends to the case of $m$ machines in time $\tilde O(P^m)$. In contrast to the previous improvements, we take a different, more direct approach inspired by the recent reductions from Modular Subset Sum to dynamic string problems. We thereby arrive at a satisfyingly simple algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13357v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.14</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 14, 1-17</arxiv:journal_reference>
      <dc:creator>Nick Fischer, Leo Wennmann</dc:creator>
    </item>
    <item>
      <title>Finding Order-Preserving Subgraphs</title>
      <link>https://arxiv.org/abs/2507.11115</link>
      <description>arXiv:2507.11115v2 Announce Type: replace 
Abstract: (Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are fundamental problems in graph pattern matching and similarity computation. In graphs derived from time-series data or protein structures, a natural total ordering of vertices often arises from their underlying structure, such as temporal sequences or amino acid sequences. This motivates the study of problem variants that respect this inherent ordering. This paper addresses Ordered (Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common Ordered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms that preserve the vertex orderings of two given ordered graphs. Our main contributions are threefold: (1) We prove that these problems remain NP-complete even when restricted to small graph classes, such as trees of depth 2 and threshold graphs. (2) We establish a gap in computational complexity between OSI and OISI on certain graph classes. For instance, OSI is polynomial-time solvable for interval graphs with their interval orderings, whereas OISI remains NP-complete under the same setting. (3) We demonstrate that the tractability of these problems can depend on the vertex ordering. For example, while OISI is NP-complete on threshold graphs, its generalization, MCOIS, can be solved in polynomial time if the specific vertex orderings that characterize the threshold graphs are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11115v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haruya Imamura, Yasuaki Kobayashi, Yota Otachi, Toshiki Saitoh, Keita Sato, Asahi Takaoka, Ryo Yoshinaka, Tom C. van der Zanden</dc:creator>
    </item>
    <item>
      <title>Fully Dynamic Euclidean k-Means</title>
      <link>https://arxiv.org/abs/2507.11256</link>
      <description>arXiv:2507.11256v2 Announce Type: replace 
Abstract: We consider the fundamental Euclidean $k$-means clustering problem in a dynamic setting, where the input $X \subseteq \mathbb{R}^d$ evolves over time via a sequence of point insertions/deletions. We have to explicitly maintain a solution (a set of $k$ centers) $S \subseteq \mathbb{R}^d$ throughout these updates, while minimizing the approximation ratio, the update time (time taken to handle a point insertion/deletion) and the recourse (number of changes made to the solution $S$) of the algorithm.
  We present a dynamic algorithm for this problem with $\text{poly}(1/\epsilon)$-approximation ratio, $\tilde{O}(k^{\epsilon})$ update time and $\tilde{O}(1)$ recourse. In the general regime, where the dimension $d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal guarantees across all these three parameters. Indeed, improving our update time or approximation ratio would imply beating the state-of-the-art static algorithm for this problem (which is widely believed to be the best possible), and the recourse of any dynamic algorithm must be $\Omega(1)$.
  We obtain our result by building on top of the recent work of [Bhattacharya, Costa, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for $k$-means in general metric spaces (as opposed to in the Euclidean setting). Along the way, we design several novel geometric data structures that are of independent interest. Specifically, one of our main contributions is designing the first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\'y, Yang; FOCS'22] that achieves $\tilde O(n^\epsilon)$ running time per point evaluation with competitive parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11256v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sayan Bhattacharya, Mart\'in Costa, Ermiya Farokhnejad, Shaofeng H. -C. Jiang, Yaonan Jin, Jianing Lou</dc:creator>
    </item>
    <item>
      <title>Multipass Linear Sketches for Geometric LP-Type Problems</title>
      <link>https://arxiv.org/abs/2507.11484</link>
      <description>arXiv:2507.11484v2 Announce Type: replace 
Abstract: LP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support Vector Machine (SVM), Linear Programming (LP), and Semidefinite Programming (SDP) are fundamental combinatorial optimization problems, with many important applications in machine learning applications such as classification, bioinformatics, and noisy learning. We study LP-type problems in several streaming and distributed big data models, giving $\varepsilon$-approximation linear sketching algorithms with a focus on the high accuracy regime with low dimensionality $d$, that is, when ${d &lt; (1/\varepsilon)^{0.999}}$. Our main result is an $O(ds)$ pass algorithm with $O(s( \sqrt{d}/\varepsilon)^{3d/s}) \cdot \mathrm{poly}(d, \log (1/\varepsilon))$ space complexity in words, for any parameter $s \in [1, d \log (1/\varepsilon)]$, to solve $\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC dimension. Notably, by taking $s = d \log (1/\varepsilon)$, we achieve space complexity polynomial in $d$ and polylogarithmic in $1/\varepsilon$, presenting exponential improvements in $1/\varepsilon$ over current algorithms. We complement our results by showing lower bounds of $(1/\varepsilon)^{\Omega(d)}$ for any $1$-pass algorithm solving the $(1 + \varepsilon)$-approximation MEB and linear SVM problems, further motivating our multi-pass approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11484v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>N. Efe \c{C}ekirge, William Gay, David P. Woodruff</dc:creator>
    </item>
    <item>
      <title>Many Objective Problems Where Crossover is Provably Essential</title>
      <link>https://arxiv.org/abs/2412.18375</link>
      <description>arXiv:2412.18375v2 Announce Type: replace-cross 
Abstract: This article addresses theory in evolutionary many-objective optimization and focuses on the role of crossover operators. The advantages of using crossover are hardly understood and rigorous runtime analyses with crossover are lagging far behind its use in practice, specifically in the case of more than two objectives. We present two many-objective problems $RR_{\text{RO}}$ and $uRR_{\text{RO}}$ together with a theoretical runtime analysis of the GSEMO and the widely used NSGA-III algorithm to demonstrate that one point crossover on $RR_{\text{RO}}$, as well as uniform crossover on $uRR_{\text{RO}}$, can yield an exponential speedup in the runtime. In particular, when the number of objectives is constant, this algorithms can find the Pareto set of both problems in expected polynomial time when using crossover while without crossover they require exponential time to even find a single Pareto-optimal point. For both problems, we also demonstrate a significant performance gap in certain superconstant parameter regimes for the number of objectives. To the best of our knowledge, this is one of the first rigorous runtime analysis in many-objective optimization which demonstrates an exponential performance gap when using crossover for more than two objectives. Additionally, it is the first runtime analysis involving crossover in many-objective optimization where the number of objectives is not necessarily constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18375v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Andre Opris</dc:creator>
    </item>
  </channel>
</rss>
