<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 May 2024 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>RA: A machine based rational agent, Part 2, Preliminary test</title>
      <link>https://arxiv.org/abs/2405.16613</link>
      <description>arXiv:2405.16613v1 Announce Type: new 
Abstract: A preliminary test of the software package RA is presented. The main focus of this test is to assess RA`s reasoning capabilities that are based on the formal system PECR. Particular attention is given to the finite computational resources of the real-world machine that define the environment within which programs are to be executed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16613v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G. Pantelis</dc:creator>
    </item>
    <item>
      <title>Conjunctive categorial grammars and Lambek grammars with additives</title>
      <link>https://arxiv.org/abs/2405.16662</link>
      <description>arXiv:2405.16662v1 Announce Type: new 
Abstract: A new family of categorial grammars is proposed, defined by enriching basic categorial grammars with a conjunction operation. It is proved that the formalism obtained in this way has the same expressive power as conjunctive grammars, that is, context-free grammars enhanced with conjunction. It is also shown that categorial grammars with conjunction can be naturally embedded into the Lambek calculus with conjunction and disjunction operations. This further implies that a certain NP-complete set can be defined in the Lambek calculus with conjunction. We also show how to handle some subtle issues connected with the empty string. Finally, we prove that a language generated by a conjunctive grammar can be described by a Lambek grammar with disjunction (but without conjunction).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16662v1</guid>
      <category>cs.LO</category>
      <category>cs.CL</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stepan L. Kuznetsov, Alexander Okhotin</dc:creator>
    </item>
    <item>
      <title>Higher-Order Mathematical Operational Semantics</title>
      <link>https://arxiv.org/abs/2405.16708</link>
      <description>arXiv:2405.16708v1 Announce Type: new 
Abstract: Compositionality proofs in higher-order languages are notoriously involved, and general semantic frameworks guaranteeing compositionality are hard to come by. In particular, Turi and Plotkin's bialgebraic abstract GSOS framework, which provides off-the-shelf compositionality results for first-order languages, so far does not apply to higher-order languages. In the present work, we develop a theory of abstract GSOS specifications for higher-order languages, in effect transferring the core principles of Turi and Plotkin's framework to a higher-order setting. In our theory, the operational semantics of higher-order languages is represented by certain dinatural transformations that we term \emph{(pointed) higher-order GSOS laws}. We give a general compositionality result that applies to all systems specified in this way and discuss how compositionality of combinatory logics and the $\lambda$-calculus w.r.t.\ a strong variant of Abramsky's applicative bisimilarity are obtained as instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16708v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Goncharov, Stefan Milius, Lutz Schr\"oder, Stelios Tsampas, Henning Urbat</dc:creator>
    </item>
    <item>
      <title>Laurel: Generating Dafny Assertions Using Large Language Models</title>
      <link>https://arxiv.org/abs/2405.16792</link>
      <description>arXiv:2405.16792v1 Announce Type: new 
Abstract: Dafny is a popular verification language, which automates proofs by outsourcing them to an SMT solver. This automation is not perfect, however, and the solver often requires guidance in the form of helper assertions creating a burden for the proof engineer. In this paper, we propose Laurel, a tool that uses large language models (LLMs) to automatically generate helper assertions for Dafny programs. To improve the success rate of LLMs in this task, we design two domain-specific prompting techniques. First, we help the LLM determine the location of the missing assertion by analyzing the verifier's error message and inserting an assertion placeholder at that location. Second, we provide the LLM with example assertions from the same codebase, which we select based on a new lemma similarity metric. We evaluate our techniques on a dataset of helper assertions we extracted from three real-world Dafny codebases. Our evaluation shows that Laurel is able to generate over 50% of the required helper assertions given only a few attempts, making LLMs a usable and affordable tool to further automate practical program verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16792v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Mugnier, Emmanuel Anaya Gonzalez, Ranjit Jhala, Nadia Polikarpova, Yuanyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Program Synthesis is $\Sigma_3^0$-Complete</title>
      <link>https://arxiv.org/abs/2405.16997</link>
      <description>arXiv:2405.16997v1 Announce Type: new 
Abstract: This paper considers program synthesis in the context of computational hardness, asking the question: How hard is it to determine whether a given synthesis problem has a solution or not?
  To answer this question, this paper studies program synthesis for a basic imperative, Turing-complete language IMP, for which this paper proves that program synthesis is $\Sigma_3^0$-\emph{complete} in the arithmetical hierarchy. The proof of this fact relies on a fully constructive encoding of program synthesis (which is typically formulated as a second-order query) as a first-order formula in the standard model of arithmetic (i.e., Peano arithmetic). Constructing such a formula then allows us to reduce the decision problem for COF (the set of functions which diverge only on a finite set of inputs), which is well-known to be a $\Sigma_3^0$-complete problem, into the constructed first-order representation of synthesis.
  In addition to this main result, we also consider the hardness of variants of synthesis problems, such as those introduced in previous work to make program synthesis more tractable (e.g., synthesis over finite examples). To the best of our knowledge, this paper is the first to give a first-order characterization of program synthesis in general, and precisely define the computability of synthesis problems and their variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16997v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinwoo Kim</dc:creator>
    </item>
    <item>
      <title>A novel framework for systematic propositional formula simplification based on existential graphs</title>
      <link>https://arxiv.org/abs/2405.17072</link>
      <description>arXiv:2405.17072v1 Announce Type: new 
Abstract: This paper presents a novel simplification calculus for propositional logic derived from Peirce's existential graphs' rules of inference and implication graphs. Our rules can be applied to propositional logic formulae in nested form, are equivalence-preserving, guarantee a monotonically decreasing number of variables, clauses and literals, and maximise the preservation of structural problem information. Our techniques can also be seen as higher-level SAT preprocessing, and we show how one of our rules (TWSR) generalises and streamlines most of the known equivalence-preserving SAT preprocessing methods. In addition, we propose a simplification procedure based on the systematic application of two of our rules (EPR and TWSR) which is solver-agnostic and can be used to simplify large Boolean satisfiability problems and propositional formulae in arbitrary form, and we provide a formal analysis of its algorithmic complexity in terms of space and time. Finally, we show how our rules can be further extended with a novel n-ary implication graph to capture all known equivalence-preserving preprocessing procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17072v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jordina Franc\`es de Mas, Juliana Bowles</dc:creator>
    </item>
    <item>
      <title>Left-Linear Completion with AC Axioms</title>
      <link>https://arxiv.org/abs/2405.17109</link>
      <description>arXiv:2405.17109v1 Announce Type: new 
Abstract: We revisit completion modulo equational theories for left-linear term rewrite systems where unification modulo the theory is avoided and the normal rewrite relation can be used in order to decide validity questions. To that end, we give a new correctness proof for finite runs and establish a simulation result between the two inference systems known from the literature. Given a concrete reduction order, novel canonicity results show that the resulting complete systems are unique up to the representation of their rules' right-hand sides. Furthermore, we show how left-linear AC completion can be simulated by general AC completion. In particular, this result allows us to switch from the former to the latter at any point during a completion process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17109v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Niederhauser, Nao Hirokawa, Aart Middeldorp</dc:creator>
    </item>
    <item>
      <title>Stochastic Omega-Regular Verification and Control with Supermartingales</title>
      <link>https://arxiv.org/abs/2405.17304</link>
      <description>arXiv:2405.17304v1 Announce Type: new 
Abstract: We present for the first time a supermartingale certificate for $\omega$-regular specifications. We leverage the Robbins &amp; Siegmund convergence theorem to characterize supermartingale certificates for the almost-sure acceptance of Streett conditions on general stochastic processes, which we call Streett supermartingales. This enables effective verification and control of discrete-time stochastic dynamical models with infinite state space under $\omega$-regular and linear temporal logic specifications. Our result generalises reachability, safety, reach-avoid, persistence and recurrence specifications; our contribution applies to discrete-time stochastic dynamical models and probabilistic programs with discrete and continuous state spaces and distributions, and carries over to deterministic models and programs. We provide a synthesis algorithm for control policies and Streett supermartingales as proof certificates for $\omega$-regular objectives, which is sound and complete for supermartingales and control policies with polynomial templates and any stochastic dynamical model whose post-expectation is expressible as a polynomial. We additionally provide an optimisation of our algorithm that reduces the problem to satisfiability modulo theories, under the assumption that templates and post-expectation are in piecewise linear form. We have built a prototype and have demonstrated the efficacy of our approach on several exemplar $\omega$-regular verification and control synthesis problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17304v1</guid>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Abate, Mirco Giacobbe, Diptarko Roy</dc:creator>
    </item>
    <item>
      <title>Semantic Objective Functions: A distribution-aware method for adding logical constraints in deep learning</title>
      <link>https://arxiv.org/abs/2405.15789</link>
      <description>arXiv:2405.15789v1 Announce Type: cross 
Abstract: Issues of safety, explainability, and efficiency are of increasing concern in learning systems deployed with hard and soft constraints. Symbolic Constrained Learning and Knowledge Distillation techniques have shown promising results in this area, by embedding and extracting knowledge, as well as providing logical constraints during neural network training. Although many frameworks exist to date, through an integration of logic and information geometry, we provide a construction and theoretical framework for these tasks that generalize many approaches. We propose a loss-based method that embeds knowledge-enforces logical constraints-into a machine learning model that outputs probability distributions. This is done by constructing a distribution from the external knowledge/logic formula and constructing a loss function as a linear combination of the original loss function with the Fisher-Rao distance or Kullback-Leibler divergence to the constraint distribution. This construction includes logical constraints in the form of propositional formulas (Boolean variables), formulas of a first-order language with finite variables over a model with compact domain (categorical and continuous variables), and in general, likely applicable to any statistical model that was pretrained with semantic information. We evaluate our method on a variety of learning tasks, including classification tasks with logic constraints, transferring knowledge from logic formulas, and knowledge distillation from general distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15789v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miguel Angel Mendez-Lucero, Enrique Bojorquez Gallardo, Vaishak Belle</dc:creator>
    </item>
    <item>
      <title>Finite Groundings for ASP with Functions: A Journey through Consistency</title>
      <link>https://arxiv.org/abs/2405.15794</link>
      <description>arXiv:2405.15794v1 Announce Type: cross 
Abstract: Answer set programming (ASP) is a logic programming formalism used in various areas of artificial intelligence like combinatorial problem solving and knowledge representation and reasoning. It is known that enhancing ASP with function symbols makes basic reasoning problems highly undecidable. However, even in simple cases, state of the art reasoners, specifically those relying on a ground-and-solve approach, fail to produce a result. Therefore, we reconsider consistency as a basic reasoning problem for ASP. We show reductions that give an intuition for the high level of undecidability. These insights allow for a more fine-grained analysis where we characterize ASP programs as "frugal" and "non-proliferous". For such programs, we are not only able to semi-decide consistency but we also propose a grounding procedure that yields finite groundings on more ASP programs with the concept of "forbidden" facts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15794v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Gerlach (TU Dresden), David Carral (LIRMM, CRISAM, UM, CNRS, BOREAL), Markus Hecher (MIT)</dc:creator>
    </item>
    <item>
      <title>Defeaters and Eliminative Argumentation in Assurance 2.0</title>
      <link>https://arxiv.org/abs/2405.15800</link>
      <description>arXiv:2405.15800v1 Announce Type: cross 
Abstract: A traditional assurance case employs a positive argument in which reasoning steps, grounded on evidence and assumptions, sustain a top claim that has external significance. Human judgement is required to check the evidence, the assumptions, and the narrative justifications for the reasoning steps; if all are assessed good, then the top claim can be accepted.
  A valid concern about this process is that human judgement is fallible and prone to confirmation bias. The best defense against this concern is vigorous and skeptical debate and discussion in the manner of a dialectic or Socratic dialog. There is merit in recording aspects of this discussion for the benefit of subsequent developers and assessors. Defeaters are a means doing this: they express doubts about aspects of the argument and can be developed into subcases that confirm or refute the doubts, and can record them as documentation to assist future consideration.
  This report describes how defeaters, and multiple levels of defeaters, should be represented and assessed in Assurance 2.0 and its Clarissa/ASCE tool support. These mechanisms also support eliminative argumentation, which is a contrary approach to assurance, favored by some, that uses a negative argument to refute all reasons why the top claim could be false.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15800v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Robin Bloomfield, Kate Netkachova, John Rushby</dc:creator>
    </item>
    <item>
      <title>Uniform Algebras: Models and constructive Completeness for Full, Simply Typed {\lambda}Prolog</title>
      <link>https://arxiv.org/abs/2405.15822</link>
      <description>arXiv:2405.15822v1 Announce Type: cross 
Abstract: This paper introduces a model theory for resolution on Higher Order Hereditarily Harrop formulae (HOHH), the logic underlying the Lambda-Prolog programming language, and proves soundness and completeness of resolution. The semantics and the proof of completeness of the formal system is shown in several ways, suitably adapted to deal with the impredicativity of higher-order logic, which rules out definitions of truth based on induction on formula structure. First, we use the least fixed point of a certain operator on interpretations, in the style of Apt and Van Emden, Then a constructive completeness theorem is given using a proof theoretic variant of the Lindenbaum algebra, which also contains a new approach to establishing cut-elimination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15822v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gianluca Amato, Mary DeMarco, James Lipton</dc:creator>
    </item>
    <item>
      <title>CFGs: Causality Constrained Counterfactual Explanations using goal-directed ASP</title>
      <link>https://arxiv.org/abs/2405.15956</link>
      <description>arXiv:2405.15956v1 Announce Type: cross 
Abstract: Machine learning models that automate decision-making are increasingly used in consequential areas such as loan approvals, pretrial bail approval, and hiring. Unfortunately, most of these models are black boxes, i.e., they are unable to reveal how they reach these prediction decisions. A need for transparency demands justification for such predictions. An affected individual might also desire explanations to understand why a decision was made. Ethical and legal considerations require informing the individual of changes in the input attribute (s) that could be made to produce a desirable outcome. Our work focuses on the latter problem of generating counterfactual explanations by considering the causal dependencies between features. In this paper, we present the framework CFGs, CounterFactual Generation with s(CASP), which utilizes the goal-directed Answer Set Programming (ASP) system s(CASP) to automatically generate counterfactual explanations from models generated by rule-based machine learning algorithms in particular. We benchmark CFGs with the FOLD-SE model. Reaching the counterfactual state from the initial state is planned and achieved using a series of interventions. To validate our proposal, we show how counterfactual explanations are computed and justified by imagining worlds where some or all factual assumptions are altered/changed. More importantly, we show how CFGs navigates between these worlds, namely, go from our initial state where we obtain an undesired outcome to the imagined goal state where we obtain the desired decision, taking into account the causal relationships among features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15956v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sopam Dasgupta, Joaqu\'in Arias, Elmer Salazar, Gopal Gupta</dc:creator>
    </item>
    <item>
      <title>Small unsatisfiable $k$-CNFs with bounded literal occurrence</title>
      <link>https://arxiv.org/abs/2405.16149</link>
      <description>arXiv:2405.16149v1 Announce Type: cross 
Abstract: We obtain the smallest unsatisfiable formulas in subclasses of $k$-CNF (exactly $k$ distinct literals per clause) with bounded variable or literal occurrences. Smaller unsatisfiable formulas of this type translate into stronger inapproximability results for MaxSAT in the considered formula class. Our results cover subclasses of 3-CNF and 4-CNF; in all subclasses of 3-CNF we considered we were able to determine the smallest size of an unsatisfiable formula; in the case of 4-CNF with at most 5 occurrences per variable we decreased the size of the smallest known unsatisfiable formula. Our methods combine theoretical arguments and symmetry-breaking exhaustive search based on SAT Modulo Symmetries (SMS), a recent framework for isomorph-free SAT-based graph generation. To this end, and as a standalone result of independent interest, we show how to encode formulas as graphs efficiently for SMS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16149v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianwei Zhang, Tom\'a\v{s} Peitl, Stefan Szeider</dc:creator>
    </item>
    <item>
      <title>RLSF: Reinforcement Learning via Symbolic Feedback</title>
      <link>https://arxiv.org/abs/2405.16661</link>
      <description>arXiv:2405.16661v1 Announce Type: cross 
Abstract: In recent years, large language models (LLMs) have had a dramatic impact on various sub-fields of AI, most notably on natural language understanding tasks. However, there is widespread agreement that the logical reasoning capabilities of contemporary LLMs are, at best, fragmentary (i.e., may work well on some problem instances but fail dramatically on others). While traditional LLM fine-tuning approaches (e.g., those that use human feedback) do address this problem to some degree, they suffer from many issues, including unsound black-box reward models, difficulties in collecting preference data, and sparse scalar reward values.
  To address these challenges, we propose a new training/fine-tuning paradigm we refer to as Reinforcement Learning via Symbolic Feedback (RLSF), which is aimed at enhancing the reasoning capabilities of LLMs. In the RLSF setting, the LLM that is being trained/fine-tuned is considered as the RL agent, while the environment is allowed access to reasoning or domain knowledge tools (e.g., solvers, algebra systems). Crucially, in RLSF, these reasoning tools can provide feedback to the LLMs via poly-sized certificates (e.g., proofs), that characterize errors in the LLM-generated object with respect to some correctness specification. The ability of RLSF-based training/fine-tuning to leverage certificate-generating symbolic tools enables sound fine-grained (token-level) reward signals to LLMs, and thus addresses the limitations of traditional reward models mentioned above. Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs outperforms traditional approaches on two different applications, namely, program synthesis from natural language pseudo-code to programming language (C++) and solving the Game of 24.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16661v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piyush Jha, Prithwish Jana, Arnav Arora, Vijay Ganesh</dc:creator>
    </item>
    <item>
      <title>Limits of Deep Learning: Sequence Modeling through the Lens of Complexity Theory</title>
      <link>https://arxiv.org/abs/2405.16674</link>
      <description>arXiv:2405.16674v1 Announce Type: cross 
Abstract: Deep learning models have achieved significant success across various applications but continue to struggle with tasks requiring complex reasoning over sequences, such as function composition and compositional tasks. Despite advancements, models like Structured State Space Models (SSMs) and Transformers underperform in deep compositionality tasks due to inherent architectural and training limitations. Maintaining accuracy over multiple reasoning steps remains a primary challenge, as current models often rely on shortcuts rather than genuine multi-step reasoning, leading to performance degradation as task complexity increases. Existing research highlights these shortcomings but lacks comprehensive theoretical and empirical analysis for SSMs. Our contributions address this gap by providing a theoretical framework based on complexity theory to explain SSMs' limitations. Moreover, we present extensive empirical evidence demonstrating how these limitations impair function composition and algorithmic task performance. Our experiments reveal significant performance drops as task complexity increases, even with Chain-of-Thought (CoT) prompting. Models frequently resort to shortcuts, leading to errors in multi-step reasoning. This underscores the need for innovative solutions beyond current deep learning paradigms to achieve reliable multi-step reasoning and compositional task-solving in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16674v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikola Zubi\'c, Federico Sold\'a, Aurelio Sulser, Davide Scaramuzza</dc:creator>
    </item>
    <item>
      <title>Autoformalizing Euclidean Geometry</title>
      <link>https://arxiv.org/abs/2405.17216</link>
      <description>arXiv:2405.17216v1 Announce Type: cross 
Abstract: Autoformalization involves automatically translating informal math into formal theorems and proofs that are machine-verifiable. Euclidean geometry provides an interesting and controllable domain for studying autoformalization. In this paper, we introduce a neuro-symbolic framework for autoformalizing Euclidean geometry, which combines domain knowledge, SMT solvers, and large language models (LLMs). One challenge in Euclidean geometry is that informal proofs rely on diagrams, leaving gaps in texts that are hard to formalize. To address this issue, we use theorem provers to fill in such diagrammatic information automatically, so that the LLM only needs to autoformalize the explicit textual steps, making it easier for the model. We also provide automatic semantic evaluation for autoformalized theorem statements. We construct LeanEuclid, an autoformalization benchmark consisting of problems from Euclid's Elements and the UniGeo dataset formalized in the Lean proof assistant. Experiments with GPT-4 and GPT-4V show the capability and limitations of state-of-the-art LLMs on autoformalizing geometry problems. The data and code are available at https://github.com/loganrjmurphy/LeanEuclid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17216v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Logan Murphy, Kaiyu Yang, Jialiang Sun, Zhaoyu Li, Anima Anandkumar, Xujie Si</dc:creator>
    </item>
    <item>
      <title>A logic for temporal conditionals and a solution to the Sea Battle Puzzle</title>
      <link>https://arxiv.org/abs/1711.02843</link>
      <description>arXiv:1711.02843v2 Announce Type: replace 
Abstract: Temporal reasoning with conditionals is more complex than both classical temporal reasoning and reasoning with timeless conditionals, and can lead to some rather counter-intuitive conclusions. For instance, Aristotle's famous "Sea Battle Tomorrow" puzzle leads to a fatalistic conclusion: whether there will be a sea battle tomorrow or not, but that is necessarily the case now. We propose a branching-time logic LTC to formalise reasoning about temporal conditionals and provide that logic with adequate formal semantics. The logic LTC extends the Nexttime fragment of CTL*, with operators for model updates, restricting the domain to only future moments where antecedent is still possible to satisfy. We provide formal semantics for these operators that implements the restrictor interpretation of antecedents of temporalized conditionals, by suitably restricting the domain of discourse. As a motivating example, we demonstrate that a naturally formalised in our logic version of the `Sea Battle' argument renders it unsound, thereby providing a solution to the problem with fatalist conclusion that it entails, because its underlying reasoning per cases argument no longer applies when these cases are treated not as material implications but as temporal conditionals. On the technical side, we analyze the semantics of LTC and provide a series of reductions of LTC-formulae, first recursively eliminating the dynamic update operators and then the path quantifiers in such formulae. Using these reductions we obtain a sound and complete axiomatization for LTC, and reduce its decision problem to that of the modal logic KD.</description>
      <guid isPermaLink="false">oai:arXiv.org:1711.02843v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengkui Ju, Gianluca Grilletti, Valentin Goranko</dc:creator>
    </item>
    <item>
      <title>Datalog-Expressibility for Monadic and Guarded Second-Order Logic</title>
      <link>https://arxiv.org/abs/2010.05677</link>
      <description>arXiv:2010.05677v2 Announce Type: replace 
Abstract: We characterise the sentences in Monadic Second-order Logic (MSO) that are over finite structures equivalent to a Datalog program, in terms of an existential pebble game. We also show that for every class C of finite structures that can be expressed in MSO and is closed under homomorphisms, and for all integers l,k, there exists a canonical Datalog program Pi of width (l,k) in the sense of Feder and Verdi. The same characterisations also hold for Guarded Second-order Logic (GSO), which properly extends MSO. To prove our results, we show that every class C in GSO whose complement is closed under homomorphisms is a finite union of constraint satisfaction problems (CSPs) of countably categorical structures. The intersection of MSO and Datalog is known to contain the class of nested monadically defined queries (Nemodeq); likewise, we show that the intersection of GSO and Datalog contains all problems that can be expressed by the more expressive language of nested guarded queries. Yet, by exploiting our results, we can show that neither of the two query languages can serve as a characterization, as we exhibit a query in the intersection of MSO and Datalog that is not expressible in nested guarded queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.05677v2</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Bodirsky, Simon Kn\"auer, Sebastian Rudolph</dc:creator>
    </item>
    <item>
      <title>Cyclic Implicit Complexity</title>
      <link>https://arxiv.org/abs/2110.01114</link>
      <description>arXiv:2110.01114v2 Announce Type: replace 
Abstract: Circular (or cyclic) proofs have received increasing attention in recent years, and have been proposed as an alternative setting for studying (co)inductive reasoning. In particular, now several type systems based on circular reasoning have been proposed. However, little is known about the complexity theoretic aspects of circular proofs, which exhibit sophisticated loop structures atypical of more common `recursion schemes'. This paper attempts to bridge the gap between circular proofs and implicit computational complexity (ICC). Namely we introduce a circular proof system based on Bellantoni and Cook's famous safe-normal function algebra, and we identify proof theoretical constraints, inspired by ICC, to characterise the polynomial-time and elementary computable functions. Along the way we introduce new recursion theoretic implicit characterisations of these classes that may be of interest in their own right.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.01114v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Curzi, Anupam Das</dc:creator>
    </item>
    <item>
      <title>Computational expressivity of (circular) proofs with fixed points</title>
      <link>https://arxiv.org/abs/2302.14825</link>
      <description>arXiv:2302.14825v2 Announce Type: replace 
Abstract: We study the computational expressivity of proof systems with fixed point operators, within the `proofs-as-programs' paradigm. We start with a calculus $\mu\mathsf{LJ}$ (due to Clairambault) that extends intuitionistic logic by least and greatest positive fixed points. Based in the sequent calculus, $\mu\mathsf{LJ}$ admits a standard extension to a `circular' calculus $\mathsf{C}\mu\mathsf{LJ}$.
  Our main result is that, perhaps surprisingly, both $\mu\mathsf{LJ}$ and $\mathsf{C}\mu\mathsf{LJ}$ represent the same first-order functions: those provably total in $\Pi^1_2$-$\mathsf{CA}_0$, a subsystem of second-order arithmetic beyond the `big five' of reverse mathematics and one of the strongest theories for which we have an ordinal analysis (due to Rathjen). This solves various questions in the literature on the computational strength of (circular) proof systems with fixed points.
  For the lower bound we give a realisability interpretation from an extension of Peano Arithmetic by fixed points that has been shown to be arithmetically equivalent to $\Pi^1_2$-$\mathsf{CA}_0$ (due to M\"ollerfeld). For the upper bound we construct a novel computability model in order to give a totality argument for circular proofs with fixed points. In fact we formalise this argument itself within $\Pi^1_2$-$\mathsf{CA}_0$ in order to obtain the tight bounds we are after.
  Along the way we develop some novel reverse mathematics for the Knaster-Tarski fixed point theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14825v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Curzi, Anupam Das</dc:creator>
    </item>
    <item>
      <title>A Complete Finite Axiomatisation of the Equational Theory of Common Meadows</title>
      <link>https://arxiv.org/abs/2307.04270</link>
      <description>arXiv:2307.04270v3 Announce Type: replace 
Abstract: We analyse abstract data types that model numerical structures with a concept of error. Specifically, we focus on arithmetic data types that contain an error value $\bot$ whose main purpose is to always return a value for division. To rings and fields, we add a division operator $x/y$ and study a class of algebras called common meadows wherein $x/0 = \bot$. The set of equations true in all common meadows is named the equational theory of common meadows. We give a finite equational axiomatisation of the equational theory of common meadows and prove that it is complete and that the equational theory is decidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04270v3</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan A Bergstra, John V Tucker</dc:creator>
    </item>
    <item>
      <title>Rings with common division, common meadows and their conditional equational theories</title>
      <link>https://arxiv.org/abs/2405.01733</link>
      <description>arXiv:2405.01733v2 Announce Type: replace 
Abstract: We examine the consequences of having a total division operation $\frac{x}{y}$ on commutative rings. We consider two forms of binary division, one derived from a unary inverse, the other defined directly as a general operation; each are made total by setting $1/0$ equal to an error value $\bot$, which is added to the ring. Such totalised divisions we call common divisions. In a field the two forms are equivalent and we have a finite equational axiomatisation $E$ that is complete for the equational theory of fields equipped with common division, called common meadows. These equational axioms $E$ turn out to be true of commutative rings with common division but only when defined via inverses. We explore these axioms $E$ and their role in seeking a completeness theorem for the conditional equational theory of common meadows. We prove they are complete for the conditional equational theory of commutative rings with inverse based common division. By adding a new proof rule, we can prove a completeness theorem for the conditional equational theory of common meadows. Although, the equational axioms $E$ fail with common division defined directly, we observe that the direct division does satisfies the equations in $E$ under a new congruence for partial terms called eager equality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01733v2</guid>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan A Bergstra, John V Tucker</dc:creator>
    </item>
    <item>
      <title>Verifying SQL Queries using Theories of Tables and Relations</title>
      <link>https://arxiv.org/abs/2405.03057</link>
      <description>arXiv:2405.03057v2 Announce Type: replace 
Abstract: We present a number of first- and second-order extensions to SMT theories specifically aimed at representing and analyzing SQL queries with join, projection, and selection operations. We support reasoning about SQL queries with either bag or set semantics for database tables. We provide the former via an extension of a theory of finite bags and the latter via an extension of the theory of finite relations. Furthermore, we add the ability to reason about tables with null values by introducing a theory of nullable sorts based on an extension of the theory of algebraic datatypes. We implemented solvers for these theories in the SMT solver cvc5 and evaluated them on a set of benchmarks derived from public sets of SQL equivalence problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03057v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mudathir Mohamed, Andrew Reynolds, Cesare Tinelli, Clark Barrett</dc:creator>
    </item>
    <item>
      <title>(Co)condition hits the Path</title>
      <link>https://arxiv.org/abs/2405.12994</link>
      <description>arXiv:2405.12994v2 Announce Type: replace 
Abstract: We propose an enhancement to inductive types and records in a dependent type theory, namely (co)conditions. With a primitive interval type, conditions generalize the cubical syntax of higher inductive types in homotopy type theory, while coconditions generalize the cubical path type. (Co)conditions are also useful without an interval type. The duality between conditions and coconditions is presented in an interesting way: The elimination principles of inductive types with conditions can be internalized with records with coconditions and vice versa.
  However, we do not develop the metatheory of conditions and coconditions in this paper. Instead, we only present the type checking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12994v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tesla Zhang, Valery Isaev</dc:creator>
    </item>
    <item>
      <title>FALCON: Scalable Reasoning over Inconsistent ALC Ontologies</title>
      <link>https://arxiv.org/abs/2208.07628</link>
      <description>arXiv:2208.07628v5 Announce Type: replace-cross 
Abstract: Ontologies are one of the richest sources of knowledge. Real-world ontologies often contain thousands of axioms and are often human-made. Hence, they may contain inconsistency and incomplete information which may impair classical reasoners to compute entailments that are considered as useful. To overcome these two challenges, we propose FALCON, a Fuzzy Ontology Neural reasoner to approximate reasoning over ALC ontologies. We provide an approximate technique for the model generation step in classical ALC reasoners. Our approximation is not guaranteed to construct exact logical models, but can approximate arbitrary models, which is notably faster for some large ontologies. Moreover, by sampling multiple approximate logical models, our technique supports approximate entailment also over inconsistent ontologies. Theoretical results show that more models generated lead to closer, i.e., faithful approximation of entailment over ALC entailments. Experimental results show that FALCON enables approximate reasoning and reasoning in the presence of inconsistency. Our experiments further demonstrate how ontologies can improve knowledge base completion in biomedicine by incorporating knowledge expressed in ALC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07628v5</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tilman Hinnerichs, Zhenwei Tang, Xi Peng, Xiangliang Zhang, Robert Hoehndorf</dc:creator>
    </item>
    <item>
      <title>Computational Complexity of Preferred Subset Repairs on Data-Graphs</title>
      <link>https://arxiv.org/abs/2402.09265</link>
      <description>arXiv:2402.09265v2 Announce Type: replace-cross 
Abstract: Preferences are a pivotal component in practical reasoning, especially in tasks that involve decision-making over different options or courses of action that could be pursued. In this work, we focus on repairing and querying inconsistent knowledge bases in the form of graph databases, which involves finding a way to solve conflicts in the knowledge base and considering answers that are entailed from every possible repair, respectively. Without a priori domain knowledge, all possible repairs are equally preferred. Though that may be adequate for some settings, it seems reasonable to establish and exploit some form of preference order among the potential repairs. We study the problem of computing prioritized repairs over graph databases with data values, using a notion of consistency based on GXPath expressions as integrity constraints. We present several preference criteria based on the standard subset repair semantics, incorporating weights, multisets, and set-based priority levels. We show that it is possible to maintain the same computational complexity as in the case where no preference criterion is available for exploitation. Finally, we explore the complexity of consistent query answering in this setting and obtain tight lower and upper bounds for all the preference criteria introduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09265v2</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nina Pardal, Santiago Cifuentes, Edwin Pin, Maria Vanina Martinez, Sergio Abriola</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming for Symbolic Boolean Realizability and Synthesis</title>
      <link>https://arxiv.org/abs/2405.07975</link>
      <description>arXiv:2405.07975v3 Announce Type: replace-cross 
Abstract: Inspired by recent progress in dynamic programming approaches for weighted model counting, we investigate a dynamic-programming approach in the context of boolean realizability and synthesis, which takes a conjunctive-normal-form boolean formula over input and output variables, and aims at synthesizing witness functions for the output variables in terms of the inputs. We show how graded project-join trees, obtained via tree decomposition, can be used to compute a BDD representing the realizability set for the input formulas in a bottom-up order. We then show how the intermediate BDDs generated during realizability checking phase can be applied to synthesizing the witness functions in a top-down manner. An experimental evaluation of a solver -- DPSynth -- based on these ideas demonstrates that our approach for Boolean realizabilty and synthesis has superior time and space performance over a heuristics-based approach using same symbolic representations. We discuss the advantage on scalability of the new approach, and also investigate our findings on the performance of the DP framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07975v3</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yi Lin, Lucas M. Tabajara, Moshe Y. Vardi</dc:creator>
    </item>
    <item>
      <title>On the Cut Elimination of Weak Intuitionistic Tense Logic</title>
      <link>https://arxiv.org/abs/2405.09970</link>
      <description>arXiv:2405.09970v2 Announce Type: replace-cross 
Abstract: In this paper, we use a new method to prove cut-elimination of weak intuitionistic tense logic. This method focuses on splitting the contraction rule and cut rules. Further general theories and applications of this method shall be developed in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09970v2</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiheng Wang, Yu Peng, Zhe Lin</dc:creator>
    </item>
  </channel>
</rss>
