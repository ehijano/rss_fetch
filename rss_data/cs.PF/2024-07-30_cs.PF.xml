<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 31 Jul 2024 01:45:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Binary Bleed: Fast Distributed and Parallel Method for Automatic Model Selection</title>
      <link>https://arxiv.org/abs/2407.19125</link>
      <description>arXiv:2407.19125v1 Announce Type: cross 
Abstract: In several Machine Learning (ML) clustering and dimensionality reduction approaches, such as non-negative matrix factorization (NMF), RESCAL, and K-Means clustering, users must select a hyper-parameter k to define the number of clusters or components that yield an ideal separation of samples or clean clusters. This selection, while difficult, is crucial to avoid overfitting or underfitting the data. Several ML applications use scoring methods (e.g., Silhouette and Davies Boulding scores) to evaluate the cluster pattern stability for a specific k. The score is calculated for different trials over a range of k, and the ideal k is heuristically selected as the value before the model starts overfitting, indicated by a drop or increase in the score resembling an elbow curve plot. While the grid-search method can be used to accurately find a good k value, visiting a range of k can become time-consuming and computationally resource-intensive. In this paper, we introduce the Binary Bleed method based on binary search, which significantly reduces the k search space for these grid-search ML algorithms by truncating the target k values from the search space using a heuristic with thresholding over the scores. Binary Bleed is designed to work with single-node serial, single-node multi-processing, and distributed computing resources. In our experiments, we demonstrate the reduced search space gain over a naive sequential search of the ideal k and the accuracy of the Binary Bleed in identifying the correct k for NMFk, K-Means pyDNMFk, and pyDRESCALk with Silhouette and Davies Boulding scores. We make our implementation of Binary Bleed for the NMF algorithm available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19125v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Barron (Theoretical Division, Los Alamos National Laboratory, Los Alamos, USA), Maksim E. Eren (Advanced Research in Cyber Systems, Los Alamos National Laboratory, Los Alamos, USA), Manish Bhattarai (Theoretical Division, Los Alamos National Laboratory, Los Alamos, USA), Ismael Boureima (Theoretical Division, Los Alamos National Laboratory, Los Alamos, USA), Cynthia Matuszek (Advanced Research in Cyber Systems, Los Alamos National Laboratory, Los Alamos, USA), Boian S. Alexandrov (Theoretical Division, Los Alamos National Laboratory, Los Alamos, USA)</dc:creator>
    </item>
    <item>
      <title>Lock-Free Computation of PageRank in Dynamic Graphs</title>
      <link>https://arxiv.org/abs/2407.19562</link>
      <description>arXiv:2407.19562v1 Announce Type: cross 
Abstract: PageRank is a metric that assigns importance to the vertices of a graph based on its neighbors and their scores. Recently, there has been increasing interest in computing PageRank on dynamic graphs, where the graph structure evolves due to edge insertions and deletions. However, traditional barrier-based approaches for updating PageRanks encounter significant wait times on certain graph structures, leading to high overall runtimes. Additionally, the growing trend of multicore architectures with increased core counts has raised concerns about random thread delays and failures. In this study, we propose a lock-free algorithm for updating PageRank scores on dynamic graphs. First, we introduce our Dynamic Frontier (DF) approach, which identifies and processes vertices likely to change PageRanks with minimal overhead. Subsequently, we integrate DF with our lock-free and fault-tolerant PageRank ($DF_{LF}$), incorporating a helping mechanism among threads between its two phases. Experimental results demonstrate that $DF_{LF}$ not only eliminates waiting times at iteration barriers but also withstands random thread delays and crashes. On average, it is 4.6x faster than lock-free Naive-dynamic PageRank ($ND_{LF}$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19562v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Subhajit Sahu</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of CMOS Annealing with Support Vector Machine</title>
      <link>https://arxiv.org/abs/2404.15752</link>
      <description>arXiv:2404.15752v2 Announce Type: replace 
Abstract: In this paper, support vector machine (SVM) performance was assessed utilizing a quantum-inspired complementary metal-oxide semiconductor (CMOS) annealer. The primary focus during performance evaluation was the accuracy rate in binary classification problems. A comparative analysis was conducted between SVM running on a CPU (classical computation) and executed on a quantum-inspired annealer. The performance outcome was evaluated using a CMOS annealing machine, thereby obtaining an accuracy rate of 93.7% for linearly separable problems, 92.7% for non-linearly separable problem 1, and 97.6% for non-linearly separable problem 2. These results reveal that a CMOS annealing machine can achieve an accuracy rate that closely rivals that of classical computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15752v2</guid>
      <category>cs.PF</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryoga Fukuhara, Makoto Morishita, Takahiro Katagiri, Masatoshi Kawai, Toru Nagai, Tetsuya Hoshino</dc:creator>
    </item>
    <item>
      <title>Can Increasing the Hit Ratio Hurt Cache Throughput? (Long Version)</title>
      <link>https://arxiv.org/abs/2404.16219</link>
      <description>arXiv:2404.16219v3 Announce Type: replace 
Abstract: Software caches are an intrinsic component of almost every computer system. Consequently, caching algorithms, particularly eviction policies, are the topic of many papers. Almost all these prior papers evaluate the caching algorithm based on its hit ratio, namely the fraction of requests that are found in the cache, as opposed to disk. The hit ratio is viewed as a proxy for traditional performance metrics like system throughput or response time. Intuitively it makes sense that higher hit ratio should lead to higher throughput (and lower response time), since more requests are found in the cache (low access time) as opposed to the disk (high access time).
  This paper challenges this intuition. We show that increasing the hit ratio can actually hurt the throughput (and response time) for many caching algorithms. Our investigation follows a three-pronged approach involving (i) queueing modeling and analysis, (ii) implementation and measurement, and (iii) simulation to validate the accuracy of the queueing model. We also show that the phenomenon of throughput decreasing at higher hit ratios is likely to be more pronounced in future systems, where the trend is towards faster disks and higher numbers of cores per CPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16219v3</guid>
      <category>cs.PF</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyue Qiu, Juncheng Yang, Mor Harchol-Balter</dc:creator>
    </item>
    <item>
      <title>Analysis of Markovian Arrivals and Service with Applications to Intermittent Overload</title>
      <link>https://arxiv.org/abs/2405.04102</link>
      <description>arXiv:2405.04102v2 Announce Type: replace 
Abstract: Almost all queueing analysis assumes i.i.d. arrivals and service. In reality, arrival and service rates fluctuate over time. In particular, it is common for real systems to intermittently experience overload, where the arrival rate temporarily exceeds the service rate, which an i.i.d. model cannot capture. We consider the MAMS system, where the arrival and service rates each vary according to an arbitrary finite-state Markov chain, allowing intermittent overload to be modeled.
  We derive the first explicit characterization of mean queue length in the MAMS system, with explicit bounds for all arrival and service chains at all loads. Our bounds are tight in heavy traffic. We prove even stronger bounds for the important special case of two-level arrivals with intermittent overload.
  Our key contribution is an extension to the drift method, based on the novel concepts of relative arrivals and relative completions. These quantities allow us to tractably capture the transient correlational effect of the arrival and service processes on the mean queue length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04102v2</guid>
      <category>cs.PF</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isaac Grosof, Yige Hong, Mor Harchol-Balter</dc:creator>
    </item>
    <item>
      <title>On-Demand JSON: A Better Way to Parse Documents?</title>
      <link>https://arxiv.org/abs/2312.17149</link>
      <description>arXiv:2312.17149v2 Announce Type: replace-cross 
Abstract: JSON is a popular standard for data interchange on the Internet. Ingesting JSON documents can be a performance bottleneck. A popular parsing strategy consists in converting the input text into a tree-based data structure -- sometimes called a Document Object Model or DOM. We designed and implemented a novel JSON parsing interface -- called On-Demand -- that appears to the programmer like a conventional DOM-based approach. However, the underlying implementation is a pointer iterating through the content, only materializing the results (objects, arrays, strings, numbers) lazily.On recent commodity processors, an implementation of our approach provides superior performance in multiple benchmarks. To ensure reproducibility, our work is freely available as open source software. Several systems use On Demand: e.g., Apache Doris, the Node.js JavaScript runtime, Milvus, and Velox.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17149v2</guid>
      <category>cs.DB</category>
      <category>cs.PF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/spe.3313</arxiv:DOI>
      <arxiv:journal_reference>Software: Practice and Experience 54 (6), 2024</arxiv:journal_reference>
      <dc:creator>John Keiser, Daniel Lemire</dc:creator>
    </item>
    <item>
      <title>Missile: Fine-Grained, Hardware-Level GPU Resource Isolation for Multi-Tenant DNN Inference</title>
      <link>https://arxiv.org/abs/2407.13996</link>
      <description>arXiv:2407.13996v2 Announce Type: replace-cross 
Abstract: Colocating high-priority, latency-sensitive (LS) and low-priority, best-effort (BE) DNN inference services reduces the total cost of ownership (TCO) of GPU clusters. Limited by bottlenecks such as VRAM channel conflicts and PCIe bus contentions, existing GPU sharing solutions are unable to avoid resource conflicts among concurrently executing tasks, failing to achieve both low latency for LS tasks and high throughput for BE tasks. To bridge this gap, this paper presents Missile, a general GPU sharing solution for multi-tenant DNN inference on NVIDIA GPUs. Missile approximates fine-grained GPU hardware resource isolation between multiple LS and BE DNN tasks at software level. Through comprehensive reverse engineering, Missile first reveals a general VRAM channel hash mapping architecture of NVIDIA GPUs and eliminates VRAM channel conflicts using software-level cache coloring. It also isolates the PCIe bus and fairly allocates PCIe bandwidth using completely fair scheduler. We evaluate 12 mainstream DNNs with synthetic and real-world workloads on four GPUs. The results show that compared to the state-of-the-art GPU sharing solutions, Missile reduces tail latency for LS services by up to ~50%, achieves up to 6.1x BE job throughput, and allocates PCIe bus bandwidth to tenants on-demand for optimal performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13996v2</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongkang Zhang, Haoxuan Yu, Chenxia Han, Cheng Wang, Baotong Lu, Yang Li, Xiaowen Chu, Huaicheng Li</dc:creator>
    </item>
  </channel>
</rss>
