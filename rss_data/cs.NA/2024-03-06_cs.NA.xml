<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Mar 2024 05:00:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Mar 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Direct Sampling Method and Its Integration with Deep Learning for Inverse Scattering Problems with Phaseless Data</title>
      <link>https://arxiv.org/abs/2403.02584</link>
      <description>arXiv:2403.02584v1 Announce Type: new 
Abstract: We consider in this work an inverse acoustic scattering problem when only phaseless data is available. The inverse problem is highly nonlinear and ill-posed due to the lack of the phase information. Solving inverse scattering problems with phaseless data is important in applications as the collection of physically acceptable phased data is usually difficult and expensive. A novel direct sampling method (DSM) will be developed to effectively estimate the locations and geometric shapes of the unknown scatterers from phaseless data generated by a very limited number of incident waves. With a careful theoretical analysis of the behavior of the index function and some representative numerical examples, the new DSM is shown to be computationally efficient, easy to implement, robust to large noise, and does not require any prior knowledge of the unknown scatterers. Furthermore, to fully exploit the index functions obtained from the DSM, we also propose to integrate the DSM with a deep learning technique (DSM-DL) to achieve high-quality reconstructions. Several challenging and representative numerical experiments are carried out to demonstrate the accuracy and robustness of reconstructions by DSM-DL. The DSM-DL networks trained by phased data are further theoretically and numerically shown to be able to solve problems with phaseless data. Additionally, our numerical experiments also show the DSM-DL can solve inverse scattering problems with mixed types of scatterers, which renders its applications in many important practical scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02584v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Ning, Fuqun Han, Jun Zou</dc:creator>
    </item>
    <item>
      <title>Learning Stochastic Dynamics from Data</title>
      <link>https://arxiv.org/abs/2403.02595</link>
      <description>arXiv:2403.02595v1 Announce Type: new 
Abstract: We present a noise guided trajectory based system identification method for inferring the dynamical structure from observation generated by stochastic differential equations. Our method can handle various kinds of noise, including the case when the the components of the noise is correlated. Our method can also learn both the noise level and drift term together from trajectory. We present various numerical tests for showcasing the superior performance of our learning algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02595v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziheng Guo, Igor Cialenco, Ming Zhong</dc:creator>
    </item>
    <item>
      <title>A randomized lattice rule without component-by-component construction</title>
      <link>https://arxiv.org/abs/2403.02660</link>
      <description>arXiv:2403.02660v1 Announce Type: new 
Abstract: We study the multivariate integration problem for periodic functions from the weighted Korobov space in the randomized setting. We introduce a new randomized rank-1 lattice rule with a randomly chosen number of points, which avoids the need for component-by-component construction in the search for good generating vectors while still achieving nearly the optimal rate of the randomized error. Our idea is to exploit the fact that at least half of the possible generating vectors yield nearly the optimal rate of the worst-case error in the deterministic setting. By randomly choosing generating vectors $r$ times and comparing their corresponding worst-case errors, one can find one generating vector with a desired worst-case error bound with a very high probability, and the (small) failure probability can be controlled by increasing $r$ logarithmically as a function of the number of points. Numerical experiments are conducted to support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02660v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Goda</dc:creator>
    </item>
    <item>
      <title>A Fully-discrete Semi-Lagrangian scheme for a price formation MFG model</title>
      <link>https://arxiv.org/abs/2403.02785</link>
      <description>arXiv:2403.02785v1 Announce Type: new 
Abstract: Here, we examine a fully-discrete Semi-Lagrangian scheme for a mean-field game price formation model. We show that the discretization is monotone as a multivalued operator and prove the uniqueness of the discretized solution. Moreover, we show that the limit of the discretization converges to the weak solution of the continuous price formation mean-field game using monotonicity methods. This scheme performs substantially better than standard methods by giving reliable results within a few iterations, as several numerical simulations and comparisons at the end of the paper illustrate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02785v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuri Ashrafyan, Diogo Gomes</dc:creator>
    </item>
    <item>
      <title>Efficient simulation of complex Ginzburg--Landau equations using high-order exponential-type methods</title>
      <link>https://arxiv.org/abs/2403.02816</link>
      <description>arXiv:2403.02816v1 Announce Type: new 
Abstract: In this paper, we consider the task of efficiently computing the numerical solution of evolutionary complex Ginzburg--Landau equations. To this aim, we employ high-order exponential methods of splitting and Lawson type for the time integration. These schemes enjoy favorable stability properties and, in particular, do not show restrictions on the time step size due to the underlying stiffness of the models. The needed actions of matrix exponentials are efficiently realized with pointwise operations in Fourier space (when the model is considered with periodic boundary conditions) or by using a tensor-oriented approach that suitably employs the so-called $\mu$-mode products (when the semidiscretization in space is performed with finite differences). The overall effectiveness of the approach is demonstrated by running simulations on a variety of two- and three-dimensional (systems of) complex Ginzburg--Landau equations with cubic and cubic-quintic nonlinearities, which are widely considered in literature to model relevant physical phenomena. In fact, in all instances high-order exponential-type schemes can outperform standard techniques to integrate in time the models under consideration, i.e., the well-known split-step method and the explicit fourth-order Runge--Kutta integrator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02816v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Caliari, Fabio Cassini</dc:creator>
    </item>
    <item>
      <title>Second-order robust parallel integrators for dynamical low-rank approximation</title>
      <link>https://arxiv.org/abs/2403.02834</link>
      <description>arXiv:2403.02834v1 Announce Type: new 
Abstract: Due to its reduced memory and computational demands, dynamical low-rank approximation (DLRA) has sparked significant interest in multiple research communities. A central challenge in DLRA is the development of time integrators that are robust to the curvature of the manifold of low-rank matrices. Recently, a parallel robust time integrator that permits dynamic rank adaptation and enables a fully parallel update of all low-rank factors was introduced. Despite its favorable computational efficiency, the construction as a first-order approximation to the augmented basis-update &amp; Galerkin integrator restricts the parallel integrator's accuracy to order one. In this work, an extension to higher order is proposed by a careful basis augmentation before solving the matrix differential equations of the factorized solution. A robust error bound with an improved dependence on normal components of the vector field together with a norm preservation property up to small terms is derived. These analytic results are complemented and demonstrated through a series of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02834v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Kusch</dc:creator>
    </item>
    <item>
      <title>Fast Numerical Approximation of Parabolic Problems Using Model Order Reduction and the Laplace Transform</title>
      <link>https://arxiv.org/abs/2403.02847</link>
      <description>arXiv:2403.02847v1 Announce Type: new 
Abstract: We introduce a novel, fast method for the numerical approximation of parabolic partial differential equations (PDEs for short) based on model order reduction techniques and the Laplace transform. We start by applying said transform to the evolution problem, thus yielding a time-independent boundary value problem solely depending on the complex Laplace parameter. In an offline stage, we judiciously sample the Laplace parameter and numerically solve the corresponding collection of high-fidelity or full-order problems. Next, we apply a proper orthogonal decomposition (POD) to this collection of solutions in order to obtain a reduced basis in the Laplace domain. We project the linear parabolic problem onto this basis, and then using any suitable time-stepping method, we solve the evolution problem. A key insight to justify the implementation and analysis of the proposed method corresponds to resorting to Hardy spaces of analytic functions and establishing, through the Paley-Wiener theorem, an isometry between the solution of the time-dependent problem and its Laplace transform. As a result, one may conclude that computing a POD with samples taken in the Laplace domain produces an exponentially accurate reduced basis for the time-dependent problem. Numerical experiments portray the performance of the method in terms of accuracy and, in particular, speed-up when compared to the solution obtained by solving the full-order model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02847v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Henr\'iquez, Jan S. Hesthaven</dc:creator>
    </item>
    <item>
      <title>Scientific machine learning for closure models in multiscale problems: a review</title>
      <link>https://arxiv.org/abs/2403.02913</link>
      <description>arXiv:2403.02913v1 Announce Type: new 
Abstract: Closure problems are omnipresent when simulating multiscale systems, where some quantities and processes cannot be fully prescribed despite their effects on the simulation's accuracy. Recently, scientific machine learning approaches have been proposed as a way to tackle the closure problem, combining traditional (physics-based) modeling with data-driven (machine-learned) techniques, typically through enriching differential equations with neural networks. This paper reviews the different reduced model forms, distinguished by the degree to which they include known physics, and the different objectives of a priori and a posteriori learning. The importance of adhering to physical laws (such as symmetries and conservation laws) in choosing the reduced model form and choosing the learning method is discussed. The effect of spatial and temporal discretization and recent trends toward discretization-invariant models are reviewed. In addition, we make the connections between closure problems and several other research disciplines: inverse problems, Mori-Zwanzig theory, and multi-fidelity methods. In conclusion, much progress has been made with scientific machine learning approaches for solving closure problems, but many challenges remain. In particular, the generalizability and interpretability of learned models is a major issue that needs to be addressed further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02913v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Benjamin Sanderse, Panos Stinis, Romit Maulik, Shady E. Ahmed</dc:creator>
    </item>
    <item>
      <title>ISC: an RADI-type method for stochastic continuous-time algebraic Riccati equations</title>
      <link>https://arxiv.org/abs/2403.02940</link>
      <description>arXiv:2403.02940v1 Announce Type: new 
Abstract: In this paper, we propose an RADI-type method for large-scale stochastic continuous-time algebraic Riccati equations with sparse and low-rank structures. The so-called ISC method is developed by using the Incorporation idea together with different Shifts to accelerate the convergence and Compressions to reduce the storage and complexity. Numerical experiments are given to show its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02940v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen-Chen Guo, Xin Liang</dc:creator>
    </item>
    <item>
      <title>Accelerating the convergence of Newton's method for nonlinear elliptic PDEs using Fourier neural operators</title>
      <link>https://arxiv.org/abs/2403.03021</link>
      <description>arXiv:2403.03021v1 Announce Type: new 
Abstract: It is well known that Newton's method, especially when applied to large problems such as the discretization of nonlinear partial differential equations (PDEs), can have trouble converging if the initial guess is too far from the solution. This work focuses on accelerating this convergence, in the context of the discretization of nonlinear elliptic PDEs. We first provide a quick review of existing methods, and justify our choice of learning an initial guess with a Fourier neural operator (FNO). This choice was motivated by the mesh-independence of such operators, whose training and evaluation can be performed on grids with different resolutions. The FNO is trained using a loss minimization over generated data, loss functions based on the PDE discretization. Numerical results, in one and two dimensions, show that the proposed initial guess accelerates the convergence of Newton's method by a large margin compared to a naive initial guess, especially for highly nonlinear or anisotropic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03021v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joubine Aghili, Emmanuel Franck, Romain Hild, Victor Michel-Dansac, Vincent Vigon</dc:creator>
    </item>
    <item>
      <title>Fast and robust method for screened Poisson lattice Green's function using asymptotic expansion and Fast Fourier Transform</title>
      <link>https://arxiv.org/abs/2403.03076</link>
      <description>arXiv:2403.03076v1 Announce Type: new 
Abstract: We study the lattice Green's function (LGF) of the screened Poisson equation on a two-dimensional rectangular lattice. This LGF arises in numerical analysis, random walks, solid-state physics, and other fields. Its defining characteristic is the screening term, which defines different regimes. When its coefficient is large, we can accurately approximate the LGF with an exponentially converging asymptotic expansion, and its convergence rate monotonically increases with the coefficient of the screening term. To tabulate the LGF when the coefficient is not large, we derive a one-dimensional integral representation of the LGF. We show that the trapezoidal rule can approximate this integral with exponential convergence, and we propose an efficient algorithm for its evaluation via the Fast Fourier Transform. We discuss applications including computing the LGF of the three-dimensional Poisson equation with one periodic direction and the return probability of a two-dimensional random walk with killing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03076v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Hou, Tim Colonius</dc:creator>
    </item>
    <item>
      <title>Learning Explicitly Conditioned Sparsifying Transforms</title>
      <link>https://arxiv.org/abs/2403.03168</link>
      <description>arXiv:2403.03168v1 Announce Type: new 
Abstract: Sparsifying transforms became in the last decades widely known tools for finding structured sparse representations of signals in certain transform domains. Despite the popularity of classical transforms such as DCT and Wavelet, learning optimal transforms that guarantee good representations of data into the sparse domain has been recently analyzed in a series of papers. Typically, the conditioning number and representation ability are complementary key features of learning square transforms that may not be explicitly controlled in a given optimization model. Unlike the existing approaches from the literature, in our paper, we consider a new sparsifying transform model that enforces explicit control over the data representation quality and the condition number of the learned transforms. We confirm through numerical experiments that our model presents better numerical behavior than the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03168v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei P\u{a}tra\c{s}cu, Cristian Rusu, Paul Irofti</dc:creator>
    </item>
    <item>
      <title>On the computation of lattice sums without translational invariance</title>
      <link>https://arxiv.org/abs/2403.03213</link>
      <description>arXiv:2403.03213v1 Announce Type: new 
Abstract: This work introduces a framework for the efficient computation of oscillatory multidimensional lattice sums in geometries with boundaries, a problem intersecting pure and applied mathematics with immediate applications in condensed matter physics and topological quantum physics. The challenge in evaluating the arising sums results from the combination of singular long-range interactions with the loss of translational invariance caused by the boundaries, rendering standard tools ineffective. Our work shows that these lattice sums can be generated from a generalization of the Riemann zeta function to multidimensional non-periodic lattice sums. We put forth a new representation of this zeta function together with a numerical algorithm that ensures super-exponential convergence across an extensive range of geometries. Notably, our method's runtime is influenced only by the complexity of the considered geometries and not by the sheer number of particles, providing the foundation for efficient simulations of macroscopic condensed matter systems. We showcase the practical utility of our method by computing interaction energies in a three-dimensional crystal structure with $3\times 10^{23}$ particles. Our method's accuracy is thoroughly assessed through a detailed error analysis that both uses analytical results and numerical experiments. A reference implementation is provided online along with the article</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03213v1</guid>
      <category>math.NA</category>
      <category>cond-mat.str-el</category>
      <category>cs.NA</category>
      <category>hep-lat</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas A. Buchheit, Torsten Ke{\ss}ler, Kirill Serkh</dc:creator>
    </item>
    <item>
      <title>A Primal-dual hybrid gradient method for solving optimal control problems and the corresponding Hamilton-Jacobi PDEs</title>
      <link>https://arxiv.org/abs/2403.02468</link>
      <description>arXiv:2403.02468v1 Announce Type: cross 
Abstract: Optimal control problems are crucial in various domains, including path planning, robotics, and humanoid control, demonstrating their broad applicability. The connection between optimal control and Hamilton-Jacobi (HJ) partial differential equations (PDEs) underscores the need for solving HJ PDEs to address these control problems effectively. While numerous numerical methods exist for tackling HJ PDEs across different dimensions, this paper introduces an innovative optimization-based approach that reformulates optimal control problems and HJ PDEs into a saddle point problem using a Lagrange multiplier. Our method, based on the preconditioned primal-dual hybrid gradient (PDHG) method, offers a solution to HJ PDEs with first-order accuracy and numerical unconditional stability, enabling larger time steps and avoiding the limitations of explicit time discretization methods. Our approach has ability to handle a wide variety of Hamiltonian functions, including those that are non-smooth and dependent on time and space, through a simplified saddle point formulation that facilitates easy and parallelizable updates. Furthermore, our framework extends to viscous HJ PDEs and stochastic optimal control problems, showcasing its versatility. Through a series of numerical examples, we demonstrate the method's effectiveness in managing diverse Hamiltonians and achieving efficient parallel computation, highlighting its potential for wide-ranging applications in optimal control and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02468v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tingwei Meng, Siting Liu, Wuchen Li, Stanley Osher</dc:creator>
    </item>
    <item>
      <title>Projected gradient descent accumulates at Bouligand stationary points</title>
      <link>https://arxiv.org/abs/2403.02530</link>
      <description>arXiv:2403.02530v1 Announce Type: cross 
Abstract: This paper concerns the projected gradient descent (PGD) algorithm for the problem of minimizing a continuously differentiable function on a nonempty closed subset of a Euclidean vector space. Without further assumptions, this problem is intractable and devoted algorithms are only expected to find a stationary point. PGD is known to generate a sequence whose accumulation points are Mordukhovich stationary. In this paper, these accumulation points are proven to be Bouligand stationary, and even proximally stationary if the gradient is locally Lipschitz continuous. These are the strongest stationarity properties that can be expected for the considered problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02530v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, Ir\`ene Waldspurger</dc:creator>
    </item>
    <item>
      <title>Neural Fractional Differential Equations</title>
      <link>https://arxiv.org/abs/2403.02737</link>
      <description>arXiv:2403.02737v1 Announce Type: cross 
Abstract: Fractional Differential Equations (FDEs) are essential tools for modelling complex systems in science and engineering. They extend the traditional concepts of differentiation and integration to non-integer orders, enabling a more precise representation of processes characterised by non-local and memory-dependent behaviours.
  This property is useful in systems where variables do not respond to changes instantaneously, but instead exhibit a strong memory of past interactions.
  Having this in mind, and drawing inspiration from Neural Ordinary Differential Equations (Neural ODEs), we propose the Neural FDE, a novel deep neural network architecture that adjusts a FDE to the dynamics of data.
  This work provides a comprehensive overview of the numerical method employed in Neural FDEs and the Neural FDE architecture. The numerical outcomes suggest that, despite being more computationally demanding, the Neural FDE may outperform the Neural ODE in modelling systems with memory or dependencies on past states, and it can effectively be applied to learn more intricate dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02737v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>C. Coelho, M. Fernanda P. Costa, L. L. Ferr\'as</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo for Efficient Fourier Pricing of Multi-Asset Options</title>
      <link>https://arxiv.org/abs/2403.02832</link>
      <description>arXiv:2403.02832v1 Announce Type: cross 
Abstract: Efficiently pricing multi-asset options poses a significant challenge in quantitative finance. The Monte Carlo (MC) method remains the prevalent choice for pricing engines; however, its slow convergence rate impedes its practical application. Fourier methods leverage the knowledge of the characteristic function to accurately and rapidly value options with up to two assets. Nevertheless, they face hurdles in the high-dimensional settings due to the tensor product (TP) structure of commonly employed quadrature techniques. This work advocates using the randomized quasi-MC (RQMC) quadrature to improve the scalability of Fourier methods with high dimensions. The RQMC technique benefits from the smoothness of the integrand and alleviates the curse of dimensionality while providing practical error estimates. Nonetheless, the applicability of RQMC on the unbounded domain, $\mathbb{R}^d$, requires a domain transformation to $[0,1]^d$, which may result in singularities of the transformed integrand at the corners of the hypercube, and deteriorate the rate of convergence of RQMC. To circumvent this difficulty, we design an efficient domain transformation procedure based on the derived boundary growth conditions of the integrand. This transformation preserves the sufficient regularity of the integrand and hence improves the rate of convergence of RQMC. To validate this analysis, we demonstrate the efficiency of employing RQMC with an appropriate transformation to evaluate options in the Fourier space for various pricing models, payoffs, and dimensions. Finally, we highlight the computational advantage of applying RQMC over MC or TP in the Fourier domain, and over MC in the physical domain for options with up to 15 assets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02832v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bayer, Chiheb Ben Hammouda, Antonis Papapantoleon, Michael Samet, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>Numerical investigation of stabilization in the Hybridizable Discontinuous Galerkin method for linear anisotropic elastic equation</title>
      <link>https://arxiv.org/abs/2403.02862</link>
      <description>arXiv:2403.02862v1 Announce Type: cross 
Abstract: This work concerns the implementation of the hybridizable discontinuous Galerkin (HDG) method to solve the linear anisotropic elastic equation in the frequency domain. First-order formulation with the compliance tensor and Voigt notation are employed to provide a compact description of the discretized problem and flexibility with highly heterogeneous media. We further focus on the question of optimal choice of stabilization in the definition of HDG numerical traces. For this purpose, we construct a hybridized Godunov-upwind flux for anisotropic elasticity possessing three distinct wavespeeds. This stabilization removes the need to choose scaling factors, contrary to identity and Kelvin-Christoffel based stabilizations which are popular choices in literature. We carry out comparisons among these families for isotropic and anisotropic material, with constant background and highly heterogeneous ones, in two and three dimensions. They establish the optimality of the Godunov stabilization which can be used as a reference choice for generic material and different types of waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02862v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ha Pham, Florian Faucher, H\'el\`ene Barucq</dc:creator>
    </item>
    <item>
      <title>An electromechanics-driven fluid dynamics model for the simulation of the whole human heart</title>
      <link>https://arxiv.org/abs/2301.02148</link>
      <description>arXiv:2301.02148v2 Announce Type: replace 
Abstract: We introduce a multiphysics and geometric multiscale computational model, suitable to describe the hemodynamics of the whole human heart, driven by a four-chamber electromechanical model. We first present a study on the calibration of the biophysically detailed RDQ20 activation model (Regazzoni et al., 2020) that is able to reproduce the physiological range of hemodynamic biomarkers. Then, we demonstrate that the ability of the force generation model to reproduce certain microscale mechanisms, such as the dependence of force on fiber shortening velocity, is crucial to capture the overall physiological mechanical and fluid dynamics macroscale behavior. This motivates the need for using multiscale models with high biophysical fidelity, even when the outputs of interest are relative to the macroscale. We show that the use of a high-fidelity electromechanical model, combined with a detailed calibration process, allows us to achieve remarkable biophysical fidelity in terms of both mechanical and hemodynamic quantities. Indeed, our electromechanical-driven CFD simulations - carried out on an anatomically accurate geometry of the whole heart - provide results that match the cardiac physiology both qualitatively (in terms of flow patterns) and quantitatively (when comparing in silico results with biomarkers acquired in vivo). We consider the pathological case of left bundle branch block, and we investigate the consequences that an electrical abnormality has on cardiac hemodynamics thanks to our multiphysics integrated model. The computational model that we propose can faithfully predict a delay and an increasing wall shear stress in the left ventricle in the pathological condition. The interaction of different physical processes in an integrated framework allows us to faithfully describe and model this pathology, by capturing and reproducing the intrinsic multiphysics nature of the human heart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02148v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>physics.bio-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2024.112885</arxiv:DOI>
      <dc:creator>Alberto Zingaro, Michele Bucelli, Roberto Piersanti, Francesco Regazzoni, Luca Dede', Alfio Quarteroni</dc:creator>
    </item>
    <item>
      <title>Robust Variational Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2308.16910</link>
      <description>arXiv:2308.16910v3 Announce Type: replace 
Abstract: We introduce a Robust version of the Variational Physics-Informed Neural Networks method (RVPINNs). As in VPINNs, we define the quadratic loss functional in terms of a Petrov-Galerkin-type variational formulation of the PDE problem: the trial space is a (Deep) Neural Network (DNN) manifold, while the test space is a finite-dimensional vector space. Whereas the VPINN's loss depends upon the selected basis functions of a given test space, herein, we minimize a loss based on the discrete dual norm of the residual. The main advantage of such a loss definition is that it provides a reliable and efficient estimator of the true error in the energy norm under the assumption of the existence of a local Fortin operator. We test the performance and robustness of our algorithm in several advection-diffusion problems. These numerical results perfectly align with our theoretical findings, showing that our estimates are sharp.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16910v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio Rojas, Pawe{\l} Maczuga, Judit Mu\~noz-Matute, David Pardo, Maciej Paszynski</dc:creator>
    </item>
    <item>
      <title>Chebyshev HOPGD with sparse grid sampling for parameterized linear systems</title>
      <link>https://arxiv.org/abs/2309.14178</link>
      <description>arXiv:2309.14178v2 Announce Type: replace 
Abstract: We consider approximating solutions to parameterized linear systems of the form $A(\mu_1,\mu_2) x(\mu_1,\mu_2) = b$, where $(\mu_1, \mu_2) \in \mathbb{R}^2$. Here the matrix $A(\mu_1,\mu_2) \in \mathbb{R}^{n \times n}$ is nonsingular, large, and sparse and depends nonlinearly on the parameters $\mu_1$ and $\mu_2$. Specifically, the system arises from a discretization of a partial differential equation and $x(\mu_1,\mu_2) \in \mathbb{R}^n$, $b \in \mathbb{R}^n$. This work combines companion linearization with the Krylov subspace method preconditioned bi-conjugate gradient (BiCG) and a decomposition of a tensor matrix of precomputed solutions, called snapshots. As a result, a reduced order model of $x(\mu_1,\mu_2)$ is constructed, and this model can be evaluated in a cheap way for many values of the parameters. Tensor decompositions performed on a set of snapshots can fail to reach a certain level of accuracy, and it is not known a priori if a decomposition will be successful. Moreover, the selection of snapshots can affect both the quality of the produced model and the computation time required for its construction. This new method offers a way to generate a new set of solutions on the same parameter space at little additional cost. An interpolation of the model is used to produce approximations on the entire parameter space, and this method can be used to solve a parameter estimation problem. Numerical examples of a parameterized Helmholtz equation show the competitiveness of our approach. The simulations are reproducible, and the software is available online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14178v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siobh\'an Correnty, Melina A. Freitag, Kirk M. Soodhalter</dc:creator>
    </item>
    <item>
      <title>A discontinuous plane wave neural network method for Helmholtz equation and time-harmonic Maxwell's equations</title>
      <link>https://arxiv.org/abs/2310.09527</link>
      <description>arXiv:2310.09527v2 Announce Type: replace 
Abstract: In this paper we propose a {\it discontinuous} plane wave neural network (DPWNN) method with $hp-$refinement for approximately solving Helmholtz equation and time-harmonic Maxwell equations. In this method, we define a quadratic functional as in the plane wave least square (PWLS) method with $h-$refinement and introduce new discretization sets spanned by element-wise neural network functions with a single hidden layer, where the activation function on each element is chosen as a complex-valued exponential function like the plane wave function. The desired approximate solution is recursively generated by iteratively solving the minimization problem associated with the functional and the sets described above, which is defined by a sequence of approximate minimizers of the underlying residual functionals, where plane wave direction angles and activation coefficients are alternatively computed by iterative algorithms. For the proposed DPWNN method, the plane wave directions are adaptively determined in the iterative process, which is different from that in the standard PWLS method (where the plane wave directions are preliminarily given). Numerical experiments will confirm that this DPWNN method can generate approximate solutions with higher accuracy than the PWLS method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09527v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Long Yuan, Qiya Hu</dc:creator>
    </item>
    <item>
      <title>An efficient frequency-independent numerical method for computing the far-field pattern induced by polygonal obstacles</title>
      <link>https://arxiv.org/abs/2310.17603</link>
      <description>arXiv:2310.17603v2 Announce Type: replace 
Abstract: For problems of time-harmonic scattering by rational polygonal obstacles, embedding formulae express the far-field pattern induced by any incident plane wave in terms of the far-field patterns for a relatively small (frequency-independent) set of canonical incident angles. Although these remarkable formulae are exact in theory, here we demonstrate that: (i) they are highly sensitive to numerical errors in practice, and (ii) direct calculation of the coefficients in these formulae may be impossible for particular sets of canonical incident angles, even in exact arithmetic. Only by overcoming these practical issues can embedding formulae provide a highly efficient approach to computing the far-field pattern induced by a large number of incident angles. Here we address challenges (i) and (ii), supporting our theory with numerical experiments. Challenge (i) is solved using techniques from computational complex analysis: we reformulate the embedding formula as a complex contour integral and prove that this is much less sensitive to numerical errors. In practice, this contour integral can be efficiently evaluated by residue calculus. Challenge (ii) is addressed using techniques from numerical linear algebra: we oversample, considering more canonical incident angles than are necessary, thus expanding the set of valid coefficient vectors. The coefficient vector can then be selected using either a least squares approach or column subset selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17603v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Gibbs, S. Langdon</dc:creator>
    </item>
    <item>
      <title>Low-rank-modified Galerkin methods for the Lyapunov equation</title>
      <link>https://arxiv.org/abs/2312.00463</link>
      <description>arXiv:2312.00463v2 Announce Type: replace 
Abstract: Of all the possible projection methods for solving large-scale Lyapunov matrix equations, Galerkin approaches remain much more popular than minimal-residual ones. This is mainly due to the different nature of the projected problems stemming from these two families of methods. While a Galerkin approach leads to the solution of a low-dimensional matrix equation per iteration, a matrix least-squares problem needs to be solved per iteration in a minimal-residual setting. The significant computational cost of these least-squares problems has steered researchers towards Galerkin methods in spite of the appealing properties of minimal-residual schemes. In this paper we introduce a framework that allows for modifying the Galerkin approach by low-rank, additive corrections to the projected matrix equation problem with the two-fold goal of attaining monotonic convergence rates similar to those of minimal-residual schemes while maintaining essentially the same computational cost of the original Galerkin method. We analyze the well-posedness of our framework and determine possible scenarios where we expect the residual norm attained by two low-rank-modified variants to behave similarly to the one computed by a minimal-residual technique. A panel of diverse numerical examples shows the behavior and potential of our new approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00463v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kathryn Lund, Davide Palitta</dc:creator>
    </item>
    <item>
      <title>Inviscid Burgers as a degenerate elliptic problem</title>
      <link>https://arxiv.org/abs/2401.08814</link>
      <description>arXiv:2401.08814v3 Announce Type: replace 
Abstract: We demonstrate the feasibility of a scheme to obtain approximate weak solutions to the (inviscid) Burgers equation in conservation and Hamilton-Jacobi form, treated as degenerate elliptic problems. We show different variants recover non-unique weak solutions as appropriate, and also specific constructive approaches to recover the corresponding entropy solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08814v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uditnarayan Kouskiya, Amit Acharya</dc:creator>
    </item>
    <item>
      <title>High curvature means low-rank: On the sectional curvature of Grassmann and Stiefel manifolds and the underlying matrix trace inequalities</title>
      <link>https://arxiv.org/abs/2403.01879</link>
      <description>arXiv:2403.01879v2 Announce Type: replace 
Abstract: Methods and algorithms that work with data on nonlinear manifolds are collectively summarised under the term `Riemannian computing'. In practice, curvature can be a key limiting factor for the performance of Riemannian computing methods. Yet, curvature can also be a powerful tool in the theoretical analysis of Riemannian algorithms. In this work, we investigate the sectional curvature of the Stiefel and Grassmann manifold from the quotient space view point. On the Grassmannian, tight curvature bounds are known since the late 1960ies. On the Stiefel manifold under the canonical metric, it was believed that the sectional curvature does not exceed 5/4. For both of these manifolds, the sectional curvature is given by the Frobenius norm of certain structured commutator brackets of skew-symmetric matrices. We provide refined inequalities for such terms and pay special attention to the maximizers of the curvature bounds. In this way, we prove that the global bound of 5/4 for Stiefel holds indeed. With this addition, a complete account of the curvature bounds in all admissible dimensions is obtained. We observe that `high curvature means low-rank', more precisely, for the Stiefel and Grassmann manifolds, the global curvature maximum is attained at tangent plane sections that are spanned by rank-two matrices. Numerical examples are included for illustration purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01879v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ralf Zimmermann, Jakob Stoye</dc:creator>
    </item>
    <item>
      <title>Optimal actuator design based on shape calculus</title>
      <link>https://arxiv.org/abs/1711.01183</link>
      <description>arXiv:1711.01183v2 Announce Type: replace-cross 
Abstract: An approach to optimal actuator design based on shape and topology optimisation techniques is presented. For linear diffusion equations, two scenarios are considered. For the first one, best actuators are determined depending on a given initial condition. In the second scenario, optimal actuators are determined based on all initial conditions not exceeding a chosen norm. Shape and topological sensitivities of these cost functionals are determined. A numerical algorithm for optimal actuator design based on the sensitivities and a level-set method is presented. Numerical results support the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:1711.01183v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Kalise, Karl Kunisch, Kevin Sturm</dc:creator>
    </item>
    <item>
      <title>A Variational Approach for Joint Image Recovery and Feature Extraction Based on Spatially-Varying Generalised Gaussian Models</title>
      <link>https://arxiv.org/abs/2209.01375</link>
      <description>arXiv:2209.01375v3 Announce Type: replace-cross 
Abstract: The joint problem of reconstruction / feature extraction is a challenging task in image processing. It consists in performing, in a joint manner, the restoration of an image and the extraction of its features. In this work, we firstly propose a novel nonsmooth and non-convex variational formulation of the problem. For this purpose, we introduce a versatile generalised Gaussian prior whose parameters, including its exponent, are space-variant. Secondly, we design an alternating proximal-based optimisation algorithm that efficiently exploits the structure of the proposed non-convex objective function. We also analyse the convergence of this algorithm. As shown in numerical experiments conducted on joint deblurring/segmentation tasks, the proposed method provides high-quality results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.01375v3</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emilie Chouzenoux, Marie-Caroline Corbineau, Jean-Christophe Pesquet, Gabriele Scrivanti</dc:creator>
    </item>
    <item>
      <title>Three Paths to Rational Curves with Rational Arc Length</title>
      <link>https://arxiv.org/abs/2310.08047</link>
      <description>arXiv:2310.08047v2 Announce Type: replace-cross 
Abstract: We solve the so far open problem of constructing all spatial rational curves with rational arc length functions. More precisely, we present three different methods for this construction. The first method adapts a recent approach of (Kalkan et al. 2022) to rational PH curves and requires solving a modestly sized system of linear equations. The second constructs the curve by imposing zero-residue conditions, thus extending ideas of previous papers by (Farouki and Sakkalis 2019) and the authors themselves (Schr\"ocker and \v{S}\'ir 2023). The third method generalizes the dual approach of (Pottmann 1995) from planar to spatial curves. The three methods share the same quaternion based representation in which not only the PH curve but also its arc length function are compactly expressed. We also present a new proof based on the quaternion polynomial factorization theory of the well known characterization of the Pythagorean quadruples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08047v2</guid>
      <category>cs.SC</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans-Peter Schr\"ocker, Zbyn\v{e}k \v{S}\`ir</dc:creator>
    </item>
  </channel>
</rss>
