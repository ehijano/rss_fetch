<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.GN</link>
    <description>q-bio.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 03:02:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Toward Interpretable and Generalizable AI in Regulatory Genomics</title>
      <link>https://arxiv.org/abs/2602.01230</link>
      <description>arXiv:2602.01230v1 Announce Type: new 
Abstract: Deciphering how DNA sequence encodes gene regulation remains a central challenge in biology. Advances in machine learning and functional genomics have enabled sequence-to-function (seq2func) models that predict molecular regulatory readouts directly from DNA sequence. These models are now widely used for variant effect prediction, mechanistic interpretation, and regulatory sequence design. Despite strong performance on held-out genomic regions, their ability to generalize across genetic variation and cellular contexts remains inconsistent. Here we examine how architectural choices, training data, and prediction tasks shape the behavior of seq2func models. We synthesize how interpretability methods and evaluation practices have probed learned cis-regulatory organization and highlighted systematic failure modes, clarifying why strong predictive accuracy can fail to translate into robust regulatory understanding. We argue that progress will require reframing seq2func models as continually refined systems, in which targeted perturbation experiments, systematic evaluation, and iterative model updates are tightly coupled through AI-experiment feedback loops. Under this framework, seq2func models become self-improving tools that progressively deepen their mechanistic grounding and more reliably support biological discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01230v1</guid>
      <category>q-bio.GN</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masayuki Nagai, Alan E. Murphy, Kaeli Rizzo, Peter K. Koo</dc:creator>
    </item>
    <item>
      <title>Accelerating De Novo Genome Assembly via Quantum-Assisted Graph Optimization with Bitstring Recovery</title>
      <link>https://arxiv.org/abs/2602.00156</link>
      <description>arXiv:2602.00156v1 Announce Type: cross 
Abstract: Genome sequencing is essential to decode genetic information, identify organisms, understand diseases and advance personalized medicine. A critical step in any genome sequencing technique is genome assembly. However, de novo genome assembly, which involves constructing an entire genome sequence from scratch without a reference genome, presents significant challenges due to its high computational complexity, affecting both time and accuracy. In this study, we propose a hybrid approach utilizing a quantum computing-based optimization algorithm integrated with classical pre-processing to expedite the genome assembly process. Specifically, we present a method to solve the Hamiltonian and Eulerian paths within the genome assembly graph using gate-based quantum computing through a Higher-Order Binary Optimization (HOBO) formulation with the Variational Quantum Eigensolver algorithm (VQE), in addition to a novel bitstring recovery mechanism to improve optimizer traversal of the solution space. A comparative analysis with classical optimization techniques was performed to assess the effectiveness of our quantum-based approach in genome assembly. The results indicate that, as quantum hardware continues to evolve and noise levels diminish, our formulation holds a significant potential to accelerate genome sequencing by offering faster and more accurate solutions to the complex challenges in genomic research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00156v1</guid>
      <category>quant-ph</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaya Vasavi Pamidimukkala, Himanshu Sahu, Ashwini Kannan, Janani Ananthanarayanan, Kalyan Dasgupta, Sanjib Senapati</dc:creator>
    </item>
    <item>
      <title>DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis</title>
      <link>https://arxiv.org/abs/2602.01839</link>
      <description>arXiv:2602.01839v1 Announce Type: cross 
Abstract: Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models.
  To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01839v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ru Zhang, Xunkai Li, Yaxin Deng, Sicheng Liu, Daohan Su, Qiangqiang Dai, Hongchao Qin, Rong-Hua Li, Guoren Wang, Jia Li</dc:creator>
    </item>
    <item>
      <title>Y-Trim: Evidence-gated per-read trimming for stochastic end artifacts in ssWGBS</title>
      <link>https://arxiv.org/abs/2601.19002</link>
      <description>arXiv:2601.19002v2 Announce Type: replace 
Abstract: Single-stranded whole-genome bisulfite sequencing (ssWGBS) profiles DNA methylation in low-input and fragmented samples, yet Adaptase-mediated tailing creates stochastic artifacts that obscure true genomic ends. Current deterministic trimming methods struggle because, as we show, bisulfite-induced degeneracy creates a locally indistinguishable regime with a strictly positive Bayes error, making exact per-read boundary recovery ill-posed from FASTQ observables alone. As a result, fixed trimming rules inevitably mix over-trimming (avoidable genomic loss) and under-trimming (residual artifactual signal) under heterogeneous tail-length regimes, amplifying end-proximal bias in methylation-relevant summaries. Here we present Y-Trim, an evidence-gated trimming framework that operationalizes these constraints. Y-Trim separates admission from inference: sample-level gating activates trimming only when chemistry-consistent evidence is present, and read-level logic treats Read 2 and Read 1 asymmetrically, reflecting kinetic tailing versus conditional read-through geometry. With explicit safeguards -- including abstention under non-separable evidence -- Y-Trim bounds action without forcing false precision. Using a chemistry-consistent simulator with ground truth and a 34-sample public cohort (CCGB-34), we show that Y-Trim yields an interpretable retention-risk frontier on Read 2 while revealing feasibility-limited behavior on Read 1, and achieves competitive end-proximal artifact suppression relative to common fixed-length practice. Y-Trim provides a practical, uncertainty-aware preprocessing step for high-precision ssWGBS methylation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19002v2</guid>
      <category>q-bio.GN</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihan Fang</dc:creator>
    </item>
    <item>
      <title>GENERator: A Long-Context Generative Genomic Foundation Model</title>
      <link>https://arxiv.org/abs/2502.07272</link>
      <description>arXiv:2502.07272v5 Announce Type: replace-cross 
Abstract: The rapid advancement of DNA sequencing has produced vast genomic datasets, yet interpreting and engineering genomic function remain fundamental challenges. Recent large language models have opened new avenues for genomic analysis, but existing approaches are often limited by restricted training scope, constrained generative capability, or prohibitive computational cost. We introduce GENErator, a generative genomic foundation model for long-context DNA modeling, with a context length of 98k nucleotides, pre-trained on 386 billion nucleotides of eukaryotic DNA. Without task-specific fine-tuning, GENERator exhibits strong intrinsic capabilities: unsupervised embedding analyses reveal phylogenetically coherent structure, and sequence recovery benchmarks demonstrate generative accuracy comparable to or exceeding state-of-the-art models with substantially improved computational efficiency. In a zero-shot setting, GENERator achieves competitive variant effect prediction performance relative to alignment-based methods, while remaining fully alignment-free and broadly applicable across species. With task-specific fine-tuning, the model attains leading performance on established genomic benchmarks. We further demonstrate practical generative applications. GENERator can generate protein-coding DNA sequences that translate into structurally plausible proteins and, through a prompt-guided design framework, design cis-regulatory elements with targeted activity profiles, including synthetic super-enhancers validated by high-throughput UMI-STARR-seq assays. Together, these results establish GENERator as an efficient and biologically grounded framework for genomic interpretation and programmable sequence design. Code and supplementary resources are available at https://github.com/GenerTeam/GENERator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07272v5</guid>
      <category>cs.CL</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Wu, Qiuyi Li, Yuanyuan Zhang, Zhihao Zhan, Ruipu Chen, Mingyang Li, Kun Fu, Junyan Qi, Yongzhou Bao, Chao Wang, Yiheng Zhu, Zhiyun Zhang, Jian Tang, Fuli Feng, Jieping Ye, Yuwen Liu, Hui Xiong, Zheng Wang</dc:creator>
    </item>
  </channel>
</rss>
