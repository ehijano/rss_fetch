<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Jan 2025 05:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Intelligent Backhaul Link Selection for Traffic Offloading in B5G Networks</title>
      <link>https://arxiv.org/abs/2501.09123</link>
      <description>arXiv:2501.09123v1 Announce Type: new 
Abstract: Fifth Generation (5G) mobile networks considers an expansive set of heterogeneous services with stringent Quality of Service (QoS) requirements, and traffic demand with inherent spatial-temporal distribution, which places the backhaul network deployment under potential strain. In this paper, we propose to harness network slicing, Integrated Access and Backhaul (IAB) technology coupled with satellite connectivity to build a dynamic wireless backhaul network that can provide additional backhaul capacity to the base stations on demand when the wired backhaul link is temporarily out of capacity. To construct the network design, Deep Reinforcement Learning (DRL) models are used to select, for each network slice of the congested base station, an appropriate backhaul link from the pool of available IAB and satellite links that meets the QoS requirements (i.e., throughput and latency) of the slice. Simulation results show that around 20 episodes are sufficient to train a Double Deep Q-Network (DDQN) agent, with one fully-connected hidden layer and Rectified Linear Unit (ReLU) activation function, that adjusts the topology of the backhaul network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09123v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2024.3436890</arxiv:DOI>
      <arxiv:journal_reference>IEEE Access, vol. 12, pp. 106757-106769, 2024</arxiv:journal_reference>
      <dc:creator>Ant\'onio J. Morgado, Firooz B. Saghezchi, Pablo Fondo-Ferreiro, Felipe Gil-Casti\~neira, Jonathan Rodriguez</dc:creator>
    </item>
    <item>
      <title>5G Network Slicing as a Service Enabler for theAutomotive Sector</title>
      <link>https://arxiv.org/abs/2501.09125</link>
      <description>arXiv:2501.09125v1 Announce Type: new 
Abstract: Network slicing, a key technology introduced in 5G standards, enables mobile networks to simultaneously support a wide range ofheterogeneous use cases with diverse quality of service (QoS) requirements. This work discusses the potential benefits of networkslicing for the automotive sector, encompassing manufacturing processes and vehicular communications. The review of the stateof the art reveals a clear gap regarding the application of network slicing from the perspective of industrial verticals such asautomotive use cases and their specific requirements. Departing from this observation, we first identify limitations of previouscellular technologies and open challenges for supporting the data services required. Then we describe network slicing as an enablerto face these challenges. We present an analysis of the cost equilibrium for network slicing to be effective for car manufacturers,and tests in real 5G networks that demonstrate the performance improvement in OTA updates coexisting with other services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09125v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/eng2.13024</arxiv:DOI>
      <arxiv:journal_reference>Engineering Reports, vol. 7, p. e13024, 2025</arxiv:journal_reference>
      <dc:creator>David Candal-Ventureira, Jos\'e Manuel R\'ua-Est\'evez, Pablo Fondo-Ferreiro, Felipe Gil-Casti\~neira, Antonio Fern\'andez-Barciela, Francisco Javier Gonz\'alez-Casta\~no, Emilio Di\'eguez-Pazo, Luis Fern\'andez-Ferreira</dc:creator>
    </item>
    <item>
      <title>Adaptive Contextual Caching for Mobile Edge Large Language Model Service</title>
      <link>https://arxiv.org/abs/2501.09383</link>
      <description>arXiv:2501.09383v1 Announce Type: new 
Abstract: Mobile edge Large Language Model (LLM) deployments face inherent constraints, such as limited computational resources and network bandwidth. Although Retrieval-Augmented Generation (RAG) mitigates some challenges by integrating external knowledge bases, inefficient cache management can still result in high retrieval latency and frequent cache updates. To address these issues, we propose an Adaptive Contextual Caching (ACC) framework that anticipates user needs by proactively caching semantically relevant data for mobile-edge LLMs. ACC utilizes a deep reinforcement learning (DRL) module to refine cache replacement policies, balancing user context, document similarity, and the overhead associated with cache misses. Experimental results demonstrate that ACC increases cache hit rates to over 80\% after only 11 training episodes, outperforming FIFO, LRU, and semantic-only caching while reducing retrieval latency by up to 40\%. In particular, ACC also reduces local caching overhead (i.e., the cost of updating the cache when a miss occurs) by as much as 55\%, enabling scalable, low-latency LLM services in resource-constrained edge environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09383v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangyuan Liu, Yinqiu Liu, Jiacheng Wang, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong</dc:creator>
    </item>
    <item>
      <title>Contract-Inspired Contest Theory for Controllable Image Generation in Mobile Edge Metaverse</title>
      <link>https://arxiv.org/abs/2501.09391</link>
      <description>arXiv:2501.09391v1 Announce Type: new 
Abstract: The rapid advancement of immersive technologies has propelled the development of the Metaverse, where the convergence of virtual and physical realities necessitates the generation of high-quality, photorealistic images to enhance user experience. However, generating these images, especially through Generative Diffusion Models (GDMs), in mobile edge computing environments presents significant challenges due to the limited computing resources of edge devices and the dynamic nature of wireless networks. This paper proposes a novel framework that integrates contract-inspired contest theory, Deep Reinforcement Learning (DRL), and GDMs to optimize image generation in these resource-constrained environments. The framework addresses the critical challenges of resource allocation and semantic data transmission quality by incentivizing edge devices to efficiently transmit high-quality semantic data, which is essential for creating realistic and immersive images. The use of contest and contract theory ensures that edge devices are motivated to allocate resources effectively, while DRL dynamically adjusts to network conditions, optimizing the overall image generation process. Experimental results demonstrate that the proposed approach not only improves the quality of generated images but also achieves superior convergence speed and stability compared to traditional methods. This makes the framework particularly effective for optimizing complex resource allocation tasks in mobile edge Metaverse applications, offering enhanced performance and efficiency in creating immersive virtual environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09391v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangyuan Liu, Hongyang Du, Jiacheng Wang, Dusit Niyato, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence, Ambient Backscatter Communication and Non-Terrestrial Networks: A 6G Commixture</title>
      <link>https://arxiv.org/abs/2501.09405</link>
      <description>arXiv:2501.09405v1 Announce Type: new 
Abstract: The advent of Non-Terrestrial Networks (NTN) represents a compelling response to the International Mobile Telecommunications 2030 (IMT-2030) framework, enabling the delivery of advanced, seamless connectivity that supports reliable, sustainable, and resilient communication systems. Nevertheless, the integration of NTN with Terrestrial Networks (TN) necessitates considerable alterations to the existing cellular infrastructure in order to address the challenges intrinsic to NTN implementation. Additionally, Ambient Backscatter Communication (AmBC), which utilizes ambient Radio Frequency (RF) signals to transmit data to the intended recipient by altering and reflecting these signals, exhibits considerable potential for the effective integration of NTN and TN. Furthermore, AmBC is constrained by its limitations regarding power, interference, and other related factors. In contrast, the application of Artificial Intelligence (AI) within wireless networks demonstrates significant potential for predictive analytics through the use of extensive datasets. AI techniques enable the real-time optimization of network parameters, mitigating interference and power limitations in AmBC. These predictive models also enhance the adaptive integration of NTN and TN, driving significant improvements in network reliability and Energy Efficiency (EE). In this paper, we present a comprehensive examination of how the commixture of AI, AmBC, and NTN can facilitate the integration of NTN and TN. We also provide a thorough analysis indicating a marked enhancement in EE predicated on this triadic relationship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09405v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ali Jamshed, Bushra Haq, Muhammad Ahmed Mohsin, Ali Nauman, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>MoE$^2$: Optimizing Collaborative Inference for Edge Large Language Models</title>
      <link>https://arxiv.org/abs/2501.09410</link>
      <description>arXiv:2501.09410v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. Exploiting the heterogeneous capabilities of edge LLMs is crucial for diverse emerging applications, as it enables greater cost-effectiveness and reduced latency. In this work, we introduce \textit{Mixture-of-Edge-Experts (MoE$^2$)}, a novel collaborative inference framework for edge LLMs. We formulate the joint gating and expert selection problem to optimize inference performance under energy and latency constraints. Unlike conventional MoE problems, LLM expert selection is significantly more challenging due to the combinatorial nature and the heterogeneity of edge LLMs across various attributes. To this end, we propose a two-level expert selection mechanism through which we uncover an optimality-preserving property of gating parameters across expert selections. This property enables the decomposition of the training and selection processes, significantly reducing complexity. Furthermore, we leverage the objective's monotonicity and design a discrete monotonic optimization algorithm for optimal expert selection. We implement edge servers with NVIDIA Jetson AGX Orins and NVIDIA RTX 4090 GPUs, and perform extensive experiments. Our results validate that performance improvements of various LLM models and show that our MoE$^2$ method can achieve optimal trade-offs among different delay and energy budgets, and outperforms baselines under various system resource constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09410v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lyudong Jin, Yanning Zhang, Yanhan Li, Shurong Wang, Howard H. Yang, Jian Wu, Meng Zhang</dc:creator>
    </item>
    <item>
      <title>SeQUeNCe GUI: An Extensible User Interface for Discrete Event Quantum Network Simulations</title>
      <link>https://arxiv.org/abs/2501.09100</link>
      <description>arXiv:2501.09100v1 Announce Type: cross 
Abstract: With recent advances in the fields of quantum information theory [J. Pablo. Nature 12, 2172 (2021)] and the approach of the Noisy Intermediate-Scale Quantum (NISQ) [J. Preskill. Quantum 2, 79 (2018)] computing era, it is necessary to provide tools for experimentation and prototyping that are able to keep pace with the rapidly progressing field of quantum computing. SeQUeNCe, an open source simulator of quantum network communication, aims to provide scalability and extensibility for the simulation of quantum networks, from the hardware level to the application and protocol level. In order to improve upon the usability of this software, we implement a graphical user interface which maintains the core principles of SeQUeNCe, scalability and extensibility, while enhancing the software's portability and ease of use. We demonstrate the capabilities of the graphical user interface through the construction of the existing Chicago metropolitan quantum network topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09100v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Kiefer</dc:creator>
    </item>
    <item>
      <title>Towards Federated Multi-Armed Bandit Learning for Content Dissemination using Swarm of UAVs</title>
      <link>https://arxiv.org/abs/2501.09146</link>
      <description>arXiv:2501.09146v1 Announce Type: cross 
Abstract: This paper introduces an Unmanned Aerial Vehicle - enabled content management architecture that is suitable for critical content access in communities of users that are communication-isolated during diverse types of disaster scenarios. The proposed architecture leverages a hybrid network of stationary anchor UAVs and mobile Micro-UAVs for ubiquitous content dissemination. The anchor UAVs are equipped with both vertical and lateral communication links, and they serve local users, while the mobile micro-ferrying UAVs extend coverage across communities with increased mobility. The focus is on developing a content dissemination system that dynamically learns optimal caching policies to maximize content availability. The core innovation is an adaptive content dissemination framework based on distributed Federated Multi-Armed Bandit learning. The goal is to optimize UAV content caching decisions based on geo-temporal content popularity and user demand variations. A Selective Caching Algorithm is also introduced to reduce redundant content replication by incorporating inter-UAV information sharing. This method strategically preserves the uniqueness in user preferences while amalgamating the intelligence across a distributed learning system. This approach improves the learning algorithm's ability to adapt to diverse user preferences. Functional verification and performance evaluation confirm the proposed architecture's utility across different network sizes, UAV swarms, and content popularity patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09146v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Kumar Bhuyan, Hrishikesh Dutta, Subir Biswas</dc:creator>
    </item>
    <item>
      <title>MagnetDB: A Longitudinal Torrent Discovery Dataset with IMDb-Matched Movies and TV Shows</title>
      <link>https://arxiv.org/abs/2501.09275</link>
      <description>arXiv:2501.09275v1 Announce Type: cross 
Abstract: BitTorrent remains a prominent channel for illicit distribution of copyrighted material, yet the supply side of such content remains understudied. We introduce MagnetDB, a longitudinal dataset of torrents discovered through the BitTorrent DHT between 2018 and 2024, containing more than 28.6 million torrents and metadata of more than 950 million files. While our primary focus is on enabling research based on the supply of pirated movies and TV shows, the dataset also encompasses other legitimate and illegitimate torrents. By applying IMDb-matching and annotation to movie and TV show torrents, MagnetDB facilitates detailed analyses of pirated content evolution in the BitTorrent network. Researchers can leverage MagnetDB to examine distribution trends, subcultural practices, and the gift economy within piracy ecosystems. Through its scale and temporal scope, MagnetDB presents a unique opportunity for investigating the broader dynamics of BitTorrent and advancing empirical knowledge on digital piracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09275v1</guid>
      <category>cs.CY</category>
      <category>cs.MM</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Seidenberger, Noah Pursell, Anindya Maiti</dc:creator>
    </item>
    <item>
      <title>HpC: A Calculus for Hybrid and Mobile Systems -- Full Version</title>
      <link>https://arxiv.org/abs/2501.09430</link>
      <description>arXiv:2501.09430v1 Announce Type: cross 
Abstract: Networked cybernetic and physical systems of the Internet of Things (IoT) immerse civilian and industrial infrastructures into an interconnected and dynamic web of hybrid and mobile devices. The key feature of such systems is the hybrid and tight coupling of mobile and pervasive discrete communications in a continuously evolving environment (discrete computations with predominant continuous dynamics). In the aim of ensuring the correctness and reliability of such heterogeneous infrastructures, we introduce the hybrid {\pi}-calculus (HpC), to formally capture both mobility, pervasiveness and hybridisation in infrastructures where the network topology and its communicating entities evolve continuously in the physical world. The {\pi}-calculus proposed by Robin Milner et al. is a process calculus that can model mobile communications and computations in a very elegant manner. The HpC we propose is a conservative extension of the classical {\pi}-calculus, i.e., the extension is ``minimal'', and yet describes mobility, time and physics of systems, while allowing to lift all theoretical results (e.g. bisimulation) to the context of that extension. We showcase the HpC by considering a realistic handover protocol among mobile devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09430v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiong Xu, Jean-Pierre Talpin, Shuling Wang, Hao Wu, Bohua Zhan, Xinxin Liu, Naijun Zhan</dc:creator>
    </item>
    <item>
      <title>Authenticated Delegation and Authorized AI Agents</title>
      <link>https://arxiv.org/abs/2501.09674</link>
      <description>arXiv:2501.09674v1 Announce Type: cross 
Abstract: The rapid deployment of autonomous AI agents creates urgent challenges around authorization, accountability, and access control in digital spaces. New standards are needed to know whom AI agents act on behalf of and guide their use appropriately, protecting online spaces while unlocking the value of task delegation to autonomous agents. We introduce a novel framework for authenticated, authorized, and auditable delegation of authority to AI agents, where human users can securely delegate and restrict the permissions and scope of agents while maintaining clear chains of accountability. This framework builds on existing identification and access management protocols, extending OAuth 2.0 and OpenID Connect with agent-specific credentials and metadata, maintaining compatibility with established authentication and web infrastructure. Further, we propose a framework for translating flexible, natural language permissions into auditable access control configurations, enabling robust scoping of AI agent capabilities across diverse interaction modalities. Taken together, this practical approach facilitates immediate deployment of AI agents while addressing key security and accountability concerns, working toward ensuring agentic AI systems perform only appropriate actions and providing a tool for digital service providers to enable AI agent interactions without risking harm from scalable interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09674v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tobin South, Samuele Marro, Thomas Hardjono, Robert Mahari, Cedric Deslandes Whitney, Dazza Greenwood, Alan Chan, Alex Pentland</dc:creator>
    </item>
    <item>
      <title>Intelligent OLSR Routing Protocol Optimization for VANETs</title>
      <link>https://arxiv.org/abs/2501.09716</link>
      <description>arXiv:2501.09716v1 Announce Type: cross 
Abstract: Recent advances in wireless technologies have given rise to the emergence of vehicular ad hoc networks (VANETs). In such networks, the limited coverage of WiFi and the high mobility of the nodes generate frequent topology changes and network fragmentations. For these reasons, and taking into account that there is no central manager entity, routing packets through the network is a challenging task. Therefore, offering an efficient routing strategy is crucial to the deployment of VANETs. This paper deals with the optimal parameter setting of the optimized link state routing (OLSR), which is a well-known mobile ad hoc network routing protocol, by defining an optimization problem. This way, a series of representative metaheuristic algorithms (particle swarm optimization, differential evolution, genetic algorithm, and simulated annealing) are studied in this paper to find automatically optimal configurations of this routing protocol. In addition, a set of realistic VANET scenarios (based in the city of M\'alaga) have been defined to accurately evaluate the performance of the network under our automatic OLSR. In the experiments, our tuned OLSR configurations result in better quality of service (QoS) than the standard request for comments (RFC 3626), as well as several human experts, making it amenable for utilization in VANET configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09716v1</guid>
      <category>cs.NE</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2012.2188552</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Vehicular Technology, vol. 61, no. 4, pp. 1884-1894, May 2012</arxiv:journal_reference>
      <dc:creator>Jamal Toutouh, Jos\'e Garc\'ia-Nieto, Enrique Alba</dc:creator>
    </item>
    <item>
      <title>Parallel multi-objective metaheuristics for smart communications in vehicular networks</title>
      <link>https://arxiv.org/abs/2501.09725</link>
      <description>arXiv:2501.09725v1 Announce Type: cross 
Abstract: This article analyzes the use of two parallel multi-objective soft computing algorithms to automatically search for high-quality settings of the Ad hoc On Demand Vector routing protocol for vehicular networks. These methods are based on an evolutionary algorithm and on a swarm intelligence approach. The experimental analysis demonstrates that the configurations computed by our optimization algorithms outperform other state-of-the-art optimized ones. In turn, the computational efficiency achieved by all the parallel versions is greater than 87 %. Therefore, the line of work presented in this article represents an efficient framework to improve vehicular communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09725v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00500-015-1891-2</arxiv:DOI>
      <arxiv:journal_reference>TSoft Computing, 21(8), 1949-1961 (2017)</arxiv:journal_reference>
      <dc:creator>Jamal Toutouh, Enrique Alba</dc:creator>
    </item>
    <item>
      <title>Energy-Efficiency and Spectral-Efficiency Trade-off in Distributed Massive-MIMO Networks</title>
      <link>https://arxiv.org/abs/2501.01271</link>
      <description>arXiv:2501.01271v2 Announce Type: replace 
Abstract: This paper investigates the inherent trade-off between energy efficiency (EE) and spectral efficiency (SE) in distributed massive-MIMO (D-mMIMO) systems. Optimizing the EE and SE together is crucial as increasing spectral efficiency often leads to higher energy consumption. Joint power allocation and AP-UE association are pivotal in this trade-off analysis because they directly influence both EE and SE. We address the gap in existing literature where the EE-SE trade-off has been analyzed but not optimized in the context of D-mMIMO systems. The focus of this study is to maximize the EE with constraints on uplink sum SE through judicious power allocation and AP-UE association, essential for enhancing network throughput. Numerical simulations are performed to validate the proposed model, exploring the impacts of AP-UE association and power allocation on the EE-SE trade-off in uplink D-mMIMO scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01271v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohd Saif Ali Khan, Samar Agnihotri, Karthik RM</dc:creator>
    </item>
    <item>
      <title>Top-k Multi-Armed Bandit Learning for Content Dissemination in Swarms of Micro-UAVs</title>
      <link>https://arxiv.org/abs/2404.10845</link>
      <description>arXiv:2404.10845v2 Announce Type: replace-cross 
Abstract: This paper presents a Micro-Unmanned Aerial Vehicle (UAV)-enhanced content management system for disaster scenarios where communication infrastructure is generally compromised. Utilizing a hybrid network of stationary and mobile Micro-UAVs, this system aims to provide crucial content access to isolated communities. In the developed architecture, stationary anchor UAVs, equipped with vertical and lateral links, serve users in individual disaster-affected communities. and mobile micro-ferrying UAVs, with enhanced mobility, extend coverage across multiple such communities. The primary goal is to devise a content dissemination system that dynamically learns caching policies to maximize content accessibility to users left without communication infrastructure. The core contribution is an adaptive content dissemination framework that employs a decentralized Top-k Multi-Armed Bandit learning approach for efficient UAV caching decisions. This approach accounts for geo-temporal variations in content popularity and diverse user demands. Additionally, a Selective Caching Algorithm is proposed to minimize redundant content copies by leveraging inter-UAV information sharing. Through functional verification and performance evaluation, the proposed framework demonstrates improved system performance and adaptability across varying network sizes, micro-UAV swarms, and content popularity distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10845v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Kumar Bhuyan, Hrishikesh Dutta, Subir Biswas</dc:creator>
    </item>
    <item>
      <title>Multiplexed Quantum Communication with Surface and Hypergraph Product Codes</title>
      <link>https://arxiv.org/abs/2406.08832</link>
      <description>arXiv:2406.08832v2 Announce Type: replace-cross 
Abstract: Connecting multiple processors via quantum interconnect technologies could help overcome scalability issues in single-processor quantum computers. Transmission via these interconnects can be performed more efficiently using quantum multiplexing, where information is encoded in high-dimensional photonic degrees of freedom. We explore the effects of multiplexing on logical error rates in surface codes and hypergraph product codes. We show that, although multiplexing makes loss errors more damaging, assigning qubits to photons in an intelligent manner can minimize these effects, and the ability to encode higher-distance codes in a smaller number of photons can result in overall lower logical error rates. This multiplexing technique can also be adapted to quantum communication and multimode quantum memory with high-dimensional qudit systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08832v2</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shin Nishio, Nicholas Connolly, Nicol\`o Lo Piparo, William John Munro, Thomas Rowan Scruby, Kae Nemoto</dc:creator>
    </item>
    <item>
      <title>Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards</title>
      <link>https://arxiv.org/abs/2408.11775</link>
      <description>arXiv:2408.11775v2 Announce Type: replace-cross 
Abstract: Recent studies show that large language models (LLMs) struggle with technical standards in telecommunications. We propose a fine-tuned retrieval-augmented generation (RAG) system based on the Phi-2 small language model (SLM) to serve as an oracle for communication networks. Our developed system leverages forward-looking semantic chunking to adaptively determine parsing breakpoints based on embedding similarity, enabling effective processing of diverse document formats. To handle the challenge of multiple similar contexts in technical standards, we employ a re-ranking algorithm to prioritize the most relevant retrieved chunks. Recognizing the limitations of Phi-2's small context window, we implement a recent technique, namely SelfExtend, to expand the context window during inference, which not only boosts the performance but also can accommodate a wider range of user queries and design requirements from customers to specialized technicians. For fine-tuning, we utilize the low-rank adaptation (LoRA) technique to enhance computational efficiency during training and enable effective fine-tuning on small datasets. Our comprehensive experiments demonstrate substantial improvements over existing question-answering approaches in the telecom domain, achieving performance that exceeds larger language models such as GPT-4 (which is about 880 times larger in size). This work presents a novel approach to leveraging SLMs for communication networks, offering a balance of efficiency and performance. This work can serve as a foundation towards agentic language models for networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11775v2</guid>
      <category>cs.CL</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Erak, Nouf Alabbasi, Omar Alhussein, Ismail Lotfi, Amr Hussein, Sami Muhaidat, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Enhanced SPS Velocity-adaptive Scheme: Access Fairness in 5G NR V2I Networks</title>
      <link>https://arxiv.org/abs/2501.08037</link>
      <description>arXiv:2501.08037v2 Announce Type: replace-cross 
Abstract: Vehicle-to-Infrastructure (V2I) technology enables information exchange between vehicles and road infrastructure. Specifically, when a vehicle approaches a roadside unit (RSU), it can exchange information with the RSU to obtain accurate data that assists in driving. With the release of the 3rd Generation Partnership Project (3GPP) Release 16, which includes the 5G New Radio (NR) Vehicle-to-Everything (V2X) standards, vehicles typically adopt mode-2 communication using sensing-based semi-persistent scheduling (SPS) for resource allocation. In this approach, vehicles identify candidate resources within a selection window and exclude ineligible resources based on information from a sensing window. However, vehicles often drive at different speeds, resulting in varying amounts of data transmission with RSUs as they pass by, which leads to unfair access. Therefore, it is essential to design an access scheme that accounts for different vehicle speeds to achieve fair access across the network. This paper formulates an optimization problem for vehicular networks and proposes a multi-objective optimization scheme to address it by adjusting the selection window in the SPS mechanism of 5G NR V2I mode-2. Simulation results demonstrate the effectiveness of the proposed scheme</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08037v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiao Xu, Qiong Wu, Pingyi Fan, Kezhi Wang</dc:creator>
    </item>
  </channel>
</rss>
