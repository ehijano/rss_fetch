<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Apr 2024 19:07:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Nonparametric Estimation of the Transition Density Function for Diffusion Processes</title>
      <link>https://arxiv.org/abs/2404.00157</link>
      <description>arXiv:2404.00157v1 Announce Type: new 
Abstract: We assume that we observe $N$ independent copies of a diffusion process on a time interval $[0,2T]$. For a given time $t$, we estimate the transition density $p_t(x,y)$, namely the conditional density of $X_{t + s}$ given $X_s = x$, under conditions on the diffusion coefficients ensuring that this quantity exists. We use a least squares projection method on a product of finite dimensional spaces, prove risk bounds for the estimator and propose an anisotropic model selection method, relying on several reference norms. A simulation study illustrates the theoretical part for Ornstein-Uhlenbeck or square-root (Cox-Ingersoll-Ross) processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00157v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabienne Comte, Nicolas Marie</dc:creator>
    </item>
    <item>
      <title>Information divergences and likelihood ratios of Poisson processes and point patterns</title>
      <link>https://arxiv.org/abs/2404.00294</link>
      <description>arXiv:2404.00294v1 Announce Type: new 
Abstract: This article develops an analytical framework for studying information divergences and likelihood ratios associated with Poisson processes and point patterns on general measurable spaces. The main results include explicit analytical formulas for Kullback-Leibler divergences, R\'enyi divergences, Hellinger distances, and likelihood ratios of the laws of Poisson point patterns in terms of their intensity measures. The general results yield similar formulas for inhomogeneous Poisson processes, compound Poisson processes, as well as spatial and marked Poisson point patterns. Additional results include simple characterisations of absolute continuity, mutual singularity, and the existence of common dominating measures. The analytical toolbox is based on Tsallis divergences of sigma-finite measures on abstract measurable spaces. The treatment is purely information-theoretic and free of any topological assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00294v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lasse Leskel\"a</dc:creator>
    </item>
    <item>
      <title>Revisiting the region determined by Spearman's $\rho$ and Spearman's footrule $\phi$</title>
      <link>https://arxiv.org/abs/2404.00398</link>
      <description>arXiv:2404.00398v1 Announce Type: new 
Abstract: Kokol and Stopar ($2023$) recently studied the exact region $\Omega_{\phi,\rho}$ determined by Spearman's footrule $\phi$ and Spearman's $\rho$ and derived a sharp lower, as well as a non-sharp upper bound for $\rho$ given $\phi$. Considering that the proofs for establishing these inequalities are novel and interesting, but technically quite involved we here provide alternative simpler proofs mainly building upon shuffles, symmetry, denseness and mass shifting. As a by-product of these proofs we derive several additional results on shuffle rearrangements and the interplay between diagonal copulas and shuffles which are of independent interest. Moreover we finally show that we can get closer to the (non-sharp) upper bound than established in the literature so far.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00398v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marco Tschimpke, Manuela Schreyer, Wolfgang Trutschnig</dc:creator>
    </item>
    <item>
      <title>Sobolev Calibration of Imperfect Computer Models</title>
      <link>https://arxiv.org/abs/2404.00630</link>
      <description>arXiv:2404.00630v1 Announce Type: new 
Abstract: Calibration refers to the statistical estimation of unknown model parameters in computer experiments, such that computer experiments can match underlying physical systems. This work develops a new calibration method for imperfect computer models, Sobolev calibration, which can rule out calibration parameters that generate overfitting calibrated functions. We prove that the Sobolev calibration enjoys desired theoretical properties including fast convergence rate, asymptotic normality and semiparametric efficiency. We also demonstrate an interesting property that the Sobolev calibration can bridge the gap between two influential methods: $L_2$ calibration and Kennedy and O'Hagan's calibration. In addition to exploring the deterministic physical experiments, we theoretically justify that our method can transfer to the case when the physical process is indeed a Gaussian process, which follows the original idea of Kennedy and O'Hagan's. Numerical simulations as well as a real-world example illustrate the competitive performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00630v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingwen Zhang, Wenjia Wang</dc:creator>
    </item>
    <item>
      <title>A compromise criterion for weighted least squares estimates</title>
      <link>https://arxiv.org/abs/2404.00753</link>
      <description>arXiv:2404.00753v1 Announce Type: new 
Abstract: When independent errors in a linear model have non-identity covariance, the ordinary least squares estimate of the model coefficients is less efficient than the weighted least squares estimate. However, the practical application of weighted least squares is challenging due to its reliance on the unknown error covariance matrix. Although feasible weighted least squares estimates, which use an approximation of this matrix, often outperform the ordinary least squares estimate in terms of efficiency, this is not always the case. In some situations, feasible weighted least squares can be less efficient than ordinary least squares. This study identifies the conditions under which feasible weighted least squares estimates using fixed weights demonstrate greater efficiency than the ordinary least squares estimate. These conditions provide guidance for the design of feasible estimates using random weights. They also shed light on how a certain robust regression estimate behaves with respect to the linear model with normal errors of unequal variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00753v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordan Bryan, Haibo Zhou, Didong Li</dc:creator>
    </item>
    <item>
      <title>Estimating sample paths of Gauss-Markov processes from noisy data</title>
      <link>https://arxiv.org/abs/2404.00784</link>
      <description>arXiv:2404.00784v1 Announce Type: new 
Abstract: I derive the pointwise conditional means and variances of an arbitrary Gauss-Markov process, given noisy observations of points on a sample path. These moments depend on the process's mean and covariance functions, and on the conditional moments of the sampled points. I study the Brownian motion and bridge as special cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00784v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Davies</dc:creator>
    </item>
    <item>
      <title>Two step estimations via the Dantzig selector for models of stochastic processes with high-dimensional parameters</title>
      <link>https://arxiv.org/abs/2404.00888</link>
      <description>arXiv:2404.00888v1 Announce Type: new 
Abstract: We consider the sparse estimation for stochastic processes with possibly infinite-dimensional nuisance parameters, by using the Dantzig selector which is a sparse estimation method similar to $Z$-estimation. When a consistent estimator for a nuisance parameter is obtained, it is possible to construct an asymptotically normal estimator for the parameter of interest under appropriate conditions. Motivated by this fact, we establish the asymptotic behavior of the Dantzig selector for models of ergodic stochastic processes with high-dimensional parameters of interest and possibly infinite-dimensional nuisance parameters. Applications to ergodic time series models including integer-valued autoregressive models and ergodic diffusion processes are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00888v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kou Fujimori, Koji Tsukuda</dc:creator>
    </item>
    <item>
      <title>Inference in Randomized Least Squares and PCA via Normality of Quadratic Forms</title>
      <link>https://arxiv.org/abs/2404.00912</link>
      <description>arXiv:2404.00912v1 Announce Type: new 
Abstract: Randomized algorithms can be used to speed up the analysis of large datasets. In this paper, we develop a unified methodology for statistical inference via randomized sketching or projections in two of the most fundamental problems in multivariate statistical analysis: least squares and PCA. The methodology applies to fixed datasets -- i.e., is data-conditional -- and the only randomness is due to the randomized algorithm. We propose statistical inference methods for a broad range of sketching distributions, such as the subsampled randomized Hadamard transform (SRHT), Sparse Sign Embeddings (SSE) and CountSketch, sketching matrices with i.i.d. entries, and uniform subsampling. To our knowledge, no comparable methods are available for SSE and for SRHT in PCA. Our novel theoretical approach rests on showing the asymptotic normality of certain quadratic forms. As a contribution of broader interest, we show central limit theorems for quadratic forms of the SRHT, relying on a novel proof via a dyadic expansion that leverages the recursive structure of the Hadamard transform. Numerical experiments using both synthetic and empirical datasets support the efficacy of our methods, and in particular suggest that sketching methods can have better computation-estimation tradeoffs than recently proposed optimal subsampling methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00912v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leda Wang, Zhixiang Zhang, Edgar Dobriban</dc:creator>
    </item>
    <item>
      <title>Optimal Ridge Regularization for Out-of-Distribution Prediction</title>
      <link>https://arxiv.org/abs/2404.01233</link>
      <description>arXiv:2404.01233v1 Announce Type: new 
Abstract: We study the behavior of optimal ridge regularization and optimal ridge risk for out-of-distribution prediction, where the test distribution deviates arbitrarily from the train distribution. We establish general conditions that determine the sign of the optimal regularization level under covariate and regression shifts. These conditions capture the alignment between the covariance and signal structures in the train and test data and reveal stark differences compared to the in-distribution setting. For example, a negative regularization level can be optimal under covariate shift or regression shift, even when the training features are isotropic or the design is underparameterized. Furthermore, we prove that the optimally-tuned risk is monotonic in the data aspect ratio, even in the out-of-distribution setting and when optimizing over negative regularization levels. In general, our results do not make any modeling assumptions for the train or the test distributions, except for moment bounds, and allow for arbitrary shifts and the widest possible range of (negative) regularization levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01233v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pratik Patil, Jin-Hong Du, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules</title>
      <link>https://arxiv.org/abs/2404.01245</link>
      <description>arXiv:2404.01245v1 Announce Type: new 
Abstract: Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of incorrectly classifying LLM-generated text as human-written). Our framework further reduces the problem of determining the optimal detection rule to solving a minimax optimization program. We apply this framework to two representative watermarks -- one of which has been internally implemented at OpenAI -- and obtain several findings that can be instrumental in guiding the practice of implementing watermarks. In particular, we derive optimal detection rules for these watermarks under our framework. These theoretically derived detection rules are demonstrated to be competitive and sometimes enjoy a higher power than existing detection approaches through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01245v1</guid>
      <category>math.ST</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Feng Ruan, Huiyuan Wang, Qi Long, Weijie J. Su</dc:creator>
    </item>
    <item>
      <title>Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data</title>
      <link>https://arxiv.org/abs/2404.00221</link>
      <description>arXiv:2404.00221v1 Announce Type: cross 
Abstract: Many public policies and medical interventions involve dynamics in their treatment assignments, where treatments are sequentially assigned to the same individuals across multiple stages, and the effect of treatment at each stage is usually heterogeneous with respect to the history of prior treatments and associated characteristics. We study statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's history. We propose a step-wise doubly-robust approach to learn the optimal DTR using observational data under the assumption of sequential ignorability. The approach solves the sequential treatment assignment problem through backward induction, where, at each step, we combine estimators of propensity scores and action-value functions (Q-functions) to construct augmented inverse probability weighting estimators of values of policies for each stage. The approach consistently estimates the optimal DTR if either a propensity score or Q-function for each stage is consistently estimated. Furthermore, the resulting DTR can achieve the optimal convergence rate $n^{-1/2}$ of regret under mild conditions on the convergence rate for estimators of the nuisance parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00221v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shosei Sakaguchi</dc:creator>
    </item>
    <item>
      <title>The distribution of Bayes' ratio</title>
      <link>https://arxiv.org/abs/2404.00744</link>
      <description>arXiv:2404.00744v1 Announce Type: cross 
Abstract: The ratio of Bayesian evidences is a popular tool in cosmology to compare different models. There are however several issues with this method: Bayes' ratio depends on the prior even in the limit of non-informative priors, and Jeffrey's scale, used to assess the test, is arbitrary. Moreover, the standard use of Bayes' ratio is often criticized for being unable to reject models. In this paper, we address these shortcoming by promoting evidences and evidence ratios to frequentist statistics and deriving their sampling distributions. By comparing the evidence ratios to their sampling distributions, poor fitting models can now be rejected. Our method additionally does not depend on the prior in the limit of very weak priors, thereby safeguarding the experimenter against premature rejection of a theory with a uninformative prior, and replaces the arbitrary Jeffrey's scale by probability thresholds for rejection. We provide analytical solutions for some simplified cases (Gaussian data, linear parameters, and nested models), and we apply the method to cosmological supernovae Ia data. We dub our method the FB method, for Frequentist-Bayesian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00744v1</guid>
      <category>astro-ph.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Amendola, Vrund Patel, Ziad Sakr, Elena Sellentin, Kevin Wolz</dc:creator>
    </item>
    <item>
      <title>Adversarially-Robust Inference on Trees via Belief Propagation</title>
      <link>https://arxiv.org/abs/2404.00768</link>
      <description>arXiv:2404.00768v1 Announce Type: cross 
Abstract: We introduce and study the problem of posterior inference on tree-structured graphical models in the presence of a malicious adversary who can corrupt some observed nodes. In the well-studied broadcasting on trees model, corresponding to the ferromagnetic Ising model on a $d$-regular tree with zero external field, when a natural signal-to-noise ratio exceeds one (the celebrated Kesten-Stigum threshold), the posterior distribution of the root given the leaves is bounded away from $\mathrm{Ber}(1/2)$, and carries nontrivial information about the sign of the root. This posterior distribution can be computed exactly via dynamic programming, also known as belief propagation.
  We first confirm a folklore belief that a malicious adversary who can corrupt an inverse-polynomial fraction of the leaves of their choosing makes this inference impossible. Our main result is that accurate posterior inference about the root vertex given the leaves is possible when the adversary is constrained to make corruptions at a $\rho$-fraction of randomly-chosen leaf vertices, so long as the signal-to-noise ratio exceeds $O(\log d)$ and $\rho \leq c \varepsilon$ for some universal $c &gt; 0$. Since inference becomes information-theoretically impossible when $\rho \gg \varepsilon$, this amounts to an information-theoretically optimal fraction of corruptions, up to a constant multiplicative factor. Furthermore, we show that the canonical belief propagation algorithm performs this inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00768v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel B. Hopkins, Anqi Li</dc:creator>
    </item>
    <item>
      <title>Convolution-t Distributions</title>
      <link>https://arxiv.org/abs/2404.00864</link>
      <description>arXiv:2404.00864v1 Announce Type: cross 
Abstract: We introduce a new class of multivariate heavy-tailed distributions that are convolutions of heterogeneous multivariate t-distributions. Unlike commonly used heavy-tailed distributions, the multivariate convolution-t distributions embody cluster structures with flexible nonlinear dependencies and heterogeneous marginal distributions. Importantly, convolution-t distributions have simple density functions that facilitate estimation and likelihood-based inference. The characteristic features of convolution-t distributions are found to be important in an empirical analysis of realized volatility measures and help identify their underlying factor structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00864v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Reinhard Hansen, Chen Tong</dc:creator>
    </item>
    <item>
      <title>Random Circuit Sampling: Fourier Expansion and Statistics</title>
      <link>https://arxiv.org/abs/2404.00935</link>
      <description>arXiv:2404.00935v1 Announce Type: cross 
Abstract: Considerable effort in experimental quantum computing is devoted to noisy intermediate scale quantum computers (NISQ computers). Understanding the effect of noise is important for various aspects of this endeavor including notable claims for achieving quantum supremacy and attempts to demonstrate quantum error correcting codes. In this paper we use Fourier methods combined with statistical analysis to study the effect of noise. In particular, we use Fourier analysis to refine the linear cross-entropy fidelity estimator. We use both analytical methods and simulations to study the effect of readout and gate errors, and we use our analysis to study the samples of Google's 2019 quantum supremacy experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00935v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gil Kalai, Yosef Rinott, Tomer Shoham</dc:creator>
    </item>
    <item>
      <title>TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression</title>
      <link>https://arxiv.org/abs/2404.01153</link>
      <description>arXiv:2404.01153v1 Announce Type: cross 
Abstract: The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused-regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the estimation rate of the centralized version. Numerical tests validate our theory, highlighting the method's robustness to covariate shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01153v1</guid>
      <category>stat.ML</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zelin He, Ying Sun, Jingyuan Liu, Runze Li</dc:creator>
    </item>
    <item>
      <title>Two-Step Mixed-Type Multivariate Bayesian Sparse Variable Selection with Shrinkage Priors</title>
      <link>https://arxiv.org/abs/2201.12839</link>
      <description>arXiv:2201.12839v5 Announce Type: replace 
Abstract: We introduce a Bayesian framework for mixed-type multivariate regression using continuous shrinkage priors. Our framework enables joint analysis of mixed continuous and discrete outcomes and facilitates variable selection from the $p$ covariates. Theoretical studies of Bayesian mixed-type multivariate response models have not been conducted previously and require more intricate arguments than the corresponding theory for univariate response models due to the correlations between the responses. In this paper, we investigate necessary and sufficient conditions for posterior contraction of our method when $p$ grows faster than sample size $n$. The existing literature on Bayesian high-dimensional asymptotics has focused only on cases where $p$ grows subexponentially with $n$. In contrast, we study the asymptotic regime where $p$ is allowed to grow exponentially terms of $n$. We develop a novel two-step approach for variable selection which possesses the sure screening property and provably achieves posterior contraction even under exponential growth of $p$. We demonstrate the utility of our method through simulation studies and applications to real data, including a cancer genomics dataset where $n=174$ and $p=9183$. The R code to implement our method is available at https://github.com/raybai07/MtMBSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.12839v5</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shao-Hsuan Wang, Ray Bai, Hsin-Hsiung Huang</dc:creator>
    </item>
    <item>
      <title>Detection of Small Holes by the Scale-Invariant Robust Density-Aware Distance (RDAD) Filtration</title>
      <link>https://arxiv.org/abs/2204.07821</link>
      <description>arXiv:2204.07821v3 Announce Type: replace 
Abstract: A novel topological-data-analytical (TDA) method is proposed to distinguish, from noise, small holes surrounded by high-density regions of a probability density function. The proposed method is robust against additive noise and outliers. Traditional TDA tools, like those based on the distance filtration, often struggle to distinguish small features from noise, because both have short persistences. An alternative filtration, called the Robust Density-Aware Distance (RDAD) filtration, is proposed to prolong the persistences of small holes of high-density regions. This is achieved by weighting the distance function by the density in the sense of Bell et al. The concept of distance-to-measure is incorporated to enhance stability and mitigate noise. The persistence-prolonging property and robustness of the proposed filtration are rigorously established, and numerical experiments are presented to demonstrate the proposed filtration's utility in identifying small holes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.07821v3</guid>
      <category>math.ST</category>
      <category>cs.CG</category>
      <category>math.AT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s41468-024-00166-9</arxiv:DOI>
      <dc:creator>Chunyin Siu, Gennady Samorodnitsky, Christina Lee Yu, Andrey Yao</dc:creator>
    </item>
    <item>
      <title>Large-scale Multiple Testing: Fundamental Limits of False Discovery Rate Control and Compound Oracle</title>
      <link>https://arxiv.org/abs/2302.06809</link>
      <description>arXiv:2302.06809v2 Announce Type: replace 
Abstract: The false discovery rate (FDR) and the false non-discovery rate (FNR), defined as the expected false discovery proportion (FDP) and the false non-discovery proportion (FNP), are the most popular benchmarks for multiple testing. Despite the theoretical and algorithmic advances in recent years, the optimal tradeoff between the FDR and the FNR has been largely unknown except for certain restricted classes of decision rules, e.g., separable rules, or for other performance metrics, e.g., the marginal FDR and the marginal FNR (mFDR and mFNR). In this paper, we determine the asymptotically optimal FDR-FNR tradeoff under the two-group random mixture model when the number of hypotheses tends to infinity. Distinct from the optimal mFDR-mFNR tradeoff, which is achieved by separable decision rules, the optimal FDR-FNR tradeoff requires compound rules even in the large-sample limit and for models as simple as the Gaussian location model. This suboptimality of separable rules also holds for other objectives, such as maximizing the expected number of true discoveries. Finally, to address the limitation of the FDR which only controls the expectation but not the fluctuation of the FDP, we also determine the optimal tradeoff when the FDP is controlled with high probability and show it coincides with that of the mFDR and the mFNR. Extensions to models with a fixed non-null proportion are also obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.06809v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Nie, Yihong Wu</dc:creator>
    </item>
    <item>
      <title>Variational Transport: A Convergent Particle-BasedAlgorithm for Distributional Optimization</title>
      <link>https://arxiv.org/abs/2012.11554</link>
      <description>arXiv:2012.11554v2 Announce Type: replace-cross 
Abstract: We consider the optimization problem of minimizing a functional defined over a family of probability distributions, where the objective functional is assumed to possess a variational form. Such a distributional optimization problem arises widely in machine learning and statistics, with Monte-Carlo sampling, variational inference, policy optimization, and generative adversarial network as examples. For this problem, we propose a novel particle-based algorithm, dubbed as variational transport, which approximately performs Wasserstein gradient descent over the manifold of probability distributions via iteratively pushing a set of particles. Specifically, we prove that moving along the geodesic in the direction of functional gradient with respect to the second-order Wasserstein distance is equivalent to applying a pushforward mapping to a probability distribution, which can be approximated accurately by pushing a set of particles. Specifically, in each iteration of variational transport, we first solve the variational problem associated with the objective functional using the particles, whose solution yields the Wasserstein gradient direction. Then we update the current distribution by pushing each particle along the direction specified by such a solution. By characterizing both the statistical error incurred in estimating the Wasserstein gradient and the progress of the optimization algorithm, we prove that when the objective function satisfies a functional version of the Polyak-\L{}ojasiewicz (PL) (Polyak, 1963) and smoothness conditions, variational transport converges linearly to the global minimum of the objective functional up to a certain statistical error, which decays to zero sublinearly as the number of particles goes to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.11554v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuoran Yang, Yufeng Zhang, Yongxin Chen, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Hypothesis Testing for Functional Linear Models via Bootstrapping</title>
      <link>https://arxiv.org/abs/2109.02309</link>
      <description>arXiv:2109.02309v4 Announce Type: replace-cross 
Abstract: Hypothesis testing for the slope function in functional linear regression is of both practical and theoretical interest. We develop a novel test for the nullity of the slope function, where testing the slope function is transformed into testing a high-dimensional vector based on functional principal component analysis. This transformation fully circumvents ill-posedness in functional linear regression, thereby enhancing numeric stability. The proposed method leverages the technique of bootstrapping max statistics and exploits the inherent variance decay property of functional data, improving the empirical power of tests especially when the sample size is limited or the signal is relatively weak. We establish validity and consistency of our proposed test when the functional principal components are derived from data. Moreover, we show that the test maintains its asymptotic validity and consistency, even when including \emph{all} empirical functional principal components in our test statistics. This sharply contrasts with the task of estimating the slope function, which requires a delicate choice of the number (at most in the order of $\sqrt n$) of functional principal components to ensure estimation consistency. This distinction highlights an interesting difference between estimation and statistical inference regarding the slope function in functional linear regression. To the best of our knowledge, the proposed test is the first of its kind to utilize all empirical functional principal components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.02309v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinan Lin, Zhenhua Lin</dc:creator>
    </item>
    <item>
      <title>Multitask Learning and Bandits via Robust Statistics</title>
      <link>https://arxiv.org/abs/2112.14233</link>
      <description>arXiv:2112.14233v4 Announce Type: replace-cross 
Abstract: Decision-makers often simultaneously face many related but heterogeneous learning problems. For instance, a large retailer may wish to learn product demand at different stores to solve pricing or inventory problems, making it desirable to learn jointly for stores serving similar customers; alternatively, a hospital network may wish to learn patient risk at different providers to allocate personalized interventions, making it desirable to learn jointly for hospitals serving similar patient populations. Motivated by real datasets, we study a natural setting where the unknown parameter in each learning instance can be decomposed into a shared global parameter plus a sparse instance-specific term. We propose a novel two-stage multitask learning estimator that exploits this structure in a sample-efficient way, using a unique combination of robust statistics (to learn across similar instances) and LASSO regression (to debias the results). Our estimator yields improved sample complexity bounds in the feature dimension d relative to commonly-employed estimators; this improvement is exponential for "data-poor" instances, which benefit the most from multitask learning. We illustrate the utility of these results for online learning by embedding our multitask estimator within simultaneous contextual bandit algorithms. We specify a dynamic calibration of our estimator to appropriately balance the bias-variance tradeoff over time, improving the resulting regret bounds in the context dimension d. Finally, we illustrate the value of our approach on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.14233v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kan Xu, Hamsa Bastani</dc:creator>
    </item>
    <item>
      <title>Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2205.13589</link>
      <description>arXiv:2205.13589v3 Announce Type: replace-cross 
Abstract: We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \underline{P}roxy variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization (\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \texttt{P3O} achieves a $n^{-1/2}$-suboptimality, where $n$ is the number of trajectories in the dataset. To our best knowledge, \texttt{P3O} is the first provably efficient offline RL algorithm for POMDPs with a confounded dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13589v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miao Lu, Yifei Min, Zhaoran Wang, Zhuoran Yang</dc:creator>
    </item>
    <item>
      <title>Estimating large causal polytrees from small samples</title>
      <link>https://arxiv.org/abs/2209.07028</link>
      <description>arXiv:2209.07028v3 Announce Type: replace-cross 
Abstract: We consider the problem of estimating a large causal polytree from a relatively small i.i.d. sample. This is motivated by the problem of determining causal structure when the number of variables is very large compared to the sample size, such as in gene regulatory networks. We give an algorithm that recovers the tree with high accuracy in such settings. The algorithm works under essentially no distributional or modeling assumptions other than some mild non-degeneracy conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.07028v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourav Chatterjee, Mathukumalli Vidyasagar</dc:creator>
    </item>
    <item>
      <title>Fast and Optimal Inference for Change Points in Piecewise Polynomials via Differencing</title>
      <link>https://arxiv.org/abs/2307.03639</link>
      <description>arXiv:2307.03639v2 Announce Type: replace-cross 
Abstract: We consider the problem of uncertainty quantification in change point regressions, where the signal can be piecewise polynomial of arbitrary but fixed degree. That is we seek disjoint intervals which, uniformly at a given confidence level, must each contain a change point location. We propose a procedure based on performing local tests at a number of scales and locations on a sparse grid, which adapts to the choice of grid in the sense that by choosing a sparser grid one explicitly pays a lower price for multiple testing. The procedure is fast as its computational complexity is always of the order $\mathcal{O} (n \log (n))$ where $n$ is the length of the data, and optimal in the sense that under certain mild conditions every change point is detected with high probability and the widths of the intervals returned match the mini-max localisation rates for the associated change point problem up to log factors. A detailed simulation study shows our procedure is competitive against state of the art algorithms for similar problems. Our procedure is implemented in the R package ChangePointInference which is available via https://github.com/gaviosha/ChangePointInference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03639v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shakeel Gavioli-Akilagun, Piotr Fryzlewicz</dc:creator>
    </item>
    <item>
      <title>Sampling depth trade-off in function estimation under a two-level design</title>
      <link>https://arxiv.org/abs/2310.02968</link>
      <description>arXiv:2310.02968v3 Announce Type: replace-cross 
Abstract: Many modern statistical applications involve a two-level sampling scheme that first samples subjects from a population and then samples observations on each subject. These schemes often are designed to learn both the population-level functional structures shared by the subjects and the functional characteristics specific to individual subjects. Common wisdom suggests that learning population-level structures benefits from sampling more subjects whereas learning subject-specific structures benefits from deeper sampling within each subject. Oftentimes these two objectives compete for limited sampling resources, which raises the question of how to optimally sample at the two levels. We quantify such sampling-depth trade-offs by establishing the $L_2$ minimax risk rates for learning the population-level and subject-specific structures under a hierarchical Gaussian process model framework where we consider a Bayesian and a frequentist perspective on the unknown population-level structure. These rates provide general lessons for designing two-level sampling schemes given a fixed sampling budget. Interestingly, they show that subject-specific learning occasionally benefits more by sampling more subjects than by deeper within-subject sampling. We show that the corresponding minimax rates can be readily achieved in practice through simple adaptive estimators without assuming prior knowledge on the underlying variability at the two sampling levels. We validate our theory and illustrate the sampling trade-off in practice through both simulation experiments and two real datasets. While we carry out all the theoretical analysis in the context of Gaussian process models for analytical tractability, the results provide insights on effective two-level sampling designs more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02968v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akira Horiguchi, Li Ma, Botond T. Szab\'o</dc:creator>
    </item>
    <item>
      <title>The twin peaks of learning neural networks</title>
      <link>https://arxiv.org/abs/2401.12610</link>
      <description>arXiv:2401.12610v2 Announce Type: replace-cross 
Abstract: Recent works demonstrated the existence of a double-descent phenomenon for the generalization error of neural networks, where highly overparameterized models escape overfitting and achieve good test performance, at odds with the standard bias-variance trade-off described by statistical learning theory. In the present work, we explore a link between this phenomenon and the increase of complexity and sensitivity of the function represented by neural networks. In particular, we study the Boolean mean dimension (BMD), a metric developed in the context of Boolean function analysis. Focusing on a simple teacher-student setting for the random feature model, we derive a theoretical analysis based on the replica method that yields an interpretable expression for the BMD, in the high dimensional regime where the number of data points, the number of features, and the input size grow to infinity. We find that, as the degree of overparameterization of the network is increased, the BMD reaches an evident peak at the interpolation threshold, in correspondence with the generalization error peak, and then slowly approaches a low asymptotic value. The same phenomenology is then traced in numerical experiments with different model classes and training setups. Moreover, we find empirically that adversarially initialized models tend to show higher BMD values, and that models that are more robust to adversarial attacks exhibit a lower BMD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12610v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elizaveta Demyanenko, Christoph Feinauer, Enrico M. Malatesta, Luca Saglietti</dc:creator>
    </item>
  </channel>
</rss>
