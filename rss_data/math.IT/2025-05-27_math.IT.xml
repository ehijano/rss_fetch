<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 May 2025 04:01:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-Subarray FD-RIS Enhanced Multi-user Wireless Networks: With Joint Distance-Angle Beamforming</title>
      <link>https://arxiv.org/abs/2505.18628</link>
      <description>arXiv:2505.18628v1 Announce Type: new 
Abstract: The concept of the frequency diverse reconfigurable intelligent surface (FD-RIS) technology has been introduced, which can enable simultaneous implementation of distance-angle beamforming in far-field communication scenarios. In order to improve the managing ability on undesired harmonic signals and the diversity of frequency offsets, this paper presents a novel multi-subarray FD-RIS framework. In this framework, the RIS is evenly divided into multiple subarrays, each employing a distinct time-modulation frequency to enable the diversity of frequency offsets. Additionally, to suppress the undesired harmonic signals, a new time-modulation technique is employed to periodically adjust the phase-shift of each element. Based on the proposed multi-subarray FD-RIS, the signal processing model is first analytically derived. To evaluate the effectiveness of the proposed multi-subarray FD-RIS, we integrate it into a multi-user communication scenario and formulate an optimization problem that aims to maximize the weighted sum rate of all users. This is achieved by jointly optimizing the active beamforming, time delays, and modulation frequencies. Subsequently, a novel iterative algorithm is proposed to effectively solve this problem with low computing complexity. Simulation results demonstrate that the proposed multi-subarray FD-RIS can significantly enhance the performance of far-field communication networks by leveraging unique distance-angle beamforming. Furthermore, to achieve same performance gains, the FD-RIS-assisted system can substantially reduce the required number of RIS elements, number of antennas, and power budget, than the conventional RIS-assisted schemes. The proposed algorithm also demonstrates a notably superiority in performance and computational complexity compared with the baseline algorithms such as semi-definite relaxation (SDR) and zero-forcing (ZF).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18628v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Xiao, Xiaoyan Hu, Wenjie Wang, Kai-Kit Wong, Kun Yang, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Neural Coding Is Not Always Semantic: Towards The Standardized Coding Workflow in Semantic Communications</title>
      <link>https://arxiv.org/abs/2505.18637</link>
      <description>arXiv:2505.18637v1 Announce Type: new 
Abstract: Semantic communication, leveraging advanced deep learning techniques, emerges as a new paradigm that meets the requirements of next-generation wireless networks. However, current semantic communication systems, which employ neural coding for feature extraction from raw data, have not adequately addressed the fundamental question: Is general feature extraction through deep neural networks sufficient for understanding semantic meaning within raw data in semantic communication? This article is thus motivated to clarify two critical aspects: semantic understanding and general semantic representation. This article presents a standardized definition on semantic coding, an extensive neural coding scheme for general semantic representation that clearly represents underlying data semantics based on contextual modeling. With these general semantic representations obtained, both human- and machine-centric end-to-end data transmission can be achieved through only minimal specialized modifications, such as fine-tuning and regularization. This article contributes to establishing a commonsense that semantic communication extends far beyond mere feature transmission, focusing instead on conveying compact semantic representations through context-aware coding schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18637v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hai-Long Qin, Jincheng Dai, Sixian Wang, Xiaoqi Qin, Shuo Shao, Kai Niu, Wenjun Xu, Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Joint Max-Min Power Control and Clustering in Cell-Free Wireless Networks: Design and Analysis</title>
      <link>https://arxiv.org/abs/2505.18676</link>
      <description>arXiv:2505.18676v1 Announce Type: new 
Abstract: Cell-free wireless networks have attracted significant interest for their ability to eliminate cell-edge effects and deliver uniformly high service quality through macro-diversity. In this paper, we develop an algorithm to jointly optimize uplink transmit powers and dynamic user-centric access point (AP) clusters in a centralized cell-free network. This approach aims to efficiently mitigate inter-user interference and achieve higher max-min signal-to-interference-plus-noise ratio (SINR) targets for users. To this end, we re-purpose an iterative power control algorithm based on non-linear Perron-Frobenius theory and prove its convergence for the maximum ratio combiner (MRC) receiver under various AP subset selection schemes. We further provide analytical results by framing the joint optimization as a conditional eigenvalue problem with power and AP association constraints, and leveraging Perron-Frobenius theory on a centrally constructed matrix. The numerical results highlight that optimizing each user's serving AP cluster is essential to achieving higher max-min SINR targets with the simple MRC receiver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18676v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Achini Jayawardane, Rajitha Senanayake, Erfan Khordad, Jamie Evans</dc:creator>
    </item>
    <item>
      <title>High Throughput QC-LDPC Decoder With Optimized Schedule Policy in Layered Decoding</title>
      <link>https://arxiv.org/abs/2505.19027</link>
      <description>arXiv:2505.19027v1 Announce Type: new 
Abstract: In this study, a scheduling policy of layered decoding for quasi-cycle (QC) low-density parity-check (LDPC) codes with high throughput and good performance is designed. The influence of scheduling on the delay of the decoder's hardware implementation and on the decoding performance are considered simultaneously. Specifically, we analyze the idle time required under various scheduling sequences within a pipelined decoding architecture and formulate the problem as a traveling salesman problem (TSP) aiming at minimizing idle time. Furthermore, considering that different scheduling sequences can affect decoding performance, we refine the graph used to solve the TSP based on scheduling characteristics that promote improved decoding outcomes. Simulation results demonstrate that the identified scheduling sequence achieves a low number of hardware delays while maintaining excellent decoding performance for 5G New Radio (NR) LDPC codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19027v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongxu Chang, Qingqing Peng, Guanghui Wang, Guiying Yan</dc:creator>
    </item>
    <item>
      <title>RIS-Assisted Survivable Fronthaul Design in Cell-Free Massive MIMO System</title>
      <link>https://arxiv.org/abs/2505.19152</link>
      <description>arXiv:2505.19152v1 Announce Type: new 
Abstract: This paper investigates the application of reconfigurable intelligent surfaces (RISs) to improve fronthaul link survivability in cell-free massive MIMO (CF mMIMO) systems. To enhance the fronthaul survivability, two complementary mechanisms are considered. Firstly, RIS is set to provide reliable line-of-sight (LOS) connectivity and enhance the mmWave backup link. Secondly, a resource-sharing scheme that leverages redundant cable capacity through neighboring master access points (APs) to guarantee availability is considered. We formulate the redundant capacity minimization problem as a RIS-assisted multi-user MIMO rate control optimization problem, developing a novel solution that combines a modified weighted minimum mean square error (WMMSE) algorithm for precoding design with Riemannian gradient descent for RIS phase shift optimization. Our numerical evaluations show that RIS reduces the required redundant capacity by 65.6% compared to the no RIS case to reach a 99% survivability. The results show that the most substantial gains of RIS occur during complete outages of the direct disconnected master AP-CPU channel. These results demonstrate RIS's potential to significantly enhance fronthaul reliability while minimizing infrastructure costs in next-generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19152v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenyu Li, \"Ozlem Tu\u{g}fe Demir, Emil Bj\"ornson, Cicek Cavdar</dc:creator>
    </item>
    <item>
      <title>On the Secrecy of RIS-aided THz Wireless System subject to $\alpha-\mu$ fading with Pointing Errors</title>
      <link>https://arxiv.org/abs/2505.19357</link>
      <description>arXiv:2505.19357v1 Announce Type: new 
Abstract: The study examines the secrecy outage probability (SOP) and intercept probability (IP) of a reflecting intelligent surface (RIS)-enabled THz wireless network experiencing $\alpha-\mu$ fading with pointing errors. Specifically, the base station (BS) sends information to a legitimate user $\ell$ via the RIS while an eavesdropper $e$ tries to overhear the conversation. Furthermore, receive nodes are equipped with a single antenna, and the RIS phase shifts were selected to boost the SNR at node $\ell$. Elementary functions are used to accurately approximate the statistical features of channel gain in BS-$\ell$ and BS-$e$ links, leading to SOP and IP approximate and asymptotic expressions. Monte Carlo simulation validates all analytical findings for different system parameters' values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19357v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faissal El Bouanani, Elmehdi Illi, Marwa Qaraqe, Osamah Badarneh</dc:creator>
    </item>
    <item>
      <title>Capacity-Optimized Pre-Equalizer Design for Visible Light Communication Systems</title>
      <link>https://arxiv.org/abs/2505.19709</link>
      <description>arXiv:2505.19709v1 Announce Type: new 
Abstract: Since commercial LEDs are primarily designed for illumination rather than data transmission, their modulation bandwidth is inherently limited to a few MHz. This becomes a major bottleneck in the implementation of visible light communication (VLC) systems necessiating the design of pre-equalizers. While state-of-the-art equalizer designs primarily focus on the data rate increasing through bandwidth expansion, they often overlook the accompanying degradation in signal-to-noise ratio (SNR). Achieving effective bandwidth extension without introducing excessive SNR penalties remains a significant challenge, since the channel capacity is a non-linear function of both parameters. In this paper, we present a fundamental analysis of how the parameters of the LED and pre-equalization circuits influence the channel capacity in intensity modulation and direct detection (IMDD)-based VLC systems. We derive a closed-form expression for channel capacity model that is an explicitly function of analog pre-equalizer circuit parameters. Building upon the derived capacity expression, we propose a systematic design methodology for analog pre-equalizers that effectively balances bandwidth and SNR, thereby maximizing the overall channel capacity across a wide range of channel attenuations. We present extensive numerical results to validate the effectiveness of the proposed design and demonstrate the improvements over conventional bandwidth-optimized pre-equalizer designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19709v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runxin Zhang, Yulin Shao, Jian Xiong, Lu Lu, Murat Uysal</dc:creator>
    </item>
    <item>
      <title>ICDM: Interference Cancellation Diffusion Models for Wireless Semantic Communications</title>
      <link>https://arxiv.org/abs/2505.19983</link>
      <description>arXiv:2505.19983v1 Announce Type: new 
Abstract: Diffusion models (DMs) have recently achieved significant success in wireless communications systems due to their denoising capabilities. The broadcast nature of wireless signals makes them susceptible not only to Gaussian noise, but also to unaware interference. This raises the question of whether DMs can effectively mitigate interference in wireless semantic communication systems. In this paper, we model the interference cancellation problem as a maximum a posteriori (MAP) problem over the joint posterior probability of the signal and interference, and theoretically prove that the solution provides excellent estimates for the signal and interference. To solve this problem, we develop an interference cancellation diffusion model (ICDM), which decomposes the joint posterior into independent prior probabilities of the signal and interference, along with the channel transition probablity. The log-gradients of these distributions at each time step are learned separately by DMs and accurately estimated through deriving. ICDM further integrates these gradients with advanced numerical iteration method, achieving accurate and rapid interference cancellation. Extensive experiments demonstrate that ICDM significantly reduces the mean square error (MSE) and enhances perceptual quality compared to schemes without ICDM. For example, on the CelebA dataset under the Rayleigh fading channel with a signal-to-noise ratio (SNR) of $20$ dB and signal to interference plus noise ratio (SINR) of 0 dB, ICDM reduces the MSE by 4.54 dB and improves the learned perceptual image patch similarity (LPIPS) by 2.47 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19983v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tong Wu, Zhiyong Chen, Dazhi He, Feng Yang, Meixia Tao, Xiaodong Xu, Wenjun Zhang, Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Study of Symbol Error Probability Constrained Precoding with Zero-Crossing Modulation for Wireless Systems with 1-Bit ADCs</title>
      <link>https://arxiv.org/abs/2505.20073</link>
      <description>arXiv:2505.20073v1 Announce Type: new 
Abstract: The next generation of wireless communications systems will employ new frequency bands such as those in the upper midband, millimeter-wave and sub-terahertz frequency bands. The high energy consumption of analog-to-digital converters resulting from their high resolution constituted a major limitation for future wireless communications systems, which will require low energy consumption and low-complexity devices at the transmitter and at the receiver. In this regard, we present a novel precoding method based on quality of service constraints for a multiuser multiple-input multiple-output downlink system with 1-bit quantization and oversampling. For this scenario, we consider the time-instance zero-crossing modulation, which conveys the information into the zero-crossings of the signals. Unlike prior works the proposed constraint is given in terms of the symbol error probability related to the minimum distance to the decision threshold and is included in the proposed optimization problem that is used in the design of the precoder. Simulation results illustrate the performance of the proposed precoding method evaluated under different parameters and scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20073v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D. Melo, L. Landau, R. de Lamare</dc:creator>
    </item>
    <item>
      <title>Extending Asynchronous Byzantine Agreement with Crusader Agreement</title>
      <link>https://arxiv.org/abs/2502.02320</link>
      <description>arXiv:2502.02320v3 Announce Type: cross 
Abstract: In this work, we study multivalued byzantine agreement (BA) in an asynchronous network of $n$ parties where up to $t &lt; \frac{n}{3}$ parties are byzantine. We present a new reduction from multivalued BA to binary BA. It allows one to achieve BA on $\ell$-bit inputs with one instance of binary BA, one instance of crusader agreement (CA) on $\ell$-bit inputs and $\Theta(\ell n + n^2)$ bits of additional communication.
  As our reduction uses multivalued CA, we also design two new information-theoretic CA protocols for $\ell$-bit inputs. In the first one, we use almost-universal hashing to achieve statistical security with probability $1 - 2^{-\lambda}$ against $t &lt; \frac{n}{3}$ faults with $\Theta(\ell n + n^2(\lambda + \log n))$ bits of communication. Following this, we replace the hashes with error correcting code symbols and add a preliminary step based on the synchronous multivalued BA protocol COOL [DISC '21] to obtain a second, perfectly secure CA protocol that can for any $\varepsilon &gt; 0$ be set to tolerate $t \leq \frac{n}{3 + \varepsilon}$ faults with $\mathcal{O}\bigl(\frac{\ell n}{\min(1, \varepsilon^2)} + n^2\max\bigl(1, \log \frac{1}{\varepsilon}\bigr) \bigr)$ bits of communication. Our CA protocols allow one to extend binary BA to multivalued BA with a constant round overhead, a quadratic-in-$n$ communication overhead, and information-theoretic security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02320v3</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mose Mizrahi Erbes, Roger Wattenhofer</dc:creator>
    </item>
    <item>
      <title>Illuminating the Path: Attention-Assisted Beamforming and Predictive Insights in 5G NR Systems</title>
      <link>https://arxiv.org/abs/2505.18160</link>
      <description>arXiv:2505.18160v1 Announce Type: cross 
Abstract: Artificial intelligence advances have recently influenced wireless communications, including beam management in fifth-generation (5G) new radio systems. AI-driven models and algorithms are being applied to enhance tasks such as beam selection, prediction, and refinement by leveraging real-time and historical data. These approaches address challenges such as mobility under complex channel conditions, showing promising results compared to traditional methods. Beam management in 5G refers to processes that ensure optimal alignment between the base station and user equipment for effective signal transmission and reception based on real-time channel state information and user positioning. This study leverages accurate beam prediction to identify a smaller subset of beams, resulting in a more efficient, streamlined, and link-adaptive communication system. The innovative approach presented introduces a precise, attention-based prediction model that derives the entire downlink transmission chain in a commercial grade 5G system. The predicted downlink beams are specifically tailored to handle the complexities of none line-of-sight environments known for high-dimensional channel dynamics and scatterer-induced signal variations. This novel method introduces a paradigm shift in utilizing environmental and channel dynamics in contrast to conventional procedures of beam management, which entails complex methods involving exhaustive techniques to predict the best beams. The presented beam prediction results demonstrate robustness in addressing the challenges posed by signal-dispersive environments, showcasing great potential in mobility scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18160v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dino Pjani\'c, Guoda Tian, Andres Reial, Xuesong Cai, Bo Bernhardsson, Fredrik Tufvesson</dc:creator>
    </item>
    <item>
      <title>Ray Antenna Array: A Novel Cost-Effective Multi-Antenna Architecture for Enhanced Wireless Communication</title>
      <link>https://arxiv.org/abs/2505.18163</link>
      <description>arXiv:2505.18163v1 Announce Type: cross 
Abstract: This paper proposes a novel multi-antenna architecture, termed ray antenna array (RAA), which aims to enhance wireless communication performance in a cost-effective manner. RAA is composed of massive cheap antenna elements and a few radio frequency (RF) chains. The massive antenna elements are arranged in a novel ray-like structure, with each ray corresponding to a simple uniform linear array (sULA) with a carefully designed orientation. The antenna elements of each sULA are directly connected to an RF combiner, so that the sULA in each ray is able to form a beam towards a direction matching the ray orientation without relying on any analog or digital beamforming. By further designing a ray selection network (RSN), appropriate sULAs are selected to connect to the RF chains for further baseband processing. Compared to conventional multi-antenna architectures like hybrid analog/digital beamforming (HBF), the proposed RAA has two major advantages. First, it can significantly reduce hardware costs since no phase shifters, which are usually expensive especially in high-frequency systems, are required. Besides, RAA can greatly improve system performance by configuring antenna elements with higher directionality, as each sULA only needs to be responsible for a portion of the total coverage angle. To demonstrate such advantages, in this paper, we first present the input-output model for RAA-based wireless communications, based on which the ray orientations of the RAA are designed. Furthermore, efficient algorithms for joint ray selection and beamforming are proposed for single-user and multi-user RAA-based wireless communications. Simulation results demonstrate the superior performance of RAA compared to HBF while significantly reducing hardware cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18163v1</guid>
      <category>eess.SP</category>
      <category>cs.AR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenjun Dong, Zhiwen Zhou, Yong Zeng</dc:creator>
    </item>
    <item>
      <title>Dim and Small Target Detection for Drone Broadcast Frames Based on Time-Frequency Analysis</title>
      <link>https://arxiv.org/abs/2505.18167</link>
      <description>arXiv:2505.18167v1 Announce Type: cross 
Abstract: We propose a dim and small target detection algorithm for drone broadcast frames based on the time-frequency analysis of communication protocol. Specifically, by analyzing modulation parameters and frame structures, the prior knowledge of transmission frequency, signal bandwidth, Zadoff-Chu (ZC) sequences, and frame length of drone broadcast frames is established. The RF signals are processed through the designed filter banks, and the frequency domain parameters of bounding boxes generated by the detector are corrected with transmission frequency and signal bandwidth. Given the remarkable correlation characteristics of ZC sequences, the frequency domain parameters of bounding boxes with low confidence scores are corrected based on ZC sequences and frame length, which improves the detection accuracy of dim targets under low signal-to noise ratio (SNR) situations. Besides, a segmented energy refinement method is applied to mitigate the deviation caused by interference signals with high energy strength, which ulteriorly corrects the time domain detection parameters for dim targets. As the sampling duration increases, the detection speed improves while the detection accuracy of broadcast frames termed as small targets decreases. The trade-off between detection accuracy and speed versus sampling duration is established, which helps to meet different drone regulation requirements. Simulation results demonstrate that the proposed algorithm improves the average intersection over union, precision, and recall by 3\%, 1.4\%, and 2.4\%, respectively, compared to existing algorithms. The proposed algorithm also performs strong robustness under varying flight distances, diverse types of environment noise, and different flight visual environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18167v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Li, Jing Li, Zhanyu Ju, Fengkui Gong, Lu Lv</dc:creator>
    </item>
    <item>
      <title>Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens</title>
      <link>https://arxiv.org/abs/2505.18237</link>
      <description>arXiv:2505.18237v1 Announce Type: cross 
Abstract: The recent rise of Large Reasoning Models (LRMs) has significantly improved multi-step reasoning performance, but often at the cost of generating excessively long reasoning chains. This paper revisits the efficiency of such reasoning processes through an information-theoretic lens, revealing a fundamental trade-off between reasoning length and semantic efficiency. We propose two metrics, InfoBias and InfoGain, to quantify divergence from ideal reasoning paths and stepwise information contribution, respectively. Empirical analyses show that longer reasoning chains tend to exhibit higher information bias and diminishing information gain, especially for incorrect answers. Motivated by these findings, we introduce an entropy-based Adaptive Think strategy that dynamically halts reasoning once confidence is sufficiently high, improving efficiency while maintaining competitive accuracy. Compared to the Vanilla Think approach (default mode), our strategy yields a 1.10% improvement in average accuracy and a 50.80% reduction in token usage on QwQ-32B across six benchmark tasks spanning diverse reasoning types and difficulty levels, demonstrating superior efficiency and reasoning performance. These results underscore the promise of entropy-based methods for enhancing both accuracy and cost-effiiciency in large language model deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18237v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xixian Yong, Xiao Zhou, Yingying Zhang, Jinlin Li, Yefeng Zheng, Xian Wu</dc:creator>
    </item>
    <item>
      <title>The end of radical concept nativism</title>
      <link>https://arxiv.org/abs/2505.18277</link>
      <description>arXiv:2505.18277v1 Announce Type: cross 
Abstract: Though humans seem to be remarkable learners, arguments in cognitive science and philosophy of mind have long maintained that learning something fundamentally new is impossible. Specifically, Jerry Fodor's arguments for radical concept nativism hold that most, if not all, concepts are innate and that what many call concept learning never actually leads to the acquisition of new concepts. These arguments have deeply affected cognitive science, and many believe that the counterarguments to radical concept nativism have been either unsuccessful or only apply to a narrow class of concepts. This paper first reviews the features and limitations of prior arguments. We then identify three critical points - related to issues of expressive power, conceptual structure, and concept possession - at which the arguments in favor of radical concept nativism diverge from describing actual human cognition. We use ideas from computer science and information theory to formalize the relevant ideas in ways that are arguably more scientifically productive. We conclude that, as a result, there is an important sense in which people do indeed learn new concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18277v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua S. Rule, Steven T. Piantadosi</dc:creator>
    </item>
    <item>
      <title>Sampling Strategies for Efficient Training of Deep Learning Object Detection Algorithms</title>
      <link>https://arxiv.org/abs/2505.18302</link>
      <description>arXiv:2505.18302v1 Announce Type: cross 
Abstract: Two sampling strategies are investigated to enhance efficiency in training a deep learning object detection model. These sampling strategies are employed under the assumption of Lipschitz continuity of deep learning models. The first strategy is uniform sampling which seeks to obtain samples evenly yet randomly through the state space of the object dynamics. The second strategy of frame difference sampling is developed to explore the temporal redundancy among successive frames in a video. Experiment result indicates that these proposed sampling strategies provide a dataset that yields good training performance while requiring relatively few manually labelled samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18302v1</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gefei Shen, Yung-Hong Sun, Yu Hen Hu, Hongrui Jiang</dc:creator>
    </item>
    <item>
      <title>A Dual Basis Approach for Structured Robust Euclidean Distance Geometry</title>
      <link>https://arxiv.org/abs/2505.18414</link>
      <description>arXiv:2505.18414v1 Announce Type: cross 
Abstract: Euclidean Distance Matrix (EDM), which consists of pairwise squared Euclidean distances of a given point configuration, finds many applications in modern machine learning. This paper considers the setting where only a set of anchor nodes is used to collect the distances between themselves and the rest. In the presence of potential outliers, it results in a structured partial observation on EDM with partial corruptions. Note that an EDM can be connected to a positive semi-definite Gram matrix via a non-orthogonal dual basis. Inspired by recent development of non-orthogonal dual basis in optimization, we propose a novel algorithmic framework, dubbed Robust Euclidean Distance Geometry via Dual Basis (RoDEoDB), for recovering the Euclidean distance geometry, i.e., the underlying point configuration. The exact recovery guarantees have been established in terms of both the Gram matrix and point configuration, under some mild conditions. Empirical experiments show superior performance of RoDEoDB on sensor localization and molecular conformation datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18414v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandra Kundu, Abiy Tasissa, HanQin Cai</dc:creator>
    </item>
    <item>
      <title>Efficient Online Random Sampling via Randomness Recycling</title>
      <link>https://arxiv.org/abs/2505.18879</link>
      <description>arXiv:2505.18879v1 Announce Type: cross 
Abstract: ``Randomness recycling'' is a powerful algorithmic technique for reusing a fraction of the random information consumed by a randomized algorithm to reduce its entropy requirements. This article presents a family of efficient randomness recycling algorithms for sampling a sequence $X_1, X_2, X_3, \dots$ of discrete random variables whose joint distribution follows an arbitrary stochastic process. We develop randomness recycling strategies to reduce the entropy cost of a variety of prominent sampling algorithms, which include uniform sampling, inverse transform sampling, lookup table sampling, alias sampling, and discrete distribution generating (DDG) tree sampling. Our method achieves an expected amortized entropy cost of $H(X_1,\dots,X_k)/k + \varepsilon$ input random bits per output sample using $O(\log(1/\varepsilon))$ space, which is arbitrarily close to the optimal Shannon entropy rate. The combination of space, time, and entropy properties of our method improve upon the Han and Hoshi interval algorithm and Knuth and Yao entropy-optimal algorithm for sampling a discrete random sequence. An empirical evaluation of the algorithm shows that it achieves state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator. Accompanying the manuscript is a performant random sampling library in the C programming language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18879v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas L. Draper, Feras A. Saad</dc:creator>
    </item>
    <item>
      <title>Agentic Information Theory: Ergodicity and Intrinsic Semantics of Information Processes</title>
      <link>https://arxiv.org/abs/2505.19275</link>
      <description>arXiv:2505.19275v1 Announce Type: cross 
Abstract: We develop information theory for the temporal behavior of memoryful agents moving through complex -- structured, stochastic -- environments. We introduce information processes -- stochastic processes produced by cognitive agents in real-time as they interact with and interpret incoming stimuli. We provide basic results on the ergodicity and semantics of the resulting time series of Shannon information measures that monitor an agent's adapting view of uncertainty and structural correlation in its environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19275v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>math.IT</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James P. Crutchfield, Alexandra Jurgens</dc:creator>
    </item>
    <item>
      <title>Near-Field Secure Beamfocusing With Receiver-Centered Protected Zone</title>
      <link>https://arxiv.org/abs/2505.19523</link>
      <description>arXiv:2505.19523v1 Announce Type: cross 
Abstract: This work studies near-field secure communications through transmit beamfocusing. We examine the benefit of having a protected eavesdropper-free zone around the legitimate receiver, and we determine the worst-case secrecy performance against a potential eavesdropper located anywhere outside the protected zone. A max-min optimization problem is formulated for the beamfocusing design with and without artificial noise transmission. Despite the NP-hardness of the problem, we develop a synchronous gradient descent-ascent framework that approximates the global maximin solution. A low-complexity solution is also derived that delivers excellent performance over a wide range of operating conditions. We further extend this study to a scenario where it is not possible to physically enforce a protected zone. To this end, we consider secure communications through the creation of a virtual protected zone using a full-duplex legitimate receiver. Numerical results demonstrate that exploiting either the physical or virtual receiver-centered protected zone with appropriately designed beamfocusing is an effective strategy for achieving secure near-field communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19523v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cen Liu, Xiangyun Zhou, Nan Yang, Salman Durrani, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>The Entropy Characterization of Quantum MDS Codes</title>
      <link>https://arxiv.org/abs/2505.19826</link>
      <description>arXiv:2505.19826v1 Announce Type: cross 
Abstract: An $[[n,k,d]]$ quantum maximum-distance-separable code maps $k$ source qudits to $n$ coded qudits such that any $n-(d-1)$ coded qudits may recover all source qudits and $n = k + 2 (d-1)$. The entropy of the joint state of the reference system of $k$ qudits and the $n$ coded qudits is fully characterized - the joint state must be pure, i.e., has entropy zero; and any sub-system whose number of qudits is at most half of $k+n$, the total number of qudits in the joint state must be maximally mixed, i.e., has entropy equal to its size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19826v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hua Sun</dc:creator>
    </item>
    <item>
      <title>Noise-Robust One-Bit Diffraction Tomography and Optimal Dose Fractionation</title>
      <link>https://arxiv.org/abs/2310.05571</link>
      <description>arXiv:2310.05571v3 Announce Type: replace 
Abstract: This study presents a noise-robust framework for 1-bit diffraction tomography, a novel imaging approach that relies on intensity-only binary measurements obtained through coded apertures. The proposed reconstruction scheme leverages random matrix theory and iterative algorithms to effectively recover 3D object structures under high-noise conditions.
  A key contribution is the numerical investigation of dose fractionation, revealing optimal performance at a signal-to-noise ratio near 1, {\em independent of the total dose}. This finding addresses the question: How to distribute a given level of total radiation energy among different tomographic views in order to optimize the quality of reconstruction?</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05571v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengwen Chen, Albert Fannjiang</dc:creator>
    </item>
    <item>
      <title>Achieving DNA Labeling Capacity with Minimum Labels through Extremal de Bruijn Subgraphs</title>
      <link>https://arxiv.org/abs/2401.15733</link>
      <description>arXiv:2401.15733v2 Announce Type: replace 
Abstract: DNA labeling is a tool in molecular biology and biotechnology to visualize, detect, and study DNA at the molecular level. In this process, a DNA molecule is labeled by a set of specific patterns, referred to as labels, and is then imaged. The resulting image is modeled as an $(\ell+1)$-ary sequence, where $\ell$ is the number of labels, in which any non-zero symbol indicates the appearance of the corresponding label in the DNA molecule. The labeling capacity refers to the maximum information rate that can be achieved by the labeling process for any given set of labels. The main goal of this paper is to study the minimum number of labels of the same length required to achieve the maximum labeling capacity of 2 for DNA sequences or $\log_2q$ for an arbitrary alphabet of size $q$. The solution to this problem requires the study of path unique subgraphs of the de Bruijn graph with the largest number of edges. We provide upper and lower bounds on this value. We draw new connections to existing literature that let us prove an asymptotic result as the label length tends to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15733v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hofmeister, Anina Gruica, Dganit Hanania, Rawad Bitar, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Towards 6G Evolution: Three Enhancements, Three Innovations, and Three Major Challenges</title>
      <link>https://arxiv.org/abs/2402.10781</link>
      <description>arXiv:2402.10781v2 Announce Type: replace 
Abstract: Over the past few decades, wireless communication has witnessed remarkable growth, experiencing several transformative changes. This article aims to provide a comprehensive overview of wireless communication technologies, from the foundations to the recent wireless advances. Specifically, we take a neutral look at the state-of-the-art technologies for 5G and the ongoing evolutions towards 6G, reviewing the recommendations of the International Mobile Communication vision for 2030 (IMT-2030). We first highlight specific features of IMT 2030, including three IMT-2020 extensions (URLLC+, eMBB+, and mMTC+) and three new innovations (Ubiquitous connectivity and integrating the new capabilities of sensing &amp; AI with communication functionality). Then, we delve into three major challenges in implementing 6G, along with global standardization efforts. Besides, a proof of concept is provided by demonstrating terahertz (THz) signal transmission using Orbital Angular Momentum (OAM) multiplexing, which is one of the potential candidates for 6G and beyond. To inspire further potential research, we conclude by identifying research opportunities and future visions on IMT-2030 recommendations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10781v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohit Singh, Aryan Kaushik, Wonjae Shin, Marco Di Renzo, Vincenzo Sciancalepore, Doohwan Lee, Hirofumi Sasaki, Arman Shojaeifard, Octavia A. Dobre</dc:creator>
    </item>
    <item>
      <title>Revealing the evanescent components in Kronecker-product based codebooks: insights and implications</title>
      <link>https://arxiv.org/abs/2407.06772</link>
      <description>arXiv:2407.06772v2 Announce Type: replace 
Abstract: The orthogonal bases of discrete Fourier transform (DFT) has been recognized as the standard spatial-domain bases for Type I, Type II and enhanced Type II codewords by the 3rd Generation Partnership Project (3GPP). For uniform planar arrays, these spatial-domain bases are derived as the Kronecker product of one-dimensional DFT bases. Theoretically, each spatial basis corresponds to a beam directed towards a specific angle of departure and the set of bases represent the orthogonal beams that cover the front hemisphere of an array. While the Kronecker-product based precoding scheme facilitates the concise indexing of a codeword in the codebooks through precoding matrix indicators (PMIs) in channel state information feedback, it introduces redundant spatial beams characterized by high spatial-frequency components. This paper investigates the presence of codewords representing high spatial-frequency components within the Kronecker-product based codebooks. Through theoretical analysis and simulations, we confirm the redundancy of these codewords in MIMO communications, advocating for their removal from the codebooks to enhance system performance. Several topics relevant to the high spatial components are also involved in the discussion. Practical suggestions regarding future standard design are provided based on our theoretical analysis and simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06772v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Yang, Yijian Chen, Yunqi Sun, Yuan Si, Hongkang Yu, Shujuan Zhang, Zhaohua Lu</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning-Based Resource Allocation for Hybrid Bit and Generative Semantic Communications in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2412.05647</link>
      <description>arXiv:2412.05647v3 Announce Type: replace 
Abstract: In this paper, we introduce a novel framework consisting of hybrid bit-level and generative semantic communications for efficient downlink image transmission within space-air-ground integrated networks (SAGINs). The proposed model comprises multiple low Earth orbit (LEO) satellites, unmanned aerial vehicles (UAVs), and ground users. Considering the limitations in signal coverage and receiver antennas that make the direct communication between satellites and ground users unfeasible in many scenarios, thus UAVs serve as relays and forward images from satellites to the ground users. Our hybrid communication framework effectively combines bit-level transmission with several semantic-level image generation modes, optimizing bandwidth usage to meet stringent satellite link budget constraints and ensure communication reliability and low latency under low signal-to-noise ratio (SNR) conditions. To reduce the transmission delay while ensuring reconstruction quality for the ground user, we propose a novel metric to measure delay and reconstruction quality in the proposed system, and employ a deep reinforcement learning (DRL)-based strategy to optimize resource allocation in the proposed network. Simulation results demonstrate the superiority of the proposed framework in terms of communication resource conservation, reduced latency, and maintaining high image quality, significantly outperforming traditional solutions. Therefore, the proposed framework can ensure that real-time image transmission requirements in SAGINs, even under dynamic network conditions and user demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05647v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Huang, Xuyang Chen, Gaojie Chen, Pei Xiao, Geoffrey Ye Li, Wei Huang</dc:creator>
    </item>
    <item>
      <title>An Analysis of RPA Decoding of Reed-Muller Codes Over the BSC</title>
      <link>https://arxiv.org/abs/2412.08129</link>
      <description>arXiv:2412.08129v2 Announce Type: replace 
Abstract: In this paper, we revisit the Recursive Projection-Aggregation (RPA) decoder, of Ye and Abbe (2020), for Reed-Muller (RM) codes. Our main contribution is an explicit upper bound on the probability of incorrect decoding, using the RPA decoder, over a binary symmetric channel (BSC). Importantly, we focus on the events where a \emph{single} iteration of the RPA decoder, in each recursive call, is sufficient for convergence. Key components of our analysis are explicit estimates of the probability of incorrect decoding of first-order RM codes using a maximum likelihood (ML) decoder, and estimates of the error probabilities during the aggregation phase of the RPA decoder. Our results allow us to show that for RM codes with blocklength $N = 2^m$, the RPA decoder can achieve vanishing error probabilities, in the large blocklength limit, for RM orders that grow roughly logarithmically in $m$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08129v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Arvind Rameshwar, V. Lalitha</dc:creator>
    </item>
    <item>
      <title>Separate Source Channel Coding Is Still What You Need: An LLM-based Rethinking</title>
      <link>https://arxiv.org/abs/2501.04285</link>
      <description>arXiv:2501.04285v4 Announce Type: replace 
Abstract: Along with the proliferating research interest in Semantic Communication (SemCom), Joint Source Channel Coding (JSCC) has dominated the attention due to the widely assumed existence in efficiently delivering information semantics. Nevertheless, this paper challenges the conventional JSCC paradigm, and advocates for adoption of Separate Source Channel Coding (SSCC) to enjoy the underlying more degree of freedom for optimization. We demonstrate that SSCC, after leveraging the strengths of Large Language Model (LLM) for source coding and Error Correction Code Transformer (ECCT) complemented for channel decoding, offers superior performance over JSCC. Our proposed framework also effectively highlights the compatibility challenges between SemCom approaches and digital communication systems, particularly concerning the resource costs associated with the transmission of high precision floating point numbers. Through comprehensive evaluations, we establish that empowered by LLM-based compression and ECCT-enhanced error correction, SSCC remains a viable and effective solution for modern communication systems. In other words, separate source and channel coding is still what we need!</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04285v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.12142/ZTECOM.202501005</arxiv:DOI>
      <arxiv:journal_reference>ZTE Communications, vol. 23, no. 1, pp. 30-44, Mar. 2025</arxiv:journal_reference>
      <dc:creator>Tianqi Ren, Rongpeng Li, Ming-min Zhao, Xianfu Chen, Guangyi Liu, Yang Yang, Zhifeng Zhao, Honggang Zhang</dc:creator>
    </item>
    <item>
      <title>Channel Resolvability Using Multiplicative Weight Update Algorithm</title>
      <link>https://arxiv.org/abs/2501.11881</link>
      <description>arXiv:2501.11881v3 Announce Type: replace 
Abstract: We study the channel resolvability problem, which is used to prove strong converse of identification via channel. Channel resolvability has been solved by only random coding in the literature. We prove channel resolvability using the multiplicative weight update algorithm. This is the first approach to channel resolvability using non-random coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11881v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koki Takahashi, Shun Watanabe</dc:creator>
    </item>
    <item>
      <title>Pcodec: Better Compression for Numerical Sequences</title>
      <link>https://arxiv.org/abs/2502.06112</link>
      <description>arXiv:2502.06112v2 Announce Type: replace 
Abstract: We present Pcodec (Pco), a format and algorithm for losslessly compressing numerical (float or integer) sequences. Pco's core and most novel component is a binning algorithm that quickly converges to the true entropy of smoothly, independently, and identically distributed (SIID) integers. We mathematically prove this convergence with a practical bound. To accommodate data this is not SIID, Pco has two opinionated preprocessing steps. The first step, Pco's mode, decomposes the numbers into more smoothly distributed integer latent variables. The second step, delta encoding, makes the latents more independently and identically distributed. We demonstrate that Pco achieves 29-94% higher compression ratio than other numerical codecs on six real-world columnar datasets while using less compression time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06112v2</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Loncaric, Niels Jeppesen, Ben Zinberg</dc:creator>
    </item>
    <item>
      <title>Masked Modulation: High-Throughput Half-Duplex ISAC Transmission Waveform Design</title>
      <link>https://arxiv.org/abs/2502.08996</link>
      <description>arXiv:2502.08996v2 Announce Type: replace 
Abstract: Integrated sensing and communication (ISAC) enables numerous innovative wireless applications. Communication-centric design is a practical choice for the construction of the sixth generation (6G) ISAC networks. Continuous-wave-based ISAC systems, with orthogonal frequency-division multiplexing (OFDM) being a representative example, suffer from the self-interference (SI) problem, and hence are less suitable for long-range sensing. On the other hand, pulse-based half-duplex ISAC systems are free of SI, but are also less favourable for high-throughput communication scenarios.
  In this treatise, we propose MASked Modulation (MASM), a half-duplex ISAC waveform design scheme, which minimises a range blindness metric, termed as "mainlobe fluctuation", given a duty cycle (proportional to communication throughput) constraint. In particular, MASM is capable of supporting high-throughput communication ($\sim$50% duty cycle) under mild mainlobe fluctuation. Moreover, MASM can be flexibly adapted to frame-level waveform designs by operating on the slow-time scale. In terms of optimal transmit mask design, a set of masks is shown to be ideal in the sense of sidelobe level and mainlobe fluctuation intensity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08996v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifeng Xiong, Junsheng Mu, Shuangyang Li, Marco Lops, Jianhua Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient Pauli channel estimation with logarithmic quantum memory</title>
      <link>https://arxiv.org/abs/2309.14326</link>
      <description>arXiv:2309.14326v4 Announce Type: replace-cross 
Abstract: Here we revisit one of the prototypical tasks for characterizing the structure of noise in quantum devices: estimating every eigenvalue of an $n$-qubit Pauli noise channel to error $\epsilon$. Prior work [14] proved no-go theorems for this task in the practical regime where one has a limited amount of quantum memory, e.g. any protocol with $\le 0.99n$ ancilla qubits of quantum memory must make exponentially many measurements, provided it is non-concatenating. Such protocols can only interact with the channel by repeatedly preparing a state, passing it through the channel, and measuring immediately afterward.
  This left open a natural question: does the lower bound hold even for general protocols, i.e. ones which chain together many queries to the channel, interleaved with arbitrary data-processing channels, before measuring? Surprisingly, in this work we show the opposite: there is a protocol that can estimate the eigenvalues of a Pauli channel to error $\epsilon$ using only $O(\log n/\epsilon^2)$ ancilla and $\tilde{O}(n^2/\epsilon^2)$ measurements. In contrast, we show that any protocol with zero ancilla, even a concatenating one, must make $\Omega(2^n/\epsilon^2)$ measurements, which is tight.
  Our results imply, to our knowledge, the first quantum learning task where logarithmically many qubits of quantum memory suffice for an exponential statistical advantage. Our protocol can be naturally extended to a protocol that learns the eigenvalues of Pauli terms within any subset $A$ of a Pauli channel with $O(\log\log(|A|)/\epsilon^2)$ ancilla and $\tilde{O}(n^2/\epsilon^2)$ measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14326v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sitan Chen, Weiyuan Gong</dc:creator>
    </item>
    <item>
      <title>Distortion Resilience for Goal-Oriented Semantic Communication</title>
      <link>https://arxiv.org/abs/2309.14587</link>
      <description>arXiv:2309.14587v2 Announce Type: replace-cross 
Abstract: Recent research efforts on Semantic Communication (SemCom) have mostly considered accuracy as a main problem for optimizing goal-oriented communication systems. However, these approaches introduce a paradox: the accuracy of Artificial Intelligence (AI) tasks should naturally emerge through training rather than being dictated by network constraints. Acknowledging this dilemma, this work introduces an innovative approach that leverages the rate distortion theory to analyze distortions induced by communication and compression, thereby analyzing the learning process. Specifically, we examine the distribution shift between the original data and the distorted data, thus assessing its impact on the AI model's performance. Founding upon this analysis, we can preemptively estimate the empirical accuracy of AI tasks, making the goal-oriented SemCom problem feasible. To achieve this objective, we present the theoretical foundation of our approach, accompanied by simulations and experiments that demonstrate its effectiveness. The experimental results indicate that our proposed method enables accurate AI task performance while adhering to network constraints, establishing it as a valuable contribution to the field of signal processing. Furthermore, this work advances research in goal-oriented SemCom and highlights the significance of data-driven approaches in optimizing the performance of intelligent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14587v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh-Duong Nguyen, Quang-Vinh Do, Zhaohui Yang, Quoc-Viet Pham, Won-Joo Hwang</dc:creator>
    </item>
    <item>
      <title>The Sample Complexity of Simple Binary Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2403.16981</link>
      <description>arXiv:2403.16981v2 Announce Type: replace-cross 
Abstract: The sample complexity of simple binary hypothesis testing is the smallest number of i.i.d.\ samples required to distinguish between two distributions $p$ and $q$ in either: (i) the prior-free setting, with type-I error at most $\alpha$ and type-II error at most $\beta$; or (ii) the Bayesian setting, with Bayes error at most $\delta$ and prior distribution $(\pi, 1-\pi)$. This problem has only been studied when $\alpha = \beta$ (prior-free) or $\pi = 1/2$ (Bayesian), and the sample complexity is known to be characterized by the Hellinger divergence between $p$ and $q$, up to multiplicative constants. In this paper, we derive a formula that characterizes the sample complexity (up to multiplicative constants that are independent of $p$, $q$, and all error parameters) for: (i) all $0 \le \alpha, \beta \le 1/8$ in the prior-free setting; and (ii) all $\delta \le \pi/4$ in the Bayesian setting. In particular, the formula admits equivalent expressions in terms of certain divergences from the Jensen--Shannon and Hellinger families. The main technical result concerns an $f$-divergence inequality between members of the Jensen--Shannon and Hellinger families, which is proved by a combination of information-theoretic tools and case-by-case analyses. We explore applications of our results to (i) robust hypothesis testing, (ii) distributed (locally-private and communication-constrained) hypothesis testing, (iii) sequential hypothesis testing, and (iv) hypothesis testing with erasures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16981v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankit Pensia, Varun Jog, Po-Ling Loh</dc:creator>
    </item>
  </channel>
</rss>
