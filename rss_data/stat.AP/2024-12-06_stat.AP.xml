<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Dec 2024 05:01:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bayesian Perspective for Orientation Estimation in Cryo-EM and Cryo-ET</title>
      <link>https://arxiv.org/abs/2412.03723</link>
      <description>arXiv:2412.03723v1 Announce Type: new 
Abstract: Accurate orientation estimation is a crucial component of 3D molecular structure reconstruction, both in single-particle cryo-electron microscopy (cryo-EM) and in the increasingly popular field of cryo-electron tomography (cryo-ET). The dominant method, which involves searching for an orientation with maximum cross-correlation relative to given templates, falls short, particularly in low signal-to-noise environments. In this work, we propose a Bayesian framework to develop a more accurate and flexible orientation estimation approach, with the minimum mean square error (MMSE) estimator as a key example. This method effectively accommodates varying structural conformations and arbitrary rotational distributions. Through simulations, we demonstrate that our estimator consistently outperforms the cross-correlation-based method, especially in challenging conditions with low signal-to-noise ratios, and offer a theoretical framework to support these improvements. We further show that integrating our estimator into the iterative refinement in the 3D reconstruction pipeline markedly enhances overall accuracy, revealing substantial benefits across the algorithmic workflow. Finally, we show empirically that the proposed Bayesian approach enhances robustness against the ``Einstein from Noise'' phenomenon, reducing model bias and improving reconstruction reliability. These findings indicate that the proposed Bayesian framework could substantially advance cryo-EM and cryo-ET by enhancing the accuracy, robustness, and reliability of 3D molecular structure reconstruction, thereby facilitating deeper insights into complex biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03723v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheng Xu, Amnon Balanov, Tamir Bendory</dc:creator>
    </item>
    <item>
      <title>Exploring Non-Linear Effects of Built Environment on Travel Using an Integrated Machine Learning and Inferential Modeling Approach: A Three-Wave Repeated Cross-Sectional Study</title>
      <link>https://arxiv.org/abs/2412.03582</link>
      <description>arXiv:2412.03582v1 Announce Type: cross 
Abstract: This study investigates the dynamic relationship between the built environment and travel in Austin, Texas, over a 20-year period. Using three waves of household travel surveys from 1997, 2006, and 2017, the research employs a repeated cross-sectional approach to address the limitations of traditional longitudinal and cross-sectional studies. Methodologically, it integrates machine learning and inferential modeling to uncover non-linear relationships and threshold effects of built environment characteristics on travel. Findings reveal that the built environment serves as a sustainable tool for managing travel in the long term, contributing 50% or more to the total feature importance in predicting individual travel-surpassing the combined effects of personal and household characteristics. Increased transit accessibility, local and regional destination accessibility, population and employment density, and diversity significantly reduce travel, particularly within their identified thresholds, though the magnitude of their influence varies across time periods. These findings highlight the potential of smart growth policies-such as expanding transit accessibility, promoting high-density and mixed-use development, and discouraging single-use development and peripheral sprawl-as effective strategies to reduce car dependency and manage travel demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03582v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niaz Mahmud Zafri, Ming Zhang</dc:creator>
    </item>
    <item>
      <title>Using a Two-Parameter Sensitivity Analysis Framework to Efficiently Combine Randomized and Non-randomized Studies</title>
      <link>https://arxiv.org/abs/2412.03731</link>
      <description>arXiv:2412.03731v1 Announce Type: cross 
Abstract: Causal inference is vital for informed decision-making across fields such as biomedical research and social sciences. Randomized controlled trials (RCTs) are considered the gold standard for the internal validity of inferences, whereas observational studies (OSs) often provide the opportunity for greater external validity. However, both data sources have inherent limitations preventing their use for broadly valid statistical inferences: RCTs may lack generalizability due to their selective eligibility criterion, and OSs are vulnerable to unobserved confounding. This paper proposes an innovative approach to integrate RCT and OS that borrows the other study's strengths to remedy each study's limitations. The method uses a novel triplet matching algorithm to align RCT and OS samples and a new two-parameter sensitivity analysis framework to quantify internal and external biases. This combined approach yields causal estimates that are more robust to hidden biases than OSs alone and provides reliable inferences about the treatment effect in the general population. We apply this method to investigate the effects of lactation on maternal health using a small RCT and a long-term observational health records dataset from the California National Primate Research Center. This application demonstrates the practical utility of our approach in generating scientifically sound and actionable causal estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03731v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoqi Yu, Bikram Karmakar, Jessica Vandeleest, Eleanor Bimla Schwarz</dc:creator>
    </item>
    <item>
      <title>Beyond Asymptotics: Practical Insights into Community Detection in Complex Networks</title>
      <link>https://arxiv.org/abs/2412.03805</link>
      <description>arXiv:2412.03805v1 Announce Type: cross 
Abstract: The stochastic block model (SBM) is a fundamental tool for community detection in networks, yet the finite-sample performance of inference methods remains underexplored. We evaluate key algorithms-spectral methods, variational inference, and Gibbs sampling-under varying conditions, including signal-to-noise ratios, heterogeneous community sizes, and multimodality. Our results highlight significant performance variations: spectral methods, especially SCORE, excel in computational efficiency and scalability, while Gibbs sampling dominates in small, well-separated networks. Variational Expectation-Maximization strikes a balance between accuracy and cost in larger networks but struggles with optimization in highly imbalanced settings. These findings underscore the practical trade-offs among methods and provide actionable guidance for algorithm selection in real-world applications. Our results also call for further theoretical investigation in SBMs with complex structures. The code can be found at https://github.com/Toby-X/SBM_computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03805v1</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianjun Ke, Zhiyu Xu</dc:creator>
    </item>
    <item>
      <title>Information Geometry for Maximum Diversity Distributions</title>
      <link>https://arxiv.org/abs/2412.03835</link>
      <description>arXiv:2412.03835v1 Announce Type: cross 
Abstract: In recent years, biodiversity measures have gained prominence as essential tools for ecological and environmental assessments, particularly in the context of increasingly complex and large-scale datasets. We provide a comprehensive review of diversity measures, including the Gini-Simpson index, Hill numbers, and Rao's quadratic entropy, examining their roles in capturing various aspects of biodiversity. Among these, Rao's quadratic entropy stands out for its ability to incorporate not only species abundance but also functional and genetic dissimilarities. The paper emphasizes the statistical and ecological significance of Rao's quadratic entropy under the information geometry framework. We explore the distribution maximizing such a diversity measure under linear constraints that reflect ecological realities, such as resource competition or habitat suitability. Furthermore, we discuss a unified approach of the Leinster-Cobbold index combining Hill numbers and Rao's entropy, allowing for an adaptable and similarity-sensitive measure of biodiversity.
  Finally, we discuss the information geometry associated with the maximum diversity distribution focusing on the cross diversity measures such as the cross-entropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03835v1</guid>
      <category>q-bio.PE</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shinto Eguchi</dc:creator>
    </item>
    <item>
      <title>Spatial Weather, Socio-Economic and Political Risks in Probabilistic Load Forecasting</title>
      <link>https://arxiv.org/abs/2408.00507</link>
      <description>arXiv:2408.00507v2 Announce Type: replace 
Abstract: Accurate forecasts of the impact of spatial weather and pan-European socio-economic and political risks on hourly electricity demand for the mid-term horizon are crucial for strategic decision-making amidst the inherent uncertainty. Most importantly, these forecasts are essential for the operational management of power plants, ensuring supply security and grid stability, and in guiding energy trading and investment decisions. The primary challenge for this forecasting task lies in disentangling the multifaceted drivers of load, which include national deterministic (daily, weekly, annual, and holiday patterns) and national stochastic weather and autoregressive effects. Additionally, transnational stochastic socio-economic and political effects add further complexity, in particular, due to their non-stationarity. To address this challenge, we present an interpretable probabilistic mid-term forecasting model for the hourly load that captures, besides all deterministic effects, the various uncertainties in load. This model recognizes transnational dependencies across 24 European countries, with multivariate modeled socio-economic and political states and cross-country dependent forecasting. Built from interpretable Generalized Additive Models (GAMs), the model enables an analysis of the transmission of each incorporated effect to the hour-specific load. Our findings highlight the vulnerability of countries reliant on electric heating under extreme weather scenarios. This emphasizes the need for high-resolution forecasting of weather effects on pan-European electricity consumption especially in anticipation of widespread electric heating adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00507v2</guid>
      <category>stat.AP</category>
      <category>cs.CE</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.RM</category>
      <category>stat.CO</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monika Zimmermann, Florian Ziel</dc:creator>
    </item>
    <item>
      <title>Algorithmic Forecasting of Extreme Heat Waves</title>
      <link>https://arxiv.org/abs/2409.18305</link>
      <description>arXiv:2409.18305v4 Announce Type: replace 
Abstract: This paper provides some foundations for valid forecasting of rare and extreme heat waves through a better understanding of the similarities and differences between several consecutive hot days under normal circumstances and rare, extreme heat waves. We analyze AIRS data from the American Pacific Northwest and AIRS data from the Phoenix, Arizona region. A genetic algorithm is used to help determine the most promising predictors. Classification accuracy with supervised learning is excellent for the Pacific Northwest and is replicated for Phoenix. Conformal prediction sets are considered as a way to represent forecasting uncertainty. Complications caused by endogenous sampling are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18305v4</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Richard A. Berk, Amy Braverman, Arun Kumar Kuchibhotla</dc:creator>
    </item>
    <item>
      <title>Modeling climate extremes using the four-parameter kappa distribution for $r$-largest order statistics</title>
      <link>https://arxiv.org/abs/2007.12031</link>
      <description>arXiv:2007.12031v3 Announce Type: replace-cross 
Abstract: Accurate estimation of the T-year return levels of climate extremes using statistical distribution is a critical step in the projection of future climate and in engineering design for disaster response. We show how the estimation of such quantities can be improved by fitting {the four-parameter kappa distribution for $r$-largest order statistics} (rK4D), which was developed in this study. The rK4D is an extension of {the generalized extreme value distribution for $r$-largest order statistics} (rGEVD), similar to the four-parameter kappa distribution (K4D), which is an extension of the generalized extreme value distribution (GEVD). This new distribution (rK4D) can be useful not only for fitting data when three parameters in the GEVD are not sufficient to capture the variability of the extreme observations, but also in reducing the estimation uncertainty by making use of the r-largest extreme observations instead of only the block maxima. We derive a joint probability density function (PDF) of rK4D and the marginal and conditional cumulative distribution functions and PDFs. To estimate the parameters, the maximum likelihood estimation and the maximum penalized likelihood estimation methods were considered. The usefulness and practical effectiveness of the rK4D are illustrated by the Monte Carlo simulation and by an application to the Bangkok extreme rainfall data. A few new distributions for $r$-largest order statistics are also derived as special cases of the rK4D, such as the $r$-largest logistic, the $r$-largest generalized logistic, and the $r$-largest generalized Gumbel distributions. These distributions for $r$-largest order statistics would be useful in modeling extreme values for many research areas, including hydrology and climatology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.12031v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.wace.2022.100533</arxiv:DOI>
      <arxiv:journal_reference>Weather and Climate Extremes, 39, 100533 (2023)</arxiv:journal_reference>
      <dc:creator>Yire Shin, Jeong-Soo Park</dc:creator>
    </item>
    <item>
      <title>Bayesian Networks for Causal Analysis in Socioecological Systems</title>
      <link>https://arxiv.org/abs/2401.10101</link>
      <description>arXiv:2401.10101v2 Announce Type: replace-cross 
Abstract: Causal and counterfactual reasoning are emerging directions in data science that allow us to reason about hypothetical scenarios. This is particularly useful in fields like environmental and ecological sciences, where interventional data are usually not available. Structural causal models are probabilistic models for causal analysis that simplify this kind of reasoning due to their graphical representation. They can be regarded as extensions of the so-called Bayesian networks, a well known modeling tool commonly used in environmental and ecological problems. The main contribution of this paper is to analyze the relations of necessity and sufficiency between the variables of a socioecological system using counterfactual reasoning with Bayesian networks. In particular, we consider a case study involving socioeconomic factors and land-uses in southern Spain. In addition, this paper aims to be a coherent overview of the fundamental concepts for applying counterfactual reasoning, so that environmental researchers with a background in Bayesian networks can easily take advantage of the structural causal model formalism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10101v2</guid>
      <category>cs.AI</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafael Caba\~nas, Ana D. Maldonado, Mar\'ia Morales, Pedro A. Aguilera, Antonio Salmer\'on</dc:creator>
    </item>
    <item>
      <title>Introducing the Large Medical Model: State of the art healthcare cost and risk prediction with transformers trained on patient event sequences</title>
      <link>https://arxiv.org/abs/2409.13000</link>
      <description>arXiv:2409.13000v2 Announce Type: replace-cross 
Abstract: With U.S. healthcare spending approaching $5T (NHE Fact Sheet 2024), and 25% of it estimated to be wasteful (Waste in the US the health care system: estimated costs and potential for savings, n.d.), the need to better predict risk and optimal patient care is evermore important. This paper introduces the Large Medical Model (LMM), a generative pre-trained transformer (GPT) designed to guide and predict the broad facets of patient care and healthcare administration. The model is trained on medical event sequences from over 140M longitudinal patient claims records with a specialized vocabulary built from medical terminology systems and demonstrates a superior capability to forecast healthcare costs and identify potential risk factors. Through experimentation and validation, we showcase the LMM's proficiency in not only in cost and risk predictions, but also in discerning intricate patterns within complex medical conditions and an ability to identify novel relationships in patient care. The LMM is able to improve both cost prediction by 14.1% over the best commercial models and chronic conditions prediction by 1.9% over the best transformer models in research predicting a broad set of conditions. The LMM is a substantial advancement in healthcare analytics, offering the potential to significantly enhance risk assessment, cost management, and personalized medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13000v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricky Sahu, Eric Marriott, Ethan Siegel, David Wagner, Flore Uzan, Troy Yang, Asim Javed</dc:creator>
    </item>
    <item>
      <title>Visual Error Patterns in Multi-Modal AI: A Statistical Approach</title>
      <link>https://arxiv.org/abs/2412.00083</link>
      <description>arXiv:2412.00083v2 Announce Type: replace-cross 
Abstract: Multi-modal large language models (MLLMs), such as GPT-4o, excel at integrating text and visual data but face systematic challenges when interpreting ambiguous or incomplete visual stimuli [9]. This study leverages statistical modeling to analyze the factors driving these errors, using a dataset of geometric stimuli characterized by features like 3D, rotation, and missing face/side. We applied parametric methods, non-parametric methods, and ensemble techniques to predict classification errors, with the non-linear gradient boosting model achieving the highest performance (AUC=0.85) during cross-validation. Feature importance analysis highlighted difficulties in depth perception and reconstructing incomplete structures as key contributors to misclassification. These findings demonstrate the effectiveness of statistical approaches for uncovering limitations in MLLMs and offer actionable insights for enhancing model architectures by integrating contextual reasoning mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00083v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ching-Yi Wang</dc:creator>
    </item>
    <item>
      <title>Characterizing the Effects of Environmental Exposures on Social Mobility: Bayesian Semi-parametrics for Principal Stratification</title>
      <link>https://arxiv.org/abs/2412.00311</link>
      <description>arXiv:2412.00311v2 Announce Type: replace-cross 
Abstract: Principal stratification provides a robust causal inference framework for the adjustment of post-treatment variables when comparing the effects of a treatment in health and social sciences. In this paper, we introduce a novel Bayesian nonparametric model for principal stratification, leveraging the dependent Dirichlet process to flexibly model the distribution of potential outcomes. By incorporating confounders and potential outcomes for the post-treatment variable in the Bayesian mixture model for the final outcome, our approach improves the accuracy of missing data imputation and allows for the characterization of treatment effects across strata defined based on the values of the post-treatment variable. We assess the performance of our method through a Monte Carlo simulation study where we compare the proposed method with state-of-the-art Bayesian method in principal stratification. Finally, we leverage the proposed method to evaluate the principal causal effects of exposure to air pollution on social mobility in the US on strata defined by educational attainment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00311v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dafne Zorzetto, Paolo Dalla Torre, Sonia Petrone, Francesca Dominici, Falco J. Bargagli-Stoffi</dc:creator>
    </item>
  </channel>
</rss>
