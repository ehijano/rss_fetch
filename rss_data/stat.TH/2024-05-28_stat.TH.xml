<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 May 2024 04:08:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Estimating the normal-inverse-Wishart distribution</title>
      <link>https://arxiv.org/abs/2405.16088</link>
      <description>arXiv:2405.16088v1 Announce Type: new 
Abstract: The normal-inverse-Wishart (NIW) distribution is commonly used as a prior distribution for the mean and covariance parameters of a multivariate normal distribution. The family of NIW distributions is also a minimal exponential family. In this short note we describe a convergent procedure for converting from mean parameters to natural parameters in the NIW family, or -- equivalently -- for performing maximum likelihood estimation of the natural parameters given observed sufficient statistics. This is needed, for example, when using a NIW base family in expectation propagation</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16088v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan So</dc:creator>
    </item>
    <item>
      <title>Confirming the Null: Remarks on Equivalence Testing and the Topology of Confirmation</title>
      <link>https://arxiv.org/abs/2405.16331</link>
      <description>arXiv:2405.16331v1 Announce Type: new 
Abstract: Null Hypothesis Statistical Testing is a dominant framework for conducting statistical analysis across the sciences. There remains considerable debate as to whether, and under what circumstances, evidence can be said to be confirmatory of a null hypothesis. This paper presents a modal logic of short-run frequentist confirmation developed by leveraging the duality between hypothesis testing and statistical estimation.
  It is shown that a hypothesis is confirmable if and only if it satisfies the topological condition of having nonempty interior. Consequently, two-sided hypotheses are not statistically confirmable owing to defects in their topological structure. Equivalence hypotheses are, by contrast, confirmable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16331v1</guid>
      <category>math.ST</category>
      <category>math.LO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reid Dale</dc:creator>
    </item>
    <item>
      <title>On Correlation Coefficients</title>
      <link>https://arxiv.org/abs/2405.16469</link>
      <description>arXiv:2405.16469v1 Announce Type: new 
Abstract: In the present paper, we discuss the Pearson, Spearman, Kendall correlation coefficients and their statistical analogues. We propose a new correlation coefficient r and its statistical analogue. The coefficient r is based on Kendal's and Spearman's correlation coefficients. A new extension of the Pearson correlation coefficient is also discussed. We conduct simulation experiments and study the behavior of the above correlation coefficients. We observe that the behavior of Pearson's sample correlation coefficient can be very different from the behavior of the rank correlation coefficients, which, in turn, behave in a similar way. The question arises: which correlation coefficient better measures the dependence rate? We try to answer this question in the final conclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16469v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Alexei Stepanov</dc:creator>
    </item>
    <item>
      <title>Adaptive estimation of $\mathbb{L}_2$-norm of a probability density and related topics I. Lower bounds</title>
      <link>https://arxiv.org/abs/2405.16515</link>
      <description>arXiv:2405.16515v1 Announce Type: new 
Abstract: We deal with the problem of the adaptive estimation of the $\mathbb{L}_2$-norm of a probability density on $\mathbb{R}^d$, $d\geq 1$, from independent observations. The unknown density is assumed to be uniformly bounded and to belong to the union of balls in the isotropic/anisotropic Nikolskii's spaces. We will show that the optimally adaptive estimators over the collection of considered functional classes do no exist. Also, in the framework of an abstract density model we present several generic lower bounds related to the adaptive estimation of an arbitrary functional of a probability density. These results having independent interest have no analogue in the existing literature. In the companion paper Cleanthous et al (2024) we prove that established lower bounds are tight and provide with explicit construction of adaptive estimators of $\mathbb{L}_2$-norm of the density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16515v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Galatia Cleanthous, Athanasios G. Georgiadis, Oleg V. Lepski</dc:creator>
    </item>
    <item>
      <title>Adaptive estimation of the $\mathbb{L}_2$-norm of a probability density and related topics II. Upper bounds via the oracle approach</title>
      <link>https://arxiv.org/abs/2405.16527</link>
      <description>arXiv:2405.16527v1 Announce Type: new 
Abstract: This is the second part of the research project initiated in Cleanthous et al (2024). We deal with the problem of the adaptive estimation of the $\mathbb{L}_2$-norm of a probability density on $\mathbb{R}^d$, $d\geq 1$, from independent observations. The unknown density is assumed to be uniformly bounded by unknown constant and to belong to the union of balls in the isotropic/anisotropic Nikolskii's spaces. In Cleanthous et al (2024) we have proved that the optimally adaptive estimators do no exist in the considered problem and provided with several lower bounds for the adaptive risk. In this part we show that these bounds are tight and present the adaptive estimator which is obtained by a data-driven selection from a family of kernel-based estimators. The proposed estimation procedure as well as the computation of its risk are heavily based on new concentration inequalities for decoupled $U$-statistics of order two established in Section 4. It is also worth noting that all our results are derived from the unique oracle inequality which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16527v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Galatia Cleanthous, Athanasios G. Georgiadis, Oleg V. Lepski</dc:creator>
    </item>
    <item>
      <title>How many samples are needed to train a deep neural network?</title>
      <link>https://arxiv.org/abs/2405.16696</link>
      <description>arXiv:2405.16696v1 Announce Type: new 
Abstract: Neural networks have become standard tools in many areas, yet many important statistical questions remain open. This paper studies the question of how much data are needed to train a ReLU feed-forward neural network. Our theoretical and empirical results suggest that the generalization error of ReLU feed-forward neural networks scales at the rate $1/\sqrt{n}$ in the sample size $n$ rather than the usual "parametric rate" $1/n$. Thus, broadly speaking, our results underpin the common belief that neural networks need "many" training samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16696v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pegah Golestaneh, Mahsa Taheri, Johannes Lederer</dc:creator>
    </item>
    <item>
      <title>A Separation in Heavy-Tailed Sampling: Gaussian vs. Stable Oracles for Proximal Samplers</title>
      <link>https://arxiv.org/abs/2405.16736</link>
      <description>arXiv:2405.16736v1 Announce Type: new 
Abstract: We study the complexity of heavy-tailed sampling and present a separation result in terms of obtaining high-accuracy versus low-accuracy guarantees i.e., samplers that require only $O(\log(1/\varepsilon))$ versus $\Omega(\text{poly}(1/\varepsilon))$ iterations to output a sample which is $\varepsilon$-close to the target in $\chi^2$-divergence. Our results are presented for proximal samplers that are based on Gaussian versus stable oracles. We show that proximal samplers based on the Gaussian oracle have a fundamental barrier in that they necessarily achieve only low-accuracy guarantees when sampling from a class of heavy-tailed targets. In contrast, proximal samplers based on the stable oracle exhibit high-accuracy guarantees, thereby overcoming the aforementioned limitation. We also prove lower bounds for samplers under the stable oracle and show that our upper bounds cannot be fundamentally improved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16736v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye He, Alireza Mousavi-Hosseini, Krishnakumar Balasubramanian, Murat A. Erdogdu</dc:creator>
    </item>
    <item>
      <title>Extremal correlation coefficient for functional data</title>
      <link>https://arxiv.org/abs/2405.17318</link>
      <description>arXiv:2405.17318v1 Announce Type: new 
Abstract: We propose a coefficient that measures dependence in paired samples of functions. It has properties similar to the Pearson correlation, but differs in significant ways: 1) it is designed to measure dependence between curves, 2) it focuses only on extreme curves. The new coefficient is derived within the framework of regular variation in Banach spaces. A consistent estimator is proposed and justified by an asymptotic analysis and a simulation study. The usefulness of the new coefficient is illustrated on financial and and climate functional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17318v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mihyun Kim, Piotr Kokoszka</dc:creator>
    </item>
    <item>
      <title>Theoretical guarantees for lifted samplers</title>
      <link>https://arxiv.org/abs/2405.15952</link>
      <description>arXiv:2405.15952v1 Announce Type: cross 
Abstract: Lifted samplers form a class of Markov chain Monte Carlo methods which has drawn a lot attention in recent years due to superior performance in challenging Bayesian applications. A canonical example of such sampler is the one that is derived from a random walk Metropolis algorithm for a totally-ordered state space such as the integers or the real numbers. The lifted sampler is derived by splitting into two the proposal distribution: one part in the increasing direction, and the other part in the decreasing direction. It keeps following a direction, until a rejection, upon which it flips the direction. In terms of asymptotic variances, it outperforms the random walk Metropolis algorithm, regardless of the target distribution, at no additional computational cost. Other studies show, however, that beyond this simple case, lifted samplers do not always outperform their Metropolis counterparts. In this paper, we leverage the celebrated work of Tierney (1998) to provide an analysis in a general framework encompassing a broad class of lifted samplers. Our finding is that, essentially, the asymptotic variances cannot increase by a factor of more than 2, regardless of the target distribution, the way the directions are induced, and the type of algorithm from which the lifted sampler is derived (be it a Metropolis--Hastings algorithm, a reversible jump algorithm, etc.). This result indicates that, while there is potentially a lot to gain from lifting a sampler, there is not much to lose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15952v1</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philippe Gagnon, Florian Maire</dc:creator>
    </item>
    <item>
      <title>Multifractal Analysis of the Sinkhorn Algorithm: Unveiling the Intricate Structure of Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2405.16006</link>
      <description>arXiv:2405.16006v1 Announce Type: cross 
Abstract: The Sinkhorn algorithm has emerged as a powerful tool for solving optimal transport problems, finding applications in various domains such as machine learning, image processing, and computational biology. Despite its widespread use, the intricate structure and scaling properties of the coupling matrices generated by the Sinkhorn algorithm remain largely unexplored. In this paper, we delve into the multifractal properties of these coupling matrices, aiming to unravel their complex behavior and shed light on the underlying dynamics of the Sinkhorn algorithm. We prove the existence of the multifractal spectrum and the singularity spectrum for the Sinkhorn coupling matrices. Furthermore, we derive bounds on the generalized dimensions, providing a comprehensive characterization of their scaling properties. Our findings not only deepen our understanding of the Sinkhorn algorithm but also pave the way for novel applications and algorithmic improvements in the realm of optimal transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16006v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Rafael Espinosa Mena</dc:creator>
    </item>
    <item>
      <title>Comparing experiments in discounted problems</title>
      <link>https://arxiv.org/abs/2405.16458</link>
      <description>arXiv:2405.16458v1 Announce Type: cross 
Abstract: This paper compares statistical experiments in discounted problems, ranging from the simplest ones where the state is fixed and the flow of information exogenous to more complex ones, where the decision-maker controls the flow of information or the state changes over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16458v1</guid>
      <category>econ.TH</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovic Renou, Xavier Venel</dc:creator>
    </item>
    <item>
      <title>Gaussian Approximation and Multiplier Bootstrap for Polyak-Ruppert Averaged Linear Stochastic Approximation with Applications to TD Learning</title>
      <link>https://arxiv.org/abs/2405.16644</link>
      <description>arXiv:2405.16644v1 Announce Type: cross 
Abstract: In this paper, we obtain the Berry-Esseen bound for multivariate normal approximation for the Polyak-Ruppert averaged iterates of the linear stochastic approximation (LSA) algorithm with decreasing step size. Our findings reveal that the fastest rate of normal approximation is achieved when setting the most aggressive step size $\alpha_{k} \asymp k^{-1/2}$. Moreover, we prove the non-asymptotic validity of the confidence intervals for parameter estimation with LSA based on multiplier bootstrap. This procedure updates the LSA estimate together with a set of randomly perturbed LSA estimates upon the arrival of subsequent observations. We illustrate our findings in the setting of temporal difference learning with linear function approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16644v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Samsonov, Eric Moulines, Qi-Man Shao, Zhuo-Song Zhang, Alexey Naumov</dc:creator>
    </item>
    <item>
      <title>The Collusion of Memory and Nonlinearity in Stochastic Approximation With Constant Stepsize</title>
      <link>https://arxiv.org/abs/2405.16732</link>
      <description>arXiv:2405.16732v1 Announce Type: cross 
Abstract: In this work, we investigate stochastic approximation (SA) with Markovian data and nonlinear updates under constant stepsize $\alpha&gt;0$. Existing work has primarily focused on either i.i.d. data or linear update rules. We take a new perspective and carefully examine the simultaneous presence of Markovian dependency of data and nonlinear update rules, delineating how the interplay between these two structures leads to complications that are not captured by prior techniques. By leveraging the smoothness and recurrence properties of the SA updates, we develop a fine-grained analysis of the correlation between the SA iterates $\theta_k$ and Markovian data $x_k$. This enables us to overcome the obstacles in existing analysis and establish for the first time the weak convergence of the joint process $(x_k, \theta_k)_{k\geq0}$. Furthermore, we present a precise characterization of the asymptotic bias of the SA iterates, given by $\mathbb{E}[\theta_\infty]-\theta^\ast=\alpha(b_\text{m}+b_\text{n}+b_\text{c})+O(\alpha^{3/2})$. Here, $b_\text{m}$ is associated with the Markovian noise, $b_\text{n}$ is tied to the nonlinearity, and notably, $b_\text{c}$ represents a multiplicative interaction between the Markovian noise and nonlinearity, which is absent in previous works. As a by-product of our analysis, we derive finite-time bounds on higher moment $\mathbb{E}[\|\theta_k-\theta^\ast\|^{2p}]$ and present non-asymptotic geometric convergence rates for the iterates, along with a Central Limit Theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16732v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyan Huo, Yixuan Zhang, Yudong Chen, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Kernel-based optimally weighted conformal prediction intervals</title>
      <link>https://arxiv.org/abs/2405.16828</link>
      <description>arXiv:2405.16828v1 Announce Type: cross 
Abstract: Conformal prediction has been a popular distribution-free framework for uncertainty quantification. In this paper, we present a novel conformal prediction method for time-series, which we call Kernel-based Optimally Weighted Conformal Prediction Intervals (KOWCPI). Specifically, KOWCPI adapts the classic Reweighted Nadaraya-Watson (RNW) estimator for quantile regression on dependent data and learns optimal data-adaptive weights. Theoretically, we tackle the challenge of establishing a conditional coverage guarantee for non-exchangeable data under strong mixing conditions on the non-conformity scores. We demonstrate the superior performance of KOWCPI on real time-series against state-of-the-art methods, where KOWCPI achieves narrower confidence intervals without losing coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16828v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonghyeok Lee, Chen Xu, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Robust Reproducible Network Exploration</title>
      <link>https://arxiv.org/abs/2405.17117</link>
      <description>arXiv:2405.17117v1 Announce Type: cross 
Abstract: We propose a novel method of network detection that is robust against any complex dependence structure. Our goal is to conduct exploratory network detection, meaning that we attempt to detect a network composed of ``connectable'' edges that are worth investigating in detail for further modelling or precise network analysis. For a reproducible network detection, we pursuit high power while controlling the false discovery rate (FDR). In particular, we formalize the problem as a multiple testing, and propose p-variables that are used in the Benjamini-Hochberg procedure. We show that the proposed method controls the FDR under arbitrary dependence structure with any sample size, and has asymptotic power one. The validity is also confirmed by simulations and a real data example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17117v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masaki Toyoda, Yoshimasa Uematsu</dc:creator>
    </item>
    <item>
      <title>Selecting the number of components in PCA via random signflips</title>
      <link>https://arxiv.org/abs/2012.02985</link>
      <description>arXiv:2012.02985v3 Announce Type: replace 
Abstract: Principal component analysis (PCA) is a foundational tool in modern data analysis, and a crucial step in PCA is selecting the number of components to keep. However, classical selection methods (e.g., scree plots, parallel analysis, etc.) lack statistical guarantees in the increasingly common setting of large-dimensional data with heterogeneous noise, i.e., where each entry may have a different noise variance. Moreover, it turns out that these methods, which are highly effective for homogeneous noise, can fail dramatically for data with heterogeneous noise. This paper proposes a new method called signflip parallel analysis (FlipPA) for the setting of approximately symmetric noise: it compares the data singular values to those of "empirical null" matrices generated by flipping the sign of each entry randomly with probability one-half. We develop a rigorous theory for FlipPA, showing that it has nonasymptotic type I error control and that it consistently selects the correct rank for signals rising above the noise floor in the large-dimensional limit (even when the noise is heterogeneous). We also rigorously explain why classical permutation-based parallel analysis degrades under heterogeneous noise. Finally, we illustrate that FlipPA compares favorably to state-of-the art methods via numerical simulations and an illustration on data coming from astronomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.02985v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Hong, Yue Sheng, Edgar Dobriban</dc:creator>
    </item>
    <item>
      <title>Another look at Stein's method for Studentized nonlinear statistics with an application to U-statistics</title>
      <link>https://arxiv.org/abs/2301.02098</link>
      <description>arXiv:2301.02098v3 Announce Type: replace 
Abstract: We take another look at using Stein's method to establish uniform Berry-Esseen bounds for Studentized nonlinear statistics, highlighting variable censoring and an exponential randomized concentration inequality for a sum of censored variables as the essential tools to carry the arguments involved. As an important application, we prove a uniform Berry-Esseen bound for Studentized U-statistics in a form that exhibits the dependence on the degree of the kernel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02098v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Leung, Qi-Man Shao, Liqian Zhang</dc:creator>
    </item>
    <item>
      <title>On deviation probabilities in non-parametric regression</title>
      <link>https://arxiv.org/abs/2301.10498</link>
      <description>arXiv:2301.10498v2 Announce Type: replace 
Abstract: This paper is devoted to the problem of determining the concentration bounds that are achievable in non-parametric regression. We consider the setting where features are supported on a bounded subset of $\mathbb{R}^d$, the regression function is Lipschitz, and the noise is only assumed to have a finite second moment. We first specify the fundamental limits of the problem by establishing a general lower bound on deviation probabilities, and then construct explicit estimators that achieve this bound. These estimators are obtained by applying the median-of-means principle to classical local averaging rules in non-parametric regression, including nearest neighbors and kernel procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10498v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Ben-Hamou, Arnaud Guyader</dc:creator>
    </item>
    <item>
      <title>On statistics which are almost sufficient from the viewpoint of the Fisher metrics</title>
      <link>https://arxiv.org/abs/2305.04199</link>
      <description>arXiv:2305.04199v2 Announce Type: replace 
Abstract: A statistic on a statistical model is sufficient if it has no information loss, namely, the Fisher metric of the induced model coincides with that of the original model due to Kullback and Ay-Jost-L\^e-Schwachh\"ofer. We introduce a quantitatively weak version of sufficient statistics such that the Fisher metric of the induced model is bi-Lipschitz equivalent to that of the original model. We characterize such statistics in terms of the conditional probability or by the existence of a certain decomposition of the density function in a way similar to characterizations of sufficient statistics due to Fisher-Neyman and Ay-Jost-L\^e-Schwachh\"ofer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.04199v2</guid>
      <category>math.ST</category>
      <category>math.DG</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaori Yamaguchi, Hiraku Nozawa</dc:creator>
    </item>
    <item>
      <title>Quasi-Likelihood Analysis for Student-L\'evy Regression</title>
      <link>https://arxiv.org/abs/2306.16790</link>
      <description>arXiv:2306.16790v3 Announce Type: replace 
Abstract: We consider the quasi-likelihood analysis for a linear regression model driven by a Student-t L\'{e}vy process with constant scale and arbitrary degrees of freedom. The model is observed at high frequency over an extending period, under which we can quantify how the sampling frequency affects estimation accuracy. In that setting, joint estimation of trend, scale, and degrees of freedom is a non-trivial problem. The bottleneck is that the Student-t distribution is not closed under convolution, making it difficult to estimate all the parameters fully based on the high-frequency time scale. To efficiently deal with the intricate nature from both theoretical and computational points of view, we propose a two-step quasi-likelihood analysis: first, we make use of the Cauchy quasi-likelihood for estimating the regression-coefficient vector and the scale parameter; then, we construct the sequence of the unit-period cumulative residuals to estimate the remaining degrees of freedom. In particular, using full data in the first step causes a problem stemming from the small-time Cauchy approximation, showing the need for data thinning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16790v3</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroki Masuda, Lorenzo Mercuri, Yuma Uehara</dc:creator>
    </item>
    <item>
      <title>Estimators for multivariate allometric regression model</title>
      <link>https://arxiv.org/abs/2402.11219</link>
      <description>arXiv:2402.11219v4 Announce Type: replace 
Abstract: In a regression model with multiple response variables and multiple explanatory variables, if the difference of the mean vectors of the response variables for different values of explanatory variables is always in the direction of the first principal eigenvector of the covariance matrix of the response variables, then it is called a multivariate allometric regression model. This paper studies the estimation of the first principal eigenvector in the multivariate allometric regression model. A class of estimators that includes conventional estimators is proposed based on weighted sum-of-squares matrices of regression sum-of-squares matrix and residual sum-of-squares matrix. We establish an upper bound of the mean squared error of the estimators contained in this class, and the weight value minimizing the upper bound is derived. Sufficient conditions for the consistency of the estimators are discussed in weak identifiability regimes under which the difference of the largest and second largest eigenvalues of the covariance matrix decays asymptotically and in ``large $p$, large $n$" regimes, where $p$ is the number of response variables and $n$ is the sample size. Several numerical results are also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11219v4</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koji Tsukuda, Shun Matsuura</dc:creator>
    </item>
    <item>
      <title>Stability via resampling: statistical problems beyond the real line</title>
      <link>https://arxiv.org/abs/2405.09511</link>
      <description>arXiv:2405.09511v2 Announce Type: replace 
Abstract: Model averaging techniques based on resampling methods (such as bootstrapping or subsampling) have been utilized across many areas of statistics, often with the explicit goal of promoting stability in the resulting output. We provide a general, finite-sample theoretical result guaranteeing the stability of bagging when applied to algorithms that return outputs in a general space, so that the output is not necessarily a real-valued -- for example, an algorithm that estimates a vector of weights or a density function. We empirically assess the stability of bagging on synthetic and real-world data for a range of problem settings, including causal inference, nonparametric regression, and Bayesian model selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09511v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake A. Soloff, Rina Foygel Barber, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>On Convergence of the Alternating Directions SGHMC Algorithm</title>
      <link>https://arxiv.org/abs/2405.13140</link>
      <description>arXiv:2405.13140v2 Announce Type: replace 
Abstract: We study convergence rates of Hamiltonian Monte Carlo (HMC) algorithms with leapfrog integration under mild conditions on stochastic gradient oracle for the target distribution (SGHMC). Our method extends standard HMC by allowing the use of general auxiliary distributions, which is achieved by a novel procedure of Alternating Directions.
  The convergence analysis is based on the investigations of the Dirichlet forms associated with the underlying Markov chain driving the algorithms. For this purpose, we provide a detailed analysis on the error of the leapfrog integrator for Hamiltonian motions with both the kinetic and potential energy functions in general form. We characterize the explicit dependence of the convergence rates on key parameters such as the problem dimension, functional properties of both the target and auxiliary distributions, and the quality of the oracle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13140v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soumyadip Ghosh, Yingdong Lu, Tomasz Nowicki</dc:creator>
    </item>
    <item>
      <title>Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining</title>
      <link>https://arxiv.org/abs/2310.08566</link>
      <description>arXiv:2310.08566v2 Announce Type: replace-cross 
Abstract: Large transformer models pretrained on offline reinforcement learning datasets have demonstrated remarkable in-context reinforcement learning (ICRL) capabilities, where they can make good decisions when prompted with interaction trajectories from unseen environments. However, when and how transformers can be trained to perform ICRL have not been theoretically well-understood. In particular, it is unclear which reinforcement-learning algorithms transformers can perform in context, and how distribution mismatch in offline training data affects the learned algorithms. This paper provides a theoretical framework that analyzes supervised pretraining for ICRL. This includes two recently proposed training methods -- algorithm distillation and decision-pretrained transformers. First, assuming model realizability, we prove the supervised-pretrained transformer will imitate the conditional expectation of the expert algorithm given the observed trajectory. The generalization error will scale with model capacity and a distribution divergence factor between the expert and offline algorithms. Second, we show transformers with ReLU attention can efficiently approximate near-optimal online reinforcement learning algorithms like LinUCB and Thompson sampling for stochastic linear bandits, and UCB-VI for tabular Markov decision processes. This provides the first quantitative analysis of the ICRL capabilities of transformers pretrained from offline trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08566v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Licong Lin, Yu Bai, Song Mei</dc:creator>
    </item>
    <item>
      <title>Mixture Matrix-valued Autoregressive Model</title>
      <link>https://arxiv.org/abs/2312.06098</link>
      <description>arXiv:2312.06098v2 Announce Type: replace-cross 
Abstract: Time series of matrix-valued data are increasingly available in various areas including economics, finance, social science, etc. These data may shed light on the inter-dynamical relationships between two sets of attributes, for instance countries and economic indices. The matrix autoregressive (MAR) model provides a parsimonious approach for analyzing such data. However, the MAR model, being a linear model with parametric constraints, cannot capture the nonlinear patterns in the data, such as regime shifts in the dynamics. We propose a mixture matrix autoregressive (MMAR) model for analyzing potential regime shifts in the dynamics between two attributes, for instance, due to recession vs. blooming, or quiet period vs. pandemic. We propose an EM algorithm for maximum likelihood estimation. We derive some theoretical properties of the proposed method including consistency and asymptotic distribution, and illustrate its performance via simulations and real applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06098v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Wu, Kung-Sik Chan</dc:creator>
    </item>
    <item>
      <title>Degrees of the Wasserstein Distance to Small Toric Models</title>
      <link>https://arxiv.org/abs/2402.09626</link>
      <description>arXiv:2402.09626v2 Announce Type: replace-cross 
Abstract: The study of the closest point(s) on a statistical model from a given distribution in the probability simplex with respect to a fixed Wasserstein metric gives rise to a polyhedral norm distance optimization problem. There are two components to the complexity of determining the Wasserstein distance from a data point to a model. One is the combinatorial complexity that is governed by the combinatorics of the Lipschitz polytope of the finite metric to be used. Another is the algebraic complexity, which is governed by the polar degrees of the Zariski closure of the model. We find formulas for the polar degrees of rational normal scrolls and graphical models whose underlying graphs are star trees. Also, the polar degrees of the graphical models with four binary random variables where the graphs are a path on four vertices and the four-cycle, as well as for small, no-three-way interaction models, were computed. We investigate the algebraic degree of computing the Wasserstein distance to a small subset of these models. It was observed that this algebraic degree is typically smaller than the corresponding polar degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09626v2</guid>
      <category>math.AG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Greg DePaul, Serkan Ho\c{s}ten, Nilava Metya, Ikenna Nometa</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion</title>
      <link>https://arxiv.org/abs/2402.17886</link>
      <description>arXiv:2402.17886v3 Announce Type: replace-cross 
Abstract: This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Diffusion Monte Carlo (DMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit still suffering from the curse of dimensionality. Consequently, for low dimensional distributions, ZOD-MC is a very efficient sampler, with performance exceeding latest samplers, including also-denoising-diffusion-based RDMC and RS-DMC. Last, we experimentally demonstrate the insensitivity of ZOD-MC to increasingly higher barriers between modes or discontinuity in non-convex potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17886v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ye He, Kevin Rojas, Molei Tao</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for the Sensitivities of the Pearson Correlation Coefficient and Its Statistical Significance to Online Data</title>
      <link>https://arxiv.org/abs/2405.14686</link>
      <description>arXiv:2405.14686v2 Announce Type: replace-cross 
Abstract: Reliably measuring the collinearity of bivariate data is crucial in statistics, particularly for time-series analysis or ongoing studies in which incoming observations can significantly impact current collinearity estimates. Leveraging identities from Welford's online algorithm for sample variance, we develop a rigorous theoretical framework for analyzing the maximal change to the Pearson correlation coefficient and its p-value that can be induced by additional data. Further, we show that the resulting optimization problems yield elegant closed-form solutions that can be accurately computed by linear- and constant-time algorithms. Our work not only creates new theoretical avenues for robust correlation measures, but also has broad practical implications for disciplines that span econometrics, operations research, clinical trials, climatology, differential privacy, and bioinformatics. Software implementations of our algorithms in Cython-wrapped C are made available at https://github.com/marc-harary/sensitivity for reproducibility, practical deployment, and future theoretical development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14686v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Harary</dc:creator>
    </item>
  </channel>
</rss>
