<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.GN</link>
    <description>q-bio.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 01:54:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Artificial Intelligence and Deep Learning Algorithms for Epigenetic Sequence Analysis: A Review for Epigeneticists and AI Experts</title>
      <link>https://arxiv.org/abs/2504.03733</link>
      <description>arXiv:2504.03733v1 Announce Type: new 
Abstract: Epigenetics encompasses mechanisms that can alter the expression of genes without changing the underlying genetic sequence. The epigenetic regulation of gene expression is initiated and sustained by several mechanisms such as DNA methylation, histone modifications, chromatin conformation, and non-coding RNA. The changes in gene regulation and expression can manifest in the form of various diseases and disorders such as cancer and congenital deformities. Over the last few decades, high throughput experimental approaches have been used to identify and understand epigenetic changes, but these laboratory experimental approaches and biochemical processes are time-consuming and expensive. To overcome these challenges, machine learning and artificial intelligence (AI) approaches have been extensively used for mapping epigenetic modifications to their phenotypic manifestations. In this paper we provide a narrative review of published research on AI models trained on epigenomic data to address a variety of problems such as prediction of disease markers, gene expression, enhancer promoter interaction, and chromatin states. The purpose of this review is twofold as it is addressed to both AI experts and epigeneticists. For AI researchers, we provided a taxonomy of epigenetics research problems that can benefit from an AI-based approach. For epigeneticists, given each of the above problems we provide a list of candidate AI solutions in the literature. We have also identified several gaps in the literature, research challenges, and recommendations to address these challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03733v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compbiomed.2024.109302</arxiv:DOI>
      <arxiv:journal_reference>journal={Computers in Biology and Medicine}, volume={183}, pages={109302}, year={2024}, publisher={Elsevier}</arxiv:journal_reference>
      <dc:creator>Muhammad Tahir, Mahboobeh Norouzi, Shehroz S. Khan, James R. Davie, Soichiro Yamanaka, Ahmed Ashraf</dc:creator>
    </item>
    <item>
      <title>SAGe: A Lightweight Algorithm-Architecture Co-Design for Alleviating Data Preparation Overheads in Large-Scale Genome Analysis</title>
      <link>https://arxiv.org/abs/2504.03732</link>
      <description>arXiv:2504.03732v1 Announce Type: cross 
Abstract: There have been extensive efforts to accelerate genome analysis, given the exponentially growing volumes of genomic data. Prior works typically assume that the data is ready to be analyzed in the desired format; in real usage scenarios, however, it is common practice to store genomic data in storage systems in a compressed format. Unfortunately, preparing genomic data (i.e., accessing compressed data from storage, and decompressing and reformatting it) for an accelerator leads to large performance and energy overheads, significantly diminishing the accelerator's intended benefits. To harness the benefits of acceleration, without needing to store massive genomic data uncompressed, there is a critical need to effectively address data preparation overheads. The solution must meet three criteria: (i) high performance and energy efficiency, (ii) high compression ratios, comparable to state-of-the-art genomic compression, and (iii) be lightweight for seamless integration with a broad range of genomics systems. This is challenging, particularly due to the high decompression complexity of state-of-the-art genomic compressors and the resource constraints of a wide range of genomics systems. We propose SAGe, an algorithm-architecture co-design for highly-compressed storage and high-performance access of large-scale genomic data in desired formats. With our rigorous analysis of genomic datasets' features, we propose a co-design of a new (de)compression algorithm, hardware, storage data layout, and interface commands. SAGe encodes data in structures decodable by efficient sequential scans and lightweight hardware. To still maintain high compression ratios, SAGe exploits unique features of genomic data. SAGe improves the average performance (energy efficiency) of state-of-the-art genomics accelerators by 3.0-12.3x (18.8-49.6x), compared to when the accelerators rely on state-of-the-art decompressors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03732v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nika Mansouri Ghiasi, Talu G\"uloglu, Harun Mustafa, Can Firtina, Konstantina Koliogeorgi, Konstantinos Kanellopoulos, Haiyu Mao, Rakesh Nadig, Mohammad Sadrosadati, Jisung Park, Onur Mutlu</dc:creator>
    </item>
    <item>
      <title>Multiscale Modeling Primer: Focus on Chromatin and Epigenetics</title>
      <link>https://arxiv.org/abs/2504.03876</link>
      <description>arXiv:2504.03876v1 Announce Type: cross 
Abstract: Essential life processes take place across multiple space and time scales in living organisms but understanding their mechanistic interactions remains an ongoing challenge. Advanced multiscale modeling techniques are providing new opportunities and insights into these complex processes. In cells, meters of chromatin are folded into a nucleus with a diameter on the order of microns. The three-dimensional chromatin structure coupled with biochemical processes that turn genes on or off, specify a given cell type through a complicated set of interactions collectively referred to as epigenetics. Important epigenetic processes include the differential accessibility of genomic loci to transcription factors and chemical modifications to DNA and DNA-binding molecules such as histones. The dynamics of these epigenetic processes span timescales from milliseconds to years. How do chemical modifications consisting of a handful of atoms cooperate to modulate genome folding at the scale of the nucleus and impact organism outcomes? In this review, we highlight the inherently multiscale nature of chromatin organization, with a focus on computational modeling to bridge the gaps in our understanding of biochemical processes across scales. We review relevant chromatin biology, including major types of epigenetic modifications as well as the higher order chromatin structures to present a multiscale view of chromatin. We also review relevant computational methods to simulate chromatin structure, function, and dynamics, as well as experimental techniques that inform and validate said models. Finally, we argue that multiscale modeling provides a path forward towards understanding emergent behavior in this inherently multiscale system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03876v1</guid>
      <category>q-bio.MN</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Achal Mahajan, Erik J. Navarro, William Poole, Carlos F Lopez</dc:creator>
    </item>
    <item>
      <title>OLAF: An Open Life Science Analysis Framework for Conversational Bioinformatics Powered by Large Language Models</title>
      <link>https://arxiv.org/abs/2504.03976</link>
      <description>arXiv:2504.03976v1 Announce Type: cross 
Abstract: OLAF (Open Life Science Analysis Framework) is an open-source platform that enables researchers to perform bioinformatics analyses using natural language. By combining large language models (LLMs) with a modular agent-pipe-router architecture, OLAF generates and executes bioinformatics code on real scientific data, including formats like .h5ad. The system includes an Angular front end and a Python/Firebase backend, allowing users to run analyses such as single-cell RNA-seq workflows, gene annotation, and data visualization through a simple web interface. Unlike general-purpose AI tools, OLAF integrates code execution, data handling, and scientific libraries in a reproducible, user-friendly environment. It is designed to lower the barrier to computational biology for non-programmers and support transparent, AI-powered life science research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03976v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dylan Riffle, Nima Shirooni, Cody He, Manush Murali, Sovit Nayak, Rishikumar Gopalan, Diego Gonzalez Lopez</dc:creator>
    </item>
    <item>
      <title>On the Coverage Required for Diploid Genome Assembly</title>
      <link>https://arxiv.org/abs/2405.05734</link>
      <description>arXiv:2405.05734v3 Announce Type: replace-cross 
Abstract: The repeat content and heterozygosity rate of a target genome are important factors in determining the feasibility of achieving a complete telomere-to-telomere assembly. The mathematical relationship between the required coverage and read length for the purpose of unique reconstruction remains unexplored for diploid genomes. We investigate the information-theoretic conditions that the given set of sequencing reads must satisfy to achieve the complete reconstruction of the true sequence of a diploid genome. We also analyze the standard greedy and de-Bruijn graph-based assembly algorithms. Our results show that the coverage and read length requirements of the assembly algorithms are considerably higher than the lower bound because both algorithms require the double repeats in the genome to be bridged. Finally, we derive the necessary conditions for the overlap graph-based assembly paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05734v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daanish Mahajan, Chirag Jain, Navin Kashyap</dc:creator>
    </item>
  </channel>
</rss>
