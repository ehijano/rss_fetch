<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.IV updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.IV</link>
    <description>eess.IV updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.IV" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Sep 2025 04:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance</title>
      <link>https://arxiv.org/abs/2508.21263</link>
      <description>arXiv:2508.21263v1 Announce Type: new 
Abstract: To reduce the amount of required labeled data for lung disease severity classification from chest X-rays (CXRs) under class imbalance, this study applied deep active learning with a Bayesian Neural Network (BNN) approximation and weighted loss function. This retrospective study collected 2,319 CXRs from 963 patients (mean age, 59.2 $\pm$ 16.6 years; 481 female) at Emory Healthcare affiliated hospitals between January and November 2020. All patients had clinically confirmed COVID-19. Each CXR was independently labeled by 3 to 6 board-certified radiologists as normal, moderate, or severe. A deep neural network with Monte Carlo Dropout was trained using active learning to classify disease severity. Various acquisition functions were used to iteratively select the most informative samples from an unlabeled pool. Performance was evaluated using accuracy, area under the receiver operating characteristic curve (AU ROC), and area under the precision-recall curve (AU PRC). Training time and acquisition time were recorded. Statistical analysis included descriptive metrics and performance comparisons across acquisition strategies. Entropy Sampling achieved 93.7% accuracy (AU ROC, 0.91) in binary classification (normal vs. diseased) using 15.4% of the training data. In the multi-class setting, Mean STD sampling achieved 70.3% accuracy (AU ROC, 0.86) using 23.1% of the labeled data. These methods outperformed more complex and computationally expensive acquisition functions and significantly reduced labeling needs. Deep active learning with BNN approximation and weighted loss effectively reduces labeled data requirements while addressing class imbalance, maintaining or exceeding diagnostic performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21263v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roy M. Gabriel, Mohammadreza Zandehshahvar, Marly van Assen, Nattakorn Kittisut, Kyle Peters, Carlo N. De Cecco, Ali Adibi</dc:creator>
    </item>
    <item>
      <title>QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.19153</link>
      <description>arXiv:2508.19153v1 Announce Type: cross 
Abstract: We address vision-guided quadruped motion control with reinforcement learning (RL) and highlight the necessity of combining proprioception with vision for robust control. We propose QuadKAN, a spline-parameterized cross-modal policy instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates a spline encoder for proprioception and a spline fusion head for proprioception-vision inputs. This structured function class aligns the state-to-action mapping with the piecewise-smooth nature of gait, improving sample efficiency, reducing action jitter and energy consumption, and providing interpretable posture-action sensitivities. We adopt Multi-Modal Delay Randomization (MMDR) and perform end-to-end training with Proximal Policy Optimization (PPO). Evaluations across diverse terrains, including both even and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate that QuadKAN achieves consistently higher returns, greater distances, and fewer collisions than state-of-the-art (SOTA) baselines. These results show that spline-parameterized policies offer a simple, effective, and interpretable alternative for robust vision-guided locomotion. A repository will be made available upon acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19153v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allen Wang, Gavin Tao</dc:creator>
    </item>
    <item>
      <title>Project-Based Learning in Introductory Quantum Computing Courses: A Case Study on Quantum Algorithms for Medical Imaging</title>
      <link>https://arxiv.org/abs/2508.21321</link>
      <description>arXiv:2508.21321v1 Announce Type: cross 
Abstract: Quantum computing introduces abstract concepts and non-intuitive behaviors that can be challenging for students to grasp through traditional lecture-based instruction alone. This paper demonstrates how Project-Based Learning (PBL) can be leveraged to bridge that gap. This can be done by engaging students in a real-world, interdisciplinary task that combines quantum computing with their field of interest. As part of a similar assignment, we investigated the application of the Harrow-Hassidim-Lloyd (HHL) algorithm for computed tomography (CT) image reconstruction and benchmarked its performance against the classical Algebraic Reconstruction Technique (ART). Through implementing and analyzing both methods on a small-scale problem, we gained practical experience with quantum algorithms, critically evaluated their limitations, and developed technical writing and research skills. The experience demonstrated that Project-Based Learning not only enhances conceptual understanding but also encourages students to engage deeply with emerging technologies through research, implementation, and reflection. We recommend the integration of similar PBL modules in introductory quantum computing courses. The assignment also works better if students are required to write and submit a conference-style paper, supported by mentorship from faculty across the different fields. In such course interdisciplinary, real-world problems can transform abstract theory into meaningful learning experiences and better prepare students for future advancements in quantum technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21321v1</guid>
      <category>physics.ed-ph</category>
      <category>eess.IV</category>
      <category>quant-ph</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nischal Binod Gautam, Keith Evan Schubert, Enrique P. Blair</dc:creator>
    </item>
    <item>
      <title>Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2508.21715</link>
      <description>arXiv:2508.21715v1 Announce Type: cross 
Abstract: Convolutional Neural Networks (CNNs) have become the foundation of modern computer vision, achieving unprecedented accuracy across diverse image recognition tasks. While these networks excel on in-distribution data, they remain vulnerable to adversarial perturbations imperceptible input modifications that cause misclassification with high confidence. However, existing detection methods either require expensive retraining, modify network architecture, or degrade performance on clean inputs. Here we show that adversarial perturbations create immediate, detectable entropy signatures in CNN activations that can be monitored without any model modification. Using parallel entropy monitoring on VGG-16, we demonstrate that adversarial inputs consistently shift activation entropy by 7% in early convolutional layers, enabling 90% detection accuracy with false positives and false negative rates below 20%. The complete separation between clean and adversarial entropy distributions reveals that CNNs inherently encode distribution shifts in their activation patterns. This work establishes that CNN reliability can be assessed through activation entropy alone, enabling practical deployment of self-diagnostic vision systems that detect adversarial inputs in real-time without compromising original model performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21715v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amirhossein Nazeri, Wael Hafez</dc:creator>
    </item>
    <item>
      <title>Endmember Extraction from Hyperspectral Images Using Self-Dictionary Approach with Linear Programming</title>
      <link>https://arxiv.org/abs/2404.13098</link>
      <description>arXiv:2404.13098v3 Announce Type: replace 
Abstract: Hyperspectral imaging technology has a wide range of applications, including forest management, mineral resource exploration, and Earth surface monitoring. A key step in utilizing this technology is endmember extraction, which aims to identify the spectral signatures of materials in observed scenes. Theoretical studies suggest that self-dictionary methods using linear programming (LP), known as Hottopixx methods, are effective in extracting endmembers. However, their practical application is hindered by high computational costs, as they require solving LP problems whose size grows quadratically with the number of pixels in the image. As a result, their actual effectiveness remains unclear. To address this issue, we propose an enhanced implementation of Hottopixx designed to reduce computational time and improve endmember extraction performance. We demonstrate its effectiveness through experiments. The results suggest that our implementation enables the application of Hottopixx for endmember extraction from real hyperspectral images and allows us to achieve reasonably high accuracy in estimating endmember signatures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13098v3</guid>
      <category>eess.IV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomohiko Mizutani</dc:creator>
    </item>
    <item>
      <title>Gaussian is All You Need: A Unified Framework for Solving Inverse Problems via Diffusion Posterior Sampling</title>
      <link>https://arxiv.org/abs/2409.08906</link>
      <description>arXiv:2409.08906v3 Announce Type: replace 
Abstract: Diffusion models can generate a variety of high-quality images by modeling complex data distributions. Trained diffusion models can also be very effective image priors for solving inverse problems. Most of the existing diffusion-based methods integrate data consistency steps by approximating the likelihood function within the diffusion reverse sampling process. In this paper, we show that the existing approximations are either insufficient or computationally inefficient. To address these issues, we propose a unified likelihood approximation method that incorporates a covariance correction term to enhance the performance and avoids propagating gradients through the diffusion model. The correction term, when integrated into the reverse diffusion sampling process, achieves better convergence towards the true data posterior for selected distributions and improves performance on real-world natural image datasets. Furthermore, we present an efficient way to factorize and invert the covariance matrix of the likelihood function for several inverse problems. Our comprehensive experiments demonstrate the effectiveness of our method over several existing approaches. Code available at https://github.com/CSIPlab/CoDPS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08906v3</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCI.2025.3594988</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Computational Imaging, vol. 11, pp. 1020-1030, 2025</arxiv:journal_reference>
      <dc:creator>Nebiyou Yismaw, Ulugbek S. Kamilov, M. Salman Asif</dc:creator>
    </item>
    <item>
      <title>DIFFRACT: Diffusion-based Restoration via Adaptive Control and Thresholding for Diffraction Imaging</title>
      <link>https://arxiv.org/abs/2504.16951</link>
      <description>arXiv:2504.16951v2 Announce Type: replace 
Abstract: This paper presents a novel approach for denoising Electron Backscatter Diffraction (EBSD) patterns using diffusion models. We propose a two-stage training process with a UNet-based architecture, incorporating an auxiliary regression head to predict the quality of the experimental pattern and assess the progress of the denoising process. The model uses an adaptive denoising strategy, which integrates quality prediction and feedback-driven iterative denoising process control. This adaptive feedback loop allows the model to adjust its schedule, providing fine control over the denoising process. Furthermore, our model can identify samples where no meaningful signal is present, thereby reducing the risk of hallucinations. We demonstrate the DIFFRACT - the successful application of diffusion models to EBSD pattern denoising using a custom-collected dataset of EBSD patterns, their corresponding Master Patterns, and quality values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16951v2</guid>
      <category>eess.IV</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nikolay Falaleev, Nikolai Orlov</dc:creator>
    </item>
    <item>
      <title>Explicit Residual-Based Scalable Image Coding for Humans and Machines</title>
      <link>https://arxiv.org/abs/2506.19297</link>
      <description>arXiv:2506.19297v2 Announce Type: replace 
Abstract: Scalable image compression is a technique that progressively reconstructs multiple versions of an image for different requirements. In recent years, images have increasingly been consumed not only by humans but also by image recognition models. This shift has drawn growing attention to scalable image compression methods that serve both machine and human vision (ICMH). Many existing models employ neural network-based codecs, known as learned image compression, and have made significant strides in this field by carefully designing the loss functions. In some cases, however, models are overly reliant on their learning capacity, and their architectural design is not sufficiently considered. In this paper, we enhance the coding efficiency and interpretability of ICMH framework by integrating an explicit residual compression mechanism, which is commonly employed in resolution scalable coding methods such as JPEG2000. Specifically, we propose two complementary methods: Feature Residual-based Scalable Coding (FR-ICMH) and Pixel Residual-based Scalable Coding (PR-ICMH). These proposed methods are applicable to various machine vision tasks. Moreover, they provide flexibility to choose between encoder complexity and compression performance, making it adaptable to diverse application requirements. Experimental results demonstrate the effectiveness of our proposed methods, with PR-ICMH achieving up to 29.57% BD-rate savings over the previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19297v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yui Tatsumi, Ziyue Zeng, Hiroshi Watanabe</dc:creator>
    </item>
    <item>
      <title>Numerical Uncertainty in Linear Registration: An Experimental Study</title>
      <link>https://arxiv.org/abs/2508.00781</link>
      <description>arXiv:2508.00781v2 Announce Type: replace-cross 
Abstract: While linear registration is a critical step in MRI preprocessing pipelines, its numerical uncertainty is understudied. Using Monte-Carlo Arithmetic (MCA) simulations, we assessed the most commonly used linear registration tools within major software packages (SPM, FSL, and ANTs) across multiple image similarity measures, two brain templates, and both healthy control (HC, n=50) and Parkinson's Disease (PD, n=50) cohorts. Our findings highlight the influence of linear registration tools and similarity measures on numerical stability. Among the evaluated tools and with default similarity measures, SPM exhibited the highest stability. FSL and ANTs showed greater and similar ranges of variability, with ANTs demonstrating particular sensitivity to numerical perturbations that occasionally led to registration failure. Furthermore, no significant differences were observed between healthy and PD cohorts, suggesting that numerical stability analyses obtained with healthy subjects may generalise to clinical populations. Finally, we also demonstrated how numerical uncertainty measures may support automated quality control (QC) of linear registration results. Overall, our experimental results characterize the numerical stability of linear registration experimentally and can serve as a basis for future uncertainty analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00781v2</guid>
      <category>q-bio.QM</category>
      <category>eess.IV</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niusha Mirhakimi, Yohan Chatelain, Tristan Glatard, Jean-Baptiste Poline</dc:creator>
    </item>
    <item>
      <title>QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots</title>
      <link>https://arxiv.org/abs/2508.02512</link>
      <description>arXiv:2508.02512v2 Announce Type: replace-cross 
Abstract: Panoramic cameras, capturing comprehensive 360-degree environmental data, are suitable for quadruped robots in surrounding perception and interaction with complex environments. However, the scarcity of high-quality panoramic training data-caused by inherent kinematic constraints and complex sensor calibration challenges-fundamentally limits the development of robust perception systems tailored to these embodied platforms. To address this issue, we propose QuaDreamer-the first panoramic data generation engine specifically designed for quadruped robots. QuaDreamer focuses on mimicking the motion paradigm of quadruped robots to generate highly controllable, realistic panoramic videos, providing a data source for downstream tasks. Specifically, to effectively capture the unique vertical vibration characteristics exhibited during quadruped locomotion, we introduce Vertical Jitter Encoding (VJE). VJE extracts controllable vertical signals through frequency-domain feature filtering and provides high-quality prompts. To facilitate high-quality panoramic video generation under jitter signal control, we propose a Scene-Object Controller (SOC) that effectively manages object motion and boosts background jitter control through the attention mechanism. To address panoramic distortions in wide-FoV video generation, we propose the Panoramic Enhancer (PE)-a dual-stream architecture that synergizes frequency-texture refinement for local detail enhancement with spatial-structure correction for global geometric consistency. We further demonstrate that the generated video sequences can serve as training data for the quadruped robot's panoramic visual perception model, enhancing the performance of multi-object tracking in 360-degree scenes. The source code and model weights will be publicly available at https://github.com/losehu/QuaDreamer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02512v2</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Wu, Fei Teng, Hao Shi, Qi Jiang, Kai Luo, Kaiwei Wang, Kailun Yang</dc:creator>
    </item>
  </channel>
</rss>
