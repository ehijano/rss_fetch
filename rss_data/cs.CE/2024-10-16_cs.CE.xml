<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 01:57:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Uncertainty quantification on the prediction of creep remaining useful life</title>
      <link>https://arxiv.org/abs/2410.10830</link>
      <description>arXiv:2410.10830v1 Announce Type: new 
Abstract: Accurate prediction of remaining useful life (RUL) under creep conditions is crucial for the design and maintenance of industrial equipment operating at high temperatures. Traditional deterministic methods often overlook significant variability in experimental data, leading to unreliable predictions. This study introduces a probabilistic framework to address uncertainties in predicting creep rupture time. We utilize robust regression methods to minimize the influence of outliers and enhance model estimates. Sobol indices-based global sensitivity analysis identifies the most influential parameters, followed by Monte Carlo simulations to determine the probability distribution of the material's RUL. Model selection techniques, including the Akaike and Bayesian information criteria, ensure the optimal predictive model. This probabilistic approach allows for the delineation of safe operational limits with quantifiable confidence levels, thereby improving the reliability and safety of high-temperature applications. The framework's versatility also allows integration with various mathematical models, offering a comprehensive understanding of creep behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10830v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Maudonet, Carlos Frederico Trotta Matt, Americo Cunha Jr</dc:creator>
    </item>
    <item>
      <title>Fair Interest Rates Are Impossible for Lending Pools: Results from Options Pricing</title>
      <link>https://arxiv.org/abs/2410.11053</link>
      <description>arXiv:2410.11053v1 Announce Type: new 
Abstract: Cryptocurrency lending pools are services that allow lenders to pool together assets in one cryptocurrency and loan it out to borrowers who provide collateral worth more (than the loan) in a separate cryptocurrency. Borrowers can repay their loans to reclaim their collateral unless their loan was liquidated, which happens when the value of the collateral dips significantly. Interest rates for these pools are currently set via supply and demand heuristics, which have several downsides, including inefficiency, inflexibility, and being vulnerable to manipulation. Here, we reduce lending pools to options, and then use ideas from options pricing to search for fair interest rates for lending pools. In a simplified model where the loans have a fixed duration and can only be repaid at the end of the term, we obtain analytical pricing results. We then consider a more realistic model, where loans can be repaid dynamically and without expiry. Our main theoretical contribution is to show that fair interest rates do not exist in this setting. We then show that impossibility results generalize even to models of lending pools which have no obvious reduction to options. To address these negative results, we introduce a model of lending pools with fixed fees, and model the ability of borrowers to top-up their loans to reduce the risk of liquidation. As a proof of concept, we use simulations to show how our model's predicted interest rates compare to interest rates in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11053v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joe Halpern, Rafael Pass, Aditya Saraf</dc:creator>
    </item>
    <item>
      <title>PhysioFormer: Integrating Multimodal Physiological Signals and Symbolic Regression for Explainable Affective State Prediction</title>
      <link>https://arxiv.org/abs/2410.11376</link>
      <description>arXiv:2410.11376v1 Announce Type: new 
Abstract: Most affective computing tasks still rely heavily on traditional methods, with few deep learning models applied, particularly in multimodal signal processing. Given the importance of stress monitoring for mental health, developing a highly reliable and accurate affective computing model is essential. In this context, we propose a novel model, for affective state prediction using physiological signals. PhysioFormer model integrates individual attributes and multimodal physiological data to address interindividual variability, enhancing its reliability and generalization across different individuals. By incorporating feature embedding and affective representation modules, PhysioFormer model captures dynamic changes in time-series data and multimodal signal features, significantly improving accuracy. The model also includes an explainability model that uses symbolic regression to extract laws linking physiological signals to affective states, increasing transparency and explainability. Experiments conducted on the Wrist and Chest subsets of the WESAD dataset confirmed the model's superior performance, achieving over 99% accuracy, outperforming existing SOTA models. Sensitivity and ablation experiments further demonstrated PhysioFormer's reliability, validating the contribution of its individual components. The integration of symbolic regression not only enhanced model explainability but also highlighted the complex relationships between physiological signals and affective states. Future work will focus on optimizing the model for larger datasets and real-time applications, particularly in more complex environments. Additionally, further exploration of physiological signals and environmental factors will help build a more comprehensive affective computing system, advancing its use in health monitoring and psychological intervention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11376v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhifeng Wang, Wanxuan Wu, Chunyan Zeng</dc:creator>
    </item>
    <item>
      <title>PANACEA: Towards Influence-driven Profiling of Drug Target Combinations in Cancer Signaling Networks</title>
      <link>https://arxiv.org/abs/2410.11458</link>
      <description>arXiv:2410.11458v1 Announce Type: new 
Abstract: Data profiling has garnered increasing attention within the data science community, primarily focusing on structured data. In this paper, we introduce a novel framework called panacea, designed to profile known cancer target combinations in cancer type-specific signaling networks. Given a large signaling network for a cancer type, known targets from approved anticancer drugs, a set of cancer mutated genes, and a combination size parameter k, panacea automatically generates a delta histogram that depicts the distribution of k-sized target combinations based on their topological influence on cancer mutated genes and other nodes. To this end, we formally define the novel problem of influence-driven target combination profiling (i-TCP) and propose an algorithm that employs two innovative personalized PageRank-based measures, PEN distance and PEN-diff, to quantify this influence and generate the delta histogram. Our experimental studies on signaling networks related to four cancer types demonstrate that our proposed measures outperform several popular network properties in profiling known target combinations. Notably, we demonstrate that panacea can significantly reduce the candidate k-node combination exploration space, addressing a longstanding challenge for tasks such as in silico target combination prediction in large cancer-specific signaling networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11458v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baihui Xu, Sourav S Bhowmick, Jiancheng Hu</dc:creator>
    </item>
    <item>
      <title>Clustering doc2vec output for topic-dimensionality reduction: A MITRE ATT&amp;CK calibration</title>
      <link>https://arxiv.org/abs/2410.11573</link>
      <description>arXiv:2410.11573v1 Announce Type: new 
Abstract: We introduce a novel approach to text classification by combining doc2vec embeddings with advanced clustering techniques to improve the analysis of specialized, high-dimensional textual data. We integrate unsupervised methods such as Louvain, K-means, and Spectral clustering with doc2vec to enhance the detection of semantic patterns across a large corpus. As a case study, we apply this methodology to cybersecurity risk analysis using the MITRE ATT\&amp;CK framework to structure and reduce the dimensionality of cyberattack tactics. Louvain clustering proved the most effective among the tested methods, achieving the best balance between cluster coherence and computational efficiency. Our approach identifies four "super tactics," demonstrating how clustering improves thematic coherence and risk attribution. The results validate the utility of combining doc2vec with clustering, particularly Louvain, for enhancing topic modeling and text classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11573v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Monnet, Lo\"ic Mar\'echal</dc:creator>
    </item>
    <item>
      <title>Parameter estimation of structural dynamics with neural operators enabled surrogate modeling</title>
      <link>https://arxiv.org/abs/2410.11712</link>
      <description>arXiv:2410.11712v1 Announce Type: new 
Abstract: Parameter estimation generally involves inferring the values of mathematical models derived from first principles or expert knowledge, which is challenging for complex structural systems. In this work, we present a unified deep learning-based framework for parameterization, forward modeling, and inverse modeling of structural dynamics. The parameterization is flexible and can be user-defined, including physical and/or non-physical (customized) parameters. In forward modeling, we train a neural operator for response prediction -- forming a surrogate model, which leverages the defined system parameters and excitation forces as inputs. The inverse modeling focuses on estimating system parameters. In particular, the learned forward surrogate model (which is differentiable) is utilized for preliminary parameter estimation via gradient-based optimization; to further boost the parameter estimation, we introduce a neural refinement method to mitigate ill-posed problems, which often occur in the former. The framework's effectiveness is verified numerically and experimentally, in both interpolation and extrapolation cases, indicating its capability to capture intrinsic dynamics of structural systems from both forward and inverse perspectives. Moreover, the framework's flexibility is expected to support a wide range of applications, including surrogate modeling, structural identification, damage detection, and inverse design of structural systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11712v1</guid>
      <category>cs.CE</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingyuan Zhou, Haoze Song, Wenjing Ye, Wei Wang, Zhilu Lai</dc:creator>
    </item>
    <item>
      <title>AT-MoE: Adaptive Task-planning Mixture of Experts via LoRA Approach</title>
      <link>https://arxiv.org/abs/2410.10896</link>
      <description>arXiv:2410.10896v1 Announce Type: cross 
Abstract: The advent of Large Language Models (LLMs) has ushered in a new era of artificial intelligence, with the potential to transform various sectors through automation and insightful analysis. The Mixture of Experts (MoE) architecture has been proposed as a solution to enhance model performance in complex tasks. Yet, existing MoE models struggle with task-specific learning and interpretability, especially in fields like medicine where precision is critical. This paper introduces the Adaptive Task-planing Mixture of Experts(AT-MoE), an innovative architecture designed to address these limitations. We first train task-specific experts via LoRA approach to enhance problem-solving capabilities and interpretability in specialized areas. Subsequently, we introduce a layer-wise adaptive grouped routing module that optimizes module fusion based on complex task instructions, ensuring optimal task resolution. The grouped routing module first perform overall weight allocation from the dimension of the expert group, and then conduct local weight normalization adjustments within the group. This design maintains multi-dimensional balance, controllability, and interpretability, while facilitating task-specific fusion in response to complex instructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10896v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xurui Li, Juanjuan Yao</dc:creator>
    </item>
    <item>
      <title>BRC20 Pinning Attack</title>
      <link>https://arxiv.org/abs/2410.11295</link>
      <description>arXiv:2410.11295v1 Announce Type: cross 
Abstract: BRC20 tokens are a type of non-fungible asset on the Bitcoin network. They allow users to embed customized content within Bitcoin satoshis. The related token frenzy has reached a market size of USD 3,650b over the past year (2023Q3-2024Q3). However, this intuitive design has not undergone serious security scrutiny.
  We present the first in-depth analysis of the BRC20 transfer mechanism and identify a critical attack vector. A typical BRC20 transfer involves two bundled on-chain transactions with different fee levels: the first (i.e., Tx1) with a lower fee inscribes the transfer request, while the second (i.e., Tx2) with a higher fee finalizes the actual transfer. We find that an adversary can exploit this by sending a manipulated fee transaction (falling between the two fee levels), which allows Tx1 to be processed while Tx2 remains pinned in the mempool. This locks the BRC20 liquidity and disrupts normal transfers for users. We term this BRC20 pinning attack.
  Our attack exposes an inherent design flaw that can be applied to 90+% inscription-based tokens within the Bitcoin ecosystem.
  We also conducted the attack on Binance's ORDI hot wallet (the most prevalent BRC20 token and the most active wallet), resulting in a temporary suspension of ORDI withdrawals on Binance for 3.5 hours, which were shortly resumed after our communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11295v1</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minfeng Qi, Qin Wang, Zhipeng Wang, Lin Zhong, Tianqing Zhu, Shiping Chen, William Knottenbelt</dc:creator>
    </item>
    <item>
      <title>On the potential of Optimal Transport in Geospatial Data Science</title>
      <link>https://arxiv.org/abs/2410.11709</link>
      <description>arXiv:2410.11709v1 Announce Type: cross 
Abstract: Prediction problems in geographic information science and transportation are frequently motivated by the possibility to enhance operational efficiency. Examples range from predicting car sharing demand for optimizing relocation to forecasting traffic congestion for navigation purposes. However, conventional accuracy metrics do not account for the spatial distribution of predictions errors, despite its relevance for operations. We put forward Optimal Transport (OT) as a spatial evaluation metric and loss function. The proposed OT metric assesses the utility of spatial prediction models in terms of the relocation costs caused by prediction errors. In experiments on real and synthetic data, we demonstrate that 1) the spatial distribution of the prediction errors is relevant in many applications and can be translated to real-world costs, 2) in contrast to other metrics, OT reflects these spatial costs, and 3) OT metrics improve comparability across spatial and temporal scales. Finally, we advocate for leveraging OT as a loss function in neural networks to improve the spatial correctness of predictions. This approach not only aligns evaluation in GeoAI with operational considerations, but also signifies a step forward in refining predictions within geospatial applications. To facilitate the adoption of OT in GIS, we provide code and tutorials at https://github.com/mie-lab/geospatialOT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11709v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nina Wiedemann, Th\'eo Uscidda, Martin Raubal</dc:creator>
    </item>
    <item>
      <title>Patient-specific coronary angioplasty simulations -- a mixed-dimensional finite element modeling approach</title>
      <link>https://arxiv.org/abs/2407.13276</link>
      <description>arXiv:2407.13276v2 Announce Type: replace 
Abstract: Coronary angioplasty with stent implantation is the most frequently used interventional treatment for coronary artery disease. However, reocclusion within the stent, referred to as in-stent restenosis, occurs in up to 10% of lesions. It is widely accepted that mechanical loads on the vessel wall strongly affect adaptive and maladaptive mechanisms. Yet, the role of procedural and lesion-specific influence on restenosis risk remains understudied. Computational modeling of the stenting procedure can provide new mechanistic insights, such as local stresses, that play a significant role in tissue growth and remodeling. Previous simulation studies often featured simplified artery and stent geometries and cannot be applied to real-world examples. Realistic simulations were computationally expensive since they featured fully resolved stenting device models. The aim of this work is to develop and present a mixed-dimensional formulation to simulate the patient-specific stenting procedure with a reduced-dimensional beam model for the stent and 3D models for the artery. In addition to presenting the numerical approach, we apply it to realistic cases to study the intervention's mechanical effect on the artery and correlate the findings with potential high-risk locations for in-stent restenosis. We found that high artery wall stresses develop during the coronary intervention in severely stenosed areas and at the stent boundaries. Herewith, we lay the groundwork for further studies towards preventing in-stent restenosis after coronary angioplasty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13276v2</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Janina C. Datz, Ivo Steinbrecher, Christoph Meier, Nora Hagmeyer, Leif-Christopher Engel, Alexander Popp, Martin R. Pfaller, Heribert Schunkert, Wolfgang A. Wall</dc:creator>
    </item>
    <item>
      <title>FLAG: Financial Long Document Classification via AMR-based GNN</title>
      <link>https://arxiv.org/abs/2410.02024</link>
      <description>arXiv:2410.02024v2 Announce Type: replace 
Abstract: The advent of large language models (LLMs) has initiated much research into their various financial applications. However, in applying LLMs on long documents, semantic relations are not explicitly incorporated, and a full or arbitrarily sparse attention operation is employed. In recent years, progress has been made in Abstract Meaning Representation (AMR), which is a graph-based representation of text to preserve its semantic relations. Since AMR can represent semantic relationships at a deeper level, it can be beneficially utilized by graph neural networks (GNNs) for constructing effective document-level graph representations built upon LLM embeddings to predict target metrics in the financial domain. We propose FLAG: Financial Long document classification via AMR-based GNN, an AMR graph based framework to generate document-level embeddings for long financial document classification. We construct document-level graphs from sentence-level AMR graphs, endow them with specialized LLM word embeddings in the financial domain, apply a deep learning mechanism that utilizes a GNN, and examine the efficacy of our AMR-based approach in predicting labeled target data from long financial documents. Extensive experiments are conducted on a dataset of quarterly earnings calls transcripts of companies in various sectors of the economy, as well as on a corpus of more recent earnings calls of companies in the S&amp;P 1500 Composite Index. We find that our AMR-based approach outperforms fine-tuning LLMs directly on text in predicting stock price movement trends at different time horizons in both datasets. Our work also outperforms previous work utilizing document graphs and GNNs for text classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02024v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bolun "Namir" Xia, Mohammed J. Zaki, Aparna Gupta</dc:creator>
    </item>
    <item>
      <title>Latent diffusion models for parameterization and data assimilation of facies-based geomodels</title>
      <link>https://arxiv.org/abs/2406.14815</link>
      <description>arXiv:2406.14815v4 Announce Type: replace-cross 
Abstract: Geological parameterization entails the representation of a geomodel using a small set of latent variables and a mapping from these variables to grid-block properties such as porosity and permeability. Parameterization is useful for data assimilation (history matching), as it maintains geological realism while reducing the number of variables to be determined. Diffusion models are a new class of generative deep-learning procedures that have been shown to outperform previous methods, such as generative adversarial networks, for image generation tasks. Diffusion models are trained to "denoise", which enables them to generate new geological realizations from input fields characterized by random noise. Latent diffusion models, which are the specific variant considered in this study, provide dimension reduction through use of a low-dimensional latent variable. The model developed in this work includes a variational autoencoder for dimension reduction and a U-net for the denoising process. Our application involves conditional 2D three-facies (channel-levee-mud) systems. The latent diffusion model is shown to provide realizations that are visually consistent with samples from geomodeling software. Quantitative metrics involving spatial and flow-response statistics are evaluated, and general agreement between the diffusion-generated models and reference realizations is observed. Stability tests are performed to assess the smoothness of the parameterization method. The latent diffusion model is then used for ensemble-based data assimilation. Two synthetic "true" models are considered. Significant uncertainty reduction, posterior P$_{10}$-P$_{90}$ forecasts that generally bracket observed data, and consistent posterior geomodels, are achieved in both cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14815v4</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guido Di Federico, Louis J. Durlofsky</dc:creator>
    </item>
  </channel>
</rss>
