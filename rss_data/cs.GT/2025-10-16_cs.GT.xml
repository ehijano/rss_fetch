<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 01:48:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Finding a Nash equilibrium of a random win-lose game in expected polynomial time</title>
      <link>https://arxiv.org/abs/2510.12846</link>
      <description>arXiv:2510.12846v1 Announce Type: new 
Abstract: A long-standing open problem in algorithmic game theory asks whether or not there is a polynomial time algorithm to compute a Nash equilibrium in a random bimatrix game. We study random win-lose games, where the entries of the $n\times n$ payoff matrices are independent and identically distributed (i.i.d.) Bernoulli random variables with parameter $p=p(n)$. We prove that, for nearly all values of the parameter $p=p(n)$, there is an expected polynomial-time algorithm to find a Nash equilibrium in a random win-lose game. More precisely, if $p\sim cn^{-a}$ for some parameters $a,c\ge 0$, then there is an expected polynomial-time algorithm whenever $a\not\in \{1/2, 1\}$. In addition, if $a = 1/2$ there is an efficient algorithm if either $c \le e^{-52} 2^{-8} $ or $c\ge 0.977$. If $a=1$, then there is an expected polynomial-time algorithm if either $c\le 0.3849$ or $c\ge \log^9 n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12846v1</guid>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Collevecchio, Gabor Lugosi, Adrian Vetta, Rui-Ray Zhang</dc:creator>
    </item>
    <item>
      <title>Equilibria in routing games with connected autonomous vehicles will not be strong, as exclusive clubs may form</title>
      <link>https://arxiv.org/abs/2510.12862</link>
      <description>arXiv:2510.12862v1 Announce Type: new 
Abstract: User Equilibrium is the standard representation of the so-called routing game in which drivers adjust their route choices to arrive at their destinations as fast as possible. Asking whether this Equilibrium is strong or not was meaningless for human drivers who did not form coalitions due to technical and behavioral constraints. This is no longer the case for connected autonomous vehicles (CAVs), which will be able to communicate and collaborate to jointly form routing coalitions.
  We demonstrate this for the first time on a carefully designed toy-network example, where a `club` of three autonomous vehicles jointly decides to deviate from the user equilibrium and benefit (arrive faster). The formation of such a club has negative consequences for other users, who are not invited to join it and now travel longer, and for the system, making it suboptimal and disequilibrated, which triggers adaptation dynamics.
  This discovery has profound implications for the future of our cities. We demonstrate that, if not prevented, CAV operators may intentionally disequilibrate traffic systems from their classic Nash equilibria, benefiting their own users and imposing costs on others. These findings suggest the possible emergence of an exclusive CAV elite, from which human-driven vehicles and non-coalition members may be excluded, potentially leading to systematically longer travel times for those outside the coalition, which would be harmful for the equity of public road networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12862v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafa{\l} Kucharski, Anastasia Psarou, Natello Descormier</dc:creator>
    </item>
    <item>
      <title>Efficiency of Constant Log Utility Market Makers</title>
      <link>https://arxiv.org/abs/2510.12952</link>
      <description>arXiv:2510.12952v1 Announce Type: new 
Abstract: Automated Market Makers (AMMs) are used to provide liquidity for combinatorial prediction markets that would otherwise be too thinly traded. They offer both buy and sell prices for any of the doubly exponential many possible securities that the market can offer. The problem of setting those prices is known to be #P-hard for the original and most well-known AMM, the logarithmic market scoring rule (LMSR) market maker [Chen et al., 2008]. We focus on another natural AMM, the Constant Log Utility Market Maker (CLUM). Unlike LMSR, whose worst-case loss bound grows with the number of outcomes, CLUM has constant worst-case loss, allowing the market to add outcomes on the fly and even operate over countably infinite many outcomes, among other features. Simpler versions of CLUM underpin several Decentralized Finance (DeFi) mechanisms including the Uniswap protocol that handles billions of dollars of cryptocurrency trades daily. We first establish the computational complexity of the problem: we prove that pricing securities is #P-hard for CLUM, via a reduction from the model counting 2-SAT problem. In order to make CLUM more practically viable, we propose an approximation algorithm for pricing securities that works with high probability. This algorithm assumes access to an oracle capable of determining the maximum shares purchased of any one outcome and the total number of outcomes that has that maximum amount purchased. We then show that this oracle can be implemented in polynomial time when restricted to interval securities, which are used in designing financial options.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12952v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maneesha Papireddygari, Xintong Wang, Bo Waggoner, David M. Pennock</dc:creator>
    </item>
    <item>
      <title>Repeated Sales with Heterogeneous Buyer Sophistication</title>
      <link>https://arxiv.org/abs/2510.13088</link>
      <description>arXiv:2510.13088v1 Announce Type: new 
Abstract: This paper considers behavior-based price discrimination in the repeated sale of a non-durable good to a single long-lived buyer, by a seller without commitment power. We assume that there is a mixed population of forward-looking ``sophisticated'' buyers and myopic ``naive'' buyers. We investigate the impact of these dynamics on the seller's ability to learn about the buyer and exploit this learning for revenue. We obtain conclusions that differ dramatically with the time horizon of the interactions. To understand short time horizons, we analyze a two-period model, and find that the strategic demand reduction observed with fully sophisticated buyers is robust to the introduction of naive types. In fact, despite the inability of naive buyers to game the pricing algorithm, their introduction can further harm the seller's revenue, due to more intense demand reduction overall. For long horizons, we consider an infinite-horizon model with time discounting. We find that the extreme demand reduction predicted by previous work does not survive the introduction of naive buyers. Instead, we observe equilibria where the seller learns meaningfully despite the sophisticated buyers' demand reduction. We prove that for a natural family of such equilibria, the seller's revenue is not just high, but approximates the revenue attainable with commitment power, even when the fraction of naive types is vanishingly small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13088v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rishi Patel, Emmanouil Pountourakis, Samuel Taggart</dc:creator>
    </item>
    <item>
      <title>A Ratio-Based Shapley Value for Collaborative Machine Learning - Extended Version</title>
      <link>https://arxiv.org/abs/2510.13261</link>
      <description>arXiv:2510.13261v1 Announce Type: new 
Abstract: Collaborative machine learning enables multiple data owners to jointly train models for improved predictive performance. However, ensuring incentive compatibility and fair contribution-based rewards remains a critical challenge. Prior work by Sim and colleagues (Rachel Hwee Ling Sim et al: Collaborative machine learning with incentive-aware model rewards. In: International conference on machine learning. PMLR. 2020, pp. 8927-8963) addressed this by allocating model rewards, which are non-monetary and freely replicable, based on the Shapley value of each party's data contribution, measured via information gain. In this paper, we introduce a ratio-based Shapley value that replaces the standard additive formulation with a relative contribution measure. While our overall reward framework, including the incentive definitions and model-reward setting, remains aligned with that of Sim and colleagues, the underlying value function is fundamentally different. Our alternative valuation induces a different distribution of model rewards and offers a new lens through which to analyze incentive properties. We formally define the ratio-based value and prove that it satisfies the same set of incentive conditions as the additive formulation, including adapted versions of fairness, individual rationality, and stability. Like the original approach, our method faces the same fundamental trade-offs between these incentives. Our contribution is a mathematically grounded alternative to the additive Shapley framework, potentially better suited to contexts where proportionality among contributors is more meaningful than additive differences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13261v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bj\"orn Filter, Ralf M\"oller, \"Ozg\"ur L\"utf\"u \"Oz\c{c}ep</dc:creator>
    </item>
    <item>
      <title>Nash Flows Over Time with Tolls</title>
      <link>https://arxiv.org/abs/2510.13518</link>
      <description>arXiv:2510.13518v1 Announce Type: new 
Abstract: We study a dynamic routing game motivated by traffic flows. The base model for an edge is the Vickrey bottleneck model. That is, edges are equipped with a free flow transit time and a capacity. When the inflow into an edge exceeds its capacity, a queue forms and the following particles experience a waiting time. In this paper, we enhance the model by introducing tolls, i.e., a cost each flow particle must pay for traversing an edge. In this setting we consider non-atomic equilibria, which means flows over time in which every particle is on a cheapest path, when summing up toll and travel time. We first show that unlike in the non-tolled version of this model, dynamic equilibria are not unique in terms of costs and do not necessarily reach a steady state. As a main result, we provide a procedure to compute steady states in the model with tolls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13518v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaul Rosner, Marc Schr\"oder, Laura Vargas Koch</dc:creator>
    </item>
    <item>
      <title>Online Fair Division With Subsidy: When Do Envy-Free Allocations Exist, and at What Cost?</title>
      <link>https://arxiv.org/abs/2510.13633</link>
      <description>arXiv:2510.13633v1 Announce Type: new 
Abstract: We study the problem of fairly allocating $m$ indivisible items arriving online, among $n$ (offline) agents. Although envy-freeness has emerged as the archetypal fairness notion, envy-free (EF) allocations need not exist with indivisible items. To bypass this, a prominent line of research demonstrates that there exist allocations that can be made envy-free by allowing a subsidy. Extensive work in the offline setting has focused on finding such envy-freeable allocations with bounded subsidy. We extend this literature to an online setting where items arrive one at a time and must be immediately and irrevocably allocated. Our contributions are two-fold:
  1. Maintaining EF Online: We show that envy-freeability cannot always be preserved online when the valuations are submodular or supermodular, even with binary marginals. In contrast, we design online algorithms that maintain envy-freeability at every step for the class of additive valuations, and for its superclasses including $k$-demand and SPLC valuations.
  2. Ensuring Low Subsidy: We investigate the quantity of subsidy required to guarantee envy-freeness online. Surprisingly, even for additive valuations, the minimum subsidy may be as large as $\Omega(mn)$, in contrast to the offline setting, where the bound is $O(n)$. On the positive side, we identify valuation classes where the minimum subsidy is small (i.e., does not depend on $m$), including $k$-valued, rank-one, restricted additive, and identical valuations, and we obtain (mostly) tight subsidy bounds for these classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13633v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pooja Kulkarni, Ruta Mehta, Vishnu V. Narayan, Tomasz Ponitka</dc:creator>
    </item>
    <item>
      <title>Achieving Logarithmic Regret in KL-Regularized Zero-Sum Markov Games</title>
      <link>https://arxiv.org/abs/2510.13060</link>
      <description>arXiv:2510.13060v1 Announce Type: cross 
Abstract: Reverse Kullback-Leibler (KL) divergence-based regularization with respect to a fixed reference policy is widely used in modern reinforcement learning to preserve the desired traits of the reference policy and sometimes to promote exploration (using uniform reference policy, known as entropy regularization). Beyond serving as a mere anchor, the reference policy can also be interpreted as encoding prior knowledge about good actions in the environment. In the context of alignment, recent game-theoretic approaches have leveraged KL regularization with pretrained language models as reference policies, achieving notable empirical success in self-play methods. Despite these advances, the theoretical benefits of KL regularization in game-theoretic settings remain poorly understood. In this work, we develop and analyze algorithms that provably achieve improved sample efficiency under KL regularization. We study both two-player zero-sum Matrix games and Markov games: for Matrix games, we propose OMG, an algorithm based on best response sampling with optimistic bonuses, and extend this idea to Markov games through the algorithm SOMG, which also uses best response sampling and a novel concept of superoptimistic bonuses. Both algorithms achieve a logarithmic regret in $T$ that scales inversely with the KL regularization strength $\beta$ in addition to the standard $\widetilde{\mathcal{O}}(\sqrt{T})$ regret independent of $\beta$ which is attained in both regularized and unregularized settings</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13060v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anupam Nayak, Tong Yang, Osman Yagan, Gauri Joshi, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Make an Offer They Can't Refuse: Grounding Bayesian Persuasion in Real-World Dialogues without Pre-Commitment</title>
      <link>https://arxiv.org/abs/2510.13387</link>
      <description>arXiv:2510.13387v2 Announce Type: cross 
Abstract: Persuasion, a fundamental social capability for humans, remains a challenge for AI systems such as large language models (LLMs). Current studies often overlook the strategic use of information asymmetry in message design or rely on strong assumptions regarding pre-commitment. In this work, we explore the application of Bayesian Persuasion (BP) in natural language within single-turn dialogue settings, to enhance the strategic persuasion capabilities of LLMs. Our framework incorporates a commitment-communication mechanism, where the persuader explicitly outlines an information schema by narrating their potential types (e.g., honest or dishonest), thereby guiding the persuadee in performing the intended Bayesian belief update. We evaluate two variants of our approach: Semi-Formal-Natural-Language (SFNL) BP and Fully-Natural-Language (FNL) BP, benchmarking them against both naive and strong non-BP (NBP) baselines within a comprehensive evaluation framework. This framework covers a diverse set of persuadees -- including LLM instances with varying prompts and fine-tuning and human participants -- across tasks ranging from specially designed persuasion scenarios to general everyday situations. Experimental results on LLM-based agents reveal three main findings: (1) LLMs guided by BP strategies consistently achieve higher persuasion success rates than NBP baselines; (2) SFNL exhibits greater credibility and logical coherence, while FNL shows stronger emotional resonance and robustness in naturalistic conversations; (3) with supervised fine-tuning, smaller models can attain BP performance comparable to that of larger models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13387v2</guid>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Buwei He, Yang Liu, Zhaowei Zhang, Zixia Jia, Huijia Wu, Zhaofeng He, Zilong Zheng, Yipeng Kang</dc:creator>
    </item>
    <item>
      <title>Going with the Flow: Approximating Banzhaf Values via Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2510.13391</link>
      <description>arXiv:2510.13391v1 Announce Type: cross 
Abstract: Computing the Banzhaf value in network flow games is fundamental for quantifying agent influence in multi-agent systems, with applications ranging from cybersecurity to infrastructure planning. However, exact computation is intractable for systems with more than $\sim20$ agents due to exponential complexity $\mathcal{O}(2^m)$. While Monte Carlo sampling methods provide statistical estimates, they suffer from high sample complexity and cannot transfer knowledge across different network configurations, making them impractical for large-scale or dynamic systems. We present a novel learning-based approach using Graph Neural Networks (GNNs) to approximate Banzhaf values in cardinal network flow games. By framing the problem as a graph-level prediction task, our method learns generalisable patterns of agent influence directly from network topology and control structure. We conduct a comprehensive empirical study comparing three state-of-the-art GNN architectures-Graph Attention Networks (GAT), Graph Isomorphism Networks with Edge features (GINE), and EdgeConv-on a large-scale synthetic dataset of 200,000 graphs per configuration, varying in size (20-100 nodes), agent count (5-20), and edge probability (0.5-1.0). Our results demonstrate that trained GNN models achieve high-fidelity Banzhaf value approximation with order-of-magnitude speedups compared to exact and sampling-based methods. Most significantly, we show strong zero-shot generalisation: models trained on graphs of a specific size and topology accurately predict Banzhaf values for entirely new networks with different structural properties, without requiring retraining. This work establishes GNNs as a practical tool for scalable cooperative game-theoretic analysis of complex networked systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13391v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Kempinski, Tal Kachman</dc:creator>
    </item>
    <item>
      <title>EFX Allocations and Orientations on Bipartite Multi-graphs: A Complete Picture</title>
      <link>https://arxiv.org/abs/2410.17002</link>
      <description>arXiv:2410.17002v3 Announce Type: replace 
Abstract: We consider the fundamental problem of fairly allocating a set of indivisible items among agents having valuations that are represented by a multi-graph -- here, agents appear as vertices and items as edges between them and each vertex (agent) only values the set of its incident edges (items). The goal is to find a fair, i.e., envy-free up to any item (EFX) allocation. This model has recently been introduced by Christodoulou et al. (EC-23) where they show that EFX allocations always exist on simple graphs for monotone valuations, i.e., where any two agents can share at most one edge (item). A natural question arises as to what happens when we go beyond simple graphs and study various classes of multi-graphs?
  We answer the above question affirmatively for the valuation class of bipartite multi-graphs and multi-cycles. The main contribution of this work is to establish the existence of EFX allocations on bipartite multi-graphs for monotone valuations and on multi-cycles for MMS-feasible valuations. We also present pseudo-polynomial time algorithms to compute EFX allocations for the above settings. Furthermore, we show that for bipartite multi-graphs with cancelable valuations, EFX allocations can be computed in polynomial time. We thus widen the spectrum where EFX allocations are guaranteed to exist.
  Next, we study EFX orientations (allocations where every item is assigned to one of its two endpoint agents) and provide a complete characterization of their existence on bipartite multi-graphs in terms of two key parameters: (i) the number of edges shared between any two agents and (ii) the diameter of the graph. Finally, we prove that it is NP-complete to determine whether a given fair division instance on a bipartite multi-graph admits an EFX orientation, even with a constant number of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17002v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahyar Afshinmehr, Alireza Danaei, Mehrafarin Kazemi, Kurt Mehlhorn, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>Metric Distortion in Peer Selection</title>
      <link>https://arxiv.org/abs/2502.21084</link>
      <description>arXiv:2502.21084v2 Announce Type: replace 
Abstract: In the metric distortion problem, a set of voters and candidates lie in a common metric space, and a committee of $k$ candidates must be elected. The objective is to minimize a social cost, defined as a function of the distances between voters and their chosen representatives, while the voting rule only has access to ordinal preferences. The distortion of a rule is the worst-case ratio between the social cost of its outcome and that of the optimal committee, taken over all consistent preferences and metrics.
  We initiate the study of metric distortion in peer selection, where voters and candidates coincide. We consider four objectives, obtained by combining two aggregation rules with two types of social cost. Under additive aggregation, an individual's cost is the sum of their distances to all committee members; under $q$-cost, it is their distance to the $q$th closest member. The overall social cost is either utilitarian, given by the sum of all individual costs, or egalitarian, given by the maximum individual cost. Surprisingly, we find that even on the line metric, peer selection retains much of the hardness of the general case: Lower bounds remain strictly larger than one for all objectives, and cases where bounded distortion is impossible in general remain so here as well. On a positive note, cases with bounded distortion in the general setting achieve better constants in peer selection. For utilitarian cost, selecting the $k$ middle agents achieves a distortion between $1$ and $2$ under additive aggregation. Under $q$-cost, we show positive results for $q=k=2$, but impossibility results largely carry over. For egalitarian cost, selecting the extremes yields an optimal distortion of $2$ under additive aggregation and for $q$-cost with $q&gt;k/3$. Thus, while peer selection on the line metric allows better constants, fundamental hardness barriers persist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21084v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Javier Cembrano, Golnoosh Shahkarami</dc:creator>
    </item>
    <item>
      <title>Constant-Memory Strategies in Stochastic Games: Best Responses and Equilibria</title>
      <link>https://arxiv.org/abs/2505.07008</link>
      <description>arXiv:2505.07008v2 Announce Type: replace 
Abstract: Stochastic games have become a prevalent framework for studying long-term multi-agent interactions, especially in the context of multi-agent reinforcement learning. In this work, we comprehensively investigate the concept of constant-memory strategies in stochastic games. We first establish some results on best responses and Nash equilibria for behavioral constant-memory strategies, followed by a discussion on the computational hardness of best responding to mixed constant-memory strategies. Those theoretic insights are later verified on several sequential decision-making testbeds, including the $\textit{Iterated Prisoner's Dilemma}$, the $\textit{Iterated Traveler's Dilemma}$, and the $\textit{Pursuit}$ domain. This work aims to enhance the understanding of theoretical issues in single-agent planning under multi-agent systems, and uncover the connection between decision models in single-agent and multi-agent contexts. The code is available at $\texttt{https://github.com/Fernadoo/Const-Mem.}$</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07008v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengming Zhu, Fangzhen Lin</dc:creator>
    </item>
    <item>
      <title>Fair and Efficient Allocation of Indivisible Mixed Manna</title>
      <link>https://arxiv.org/abs/2507.03946</link>
      <description>arXiv:2507.03946v2 Announce Type: replace 
Abstract: We study fair division of indivisible mixed manna (items whose values may be positive, negative, or zero) among agents with additive valuations. Here, we establish that fairness -- in terms of a relaxation of envy-freeness -- and Pareto efficiency can always be achieved together. Specifically, our fairness guarantees are in terms of envy-freeness up to $k$ reallocations (EFR-$k$): An allocation $A$ of the indivisible items is said to be EFR-$k$ if there exists a subset $R$ of at most $k$ items such that, for each agent $i$, we can reassign items from within $R$ (in $A$) and obtain an allocation, $A^i$, which is envy-free for $i$. We establish that, when allocating mixed manna among $n$ agents with additive valuations, an EFR-$(n-1)$ and Pareto optimal (PO) allocation $A$ always exists. Further, the individual envy-free allocations $A^i$, induced by reassignments, are also PO. In addition, we prove that such fair and efficient allocations are efficiently computable when the number of agents, $n$, is fixed.
  We also obtain positive results focusing on EFR by itself (and without the PO desideratum). Specifically, we show that an EFR-$(n-1)$ allocation of mixed manna can be computed in polynomial time. In addition, we prove that when all the items are goods, an EFR-${\lfloor n/2 \rfloor}$ allocation exists and can be computed efficiently. Here, the $(n-1)$ bound is tight for chores and $\lfloor n/2 \rfloor$ is tight for goods.
  Our results advance the understanding of fair and efficient allocation of indivisible mixed manna and rely on a novel application of the Knaster-Kuratowski-Mazurkiewicz (KKM) Theorem in discrete fair division. We utilize weighted welfare maximization, with perturbed valuations, to achieve Pareto efficiency, and overall, our techniques are notably different from existing market-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03946v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddharth Barman, Vishwa Prakash HV, Aditi Sethia, Mashbat Suzuki</dc:creator>
    </item>
    <item>
      <title>Stability in Online Assignment Games</title>
      <link>https://arxiv.org/abs/2510.09814</link>
      <description>arXiv:2510.09814v2 Announce Type: replace 
Abstract: The assignment game models a housing market where buyers and sellers are matched, and transaction prices are set so that the resulting allocation is stable. Shapley and Shubik showed that every stable allocation is necessarily built on a maximum social welfare matching. In practice, however, stable allocations are rarely attainable, as matchings are often sub-optimal, particularly in online settings where eagents arrive sequentially to the market. In this paper, we introduce and compare two complementary measures of instability for allocations with sub-optimal matchings, establish their connections to the optimality ratio of the underlying matching, and use this framework to study the stability performances of randomized algorithms in online assignment games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09814v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emile Martinez, Felipe Garrido-Lucero, Umberto Grandi</dc:creator>
    </item>
    <item>
      <title>Do LLM Agents Have Regret? A Case Study in Online Learning and Games</title>
      <link>https://arxiv.org/abs/2403.16843</link>
      <description>arXiv:2403.16843v5 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have been increasingly employed for (interactive) decision-making, via the development of LLM-based autonomous agents. Despite their emerging successes, the performance of LLM agents in decision-making has not been fully investigated through quantitative metrics, especially in the multi-agent setting when they interact with each other, a typical scenario in real-world LLM-agent applications. To better understand the limits of LLM agents in these interactive environments, we propose to study their interactions in benchmark decision-making settings in online learning and game theory, through the performance metric of \emph{regret}. We first empirically study the {no-regret} behaviors of LLMs in canonical (non-stationary) online learning problems, as well as the emergence of equilibria when LLM agents interact through playing repeated games. We then provide some theoretical insights into the no-regret behaviors of LLM agents, under certain assumptions on the supervised pre-training and the rationality model of human decision-makers who generate the data. Notably, we also identify (simple) cases where advanced LLMs such as GPT-4 fail to be no-regret. To promote the no-regret behaviors, we propose a novel \emph{unsupervised} training loss of \emph{regret-loss}, which, in contrast to the supervised pre-training loss, does not require the labels of (optimal) actions. We then establish the statistical guarantee of generalization bound for regret-loss minimization, followed by the optimization guarantee that minimizing such a loss may automatically lead to known no-regret learning algorithms. Our further experiments demonstrate the effectiveness of our regret-loss, especially in addressing the above ``regrettable'' cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16843v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chanwoo Park, Xiangyu Liu, Asuman Ozdaglar, Kaiqing Zhang</dc:creator>
    </item>
  </channel>
</rss>
