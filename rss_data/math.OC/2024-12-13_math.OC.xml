<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Dec 2024 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On improving generalization in a class of learning problems with the method of small parameters for weakly-controlled optimal gradient systems</title>
      <link>https://arxiv.org/abs/2412.08772</link>
      <description>arXiv:2412.08772v1 Announce Type: new 
Abstract: In this paper, we provide a mathematical framework for improving generalization in a class of learning problems which is related to point estimations for modeling of high-dimensional nonlinear functions. In particular, we consider a variational problem for a weakly-controlled gradient system, whose control input enters into the system dynamics as a coefficient to a nonlinear term which is scaled by a small parameter. Here, the optimization problem consists of a cost functional, which is associated with how to gauge the quality of the estimated model parameters at a certain fixed final time w.r.t. the model validating dataset, while the weakly-controlled gradient system, whose the time-evolution is guided by the model training dataset and its perturbed version with small random noise. Using the perturbation theory, we provide results that will allow us to solve a sequence of optimization problems, i.e., a set of decomposed optimization problems, so as to aggregate the corresponding approximate optimal solutions that are reasonably sufficient for improving generalization in such a class of learning problems. Moreover, we also provide an estimate for the rate of convergence for such approximate optimal solutions. Finally, we present some numerical results for a typical case of nonlinear regression problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08772v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K. Befekadu</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Probabilistic Prediction for Stochastic Dynamical Systems</title>
      <link>https://arxiv.org/abs/2412.08858</link>
      <description>arXiv:2412.08858v1 Announce Type: new 
Abstract: Probabilistic prediction of stochastic dynamical systems (SDSs) aims to accurately predict the conditional probability distributions of future states. However, accurate probabilistic predictions tightly hinge on accurate distributional information from a nominal model, which is hardly available in practice. To address this issue, we propose a novel functional-maximin-based distributionally robust probabilistic prediction (DRPP) framework. In this framework, one can design probabilistic predictors that have worst-case performance guarantees over a pre-defined ambiguity set of SDSs. Nevertheless, DRPP requires optimizing over the function space of probability distributions, which is generally intractable. We develop a methodology that equivalently transforms the original maximin in function spaces into convex-nonconcave minimax in Euclidean spaces. Although it remains intractable to seek a global optimal solution, two suboptimal solutions are derived. By relaxing the inner constraints, we obtain a suboptimal predictor called Noise-DRPP. Relaxing the outer constraints yields another suboptimal predictor, Eig-DRPP. More importantly, we establish an explicit upper bound on the optimality gap between Eig-DRPP and the global optimal predictor. Utilizing the theoretical results obtained from solving the two suboptimal predictors, we synthesize practical rules to judge whether the pre-defined ambiguity set is too large or small. Finally, we conduct elaborate numerical simulations to compare the performance of different predictors under different SDSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08858v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tao Xu, Jianping He</dc:creator>
    </item>
    <item>
      <title>Three-Level Multi-Leader-Follower Incentive Stackelberg Differential Game with $H_\infty$ Constraint</title>
      <link>https://arxiv.org/abs/2412.09004</link>
      <description>arXiv:2412.09004v1 Announce Type: new 
Abstract: This paper is concerned with a three-level multi-leader-follower incentive Stackelberg game with $H_\infty$ constraint. Based on $H_2/H_\infty$ control theory, we firstly obtain the worst-case disturbance and the team-optimal strategy by dealing with a nonzero-sum stochastic differential game. The main objective is to establish an incentive Stackelberg strategy set of the three-level hierarchy in which the whole system achieves the top leader's team-optimal solution and attenuates the external disturbance under $H_\infty$ constraint. On the other hand, followers on the bottom two levels in turn attain their state feedback Nash equilibrium, ensuring incentive Stackelberg strategies while considering the worst-case disturbance. By convex analysis theory, maximum principle and decoupling technique, the three-level incentive Stackelberg strategy set is obtained. Finally, a numerical example is given to illustrate the existence of the proposed strategy set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09004v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Na Xiang, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>A Symplectic Discretization Based Proximal Point Algorithm for Convex Minimization</title>
      <link>https://arxiv.org/abs/2412.09077</link>
      <description>arXiv:2412.09077v1 Announce Type: new 
Abstract: The proximal point algorithm plays a central role in non-smooth convex programming. The Augmented Lagrangian Method, one of the most famous optimization algorithms, has been found to be closely related to the proximal point algorithm. Due to its importance, accelerated variants of the proximal point algorithm have received considerable attention. In this paper, we first study an Ordinary Differential Equation (ODE) system, which provides valuable insights into proving the convergence rate of the desired algorithm. Using the Lyapunov function technique, we establish the convergence rate of the ODE system. Next, we apply the Symplectic Euler Method to discretize the ODE system to derive a new proximal point algorithm, called the Symplectic Proximal Point Algorithm (SPPA). By utilizing the proof techniques developed for the ODE system, we demonstrate the convergence rate of the SPPA. Additionally, it is shown that existing accelerated proximal point algorithm can be considered a special case of the SPPA in a specific manner. Furthermore, under several additional assumptions, we prove that the SPPA exhibits a finer convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09077v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-xiang Yuan, Yi Zhang</dc:creator>
    </item>
    <item>
      <title>How Stringent is the Linear Independence Kink Qualification in Abs-Smooth Optimization?</title>
      <link>https://arxiv.org/abs/2412.09175</link>
      <description>arXiv:2412.09175v1 Announce Type: new 
Abstract: Abs-smooth functions are given by compositions of smooth functions and the evaluation of the absolute value. The linear independence kink qualification (LIKQ) is a fundamental assumption in optimization problems governed by these abs-smooth functions, generalizing the well-known LICQ from smooth optimization. In particular, provided that LIKQ holds it is possible to derive optimality conditions for abs-smooth optimization problems that can be checked in polynomial time. Utilizing tools from differential topology, namely a version of the jet-transversality theorem, it is shown that assuming LIKQ for all feasible points of an abs-smooth optimization problem is a generic assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09175v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Baumg\"artner, Franz Bethke, Ganna Shyshkanova, Andrea Walther</dc:creator>
    </item>
    <item>
      <title>Liquidity Pools as Mean Field Games: A New Framework</title>
      <link>https://arxiv.org/abs/2412.09180</link>
      <description>arXiv:2412.09180v1 Announce Type: new 
Abstract: In this work, we present an innovative application of the probabilistic weak formulation of mean field games (MFG) for modeling liquidity pools in a constant product automated market maker (AMM) protocol in the context of decentralized finance. Our work extends one of the most conventional applications of MFG, which is the price impact model in an order book, by incorporating an AMM instead of a traditional order book. Through our approach, we achieve results that support the existence of solutions to the Mean Field Game and, additionally, the existence of approximate Nash equilibria for the proposed problem. These results not only offer a new perspective for representing liquidity pools in AMMs but also open promising opportunities for future research in this emerging field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09180v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan I. Sequeira, Agust\'in Mu\~noz Gonz\'alez, Rafael Orive Illera</dc:creator>
    </item>
    <item>
      <title>Dimensionality Reduction Techniques for Global Bayesian Optimisation</title>
      <link>https://arxiv.org/abs/2412.09183</link>
      <description>arXiv:2412.09183v1 Announce Type: new 
Abstract: Bayesian Optimisation (BO) is a state-of-the-art global optimisation technique for black-box problems where derivative information is unavailable, and sample efficiency is crucial. However, improving the general scalability of BO has proved challenging. Here, we explore Latent Space Bayesian Optimisation (LSBO), that applies dimensionality reduction to perform BO in a reduced-dimensional subspace. While early LSBO methods used (linear) random projections (Wang et al., 2013), we employ Variational Autoencoders (VAEs) to manage more complex data structures and general DR tasks. Building on Grosnit et. al. (2021), we analyse the VAE-based LSBO framework, focusing on VAE retraining and deep metric loss. We suggest a few key corrections in their implementation, originally designed for tasks such as molecule generation, and reformulate the algorithm for broader optimisation purposes. Our numerical results show that structured latent manifolds improve BO performance. Additionally, we examine the use of the Mat\'{e}rn-$\frac{5}{2}$ kernel for Gaussian Processes in this LSBO context. We also integrate Sequential Domain Reduction (SDR), a standard global optimization efficiency strategy, into BO. SDR is included in a GPU-based environment using \textit{BoTorch}, both in the original and VAE-generated latent spaces, marking the first application of SDR within LSBO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09183v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luo Long, Coralia Cartis, Paz Fink Shustin</dc:creator>
    </item>
    <item>
      <title>When to use simulated annealing for solving CVRP? A case study of fuel deliveries in Poland</title>
      <link>https://arxiv.org/abs/2412.09293</link>
      <description>arXiv:2412.09293v1 Announce Type: new 
Abstract: The paper addresses Capacitated Vehicle Routing Problem (CVRP) in the context of fuel delivery to gas stations. The CVRP aims to minimize total travel distance for a fleet with limited capacity. Fuel delivery, however, introduces unique complexities within the CVRP framework. We propose a novel approach that integrates the Simulated Annealing (SA) algorithm with a customized CVRP model specifically designed for gas station networks. This model incorporates real-world constraints like vehicle capacity, fuel demands at each station, and road network distances. The paper outlines the design of SA-based CVRP model for fuel delivery. We detail the objective function (minimizing distance) and the SA's exploration mechanism for generating candidate solutions. To assess its effectiveness, the proposed approach undergoes computational tests in Poland's gas station network serviced by the Samat transportation company. We compare the performance of our SA-based CVRP model with the conventional Mixed Integer Programming model for CVRP powered by Gurobi. The results aim to demonstrate the efficacy of the proposed SA-based heuristic in finding efficient routes for fuel deliveries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09293v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vitalii Naumov</dc:creator>
    </item>
    <item>
      <title>Digital twin of wood working enterprise</title>
      <link>https://arxiv.org/abs/2412.09438</link>
      <description>arXiv:2412.09438v1 Announce Type: new 
Abstract: A review of scientific papers has shown that digital twins are very common for modeling the states of physical objects. It is relevant to consider the creation of a digital twin of an enterprise to obtain various assessments in management, taking into account the human factor. In the research, the impact of the human factor is assessed by the digital twin and staff competencies. The system of goals of staff competencies stands for: cognitive, affective, psychomotor. An enterprise model is created from the description of the set of events taking place on it. Each event is mapped to an element of staff competencies target system. The resulting set of staff competencies is estimated by a universal (integral) indicator. The dynamics of the universal indicator characterizes two modes of operation of the enterprise. The first operating mode is normal. The second mode of operation is based on the implementation of staff competencies. Taking into account the competencies of personnel by Bloom's taxonomy allows you to determine their interconnection: cognitive, affective, psychomotor. It correlation depends on the work performed by the employee and the influence of the external environment. It depends on the efforts of the employee as a learner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09438v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1755-1315/806/1/012022</arxiv:DOI>
      <arxiv:journal_reference>2021 IOP Conf. Ser.: Earth Environ. Sci. 806 012022</arxiv:journal_reference>
      <dc:creator>Sergey Masaev, Andrey Minkin, Evgeniy Troyak, Andrey Khrulkevich</dc:creator>
    </item>
    <item>
      <title>Enhancing Convergence of Decentralized Gradient Tracking under the KL Property</title>
      <link>https://arxiv.org/abs/2412.09556</link>
      <description>arXiv:2412.09556v1 Announce Type: new 
Abstract: We study decentralized multiagent optimization over networks, modeled as undirected graphs. The optimization problem consists of minimizing a nonconvex smooth function plus a convex extended-value function, which enforces constraints or extra structure on the solution (e.g., sparsity, low-rank). We further assume that the objective function satisfies the Kurdyka-{\L}ojasiewicz (KL) property, with given exponent $\theta\in [0,1)$. The KL property is satisfied by several (nonconvex) functions of practical interest, e.g., arising from machine learning applications; in the centralized setting, it permits to achieve strong convergence guarantees. Here we establish convergence of the same type for the notorious decentralized gradient-tracking-based algorithm SONATA. Specifically, $\textbf{(i)}$ when $\theta\in (0,1/2]$, the sequence generated by SONATA converges to a stationary solution of the problem at R-linear rate;$ \textbf{(ii)} $when $\theta\in (1/2,1)$, sublinear rate is certified; and finally $\textbf{(iii)}$ when $\theta=0$, the iterates will either converge in a finite number of steps or converges at R-linear rate. This matches the convergence behavior of centralized proximal-gradient algorithms except when $\theta=0$. Numerical results validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09556v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaokai Chen, Tianyu Cao, Gesualdo Scutari</dc:creator>
    </item>
    <item>
      <title>Subspace tracking for online system identification</title>
      <link>https://arxiv.org/abs/2412.09052</link>
      <description>arXiv:2412.09052v1 Announce Type: cross 
Abstract: This paper introduces an online approach for identifying time-varying subspaces defined by linear dynamical systems, leveraging optimization on the Grassmannian manifold leading to the Grassmannian Recursive Algorithm for Tracking (GREAT) method. The approach of representing linear systems by non-parametric subspace models has received significant interest in the field of data-driven control recently. We view subspaces as points on the Grassmannian manifold, and therefore, tracking is achieved by performing optimization on the manifold. At each time step, a single measurement from the current subspace corrupted by a bounded error is available. The subspace estimate is updated online using Grassmannian gradient descent on a cost function incorporating a window of the most recent data. Under suitable assumptions on the signal-to-noise ratio of the online data and the subspace's rate of change, we establish theoretical guarantees for the resulting algorithm. More specifically, we prove an exponential convergence rate and provide a consistent uncertainty quantification of the estimates in terms of an upper bound on their distance to the true subspace. The applicability of the proposed algorithm is demonstrated by means of numerical examples, and it is shown to compare favorably with competing parametric system identification methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09052v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'as Sasfi, Alberto Padoan, Ivan Markovsky, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>General Markovian randomized equilibrium existence and construction in zero-sum Dynkin games for diffusions</title>
      <link>https://arxiv.org/abs/2412.09087</link>
      <description>arXiv:2412.09087v1 Announce Type: cross 
Abstract: One of the most classical games for stochastic processes is the zero-sum Dynkin (stopping) game. We present a complete equilibrium solution to a general formulation of this game with an underlying one-dimensional diffusion. A key result is the construction of a characterizable global $\epsilon$-Nash equilibrium in Markovian randomized stopping times for every $\epsilon &gt; 0$. This is achieved by leveraging the well-known equilibrium structure under a restrictive ordering condition on the payoff functions, leading to a novel approach based on an appropriate notion of randomization that allows for solving the general game without any ordering condition. Additionally, we provide conditions for the existence of pure and randomized Nash equilibria (with $\epsilon=0$). Our results enable explicit identification of equilibrium stopping times and their corresponding values in many cases, illustrated by several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09087v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"oren Christensen, Kristoffer Lindensj\"o</dc:creator>
    </item>
    <item>
      <title>Integrated trucks assignment and scheduling problem with mixed service mode docks: A Q-learning based adaptive large neighborhood search algorithm</title>
      <link>https://arxiv.org/abs/2412.09090</link>
      <description>arXiv:2412.09090v1 Announce Type: cross 
Abstract: Mixed service mode docks enhance efficiency by flexibly handling both loading and unloading trucks in warehouses. However, existing research often predetermines the number and location of these docks prior to planning truck assignment and sequencing. This paper proposes a new model integrating dock mode decision, truck assignment, and scheduling, thus enabling adaptive dock mode arrangements. Specifically, we introduce a Q-learning-based adaptive large neighborhood search (Q-ALNS) algorithm to address the integrated problem. The algorithm adjusts dock modes via perturbation operators, while truck assignment and scheduling are solved using destroy and repair local search operators. Q-learning adaptively selects these operators based on their performance history and future gains, employing the epsilon-greedy strategy. Extensive experimental results and statistical analysis indicate that the Q-ALNS benefits from efficient operator combinations and its adaptive mechanism, consistently outperforming benchmark algorithms in terms of optimality gap and Pareto front discovery. In comparison to the predetermined service mode, our adaptive strategy results in lower average tardiness and makespan, highlighting its superior adaptability to varying demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09090v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueyi Li, Mehrdad Mohammadi, Xiaodong Zhang, Yunxing Lan, Willem van Jaarsveld</dc:creator>
    </item>
    <item>
      <title>evS2CP: Real-time Simultaneous Speed and Charging Planner for Connected Electric Vehicles</title>
      <link>https://arxiv.org/abs/2412.09109</link>
      <description>arXiv:2412.09109v1 Announce Type: cross 
Abstract: This paper presents evS2CP, an optimization-based framework for simultaneous speed and charging planning designed for connected electric vehicles (EVs). With EVs emerging as competitive alternatives to internal combustion engine vehicles, overcoming challenges such as limited charging infrastructure is crucial. evS2CP addresses these issues by minimizing the travel time, charging time, and energy consumption, providing practical solutions for both human-operated and autonomous vehicles. This framework leverages V2X communication to integrate essential EV planning data, including route geometry, real-time traffic conditions, and charging station availability, while simulating dynamic driving environments using open-web API services. The speed and charging planning problem was initially formulated as a nonlinear programming model, which was then convexified into a quadratic programming model without charging-stop constraints. Additionally, a mixed-integer programming approach was employed to optimize charging station selection and minimize the frequency of charging events. A mixed-integer quadratic programming implementation exhibited exceptional computational efficiency and scalability, effectively solving trip plans over distances exceeding 700 km in a few seconds. Simulations conducted using open-source and commercial solvers validated the framework's near-global optimality, demonstrating its robustness and feasibility for real-world applications in connected EV ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09109v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minwoo Gwon, Jiwon Kim, Seungjun Yoo, Kwang-Ki K. Kim</dc:creator>
    </item>
    <item>
      <title>The Utility and Complexity of In- and Out-of-Distribution Machine Unlearning</title>
      <link>https://arxiv.org/abs/2412.09119</link>
      <description>arXiv:2412.09119v1 Announce Type: cross 
Abstract: Machine unlearning, the process of selectively removing data from trained models, is increasingly crucial for addressing privacy concerns and knowledge gaps post-deployment. Despite this importance, existing approaches are often heuristic and lack formal guarantees. In this paper, we analyze the fundamental utility, time, and space complexity trade-offs of approximate unlearning, providing rigorous certification analogous to differential privacy. For in-distribution forget data -- data similar to the retain set -- we show that a surprisingly simple and general procedure, empirical risk minimization with output perturbation, achieves tight unlearning-utility-complexity trade-offs, addressing a previous theoretical gap on the separation from unlearning "for free" via differential privacy, which inherently facilitates the removal of such data. However, such techniques fail with out-of-distribution forget data -- data significantly different from the retain set -- where unlearning time complexity can exceed that of retraining, even for a single sample. To address this, we propose a new robust and noisy gradient descent variant that provably amortizes unlearning time complexity without compromising utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09119v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youssef Allouah, Joshua Kazdan, Rachid Guerraoui, Sanmi Koyejo</dc:creator>
    </item>
    <item>
      <title>Many-insurer robust games of reinsurance and investment under model uncertainty in incomplete markets</title>
      <link>https://arxiv.org/abs/2412.09157</link>
      <description>arXiv:2412.09157v1 Announce Type: cross 
Abstract: This paper studies the robust reinsurance and investment games for competitive insurers. Model uncertainty is characterized by a class of equivalent probability measures. Each insurer is concerned with relative performance under the worst-case scenario. Insurers' surplus processes are approximated by drifted Brownian motion with common and idiosyncratic insurance risks. The insurers can purchase proportional reinsurance to divide the insurance risk with the reinsurance premium calculated by the variance principle. We consider an incomplete market driven by the 4/2 stochastic volatility mode. This paper formulates the robust mean-field game for a non-linear system originating from the variance principle and the 4/2 model. For the case of an exponential utility function, we derive closed-form solutions for the $n$-insurer game and the corresponding mean-field game. We show that relative concerns lead to new hedging terms in the investment and reinsurance strategies. Model uncertainty can significantly change the insurers' hedging demands. The hedging demands in the investment-reinsurance strategies exhibit highly non-linear dependence with the insurers' competitive coefficients, risk aversion and ambiguity aversion coefficients. Finally, numerical results demonstrate the herd effect of competition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09157v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guohui Guan, Zongxia Liang, Yi Xia</dc:creator>
    </item>
    <item>
      <title>A semiconcavity approach to stability of entropic plans and exponential convergence of Sinkhorn's algorithm</title>
      <link>https://arxiv.org/abs/2412.09235</link>
      <description>arXiv:2412.09235v1 Announce Type: cross 
Abstract: We study stability of optimizers and convergence of Sinkhorn's algorithm in the framework of entropic optimal transport. We show entropic stability for optimal plans in terms of the Wasserstein distance between their marginals under a semiconcavity assumption on the sum of the cost and one of the two entropic potentials. When employed in the analysis of Sinkhorn's algorithm, this result gives a natural sufficient condition for its exponential convergence, which does not require the ground cost to be bounded. By controlling from above the Hessians of Sinkhorn potentials in examples of interest, we obtain new exponential convergence results. For instance, for the first time we obtain exponential convergence for log-concave marginals and quadratic costs for all values of the regularization parameter. Moreover, the convergence rate has a linear dependence on the regularization: this behavior is sharp and had only been previously obtained for compact distributions arXiv:2407.01202. Other interesting new applications include subspace elastic costs [Cuturi et al. PMLR 202(2023)], weakly log-concave marginals, marginals with light tails, where, under reinforced assumptions, we manage to improve the rates obtained in arXiv:2311.04041, the case of unbounded Lipschitz costs, and compact Riemannian manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09235v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Chiarini, Giovanni Conforti, Giacomo Greco, Luca Tamanini</dc:creator>
    </item>
    <item>
      <title>Free-Energy Machine for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2412.09285</link>
      <description>arXiv:2412.09285v1 Announce Type: cross 
Abstract: Finding optimal solutions to combinatorial optimization problems is pivotal in both scientific and technological domains, within academic research and industrial applications. A considerable amount of effort has been invested in the development of accelerated methods that leverage sophisticated models and harness the power of advanced computational hardware. Despite the advancements, a critical challenge persists, the dual demand for both high efficiency and broad generality in solving problems. In this work, we propose a general method, Free-Energy Machine (FEM), based on the ideas of free-energy minimization in statistical physics, combined with automatic differentiation and gradient-based optimization in machine learning. The algorithm is flexible, solving various combinatorial optimization problems using a unified framework, and is efficient, naturally utilizing massive parallel computational devices such as graph processing units (GPUs) and field-programmable gate arrays (FPGAs). We benchmark our algorithm on various problems including the maximum cut problems, balanced minimum cut problems, and maximum $k$-satisfiability problems, scaled to millions of variables, across both synthetic, real-world, and competition problem instances. The findings indicate that our algorithm not only exhibits exceptional speed but also surpasses the performance of state-of-the-art algorithms tailored for individual problems. This highlights that the interdisciplinary fusion of statistical physics and machine learning opens the door to delivering cutting-edge methodologies that will have broad implications across various scientific and industrial landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09285v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zi-Song Shen, Feng Pan, Yao Wang, Yi-Ding Men, Wen-Biao Xu, Man-Hong Yung, Pan Zhang</dc:creator>
    </item>
    <item>
      <title>Entropy-Regularized Optimal Transport in Information Design</title>
      <link>https://arxiv.org/abs/2412.09316</link>
      <description>arXiv:2412.09316v1 Announce Type: cross 
Abstract: In this paper, we explore a scenario where a sender provides an information policy and a receiver, upon observing a realization of this policy, decides whether to take a particular action, such as making a purchase. The sender's objective is to maximize her utility derived from the receiver's action, and she achieves this by careful selection of the information policy. Building on the work of Kleiner et al., our focus lies specifically on information policies that are associated with power diagram partitions of the underlying domain. To address this problem, we employ entropy-regularized optimal transport, which enables us to develop an efficient algorithm for finding the optimal solution. We present experimental numerical results that highlight the qualitative properties of the optimal configurations, providing valuable insights into their structure. Furthermore, we extend our numerical investigation to derive optimal information policies for monopolists dealing with multiple products, where the sender discloses information about product qualities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09316v1</guid>
      <category>math.NA</category>
      <category>cs.GT</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge Justiniano, Andreas Kleiner, Benny Moldovanu, Martin Rumpf, Philipp Strack</dc:creator>
    </item>
    <item>
      <title>Gradient descent inference in empirical risk minimization</title>
      <link>https://arxiv.org/abs/2412.09498</link>
      <description>arXiv:2412.09498v1 Announce Type: cross 
Abstract: Gradient descent is one of the most widely used iterative algorithms in modern statistical learning. However, its precise algorithmic dynamics in high-dimensional settings remain only partially understood, which has therefore limited its broader potential for statistical inference applications.
  This paper provides a precise, non-asymptotic distributional characterization of gradient descent iterates in a broad class of empirical risk minimization problems, in the so-called mean-field regime where the sample size is proportional to the signal dimension. Our non-asymptotic state evolution theory holds for both general non-convex loss functions and non-Gaussian data, and reveals the central role of two Onsager correction matrices that precisely characterize the non-trivial dependence among all gradient descent iterates in the mean-field regime.
  Although the Onsager correction matrices are typically analytically intractable, our state evolution theory facilitates a generic gradient descent inference algorithm that consistently estimates these matrices across a broad class of models. Leveraging this algorithm, we show that the state evolution can be inverted to construct (i) data-driven estimators for the generalization error of gradient descent iterates and (ii) debiased gradient descent iterates for inference of the unknown signal. Detailed applications to two canonical models--linear regression and (generalized) logistic regression--are worked out to illustrate model-specific features of our general theory and inference methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09498v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyang Han, Xiaocong Xu</dc:creator>
    </item>
    <item>
      <title>Sail into the Headwind: Alignment via Robust Rewards and Dynamic Labels against Reward Hacking</title>
      <link>https://arxiv.org/abs/2412.09544</link>
      <description>arXiv:2412.09544v1 Announce Type: cross 
Abstract: Aligning AI systems with human preferences typically suffers from the infamous reward hacking problem, where optimization of an imperfect reward model leads to undesired behaviors. In this paper, we investigate reward hacking in offline preference optimization, which aims to improve an initial model using a preference dataset. We identify two types of reward hacking stemming from statistical fluctuations in the dataset: Type I Reward Hacking due to subpar choices appearing more favorable, and Type II Reward Hacking due to decent choices appearing less favorable. We prove that many (mainstream or theoretical) preference optimization methods suffer from both types of reward hacking. To mitigate Type I Reward Hacking, we propose POWER, a new preference optimization method that combines Guiasu's weighted entropy with a robust reward maximization objective. POWER enjoys finite-sample guarantees under general function approximation, competing with the best covered policy in the data. To mitigate Type II Reward Hacking, we analyze the learning dynamics of preference optimization and develop a novel technique that dynamically updates preference labels toward certain "stationary labels", resulting in diminishing gradients for untrustworthy samples. Empirically, POWER with dynamic labels (POWER-DL) consistently outperforms state-of-the-art methods on alignment benchmarks, achieving improvements of up to 13.0 points on AlpacaEval 2.0 and 11.5 points on Arena-Hard over DPO, while also improving or maintaining performance on downstream tasks such as mathematical reasoning. Strong theoretical guarantees and empirical results demonstrate the promise of POWER-DL in mitigating reward hacking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09544v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paria Rashidinejad, Yuandong Tian</dc:creator>
    </item>
    <item>
      <title>Wait-Less Offline Tuning and Re-solving for Online Decision Making</title>
      <link>https://arxiv.org/abs/2412.09594</link>
      <description>arXiv:2412.09594v1 Announce Type: cross 
Abstract: Online linear programming (OLP) has found broad applications in revenue management and resource allocation. State-of-the-art OLP algorithms achieve low regret by repeatedly solving linear programming (LP) subproblems that incorporate updated resource information. However, LP-based methods are computationally expensive and often inefficient for large-scale applications. In contrast, recent first-order OLP algorithms are more computationally efficient but typically suffer from worse regret guarantees. To address these shortcomings, we propose a new algorithm that combines the strengths of LP-based and first-order OLP methods. The algorithm re-solves the LP subproblems periodically at a predefined frequency $f$ and uses the latest dual prices to guide online decision-making. In addition, a first-order method runs in parallel during each interval between LP re-solves, smoothing resource consumption. Our algorithm achieves $\mathscr{O}(\log (T/f) + \sqrt{f})$ regret, delivering a "wait-less" online decision-making process that balances the computational efficiency of first-order methods and the superior regret guarantee of LP-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09594v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jingruo Sun, Wenzhi Gao, Ellen Vitercik, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>The rate of convergence of Bregman proximal methods: Local geometry vs. regularity vs. sharpness</title>
      <link>https://arxiv.org/abs/2211.08043</link>
      <description>arXiv:2211.08043v3 Announce Type: replace 
Abstract: We examine the last-iterate convergence rate of Bregman proximal methods - from mirror descent to mirror-prox and its optimistic variants - as a function of the local geometry induced by the prox-mapping defining the method. For generality, we focus on local solutions of constrained, non-monotone variational inequalities, and we show that the convergence rate of a given method depends sharply on its associated Legendre exponent, a notion that measures the growth rate of the underlying Bregman function (Euclidean, entropic, or other) near a solution. In particular, we show that boundary solutions exhibit a stark separation of regimes between methods with a zero and non-zero Legendre exponent: the former converge at a linear rate, while the latter converge, in general, sublinearly. This dichotomy becomes even more pronounced in linearly constrained problems where methods with entropic regularization achieve a linear convergence rate along sharp directions, compared to convergence in a finite number of steps under Euclidean regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08043v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1580218</arxiv:DOI>
      <dc:creator>Wa\"iss Azizian, Franck Iutzeler, J\'er\^ome Malick, Panayotis Mertikopoulos</dc:creator>
    </item>
    <item>
      <title>Stochastic Reachability of Uncontrolled Systems via Probability Measures: Approximation via Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2304.00598</link>
      <description>arXiv:2304.00598v3 Announce Type: replace 
Abstract: This paper poses a theoretical characterization of the stochastic reachability problem in terms of probability measures, capturing the probability measure of the state of the system that satisfies the reachability specification for all probabilities over a finite horizon. We achieve this by constructing the level sets of the probability measure for all probability values and, since our approach is only for autonomous systems, we can determine the level sets via forward simulations of the system from a point in the state space at some time step in the finite horizon to estimate the reach probability. We devise a training procedure which exploits this forward simulation and employ it to design a deep neural network (DNN) to predict the reach probability provided the current state and time step. We validate the effectiveness of our approach through three examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00598v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karthik Sivaramakrishnan, Vignesh Sivaramakrishnan, Rosalyn Alex Devonport, Meeko M. K. Oishi</dc:creator>
    </item>
    <item>
      <title>On structural contraction of biological interaction networks</title>
      <link>https://arxiv.org/abs/2307.13678</link>
      <description>arXiv:2307.13678v2 Announce Type: replace 
Abstract: Biological networks function extremely well under severe forms of pertubations affecting both the concentrations and the kinetic parameters. Structural dynamical robustness has been proposed as a defining feature of such networks. In this paper, we propose the notion of structural contractivity. We build on the previous work of the authors which characterized the long-term dynamics of classes of Biological Interaction Networks (BINs), based on "rate-dependent Lyapunov functions". Here, we show that stronger notions of convergence can be established by proving structural contractivity with respect to non-standard polyhederal $\ell_\infty$-norms. In particular, we show that such networks are non-expansive. With additional verifiable conditions, we show that they are strictly contractive over arbitrary positive compact sets. In addition, we show that such networks entrain to periodic inputs. We illustrate our theory with examples from signaling pathways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13678v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>q-bio.MN</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Ali Al-Radhawi, David Angeli, Eduardo Sontag</dc:creator>
    </item>
    <item>
      <title>Newton-CG methods for nonconvex unconstrained optimization with H\"older continuous Hessian</title>
      <link>https://arxiv.org/abs/2311.13094</link>
      <description>arXiv:2311.13094v2 Announce Type: replace 
Abstract: In this paper we consider a nonconvex unconstrained optimization problem minimizing a twice differentiable objective function with H\"older continuous Hessian. Specifically, we first propose a Newton-conjugate gradient (Newton-CG) method for finding an approximate first- and second-order stationary point of this problem, assuming the associated the H\"older parameters are explicitly known. Then we develop a parameter-free Newton-CG method without requiring any prior knowledge of these parameters. To the best of our knowledge, this method is the first parameter-free second-order method achieving the best-known iteration and operation complexity for finding an approximate first- and second-order stationary point of this problem. Finally, we present preliminary numerical results to demonstrate the superior practical performance of our parameter-free Newton-CG method over a well-known regularized Newton method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13094v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Heng Huang, Zhaosong Lu</dc:creator>
    </item>
    <item>
      <title>Avoiding strict saddle points of nonconvex regularized problems</title>
      <link>https://arxiv.org/abs/2401.09274</link>
      <description>arXiv:2401.09274v5 Announce Type: replace 
Abstract: In this paper, we consider a class of non-convex and non-smooth sparse optimization problems, which encompass most existing nonconvex sparsity-inducing terms. We show the second-order optimality conditions only depend on the nonzeros of the stationary points. We propose two damped iterative reweighted algorithms including the iteratively reweighted $\ell_1$ algorithm (DIRL$_1$) and the iteratively reweighted $\ell_2$ (DIRL$_2$) algorithm, to solve these problems. For DIRL$_1$, we show the reweighted $\ell_1$ subproblem has support identification property so that DIRL$_1$ locally reverts to a gradient descent algorithm around a stationary point. For DIRL$_2$, we show the solution map of the reweighted $\ell_2$ subproblem is differentiable and Lipschitz continuous everywhere. Therefore, the map of DIRL$_1$ and DIRL$_2$ and their inverse are Lipschitz continuous, and the strict saddle points are their unstable fixed points. By applying the stable manifold theorem, these algorithms are shown to converge only to local minimizers with randomly initialization when the strictly saddle point property is assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09274v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luwei Bai, Yaohua Hu, Hao Wang, Xiaoqi Yang</dc:creator>
    </item>
    <item>
      <title>On Linear Threshold Policies for Continuous-Time Dynamic Yield Management</title>
      <link>https://arxiv.org/abs/2403.11443</link>
      <description>arXiv:2403.11443v2 Announce Type: replace 
Abstract: We study the finite-horizon continuous-time dynamic yield management problem with stationary arrival rates and two customer types. We consider a class of linear threshold policies proposed by Hodge (2008), in which each less-profitable customer is accepted if and only if the remaining inventory exceeds a threshold that linearly decreases over the horizon. We use a Markov chain representation to show that such policies achieve uniformly bounded regret. We then generalize this result to analogous policies for arbitrarily many customer types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11443v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipayan Banerjee, Alan Erera, Alejandro Toriello</dc:creator>
    </item>
    <item>
      <title>A Novel State-Centric Necessary Condition for Time-Optimal Control of Controllable Linear Systems Based on Augmented Switching Laws (Extended Version)</title>
      <link>https://arxiv.org/abs/2404.08943</link>
      <description>arXiv:2404.08943v2 Announce Type: replace 
Abstract: Most existing necessary conditions for optimal control based on adjoining methods require both state and costate information, yet the unobservability of costates for a given feasible trajectory impedes the determination of optimality in practice. This paper establishes a novel theoretical framework for time-optimal control of controllable linear systems with a single input, proposing the augmented switching law (ASL) that represents the input control and the feasibility in a compact form. Given a feasible trajectory, the perturbed trajectory under the constraints of ASL is guaranteed to be feasible, resulting in a novel state-centric necessary condition without dependence on costate information. A first-order necessary condition is proposed that the Jacobian matrix of the ASL is not full row rank, which also results in a potential approach to optimizing a given feasible trajectory with the preservation of arc structures. The proposed necessary condition is applied to high-order chain-of-integrator systems with full box constraints, contributing to some theoretical results challenging to reason by costate-based conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08943v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunan Wang, Chuxiong Hu, Yujie Lin, Zeyang Li, Shize Lin, Suqin He</dc:creator>
    </item>
    <item>
      <title>Contaminated Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2404.18093</link>
      <description>arXiv:2404.18093v2 Announce Type: replace 
Abstract: In online convex optimization, some efficient algorithms have been designed for each of the individual classes of objective functions, e.g., convex, strongly convex, and exp-concave. However, existing regret analyses, including those of universal algorithms, are limited to cases in which the objective functions in all rounds belong to the same class and cannot be applied to cases in which the property of objective functions may change in each time step. This paper introduces a novel approach to address such cases, proposing a new regime we term as \textit{contaminated} online convex optimization. For the contaminated case, we demonstrate that the regret is lower bounded by $\Omega(\log T + \sqrt{k})$. Here, $k$ signifies the level of contamination in the objective functions. We also demonstrate that the regret is bounded by $O(\log T+\sqrt{k\log T})$ when universal algorithms are used. When our proposed algorithms with additional information are employed, the regret is bounded by $O(\log T+\sqrt{k})$, which matches the lower bound. These are intermediate bounds between a convex case and a strongly convex or exp-concave case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18093v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Kamijima, Shinji Ito</dc:creator>
    </item>
    <item>
      <title>Causal feedback strategies for controlled stochastic Volterra systems: a unified treatment</title>
      <link>https://arxiv.org/abs/2406.11009</link>
      <description>arXiv:2406.11009v2 Announce Type: replace 
Abstract: This paper is concerned with a unified treatment of linear quadratic control problem for stochastic Volterra integral equations (SVIEs), motivated by the various approaches and scattered results in the existing literature. A novel class of optimal causal feedback strategy is introduced and characterized by means of a new Riccati system. To this end, a fundamental function space and an appropriate multiplicative rule among functions are defined for the first time. In contrast with the existing works, our unified treatment not only provides a new approach, but also extends or improves the known conclusions in stochastic differential equations, convolution SVIEs, stochastic Volterra integro-differential equations (VIDEs), deterministic VIEs, deterministic VIDEs. In addition, an interesting phenomenon is reveal by the current study: for SVIEs the conventional structure of state feedback is replaced by a suitable causal form, and the original state process no longer plays indispensable role in the feedbacks while an auxiliary state process does.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11009v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayin Gong, Tianxiao Wang</dc:creator>
    </item>
    <item>
      <title>Analysis of the SiMPL method for density-based topology optimization</title>
      <link>https://arxiv.org/abs/2409.19341</link>
      <description>arXiv:2409.19341v2 Announce Type: replace 
Abstract: We present a rigorous convergence analysis of a new method for density-based topology optimization: Sigmoidal Mirror descent with a Projected Latent variable. SiMPL, pronounced like "simple," provides point-wise bound preserving design updates and faster convergence than other popular first-order topology optimization methods. Due to its strong bound preservation, the method is exceptionally robust, as demonstrated in numerous examples here and in the companion article. Furthermore, it is easy to implement with clear structure and analytical expressions for the updates. Our analysis covers two versions of the method, characterized by the employed line search strategies. We consider a modified Armijo backtracking line search and a Bregman backtracking line search. For both line search algorithms, SiMPL delivers a strict monotone decrease in the objective function and further intuitive convergence properties, e.g., strong and pointwise convergence of the density variables on the active sets, norm convergence to zero of the increments, convergence of the Lagrange multipliers, and more. In addition, the numerical experiments demonstrate apparent mesh-independent convergence of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19341v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Keith, Dohyun Kim, Boyan S. Lazarov, Thomas M. Surowiec</dc:creator>
    </item>
    <item>
      <title>Kantorovich-Rubinstein duality theory for the Hessian</title>
      <link>https://arxiv.org/abs/2412.00516</link>
      <description>arXiv:2412.00516v2 Announce Type: replace 
Abstract: The classical Kantorovich-Rubinstein duality theorem establishes a significant connection between Monge optimal transport and maximization of a linear form on the set of 1-Lipschitz functions. This result has been widely used in various research areas. In particular, it unlocks the optimal transport methods in some of the optimal design problems. This paper puts forth a similar theory when the linear form is maximized over $C^{1,1}$ functions whose Hessian lies between minus and plus identity matrix. The problem will be identified as the dual of a specific optimal transport formulation that involves three-point plans. The first two marginals are fixed, while the third must dominate the other two in the sense of convex order. The existence of optimal plans allows to express solutions of the underlying Beckmann problem as a combination of rank-one tensor measures supported on a graph. In the context of two-dimensional mechanics, this graph encodes the optimal configuration of a grillage that transfers a given load system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00516v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karol Bo{\l}botowski, Guy Bouchitt\'e</dc:creator>
    </item>
    <item>
      <title>Dublin Descriptors</title>
      <link>https://arxiv.org/abs/2412.06253</link>
      <description>arXiv:2412.06253v2 Announce Type: replace 
Abstract: Dublin descriptors are under consideration. It is part of one of the global integration processes between European countries and Russia, which began in 1999. It causes a lot of controversy and approval from different sides. For the sake of clarity, an assessment is being made of the industrial application of the Dublin Descriptors. The assessment is based on the method of integral indicators. To use the method, the enterprise is formalized as a model of events at each moment in time. Each event in the enterprise is tied to the student's skill. Accordingly, students' skills are grouped by educational level. Education levels are given as Dublin descriptors. The chosen approach makes it possible to determine the correlation between levels of education and skills. It makes it possible to analyze meaningful interconnection. A universal assessment of the use of Dublin descriptors in the enterprise allows the formation of up-to-date lists of employees for higher education, professional development and training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06253v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1742-6596/1691/1/012021</arxiv:DOI>
      <arxiv:journal_reference>Journal of Physics: Conference Series 1691 (2020) 012021</arxiv:journal_reference>
      <dc:creator>Sergey Masaev, Georgiy Dorrer, Valentina Vingert, Elena Yakimova, Svatoslav Klochkov</dc:creator>
    </item>
    <item>
      <title>A Cardinality-Constrained Approach to Combinatorial Bilevel Congestion Pricing</title>
      <link>https://arxiv.org/abs/2412.06482</link>
      <description>arXiv:2412.06482v2 Announce Type: replace 
Abstract: Combinatorial bilevel congestion pricing (CBCP), a variant of the discrete network design problem, seeks to minimize the total travel time experienced by all travelers in a road network, by strategically selecting toll locations and determining the corresponding charges. Conventional wisdom suggests that these problems are intractable since they have to be formulated and solved with a significant number of integer variables. Here, we devise a scalable local algorithm for the CBCP problem that guarantees convergence to a Kuhn-Tucker-Karush point. Our approach is novel in that it eliminates the use of integer variables altogether, instead introducing a cardinality constraint that limits the number of toll locations to a user-specified upper bound. The resulting bilevel program with the cardinality constraint is then transformed into a block-separable, single-level optimization problem that can be solved efficiently after penalization and decomposition. We are able to apply the algorithm to solve, in about 20 minutes, a CBCP instance with up to 3,000 links, of which hundreds can be tolled. To the best of our knowledge, no existing algorithm can solve CBCP problems at such a scale while providing any assurance of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06482v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Guo, Jiayang Li, Yu Marco Nie, Jun Xie</dc:creator>
    </item>
    <item>
      <title>Fast Online $L_0$ Elastic Net Subspace Clustering via A Novel Dictionary Update Strategy</title>
      <link>https://arxiv.org/abs/2412.07335</link>
      <description>arXiv:2412.07335v2 Announce Type: replace 
Abstract: With the rapid growth of data volume and the increasing demand for real-time analysis, online subspace clustering has emerged as an effective tool for processing dynamic data streams. However, existing online subspace clustering methods often struggle to capture the complex and evolving distribution of such data due to their reliance on rigid dictionary learning mechanisms. In this paper, we propose a novel $\ell_0$ elastic net subspace clustering model by integrating the $\ell_0$ norm and the Frobenius norm, which owns the desirable block diagonal property. To address the challenges posed by the evolving data distributions in online data, we design a fast online alternating direction method of multipliers with an innovative dictionary update strategy based on support points, which are a set of data points to capture the underlying distribution of the data. By selectively updating dictionary atoms according to the support points, the proposed method can dynamically adapt to the evolving data characteristics, thereby enhancing both adaptability and computational efficiency. Moreover, we rigorously prove the convergence of the algorithm. Finally, extensive numerical experiments demonstrate that the proposed method improves clustering performance and computational efficiency, making it well-suited for real-time and large-scale data processing tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07335v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wentao Qu, Lingchen Kong, Linglong Kong, Bei Jiang</dc:creator>
    </item>
    <item>
      <title>A wonderful triangle in compressed sensing</title>
      <link>https://arxiv.org/abs/2202.09952</link>
      <description>arXiv:2202.09952v2 Announce Type: replace-cross 
Abstract: In order to determine the sparse approximation function which has a direct metric relationship with the $\ell_{0}$ quasi-norm, we introduce a wonderful triangle whose sides are composed of $\Vert \mathbf{x} \Vert_{0}$, $\Vert \mathbf{x} \Vert_{1}$ and $\Vert \mathbf{x} \Vert_{\infty}$ for any non-zero vector $\mathbf{x} \in \mathbb{R}^{n}$ by delving into the iterative soft-thresholding operator in this paper. Based on this triangle, we deduce the ratio $\ell_{1}$ and $\ell_{\infty}$ norms as a sparsity-promoting objective function for sparse signal reconstruction and also try to give the sparsity interval of the signal. Considering the $\ell_{1}/\ell_{\infty}$ minimization from a angle $\beta$ of the triangle corresponding to the side whose length is $\Vert \mathbf{x} \Vert_{\infty} - \Vert \mathbf{x} \Vert_{1}/\Vert \mathbf{x} \Vert_{0}$, we finally demonstrate the performance of existing $\ell_{1}/\ell_{\infty}$ algorithm by comparing it with $\ell_{1}/\ell_{2}$ algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.09952v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Wang</dc:creator>
    </item>
    <item>
      <title>Reflections on BSDEs</title>
      <link>https://arxiv.org/abs/2306.14615</link>
      <description>arXiv:2306.14615v4 Announce Type: replace-cross 
Abstract: We prove well-posedness results for backward stochastic differential equations (BSDEs) and reflected BSDEs with an optional obstacle process in the case of appropriately weighted $\mathbb{L}^2$-data when the generator is integrated with respect to a possibly purely discontinuous process. This leads to a unified treatment of discrete-time and continuous-time (reflected) BSDEs. We compare our well-posedness results with the current literature and highlight that our results are sharp and cannot be improved within the framework presented here. Finally, we provide sufficient conditions for a comparison principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14615v4</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1214/24-EJP1123</arxiv:DOI>
      <arxiv:journal_reference>Electronic Journal of Probability, 29: 1-82, 2024</arxiv:journal_reference>
      <dc:creator>Dylan Possama\"i, Marco Rodrigues</dc:creator>
    </item>
    <item>
      <title>Partial Information in a Mean-Variance Portfolio Selection Game</title>
      <link>https://arxiv.org/abs/2312.04045</link>
      <description>arXiv:2312.04045v4 Announce Type: replace-cross 
Abstract: This paper considers finitely many investors who perform mean-variance portfolio selection under relative performance criteria. That is, each investor is concerned about not only her terminal wealth, but how it compares to the average terminal wealth of all investors. At the inter-personal level, each investor selects a trading strategy in response to others' strategies. This selected strategy additionally needs to yield an equilibrium intra-personally, so as to resolve time inconsistency among the investor's current and future selves (triggered by the mean-variance objective). A Nash equilibrium we look for is thus a tuple of trading strategies under which every investor achieves her intra-personal equilibrium simultaneously. We derive such a Nash equilibrium explicitly in the idealized case of full information (i.e., the dynamics of the underlying stock is perfectly known) and semi-explicitly in the realistic case of partial information (i.e., the stock evolution is observed, but the expected return of the stock is not precisely known). The formula under partial information consists of the myopic trading and intertemporal hedging terms, both of which depend on an additional state process that serves to filter the true expected return and whose influence on trading is captured by a degenerate Cauchy problem. Our results identify that relative performance criteria can induce downward self-reinforcement of investors' wealth--if every investor suffers a wealth decline simultaneously, then everyone's wealth tends to decline further. This phenomenon, as numerical examples show, is negligible under full information but pronounced under partial information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04045v4</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Jui Huang, Li-Hsien Sun</dc:creator>
    </item>
    <item>
      <title>Schr\"odinger's control and estimation paradigm with spatio-temporal distributions on graphs</title>
      <link>https://arxiv.org/abs/2312.05679</link>
      <description>arXiv:2312.05679v2 Announce Type: replace-cross 
Abstract: The problem of reconciling a prior probability law on paths with data was introduced by E. Schr\"odinger in 1931/32. It represents an early formulation of a maximum likelihood problem. This specific formulation can also be seen as the control problem to modify the law of a diffusion process so as to match specifications on marginal distributions at given times. Thereby, in recent years, this so-called Schr\"odinger's bridge problem has been at the center of the uncertainty control development. However, an understudied facet of this program has been to address uncertainty in space (state) and time, modeling the effect of tasks being completed contingent on meeting a certain condition at some random time instead of imposing specifications at fixed times. The present work is a study to extend Schr\"odinger's paradigm on such an issue, and herein, it is tackled in the context of random walks on directed graphs. Specifically, we study the case where one marginal is the initial probability distribution on a Markov chain, while others are marginals of stopping (first-arrival) times at absorbing states, signifying completion of tasks. We show when the prior law on paths is Markov, a Markov policy is once again optimal to satisfy those marginal constraints with respect to a likelihood cost following Schr\"odinger's dictum. Based on this, we present the mathematical formulation involving a Sinkhorn-type iteration to construct the optimal probability law on paths matching the spatio-temporal marginals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05679v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asmaa Eldesoukey, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Feedback stabilization and observer design for sterile insect technique model</title>
      <link>https://arxiv.org/abs/2402.01221</link>
      <description>arXiv:2402.01221v2 Announce Type: replace-cross 
Abstract: This paper focuses on the feedback global stabilization and observer construction for a sterile insect technique model. The Sterile Insect Technique (SIT) is one of the most ecological methods for controlling insect pests responsible for worldwide crop destruction and disease transmission. In this work, we construct a feedback law that globally asymptotically stabilizes a SIT model at extinction equilibrium. Since the application of this type of control requires the measurement of different states of the target insect population, and in practice, some states are more difficult and very expensive to measure than others, it is important to know how to construct a state estimator which from a few measured states, estimates the other ones as the one we build in the second part of our work. In the last part of our work, we show that we can apply the feedback control with estimated states to stabilize the full system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01221v2</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3934/mbe.2024274</arxiv:DOI>
      <arxiv:journal_reference>Mathematical Biosciences and Engineering, 2024, 21, pp.6263-6288</arxiv:journal_reference>
      <dc:creator>Kala Agbo Bidi (LJLL, SU, UPCit\'e)</dc:creator>
    </item>
    <item>
      <title>Model Developmental Safety: A Retention-Centric Method and Applications in Vision-Language Models</title>
      <link>https://arxiv.org/abs/2410.03955</link>
      <description>arXiv:2410.03955v3 Announce Type: replace-cross 
Abstract: In the real world, a learning-enabled system usually undergoes multiple cycles of model development to enhance the system's ability to handle difficult or emerging tasks. This continual model development process raises a significant issue that the model development for acquiring new or improving existing capabilities may inadvertently lose capabilities of the old model, also known as catastrophic forgetting. Existing continual learning studies focus on mitigating catastrophic forgetting by trading off performance on previous tasks and new tasks to ensure good average performance. However, they are inadequate for many applications especially in safety-critical domains, as failure to strictly preserve the good performance of the old model not only introduces safety risks and uncertainties but also imposes substantial expenses in the re-improving and re-validation of existing properties. To address this issue, we introduce model developmental safety as a guarantee of a learning system such that in the model development process the new model should strictly preserve the existing protected capabilities of the old model while improving its performance on target tasks. To ensure the model developmental safety, we present a retention-centric framework by formulating the model developmental safety as data-dependent constraints. Under this framework, we study how to develop a pretrained vision-language model, specifically the CLIP model, for acquiring new capabilities or improving existing capabilities of image classification. We propose an efficient constrained optimization algorithm with theoretical guarantee and use its insights to finetune a CLIP model with task-dependent heads for promoting the model developmental safety. Our experiments on improving vision perception capabilities on autonomous driving and scene recognition datasets demonstrate the efficacy of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03955v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gang Li, Wendi Yu, Yao Yao, Wei Tong, Yingbin Liang, Qihang Lin, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>A second-order-like optimizer with adaptive gradient scaling for deep learning</title>
      <link>https://arxiv.org/abs/2410.05871</link>
      <description>arXiv:2410.05871v2 Announce Type: replace-cross 
Abstract: In this empirical article, we introduce INNAprop, an optimization algorithm that combines the INNA method with the RMSprop adaptive gradient scaling. It leverages second-order information and rescaling while keeping the memory requirements of standard DL methods as AdamW or SGD with momentum. After giving geometrical insights, we evaluate INNAprop on CIFAR-10, Food101, and ImageNet with ResNets, VGG, DenseNet, and ViT, and on GPT-2 (OpenWebText) train from scratch and with LoRA fine-tuning (E2E). INNAprop consistently matches or outperforms AdamW both in training speed and accuracy, with minimal hyperparameter tuning in large-scale settings. Our code is publicly available at \url{https://github.com/innaprop/innaprop}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05871v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\'er\^ome Bolte (TSE-R), Ryan Boustany (TSE-R), Edouard Pauwels (TSE-R, IRIT-ADRIA), Andrei Purica</dc:creator>
    </item>
    <item>
      <title>Unlocking FedNL: Self-Contained Compute-Optimized Implementation</title>
      <link>https://arxiv.org/abs/2410.08760</link>
      <description>arXiv:2410.08760v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) is an emerging paradigm that enables intelligent agents to collaboratively train Machine Learning (ML) models in a distributed manner, eliminating the need for sharing their local data. The recent work (arXiv:2106.02969) introduces a family of Federated Newton Learn (FedNL) algorithms, marking a significant step towards applying second-order methods to FL and large-scale optimization. However, the reference FedNL prototype exhibits three serious practical drawbacks: (i) It requires 4.8 hours to launch a single experiment in a sever-grade workstation; (ii) The prototype only simulates multi-node setting; (iii) Prototype integration into resource-constrained applications is challenging. To bridge the gap between theory and practice, we present a self-contained implementation of FedNL, FedNL-LS, FedNL-PP for single-node and multi-node settings. Our work resolves the aforementioned issues and reduces the wall clock time by x1000. With this FedNL outperforms alternatives for training logistic regression in a single-node -- CVXPY (arXiv:1603.00943), and in a multi-node -- Apache Spark (arXiv:1505.06807), Ray/Scikit-Learn (arXiv:1712.05889). Finally, we propose two practical-orientated compressors for FedNL - adaptive TopLEK and cache-aware RandSeqK, which fulfill the theory of FedNL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08760v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MS</category>
      <category>cs.PF</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Burlachenko, Peter Richt\'arik</dc:creator>
    </item>
  </channel>
</rss>
