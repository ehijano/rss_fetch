<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Feb 2025 05:05:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Ultrasound imaging of cortical bone: cortex geometry and measurement of porosity based on wave speed for bone remodeling estimation</title>
      <link>https://arxiv.org/abs/2502.08824</link>
      <description>arXiv:2502.08824v1 Announce Type: new 
Abstract: Intracortical US imaging extends B-mode imaging into bone using a dedicated image reconstruction algorithm that corrects for refraction at the bone-soft tissue interfaces. It has shown promising results in a few healthy, predominantly young adults, providing anatomical images of the cortex (periosteal and endosteal surfaces) along with estimations of US wave speed. However, its reliability in older or osteoporotic bones remains uncertain. In this study, we critically assessed the performance of intracortical US imaging ex vivo in bones with various microstructural patterns, including bones exhibiting signs of unbalanced intracortical remodeling. We analyzed factors influencing US image quality, particularly endosteal surface reconstruction, as well as the accuracy of wave speed estimation and its relationship with porosity. We imaged 20 regions of interest from the femoral diaphysis of five elderly donors using a 2.5 MHz US transducer. The reconstructed US images were compared to site-matched high-resolution micro-CT (HR-muCT) images. In samples with moderate porosity, the endosteal surface was accurately identified, and thickness estimates from US and HR-muCT differed by less than 10%. In highly remodeled bones with increased porosity, the reconstructed endosteal surface appeared less bright and was located above the cortex region containing resorption cavities. We observed a decrease in US wave speed with increasing cortical porosity suggesting that the method could discriminate between bones with low porosity (less than 5%) and those with moderate to high porosity (greater than ~10%). This study paves the way for the application of US imaging in diagnosing cortical bone health, particularly for detecting increased cortical porosity and reduced cortical thickness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08824v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amadou S. Dia, Guillaume Renaud, Christine Chappard, Quentin Grimal</dc:creator>
    </item>
    <item>
      <title>A Physics-Informed Deep Learning Model for MRI Brain Motion Correction</title>
      <link>https://arxiv.org/abs/2502.09296</link>
      <description>arXiv:2502.09296v1 Announce Type: cross 
Abstract: Background: MRI is crucial for brain imaging but is highly susceptible to motion artifacts due to long acquisition times. This study introduces PI-MoCoNet, a physics-informed motion correction network that integrates spatial and k-space information to remove motion artifacts without explicit motion parameter estimation, enhancing image fidelity and diagnostic reliability. Materials and Methods: PI-MoCoNet consists of a motion detection network (U-net with spatial averaging) to identify corrupted k-space lines and a motion correction network (U-net with Swin Transformer blocks) to reconstruct motion-free images. The correction is guided by three loss functions: reconstruction (L1), perceptual (LPIPS), and data consistency (Ldc). Motion artifacts were simulated via rigid phase encoding perturbations and evaluated on IXI and MR-ART datasets against Pix2Pix, CycleGAN, and U-net using PSNR, SSIM, and NMSE. Results: PI-MoCoNet significantly improved image quality. On IXI, for minor artifacts, PSNR increased from 34.15 dB to 45.95 dB, SSIM from 0.87 to 1.00, and NMSE reduced from 0.55% to 0.04%. For moderate artifacts, PSNR improved from 30.23 dB to 42.16 dB, SSIM from 0.80 to 0.99, and NMSE from 1.32% to 0.09%. For heavy artifacts, PSNR rose from 27.99 dB to 36.01 dB, SSIM from 0.75 to 0.97, and NMSE decreased from 2.21% to 0.36%. On MR-ART, PI-MoCoNet achieved PSNR gains of ~10 dB and SSIM improvements of up to 0.20, with NMSE reductions of ~6%. Ablation studies confirmed the importance of data consistency and perceptual losses, yielding a 1 dB PSNR gain and 0.17% NMSE reduction. Conclusions: PI-MoCoNet effectively mitigates motion artifacts in brain MRI, outperforming existing methods. Its ability to integrate spatial and k-space information makes it a promising tool for clinical use in motion-prone settings. Code: https://github.com/mosaf/PI-MoCoNet.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09296v1</guid>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mojtaba Safari, Shansong Wang, Zach Eidex, Richard Qiu, Chih-Wei Chang, David S. Yu, Xiaofeng Yang</dc:creator>
    </item>
    <item>
      <title>Deep Learning-Based Beamlet Model for Generic X-Ray Beam Dose Calculation</title>
      <link>https://arxiv.org/abs/2405.02477</link>
      <description>arXiv:2405.02477v2 Announce Type: replace 
Abstract: Modeling the absorbed dose during X-ray imaging is essential for optimizing radiation exposure. Monte Carlo simulations (MCS) are the gold standard for precise 3D dose estimation but require significant computation time. Deep learning offers faster dose prediction but often lacks generality, as models are typically trained for specific anatomical sites and beam geometries. The aim in this work was proposing a generic deep-learning approach for dose calculation that can be used for multiple X-ray imaging systems. This article proposes a versatile approach combining beamlet decomposition with deep learning, where the X-ray beam is broken down into beamlets. By using a sampling approach, various beam shapes can be generated, reducing learning complexity. The model learns the dose response of a beamlet for different energies and patient properties, making it adaptable to new system geometries without altering the learning model. In this work, we propose combining two U-Net networks (1D+3D) trained on different body parts to predict the dose of a beamlet regardless of its orientation and energy. Results have shown that the deep learning-based dose engine achieved a relative dose error of approximately 1.2+/-3.87% compared to the reference dose. For a more realistic simulation in cone-beam CT, dose results exhibited a relative error within the beam of 5% compared to a full MCS. The convergence of the proposed method was faster compared to MCS, with a speedup of 130 times for equivalent dose results. The versatility of the proposed solution allows for the simulation of multiple X-ray systems without the need to retrain the deep learning model with new beam specificities. The same trained model is capable of calculating the 3D dose within the patient for helical CT, cone-beam CT, fan-beam CT, or any collimated beam shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02477v2</guid>
      <category>physics.med-ph</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Maxime Rousselot, Jing Zhang, Didier Benoit, Chi-Hieu Pham, Julien Bert</dc:creator>
    </item>
  </channel>
</rss>
