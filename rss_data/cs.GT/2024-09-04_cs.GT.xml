<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Sep 2024 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Proportionality for Constrained Public Decisions</title>
      <link>https://arxiv.org/abs/2409.02609</link>
      <description>arXiv:2409.02609v1 Announce Type: new 
Abstract: We study situations where a group of voters need to take a collective decision over a number of public issues, with the goal of getting a result that reflects the voters' opinions in a proportional manner. Our focus is on interconnected public decisions, where the decision on one or more issues has repercussions on the acceptance or rejection of other public issues in the agenda. We show that the adaptations of classical justified-representation axioms to this enriched setting are always satisfiable only for restricted classes of public agendas. However, the use of suitably adapted well-known decision rules on a class of quite expressive constraints, yields proportionality guarantees that match these justified-representation properties in an approximate sense. We also identify another path to achieving proportionality via an adaptation of the notion of priceability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02609v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Chingoma, Umberto Grandi, Arianna Novaro</dc:creator>
    </item>
    <item>
      <title>Generalized Individual Q-learning for Polymatrix Games with Partial Observations</title>
      <link>https://arxiv.org/abs/2409.02663</link>
      <description>arXiv:2409.02663v1 Announce Type: new 
Abstract: This paper addresses the challenge of limited observations in non-cooperative multi-agent systems where agents can have partial access to other agents' actions. We present the generalized individual Q-learning dynamics that combine belief-based and payoff-based learning for the networked interconnections of more than two self-interested agents. This approach leverages access to opponents' actions whenever possible, demonstrably achieving a faster (guaranteed) convergence to quantal response equilibrium in multi-agent zero-sum and potential polymatrix games. Notably, the dynamics reduce to the well-studied smoothed fictitious play and individual Q-learning under full and no access to opponent actions, respectively. We further quantify the improvement in convergence rate due to observing opponents' actions through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02663v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Said Donmez, Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>Beyond Nash Equilibrium: Achieving Bayesian Perfect Equilibrium with Belief Update Fictitious Play</title>
      <link>https://arxiv.org/abs/2409.02706</link>
      <description>arXiv:2409.02706v1 Announce Type: new 
Abstract: In the domain of machine learning and game theory, the quest for Nash Equilibrium (NE) in extensive-form games with incomplete information is challenging yet crucial for enhancing AI's decision-making support under varied scenarios. Traditional Counterfactual Regret Minimization (CFR) techniques excel in navigating towards NE, focusing on scenarios where opponents deploy optimal strategies. However, the essence of machine learning in strategic game play extends beyond reacting to optimal moves; it encompasses aiding human decision-making in all circumstances. This includes not only crafting responses to optimal strategies but also recovering from suboptimal decisions and capitalizing on opponents' errors. Herein lies the significance of transitioning from NE to Bayesian Perfect Equilibrium (BPE), which accounts for every possible condition, including the irrationality of opponents.
  To bridge this gap, we propose Belief Update Fictitious Play (BUFP), which innovatively blends fictitious play with belief to target BPE, a more comprehensive equilibrium concept than NE. Specifically, through adjusting iteration stepsizes, BUFP allows for strategic convergence to both NE and BPE. For instance, in our experiments, BUFP(EF) leverages the stepsize of Extensive Form Fictitious Play (EFFP) to achieve BPE, outperforming traditional CFR by securing a 48.53\% increase in benefits in scenarios characterized by dominated strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02706v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Ju, Zhemei Fang, Yunfeng Luo</dc:creator>
    </item>
    <item>
      <title>Designing Fair Systems for Consumers to Exploit Personalized Pricing</title>
      <link>https://arxiv.org/abs/2409.02777</link>
      <description>arXiv:2409.02777v1 Announce Type: new 
Abstract: Many online marketplaces personalize prices based on consumer attributes. Since these prices are private, consumers will not realize if they spend more on a good than the lowest possible price, and cannot easily take action to get better prices. In this paper we introduce a system that takes advantage of personalized pricing so consumers can profit while improving fairness. Our system matches consumers for trading; the lower-paying consumer buys the good for the higher-paying consumer for some fee. We explore various modeling choices and fairness targets to determine which schema will leave consumers best off, while also earning revenue for the system itself. We show that when consumers individually negotiate the transaction price, they are able to achieve the most fair outcomes. Conversely, when transaction prices are centrally set, consumers are often unwilling to transact. Minimizing the average price paid by an individual or group is most profitable for the system, while achieving a $67\%$ reduction in prices. We see that a high dispersion (or range) of original prices is necessary for our system to be viable. Higher dispersion can actually lead to increased consumer welfare, and act as a check against extreme personalization. Our results provide theoretical evidence that such a system could improve fairness for consumers while sustaining itself financially.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02777v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Karan, Naina Balepur, Hari Sundaram</dc:creator>
    </item>
    <item>
      <title>Epistemic Selection of Costly Alternatives: The Case of Participatory Budgeting</title>
      <link>https://arxiv.org/abs/2304.10940</link>
      <description>arXiv:2304.10940v3 Announce Type: replace 
Abstract: We initiate the study of voting rules for participatory budgeting using the so-called epistemic approach, where one interprets votes as noisy reflections of some ground truth regarding the objectively best set of projects to fund. Using this approach, we first show that both the most studied rules in the literature and the most widely used rule in practice cannot be justified on epistemic grounds: they cannot be interpreted as maximum likelihood estimators, whatever assumptions we make about the accuracy of voters. Focusing then on welfare-maximising rules, we obtain both positive and negative results regarding epistemic guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.10940v3</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Rey, Ulle Endriss</dc:creator>
    </item>
    <item>
      <title>Query-Efficient Algorithm to Find all Nash Equilibria in a Two-Player Zero-Sum Matrix Game</title>
      <link>https://arxiv.org/abs/2310.16236</link>
      <description>arXiv:2310.16236v3 Announce Type: replace 
Abstract: We study the query complexity of finding the set of all Nash equilibria $\mathcal X_\star \times \mathcal Y_\star$ in two-player zero-sum matrix games. Fearnley and Savani (2016) showed that for any randomized algorithm, there exists an $n \times n$ input matrix where it needs to query $\Omega(n^2)$ entries in expectation to compute a single Nash equilibrium. On the other hand, Bienstock et al. (1991) showed that there is a special class of matrices for which one can query $O(n)$ entries and compute its set of all Nash equilibria. However, these results do not fully characterize the query complexity of finding the set of all Nash equilibria in two-player zero-sum matrix games.
  In this work, we characterize the query complexity of finding the set of all Nash equilibria $\mathcal X_\star \times \mathcal Y_\star$ in terms of the number of rows $n$ of the input matrix $A \in \mathbb{R}^{n \times n}$, row support size $k_1 := |\bigcup_{x \in \mathcal X_\star} \text{supp}(x)|$, and column support size $k_2 := |\bigcup_{y \in \mathcal Y_\star} \text{supp}(y)|$. We design a simple yet non-trivial randomized algorithm that, with probability $1 - \delta$, returns the set of all Nash equilibria $\mathcal X_\star \times \mathcal Y_\star$ by querying at most $O(nk^5 \cdot \text{polylog}(n / \delta))$ entries of the input matrix $A \in \mathbb{R}^{n \times n}$, where $k := \max\{k_1, k_2\}$. This upper bound is tight up to a factor of $\text{poly}(k)$, as we show that for any randomized algorithm, there exists an $n \times n$ input matrix with $\min\{k_1, k_2\} = 1$, for which it needs to query $\Omega(nk)$ entries in expectation in order to find the set of all Nash equilibria $\mathcal X_\star \times \mathcal Y_\star$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16236v3</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnab Maiti, Ross Boczar, Kevin Jamieson, Lillian J. Ratliff</dc:creator>
    </item>
    <item>
      <title>Search Games with Predictions</title>
      <link>https://arxiv.org/abs/2401.01149</link>
      <description>arXiv:2401.01149v2 Announce Type: replace 
Abstract: We introduce the study of search games between a mobile Searcher and an immobile Hider in a new setting in which the Searcher has some potentially erroneous information, i.e., a prediction on the Hider's position. The objective is to establish tight tradeoffs between the consistency of a search strategy (i.e., its worst case expected payoff assuming the prediction is correct) and its robustness (i.e., the worst case expected payoff with no assumptions on the quality of the prediction). Our study is the first to address the full power of mixed (randomized) strategies; previous work focused only on deterministic strategies, or relied on stochastic assumptions that do not guarantee worst-case robustness in adversarial situations. We give Pareto-optimal strategies for three fundamental problems, namely searching in discrete locations, searching with stochastic overlook, and searching in the infinite line. As part of our contribution, we provide a novel framework for proving optimal tradeoffs in search games which is applicable, more broadly, to any two-person zero-sum games in learning-augmented settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01149v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spyros Angelopoulos, Thomas Lidbetter, Konstantinos Panagiotou</dc:creator>
    </item>
    <item>
      <title>Beyond matroids: Secretary Problem and Prophet Inequality with general constraints</title>
      <link>https://arxiv.org/abs/1604.00357</link>
      <description>arXiv:1604.00357v2 Announce Type: replace-cross 
Abstract: We study generalizations of the "Prophet Inequality" and "Secretary Problem", where the algorithm is restricted to an arbitrary downward-closed set system. For {0,1}-values, we give O(log n)-competitive algorithms for both problems. This is close to the \Omega(log n / loglog n) lower bound due to Babaioff, Immorlica, and Kleinberg. For general values, our results translate to O(log n log r)-competitive algorithms, where r is the cardinality of the largest feasible set. This resolves (up to the O(log r loglog n) factors) an open question posed to us by Bobby Kleinberg.</description>
      <guid isPermaLink="false">oai:arXiv.org:1604.00357v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviad Rubinstein</dc:creator>
    </item>
    <item>
      <title>Moderate Adaptive Linear Units (MoLU)</title>
      <link>https://arxiv.org/abs/2302.13696</link>
      <description>arXiv:2302.13696v5 Announce Type: replace-cross 
Abstract: We propose a new high-performance activation function, Moderate Adaptive Linear Units (MoLU), for the deep neural network. The MoLU is a simple, beautiful and powerful activation function that can be a good main activation function among hundreds of activation functions. Because the MoLU is made up of the elementary functions, not only it is a diffeomorphism (i.e. analytic over whole domains), but also it reduces the training time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13696v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hankyul Koh, Joon-hyuk Ko, Wonho Jhe</dc:creator>
    </item>
    <item>
      <title>Partially Observable Multi-Agent Reinforcement Learning with Information Sharing</title>
      <link>https://arxiv.org/abs/2308.08705</link>
      <description>arXiv:2308.08705v3 Announce Type: replace-cross 
Abstract: We study provable multi-agent reinforcement learning (RL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \emph{information-sharing} among agents, a common practice in empirical multi-agent RL, and a standard model for multi-agent control systems with communications. We first establish several computational complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for efficiently solving POSGs. {Inspired by the inefficiency of planning in the ground-truth model,} we then propose to further \emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate \emph{equilibrium} (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable multi-agent RL algorithm that is \emph{both} statistically and computationally quasi-efficient. {Finally, beyond equilibrium learning, we extend our algorithmic framework to finding the \emph{team-optimal solution} in cooperative POSGs, i.e., decentralized partially observable Markov decision processes, a much more challenging goal. We establish concrete computational and sample complexities under several common structural assumptions of the model.} We hope our study could open up the possibilities of leveraging and even designing different \emph{information structures}, a well-studied notion in control theory, for developing both sample- and computation-efficient partially observable multi-agent RL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08705v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyu Liu, Kaiqing Zhang</dc:creator>
    </item>
    <item>
      <title>Bayesian Persuasion for Containing SIS Epidemics with Asymptomatic Infection</title>
      <link>https://arxiv.org/abs/2312.04182</link>
      <description>arXiv:2312.04182v2 Announce Type: replace-cross 
Abstract: We investigate the strategic behavior of a large population of agents who decide whether to adopt a costly partially effective protection or remain unprotected against the susceptible-infected-susceptible epidemic. In contrast with most prior works on epidemic games, we assume that the agents are not aware of their true infection status while making decisions. We adopt the Bayesian persuasion framework where the agents receive a noisy signal regarding their true infection status, and maximize their expected utility computed using the posterior probability of being infected conditioned on the received signal. We characterize the stationary Nash equilibrium of this setting under suitable assumptions, and identify conditions under which partial information disclosure leads to a smaller proportion of infected individuals at the equilibrium compared to full information disclosure, and vice versa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04182v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashish R. Hota, Abhisek Satapathi, Urmee Maitra</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Reinforcement Learning from Human Feedback: Data Coverage and Algorithmic Techniques</title>
      <link>https://arxiv.org/abs/2409.00717</link>
      <description>arXiv:2409.00717v2 Announce Type: replace-cross 
Abstract: We initiate the study of Multi-Agent Reinforcement Learning from Human Feedback (MARLHF), exploring both theoretical foundations and empirical validations. We define the task as identifying Nash equilibrium from a preference-only offline dataset in general-sum games, a problem marked by the challenge of sparse feedback signals. Our theory establishes the upper complexity bounds for Nash Equilibrium in effective MARLHF, demonstrating that single-policy coverage is inadequate and highlighting the importance of unilateral dataset coverage. These theoretical insights are verified through comprehensive experiments. To enhance the practical performance, we further introduce two algorithmic techniques. (1) We propose a Mean Squared Error (MSE) regularization along the time axis to achieve a more uniform reward distribution and improve reward learning outcomes. (2) We utilize imitation learning to approximate the reference policy, ensuring stability and effectiveness in training. Our findings underscore the multifaceted approach required for MARLHF, paving the way for effective preference-based multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00717v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalia Zhang, Xinqi Wang, Qiwen Cui, Runlong Zhou, Sham M. Kakade, Simon S. Du</dc:creator>
    </item>
  </channel>
</rss>
