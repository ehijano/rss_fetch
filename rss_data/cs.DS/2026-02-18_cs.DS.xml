<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Near-real-time Solutions for Online String Problems</title>
      <link>https://arxiv.org/abs/2602.15311</link>
      <description>arXiv:2602.15311v1 Announce Type: new 
Abstract: Based on the Breslauer-Italiano online suffix tree construction algorithm (2013) with double logarithmic worst-case guarantees on the update time per letter, we develop near-real-time algorithms for several classical problems on strings, including the computation of the longest repeating suffix array, the (reversed) Lempel-Ziv 77 factorization, and the maintenance of minimal unique substrings, all in an online manner. Our solutions improve over the best known running times for these problems in terms of the worst-case time per letter, for which we achieve a poly-log-logarithmic time complexity, within a linear space. Best known results for these problems require a poly-logarithmic time complexity per letter or only provide amortized complexity bounds. As a result of independent interest, we give conversions between the longest previous factor array and the longest repeating suffix array in space and time bounds based on their irreducible representations, which can have sizes sublinear in the length of the input string.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15311v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik K\"oppl, Gregory Kucherov</dc:creator>
    </item>
    <item>
      <title>Revisiting the Sparse Matrix Compression Problem</title>
      <link>https://arxiv.org/abs/2602.15314</link>
      <description>arXiv:2602.15314v1 Announce Type: new 
Abstract: The sparse matrix compression problem asks for a one-dimensional representation of a binary $n \times \ell$ matrix, formed by an integer array of row indices and a shift function for each row, such that accessing a matrix entry is possible in constant time by consulting this representation. It has been shown that the decision problem for finding an integer array of length $\ell+\rho$ or restricting the shift function up to values of $\rho$ is NP-complete (cf. the textbook of Garey and Johnson). As a practical heuristic, a greedy algorithm has been proposed to shift the $i$-th row until it forms a solution with its predecessor rows. Despite that this greedy algorithm is cherished for its good approximation in practice, we show that it actually exhibits an approximation ratio of $\Theta(\sqrt{\ell+\rho})$. We give further hardness results for parameterizations such as the number of distinct rows or the maximum number of non-zero entries per row. Finally, we devise a DP-algorithm that solves the problem for double-logarithmic matrix widths or logarithmic widths for further restrictions. We study all these findings also under a new perspective by introducing a variant of the problem, where we wish to minimize the length of the resulting integer array by trimming the non-zero borders, which has not been studied in the literature before but has practical motivations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15314v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Jug\'e, Dominik K\"oppl, Vincent Limouzy, Andrea Marino, Jannik Olblich, Giulia Punzi, Takeaki Uno</dc:creator>
    </item>
    <item>
      <title>Testing Monotonicity of Real-Valued Functions on DAGs</title>
      <link>https://arxiv.org/abs/2602.15341</link>
      <description>arXiv:2602.15341v1 Announce Type: new 
Abstract: We study monotonicity testing of real-valued functions on directed acyclic graphs (DAGs) with $n$ vertices. For every constant $\delta&gt;0$, we prove a $\Omega(n^{1/2-\delta}/\sqrt{\varepsilon})$ lower bound against non-adaptive two-sided testers on DAGs, nearly matching the classical $O(\sqrt{n/\varepsilon})$-query upper bound. For constant $\varepsilon$, we also prove an $\Omega(\sqrt n)$ lower bound for randomized adaptive one-sided testers on explicit bipartite DAGs, whereas previously only an $\Omega(\log n)$ lower bound was known. A key technical ingredient in both lower bounds is positive-matching Ruzsa--Szemer\'edi families. On the algorithmic side, we give simple non-adaptive one-sided testers with query complexity $O(\sqrt{m\,\ell}/(\varepsilon n))$ and $O(m^{1/3}/\varepsilon^{2/3})$, where $m$ is the number of edges in the transitive reduction and $\ell$ is the number of edges in the transitive closure. For constant $\varepsilon&gt;0$, these improve over the previous $O(\sqrt{n/\varepsilon})$ bound when $m\ell=o(n^3)$ and $m=o(n^{3/2})$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15341v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuichi Yoshida</dc:creator>
    </item>
    <item>
      <title>Memory Reallocation with Polylogarithmic Overhead</title>
      <link>https://arxiv.org/abs/2602.15417</link>
      <description>arXiv:2602.15417v1 Announce Type: new 
Abstract: The Memory Reallocation problem asks to dynamically maintain an assignment of given objects of various sizes to non-overlapping contiguous chunks of memory, while supporting updates (insertions/deletions) in an online fashion. The total size of live objects at any time is guaranteed to be at most a $1-\epsilon$ fraction of the total memory. To handle an online update, the allocator may rearrange the objects in memory to make space, and the overhead for this update is defined as the total size of moved objects divided by the size of the object being inserted/deleted.
  Our main result is an allocator with worst-case expected overhead $\mathrm{polylog}(\epsilon^{-1})$. This exponentially improves the previous worst-case expected overhead $\tilde O({\epsilon}^{-1/2})$ achieved by Farach-Colton, Kuszmaul, Sheffield, and Westover (2024), narrowing the gap towards the $\Omega(\log\epsilon^{-1})$ lower bound. Our improvement is based on an application of the sunflower lemma previously used by Erd\H{o}s and S\'{a}rk\"{o}zy (1992) in the context of subset sums.
  Our allocator achieves polylogarithmic overhead only in expectation, and sometimes performs expensive rebuilds. Our second technical result shows that this is necessary: it is impossible to achieve subpolynomial overhead with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15417v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ce Jin</dc:creator>
    </item>
    <item>
      <title>Fair Correlation Clustering Meets Graph Parameters</title>
      <link>https://arxiv.org/abs/2602.15683</link>
      <description>arXiv:2602.15683v1 Announce Type: new 
Abstract: We study the generalization of Correlation Clustering which incorporates fairness constraints via the notion of fairlets. The corresponding Fair Correlation Clustering problem has been studied from several perspectives to date, but has so far lacked a detailed analysis from the parameterized complexity paradigm. We close this gap by providing tractability results for the problem under a variety of structural graph parameterizations, including treewidth, treedepth and the vertex cover number; our results lie at the very edge of tractability given the known NP-hardness of the problem on severely restricted inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15683v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Blaha, Robert Ganian, Katharina Gillig, Jonathan S. H{\o}jlev, Simon Wietheger</dc:creator>
    </item>
    <item>
      <title>A Weighted-to-Unweighted Reduction for Matroid Intersection</title>
      <link>https://arxiv.org/abs/2602.15702</link>
      <description>arXiv:2602.15702v1 Announce Type: new 
Abstract: Given two matroids $\mathcal{M}_1$ and $\mathcal{M}_2$ over the same ground set, the matroid intersection problem is to find the maximum cardinality common independent set. In the weighted version of the problem, the goal is to find a maximum weight common independent set. It has been a matter of interest to find efficient approximation algorithms for this problem in various settings. In many of these models, there is a gap between the best known results for the unweighted and weighted versions. In this work, we address the question of closing this gap. Our main result is a reduction which converts any $\alpha$-approximate unweighted matroid intersection algorithm into an $\alpha(1-\varepsilon)$-approximate weighted matroid intersection algorithm, while increasing the runtime of the algorithm by a $\log W$ factor, where $W$ is the aspect ratio. Our framework is versatile and translates to settings such as streaming and one-way communication complexity where matroid intersection is well-studied. As a by-product of our techniques, we derive new results for weighted matroid intersection in these models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15702v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditi Dudeja, Mara Grilnberger</dc:creator>
    </item>
    <item>
      <title>Local Node Differential Privacy</title>
      <link>https://arxiv.org/abs/2602.15802</link>
      <description>arXiv:2602.15802v1 Announce Type: new 
Abstract: We initiate an investigation of node differential privacy for graphs in the local model of private data analysis. In our model, dubbed LNDP, each node sees its own edge list and releases the output of a local randomizer on this input. These outputs are aggregated by an untrusted server to obtain a final output.
  We develop a novel algorithmic framework for this setting that allows us to accurately answer arbitrary linear queries on a blurry approximation of the input graph's degree distribution. For some natural problems, the resulting algorithms match the accuracy achievable with node privacy in the central model, where data are held and processed by a trusted server. We also prove lower bounds on the error required by LNDP that imply the optimality of our algorithms for several fundamental graph statistics. We then lift these lower bounds to the interactive LNDP setting, demonstrating the optimality of our algorithms even when constantly many rounds of interaction are permitted. Obtaining our lower bounds requires new approaches, since those developed for the usual local model do not apply to the inherently overlapping inputs that arise from graphs. Finally, we prove structural results that reveal qualitative differences between local node privacy and the standard local model for tabular data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15802v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofya Raskhodnikova, Adam Smith, Connor Wagaman, Anatoly Zavyalov</dc:creator>
    </item>
    <item>
      <title>Tensor Decomposition for Non-Clifford Gate Minimization</title>
      <link>https://arxiv.org/abs/2602.15285</link>
      <description>arXiv:2602.15285v1 Announce Type: cross 
Abstract: Fault-tolerant quantum computation requires minimizing non-Clifford gates, whose implementation via magic state distillation dominates the resource costs. While $T$-count minimization is well-studied, dedicated $CCZ$ factories shift the natural target to direct Toffoli minimization. We develop algebraic methods for this problem, building on a connection between Toffoli count and tensor decomposition over $\mathbb{F}_2$. On standard benchmarks, these methods match or improve all reported results for both Toffoli and $T$-count, with most circuits completing in under a minute on a single CPU instead of thousands of TPUs used by prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15285v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kirill Khoruzhii, Patrick Gel{\ss}, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Self-dual Stacked Quantum Low-Density Parity-Check Codes</title>
      <link>https://arxiv.org/abs/2602.15372</link>
      <description>arXiv:2602.15372v1 Announce Type: cross 
Abstract: Quantum low-density parity-check (qLDPC) codes are promising candidates for fault-tolerant quantum computation due to their high encoding rates and distances. However, implementing logical operations using qLDPC codes presents significant challenges. Previous research has demonstrated that self-dual qLDPC codes facilitate the implementation of transversal Clifford gates. Here we introduce a method for constructing self-dual qLDPC codes by stacking non-self-dual qLDPC codes. Leveraging this methodology, we develop double-chain bicycle codes, double-layer bivariate bicycle (BB) codes, double-layer twisted BB codes, and double-layer reflection codes, many of which exhibit favorable code parameters. Additionally, we conduct numerical calculations to assess the performance of these codes as quantum memory under the circuit-level noise model, revealing that the logical failure rate can be significantly reduced with high pseudo-thresholds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15372v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ze-Chuan Liu, Chong-Yuan Xu, Yong Xu</dc:creator>
    </item>
    <item>
      <title>Natural Privacy Filters Are Not Always Free: A Characterization of Free Natural Filters</title>
      <link>https://arxiv.org/abs/2602.15815</link>
      <description>arXiv:2602.15815v1 Announce Type: cross 
Abstract: We study natural privacy filters, which enable the exact composition of differentially private (DP) mechanisms with adaptively chosen privacy characteristics. Earlier privacy filters consider only simple privacy parameters such as R\'enyi-DP or Gaussian DP parameters. Natural filters account for the entire privacy profile of every query, promising greater utility for a given privacy budget. We show that, contrary to other forms of DP, natural privacy filters are not free in general. Indeed, we show that only families of privacy mechanisms that are well-ordered when composed admit free natural privacy filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15815v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Regehr, Bingshan Hu, Ethan Leeman, Pasin Manurangsi, Pierre Tholoniat, Mathias L\'ecuyer</dc:creator>
    </item>
    <item>
      <title>Finding Small Complete Subgraphs Efficiently</title>
      <link>https://arxiv.org/abs/2308.11146</link>
      <description>arXiv:2308.11146v4 Announce Type: replace 
Abstract: (I) We revisit the algorithmic problem of finding all triangles in a graph $G=(V,E)$ with $n$ vertices and $m$ edges. According to a result of Chiba and Nishizeki (1985), this task can be achieved by a combinatorial algorithm running in $O(m \alpha) = O(m^{3/2})$ time, where $\alpha= \alpha(G)$ is the graph arboricity. We provide a new very simple combinatorial algorithm for finding all triangles in a graph and show that is amenable to the same running time analysis. We derive these worst-case bounds from first principles and with very simple proofs that do not rely on classic results due to Nash-Williams from the 1960s. Our experimental results show that our simple algorithm for triangle listing is substantially faster in practice than that of Chiba and Nishizeki on all examples of real-world graphs we tried.
  (II) We extend our arguments to the problem of finding all small complete subgraphs of a given fixed size. We show that the dependency on $m$ and $\alpha$ in the running time $O(\alpha^{\ell-2} \cdot m)$ of the algorithm of Chiba and Nishizeki for listing all copies of $K_\ell$, where $\ell \geq 3$, is asymptotically tight.
  (III) We give improved arboricity-sensitive running times for counting and/or detection of copies of $K_\ell$, for small $\ell \geq 4$. A key ingredient in our algorithms is, once again, the algorithm of Chiba and Nishizeki. Our new algorithms are faster than all previous algorithms in certain high-range arboricity intervals for every $\ell \geq 7$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11146v4</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Chen, Adrian Dumitrescu, Andrzej Lingas</dc:creator>
    </item>
    <item>
      <title>Exact and Heuristic Computation of the Scanwidth of Directed Acyclic Graphs</title>
      <link>https://arxiv.org/abs/2403.12734</link>
      <description>arXiv:2403.12734v2 Announce Type: replace 
Abstract: To measure the tree-likeness of a directed acyclic graph (DAG), a new width parameter that considers the directions of the arcs was recently introduced: scanwidth. We present the first algorithm that efficiently computes the exact scanwidth of general DAGs. For DAGs with one root and scanwidth $k$ it runs in $O(k \cdot n^k \cdot m)$ time. The algorithm also functions as an FPT algorithm with complexity $O(2^{4 \ell - 1} \cdot \ell \cdot n + n^2)$ for phylogenetic networks of level-$\ell$, a type of DAG used to depict evolutionary relationships among species. Our algorithm performs well in practice, being able to compute the scanwidth of synthetic networks up to 30 reticulations and 100 leaves within 500 seconds. Furthermore, we propose a heuristic that obtains an average practical approximation ratio of 1.5 on these networks. While we prove that the scanwidth is bounded from below by the treewidth of the underlying undirected graph, experiments suggest that for networks the parameters are close in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12734v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels Holtgrefe, Leo van Iersel, Mark Jones</dc:creator>
    </item>
    <item>
      <title>Differentially Private Matchings</title>
      <link>https://arxiv.org/abs/2501.00926</link>
      <description>arXiv:2501.00926v4 Announce Type: replace 
Abstract: Computing matchings in graphs is a foundational algorithmic task. Despite extensive interest in differentially private (DP) graph analysis, work on privately computing matching solutions, rather than just their size, has been sparse. The sole prior work in the standard model of pure $\varepsilon$-differential privacy, by Hsu, Huang, Roth, Roughgarden, and Wu [HHR+14, STOC'14], focused on allocations and was thus restricted to bipartite graphs. We present a comprehensive study of DP algorithms for maximum matching and b-matching in general graphs, which also yields techniques that improve upon the bipartite setting. En route to solving these matching problems, we develop a set of novel techniques with broad applicability, including a new symmetry argument for DP lower bounds, the first arboricity-based sparsifiers for node-DP, and the novel Public Vertex Subset Mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00926v4</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Dinitz, George Z. Li, Quanquan C. Liu, Felix Zhou</dc:creator>
    </item>
    <item>
      <title>Reveal-or-Obscure: A Differentially Private Sampling Algorithm for Discrete Distributions</title>
      <link>https://arxiv.org/abs/2504.14696</link>
      <description>arXiv:2504.14696v3 Announce Type: replace-cross 
Abstract: We introduce a differentially private (DP) algorithm called reveal-or-obscure (ROO) to generate a single representative sample from a dataset of $n$ observations drawn i.i.d. from an unknown discrete distribution $P$. Unlike methods that add explicit noise to the estimated empirical distribution, ROO achieves $\epsilon$-differential privacy by randomly choosing whether to "reveal" or "obscure" the empirical distribution. While ROO is structurally identical to Algorithm 1 proposed by Cheu and Nayak (arXiv:2412.10512), we prove a strictly better bound on the sampling complexity than that established in Theorem 12 of (arXiv:2412.10512). To further improve the privacy-utility trade-off, we propose a novel generalized sampling algorithm called Data-Specific ROO (DS-ROO), where the probability of obscuring the empirical distribution of the dataset is chosen adaptively. We prove that DS-ROO satisfies $\epsilon$-DP, and provide empirical evidence that DS-ROO can achieve better utility under the same privacy budget of vanilla ROO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14696v3</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naima Tasnim, Atefeh Gilani, Lalitha Sankar, Oliver Kosut</dc:creator>
    </item>
    <item>
      <title>Constitutional Consensus for Democratic Governance</title>
      <link>https://arxiv.org/abs/2505.19216</link>
      <description>arXiv:2505.19216v5 Announce Type: replace-cross 
Abstract: Permissionless-consensus-based Decentralised Autonomous Organisations (DAOs) are the prevailing paradigm for participant-governed digital organisations. As participants have verified resources but no trusted identities, this ecosystem is necessarily plutocratic (one coin -- one vote). Here we offer, for the first time, a democratic (one person -- one vote) paradigm for the governance of digital communities and organisations, based on permissioned consensus and egalitarian decision processes.
  In line with Lamport's vision of consensus as a self-governing parliament, in the democratic paradigm a constitution specifies both a decision making protocol as well as a consensus protocol, combined to let participants amend the constitution through constitutionally-valid decisions that are ratified by consensus. To meaningfully instantiate this paradigm we integrate the disciplines of distributed computing and computational social choice, with the goal of providing a practical and efficient smartphone-based solution for the democratic self-governance of grassroots sovereign digital communities and organisations.
  The resulting Constitutional Consensus protocol employs (1) state-of-the-art Sybil-resilient democratic decision processes for amending the set of participants, supermajority threshold, and timeout; and (2) a novel Byzantine-fault tolerant consensus protocol that is DAG-based (following Cordial Miners) thus eschewing reliable broadcast, with dual-mode operation (following Morpheus) that is quiescent when idle, has spontaneous leaders for isolated transactions, and formal round-robin leadership during high throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19216v5</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idit Keidar, Andrew Lewis-Pye, Ehud Shapiro, Nimrod Talmon</dc:creator>
    </item>
    <item>
      <title>Is nasty noise actually harder than malicious noise?</title>
      <link>https://arxiv.org/abs/2511.09763</link>
      <description>arXiv:2511.09763v2 Announce Type: replace-cross 
Abstract: We consider the relative abilities and limitations of computationally efficient algorithms for learning in the presence of noise, under two well-studied and challenging adversarial noise models for learning Boolean functions: malicious noise, in which an adversary can arbitrarily corrupt a random subset of examples given to the learner; and nasty noise, in which an adversary can arbitrarily corrupt an adversarially chosen subset of examples given to the learner.
  We consider both the distribution-independent and fixed-distribution settings. Our main results highlight a dramatic difference between these two settings: For distribution-independent learning, we prove a strong equivalence between the two noise models: If a class ${\cal C}$ of functions is efficiently learnable in the presence of $\eta$-rate malicious noise, then it is also efficiently learnable in the presence of $\eta$-rate nasty noise. In sharp contrast, for the fixed-distribution setting we show an arbitrarily large separation: Under a standard cryptographic assumption, for any arbitrarily large value $r$ there exists a concept class for which there is a ratio of $r$ between the rate $\eta_{malicious}$ of malicious noise that polynomial-time learning algorithms can tolerate, versus the rate $\eta_{nasty}$ of nasty noise that such learning algorithms can tolerate.
  To offset the negative result for the fixed-distribution setting, we define a broad and natural class of algorithms, namely those that ignore contradictory examples (ICE). We show that for these algorithms, malicious noise and nasty noise are equivalent up to a factor of two in the noise rate: Any efficient ICE learner that succeeds with $\eta$-rate malicious noise can be converted to an efficient learner that succeeds with $\eta/2$-rate nasty noise. We further show that the above factor of two is necessary, again under a standard cryptographic assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09763v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Guy Blanc, Yizhi Huang, Tal Malkin, Rocco A. Servedio</dc:creator>
    </item>
  </channel>
</rss>
