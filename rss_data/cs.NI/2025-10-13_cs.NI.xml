<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Oct 2025 03:09:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Wireless Datasets for Aerial Networks</title>
      <link>https://arxiv.org/abs/2510.08752</link>
      <description>arXiv:2510.08752v1 Announce Type: new 
Abstract: The integration of unmanned aerial vehicles (UAVs) into 5G-Advanced and future 6G networks presents a transformative opportunity for wireless connectivity, enabling agile deployment and improved LoS communications. However, the effective design and optimization of these aerial networks depend critically on high-quality, empirical data. This paper provides a comprehensive survey of publicly available wireless datasets collected from an airborne platform called Aerial Experimentation and Research Platform on Advanced Wireless (AERPAW). We highlight the unique challenges associated with generating reproducible aerial wireless datasets, and review the existing related works in the literature. Subsequently, for each dataset considered, we explain the hardware and software used, present the dataset format, provide representative results, and discuss how these datasets can be used to conduct additional research. The specific aerial wireless datasets presented include raw I/Q samples from a cellular network over different UAV trajectories, spectrum measurements at different altitudes, flying 4G base station (BS), a 5G-NSA Ericsson network, a LoRaWAN network, an radio frequency (RF) sensor network for source localization, wireless propagation data for various scenarios, and comparison of ray tracing and real-world propagation scenarios. References to all datasets and post-processing scripts are provided to enable full reproducibility of the results. Ultimately, we aim to guide the community toward effective dataset utilization for validating propagation models, developing machine learning algorithms, and advancing the next generation of aerial wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08752v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Hossein Fahim Raouf, Donggu Lee, Mushfiqur Rahman, Saad Masrur, Gautham Reddy, Cole Dickerson, Md Sharif Hossen, Sergio Vargas Villar, An{\i}l G\"urses, Simran Singh, Sung Joon Maeng, Martins Ezuma, Christopher Roberts, Mohamed Rabeek Sarbudeen, Thomas J. Zajkowski, Magreth Mushi, Ozgur Ozdemir, Ram Asokan, Ismail Guvenc, Mihail L. Sichitiu, Rudra Dutta</dc:creator>
    </item>
    <item>
      <title>Prioritizing Latency with Profit: A DRL-Based Admission Control for 5G Network Slices</title>
      <link>https://arxiv.org/abs/2510.08769</link>
      <description>arXiv:2510.08769v1 Announce Type: new 
Abstract: 5G networks enable diverse services such as eMBB, URLLC, and mMTC through network slicing, necessitating intelligent admission control and resource allocation to meet stringent QoS requirements while maximizing Network Service Provider (NSP) profits. However, existing Deep Reinforcement Learning (DRL) frameworks focus primarily on profit optimization without explicitly accounting for service delay, potentially leading to QoS violations for latency-sensitive slices. Moreover, commonly used epsilon-greedy exploration of DRL often results in unstable convergence and suboptimal policy learning. To address these gaps, we propose DePSAC -- a Delay and Profit-aware Slice Admission Control scheme. Our DRL-based approach incorporates a delay-aware reward function, where penalties due to service delay incentivize the prioritization of latency-critical slices such as URLLC. Additionally, we employ Boltzmann exploration to achieve smoother and faster convergence. We implement and evaluate DePSAC on a simulated 5G core network substrate with realistic Network Slice Request (NSLR) arrival patterns. Experimental results demonstrate that our method outperforms the DSARA baseline in terms of overall profit, reduced URLLC slice delays, improved acceptance rates, and improved resource consumption. These findings validate the effectiveness of the proposed DePSAC in achieving better QoS-profit trade-offs for practical 5G network slicing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08769v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Proggya Chakraborty, Aaquib Asrar, Jayasree Sengupta, Sipra Das Bit</dc:creator>
    </item>
    <item>
      <title>Characterizing 5G User Throughput via Uncertainty Modeling and Crowdsourced Measurements</title>
      <link>https://arxiv.org/abs/2510.09239</link>
      <description>arXiv:2510.09239v1 Announce Type: new 
Abstract: Characterizing application-layer user throughput in next-generation networks is increasingly challenging as the higher capacity of the 5G Radio Access Network (RAN) shifts connectivity bottlenecks towards deeper parts of the network. Traditional methods, such as drive tests and operator equipment counters, are costly, limited, or fail to capture end-to-end (E2E) Quality of Service (QoS) and its variability. In this work, we leverage large-scale crowdsourced measurements-including E2E, radio, contextual and network deployment features collected by the user equipment (UE)-to propose an uncertainty-aware and explainable approach for downlink user throughput estimation. We first validate prior 4G methods, improving R^2 by 8.7%, and then extend them to 5G NSA and 5G SA, providing the first benchmarks for 5G crowdsourced datasets. To address the variability of throughput, we apply NGBoost, a model that outputs both point estimates and calibrated confidence intervals, representing its first use in the field of computer communications. Finally, we use the proposed model to analyze the evolution from 4G to 5G SA, and show that throughput bottlenecks move from the RAN to transport and service layers, as seen by E2E metrics gaining importance over radio-related features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09239v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Albert-Smet, Zoraida Frias, Luis Mendo, Sergio Melones, Eduardo Yraola</dc:creator>
    </item>
    <item>
      <title>Robust Heuristic Algorithm Design with LLMs</title>
      <link>https://arxiv.org/abs/2510.08755</link>
      <description>arXiv:2510.08755v1 Announce Type: cross 
Abstract: We posit that we can generate more robust and performant heuristics if we augment approaches using LLMs for heuristic design with tools that explain why heuristics underperform and suggestions about how to fix them. We find even simple ideas that (1) expose the LLM to instances where the heuristic underperforms; (2) explain why they occur; and (3) specialize design to regions in the input space, can produce more robust algorithms compared to existing techniques~ -- ~the heuristics we produce have a $\sim28\times$ better worst-case performance compared to FunSearch, improve average performance, and maintain the runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08755v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.NI</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pantea Karimi, Dany Rouhana, Pooria Namyar, Siva Kesava Reddy Kakarla, Venkat Arun, Behnaz Arzani</dc:creator>
    </item>
    <item>
      <title>Velocity and Density-Aware RRI Analysis and Optimization for AoI Minimization in IoV SPS</title>
      <link>https://arxiv.org/abs/2510.08911</link>
      <description>arXiv:2510.08911v1 Announce Type: cross 
Abstract: Addressing the problem of Age of Information (AoI) deterioration caused by packet collisions and vehicle speed-related channel uncertainties in Semi-Persistent Scheduling (SPS) for the Internet of Vehicles (IoV), this letter proposes an optimization approach based on Large Language Models (LLM) and Deep Deterministic Policy Gradient (DDPG). First, an AoI calculation model influenced by vehicle speed, vehicle density, and Resource Reservation Interval (RRI) is established, followed by the design of a dual-path optimization scheme. The DDPG is guided by the state space and reward function, while the LLM leverages contextual learning to generate optimal parameter configurations. Experimental results demonstrate that LLM can significantly reduce AoI after accumulating a small number of exemplars without requiring model training, whereas the DDPG method achieves more stable performance after training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08911v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maoxin Ji, Tong Wang, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen</dc:creator>
    </item>
    <item>
      <title>On the Placement and Sustainability of Drone FSO Backhaul Relays</title>
      <link>https://arxiv.org/abs/2205.15006</link>
      <description>arXiv:2205.15006v2 Announce Type: replace 
Abstract: We consider free-space optical (FSO) communication links for the backhaul connectivity of small cells (SCs) where a UAV with an FSO apparatus can serve as a backhaul relay node. We demonstrate how such drone relay stations (DRSs) can be deployed in a high-rise urban area in order to provide FSO line-of-sight (LOS) links that are unobstructed by buildings. Also, in our solution we consider the case where solar panels are mounted on DRSs such that placing the DRS in a sunny location is prioritized, and we show the gain in terms of number of required trips to recharge the UAV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.15006v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LWC.2022.3178546</arxiv:DOI>
      <arxiv:journal_reference>IEEE Wireless Communications Letters 2022</arxiv:journal_reference>
      <dc:creator>Salim Janji, Adam Samorzewski, Ma{\l}gorzata Wasilewska, Adrian Kliks</dc:creator>
    </item>
    <item>
      <title>Energy-efficient User Clustering for UAV-enabled Wireless Networks Using EM Algorithm</title>
      <link>https://arxiv.org/abs/2207.00873</link>
      <description>arXiv:2207.00873v2 Announce Type: replace 
Abstract: Unmanned Aerial Vehicles (UAVs) can be used to provide wireless connectivity to support the existing infrastructure in hot-spots or replace it in cases of destruction. UAV-enabled wireless provides several advantages in network performance due to drone small cells (DSCs) mobility despite the limited onboard energy. However, the problem of resource allocation has added complexity. In this paper, we propose an energy-efficient user clustering mechanism based on Gaussian mixture models (GMM) using a modified Expected-Maximization (EM) algorithm. The algorithm is intended to provide the initial user clustering and drone deployment upon which additional mechanisms can be employed to further enhance the system performance. The proposed algorithm improves the energy efficiency of the system by 25% and link reliability by 18.3% compared to other baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.00873v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/SoftCOM52868.2021.9559068</arxiv:DOI>
      <dc:creator>Salim Janji, Adrian Kliks</dc:creator>
    </item>
    <item>
      <title>Towards a Non-Binary View of IPv6 Adoption</title>
      <link>https://arxiv.org/abs/2507.11678</link>
      <description>arXiv:2507.11678v2 Announce Type: replace 
Abstract: Twelve years have passed since World IPv6 Launch Day, but what is the current state of IPv6 deployment? Prior work has examined IPv6 status as a binary: can a user do any IPv6? As deployment increases, we must consider a more nuanced, non-binary perspective on IPv6: how much and often can a user or a service use IPv6? We consider this question as a client, server, and cloud provider. Considering the client's perspective, we observe user traffic. We see that the fraction of IPv6 traffic a user sends varies greatly, both across users and day-by-day, with a standard deviation of over 15%. We show this variation occurs for two main reasons. First, IPv6 traffic is primarily human-generated, thus showing diurnal patterns. Second, some services lead with full IPv6 adoption, while others lag with partial or no support, so as users do different things their fraction of IPv6 varies. We look at server-side IPv6 adoption in two ways. First, we expand analysis of web services to examine how many are only partially IPv6 enabled due to their reliance on IPv4-only resources. Our findings reveal that only 12.6% of top 100k websites qualify as fully IPv6-ready. Finally, we examine cloud support for IPv6. Although all clouds and CDNs support IPv6, we find that tenant deployment rates vary significantly across providers. We find that ease of enabling IPv6 in the cloud is correlated with tenant IPv6 adoption rates, and recommend best practices for cloud providers to improve IPv6 adoption. Our results suggest IPv6 deployment is growing, but many services lag, presenting a potential for improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11678v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3730567.3764467</arxiv:DOI>
      <dc:creator>Sulyab Thottungal Valapu, John Heidemann</dc:creator>
    </item>
    <item>
      <title>Preprint: Poster: Did I Just Browse A Website Written by LLMs?</title>
      <link>https://arxiv.org/abs/2507.13933</link>
      <description>arXiv:2507.13933v2 Announce Type: replace 
Abstract: Increasingly, web content is automatically generated by large language models (LLMs) with little human input. We call this "LLM-dominant" content. Since LLMs plagiarize and hallucinate, LLM-dominant content can be unreliable and unethical. Yet, websites rarely disclose such content, and human readers struggle to distinguish it. Thus, we must develop reliable detectors for LLM-dominant content. However, state-of-the-art LLM detectors are inaccurate on web content, because web content has low positive rates, complex markup, and diverse genres, instead of clean, prose-like benchmark data SoTA detectors are optimized for.
  We propose a highly reliable, scalable pipeline that classifies entire websites. Instead of naively classifying text extracted from each page, we classify each site based on an LLM text detector's outputs of multiple prose-like pages to boost accuracies. We train and evaluate our detector by collecting 2 distinct ground truth datasets totaling 120 sites, and obtain 100% accuracies testing across them. In the wild, we detect a sizable portion of sites as LLM-dominant among 10k sites in search engine results and 10k in Common Crawl archives. We find LLM-dominant sites are growing in prevalence and rank highly in search results, raising questions about their impact on end users and the overall Web ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13933v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sichang Steven He, Ramesh Govindan, Harsha V. Madhyastha</dc:creator>
    </item>
    <item>
      <title>1Q: First-Generation Wireless Systems Integrating Classical and Quantum Communication</title>
      <link>https://arxiv.org/abs/2509.14731</link>
      <description>arXiv:2509.14731v3 Announce Type: replace 
Abstract: We introduce the concept of 1Q, the first wireless generation of integrated classical and quantum communication. 1Q features quantum base stations (QBSs) that support entanglement distribution via free-space optical links alongside traditional radio communications. Key new components include quantum cells, quantum user equipment (QUEs), and hybrid resource allocation spanning classical time-frequency and quantum entanglement domains. Several application scenarios are discussed and illustrated through system design requirements for quantum key distribution, blind quantum computing, and distributed quantum sensing. A range of unique quantum constraints are identified, including decoherence timing, fidelity requirements, and the interplay between quantum and classical error probabilities. Protocol adaptations extend cellular connection management to incorporate entanglement generation, distribution, and handover procedures, expanding the Quantum Internet to the cellular wireless.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14731v3</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petar Popovski, \v{C}edomir Stefanovi\'c, Beatriz Soret, Israel Leyva-Mayorga, Shashi Raj Pandey, Ren\'e B{\o}dker Christensen, Jakob Kaltoft S{\o}ndergaard, Kristian Skafte Jensen, Thomas Garm Pedersen, Angela Sara Cacciapuoti, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems: An Experimental Validation with Industrial Bearing Fault Detection</title>
      <link>https://arxiv.org/abs/2510.03807</link>
      <description>arXiv:2510.03807v2 Announce Type: replace 
Abstract: Current Cyber-Physical Systems (CPS) integrated with Digital Twin (DT) technology face critical limitations in achieving real-time performance for mission-critical industrial applications. Existing 5G-enabled systems suffer from latencies exceeding 10ms, which are inadequate for applications requiring sub-millisecond response times, such as autonomous industrial control and predictive maintenance. This research aims to develop and validate a 6G-enabled Digital Twin framework that achieves ultra-low latency communication and real-time synchronization between physical industrial assets and their digital counterparts, specifically targeting bearing fault detection as a critical industrial use case. The proposed framework integrates terahertz communications (0.1-1 THz), intelligent reflecting surfaces, and edge artificial intelligence within a five-layer architecture. Experimental validation was conducted using the Case Western Reserve University (CWRU) bearing dataset, implementing comprehensive feature extraction (15 time and frequency domain features) and Random Forest classification algorithms. The system performance was evaluated against traditional WiFi-6 and 5G networks across multiple metrics, including classification accuracy, end-to-end latency, and scalability. It achieved 97.7% fault classification accuracy with 0.8ms end-to-end latency, representing a 15.6x improvement over WiFi-6 (12.5ms) and 5.25x improvement over 5G (4.2ms) networks. The system demonstrated superior scalability with sub-linear processing time growth and maintained consistent performance across four bearing fault categories (normal, inner race, outer race, and ball faults) with macro-averaged F1-scores exceeding 97%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03807v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vaskar Chakma, Wooyeol Choi</dc:creator>
    </item>
    <item>
      <title>URLLC for 6G Enabled Industry 5.0: A Taxonomy of Architectures, Cross Layer Techniques, and Time Critical Applications</title>
      <link>https://arxiv.org/abs/2510.08080</link>
      <description>arXiv:2510.08080v2 Announce Type: replace 
Abstract: The evolution from Industry 4.0 to Industry 5.0 introduces stringent requirements for ultra reliable low latency communication (URLLC) to support human centric, intelligent, and resilient industrial systems. Sixth-generation (6G) wireless networks aim to meet these requirements through sub-millisecond end-to-end delays, microsecond level jitter, and near perfect reliability, enabled by advances such as terahertz (THz) communication, reconfigurable intelligent surfaces (RIS), multi-access edge computing (MEC), and AI driven cross layer optimization. This paper presents a comprehensive review of URLLC solutions for 6G enabled industry 5.0, organized into a structured taxonomy including application domains, key technical enablers, design challenges, and performance enhancements. The survey examines emerging approaches, including digital twin integration, AI/ML based resource orchestration, Network Function Virtualization (NFV) enabled service function chaining, and cross domain networking, while mapping them to critical industrial scenarios such as smart manufacturing, connected healthcare, autonomous mobility, remote control, and next-generation mobile networks. Performance trade-offs between latency, reliability, scalability, and energy efficiency are analyzed in the context of representative state-of-the-art studies. Finally, the paper identifies open challenges and outlines future research directions to realize deterministic, secure, and sustainable URLLC architectures for Industry 5.0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08080v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdikarim Mohamed Ibrahim, Rosdiadee Nordin, Yahya S. M. Khamayseh, Angela Amphawan, Muhammed Basheer Jasser</dc:creator>
    </item>
    <item>
      <title>FAST: An Efficient Scheduler for All-to-All GPU Communication</title>
      <link>https://arxiv.org/abs/2505.09764</link>
      <description>arXiv:2505.09764v2 Announce Type: replace-cross 
Abstract: All-to-All(v) communication is a critical primitive in modern machine learning workloads, particularly mixture-of-experts (MoE) models. Unfortunately, efficient scheduling is challenging due to workload skew, heterogeneous two-tier fabrics, and incast congestion, compounded by the dynamic nature of MoE workloads, where traffic shifts every few hundred milliseconds. Existing schedulers are hardly scalable, incurring seconds to hours of synthesis time, making them impractical. We present FAST, an efficient All-to-All(v) scheduler. FAST addresses skew through intra-server rebalancing and enforces balanced, one-to-one scale-out transfers that avoid incast. Evaluated extensively on both NVIDIA H200 and AMD MI300X clusters, FAST consistently outperforms state-of-the-art solutions on skewed workloads while reducing synthesis time by orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09764v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiran Lei, Dongjoo Lee, Liangyu Zhao, Daniar Kurniawan, Chanmyeong Kim, Heetaek Jeong, Changsu Kim, Hyeonseong Choi, Liangcheng Yu, Arvind Krishnamurthy, Justine Sherry, Eriko Nurvitadhi</dc:creator>
    </item>
  </channel>
</rss>
