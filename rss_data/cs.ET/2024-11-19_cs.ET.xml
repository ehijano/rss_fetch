<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Nov 2024 02:48:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Classical optimization with imaginary time block encoding on quantum computers: The MaxCut problem</title>
      <link>https://arxiv.org/abs/2411.10737</link>
      <description>arXiv:2411.10737v1 Announce Type: cross 
Abstract: Finding ground state solutions of diagonal Hamiltonians is relevant for both theoretical as well as practical problems of interest in many domains such as finance, physics and computer science. These problems are typically very hard to tackle by classical computing and quantum computing could help in speeding up computations and efficiently tackling larger problems. Here we use imaginary time evolution through a new block encoding scheme to obtain the ground state of such problems and apply our method to MaxCut as an illustration. Our method, which for simplicity we call ITE-BE, requires no variational parameter optimization as all the parameters in the procedure are expressed as analytical functions of the couplings of the Hamiltonian. We demonstrate that our method can be successfully combined with other quantum algorithms such as quantum approximate optimization algorithm (QAOA). We find that the QAOA ansatz increases the post-selection success of ITE-BE, and shallow QAOA circuits, when boosted with ITE-BE, achieve better performance than deeper QAOA circuits. For the special case of the transverse initial state, we adapt our block encoding scheme to allow for a deterministic application of the first layer of the circuit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10737v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dawei Zhong, Akhil Francis, Ermal Rrapaj</dc:creator>
    </item>
    <item>
      <title>Forecasting the risk of software choices: A model to foretell security vulnerabilities from library dependencies and source code evolution</title>
      <link>https://arxiv.org/abs/2411.11202</link>
      <description>arXiv:2411.11202v1 Announce Type: cross 
Abstract: Software security mainly studies vulnerability detection: is my code vulnerable today? This hinders risk estimation, so new approaches are emerging to forecast the occurrence of future vulnerabilities. While useful, these approaches are coarse-grained and hard to employ for project-specific technical decisions. We introduce a model capable of vulnerability forecasting at library level. Formalising source-code evolution in time together with library dependency, our model can estimate the probability that a software project faces a CVE disclosure in a future time window. Our approach is white-box and lightweight, which we demonstrate via experiments involving 1255 CVEs and 768 Java libraries, made public as an open-source artifact. Besides probabilities estimation, e.g. to plan software updates, this formal model can be used to detect security-sensitive points in a project, or measure the health of a development ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11202v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Carlos E. Budde, Ranindya Paramitha, Fabio Massacci</dc:creator>
    </item>
    <item>
      <title>Closed-loop multi-step planning with innate physics knowledge</title>
      <link>https://arxiv.org/abs/2411.11510</link>
      <description>arXiv:2411.11510v1 Announce Type: cross 
Abstract: We present a hierarchical framework to solve robot planning as an input control problem. At the lowest level are temporary closed control loops, ("tasks"), each representing a behaviour, contingent on a specific sensory input and therefore temporary. At the highest level, a supervising "Configurator" directs task creation and termination. Here resides "core" knowledge as a physics engine, where sequences of tasks can be simulated. The Configurator encodes and interprets simulation results,based on which it can choose a sequence of tasks as a plan. We implement this framework on a real robot and test it in an overtaking scenario as proof-of-concept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11510v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulia Lafratta, Bernd Porr, Christopher Chandler, Alice Miller</dc:creator>
    </item>
    <item>
      <title>Quantum Buffer Design Using Petri Nets</title>
      <link>https://arxiv.org/abs/2408.08369</link>
      <description>arXiv:2408.08369v2 Announce Type: replace 
Abstract: This paper introduces a simplified quantum Petri net (QPN) model and uses this model to generalize classical SISO, SIMO, MISO, MIMO and priority buffers to their quantum counterparts. It provides a primitive storage element, namely a quantum S-R flip-flop design using quantum CNOT and SWAP gates that can be replicated to obtain a quantum register for any given number of qubits. The aforementioned quantum buffers are then obtained using the simplified QPN model and quantum registers. $\!\!$The quantum S-R flip-flop and quantum buffer designs have been tested using OpenQASM and Qiskit on IBM quantum computers and simulators and the results validate the presented quantum S-R flip-flop and buffer designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08369v2</guid>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Syed Asad Shah, A. Yavuz Oru\c{c}</dc:creator>
    </item>
    <item>
      <title>UniTraj: Learning a Universal Trajectory Foundation Model from Billion-Scale Worldwide Traces</title>
      <link>https://arxiv.org/abs/2411.03859</link>
      <description>arXiv:2411.03859v2 Announce Type: replace 
Abstract: Human trajectory modeling is essential for deciphering movement patterns and supporting advanced applications across various domains. However, existing methods are often tailored to specific tasks and regions, resulting in limitations related to task specificity, regional dependency, and data quality sensitivity. Addressing these challenges requires a universal human trajectory foundation model capable of generalizing and scaling across diverse tasks and geographic contexts. To this end, we propose UniTraj, a Universal human Trajectory foundation model that is task-adaptive, region-independent, and highly generalizable. To further enhance performance, we construct WorldTrace, the first large-scale, high-quality, globally distributed dataset sourced from open web platforms, encompassing 2.45 million trajectories with billions of points across 70 countries. Through multiple resampling and masking strategies designed for pre-training, UniTraj effectively overcomes geographic and task constraints, adapting to heterogeneous data quality. Extensive experiments across multiple trajectory analysis tasks and real-world datasets demonstrate that UniTraj consistently outperforms existing approaches in terms of scalability and adaptability. These results underscore the potential of UniTraj as a versatile, robust solution for a wide range of trajectory analysis applications, with WorldTrace serving as an ideal but non-exclusive foundation for training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03859v2</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuanshao Zhu, James Jianqiao Yu, Xiangyu Zhao, Xuetao Wei, Yuxuan Liang</dc:creator>
    </item>
    <item>
      <title>Towards Evaluating Large Language Models for Graph Query Generation</title>
      <link>https://arxiv.org/abs/2411.08449</link>
      <description>arXiv:2411.08449v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are revolutionizing the landscape of Generative Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging rapidly. However, when applied to database technologies, specifically query generation for graph databases and Knowledge Graphs (KGs), LLMs still face significant challenges. While research on LLM-driven query generation for Structured Query Language (SQL) exists, similar systems for graph databases remain underdeveloped. This paper presents a comparative study addressing the challenge of generating Cypher queries a powerful language for interacting with graph databases using open-access LLMs. We rigorously evaluate several LLM agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT) reasoning. Our empirical analysis of query generation accuracy reveals that Claude Sonnet 3.5 outperforms its counterparts in this specific domain. Further, we highlight promising future research directions to address the identified limitations and advance LLM-driven query generation for graph databases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08449v2</guid>
      <category>cs.ET</category>
      <category>cs.CL</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siraj Munir, Alessandro Aldini</dc:creator>
    </item>
    <item>
      <title>Grover Speedup from Many Forms of the Zeno Effect</title>
      <link>https://arxiv.org/abs/2305.11146</link>
      <description>arXiv:2305.11146v5 Announce Type: replace-cross 
Abstract: It has previously been established that adiabatic quantum computation, operating based on a continuous Zeno effect due to dynamical phases between eigenstates, is able to realise an optimal Grover-like quantum speedup. In other words, is able to solve an unstructured search problem with the same $\sqrt{N}$ scaling as Grover's original algorithm. A natural question is whether other manifestations of the Zeno effect can also support an optimal speedup in a physically realistic model (through direct analogue application rather than indirectly by supporting a universal gateset). In this paper we show that they can support such a speedup, whether due to measurement, decoherence, or even decay of the excited state into a computationally useless state. Our results also suggest a wide variety of methods to realise speedup which do not rely on Zeno behaviour. We group these algorithms into three families to facilitate a structured understanding of how speedups can be obtained: one based on phase kicks, containing adiabatic computation and continuous-time quantum walks; one based on dephasing and measurement; and finally one based on destruction of the amplitude within the excited state, for which we are not aware of any previous results. These results suggest that there may be exciting opportunities for new paradigms of analog quantum computing based on these effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.11146v5</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesse Berwald, Nick Chancellor, Raouf Dridi</dc:creator>
    </item>
    <item>
      <title>HATT: Hamiltonian Adaptive Ternary Tree for Optimizing Fermion-to-Qubit Mapping</title>
      <link>https://arxiv.org/abs/2409.02010</link>
      <description>arXiv:2409.02010v2 Announce Type: replace-cross 
Abstract: This paper introduces the Hamiltonian-Adaptive Ternary Tree (HATT) framework to compile optimized Fermion-to-qubit mapping for specific Fermionic Hamiltonians. In the simulation of Fermionic quantum systems, efficient Fermion-to-qubit mapping plays a critical role in transforming the Fermionic system into a qubit system. HATT utilizes ternary tree mapping and a bottom-up construction procedure to generate Hamiltonian aware Fermion-to-qubit mapping to reduce the Pauli weight of the qubit Hamiltonian, resulting in lower quantum simulation circuit overhead. Additionally, our optimizations retain the important vacuum state preservation property in our Fermion-to-qubit mapping and reduce the complexity of our algorithm from $O(N^4)$ to $O(N^3)$. Evaluations and simulations of various Fermionic systems demonstrate $5\sim20\%$ reduction in Pauli weight, gate count, and circuit depth, alongside excellent scalability to larger systems. Experiments on the Ionq quantum computer also show the advantages of our approach in noise resistance in quantum simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02010v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Liu, Kevin Yao, Jonathan Hong, Julien Froustey, Ermal Rrapaj, Costin Iancu, Gushu Li, Yunong Shi</dc:creator>
    </item>
    <item>
      <title>Fault-Tolerant Masked Matrix Accumulation using Bulk Bitwise In-Memory Engines</title>
      <link>https://arxiv.org/abs/2409.10136</link>
      <description>arXiv:2409.10136v2 Announce Type: replace-cross 
Abstract: Big data processing has exposed the limits of compute-centric hardware acceleration due to the memory-to-processor bandwidth bottleneck. Consequently, there has been a shift towards memory-centric architectures, leveraging substantial compute parallelism by processing using the memory elements directly. Computing-in-memory (CIM) proposals for both conventional and emerging memory technologies often target massively parallel operations. However, current CIM solutions face significant challenges. For emerging data-intensive applications, such as advanced machine learning techniques and bioinformatics, where matrix multiplication is a key primitive, memristor crossbars suffer from limited write endurance and expensive write operations. In contrast, while DRAM-based solutions have successfully demonstrated multiplication using additions, they remain prohibitively slow. This paper introduces Count2Multiply, a technology-agnostic digital-CIM method for performing integer-binary and integer-integer matrix multiplications using high-radix, massively parallel counting implemented with bitwise logic operations. In addition, Count2Multiply is designed with fault tolerance in mind and leverages traditional scalable row-wise error correction codes, such as Hamming and BCH codes, to protect against the high error rates of existing CIM designs. We demonstrate Count2Multiply with a detailed application to CIM in conventional DRAM due to its ubiquity and high endurance. We also explore the acceleration potential of racetrack memories due to their shifting properties, which are natural for Count2Multiply, and their high endurance. Compared to the state-of-the-art in-DRAM method, Count2Multiply achieves up to 10x speedup, 3.8x higher GOPS/Watt, and 1.4x higher GOPS/area, while the RTM counterpart offers gains of 10x, 57x, and 3.8x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10136v2</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Paulo Cardoso de Lima, Benjamin Franklin Morris III, Asif Ali Khan, Jeronimo Castrillon, Alex K. Jones</dc:creator>
    </item>
  </channel>
</rss>
