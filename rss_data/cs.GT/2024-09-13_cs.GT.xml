<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2024 04:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Static Pricing for Single Sample Multi-unit Prophet Inequalities</title>
      <link>https://arxiv.org/abs/2409.07719</link>
      <description>arXiv:2409.07719v1 Announce Type: new 
Abstract: In this paper, we study $k$-unit single sample prophet inequalities. A seller has $k$ identical, indivisible items to sell. A sequence of buyers arrive one-by-one, with each buyer's private value for the item, $X_i$, revealed to the seller when they arrive. While the seller is unaware of the distribution from which $X_i$ is drawn, they have access to a single sample, $Y_i$ drawn from the same distribution as $X_i$. What strategies can the seller adopt so as to maximize social welfare?
  Previous work has demonstrated that when $k = 1$, if the seller sets a price equal to the maximum of the samples, they can achieve a competitive ratio of $\frac{1}{2}$ of the social welfare, and recently Pashkovich and Sayutina established an analogous result for $k = 2$. In this paper, we prove that for $k \geq 3$, setting a (static) price equal to the $k^{\text{th}}$ largest sample also obtains a competitive ratio of $\frac{1}{2}$, resolving a conjecture Pashkovich and Sayutina pose.
  We then consider the situation where $k$ is large. We demonstrate that setting a price equal to the $(k-\sqrt{2k\log k})^{\text{th}}$ largest sample obtains a competitive ratio of $1 - \sqrt{\frac{2\log k}{k}} - o\left(\sqrt{\frac{\log k}{k}}\right)$, and that this is the optimal possible ratio achievable with a static pricing scheme that sets one of the samples as a price.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07719v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pranav Nuti, Peter Westbrook</dc:creator>
    </item>
    <item>
      <title>Distributed Learning Dynamics Converging to the Core of $B$-Matchings</title>
      <link>https://arxiv.org/abs/2409.07754</link>
      <description>arXiv:2409.07754v1 Announce Type: new 
Abstract: $B$-matching is a special case of matching problems where nodes can join multiple matchings with the degree of each node constrained by an upper bound, the node's $B$-value. The core solution of a bipartite $B$-matching is both a matching between the agents respecting the upper bound constraint and an allocation of the value of the edge among its nodes such that no group of agents can deviate and collectively gain higher allocation. We present two learning dynamics that converge to the core of the bipartite $B$-matching problems. The first dynamics are centralized dynamics in the nature of the Hungarian method, which converge to the core in a polynomial time. The second dynamics are distributed dynamics, which converge to the core with probability one. For the distributed dynamics, a node maintains only a state consisting of (i) its aspiration levels for all of its possible matches and (ii) the matches, if any, to which it belongs. The node does not keep track of its history nor is it aware of the environment state. In each stage, a randomly activated node proposes to form a new match and changes its aspiration based on the success or failure of its proposal. At this stage, the proposing node inquires about the aspiration of the agent it wants to match with to calculate the feasibility of the match. The environment matching structure changes whenever a proposal succeeds. A state is absorbing for the distributed dynamics if and only if it is in the core of the $B$-matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07754v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aya Hamed, Jeff S. Shamma</dc:creator>
    </item>
    <item>
      <title>Selling Joint Ads: A Regret Minimization Perspective</title>
      <link>https://arxiv.org/abs/2409.07819</link>
      <description>arXiv:2409.07819v1 Announce Type: new 
Abstract: Motivated by online retail, we consider the problem of selling one item (e.g., an ad slot) to two non-excludable buyers (say, a merchant and a brand). This problem captures, for example, situations where a merchant and a brand cooperatively bid in an auction to advertise a product, and both benefit from the ad being shown. A mechanism collects bids from the two and decides whether to allocate and which payments the two parties should make. This gives rise to intricate incentive compatibility constraints, e.g., on how to split payments between the two parties. We approach the problem of finding a revenue-maximizing incentive-compatible mechanism from an online learning perspective; this poses significant technical challenges. First, the action space (the class of all possible mechanisms) is huge; second, the function that maps mechanisms to revenue is highly irregular, ruling out standard discretization-based approaches.
  In the stochastic setting, we design an efficient learning algorithm achieving a regret bound of $O(T^{3/4})$. Our approach is based on an adaptive discretization scheme of the space of mechanisms, as any non-adaptive discretization fails to achieve sublinear regret. In the adversarial setting, we exploit the non-Lipschitzness of the problem to prove a strong negative result, namely that no learning algorithm can achieve more than half of the revenue of the best fixed mechanism in hindsight. We then consider the $\sigma$-smooth adversary; we construct an efficient learning algorithm that achieves a regret bound of $O(T^{2/3})$ and builds on a succinct encoding of exponentially many experts. Finally, we prove that no learning algorithm can achieve less than $\Omega(\sqrt T)$ regret in both the stochastic and the smooth setting, thus narrowing the range where the minimax regret rates for these two problems lie.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07819v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gagan Aggarwal, Ashwinkumar Badanidiyuru, Paul D\"utting, Federico Fusco</dc:creator>
    </item>
    <item>
      <title>Multi-Robot Coordination Induced in Hazardous Environments through an Adversarial Graph-Traversal Game</title>
      <link>https://arxiv.org/abs/2409.08222</link>
      <description>arXiv:2409.08222v1 Announce Type: new 
Abstract: This paper presents a game theoretic formulation of a graph traversal problem, with applications to robots moving through hazardous environments in the presence of an adversary, as in military and security applications. The blue team of robots moves in an environment modeled by a time-varying graph, attempting to reach some goal with minimum cost, while the red team controls how the graph changes to maximize the cost. The problem is formulated as a stochastic game, so that Nash equilibrium strategies can be computed numerically. Bounds are provided for the game value, with a guarantee that it solves the original problem. Numerical simulations demonstrate the results and the effectiveness of this method, particularly showing the benefit of mixing actions for both players, as well as beneficial coordinated behavior, where blue robots split up and/or synchronize to traverse risky edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08222v1</guid>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Berneburg, Xuan Wang, Xuesu Xiao, Daigo Shishika</dc:creator>
    </item>
    <item>
      <title>Communication Separations for Truthful Auctions: Breaking the Two-Player Barrier</title>
      <link>https://arxiv.org/abs/2409.08241</link>
      <description>arXiv:2409.08241v1 Announce Type: new 
Abstract: We study the communication complexity of truthful combinatorial auctions, and in particular the case where valuations are either subadditive or single-minded, which we denote with $\mathsf{SubAdd}\cup\mathsf{SingleM}$. We show that for three bidders with valuations in $\mathsf{SubAdd}\cup\mathsf{SingleM}$, any deterministic truthful mechanism that achieves at least a $0.366$-approximation requires $\exp(m)$ communication. In contrast, a natural extension of [Fei09] yields a non-truthful $\mathrm{poly}(m)$-communication protocol that achieves a $\frac{1}{2}$-approximation, demonstrating a gap between the power of truthful mechanisms and non-truthful protocols for this problem.
  Our approach follows the taxation complexity framework laid out in [Dob16b], but applies this framework in a setting not encompassed by the techniques used in past work. In particular, the only successful prior application of this framework uses a reduction to simultaneous protocols which only applies for two bidders [AKSW20], whereas our three-player lower bounds are stronger than what can possibly arise from a two-player construction (since a trivial truthful auction guarantees a $\frac{1}{2}$-approximation for two players).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08241v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiri Ron, Clayton Thomas, S. Matthew Weinberg, Qianfan Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic Principal-Agent Problems: Efficient Computation and Learning</title>
      <link>https://arxiv.org/abs/2306.03832</link>
      <description>arXiv:2306.03832v3 Announce Type: replace 
Abstract: We introduce a stochastic principal-agent model. A principal and an agent interact in a stochastic environment, each privy to observations about the state not available to the other. The principal has the power of commitment, both to elicit information from the agent and to provide signals about her own information. The players communicate with each other and then select actions independently. Each of them receives a payoff based on the state and their joint action, and the environment transitions to a new state. The interaction continues over a finite time horizon. Both players are far-sighted, aiming to maximize their total payoffs over the time horizon. The model encompasses as special cases extensive-form games (EFGs) and stochastic games of incomplete information, partially observable Markov decision processes (POMDPs), as well as other forms of sequential principal-agent interactions, including Bayesian persuasion and automated mechanism design problems.
  We consider both the computation and learning of the principal's optimal policy. Since the general problem, which subsumes POMDPs, is intractable, we explore algorithmic solutions under hindsight observability, where the state and the interaction history are revealed at the end of each step. Though the problem becomes more amenable under this condition, the number of possible histories remains exponential in the length of the time horizon, making approaches for EFG-based models infeasible. We present an efficient algorithm based on the inducible value sets. The algorithm computes an $\epsilon$-approximate optimal policy in time polynomial in $1/\epsilon$. Additionally, we show an efficient learning algorithm for an episodic reinforcement learning setting where the transition probabilities are unknown. The algorithm guarantees sublinear regret $\tilde{O}(T^{2/3})$ for both players over $T$ episodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03832v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiarui Gan, Rupak Majumdar, Debmalya Mandal, Goran Radanovic</dc:creator>
    </item>
    <item>
      <title>Strategic Routing and Scheduling for Evacuations</title>
      <link>https://arxiv.org/abs/2401.04371</link>
      <description>arXiv:2401.04371v2 Announce Type: replace 
Abstract: Evacuation planning is an essential part of disaster management where the goal is to relocate people under imminent danger to safety. However, finding jointly optimal evacuation routes and schedule that minimizes the average evacuation time or evacuation completion time, is a computationally hard problem. As a result, large-scale evacuation routing and scheduling continues to be a challenge. In this paper, we present a game-theoretic approach to tackle this problem. We start by formulating a strategic routing and scheduling game, named the Evacuation Game: Routing and Scheduling (EGRES), where players choose their route and time of departure. We show that: (i) every instance of EGRES has at least one pure strategy Nash equilibrium, and (ii) an optimal outcome in an instance will always be an equilibrium in that instance. We then provide bounds on how bad an equilibrium can be compared to an optimal outcome. Additionally, we present a polynomial-time algorithm, the Sequential Action Algorithm (SAA), for finding equilibria in a given instance under a special condition. We use Virginia Beach City in Virginia, and Harris County in Houston, Texas as study areas and construct two EGRES instances. Our results show that, by utilizing SAA, we can efficiently find equilibria in these instances that have social objective close to the optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04371v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kazi Ashik Islam, Da Qi Chen, Madhav Marathe, Henning Mortveit, Samarth Swarup, Anil Vullikanti</dc:creator>
    </item>
    <item>
      <title>Private Private Information</title>
      <link>https://arxiv.org/abs/2112.14356</link>
      <description>arXiv:2112.14356v4 Announce Type: replace-cross 
Abstract: Private signals model noisy information about an unknown state. Although these signals are called "private," they may still carry information about each other. Our paper introduces the concept of private private signals, which contain information about the state but not about other signals. To achieve privacy, signal quality may need to be sacrificed. We study the informativeness of private private signals and characterize those that are optimal in the sense that they cannot be made more informative without violating privacy. We discuss implications for privacy in recommendation systems, information design, causal inference, and mechanism design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.14356v4</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin He, Fedor Sandomirskiy, Omer Tamuz</dc:creator>
    </item>
    <item>
      <title>Pure-Circuit: Tight Inapproximability for PPAD</title>
      <link>https://arxiv.org/abs/2209.15149</link>
      <description>arXiv:2209.15149v3 Announce Type: replace-cross 
Abstract: The current state-of-the-art methods for showing inapproximability in PPAD arise from the $\varepsilon$-Generalized-Circuit ($\varepsilon$-GCircuit) problem. Rubinstein (2018) showed that there exists a small unknown constant $\varepsilon$ for which $\varepsilon$-GCircuit is PPAD-hard, and subsequent work has shown hardness results for other problems in PPAD by using $\varepsilon$-GCircuit as an intermediate problem.
  We introduce Pure-Circuit, a new intermediate problem for PPAD, which can be thought of as $\varepsilon$-GCircuit pushed to the limit as $\varepsilon \rightarrow 1$, and we show that the problem is PPAD-complete. We then prove that $\varepsilon$-GCircuit is PPAD-hard for all $\varepsilon &lt; 0.1$ by a reduction from Pure-Circuit, and thus strengthen all prior work that has used GCircuit as an intermediate problem from the existential-constant regime to the large-constant regime.
  We show that stronger inapproximability results can be derived by reducing directly from Pure-Circuit. In particular, we prove tight inapproximability results for computing approximate Nash equilibria and approximate well-supported Nash equilibria in graphical games, for finding approximate well-supported Nash equilibria in polymatrix games, and for finding approximate equilibria in threshold games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.15149v3</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3678166</arxiv:DOI>
      <dc:creator>Argyrios Deligkas, John Fearnley, Alexandros Hollender, Themistoklis Melissourgos</dc:creator>
    </item>
    <item>
      <title>On Time-Inconsistency in Mean Field Games</title>
      <link>https://arxiv.org/abs/2312.07770</link>
      <description>arXiv:2312.07770v2 Announce Type: replace-cross 
Abstract: We investigate an infinite-horizon time-inconsistent mean-field game (MFG) in a discrete time setting. We first present a classic equilibrium for the MFG and its associated existence result. This classic equilibrium aligns with the conventional equilibrium concept studied in MFG literature when the context is time-consistent. Then we demonstrate that while this equilibrium produces an approximate optimal strategy when applied to the related $N$-agent games, it does so solely in a precommitment sense. Therefore, it cannot function as a genuinely approximate equilibrium strategy from the perspective of a sophisticated agent within the $N$-agent game. To address this limitation, we propose a new consistent equilibrium concept in both the MFG and the $N$-agent game. We show that a consistent equilibrium in the MFG can indeed function as an approximate consistent equilibrium in the $N$-agent game. Additionally, we analyze the convergence of consistent equilibria for $N$-agent games toward a consistent MFG equilibrium as $N$ tends to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07770v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Zhenhua Wang</dc:creator>
    </item>
    <item>
      <title>Rethinking Teacher-Student Curriculum Learning through the Cooperative Mechanics of Experience</title>
      <link>https://arxiv.org/abs/2404.03084</link>
      <description>arXiv:2404.03084v2 Announce Type: replace-cross 
Abstract: Teacher-Student Curriculum Learning (TSCL) is a curriculum learning framework that draws inspiration from human cultural transmission and learning. It involves a teacher algorithm shaping the learning process of a learner algorithm by exposing it to controlled experiences. Despite its success, understanding the conditions under which TSCL is effective remains challenging. In this paper, we propose a data-centric perspective to analyze the underlying mechanics of the teacher-student interactions in TSCL. We leverage cooperative game theory to describe how the composition of the set of experiences presented by the teacher to the learner, as well as their order, influences the performance of the curriculum that is found by TSCL approaches. To do so, we demonstrate that for every TSCL problem, an equivalent cooperative game exists, and several key components of the TSCL framework can be reinterpreted using game-theoretic principles. Through experiments covering supervised learning, reinforcement learning, and classical games, we estimate the cooperative values of experiences and use value-proportional curriculum mechanisms to construct curricula, even in cases where TSCL struggles. The framework and experimental setup we present in this work represents a novel foundation for a deeper exploration of TSCL, shedding light on its underlying mechanisms and providing insights into its broader applicability in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03084v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manfred Diaz, Liam Paull, Andrea Tacchetti</dc:creator>
    </item>
    <item>
      <title>Permissible four-strategy quantum extensions of classical games</title>
      <link>https://arxiv.org/abs/2405.07380</link>
      <description>arXiv:2405.07380v3 Announce Type: replace-cross 
Abstract: The study focuses on strategic-form games extended in the Eisert-Wilkens-Lewenstein scheme by two unitary operations. Conditions are determined under which the pair of unitary operators, along with classical strategies, form a game invariant under isomorphic transformations of the input classical game. These conditions are then applied to determine these operators, resulting in five main classes of games satisfying the isomorphism criterion, and a theorem is proved providing a practical criterion for this isomorphism. The interdependencies between different classes of extensions are identified, including limit cases in which one class transforms into another.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07380v3</guid>
      <category>quant-ph</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Fr\k{a}ckiewicz, Anna Gorczyca-Goraj, Marek Szopa</dc:creator>
    </item>
    <item>
      <title>Evolutionary mechanisms that promote cooperation may not promote social welfare</title>
      <link>https://arxiv.org/abs/2408.05373</link>
      <description>arXiv:2408.05373v2 Announce Type: replace-cross 
Abstract: Understanding the emergence of prosocial behaviours among self-interested individuals is an important problem in many scientific disciplines. Various mechanisms have been proposed to explain the evolution of such behaviours, primarily seeking the conditions under which a given mechanism can induce highest levels of cooperation. As these mechanisms usually involve costs that alter individual payoffs, it is however possible that aiming for highest levels of cooperation might be detrimental for social welfare -- the later broadly defined as the total population payoff, taking into account all costs involved for inducing increased prosocial behaviours. Herein, by comparatively analysing the social welfare and cooperation levels obtained from stochastic evolutionary models of two well-established mechanisms of prosocial behaviour, namely, peer and institutional incentives, we demonstrate exactly that. We show that the objectives of maximising cooperation levels and the objectives of maximising social welfare are often misaligned. We argue for the need of adopting social welfare as the main optimisation objective when designing and implementing evolutionary mechanisms for social and collective goods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05373v2</guid>
      <category>math.DS</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>The Anh Han, Manh Hong Duong, Matjaz Perc</dc:creator>
    </item>
  </channel>
</rss>
