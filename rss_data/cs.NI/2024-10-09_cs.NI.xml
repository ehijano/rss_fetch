<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Oct 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Minimally Intrusive Access Management to Content Delivery Networks based on Performance Models and Access Patterns</title>
      <link>https://arxiv.org/abs/2410.05642</link>
      <description>arXiv:2410.05642v1 Announce Type: new 
Abstract: This paper presents an approach to managing access to Content Delivery Networks (CDNs), focusing on combating the misuse of tokens through performance analysis and statistical access patterns. In particular, we explore the impact of token sharing on the content delivery infrastructure, proposing the definition of acceptable request limits to detect and block abnormal accesses. Additionally, we introduce countermeasures against piracy, such as degrading the quality of service for pirate users to discourage them from illegal sharing, and using queuing models to quantify system performance in different piracy scenarios. Adopting these measures can improve the consistency and efficiency of CDN access and cost management, protecting the infrastructure and the legitimate user experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05642v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lenise M. V. Rodrigues, Daniel Sadoc Menasch\'e, Arthur Serra, Antonio A. de Arag\~ao Rocha</dc:creator>
    </item>
    <item>
      <title>A$^3$L-FEC: Age-Aware Application Layer Forward Error Correction Flow Control</title>
      <link>https://arxiv.org/abs/2410.05852</link>
      <description>arXiv:2410.05852v1 Announce Type: new 
Abstract: Age of Information (AoI) is a metric and KPI that has been developed for measuring and controlling data freshness. Optimization of AoI in a real-life network requires adapting the rate and timing of transmissions to varying network conditions. The vast majority of previous research on the control of AoI has been theoretical, using idealized models which ignored certain implementation aspects. As such, there is still a gap between the research on AoI and real-world protocols. In this paper we present an effort toward closing this gap by introducing an age-aware flow control algorithm. The algorithm, Age-Aware Application Layer Forward Error Correction (A$^3$L-FEC), is a packet generation mechanism operating on top of the user datagram protocol (UDP). The purpose is to control peak Age of the end-to-end packet flow, specifically, to reduce the rate of what we call "Age Violations", that is, the events where the peak age exceeds a given threshold. Evaluations in Mininet-WiFi and MATLAB indicate that A$^3$L-FEC reduces age violations compared to two related protocols in the literature, namely TCP-BBR and ACP+.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05852v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sajjad Baghaee, Elif Uysal</dc:creator>
    </item>
    <item>
      <title>Content-based Wake-up for Energy-efficient and Timely Top-k IoT Sensing Data Retrieval</title>
      <link>https://arxiv.org/abs/2410.06026</link>
      <description>arXiv:2410.06026v1 Announce Type: new 
Abstract: Energy efficiency and information freshness are key requirements for sensor nodes serving Industrial Internet of Things (IIoT) applications, where a sink node collects informative and fresh data before a deadline, e.g., to control an external actuator. Content-based wake-up (CoWu) activates a subset of nodes that hold data relevant for the sink's goal, thereby offering an energy-efficient way to attain objectives related to information freshness. This paper focuses on a scenario where the sink collects fresh information on top-k values, defined as data from the nodes observing the k highest readings at the deadline. We introduce a new metric called top-k Query Age of Information (k-QAoI), which allows us to characterize the performance of CoWu by considering the characteristics of the physical process. Further, we show how to select the CoWu parameters, such as its timing and threshold, to attain both information freshness and energy efficiency. The numerical results reveal the effectiveness of the CoWu approach, which is able to collect top-k data with higher energy efficiency while reducing k-QAoI when compared to round-robin scheduling, especially when the number of nodes is large and the required size of k is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06026v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junya Shiraishi, Anders E. Kal{\o}r, Israel Leyva-Mayorga, Federico Chiariotti, Petar Popovski, Hiroyuki Yomo</dc:creator>
    </item>
    <item>
      <title>An Analysis of QUIC Connection Migration in the Wild</title>
      <link>https://arxiv.org/abs/2410.06066</link>
      <description>arXiv:2410.06066v1 Announce Type: new 
Abstract: As QUIC gains attention, more applications that leverage its capabilities are emerging. These include defenses against on-path IP tracking and traffic analysis. However, the deployment of the underlying required support for connection migration remains largely unexplored. This paper provides a comprehensive examination of the support of the QUIC connection migration mechanism over the Internet. We perform Internet-wide scans revealing that despite a rapid evolution in the deployment of QUIC on web servers, some of the most popular destinations do not support connection migration yet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06066v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aur\'elien Buchet, Cristel Pelsser</dc:creator>
    </item>
    <item>
      <title>SwiftQueue: Optimizing Low-Latency Applications with Swift Packet Queuing</title>
      <link>https://arxiv.org/abs/2410.06112</link>
      <description>arXiv:2410.06112v1 Announce Type: new 
Abstract: Low Latency, Low Loss, and Scalable Throughput (L4S), as an emerging router-queue management technique, has seen steady deployment in the industry. An L4S-enabled router assigns each packet to the queue based on the packet header marking. Currently, L4S employs per-flow queue selection, i.e. all packets of a flow are marked the same way and thus use the same queues, even though each packet is marked separately. However, this may hurt tail latency and latency-sensitive applications because transient congestion and queue buildups may only affect a fraction of packets in a flow.
  We present SwiftQueue, a new L4S queue-selection strategy in which a sender uses a novel per-packet latency predictor to pinpoint which packets likely have latency spikes or drops. The insight is that many packet-level latency variations result from complex interactions among recent packets at shared router queues. Yet, these intricate packet-level latency patterns are hard to learn efficiently by traditional models. Instead, SwiftQueue uses a custom Transformer, which is well-studied for its expressiveness on sequential patterns, to predict the next packet's latency based on the latencies of recently received ACKs. Based on the predicted latency of each outgoing packet, SwiftQueue's sender dynamically marks the L4S packet header to assign packets to potentially different queues, even within the same flow. Using real network traces, we show that SwiftQueue is 45-65% more accurate in predicting latency and its variations than state-of-art methods. Based on its latency prediction, SwiftQueue reduces the tail latency for L4S-enabled flows by 36-45%, compared with the existing L4S queue-selection method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06112v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddhant Ray, Xi Jiang, Jack Luo, Nick Feamster, Junchen Jiang</dc:creator>
    </item>
    <item>
      <title>Optimizing Integrated Terrestrial and Non-Terrestrial Networks Performance with Traffic-Aware Resource Management</title>
      <link>https://arxiv.org/abs/2410.06700</link>
      <description>arXiv:2410.06700v1 Announce Type: new 
Abstract: To address an ever-increasing demand for ubiquitous high-speed connectivity, mobile networks have intensified their deployment process. However, achieving this target has proven to be a challenge and has led to a surge in overall energy consumption. In recent years, non-terrestrial networks (NTNs) have been endorsed as a potential solution to these problems by complementing the coverage of the terrestrial network in areas with limited network deployment. To this end, this paper proposes an integrated terrestrial and non-terrestrial network (TN-NTN) that utilises the overall available communication resources to expand coverage and meet Quality of Service (QoS) requirements during high-traffic hours in any deployment scenario. Importantly, our framework allows to drastically reduce the terrestrial network energy consumption during low-traffic hours. Specifically, we introduce a novel radio resource management algorithm, BLASTER (Bandwidth SpLit, User ASsociation, and PowEr ContRol), which integrates bandwidth allocation, user equipment (UE) association, power control, and base station activation within the TN-NTN. This algorithm aims to optimize network resource allocation fairness and energy consumption dynamically, demonstrating new opportunities in deploying satellite networks in legacy cellular systems. Our study offers a comprehensive analysis of the integrated network model, emphasizing the effective balance between energy saving and QoS, and proposing practical solutions to meet the fluctuating traffic demands of cellular networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06700v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henri Alam, Antonio de Domenico, David L\'opez-P\'erez, Florian Kaltenberger</dc:creator>
    </item>
    <item>
      <title>VEC-Sim: A Simulation Platform for Evaluating Service Caching and Computation Offloading Policies in Vehicular Edge Networks</title>
      <link>https://arxiv.org/abs/2410.06934</link>
      <description>arXiv:2410.06934v1 Announce Type: new 
Abstract: Computer simulation platforms offer an alternative solution by emulating complex systems in a controlled manner. However, existing Edge Computing (EC) simulators, as well as general-purpose vehicular network simulators, are not tailored for VEC and lack dedicated support for modeling the distinct access pattern, entity mobility trajectory and other unique characteristics of VEC networks. To fill this gap, this paper proposes VEC-Sim, a versatile simulation platform for in-depth evaluation and analysis of various service caching and computation offloading policies in VEC networks. VEC-Sim incorporates realistic mechanisms to replicate real-world access patterns, including service feature vector, vehicle mobility modeling, evolving service popularity, new service upload and user preference shifts, etc. Moreover, its modular architecture and extensive Application Programming Interfaces (APIs) allow seamless integration of customized scheduling policies and user-defined metrics. A comprehensive evaluation of VEC-Sim's capabilities is undertaken in comparison to real-world ground truths. Results prove it to be accurate in reproducing classical scheduling algorithms and extremely effective in conducting case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06934v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu, Xiaolong Xu, Muhammad Bilal, Xiangwei Wang, Hao Cheng, Siyu Wu</dc:creator>
    </item>
    <item>
      <title>Radio signal propagation in 5G systems equipped with RISs (PL: Propagacja sygna{\l}u radiowego w systemach 5G wyposa\.zonych w matryce IPR)</title>
      <link>https://arxiv.org/abs/2410.06987</link>
      <description>arXiv:2410.06987v1 Announce Type: new 
Abstract: In this paper, the characteristics of radio signal propagation within the boundaries of the city of Poznan (Poland) are analyzed. The study considers the use of a Radio Access Network (RAN) of the 5th generation wireless system (5G NR - New Radio), which includes 8 base stations (BSs) utilizing Single Input Single Output (SISO) or Multiple Input Multiple Output (MIMO) antenna technology depending on the adopted configuration of network cells. Additionally, 15 reflecting arrays known as Reconfigurable Intelligent Surfaces (RISs) were placed in the studied area, and their impact on radio signal propagation at different suspension heights was taken into account.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06987v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.15199/59.2024.4.61</arxiv:DOI>
      <arxiv:journal_reference>Telecommunication Review - Telecommunication News, 2024, no. 4, pp. 280-283</arxiv:journal_reference>
      <dc:creator>Adam Samorzewski, Adrian Kliks</dc:creator>
    </item>
    <item>
      <title>An Intelligent Native Network Slicing Security Architecture Empowered by Federated Learning</title>
      <link>https://arxiv.org/abs/2410.05312</link>
      <description>arXiv:2410.05312v1 Announce Type: cross 
Abstract: Network Slicing (NS) has transformed the landscape of resource sharing in networks, offering flexibility to support services and applications with highly variable requirements in areas such as the next-generation 5G/6G mobile networks (NGMN), vehicular networks, industrial Internet of Things (IoT), and verticals. Although significant research and experimentation have driven the development of network slicing, existing architectures often fall short in intrinsic architectural intelligent security capabilities. This paper proposes an architecture-intelligent security mechanism to improve the NS solutions. We idealized a security-native architecture that deploys intelligent microservices as federated agents based on machine learning, providing intra-slice and architectural operation security for the Slicing Future Internet Infrastructures (SFI2) reference architecture. It is noteworthy that federated learning approaches match the highly distributed modern microservice-based architectures, thus providing a unifying and scalable design choice for NS platforms addressing both service and security. Using ML-Agents and Security Agents, our approach identified Distributed Denial-of-Service (DDoS) and intrusion attacks within the slice using generic and non-intrusive telemetry records, achieving an average accuracy of approximately $95.60\%$ in the network slicing architecture and $99.99\%$ for the deployed slice -- intra-slice. This result demonstrates the potential for leveraging architectural operational security and introduces a promising new research direction for network slicing architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05312v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.future.2024.107537</arxiv:DOI>
      <arxiv:journal_reference>Future Generation Computer Systems (FGCS); ISSN:0167-739X; 2024</arxiv:journal_reference>
      <dc:creator>Rodrigo Moreira, Rodolfo S. Villaca, Moises R. N. Ribeiro, Joberto S. B. Martins, Joao Henrique Correa, Tereza C. Carvalho, Flavio de Oliveira Silva</dc:creator>
    </item>
    <item>
      <title>FogROS2-PLR: Probabilistic Latency-Reliability For Cloud Robotics</title>
      <link>https://arxiv.org/abs/2410.05562</link>
      <description>arXiv:2410.05562v1 Announce Type: cross 
Abstract: Cloud robotics enables robots to offload computationally intensive tasks to cloud servers for performance, cost, and ease of management. However, the network and cloud computing infrastructure are not designed for reliable timing guarantees, due to fluctuating Quality-of-Service (QoS). In this work, we formulate an impossibility triangle theorem for: Latency reliability, Singleton server, and Commodity hardware. The LSC theorem suggests that providing replicated servers with uncorrelated failures can exponentially reduce the probability of missing a deadline. We present FogROS2-Probabilistic Latency Reliability (PLR) that uses multiple independent network interfaces to send requests to replicated cloud servers and uses the first response back. We design routing mechanisms to discover, connect, and route through non-default network interfaces on robots. FogROS2-PLR optimizes the selection of interfaces to servers to minimize the probability of missing a deadline. We conduct a cloud-connected driving experiment with two 5G service providers, demonstrating FogROS2-PLR effectively provides smooth service quality even if one of the service providers experiences low coverage and base station handover. We use 99 Percentile (P99) latency to evaluate anomalous long-tail latency behavior. In one experiment, FogROS2-PLR improves P99 latency by up to 3.7x compared to using one service provider. We deploy FogROS2-PLR on a physical Stretch 3 robot performing an indoor human-tracking task. Even in a fully covered Wi-Fi and 5G environment, FogROS2-PLR improves the responsiveness of the robot reducing mean latency by 36% and P99 latency by 33%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05562v1</guid>
      <category>cs.RO</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaiyuan Chen, Nan Tian, Christian Juette, Tianshuang Qiu, Liu Ren, John Kubiatowicz, Ken Goldberg</dc:creator>
    </item>
    <item>
      <title>Estimating the Number of HTTP/3 Responses in QUIC Using Deep Learning</title>
      <link>https://arxiv.org/abs/2410.06140</link>
      <description>arXiv:2410.06140v1 Announce Type: cross 
Abstract: QUIC, a new and increasingly used transport protocol, enhances TCP by providing better security, performance, and features like stream multiplexing. These features, however, also impose challenges for network middle-boxes that need to monitor and analyze web traffic. This paper proposes a novel solution for estimating the number of HTTP/3 responses in a given QUIC connection by an observer. This estimation reveals server behavior, client-server interactions, and data transmission efficiency, which is crucial for various applications such as designing a load balancing solution and detecting HTTP/3 flood attacks. The proposed scheme transforms QUIC connection traces into a sequence of images and trains machine learning (ML) models to predict the number of responses. Then, by aggregating images of a QUIC connection, an observer can estimate the total number of responses. As the problem is formulated as a discrete regression problem, we introduce a dedicated loss function. The proposed scheme is evaluated on a dataset of over seven million images, generated from $100,000$ traces collected from over $44,000$ websites over a four-month period, from various vantage points. The scheme achieves up to 97\% cumulative accuracy in both known and unknown web server settings and 92\% accuracy in estimating the total number of responses in unseen QUIC traces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06140v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Barak Gahtan, Robert J. Shahla, Reuven Cohen, Alex M. Bronstein</dc:creator>
    </item>
    <item>
      <title>Filtered Randomized Smoothing: A New Defense for Robust Modulation Classification</title>
      <link>https://arxiv.org/abs/2410.06339</link>
      <description>arXiv:2410.06339v1 Announce Type: cross 
Abstract: Deep Neural Network (DNN) based classifiers have recently been used for the modulation classification of RF signals. These classifiers have shown impressive performance gains relative to conventional methods, however, they are vulnerable to imperceptible (low-power) adversarial attacks. Some of the prominent defense approaches include adversarial training (AT) and randomized smoothing (RS). While AT increases robustness in general, it fails to provide resilience against previously unseen adaptive attacks. Other approaches, such as Randomized Smoothing (RS), which injects noise into the input, address this shortcoming by providing provable certified guarantees against arbitrary attacks, however, they tend to sacrifice accuracy.
  In this paper, we study the problem of designing robust DNN-based modulation classifiers that can provide provable defense against arbitrary attacks without significantly sacrificing accuracy. To this end, we first analyze the spectral content of commonly studied attacks on modulation classifiers for the benchmark RadioML dataset. We observe that spectral signatures of un-perturbed RF signals are highly localized, whereas attack signals tend to be spread out in frequency. To exploit this spectral heterogeneity, we propose Filtered Randomized Smoothing (FRS), a novel defense which combines spectral filtering together with randomized smoothing. FRS can be viewed as a strengthening of RS by leveraging the specificity (spectral Heterogeneity) inherent to the modulation classification problem. In addition to providing an approach to compute the certified accuracy of FRS, we also provide a comprehensive set of simulations on the RadioML dataset to show the effectiveness of FRS and show that it significantly outperforms existing defenses including AT and RS in terms of accuracy on both attacked and benign signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06339v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenhan Zhang, Meiyu Zhong, Ravi Tandon, Marwan Krunz</dc:creator>
    </item>
    <item>
      <title>netFound: Foundation Model for Network Security</title>
      <link>https://arxiv.org/abs/2310.17025</link>
      <description>arXiv:2310.17025v3 Announce Type: replace 
Abstract: Developing generalizable ML-based solutions for disparate learning problems in network security is highly desired. However, despite a rich history of applying ML to network security, most existing solutions lack generalizability. This lack of progress can be attributed to an overreliance on supervised learning techniques and the associated challenges of curating well-specified labeled training data. This paper addresses a fundamental gap by introducing a novel transformer-based network foundation model, netFound. We employ self-supervised learning techniques on abundant, unlabeled network telemetry data for pre-training. This pretrained model can subsequently be fine-tuned to create generalizable learning artifacts for disparate learning tasks, even when using commonly available but challenging labeled datasets that are sparse, noisy, and skewed. To realize this goal, netFound leverages various domain-specific attributes and constraints unique to network data (packet traces) by developing multi-modal embeddings, protocol-aware tokenization, data-driven token composition, and hierarchical transformers. Our results demonstrate that netFound's domain-specific design choices ensure that it (1) effectively captures the hidden networking context in production settings, (2) outperforms four different SOTA methods on five different learning tasks, and (3) is robust to both noisy labels and learning shortcuts -- critical for developing generalizable ML models in practical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17025v3</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Satyandra Guthula, Roman Beltiukov, Navya Battula, Wenbo Guo, Arpit Gupta</dc:creator>
    </item>
    <item>
      <title>5G cellular systems supported by UAVs, RESs, and RISs (PL: Systemy kom\'orkowe 5G wspierane przez BSP, OZE oraz IPR)</title>
      <link>https://arxiv.org/abs/2403.12296</link>
      <description>arXiv:2403.12296v3 Announce Type: replace 
Abstract: The paper considers energy consumption in 5G cellular networks powered by Renewable Energy Sources (RESs) and equipped with Reconfigurable Intelligent Surfaces (RISs) and tethered Unmanned Aerial Vehicles (UAVs), acting as mobile access points. The study was focused on the energy side of the Radio Access Network (RAN) located in the city of Pozna\'n in Poland. The profit associated with the use of renewable energy generators, i.e. photovoltaic panels (PVP) for base stations (BSs) is presented in the form of two factors: the average number of UAV charges (ANUC) to provide continuous access to mobile services for connected user equipment (UE) terminals, and the average reduction in energy consumption (AREC) of the wireless system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12296v3</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.15199/59.2023.4.18</arxiv:DOI>
      <arxiv:journal_reference>Telecommunication Review - Telecommunication News, 2023, no. 4, pp. 97-100</arxiv:journal_reference>
      <dc:creator>Adam Samorzewski, Adrian Kliks</dc:creator>
    </item>
    <item>
      <title>Trust, But Verify, Operator-Reported Geolocation</title>
      <link>https://arxiv.org/abs/2409.19109</link>
      <description>arXiv:2409.19109v2 Announce Type: replace 
Abstract: Geolocation plays a critical role in understanding the Internet. In this work, we provide an in-depth analysis of operator-misreported geolocation. Using a bandwidth-efficient methodology, we find in May 2024 that only a small percentage (1.5%) of vantage points in the largest community-vantage point collection, RIPE Atlas, do not respond from their operator-reported geolocation. However, misreported geolocations disproportionately affect areas with limited coverage and cause entire countries to be left with no vantage points. Furthermore, the problem is escalating: within the past five years, the number of probes reporting the wrong location has increased ten-fold. To increase the accuracy of future methodologies and studies that rely upon operator-reported geolocation, we open source our methodology and release a continually updated dataset of RIPE Atlas vantage points that misreport geolocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19109v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katherine Izhikevich, Ben Du, Sumanth Rao, Alisha Ukani, Liz Izhikevich</dc:creator>
    </item>
    <item>
      <title>AI-Native Network Digital Twin for Intelligent Network Management in 6G</title>
      <link>https://arxiv.org/abs/2410.01584</link>
      <description>arXiv:2410.01584v2 Announce Type: replace 
Abstract: As a pivotal virtualization technology, network digital twin is expected to accurately reflect real-time status and abstract features in the on-going sixth generation (6G) networks. In this article, we propose an artificial intelligence (AI)-native network digital twin framework for 6G networks to enable the synergy of AI and network digital twin, thereby facilitating intelligent network management. In the proposed framework, AI models are utilized to establish network digital twin models to facilitate network status prediction, network pattern abstraction, and network management decision-making. Furthermore, potential solutions are proposed for enhance the performance of network digital twin. Finally, a case study is presented, followed by a discussion of open research issues that are essential for AI-native network digital twin in 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01584v2</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Wu, Xinyu Huang, Tom H. Luan</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Delay-Optimized Task Offloading in Vehicular Fog Computing</title>
      <link>https://arxiv.org/abs/2410.03472</link>
      <description>arXiv:2410.03472v2 Announce Type: replace 
Abstract: The imminent rise of autonomous vehicles (AVs) is revolutionizing the future of transport. The Vehicular Fog Computing (VFC) paradigm has emerged to alleviate the load of compute-intensive and delay-sensitive AV programs via task offloading to nearby vehicles. Effective VFC requires an intelligent and dynamic offloading algorithm. As a result, this paper adapts Deep Reinforcement Learning (DRL) for VFC offloading. First, a simulation environment utilizing realistic hardware and task specifications, in addition to a novel vehicular movement model based on grid-planned cities, is created. Afterward, a DRL-based algorithm is trained and tested on the environment with the goal of minimizing global task delay. The DRL model displays impressive results, outperforming other greedy and conventional methods. The findings further demonstrate the effectiveness of the DRL model in minimizing queue congestion, especially when compared to traditional cloud computing methods that struggle to handle the demands of a large fleet of vehicles. This is corroborated by queuing theory, highlighting the self-scalability of the VFC-based DRL approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03472v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Parsa Toopchinezhad, Mahmood Ahmadi</dc:creator>
    </item>
    <item>
      <title>PAMLR: A Passive-Active Multi-Armed Bandit-Based Solution for LoRa Channel Allocation</title>
      <link>https://arxiv.org/abs/2410.05147</link>
      <description>arXiv:2410.05147v2 Announce Type: replace 
Abstract: Achieving low duty cycle operation in low-power wireless networks in urban environments is complicated by the complex and variable dynamics of external interference and fading. We explore the use of reinforcement learning for achieving low power consumption for the task of optimal selection of channels. The learning relies on a hybrid of passive channel sampling for dealing with external interference and active channel sampling for dealing with fading. Our solution, Passive-Active Multi-armed bandit for LoRa (PAMLR, pronounced "Pamela"), balances the two types of samples to achieve energy-efficient channel selection: active channel measurements are tuned to an appropriately low level to update noise thresholds, and to compensate passive channel measurements are tuned to an appropriately high level for selecting the top-most channels from channel exploration using the noise thresholds. The rates of both types of samples are adapted in response to channel dynamics. Based on extensive testing in multiple environments in different cities, we validate that PAMLR can maintain excellent communication quality, as demonstrated by a low SNR regret compared to the optimal channel allocation policy, while substantially minimizing the energy cost associated with channel measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05147v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3600100.3623725</arxiv:DOI>
      <dc:creator>Jihoon Yun, Chengzhang Li, Anish Arora</dc:creator>
    </item>
    <item>
      <title>A Multi-Layered Distributed Computing Framework for Enhanced Edge Computing</title>
      <link>https://arxiv.org/abs/2407.00565</link>
      <description>arXiv:2407.00565v2 Announce Type: replace-cross 
Abstract: The rise of the Internet of Things and edge computing has shifted computing resources closer to end-users, benefiting numerous delay-sensitive, computation-intensive applications. To speed up computation, distributed computing is a promising technique that allows parallel execution of tasks across multiple compute nodes. However, current research predominantly revolves around the master-worker paradigm, limiting resource sharing within one-hop neighborhoods. This limitation can render distributed computing ineffective in scenarios with limited nearby resources or constrained/dynamic connectivity. In this paper, we address this limitation by introducing a new distributed computing framework that extends resource sharing beyond one-hop neighborhoods through exploring layered network structures. Our framework involves transforming the network graph into a sink tree and formulating a joint optimization problem based on the layered tree structure for task allocation and scheduling. To solve this problem, we propose two exact methods that find optimal solutions and three heuristic strategies to improve efficiency and scalability. The performances of these methods are analyzed and evaluated through theoretical analyses and comprehensive simulation studies. The results demonstrate their promising performances over the traditional distributed computing and computation offloading strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00565v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Ma, Junfei Xie</dc:creator>
    </item>
    <item>
      <title>Asynchronous Fractional Multi-Agent Deep Reinforcement Learning for Age-Minimal Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2409.16832</link>
      <description>arXiv:2409.16832v2 Announce Type: replace-cross 
Abstract: In the realm of emerging real-time networked applications like cyber-physical systems (CPS), the Age of Information (AoI) has merged as a pivotal metric for evaluating the timeliness. To meet the high computational demands, such as those in intelligent manufacturing within CPS, mobile edge computing (MEC) presents a promising solution for optimizing computing and reducing AoI. In this work, we study the timeliness of computational-intensive updates and explores jointly optimize the task updating and offloading policies to minimize AoI. Specifically, we consider edge load dynamics and formulate a task scheduling problem to minimize the expected time-average AoI. The fractional objective introduced by AoI and the semi-Markov game nature of the problem render this challenge particularly difficult, with existing approaches not directly applicable. To this end, we present a comprehensive framework to fractional reinforcement learning (RL). We first introduce a fractional single-agent RL framework and prove its linear convergence. We then extend this to a fractional multi-agent RL framework with a convergence analysis. To tackle the challenge of asynchronous control in semi-Markov game, we further design an asynchronous model-free fractional multi-agent RL algorithm, where each device makes scheduling decisions with the hybrid action space without knowing the system dynamics and decisions of other devices. Experimental results show that our proposed algorithms reduce the average AoI by up to 52.6% compared with the best baseline algorithm in our experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16832v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lyudong Jin, Ming Tang, Jiayu Pan, Meng Zhang, Hao Wang</dc:creator>
    </item>
  </channel>
</rss>
