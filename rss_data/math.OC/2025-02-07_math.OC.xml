<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Vehicle Routing Problems in the Age of Semi-Autonomous Driving</title>
      <link>https://arxiv.org/abs/2502.03655</link>
      <description>arXiv:2502.03655v1 Announce Type: new 
Abstract: We are in the midst of a semi-autonomous era in urban transportation in which varying forms of vehicle autonomy are gradually being introduced. This phase of partial autonomy is anticipated by some to span a few decades due to various challenges, including budgetary constraints to upgrade the infrastructure and technological obstacles in the deployment of fully autonomous vehicles (AV) at scale. In this study, we introduce the vehicle routing problem in a semi-autonomous environment (VRP-SA) where the road network is not fully AV-enabled in the sense that a portion of it is either not suitable for AVs or requires additional resources in real-time (e.g., remote control) for AVs to pass through. Moreover, such resources are scarce and usually subject to a budget constraint. An exact mixed-integer linear program (MILP) is formulated to minimize the total routing cost of service in this environment. We propose a two-phase algorithm based on a family of feasibility recovering sub-problems (FRP) to solve the VRP-SA efficiently. Our algorithm is implemented and tested on a new set of instances that are tailored for the VRP-SA by adding stratified grid road networks to the benchmark instances. The result demonstrates a reduction of up to 37.5% in vehicle routing costs if the fleet actively exploits the AV-enabled roads in the environment. Additional analysis reveals that cost reduction is higher with more budget and longer operational hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03655v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hins Hu, Samitha Samaranayake</dc:creator>
    </item>
    <item>
      <title>The Kalman rank condition and the optimal cost for the null-controllability of coupled Stokes systems</title>
      <link>https://arxiv.org/abs/2502.03690</link>
      <description>arXiv:2502.03690v1 Announce Type: new 
Abstract: This paper considers the controllability of a class of coupled Stokes systems with distributed controls. The coupling terms are of a different nature. The first coupling is through the principal part of the Stokes operator with a constant real-valued positive-definite matrix. The second one acts through zero-order terms with a constant real-valued matrix. We assume the controls have their support in different measurable subsets of the spatial domain. Our main result states that such a system is small-time null-controllable if and only if a Kalman rank condition is satisfied. Moreover, when this condition holds, we prove the sharp upper bound for the cost of null-controllability for these systems. Our method is based on two ingredients. We start from the recent spectral estimate for the Stokes operator from Chaves-Silva, Souza, and Zhang. Then, we adapt Lissy and Zuazua's strategy concerning the internal observability for coupled systems of linear parabolic equations to coupled Stokes systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03690v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K\'evin Le Balc'h, Luz de Teresa</dc:creator>
    </item>
    <item>
      <title>First-ish Order Methods: Hessian-aware Scalings of Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.03701</link>
      <description>arXiv:2502.03701v1 Announce Type: new 
Abstract: Gradient descent is the primary workhorse for optimizing large-scale problems in machine learning. However, its performance is highly sensitive to the choice of the learning rate. A key limitation of gradient descent is its lack of natural scaling, which often necessitates expensive line searches or heuristic tuning to determine an appropriate step size. In this paper, we address this limitation by incorporating Hessian information to scale the gradient direction. By accounting for the curvature of the function along the gradient, our adaptive, Hessian-aware scaling method ensures a local unit step size guarantee, even in nonconvex settings. Near a local minimum that satisfies the second-order sufficient conditions, our approach achieves linear convergence with a unit step size. We show that our method converges globally under a significantly weaker version of the standard Lipschitz gradient smoothness assumption. Even when Hessian information is inexact, the local unit step size guarantee and global convergence properties remain valid under mild conditions. Finally, we validate our theoretical results empirically on a range of convex and nonconvex machine learning tasks, showcasing the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03701v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar Smee, Fred Roosta, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>A necessary condition for the guarantee of the superiorization method</title>
      <link>https://arxiv.org/abs/2502.03867</link>
      <description>arXiv:2502.03867v1 Announce Type: new 
Abstract: We study a method that involves principally convex feasibility-seeking and makes secondary efforts of objective function value reduction. This is the well-known superiorization method (SM), where the iterates of an asymptotically convergent iterative feasibility-seeking algorithm are perturbed by objective function nonascent steps. We investigate the question under what conditions a sequence generated by an SM algorithm asymptotically converges to a feasible point whose objective function value is superior (meaning smaller or equal) to that of a feasible point reached by the corresponding unperturbed one (i.e., the exactly same feasibility-seeking algorithm that the SM algorithm employs.) This question is yet only partially answered in the literature. We present a condition under which an SM algorithm that uses negative gradient descent steps in its perturbations fails to yield such a superior outcome. The significance of the discovery of this negative condition is that it necessitates that the inverse of this condition will have to be assumed to hold in any future guarantee result for the SM. The condition is important for practitioners who use the SM because it is avoidable in experimental work with the SM, thus increasing the success rate of the method in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03867v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kay Barshad, Yair Censor, Walaa Moursi, Tyler Weames, Henry Wolkowicz</dc:creator>
    </item>
    <item>
      <title>Blackwell's Approachability with Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2502.03919</link>
      <description>arXiv:2502.03919v1 Announce Type: new 
Abstract: We revisit Blackwell's celebrated approachability problem which considers a repeated vector-valued game between a player and an adversary. Motivated by settings in which the action set of the player or adversary (or both) is difficult to optimize over, for instance when it corresponds to the set of all possible solutions to some NP-Hard optimization problem, we ask what can the player guarantee \textit{efficiently}, when only having access to these sets via approximation algorithms with ratios $\alpha_{\mX} \geq 1$ and $ 1 \geq \alpha_{\mY} &gt; 0$, respectively. Assuming the player has monotone preferences, in the sense that he does not prefer a vector-valued loss $\ell_1$ over $\ell_2$ if $\ell_2 \leq \ell_1$, we establish that given a Blackwell instance with an approachable target set $S$, the downward closure of the appropriately-scaled set $\alpha_{\mX}\alpha_{\mY}^{-1}S$ is \textit{efficiently} approachable with optimal rate. In case only the player's or adversary's set is equipped with an approximation algorithm, we give simpler and more efficient algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03919v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Garber, Mhna Massalha</dc:creator>
    </item>
    <item>
      <title>Density-Based Topology Optimization for Characteristic Modes Manipulation</title>
      <link>https://arxiv.org/abs/2502.03985</link>
      <description>arXiv:2502.03985v1 Announce Type: new 
Abstract: A density-based topology optimization framework is developed to manipulate characteristic modes of conducting surfaces. The adjoint sensitivity analysis provides an efficient computation of the material gradient utilized by the local optimizer to update the material distribution. The modal approach naturally separates geometry and feeding synthesis, demonstrating its ability to optimize modal quantities while maintaining computational efficiency through gradient-based updates. The framework's properties and performance are illustrated through several examples, including single-mode resonance control, modal Q-factor, and multi-mode optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03985v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jonas Tucek, Miloslav Capek, Lukas Jelinek</dc:creator>
    </item>
    <item>
      <title>Facial structure of copositive and completely positive cones over a second-order cone</title>
      <link>https://arxiv.org/abs/2502.04006</link>
      <description>arXiv:2502.04006v1 Announce Type: new 
Abstract: We classify the faces of copositive and completely positive cones over a second-order cone and investigate their dimension and exposedness properties. Then we compute two parameters related to chains of faces of both cones. At the end, we discuss some possible extensions of the results with a view toward analyzing the facial structure of general copositive and completely positive cones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04006v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitsuhiro Nishijima, Bruno F. Louren\c{c}o</dc:creator>
    </item>
    <item>
      <title>Recovering sparse DFT from missing signals via interior point method on GPU</title>
      <link>https://arxiv.org/abs/2502.04217</link>
      <description>arXiv:2502.04217v1 Announce Type: new 
Abstract: We propose a method to recover the sparse discrete Fourier transform (DFT) of a signal that is both noisy and potentially incomplete, with missing values. The problem is formulated as a penalized least-squares minimization based on the inverse discrete Fourier transform (IDFT) with an $\ell_1$-penalty term, reformulated to be solvable using a primal-dual interior point method (IPM). Although Krylov methods are not typically used to solve Karush-Kuhn-Tucker (KKT) systems arising in IPMs due to their ill-conditioning, we employ a tailored preconditioner and establish new asymptotic bounds on the condition number of preconditioned KKT matrices. Thanks to this dedicated preconditioner -- and the fact that FFT and IFFT operate as linear operators without requiring explicit matrix materialization -- KKT systems can be solved efficiently at large scales in a matrix-free manner. Numerical results from a Julia implementation leveraging GPU-accelerated interior point methods, Krylov methods, and FFT toolkits demonstrate the scalability of our approach on problems with hundreds of millions of variables, inclusive of real data obtained from the diffuse scattering from a slightly disordered Molybdenum Vanadium Dioxide crystal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04217v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Kuang, Alexis Montoison, Vishwas Rao, Fran\c{c}ois Pacaud, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>On the Effect of Alpha Decay and Transaction Costs on the Multi-period Optimal Trading Strategy</title>
      <link>https://arxiv.org/abs/2502.04284</link>
      <description>arXiv:2502.04284v1 Announce Type: new 
Abstract: We consider the multi-period portfolio optimization problem with a single asset that can be held long or short. Due to the presence of transaction costs, maximizing the immediate reward at each period may prove detrimental, as frequent trading results in consistent negative cash outflows. To simulate alpha decay, we consider a case where not only the present value of a signal, but also past values, have predictive power. We formulate the problem as an infinite horizon Markov Decision Process and seek to characterize the optimal policy that realizes the maximum average expected reward. We propose a variant of the standard value iteration algorithm for computing the optimal policy. Establishing convergence in our setting is nontrivial, and we provide a rigorous proof. Addtionally, we compute a first-order approximation and asymptotics of the optimal policy with small transaction costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04284v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chutian Ma, Paul Smith</dc:creator>
    </item>
    <item>
      <title>Unrealized Expectations: Comparing AI Methods vs Classical Algorithms for Maximum Independent Set</title>
      <link>https://arxiv.org/abs/2502.03669</link>
      <description>arXiv:2502.03669v1 Announce Type: cross 
Abstract: AI methods, such as generative models and reinforcement learning, have recently been applied to combinatorial optimization (CO) problems, especially NP-hard ones. This paper compares such GPU-based methods with classical CPU-based methods on Maximum Independent Set (MIS). Experiments on standard graph families show that AI-based algorithms fail to outperform and, in many cases, to match the solution quality of the state-of-art classical solver KaMIS running on a single CPU. Some GPU-based methods even perform similarly to the simplest heuristic, degree-based greedy. Even with post-processing techniques like local search, AI-based methods still perform worse than CPU-based solvers.
  We develop a new mode of analysis to reveal that non-backtracking AI methods, e.g. LTFT (which is based on GFlowNets), end up reasoning similarly to the simplest degree-based greedy approach, and thus worse than KaMIS. We also find that CPU-based algorithms, notably KaMIS, have strong performance on sparse random graphs, which appears to refute a well-known conjectured upper bound for efficient algorithms from Coja-Oghlan &amp; Efthymiou (2015).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03669v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yikai Wu, Haoyu Zhao, Sanjeev Arora</dc:creator>
    </item>
    <item>
      <title>PINS: Proximal Iterations with Sparse Newton and Sinkhorn for Optimal Transport</title>
      <link>https://arxiv.org/abs/2502.03749</link>
      <description>arXiv:2502.03749v1 Announce Type: cross 
Abstract: Optimal transport (OT) is a critical problem in optimization and machine learning, where accuracy and efficiency are paramount. Although entropic regularization and the Sinkhorn algorithm improve scalability, they frequently encounter numerical instability and slow convergence, especially when the regularization parameter is small. In this work, we introduce Proximal Iterations with Sparse Newton and Sinkhorn methods (PINS) to efficiently compute highly accurate solutions for large-scale OT problems. A reduced computational complexity through overall sparsity and global convergence are guaranteed by rigorous theoretical analysis. Our approach offers three key advantages: it achieves accuracy comparable to exact solutions, progressively accelerates each iteration for greater efficiency, and enhances robustness by reducing sensitivity to regularization parameters. Extensive experiments confirm these advantages, demonstrating superior performance compared to related methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03749v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Wu, Ling Liang, Haizhao Yang</dc:creator>
    </item>
    <item>
      <title>Exact controllability of anisotropic 1D partial differential equations in spaces of analytic functions</title>
      <link>https://arxiv.org/abs/2502.03800</link>
      <description>arXiv:2502.03800v1 Announce Type: cross 
Abstract: In this article, we prove a local controllability result for a general class of 1D partial differential equations on the interval $(0,1)$. The PDEs we consider take the form $\partial_t^N y=\zeta_M \partial_{x}^{M}y+f(x , y , \partial_{x} y,\ldots, \partial_x^{M-1} y)$ where $1\le N &lt; M$, $\zeta_M\in \mathbb{C} ^*$, and $f$ is some linear or nonlinear term of lower order. In this context, we prove a local controllability result between states that are analytic functions. If some boundary conditions are prescribed, a similar local controllability result holds between analytic functions satisfying some compatibility conditions that are natural for the existence of smooth solutions of the considered PDE. The proof is performed by studying a nonlinear Cauchy problem in the spatial variable with data in some spaces of Gevrey functions and by investigating the relationship between the jet of space derivatives and the jet of time derivatives. We give various examples of applications, including the (good and bad) Boussinesq equation, the Ginzburg-Landau equation, the Kuramoto-Sivashinsky equation and the Korteweg-de Vries equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03800v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Camille Laurent (CNRS, URCA), Ivonne Rivas (Univalle), Lionel Rosier (ULCO)</dc:creator>
    </item>
    <item>
      <title>Feedback stabilization for a spatial-dependent Sterile Insect Technique model with Allee Effect</title>
      <link>https://arxiv.org/abs/2502.03898</link>
      <description>arXiv:2502.03898v1 Announce Type: cross 
Abstract: This work focuses on feedback control strategies for applying the sterile insect technique (SIT) to eliminate pest populations. The presentation is centered on the case of mosquito populations, but most of the results can be extended to other species by adapting the model and selecting appropriate parameter values to describe the reproduction and movement dynamics of the species under consideration. In our study, we address the spatial distribution of the population in a two dimensional bounded domain by extending the temporal SIT model analyzed in [2], thereby obtaining a reaction-diffusion SIT model. After the analysis of the existence and the uniqueness of the solution of this problem, we construct a feedback law that globally asymptotically stabilizes the extinction equilibrium thus yielding a robust strategy to keep the pest population at very low levels in the long term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03898v1</guid>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kala Agbo bidi (LJLL), Lu\'is Almeida (LJLL), Jean-Michel Coron (LJLL)</dc:creator>
    </item>
    <item>
      <title>Geometric Stabilization of Virtual Nonlinear Nonholonomic Constraints</title>
      <link>https://arxiv.org/abs/2502.03902</link>
      <description>arXiv:2502.03902v1 Announce Type: cross 
Abstract: In this paper, we address the problem of stabilizing a system around a desired manifold determined by virtual nonlinear nonholonomic constraints. Virtual constraints are relationships imposed on a control system that are rendered invariant through feedback control. Virtual nonholonomic constraints represent a specific class of virtual constraints that depend on the system's velocities in addition to its configurations. We derive a control law under which a mechanical control system achieves exponential convergence to the virtual constraint submanifold, and rendering it control-invariant. The proposed controller's performance is validated through simulation results in two distinct applications: flocking motion in multi-agent systems and the control of an unmanned surface vehicle (USV) navigating a stream.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03902v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Efstratios Stratoglou, Alexandre Anahory Simoes, Anthony Bloch, Leonardo Colombo</dc:creator>
    </item>
    <item>
      <title>Adaptive Output Feedback MPC with Guaranteed Stability and Robustness</title>
      <link>https://arxiv.org/abs/2502.04048</link>
      <description>arXiv:2502.04048v1 Announce Type: cross 
Abstract: This work proposes an adaptive output feedback model predictive control (MPC) framework for uncertain systems subject to external disturbances. In the absence of exact knowledge about the plant parameters and complete state measurements, the MPC optimization problem is reformulated in terms of their estimates derived from a suitably designed robust adaptive observer. The MPC routine returns a homothetic tube for the state estimate trajectory. Sets that characterize the state estimation errors are then added to the homothetic tube sections, resulting in a larger tube containing the true state trajectory. The two-tier tube architecture provides robustness to uncertainties due to imperfect parameter knowledge, external disturbances, and incomplete state information. Additionally, recursive feasibility and robust exponential stability are guaranteed and validated using a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04048v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anchita Dey, Shubhendu Bhasin</dc:creator>
    </item>
    <item>
      <title>User-Friendly Game-Theoretic Modeling and Analysis of Multi-Modal Transportation Systems</title>
      <link>https://arxiv.org/abs/2502.04155</link>
      <description>arXiv:2502.04155v1 Announce Type: cross 
Abstract: The evolution of existing transportation systems, mainly driven by urbanization and increased availability of mobility options, such as private, profit-maximizing ride-hailing companies, calls for tools to reason about their design and regulation. To study this complex socio-technical problem, one needs to account for the strategic interactions of the stakeholders involved in the mobility ecosystem. In this paper, we present a game-theoretic framework to model multi-modal mobility systems, focusing on municipalities, service providers, and travelers. Through a user-friendly, Graphical User Interface, one can visualize system dynamics and compute equilibria for various scenarios. The framework enables stakeholders to assess the impact of local decisions (e.g., fleet size for services or taxes for private companies) on the full mobility system. Furthermore, this project aims to foster STEM interest among high school students (e.g., in the context of prior activities in Switzerland, and planned activities with the MIT museum). This initiative combines theoretical advancements, practical applications, and educational outreach to improve mobility system design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04155v1</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Margarita Zambrano, Xinling Li, Riccardo Fiorista, Gioele Zardini</dc:creator>
    </item>
    <item>
      <title>Fair Schedules for Single Round Robin Tournaments with Ranked Participants</title>
      <link>https://arxiv.org/abs/2502.04159</link>
      <description>arXiv:2502.04159v1 Announce Type: cross 
Abstract: We introduce a new measure to capture fairness of a schedule in a single round robin (SRR) tournament when participants are ranked by strength. To prevent distortion of the outcome of an SRR tournament as well as to guarantee equal treatment, we argue that each participant should face its opponents when ranked by strength in an alternating fashion with respect to the home/away advantage. Here, the home/away advantage captures a variety of situations. We provide an explicit construction proving that so-called ranking-fair schedules exist when the number of participants is a multiple of 4. Further, we give a formulation that outputs ranking-fair schedules when they exist. Finally, we show that the most popular method to come to a schedule for an SRR tournament, does not allow ranking-fair schedules when the number of teams exceeds 8. These findings impact the type of schedules to be used for SRR tournaments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04159v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sten Wessel, Cor Hurkens, Frits Spieksma</dc:creator>
    </item>
    <item>
      <title>Every Call is Precious: Global Optimization of Black-Box Functions with Unknown Lipschitz Constants</title>
      <link>https://arxiv.org/abs/2502.04290</link>
      <description>arXiv:2502.04290v1 Announce Type: cross 
Abstract: Optimizing expensive, non-convex, black-box Lipschitz continuous functions presents significant challenges, particularly when the Lipschitz constant of the underlying function is unknown. Such problems often demand numerous function evaluations to approximate the global optimum, which can be prohibitive in terms of time, energy, or resources. In this work, we introduce Every Call is Precious (ECP), a novel global optimization algorithm that minimizes unpromising evaluations by strategically focusing on potentially optimal regions. Unlike previous approaches, ECP eliminates the need to estimate the Lipschitz constant, thereby avoiding additional function evaluations. ECP guarantees no-regret performance for infinite evaluation budgets and achieves minimax-optimal regret bounds within finite budgets. Extensive ablation studies validate the algorithm's robustness, while empirical evaluations show that ECP outperforms 10 benchmark algorithms including Lipschitz, Bayesian, bandits, and evolutionary methods across 30 multi-dimensional non-convex synthetic and real-world optimization problems, which positions ECP as a competitive approach for global optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04290v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fares Fourati, Salma Kharrat, Vaneet Aggarwal, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Statistical guarantees for continuous-time policy evaluation: blessing of ellipticity and new tradeoffs</title>
      <link>https://arxiv.org/abs/2502.04297</link>
      <description>arXiv:2502.04297v1 Announce Type: cross 
Abstract: We study the estimation of the value function for continuous-time Markov diffusion processes using a single, discretely observed ergodic trajectory. Our work provides non-asymptotic statistical guarantees for the least-squares temporal-difference (LSTD) method, with performance measured in the first-order Sobolev norm. Specifically, the estimator attains an $O(1 / \sqrt{T})$ convergence rate when using a trajectory of length $T$; notably, this rate is achieved as long as $T$ scales nearly linearly with both the mixing time of the diffusion and the number of basis functions employed.
  A key insight of our approach is that the ellipticity inherent in the diffusion process ensures robust performance even as the effective horizon diverges to infinity. Moreover, we demonstrate that the Markovian component of the statistical error can be controlled by the approximation error, while the martingale component grows at a slower rate relative to the number of basis functions. By carefully balancing these two sources of error, our analysis reveals novel trade-offs between approximation and statistical errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04297v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Mou</dc:creator>
    </item>
    <item>
      <title>The Necessary and Sufficient Conditions for Representing Lipschitz Bivariate Functions as a Difference of Two Convex Functions(corrected)</title>
      <link>https://arxiv.org/abs/1204.1727</link>
      <description>arXiv:1204.1727v4 Announce Type: replace 
Abstract: In the article the necessary and sufficient conditions for a representation of Lipschitz function of two variables as a difference of two convex functions are formulated. An algorithm of this representation is given. The outcome of this algorithm is a sequence of pairs of convex functions that converge uniformly to a pair of convex functions if the conditions of the formulated theorems are satisfied. A geometric interpretation is also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:1204.1727v4</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1134/S0037446614060147</arxiv:DOI>
      <dc:creator>Igor Proudnikov</dc:creator>
    </item>
    <item>
      <title>Constrained Efficient Global Optimization of Expensive Black-box Functions</title>
      <link>https://arxiv.org/abs/2211.00162</link>
      <description>arXiv:2211.00162v4 Announce Type: replace 
Abstract: We study the problem of constrained efficient global optimization, where both the objective and constraints are expensive black-box functions that can be learned with Gaussian processes. We propose CONFIG (CONstrained efFIcient Global Optimization), a simple and effective algorithm to solve it. Under certain regularity assumptions, we show that our algorithm enjoys the same cumulative regret bound as that in the unconstrained case and similar cumulative constraint violation upper bounds. For commonly used Matern and Squared Exponential kernels, our bounds are sublinear and allow us to derive a convergence rate to the optimal solution of the original constrained problem. In addition, our method naturally provides a scheme to declare infeasibility when the original black-box optimization problem is infeasible. Numerical experiments on sampled instances from the Gaussian process, artificial numerical problems, and a black-box building controller tuning problem all demonstrate the competitive performance of our algorithm. Compared to the other state-of-the-art methods, our algorithm significantly improves the theoretical guarantees, while achieving competitive empirical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00162v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wenjie Xu, Yuning Jiang, Bratislav Svetozarevic, Colin N. Jones</dc:creator>
    </item>
    <item>
      <title>Trust Region Methods For Nonconvex Stochastic Optimization Beyond Lipschitz Smoothness</title>
      <link>https://arxiv.org/abs/2310.17319</link>
      <description>arXiv:2310.17319v2 Announce Type: replace 
Abstract: In many important machine learning applications, the standard assumption of having a globally Lipschitz continuous gradient may fail to hold. This paper delves into a more general $(L_0, L_1)$-smoothness setting, which gains particular significance within the realms of deep neural networks and distributionally robust optimization (DRO). We demonstrate the significant advantage of trust region methods for stochastic nonconvex optimization under such generalized smoothness assumption. We show that first-order trust region methods can recover the normalized and clipped stochastic gradient as special cases and then provide a unified analysis to show their convergence to first-order stationary conditions. Motivated by the important application of DRO, we propose a generalized high-order smoothness condition, under which second-order trust region methods can achieve a complexity of $\mathcal{O}(\epsilon^{-3.5})$ for convergence to second-order stationary points. By incorporating variance reduction, the second-order trust region method obtains an even better complexity of $\mathcal{O}(\epsilon^{-3})$, matching the optimal bound for standard smooth optimization. To our best knowledge, this is the first work to show convergence beyond the first-order stationary condition for generalized smooth optimization. Preliminary experiments show that our proposed algorithms perform favorably compared with existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17319v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenghan Xie, Chenxi Li, Chuwen Zhang, Qi Deng, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>On the sequential convergence of Lloyd's algorithms</title>
      <link>https://arxiv.org/abs/2405.20744</link>
      <description>arXiv:2405.20744v3 Announce Type: replace 
Abstract: Lloyd's algorithm is an iterative method that solves the quantization problem, i.e. the approximation of a target probability measure by a discrete one, and is particularly used in digital applications.This algorithm can be interpreted as a gradient method on a certain quantization functional which is given by optimal transport. We study the sequential convergence (to a single accumulation point) for two variants of Lloyd's method: (i) optimal quantization with an arbitrary discrete measure and (ii) uniform quantization with a uniform discrete measure. For both cases, we prove sequential convergence of the iterates under an analiticity assumption on the density of the target measure. This includes for example analytic densities truncated to a compact semi-algebraic set. The argument leverages the log analytic nature of globally subanalytic integrals, the interpretation of Lloyd's method as a gradient method and the convergence analysis of gradient algorithms under Kurdyka-Lojasiewicz assumptions. As a by-product, we also obtain definability results for more general semi-discrete optimal transport losses such as transport distances with general costs, the max-sliced Wasserstein distance and the entropy regularized optimal transport loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20744v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'eo Portales, Elsa Cazelles, Edouard Pauwels</dc:creator>
    </item>
    <item>
      <title>Tight Time Complexities in Parallel Stochastic Optimization with Arbitrary Computation Dynamics</title>
      <link>https://arxiv.org/abs/2408.04929</link>
      <description>arXiv:2408.04929v2 Announce Type: replace 
Abstract: In distributed stochastic optimization, where parallel and asynchronous methods are employed, we establish optimal time complexities under virtually any computation behavior of workers/devices/CPUs/GPUs, capturing potential disconnections due to hardware and network delays, time-varying computation powers, and any possible fluctuations and trends of computation speeds. These real-world scenarios are formalized by our new universal computation model. Leveraging this model and new proof techniques, we discover tight lower bounds that apply to virtually all synchronous and asynchronous methods, including Minibatch SGD, Asynchronous SGD (Recht et al., 2011), and Picky SGD (Cohen et al., 2021). We show that these lower bounds, up to constant factors, are matched by the optimal Rennala SGD and Malenia SGD methods (Tyurin &amp; Richt\'arik, 2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04929v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean High-Order Smooth Convex Optimization</title>
      <link>https://arxiv.org/abs/2411.08987</link>
      <description>arXiv:2411.08987v2 Announce Type: replace 
Abstract: We develop algorithms for the optimization of convex objectives that have H\"older continuous $q$-th derivatives by using a $q$-th order oracle, for any $q \geq 1$. Our algorithms work for general norms under mild conditions, including the $\ell_p$-settings for $1\leq p\leq \infty$. We can also optimize structured functions that allow for inexactly implementing a non-Euclidean ball optimization oracle. We do this by developing a non-Euclidean inexact accelerated proximal point method that makes use of an \emph{inexact uniformly convex regularizer}. We show a lower bound for general norms that demonstrates our algorithms are nearly optimal in high-dimensions in the black-box oracle model for $\ell_p$-settings and all $q \geq 1$, even in randomized and parallel settings. This new lower bound, when applied to the first-order smooth case, resolves an open question in parallel convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08987v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Pablo Contreras, Crist\'obal Guzm\'an, David Mart\'inez-Rubio</dc:creator>
    </item>
    <item>
      <title>MPAX: Mathematical Programming in JAX</title>
      <link>https://arxiv.org/abs/2412.09734</link>
      <description>arXiv:2412.09734v2 Announce Type: replace 
Abstract: This paper presents MPAX (Mathematical Programming in JAX), a versatile and efficient toolbox for integrating linear programming (LP) into machine learning workflows. MPAX implemented the state-of-the-art first-order methods, restarted average primal-dual hybrid gradient and reflected restarted Halpern primal-dual hybrid gradient, to solve LPs in JAX. This provides native support for hardware accelerations along with features like batch solving, auto-differentiation, and device parallelism. Extensive numerical experiments demonstrate the advantages of MPAX over existing solvers. The solver is available at https://github.com/MIT-Lu-Lab/MPAX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09734v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haihao Lu, Zedong Peng, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>On characterizing optimal learning trajectories in a class of learning problems</title>
      <link>https://arxiv.org/abs/2501.16521</link>
      <description>arXiv:2501.16521v2 Announce Type: replace 
Abstract: In this brief paper, we provide a mathematical framework that exploits the relationship between the maximum principle and dynamic programming for characterizing optimal learning trajectories in a class of learning problem, which is related to point estimations for modeling of high-dimensional nonlinear functions. Here, such characterization for the optimal learning trajectories is associated with the solution of an optimal control problem for a weakly-controlled gradient system with small parameters, whose time-evolution is guided by a model training dataset and its perturbed version, while the optimization problem consists of a cost functional that summarizes how to gauge the quality/performance of the estimated model parameters at a certain fixed final time w.r.t. a model validating dataset. Moreover, using a successive Galerkin approximation method, we provide an algorithmic recipe how to construct the corresponding optimal learning trajectories leading to the optimal estimated model parameters for such a class of learning problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16521v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K Befekadu</dc:creator>
    </item>
    <item>
      <title>Rates of Convergence in the Central Limit Theorem for Markov Chains, with an Application to TD Learning</title>
      <link>https://arxiv.org/abs/2401.15719</link>
      <description>arXiv:2401.15719v3 Announce Type: replace-cross 
Abstract: We prove a non-asymptotic central limit theorem for vector-valued martingale differences using Stein's method, and use Poisson's equation to extend the result to functions of Markov Chains. We then show that these results can be applied to establish a non-asymptotic central limit theorem for Temporal Difference (TD) learning with averaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15719v3</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R. Srikant</dc:creator>
    </item>
    <item>
      <title>Distributed Event-Based Learning via ADMM</title>
      <link>https://arxiv.org/abs/2405.10618</link>
      <description>arXiv:2405.10618v2 Announce Type: replace-cross 
Abstract: We consider a distributed learning problem, where agents minimize a global objective function by exchanging information over a network. Our approach has two distinct features: (i) It substantially reduces communication by triggering communication only when necessary, and (ii) it is agnostic to the data-distribution among the different agents. We therefore guarantee convergence even if the local data-distributions of the agents are arbitrarily distinct. We analyze the convergence rate of the algorithm both in convex and nonconvex settings and derive accelerated convergence rates for the convex case. We also characterize the effect of communication failures and demonstrate that our algorithm is robust to these. The article concludes by presenting numerical results from distributed learning tasks on the MNIST and CIFAR-10 datasets. The experiments underline communication savings of 35% or more due to the event-based communication strategy, show resilience towards heterogeneous data-distributions, and highlight that our approach outperforms common baselines such as FedAvg, FedProx, SCAFFOLD and FedADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10618v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guner Dilsad Er, Sebastian Trimpe, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>Robust model predictive control exploiting monotonicity properties</title>
      <link>https://arxiv.org/abs/2408.17348</link>
      <description>arXiv:2408.17348v2 Announce Type: replace-cross 
Abstract: Robust model predictive control algorithms are essential for addressing unavoidable errors due to the uncertainty in predicting real-world systems. However, the formulation of such algorithms typically results in a trade-off between conservatism and computational complexity. Monotone systems facilitate the efficient computation of reachable sets and thus the straightforward formulation of a robust model predictive control approach optimizing over open-loop predictions. We present an approach based on the division of reachable sets to incorporate feedback in the predictions, resulting in less conservative strategies. The concept of mixed-monotonicity enables an extension of our methodology to non-monotone systems. The potential of the proposed approaches is demonstrated through a nonlinear high-dimensional chemical tank reactor cascade case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17348v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moritz Heinlein, Sankaranarayanan Subramanian, Sergio Lucia</dc:creator>
    </item>
    <item>
      <title>Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning</title>
      <link>https://arxiv.org/abs/2410.15483</link>
      <description>arXiv:2410.15483v3 Announce Type: replace-cross 
Abstract: Post-training of pre-trained LLMs, which typically consists of the supervised fine-tuning (SFT) stage and the preference learning (RLHF or DPO) stage, is crucial to effective and safe LLM applications. The widely adopted approach in post-training popular open-source LLMs is to sequentially perform SFT and RLHF/DPO. However, sequential training is sub-optimal in terms of SFT and RLHF/DPO trade-off: the LLM gradually forgets about the first stage's training when undergoing the second stage's training. We theoretically prove the sub-optimality of sequential post-training. Furthermore, we propose a practical joint post-training framework with theoretical convergence guarantees and empirically outperforms sequential post-training framework, while having similar computational cost. Our code is available at https://github.com/heshandevaka/XRIGHT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15483v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz, Nathalie Baracaldo, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Efficient Adaptive Federated Optimization</title>
      <link>https://arxiv.org/abs/2410.18117</link>
      <description>arXiv:2410.18117v2 Announce Type: replace-cross 
Abstract: Adaptive optimization is critical in federated learning, where enabling adaptivity on both the server and client sides has proven essential for achieving optimal performance. However, the scalability of such jointly adaptive systems is often hindered by resource limitations in communication and memory. In this paper, we introduce a class of efficient adaptive algorithms, named $FedAda^2$ and its enhanced version $FedAda^2$++, designed specifically for large-scale, cross-device federated environments. $FedAda^2$ optimizes communication efficiency by avoiding the transfer of preconditioners between the server and clients. Additionally, $FedAda^2$++ extends this approach by incorporating memory-efficient adaptive optimizers on the client side, further reducing on-device memory usage. Theoretically, we demonstrate that $FedAda^2$ and $FedAda^2$++ achieve the same convergence rates for general, non-convex objectives as its more resource-intensive counterparts that directly integrate joint adaptivity. Extensive empirical evaluations on image and text datasets demonstrate both the advantages of joint adaptivity and the effectiveness of $FedAda^2$/$FedAda^2$++.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18117v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Su Hyeong Lee, Sidharth Sharma, Manzil Zaheer, Tian Li</dc:creator>
    </item>
    <item>
      <title>Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities</title>
      <link>https://arxiv.org/abs/2411.10868</link>
      <description>arXiv:2411.10868v2 Announce Type: replace-cross 
Abstract: Social influence plays a significant role in shaping individual opinions and actions, particularly in a world of ubiquitous digital interconnection. The rapid development of generative AI has engendered well-founded concerns regarding the potential scalable implementation of radicalization techniques in social media. Motivated by these developments, we present a case study investigating the effects of small but intentional perturbations on a simple social network. We employ Taylor's classic model of social influence and use tools from robust control theory (most notably the Dynamical Structure Function (DSF)), to identify perturbations that qualitatively alter the system's behavior while remaining as unobtrusive as possible. We examine two such scenarios: perturbations to an existing link and perturbations that introduce a new link to the network. In each case, we identify destabilizing perturbations of minimal norm and simulate their effects. Remarkably, we find that small but targeted alterations to network structure may lead to the radicalization of all agents -- sentiments grow without bound -- exhibiting the potential for large-scale shifts in collective behavior to be triggered by comparatively minuscule adjustments in social influence. Given that this method of identifying perturbations that are innocuous but destabilizing applies to any suitable dynamical system, our findings emphasize a need for similar analyses to be carried out on real systems (e.g., real social networks), to identify where such dynamics may already exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10868v2</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lane H. Rogers, Emma J. Reid, Robert A. Bridges</dc:creator>
    </item>
    <item>
      <title>Efficient Over-parameterized Matrix Sensing from Noisy Measurements via Alternating Preconditioned Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.00463</link>
      <description>arXiv:2502.00463v2 Announce Type: replace-cross 
Abstract: We consider the noisy matrix sensing problem in the over-parameterization setting, where the estimated rank $r$ is larger than the true rank $r_\star$. Specifically, our main objective is to recover a matrix $ X_\star \in \mathbb{R}^{n_1 \times n_2} $ with rank $ r_\star $ from noisy measurements using an over-parameterized factorized form $ LR^\top $, where $ L \in \mathbb{R}^{n_1 \times r}, \, R \in \mathbb{R}^{n_2 \times r} $ and $ \min\{n_1, n_2\} \ge r &gt; r_\star $, with the true rank $ r_\star $ being unknown. Recently, preconditioning methods have been proposed to accelerate the convergence of matrix sensing problem compared to vanilla gradient descent, incorporating preconditioning terms $ (L^\top L + \lambda I)^{-1} $ and $ (R^\top R + \lambda I)^{-1} $ into the original gradient. However, these methods require careful tuning of the damping parameter $\lambda$ and are sensitive to initial points and step size. To address these limitations, we propose the alternating preconditioned gradient descent (APGD) algorithm, which alternately updates the two factor matrices, eliminating the need for the damping parameter and enabling faster convergence with larger step sizes. We theoretically prove that APGD achieves near-optimal error convergence at a linear rate, starting from arbitrary random initializations. Through extensive experiments, we validate our theoretical results and demonstrate that APGD outperforms other methods, achieving the fastest convergence rate. Notably, both our theoretical analysis and experimental results illustrate that APGD does not rely on the initialization procedure, making it more practical and versatile.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00463v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Liu, Zhi Han, Yandong Tang, Hai Zhang, Shaojie Tang, Yao Wang</dc:creator>
    </item>
    <item>
      <title>Containment Control Approach for Steering Opinion in a Social Network</title>
      <link>https://arxiv.org/abs/2502.01847</link>
      <description>arXiv:2502.01847v2 Announce Type: replace-cross 
Abstract: The paper studies the problem of steering multi-dimensional opinion in a social network. Assuming the society of desire consists of stubborn and regular agents, stubborn agents are considered as leaders who specify the desired opinion distribution as a distributed reward or utility function. In this context, each regular agent is seen as a follower, updating its bias on the initial opinion and influence weights by averaging their observations of the rewards their influencers have received. Assuming random graphs with reducible and irreducible topology specify the influences on regular agents, opinion evolution is represented as a containment control problem in which stability and convergence to the final opinion are proven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01847v2</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossein Rastgoftar</dc:creator>
    </item>
    <item>
      <title>Global Contact-Rich Planning with Sparsity-Rich Semidefinite Relaxations</title>
      <link>https://arxiv.org/abs/2502.02829</link>
      <description>arXiv:2502.02829v2 Announce Type: replace-cross 
Abstract: We show that contact-rich motion planning is also sparsity-rich when viewed as polynomial optimization (POP). We can exploit not only the correlative and term sparsity patterns that are general to all POPs, but also specialized sparsity patterns from the robot kinematic structure and the separability of contact modes. Such sparsity enables the design of high-order but sparse semidefinite programming (SDPs) relaxations--building upon Lasserre's moment and sums of squares hierarchy--that (i) can be solved in seconds by off-the-shelf SDP solvers, and (ii) compute near globally optimal solutions to the nonconvex contact-rich planning problems with small certified suboptimality. Through extensive experiments both in simulation (Push Bot, Push Box, Push Box with Obstacles, and Planar Hand) and real world (Push T), we demonstrate the power of using convex SDP relaxations to generate global contact-rich motion plans. As a contribution of independent interest, we release the Sparse Polynomial Optimization Toolbox (SPOT)--implemented in C++ with interfaces to both Python and Matlab--that automates sparsity exploitation for robotics and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02829v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shucheng Kang, Guorui Liu, Heng Yang</dc:creator>
    </item>
  </channel>
</rss>
