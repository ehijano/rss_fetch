<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 01:46:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Explainability by design: an experimental analysis of the legal coding process</title>
      <link>https://arxiv.org/abs/2505.01944</link>
      <description>arXiv:2505.01944v1 Announce Type: new 
Abstract: Behind a set of rules in Deontic Defeasible Logic, there is a mapping process of normative background fragments. This process goes from text to rules and implicitly encompasses an explanation of the coded fragments.
  In this paper we deliver a methodology for \textit{legal coding} that starts with a fragment and goes onto a set of Deontic Defeasible Logic rules, involving a set of \textit{scenarios} to test the correctness of the coded fragments. The methodology is illustrated by the coding process of an example text. We then show the results of a series of experiments conducted with humans encoding a variety of normative backgrounds and corresponding cases in which we have measured the efforts made in the coding process, as related to some measurable features. To process these examples, a recently developed technology, Houdini, that allows reasoning in Deontic Defeasible Logic, has been employed.
  Finally we provide a technique to forecast time required in coding, that depends on factors such as knowledge of the legal domain, knowledge of the coding processes, length of the text, and a measure of \textit{depth} that refers to the length of the paths of legal references.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01944v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Cristani, Guido Governatori, Francesco Olivieri, Monica Palmirani, Gabriele Buriola</dc:creator>
    </item>
    <item>
      <title>VECSR: Virtually Embodied Common Sense Reasoning System</title>
      <link>https://arxiv.org/abs/2505.02144</link>
      <description>arXiv:2505.02144v1 Announce Type: new 
Abstract: The development of autonomous agents has seen a revival of enthusiasm due to the emergence of LLMs, such as GPT-4o. Deploying these agents in environments where they coexist with humans (e.g., as domestic assistants) requires special attention to trustworthiness and explainability. However, the use of LLMs and other deep learning models still does not resolve these key issues. Deep learning systems may hallucinate, be unable to justify their decisions as black boxes, or perform badly on unseen scenarios. In this work, we propose the use of s(CASP), a goal-directed common sense reasoner based on Answer Set Programming, to break down the high-level tasks of an autonomous agent into mid-level instructions while justifying the selection of these instructions. To validate its use in real applications we present a framework that integrates the reasoner into the VirtualHome simulator and compares its accuracy with GPT-4o, running some of the real use cases available in the domestic environments of VirtualHome. Additionally, since experiments with VirtualHome have shown the need to reduce the response time (which increases as the agent's decision space grows), we have proposed and evaluated a series of optimizations based on program analysis that exploit the advantages of the top-down execution of s(CASP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02144v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexis R. Tudor, Joaqu\'in Arias, Gopal Gupta</dc:creator>
    </item>
    <item>
      <title>Courcelle's Theorem Without Logic</title>
      <link>https://arxiv.org/abs/2505.02771</link>
      <description>arXiv:2505.02771v1 Announce Type: new 
Abstract: Courcelle's Theorem states that on graphs $G$ of tree-width at most $k$ with a given tree-decomposition of size $t(G)$, graph properties $\mathcal{P}$ definable in Monadic Second Order Logic can be checked in linear time in the size of $t(G)$. Inspired by L. Lov\'asz' work using connection matrices instead of logic, we give a generalized version of Courcelle's theorem which replaces the definability hypothesis by a purely combinatorial hypothesis using a generalization of connection matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02771v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuval Filmus, Johann A. Makowsky</dc:creator>
    </item>
    <item>
      <title>Bilateral base-extension semantics</title>
      <link>https://arxiv.org/abs/2505.01593</link>
      <description>arXiv:2505.01593v1 Announce Type: cross 
Abstract: Bilateralism is the position according to which assertion and rejection are conceptually independent speech acts. Logical bilateralism demands that systems of logic provide conditions for assertion and rejection that are not reducible to each other, which often leads to independent definitions of proof rules (for assertion) and dual proof rules, also called refutation rules (for rejection). Since it provides a critical account of what it means for something to be a proof or a refutation, bilateralism is often studied in the context of proof-theoretic semantics, an approach that aims to elucidate both the meaning of proofs (and refutations) and what kinds of semantics can be given if proofs (and refutations) are considered as basic semantic notions. The recent literature on bilateral proof-theoretic semantics has only dealt with the semantics of proofs and refutations, whereas we deal with semantics in terms of proofs and refutations. In this paper we present a bilateral version of base-extension semantics - one of the most widely studied proof-theoretic semantics - by allowing atomic bases to contain both atomic proof rules and atomic refutation rules. The semantics is shown to be sound and complete with respect to the bilateral dual intuitionistic logic 2Int. Structural similarities between atomic proofs and refutations also allow us to define duality notions for atomic rules, deductions and bases, which may then be used for the proof of bilateral semantic harmony results. Aside from enabling embeddings between different fragments of the language, bilateral semantic harmony is shown to be a restatement of the syntactic horizontal inversion principle, whose meaning-conferring character may now be interpreted as the requirement of preservation of harmony notions already present at the core of the semantics by inferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01593v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Barroso-Nascimento, Maria Os\'orio</dc:creator>
    </item>
    <item>
      <title>Cubing for Tuning</title>
      <link>https://arxiv.org/abs/2504.19039</link>
      <description>arXiv:2504.19039v2 Announce Type: replace 
Abstract: We are exploring the problem of building an automated reasoning procedure that adaptively tunes the high-level solving strategy for a given problem. There are two main distinctive characteristics of our approach: tuning is performed solely online, unlike the common use of tuning as an offline process; and tuning data comes exclusively from the given instance, so we do not rely on the availability of similar benchmarks and can work with unique challenging instances. Our approach builds on top of the divide-and-conquer paradigm that naturally serves partitioned sub-problems for an automated tuning algorithm to obtain a good solving strategy. We demonstrate performance improvement on two classes of important problems--SAT-solving and neural network verification--and show that our method can learn unconventional solving strategies in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19039v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Haoze Wu, Clark Barrett, Nina Narodytska</dc:creator>
    </item>
    <item>
      <title>Terminal Coalgebras and Non-wellfounded Sets in Homotopy Type Theory</title>
      <link>https://arxiv.org/abs/2001.06696</link>
      <description>arXiv:2001.06696v5 Announce Type: replace-cross 
Abstract: Non-wellfounded material sets have been modeled in Martin-L\"of type theory by Lindstr\"om using setoids. In this paper we construct models of non-wellfounded material sets in Homotopy Type Theory (HoTT) where equality is interpreted as the identity type. The first model satisfies Scott's Anti-Foundation Axiom (SAFA) and dualises the construction of iterative sets. The second model satisfies Aczel's Anti-Foundation Axiom (AFA), and is constructed by adaption of Aczel--Mendler's terminal coalgebra theorem to type theory, which requires propositional resizing.
  In an bid to extend coalgebraic theory and anti-foundation axioms to higher type levels, we formulate generalisations of AFA and SAFA, and construct a hierarchy of models which satisfies the SAFA generalisations. These generalisations build on the framework of Univalent Material Set Theory, previously developed by two of the authors.
  Since the model constructions are based on M-types, the paper also includes a characterisation of the identity type of M-types as indexed M-types.
  Our results are formalised in the proof-assistant Agda.</description>
      <guid isPermaLink="false">oai:arXiv.org:2001.06696v5</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H{\aa}kon Robbestad Gylterud, Elisabeth Stenholm, Niccol\`o Veltri</dc:creator>
    </item>
    <item>
      <title>Lifting couplings in Wasserstein spaces</title>
      <link>https://arxiv.org/abs/2110.06591</link>
      <description>arXiv:2110.06591v4 Announce Type: replace-cross 
Abstract: This paper makes mathematically precise the idea that conditional probabilities are analogous to path liftings in geometry.
  The idea of lifting is modelled in terms of the category-theoretic concept of a lens, which can be interpreted as a consistent choice of arrow liftings. The category we study is the one of probability measures over a given standard Borel space, with morphisms given by the couplings, or transport plans.
  The geometrical picture is even more apparent once we equip the arrows of the category with weights, which one can interpret as "lengths" or "costs", forming a so-called weighted category, which unifies several concepts of category theory and metric geometry.
  Indeed, we show that the weighted version of a lens is tightly connected to the notion of submetry in geometry.
  Every weighted category gives rise to a pseudo-quasimetric space via optimization over the arrows. In particular, Wasserstein spaces can be obtained from the weighted categories of probability measures and their couplings, with the weight of a coupling given by its cost.
  In this case, conditionals allow one to form weighted lenses, which one can interpret as "lifting transport plans, while preserving their cost".</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.06591v4</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <category>math.MG</category>
      <category>math.PR</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.46298/compositionality-7-2</arxiv:DOI>
      <arxiv:journal_reference>Compositionality 7(2), 2025</arxiv:journal_reference>
      <dc:creator>Paolo Perrone</dc:creator>
    </item>
    <item>
      <title>DECIDER: A Dual-System Rule-Controllable Decoding Framework for Language Generation</title>
      <link>https://arxiv.org/abs/2403.01954</link>
      <description>arXiv:2403.01954v4 Announce Type: replace-cross 
Abstract: Constrained decoding approaches aim to control the meaning or style of text generated by the pre-trained large language models (LLMs or also PLMs) for various tasks at inference time. However, these methods often guide plausible continuations by greedily and explicitly selecting targets. Though fulfilling the task requirements, these methods may overlook certain general and natural logics that humans would implicitly follow towards such targets. Inspired by cognitive dual-process theory, in this work, we propose a novel decoding framework DECIDER where the base LLMs are equipped with a First-Order Logic (FOL) reasoner to express and evaluate the rules, along with a decision function that merges the outputs of both systems to guide the generation. Unlike previous constrained decodings, DECIDER transforms the encouragement of target-specific words into all words that satisfy several high-level rules, enabling us to programmatically integrate our logic into LLMs. Experiments on CommonGen and PersonaChat demonstrate that DECIDER effectively follows given FOL rules to guide LLMs in a more human-like and logic-controlled manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01954v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Xu, Tian Lan, Yu Ji, Changlong Yu, Wei Wang, Jun Gao, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu</dc:creator>
    </item>
    <item>
      <title>Further Comments on Yablo's Construction</title>
      <link>https://arxiv.org/abs/2504.10370</link>
      <description>arXiv:2504.10370v2 Announce Type: replace-cross 
Abstract: We continue our analysis of Yablo's coding of the liar paradox by infinite acyclic graphs. The present notes are based on and continue the author's previous results on the problem. In particular, our approach is often more systematic than before.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10370v2</guid>
      <category>math.CO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Schlechta</dc:creator>
    </item>
  </channel>
</rss>
