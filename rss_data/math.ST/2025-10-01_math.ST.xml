<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Oct 2025 01:51:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dirichlet moment tensors and the correspondence between admixture and mixture of product models</title>
      <link>https://arxiv.org/abs/2509.25441</link>
      <description>arXiv:2509.25441v2 Announce Type: new 
Abstract: Understanding posterior contraction behavior in Bayesian hierarchical models is of fundamental importance, but progress in this question is relatively sparse in comparison to the theory of density estimation. In this paper, we study two classes of hierarchical models for grouped data, where observations within groups are exchangeable. Using moment tensor decomposition of the distribution of the latent variables, we establish a precise equivalence between the class of Admixture models (such as Latent Dirichlet Allocation) and the class of Mixture of products of multinomial distributions. This correspondence enables us to leverage the result from the latter class of models, which are more well-understood, so as to arrive at the identifiability and posterior contraction rates in both classes under conditions much weaker than in existing literature. For instance, our results shed light on cases where the topics are not linearly independent or the number of topics is misspecified in the admixture setting. Finally, we analyze individual documents' latent allocation performance via the borrowing of strength properties of hierarchical Bayesian modeling. Many illustrations and simulations are provided to support the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25441v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dat Do, Sunrit Chakraborty, Jonathan Terhorst, XuanLong Nguyen</dc:creator>
    </item>
    <item>
      <title>Optimal Nuisance Function Tuning for Estimating a Doubly Robust Functional under Proportional Asymptotics</title>
      <link>https://arxiv.org/abs/2509.25536</link>
      <description>arXiv:2509.25536v1 Announce Type: new 
Abstract: In this paper, we explore the asymptotically optimal tuning parameter choice in ridge regression for estimating nuisance functions of a statistical functional that has recently gained prominence in conditional independence testing and causal inference. Given a sample of size $n$, we study estimators of the Expected Conditional Covariance (ECC) between variables $Y$ and $A$ given a high-dimensional covariate $X \in \mathbb{R}^p$. Under linear regression models for $Y$ and $A$ on $X$ and the proportional asymptotic regime $p/n \to c \in (0, \infty)$, we evaluate three existing ECC estimators and two sample splitting strategies for estimating the required nuisance functions. Since no consistent estimator of the nuisance functions exists in the proportional asymptotic regime without imposing further structure on the problem, we first derive debiased versions of the ECC estimators that utilize the ridge regression nuisance function estimators. We show that our bias correction strategy yields $\sqrt{n}$-consistent estimators of the ECC across different sample splitting strategies and estimator choices. We then derive the asymptotic variances of these debiased estimators to illustrate the nuanced interplay between the sample splitting strategy, estimator choice, and tuning parameters of the nuisance function estimators for optimally estimating the ECC. Our analysis reveals that prediction-optimal tuning parameters (i.e., those that optimally estimate the nuisance functions) may not lead to the lowest asymptotic variance of the ECC estimator -- thereby demonstrating the need to be careful in selecting tuning parameters based on the final goal of inference. Finally, we verify our theoretical results through extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25536v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean McGrath, Debarghya Mukherjee, Rajarshi Mukherjee, Zixiao Jolene Wang</dc:creator>
    </item>
    <item>
      <title>Minimax and adaptive estimation of general linear functionals under sparsity</title>
      <link>https://arxiv.org/abs/2509.25595</link>
      <description>arXiv:2509.25595v1 Announce Type: new 
Abstract: We study the problem of estimating a linear functional $\eta^\intercal \theta$ of a high-dimensional sparse mean vector $\theta$ with an arbitrary loading vector $\eta$ under symmetric noise with exponentially decaying tails, with Gaussian noise as an important example. We first establish the nonasymptotic minimax rate in the oracle setting with known sparsity level $s$. This rate explicitly depends on the structure of $\eta$, sparsity level $s$, and tail parameter of noise. We then develop an adaptive estimator that does not require knowledge of $s$ and prove its optimality, showing that the cost of adaptation is at most logarithmic in $s$. Our analysis for arbitrary loadings uncovers a new phase transition in minimax estimation that does not arise under homogeneous loadings. In addition, we extend the minimax theory to non-symmetric noise settings and to hypothesis testing, and we further explore the estimation with unknown noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25595v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Xie, Dongming Huang</dc:creator>
    </item>
    <item>
      <title>Nonparametric inference under shape constraints: past, present and future</title>
      <link>https://arxiv.org/abs/2509.26040</link>
      <description>arXiv:2509.26040v1 Announce Type: new 
Abstract: We survey the field of nonparametric inference under shape constraints, providing a historical overview and a perspective on its current state. An outlook and some open problems offer thoughts on future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26040v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard J. Samworth</dc:creator>
    </item>
    <item>
      <title>A Tractable Family of Smooth Copulas with Rotational Dependence: Properties, Inference, and Application</title>
      <link>https://arxiv.org/abs/2509.26635</link>
      <description>arXiv:2509.26635v1 Announce Type: new 
Abstract: We introduce a new family of copula densities constructed from univariate distributions on $[0,1]$. Although our construction is structurally simple, the resulting family is versatile: it includes both smooth and irregular examples, and reveals clear links between properties of the underlying univariate distribution and the strength, direction, and form of multivariate dependence. The framework brings with it a range of explicit mathematical properties, including interpretable characterizations of dependence and transparent descriptions of how rotational forms arise. We propose model selection and inference methods in parametric and nonparametric settings, supported by asymptotic theory that reduces multivariate estimation to well-studied univariate problems. Simulation studies confirm the reliable recovery of structural features, and an application involving neural connectivity data illustrates how the family can yield a better fit than existing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26635v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha\"el Lalancette, Robert Zimmerman</dc:creator>
    </item>
    <item>
      <title>One-shot Conditional Sampling: MMD meets Nearest Neighbors</title>
      <link>https://arxiv.org/abs/2509.25507</link>
      <description>arXiv:2509.25507v1 Announce Type: cross 
Abstract: How can we generate samples from a conditional distribution that we never fully observe? This question arises across a broad range of applications in both modern machine learning and classical statistics, including image post-processing in computer vision, approximate posterior sampling in simulation-based inference, and conditional distribution modeling in complex data settings. In such settings, compared with unconditional sampling, additional feature information can be leveraged to enable more adaptive and efficient sampling. Building on this, we introduce Conditional Generator using MMD (CGMMD), a novel framework for conditional sampling. Unlike many contemporary approaches, our method frames the training objective as a simple, adversary-free direct minimization problem. A key feature of CGMMD is its ability to produce conditional samples in a single forward pass of the generator, enabling practical one-shot sampling with low test-time complexity. We establish rigorous theoretical bounds on the loss incurred when sampling from the CGMMD sampler, and prove convergence of the estimated distribution to the true conditional distribution. In the process, we also develop a uniform concentration result for nearest-neighbor based functionals, which may be of independent interest. Finally, we show that CGMMD performs competitively on synthetic tasks involving complex conditional densities, as well as on practical applications such as image denoising and image super-resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25507v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anirban Chatterjee, Sayantan Choudhury, Rohan Hore</dc:creator>
    </item>
    <item>
      <title>A Martingale approach to continuous Portfolio Optimization under CVaR like constraints</title>
      <link>https://arxiv.org/abs/2509.26009</link>
      <description>arXiv:2509.26009v1 Announce Type: cross 
Abstract: We study a continuous-time portfolio optimization problem under an explicit constraint on the Deviation Conditional Value-at-Risk (DCVaR), defined as the difference between the CVaR and the expected terminal wealth. While the mean-CVaR framework has been widely explored, its time-inconsistency complicates the use of dynamic programming. We follow the martingale approach in a complete market setting, as in Gao et al. [4], and extend it by retaining an explicit DCVaR constraint in the problem formulation.  The optimal terminal wealth is obtained by solving a convex constrained minimization problem. This leads to a tractable and interpretable characterization of the optimal strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26009v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>q-fin.RM</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\'er\^ome Lelong (LJK), V\'eronique Maume-Deschamps, William Thevenot</dc:creator>
    </item>
    <item>
      <title>Spectral gap of Metropolis-within-Gibbs under log-concavity</title>
      <link>https://arxiv.org/abs/2509.26175</link>
      <description>arXiv:2509.26175v1 Announce Type: cross 
Abstract: The Metropolis-within-Gibbs (MwG) algorithm is a widely used Markov Chain Monte Carlo method for sampling from high-dimensional distributions when exact conditional sampling is intractable. We study MwG with Random Walk Metropolis (RWM) updates, using proposal variances tuned to match the target's conditional variances. Assuming the target $\pi$ is a $d$-dimensional log-concave distribution with condition number $\kappa$, we establish a spectral gap lower bound of order $\mathcal{O}(1/\kappa d)$ for the random-scan version of MwG, improving on the previously available $\mathcal{O}(1/\kappa^2 d)$ bound. This is obtained by developing sharp estimates of the conductance of one-dimensional RWM kernels, which can be of independent interest. The result shows that MwG can mix substantially faster with variance-adaptive proposals and that its mixing performance is just a constant factor worse than that of the exact Gibbs sampler, thus providing theoretical support to previously observed empirical behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26175v1</guid>
      <category>stat.ML</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cecilia Secchi, Giacomo Zanella</dc:creator>
    </item>
    <item>
      <title>Statistical Inference Framework for Extended Target Detection in mmWave Automotive Radar</title>
      <link>https://arxiv.org/abs/2509.26573</link>
      <description>arXiv:2509.26573v1 Announce Type: cross 
Abstract: Millimeter wave (mmWave) radar systems, owing to their large bandwidth, provide fine range resolution that enables the observation of multiple scatterers originating from a single automotive target commonly referred to as an extended target. Conventional CFAR-based detection algorithms typically treat these scatterers as independent detections, thereby discarding the spatial scattering structure intrinsic to the target. To preserve this scattering spread, this paper proposes a Range-Doppler (RD) segment framework designed to encapsulate the typical scattering profile of an automobile. The statistical characterization of the segment is performed using Maximum Likelihood Estimation (MLE) and posterior density modeling facilitated through Gibbs Markov Chain Monte Carlo (MCMC) sampling. A skewness-based test statistic, derived from the estimated statistical model, is introduced for binary hypothesis classification of extended targets. Additionally, the paper presents a detection pipeline that incorporates Intersection over Union (IoU) and segment centering based on peak response, optimized to work within a single dwell. Extensive evaluations using both simulated and real-world datasets demonstrate the effectiveness of the proposed approach, underscoring its suitability for automotive radar applications through improved detection accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26573v1</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinay Kulkarni, V. V. Reddy, Neha Maheshwari</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation of the stationary density for Hawkes-diffusion systems with known and unknown intensity</title>
      <link>https://arxiv.org/abs/2412.08386</link>
      <description>arXiv:2412.08386v2 Announce Type: replace 
Abstract: We investigate the nonparametric estimation problem of the density $\pi$, representing the stationary distribution of a two-dimensional system $\left(Z_t\right)_{t \in[0, T]}=\left(X_t, \lambda_t\right)_{t \in[0, T]}$. In this system, $X$ is a Hawkes-diffusion process, and $\lambda$ denotes the stochastic intensity of the Hawkes process driving the jumps of $X$. Based on the continuous observation of a path of $(X_t)$ over $[0, T]$, and initially assuming that $\lambda$ is known, we establish the convergence rate of a kernel estimator $\widehat\pi\left(x^*, y^*\right)$ of $\pi\left(x^*,y^*\right)$ as $T \rightarrow \infty$. Interestingly, this rate depends on the value of $y^*$ influenced by the baseline parameter of the Hawkes intensity process. From the rate of convergence of $\widehat\pi\left(x^*,y^*\right)$, we derive the rate of convergence for an estimator of the invariant density $\lambda$. Subsequently, we extend the study to the case where $\lambda$ is unknown, plugging an estimator of $\lambda$ in the kernel estimator and deducing new rates of convergence for the obtained estimator. The proofs establishing these convergence rates rely on probabilistic results that may hold independent interest. We introduce a Girsanov change of measure to transform the Hawkes process with intensity $\lambda$ into a Poisson process with constant intensity. To achieve this, we extend a bound for the exponential moments for the Hawkes process, originally established in the stationary case, to the non-stationary case. Lastly, we conduct a numerical study to illustrate the obtained rates of convergence of our estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08386v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Amorino, Charlotte Dion-Blanc, Arnaud Gloter, Sarah Lemler</dc:creator>
    </item>
    <item>
      <title>Performance of the empirical median for location estimation in heteroscedastic settings</title>
      <link>https://arxiv.org/abs/2501.16956</link>
      <description>arXiv:2501.16956v3 Announce Type: replace 
Abstract: We investigate the performance of the empirical median for location estimation in heteroscedastic settings. Specifically, we consider independent symmetric real-valued random variables that share a common but unknown location parameter while having different and unknown scale parameters. Estimation under heteroscedasticity arises naturally in many practical situations and has recently attracted considerable attention. In this work, we analyze the empirical median as an estimator of the common location parameter and derive matching non-asymptotic upper and lower bounds on its estimation error. These results fully characterize the behavior of the empirical median in heteroscedastic settings, clarifying both its robustness and its intrinsic limitations and offering a precise understanding of its performance in modern settings where data quality may vary across sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16956v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sirine Louati</dc:creator>
    </item>
    <item>
      <title>Conditional Feature Importance revisited: Double Robustness, Efficiency and Inference</title>
      <link>https://arxiv.org/abs/2501.17520</link>
      <description>arXiv:2501.17520v4 Announce Type: replace 
Abstract: Conditional Feature Importance (CFI) was introduced long ago to account for the relationship between the studied feature and the rest of the input. However, CFI has not yet been studied from a theoretical perspective because the conditional sampling step has generally been overlooked. In this article, we demonstrate that the recent Conditional Permutation Importance (CPI) is indeed a valid implementation of this concept. Under the conditional null hypothesis, we then establish a double robustness property that can be leveraged for variable selection: with either a valid model or a valid conditional sampler, the method correctly identifies null coordinates.
  Under the alternative hypothesis, we study the theoretical target and link it to the popular Total Sobol Index (TSI). We introduce the Sobol-CPI, which generalizes CPI/CFI, prove that it is nonparametrically efficient, and provide a bias correction. Finally, we propose a consistent and valid type-I error test and present numerical experiments that illustrate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17520v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angel Reyero-Lobo, Pierre Neuvial, Bertrand Thirion</dc:creator>
    </item>
    <item>
      <title>A Note on Inferential Decisions, Errors and Path-Dependency</title>
      <link>https://arxiv.org/abs/2507.05634</link>
      <description>arXiv:2507.05634v4 Announce Type: replace 
Abstract: Consider the sequential inference of a binary outcome. The process of a posteriori beliefs and its objectively true conditional-probability counterpart generally differ but should lead to the same result eventually in well-defined tests. We show that unless the two are 'essentially identical', differing only by an a priori factor, time-homogeneous continuous decisions based on the former must be path-dependent with respect to state-variables based on the latter or any non-essentially-identical process. Inferential errors decompose into path-dependent and path-independent parts, whose distinct properties are relevant to error mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05634v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangda K. Wren</dc:creator>
    </item>
    <item>
      <title>Gaussian Mixture Model with unknown diagonal covariances via continuous sparse regularization</title>
      <link>https://arxiv.org/abs/2509.12889</link>
      <description>arXiv:2509.12889v2 Announce Type: replace 
Abstract: This paper addresses the statistical estimation of Gaussian Mixture Models (GMMs) with unknown diagonal covariances from independent and identically distributed samples. We employ the Beurling-LASSO (BLASSO), a convex optimization framework that promotes sparsity in the space of measures, to simultaneously estimate the number of components and their parameters. Our main contribution extends the BLASSO methodology to multivariate GMMs with component-specific unknown diagonal covariance matrices-a significantly more flexible setting than previous approaches requiring known and identical covariances. We establish non-asymptotic recovery guarantees with nearly parametric convergence rates for component means, diagonal covariances, and weights, as well as for density prediction. A key theoretical contribution is the identification of an explicit separation condition on mixture components that enables the construction of non-degenerate dual certificates-essential tools for establishing statistical guarantees for the BLASSO. Our analysis leverages the Fisher-Rao geometry of the statistical model and introduces a novel semi-distance adapted to our framework, providing new insights into the interplay between component separation, parameter space geometry, and achievable statistical recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12889v2</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romane Giard (ECL, ICJ, PSPM), Yohann de Castro (ICJ, ECL, PSPM, IUF), Cl\'ement Marteau (PSPM, ICJ, UCBL)</dc:creator>
    </item>
    <item>
      <title>Monte Carlo on a single sample</title>
      <link>https://arxiv.org/abs/2509.17025</link>
      <description>arXiv:2509.17025v3 Announce Type: replace 
Abstract: In this paper, we consider a Monte Carlo simulation method (MinMC) that approximates prices and risk measures for a range $\Gamma$ of model parameters at once. The simulation method that we study has recently gained popularity [HS20, FPP22, BDG24], and we provide a theoretical framework and convergence rates for it. In particular, we show that sample-based approximations to $\mathbb{E}_{\theta}[X]$, where $\theta$ denotes the model and $\mathbb{E}_{\theta}$ the expectation with respect to the distribution $P_\theta$ of the model $\theta$, can be obtained across all $\theta \in \Gamma$ by minimizing a map $V:H\rightarrow \mathbb{R}$ with $H$ a suitable function space. The minimization can be achieved easily by fitting a standard feedforward neural network with stochastic gradient descent. We show that MinMC, which uses only one sample for each model, significantly outperforms a traditional Monte Carlo method performed for multiple values of $\theta$, which are subsequently interpolated. Our case study suggests that MinMC might serve as a new benchmark for parameter-dependent Monte Carlo simulations, which appear not only in quantitative finance but also in many other areas of scientific computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17025v3</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils Detering, Nicole Hufnagel, Paul Kr\"uhner</dc:creator>
    </item>
    <item>
      <title>Nonparametric hazard rate estimation with associated kernels and minimax bandwidth choice</title>
      <link>https://arxiv.org/abs/2509.24535</link>
      <description>arXiv:2509.24535v2 Announce Type: replace 
Abstract: In this paper, we consider the general theory of nonparametric hazard rate estimation with associated kernels, for which the shape of the kernel depends on the point of estimation. We prove MISE convergence results and a central limit theorem for such estimators. We then prove an oracle type inequality for both a local and global minimax bandwidth choice. The results are then illustrated by showing that they apply to the Gamma kernel and providing numerical simulations and an application to biological data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24535v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luce Breuil (MERGE), Sarah Kaaka\"i (LAGA)</dc:creator>
    </item>
    <item>
      <title>Resolution of the Borel-Kolmogorov Paradox via the Maximum Entropy Principle</title>
      <link>https://arxiv.org/abs/2509.24735</link>
      <description>arXiv:2509.24735v2 Announce Type: replace 
Abstract: This paper presents a rigorous resolution of the Borel-Kolmogorov paradox using the Maximum Entropy Principle. We construct a metric-based framework for Bayesian inference that uniquely extends conditional probability to events of null measure. The results unify classical Bayes' rules and provide a robust foundation for Bayesian inference in metric spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24735v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Tr\'esor, Mykola Lukashchuk</dc:creator>
    </item>
    <item>
      <title>Combining an experimental study with external data: study designs and identification strategies</title>
      <link>https://arxiv.org/abs/2406.03302</link>
      <description>arXiv:2406.03302v2 Announce Type: replace-cross 
Abstract: There is increasing interest in combining information from experimental studies, including randomized and single-group trials, with information from external experimental or observational data sources. Such efforts are usually motivated by the desire to compare treatments evaluated in different studies -- for instance, through the introduction of external treatment groups -- or to estimate treatment effects with greater precision. Proposals to combine experimental studies with external data were made at least as early as the 1970s, but in recent years have come under increasing consideration by regulatory agencies involved in drug and device evaluation, particularly with the increasing availability of rich observational data. In this paper, we describe basic templates of study designs and data structures for combining information from experimental studies with external data, and use the potential (counterfactual) outcomes framework to elaborate identification strategies for potential outcome means and average treatment effects in these designs. In formalizing designs and identification strategies for combining information from experimental studies with external data, we hope to provide a conceptual foundation to support the systematic use and evaluation of such efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03302v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lawson Ung, Guanbo Wang, Sebastien Haneuse, Miguel A. Hern\'an, Issa J. Dahabreh</dc:creator>
    </item>
    <item>
      <title>Concentration and moment inequalities for sums of independent heavy-tailed random matrices</title>
      <link>https://arxiv.org/abs/2407.12948</link>
      <description>arXiv:2407.12948v2 Announce Type: replace-cross 
Abstract: We prove Fuk-Nagaev and Rosenthal-type inequalities for sums of independent random matrices, focusing on the situation when the norms of the matrices possess finite moments of only low orders. Our bounds depend on the ``intrinsic'' dimensional characteristics such as the effective rank, as opposed to the dimension of the ambient space. We illustrate the advantages of such results through several applications, including new moment inequalities for sample covariance matrices and their eigenvectors when the underlying distribution is heavy-tailed. Moreover, we demonstrate that our techniques yield sharpened versions of moment inequalities for empirical processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12948v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00440-025-01412-6</arxiv:DOI>
      <arxiv:journal_reference>Probabability Theory and Related Fields (2025), p. 1-28</arxiv:journal_reference>
      <dc:creator>Moritz Jirak, Stanislav Minsker, Yiqiu Shen, Martin Wahl</dc:creator>
    </item>
    <item>
      <title>A unified framework for multivariate two-sample and k-sample kernel-based quadratic distance goodness-of-fit tests</title>
      <link>https://arxiv.org/abs/2407.16374</link>
      <description>arXiv:2407.16374v2 Announce Type: replace-cross 
Abstract: In the statistical literature, as well as in artificial intelligence and machine learning, measures of discrepancy between two probability distributions are largely used to develop measures of goodness-of-fit. We concentrate on quadratic distances, which depend on a non-negative definite kernel. We propose a unified framework for the study of two-sample and k-sample goodness of fit tests based on the concept of matrix distance. We provide a succinct review of the goodness of fit literature related to the use of distance measures, and specifically to quadratic distances. We show that the quadratic distance kernel-based two-sample test has the same functional form with the maximum mean discrepancy test. We develop tests for the $k$-sample scenario, where the two-sample problem is a special case. We derive their asymptotic distribution under the null hypothesis and discuss computational aspects of the test procedures. We assess their performance, in terms of level and power, via extensive simulations and a real data example. The proposed framework is implemented in the QuadratiK package, available in both R and Python environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16374v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marianthi Markatou, Giovanni Saraceno</dc:creator>
    </item>
    <item>
      <title>Asymptotic Classification Error for Heavy-Tailed Renewal Processes</title>
      <link>https://arxiv.org/abs/2408.10502</link>
      <description>arXiv:2408.10502v2 Announce Type: replace-cross 
Abstract: Despite the widespread occurrence of classification problems and the increasing collection of point process data across many disciplines, study of error probability for point process classification only emerged very recently. Here, we consider classification of renewal processes. We obtain asymptotic expressions for the Bhattacharyya bound on misclassification error probabilities for heavy-tailed renewal processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10502v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LSP.2025.3611709</arxiv:DOI>
      <dc:creator>Xinhui Rong, Victor Solo</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic and distribution-uniform Koml\'os-Major-Tusn\'ady approximation</title>
      <link>https://arxiv.org/abs/2502.06188</link>
      <description>arXiv:2502.06188v2 Announce Type: replace-cross 
Abstract: We present nonasymptotic concentration inequalities for sums of independent and identically distributed random variables that yield asymptotic strong Gaussian approximations of Koml\'os, Major, and Tusn\'ady (KMT) [1975,1976]. The constants appearing in our inequalities are either universal or explicit, and thus as corollaries, they imply distribution-uniform generalizations of the aforementioned KMT approximations. In particular, it is shown that uniform integrability of a random variable's $q^{\text{th}}$ moment is both necessary and sufficient for the KMT approximations to hold uniformly at the rate of $o(n^{1/q})$ for $q &gt; 2$ and that having a uniformly lower bounded Sakhanenko parameter -- equivalently, a uniformly upper-bounded Bernstein parameter -- is both necessary and sufficient for the KMT approximations to hold uniformly at the rate of $O(\log n)$. Instantiating these uniform results for a single probability space yields the analogous results of KMT exactly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06188v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian Waudby-Smith, Martin Larsson, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Estimation of relative risk, odds ratio and their logarithms with guaranteed accuracy and controlled sample size ratio</title>
      <link>https://arxiv.org/abs/2503.04876</link>
      <description>arXiv:2503.04876v2 Announce Type: replace-cross 
Abstract: Given two populations from which independent binary observations are taken with parameters $p_1$ and $p_2$ respectively, estimators are proposed for the relative risk $p_1/p_2$, the odds ratio $p_1(1-p_2)/(p_2(1-p_1))$ and their logarithms. The sampling strategy used by the estimators is based on two-stage sequential sampling applied to each population, where the sample sizes of the second stage are computed from the results observed in the first stage. The estimators guarantee that the relative mean-square error, or the mean-square error for the logarithmic versions, is less than a target value for any $p_1, p_2 \in (0,1)$, and the ratio of average sample sizes from the two populations is close to a prescribed value. The estimators can also be used with group sampling, whereby samples are taken in batches of fixed size from the two populations simultaneously, each batch containing samples from the two populations. The efficiency of the estimators with respect to the Cram\'er-Rao bound is good, and in particular it is close to $1$ for small values of the target error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04876v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Mendo</dc:creator>
    </item>
    <item>
      <title>An exploration of sequential Bayesian variable selection -- A comment on Garc\'{i}a-Donato et al. (2025). "Model uncertainty and missing data: An objective Bayesian perspective"</title>
      <link>https://arxiv.org/abs/2509.22901</link>
      <description>arXiv:2509.22901v2 Announce Type: replace-cross 
Abstract: Our comment on Garc\'ia-Donato et al. (2025). "Model uncertainty and missing data: An objective Bayesian perspective" explores a further extension of the proposed methodology. Specifically, we consider the sequential setting where (potentially missing) data accumulate over time, with the goal of continuously monitoring statistical evidence, as opposed to assessing it only once data collection terminates. We explore a new variable selection method based on sequential model confidence sets, as proposed by Arnold et al. (2024), and show that it can help stabilise the inference of Garc\'ia-Donato et al. (2025). To be published as "Invited discussion" in Bayesian Analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22901v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sebastian Arnold, Alexander Ly</dc:creator>
    </item>
    <item>
      <title>Sign and signed rank tests for paired functions</title>
      <link>https://arxiv.org/abs/2509.24170</link>
      <description>arXiv:2509.24170v2 Announce Type: replace-cross 
Abstract: Simple nonparametric tests for paired functional data are an understudied area, despite recent advances in similar tests for other types of functional data. While the sign test has received limited treatment, the signed rank-type test has not previously been examined. The aim of the present work is to develop and evaluate these types of tests for functional data. We derive a simple, theoretical framework for both sign and signed rank tests for pairs of functions. In particular, we demonstrate that doubly ranked testing -- a newly developed framework for testing hypotheses involving functional data -- is a useful conduit for examining hypotheses regarding pairs o,f functions. We briefly examine the operating characteristics of all derived tests. We also use the described approaches to re-analyze pairs of functions from a randomized crossover study of heart health during simulated flight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24170v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark J. Meyer</dc:creator>
    </item>
  </channel>
</rss>
