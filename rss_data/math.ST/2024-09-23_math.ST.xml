<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Sep 2024 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stochastic mirror descent for nonparametric adaptive importance sampling</title>
      <link>https://arxiv.org/abs/2409.13272</link>
      <description>arXiv:2409.13272v1 Announce Type: new 
Abstract: This paper addresses the problem of approximating an unknown probability distribution with density $f$ -- which can only be evaluated up to an unknown scaling factor -- with the help of a sequential algorithm that produces at each iteration $n\geq 1$ an estimated density $q_n$.The proposed method optimizes the Kullback-Leibler divergence using a mirror descent (MD) algorithm directly on the space of density functions, while a stochastic approximation technique helps to manage between algorithm complexity and variability. One of the key innovations of this work is the theoretical guarantee that is provided for an algorithm with a fixed MD learning rate  $\eta \in (0,1 )$. The main result is that the sequence $q_n$ converges almost surely to the target density $f$ uniformly on compact sets. Through numerical experiments, we show that fixing the learning rate $\eta \in (0,1 )$ significantly improves the algorithm's performance, particularly in the context of multi-modal target distributions where a small value of $\eta$ allows to increase the chance of finding all modes. Additionally, we propose a particle subsampling method to enhance computational efficiency and compare our method against other approaches through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13272v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pascal Bianchi (IRMAR), Bernard Delyon (IRMAR), Victor Priser, Fran\c{c}ois Portier</dc:creator>
    </item>
    <item>
      <title>Properly constrained reference priors decay rates for efficient and robust posterior inference</title>
      <link>https://arxiv.org/abs/2409.13041</link>
      <description>arXiv:2409.13041v1 Announce Type: cross 
Abstract: In Bayesian analysis, reference priors are widely recognized for their objective nature. Yet, they often lead to intractable and improper priors, which complicates their application. Besides, informed prior elicitation methods are penalized by the subjectivity of the choices they require. In this paper, we aim at proposing a reconciliation of the aforementioned aspects. Leveraging the objective aspect of reference prior theory, we introduce two strategies of constraint incorporation to build tractable reference priors. One provides a simple and easy-to-compute solution when the improper aspect is not questioned, and the other introduces constraints to ensure the reference prior is proper, or it provides proper posterior. Our methodology emphasizes the central role of Jeffreys prior decay rates in this process, and the practical applicability of our results is demonstrated using an example taken from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13041v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Van Biesbroeck</dc:creator>
    </item>
    <item>
      <title>High Dimensional Space Oddity</title>
      <link>https://arxiv.org/abs/2409.13046</link>
      <description>arXiv:2409.13046v1 Announce Type: cross 
Abstract: In his 1996 paper, Talagrand highlighted that the Law of Large Numbers (LLN) for independent random variables can be viewed as a geometric property of multidimensional product spaces. This phenomenon is known as the concentration of measure. To illustrate this profound connection between geometry and probability theory, we consider a seemingly intractable geometric problem in multidimensional Euclidean space and solve it using standard probabilistic tools such as the LLN and the Central Limit Theorem (CLT).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13046v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haim Bar, Vladimir Pozdnyakov</dc:creator>
    </item>
    <item>
      <title>A Two-stage Inference Procedure for Sample Local Average Treatment Effects in Randomized Experiments</title>
      <link>https://arxiv.org/abs/2409.13300</link>
      <description>arXiv:2409.13300v1 Announce Type: cross 
Abstract: In a given randomized experiment, individuals are often volunteers and can differ in important ways from a population of interest. It is thus of interest to focus on the sample at hand. This paper focuses on inference about the sample local average treatment effect (LATE) in randomized experiments with non-compliance. We present a two-stage procedure that provides asymptotically correct coverage rate of the sample LATE in randomized experiments. The procedure uses a first-stage test to decide whether the instrument is strong or weak, and uses different confidence sets depending on the first-stage result. Proofs of the procedure is developed for the situation with and without regression adjustment and for two experimental designs (complete randomization and Mahalaonobis distance based rerandomization). Finite sample performance of the methods are studied using extensive Monte Carlo simulations and the methods are applied to data from a voter encouragement experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13300v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhen Zhong, Per Johansson, Junni L. Zhang</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation of trawl processes: Theory and Applications</title>
      <link>https://arxiv.org/abs/2209.05894</link>
      <description>arXiv:2209.05894v2 Announce Type: replace 
Abstract: Trawl processes belong to the class of continuous-time, strictly stationary, infinitely divisible processes; they are defined as L\'{e}vy bases evaluated over deterministic trawl sets. This article presents the first nonparametric estimator of the trawl function characterising the trawl set and the serial correlation of the process. Moreover, it establishes a detailed asymptotic theory for the proposed estimator, including a law of large numbers and a central limit theorem for various asymptotic relations between an in-fill and a long-span asymptotic regime. In addition, it develops consistent estimators for both the asymptotic bias and variance, which are subsequently used for establishing feasible central limit theorems which can be applied to data. A simulation study shows the good finite sample performance of the proposed estimators. The new methodology is applied to forecasting high-frequency financial spread data from a limit order book and to estimating the busy-time distribution of a stochastic queue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.05894v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Orimar Sauri, Almut E. D. Veraart</dc:creator>
    </item>
    <item>
      <title>Multivariate generalized Pareto distributions along extreme directions</title>
      <link>https://arxiv.org/abs/2311.04618</link>
      <description>arXiv:2311.04618v4 Announce Type: replace 
Abstract: When modeling a vector of risk variables, extreme scenarios are often of special interest. The peaks-over-thresholds method hinges on the notion that, asymptotically, the excesses over a vector of high thresholds follow a multivariate generalized Pareto distribution. However, existing literature has primarily concentrated on the setting when all risk variables are always large simultaneously. In reality, this assumption is often not met, especially in high dimensions.
  In response to this limitation, we study scenarios where distinct groups of risk variables may exhibit joint extremes while others do not. These discernible groups are derived from the angular measure inherent in the corresponding max-stable distribution, whence the term extreme direction. We explore such extreme directions within the framework of multivariate generalized Pareto distributions, with a focus on their probability density functions in relation to an appropriate dominating measure.
  Furthermore, we provide a stochastic construction that allows any prespecified set of risk groups to constitute the distribution's extreme directions. This construction takes the form of a smoothed max-linear model and accommodates the full spectrum of conceivable max-stable dependence structures. Additionally, we introduce a generic simulation algorithm tailored for multivariate generalized Pareto distributions, offering specific implementations for extensions of the logistic and H\"usler-Reiss families capable of carrying arbitrary extreme directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04618v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anas Mourahib, Anna Kiriliouk, Johan Segers</dc:creator>
    </item>
    <item>
      <title>A Trek Rule for the Lyapunov Equation</title>
      <link>https://arxiv.org/abs/2407.21223</link>
      <description>arXiv:2407.21223v2 Announce Type: replace 
Abstract: The Lyapunov equation is a linear matrix equation characterizing the cross-sectional steady-state covariance matrix of a Gaussian Markov process. We show a new version of the trek rule for this equation, which links the graphical structure of the drift of the process to the entries of the steady-state covariance matrix. In general, the trek rule is a power series expansion of the covariance matrix, though for acyclic models it simplifies to a polynomial in the off-diagonal entries of the drift matrix. Using the trek rule we can give relatively explicit formulas for the entries of the covariance matrix for some special cases of the drift matrix. These results illustrate notable differences between covariance models entailed by the Lyapunov equation and those entailed by linear additive noise models. To further explore differences and similarities between these two model classes, we use the trek rule to derive a new lower bound for the marginal variances in the acyclic case. This sheds light on the phenomenon, well known for the linear additive noise model, that the variances in the acyclic case tend to increase along a topological ordering of the variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21223v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels Richard Hansen</dc:creator>
    </item>
    <item>
      <title>Rates of Fisher information convergence in the central limit theorem for nonlinear statistics</title>
      <link>https://arxiv.org/abs/2205.14446</link>
      <description>arXiv:2205.14446v4 Announce Type: replace-cross 
Abstract: We develop a general method to study the Fisher information distance in central limit theorem for nonlinear statistics. We first construct completely new representations for the score function. We then use these representations to derive quantitative estimates for the Fisher information distance. To illustrate the applicability of our approach, explicit rates of Fisher information convergence for quadratic forms and the functions of sample means are provided. For the sums of independent random variables, we obtain the Fisher information bounds without requiring the finiteness of Poincar\'e constant. Our method can also be used to bound the Fisher information distance in non-central limit theorems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.14446v4</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nguyen Tien Dung</dc:creator>
    </item>
    <item>
      <title>Causal Identification for Complex Functional Longitudinal Studies</title>
      <link>https://arxiv.org/abs/2206.12525</link>
      <description>arXiv:2206.12525v5 Announce Type: replace-cross 
Abstract: Real-time monitoring in modern medical research introduces functional longitudinal data, characterized by continuous-time measurements of outcomes, treatments, and confounders. This complexity leads to uncountably infinite treatment-confounder feedbacks, which traditional causal inference methodologies cannot handle. Inspired by the coarsened data framework, we adopt stochastic process theory, measure theory, and net convergence to propose a nonparametric causal identification framework. This framework generalizes classical g-computation, inverse probability weighting, and doubly robust formulas, accommodating time-varying outcomes subject to mortality and censoring for functional longitudinal data. We examine our framework through Monte Carlo simulations. Our approach addresses significant gaps in current methodologies, providing a solution for functional longitudinal data and paving the way for future estimation work in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.12525v5</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Ying</dc:creator>
    </item>
    <item>
      <title>Vaccine efficacy for binary post-infection outcomes under misclassification without monotonicity</title>
      <link>https://arxiv.org/abs/2211.16502</link>
      <description>arXiv:2211.16502v5 Announce Type: replace-cross 
Abstract: In order to meet regulatory approval, pharmaceutical companies often must demonstrate that new vaccines reduce the total risk of a post-infection outcome like transmission, symptomatic disease, severe illness, or death in randomized, placebo-controlled trials. Given that infection is a necessary precondition for a post-infection outcome, one can use principal stratification to partition the total causal effect of vaccination into two causal effects: vaccine efficacy against infection, and the principal effect of vaccine efficacy against a post-infection outcome in the patients that would be infected under both placebo and vaccination. Despite the importance of such principal effects to policymakers, these estimands are generally unidentifiable, even under strong assumptions that are rarely satisfied in real-world trials. We develop a novel method to nonparametrically point identify these principal effects while eliminating the monotonicity assumption and allowing for measurement error. Furthermore, our results allow for multiple treatments, and are general enough to be applicable outside of vaccine efficacy. Our method relies on the fact that many vaccine trials are run at geographically disparate health centers, and measure biologically-relevant categorical pretreatment covariates. We show that our method can be applied to a variety of clinical trial settings where vaccine efficacy against infection and a post-infection outcome can be jointly inferred. This can yield new insights from existing vaccine efficacy trial data and will aid researchers in designing new multi-arm clinical trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.16502v5</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rob Trangucci, Yang Chen, Jon Zelner</dc:creator>
    </item>
    <item>
      <title>Fusion regression methods with repeated functional data</title>
      <link>https://arxiv.org/abs/2308.01747</link>
      <description>arXiv:2308.01747v4 Announce Type: replace-cross 
Abstract: Linear regression and classification methods with repeated functional data are considered. For each statistical unit in the sample, a real-valued parameter is observed over time under different conditions related by some neighborhood structure (spatial, group, etc.). Two regression methods based on fusion penalties are proposed to consider the dependence induced by this structure. These methods aim to obtain parsimonious coefficient regression functions, by determining if close conditions are associated with common regression coefficient functions. The first method is a generalization to functional data of the variable fusion methodology based on the 1-nearest neighbor. The second one relies on the group fusion lasso penalty which assumes some grouping structure of conditions and allows for homogeneity among the regression coefficient functions within groups. Numerical simulations and an application of electroencephalography data are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01747v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Issam-Ali Moindji\'e, Cristian Preda, Sophie Dabo-Niang</dc:creator>
    </item>
    <item>
      <title>Randomization Inference When N Equals One</title>
      <link>https://arxiv.org/abs/2310.16989</link>
      <description>arXiv:2310.16989v2 Announce Type: replace-cross 
Abstract: N-of-1 experiments, where a unit serves as its own control and treatment in different time windows, have been used in certain medical contexts for decades. However, due to effects that accumulate over long time windows and interventions that have complex evolution, a lack of robust inference tools has limited the widespread applicability of such N-of-1 designs. This work combines techniques from experiment design in causal inference and system identification from control theory to provide such an inference framework. We derive a model of the dynamic interference effect that arises in linear time-invariant dynamical systems. We show that a family of causal estimands analogous to those studied in potential outcomes are estimable via a standard estimator derived from the method of moments. We derive formulae for higher moments of this estimator and describe conditions under which N-of-1 designs may provide faster ways to estimate the effects of interventions in dynamical systems. We also provide conditions under which our estimator is asymptotically normal and derive valid confidence intervals for this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16989v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tengyuan Liang, Benjamin Recht</dc:creator>
    </item>
  </channel>
</rss>
