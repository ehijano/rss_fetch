<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 May 2024 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Beyond Theorems: A Counterexample to Potential Markov Game Criteria</title>
      <link>https://arxiv.org/abs/2405.08206</link>
      <description>arXiv:2405.08206v1 Announce Type: new 
Abstract: There are only limited classes of multi-player stochastic games in which independent learning is guaranteed to converge to a Nash equilibrium. Markov potential games are a key example of such classes. Prior work has outlined sets of sufficient conditions for a stochastic game to qualify as a Markov potential game. However, these conditions often impose strict limitations on the game's structure and tend to be challenging to verify. To address these limitations, Mguni et al. [12] introduce a relaxed notion of Markov potential games and offer an alternative set of necessary conditions for categorizing stochastic games as potential games. Under these conditions, the authors claim that a deterministic Nash equilibrium can be computed efficiently by solving a dual Markov decision process. In this paper, we offer evidence refuting this claim by presenting a counterexample.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08206v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fatemeh Fardno, Seyed Majid Zahedi</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Combinatorial Contracts</title>
      <link>https://arxiv.org/abs/2405.08260</link>
      <description>arXiv:2405.08260v1 Announce Type: new 
Abstract: Combinatorial contracts are emerging as a key paradigm in algorithmic contract design, paralleling the role of combinatorial auctions in algorithmic mechanism design. In this paper we study natural combinatorial contract settings involving teams of agents, each capable of performing multiple actions. This scenario extends two fundamental special cases previously examined in the literature, namely the single-agent combinatorial action model of [Duetting et al., 2021] and the multi-agent binary-action model of [Babaioff et al., 2012, Duetting et al., 2023].
  We study the algorithmic and computational aspects of these settings, highlighting the unique challenges posed by the absence of certain monotonicity properties essential for analyzing the previous special cases. To navigate these complexities, we introduce a broad set of novel tools that deepen our understanding of combinatorial contracts environments and yield good approximation guarantees.
  Our main result is a constant-factor approximation for submodular multi-agent multi-action problems with value and demand oracles access. This result is tight: we show that this problem admits no PTAS (even under binary actions). As a side product of our main result, we devise an FPTAS, with value and demand oracles, for single-agent combinatorial action scenarios with general reward functions, which is of independent interest. We also provide bounds on the gap between the optimal welfare and the principal's utility. We show that, for subadditive rewards, perhaps surprisingly, this gap scales only logarithmically (rather than linearly) in the size of the action space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08260v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Duetting, Tomer Ezra, Michal Feldman, Thomas Kesselheim</dc:creator>
    </item>
    <item>
      <title>Exploring Equilibrium Strategies in Network Games with Generative AI</title>
      <link>https://arxiv.org/abs/2405.08289</link>
      <description>arXiv:2405.08289v1 Announce Type: new 
Abstract: Game theory offers a powerful framework for analyzing strategic interactions among decision-makers, providing tools to model, analyze, and predict their behavior. However, implementing game theory can be challenging due to difficulties in deriving solutions, understanding interactions, and ensuring optimal performance. Traditional non-AI and discriminative AI approaches have made valuable contributions but struggle with limitations in handling large-scale games and dynamic scenarios. In this context, generative AI emerges as a promising solution because of its superior data analysis and generation capabilities. This paper comprehensively summarizes the challenges, solutions, and outlooks of combining generative AI with game theory. We start with reviewing the limitations of traditional non-AI and discriminative AI approaches in employing game theory, and then highlight the necessity and advantages of integrating generative AI. Next, we explore the applications of generative AI in various stages of the game theory lifecycle, including model formulation, solution derivation, and strategy improvement. Additionally, from game theory viewpoint, we propose a generative AI-enabled framework for optimizing machine learning model performance against false data injection attacks, supported by a case study to demonstrate its effectiveness. Finally, we outline future research directions for generative AI-enabled game theory, paving the way for its further advancements and development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08289v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaoqi Yang, Hongyang Du, Geng Sun, Zehui Xiong, Dusit Niyato, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Differentiable Bilevel Programming for Stackelberg Congestion Games</title>
      <link>https://arxiv.org/abs/2209.07618</link>
      <description>arXiv:2209.07618v4 Announce Type: replace 
Abstract: In a Stackelberg congestion game (SCG), a leader aims to maximize their own gain by anticipating and manipulating the equilibrium state at which the followers settle by playing a congestion game. Often formulated as bilevel programs, large-scale SCGs are well known for their intractability and complexity. Here, we attempt to tackle this computational challenge by marrying traditional methodologies with the latest differentiable programming techniques in machine learning. The core idea centers on replacing the lower-level equilibrium problem with a smooth evolution trajectory defined by the imitative logit dynamic (ILD), which we prove converges to the equilibrium of the congestion game under mild conditions. Building upon this theoretical foundation, we propose two new local search algorithms for SCGs. The first is a gradient descent algorithm that obtains the derivatives by unrolling ILD via differentiable programming. Thanks to the smoothness of ILD, the algorithm promises both efficiency and scalability. The second algorithm adds a heuristic twist by cutting short the followers' evolution trajectory. Behaviorally, this means that, instead of anticipating the followers' best response at equilibrium, the leader seeks to approximate that response by only looking ahead a limited number of steps. Our numerical experiments are carried out over various instances of classic SCG applications, ranging from toy benchmarks to large-scale real-world examples. The results show the proposed algorithms are reliable and scalable local solvers that deliver high-quality solutions with greater regularity and significantly less computational effort compared to the many incumbents included in our study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.07618v4</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayang Li, Jing Yu, Qianni Wang, Boyi Liu, Zhaoran Wang, Yu Marco Nie</dc:creator>
    </item>
    <item>
      <title>Liquid Welfare Guarantees for No-Regret Learning in Sequential Budgeted Auctions</title>
      <link>https://arxiv.org/abs/2210.07502</link>
      <description>arXiv:2210.07502v4 Announce Type: replace 
Abstract: We study the liquid welfare in sequential first-price auctions with budget-limited buyers. We focus on first-price auctions, which are increasingly commonly used in many settings, and consider liquid welfare, a natural and well-studied generalization of social welfare for buyers with budgets. We use a behavioral model for the buyers, assuming a learning style guarantee: the resulting utility of each buyer is within a $\gamma$ factor (where $\gamma\ge 1$) of the utility achievable by shading her value with the same factor at each round. Under this assumption, we show a $\gamma+1/2+O(1/\gamma)$ price of anarchy for liquid welfare assuming buyers have additive valuations. This positive result is in contrast to sequential second-price auctions, where even with $\gamma=1$, the resulting liquid welfare can be arbitrarily smaller than the maximum liquid welfare. We prove a lower bound of $\gamma$ on the liquid welfare loss under the above assumption in first-price auctions, making our bound asymptotically tight. For the case when $\gamma = 1$ our theorem implies a price of anarchy upper bound that is about $2.41$; we show a lower bound of $2$ for that case.
  We also give a learning algorithm that the players can use to achieve the guarantee needed for our liquid welfare result. Our algorithm achieves utility within a $\gamma=O(1)$ factor of the optimal utility even when a buyer's values and the bids of the other buyers are chosen adversarially, assuming the buyer's budget grows linearly with time. The competitiveness guarantee of the learning algorithm deteriorates somewhat as the budget grows slower than linearly with time.
  Finally, we extend our liquid welfare results for the case where buyers have submodular valuations over the set of items they win across iterations with a slightly worse price of anarchy bound of $\gamma+1+O(1/\gamma)$ compared to the guarantee for the additive case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.07502v4</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3580507.3597772 10.1287/moor.2023.0274</arxiv:DOI>
      <dc:creator>Giannis Fikioris, \'Eva Tardos</dc:creator>
    </item>
    <item>
      <title>Bandits for Sponsored Search Auctions under Unknown Valuation Model: Case Study in E-Commerce Advertising</title>
      <link>https://arxiv.org/abs/2304.00999</link>
      <description>arXiv:2304.00999v2 Announce Type: replace 
Abstract: This paper presents a bidding system for sponsored search auctions under an unknown valuation model. This formulation assumes that the bidder's value is unknown, evolving arbitrarily, and observed only upon winning an auction. Unlike previous studies, we do not impose any assumptions on the nature of feedback and consider the problem of bidding in sponsored search auctions in its full generality. Our system is based on a bandit framework that is resilient to the black-box auction structure and delayed and batched feedback. To validate our proposed solution, we conducted a case study at Zalando, a leading fashion e-commerce company. We outline the development process and describe the promising outcomes of our bandits-based approach to increase profitability in sponsored search auctions. We discuss in detail the technical challenges that were overcome during the implementation, shedding light on the mechanisms that led to increased profitability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00999v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danil Provodin, J\'er\'emie Joudioux, Eduard Duryev</dc:creator>
    </item>
    <item>
      <title>On the Potential and Limitations of Proxy Voting: Delegation with Incomplete Votes</title>
      <link>https://arxiv.org/abs/2309.05642</link>
      <description>arXiv:2309.05642v2 Announce Type: replace 
Abstract: We study elections where voters are faced with the challenge of expressing preferences over an extreme number of issues under consideration. This is largely motivated by emerging blockchain governance systems, which include voters with different weights and a massive number of community generated proposals. In such scenarios, it is natural to expect that voters will have incomplete preferences, as they may only be able to evaluate or be confident about a very small proportion of the alternatives. As a result, the election outcome may be significantly affected, leading to suboptimal decisions. Our central inquiry revolves around whether delegation of ballots to proxies possessing greater expertise or a more comprehensive understanding of the voters' preferences can lead to outcomes with higher legitimacy and enhanced voters' satisfaction in elections where voters submit incomplete preferences. To explore its aspects, we introduce the following model: potential proxies advertise their ballots over multiple issues, and each voter either delegates to a seemingly attractive proxy or casts a ballot directly. We identify necessary and sufficient conditions that could lead to a socially better outcome by leveraging the participation of proxies. We accompany our theoretical findings with experiments on instances derived from real datasets. Overall, our results enhance the understanding of the power of delegation towards improving election outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05642v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgios Amanatidis, Aris Filos-Ratsikas, Philip Lazos, Evangelos Markakis, Georgios Papasotiropoulos</dc:creator>
    </item>
    <item>
      <title>Proof of Sampling: A Nash Equilibrium-Secured Verification Protocol for Decentralized Systems</title>
      <link>https://arxiv.org/abs/2405.00295</link>
      <description>arXiv:2405.00295v2 Announce Type: replace 
Abstract: This paper presents a secure and versatile sampling-based verification protocol, Proof of Sampling (PoSP) protocol, suitable for a wide range of decentralized applications. Our protocol has a unique Nash Equilibrium in pure strategies, which compels rational participants to act honestly, thus fortifying the network's integrity. This can be achieved with manageable computational overhead. When applied to decentralized inference for AI applications, we design spML based on PoSP protocol, which ingeniously amalgamates the strengths of optimistic fraud proof and zero knowledge proof based approaches, the foremost approaches in the domain at present. Moreover, the PoSP protocol can be effectively utilized for designing verification mechanisms within Actively Validated Services (AVS) in EigenLayer and Layer 2 solutions, further broadening its applicability. This innovative approach not only enhances the security and efficiency of decentralized systems but also paves the way for a new generation of scalable and reliable decentralized applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00295v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Zhang, Shouqiao Wang</dc:creator>
    </item>
    <item>
      <title>Incentive Compatibility in the Auto-bidding World</title>
      <link>https://arxiv.org/abs/2301.13414</link>
      <description>arXiv:2301.13414v2 Announce Type: replace-cross 
Abstract: Auto-bidding has recently become a popular feature in ad auctions. This feature enables advertisers to simply provide high-level constraints and goals to an automated agent, which optimizes their auction bids on their behalf. In this paper, we examine the effect of different auctions on the incentives of advertisers to report their constraints to the auto-bidder intermediaries. More precisely, we study whether canonical auctions such as first price auction (FPA) and second price auction (SPA) are auto-bidding incentive compatible (AIC): whether an advertiser can gain by misreporting their constraints to the autobidder.
  We consider value-maximizing advertisers in two important settings: when they have a budget constraint and when they have a target cost-per-acquisition constraint. The main result of our work is that for both settings, FPA and SPA are not AIC. This contrasts with FPA being AIC when auto-bidders are constrained to bid using a (sub-optimal) uniform bidding policy. We further extend our main result and show that any (possibly randomized) auction that is truthful (in the classic profit-maximizing sense), scalar invariant and symmetric is not AIC. Finally, to complement our findings, we provide sufficient market conditions for FPA and SPA to become AIC for two advertisers. These conditions require advertisers' valuations to be well-aligned. This suggests that when the competition is intense for all queries, advertisers have less incentive to misreport their constraints.
  From a methodological standpoint, we develop a novel continuous model of queries. This model provides tractability to study equilibrium with auto-bidders, which contrasts with the standard discrete query model, which is known to be hard. Through the analysis of this model, we uncover a surprising result: in auto-bidding with two advertisers, FPA and SPA are auction equivalent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13414v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yeganeh Alimohammadi, Aranyak Mehta, Andres Perlroth</dc:creator>
    </item>
    <item>
      <title>Minimizing Weighted Counterfactual Regret with Optimistic Online Mirror Descent</title>
      <link>https://arxiv.org/abs/2404.13891</link>
      <description>arXiv:2404.13891v2 Announce Type: replace-cross 
Abstract: Counterfactual regret minimization (CFR) is a family of algorithms for effectively solving imperfect-information games. It decomposes the total regret into counterfactual regrets, utilizing local regret minimization algorithms, such as Regret Matching (RM) or RM+, to minimize them. Recent research establishes a connection between Online Mirror Descent (OMD) and RM+, paving the way for an optimistic variant PRM+ and its extension PCFR+. However, PCFR+ assigns uniform weights for each iteration when determining regrets, leading to substantial regrets when facing dominated actions. This work explores minimizing weighted counterfactual regret with optimistic OMD, resulting in a novel CFR variant PDCFR+. It integrates PCFR+ and Discounted CFR (DCFR) in a principled manner, swiftly mitigating negative effects of dominated actions and consistently leveraging predictions to accelerate convergence. Theoretical analyses prove that PDCFR+ converges to a Nash equilibrium, particularly under distinct weighting schemes for regrets and average strategies. Experimental results demonstrate PDCFR+'s fast convergence in common imperfect-information games. The code is available at https://github.com/rpSebastian/PDCFRPlus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13891v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Xu, Kai Li, Bingyun Liu, Haobo Fu, Qiang Fu, Junliang Xing, Jian Cheng</dc:creator>
    </item>
  </channel>
</rss>
