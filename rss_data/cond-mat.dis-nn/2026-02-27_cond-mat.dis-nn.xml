<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Probing the influence of topological and geometric disorder on the spectrum of the differential Laplacian operator on networks</title>
      <link>https://arxiv.org/abs/2602.22341</link>
      <description>arXiv:2602.22341v1 Announce Type: new 
Abstract: Metric networks are network-shaped, one-dimensional structures on which one can solve differential equations to simulate a wide range of physical systems including conjugated molecules, photonic crystals, quantum mechanics in waveguide networks, and acoustic metamaterials. More concretely, a metric network is a network whose edges are each assigned a notion of length and a coordinate describing position. One can then define function spaces and differential operators on these objects to model the aforementioned systems. Recent software advancements have made it feasible to analyze partial differential equations on large, compact metric networks with a vast array of structures. Here, we generate compact metric network structures using the spatial tessellations of two-dimensional hyperuniform point patterns, which have suppressed large-scale density fluctuations relative to typical disordered point patterns. This choice of structure is inspired by the exotic physical properties of network materials with these structures in other contexts. Then, we characterize the eigenvalue spectrum structure of the differential Laplace operator on these networks. In particular, we find that gaps can form in the eigenvalue spectra of these networks whose widths increase when the distribution of edge lengths is narrow and as the number of triangular faces increases. Importantly, many of the structures we consider are realizable in Euclidean space, meaning they are well-suited for practical applications in, e.g., metamaterial design. This work can thus be used to inform the design of metric network-based systems with spectral gaps with tunable widths and locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22341v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Emmett Maher, Jeremy L. Marzuola, Katherine A. Newhall</dc:creator>
    </item>
    <item>
      <title>Impact of Stealthy Hyperuniform Magnetic Impurity Configurations on Bulk Magnetism in a Two-dimensional Heisenberg Model</title>
      <link>https://arxiv.org/abs/2602.22484</link>
      <description>arXiv:2602.22484v1 Announce Type: new 
Abstract: We investigate an antiferromagnetic quantum Heisenberg model on a square lattice with high-spin magnetic impurities to clarify how random and stealthy hyperuniform impurity configurations influence the bulk magnetic properties. Stealthy hyperuniform configurations are generated using generalized cost functions that interpolate between square-lattice-like and triangular-lattice-like arrangements. Using linear spin-wave theory for the mixed-spin model, we demonstrate that triangular-lattice-like arrangements yield a larger average staggered magnetization than both random and square-lattice-like cases. This enhancement originates from sublattice effects: while the square-lattice-like configuration enforces nearest-neighbor impurities to occupy opposite sublattices due to its bipartite structure, the triangular-lattice-like arrangement allows same-sublattice nearest-neighbor pairs, thereby strengthening cooperative magnetic enhancement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22484v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Asakura, K. Yamamoto, A. Koga</dc:creator>
    </item>
    <item>
      <title>Exact mapping of a spin glass with correlated disorder to the pure Ising model</title>
      <link>https://arxiv.org/abs/2602.22657</link>
      <description>arXiv:2602.22657v1 Announce Type: new 
Abstract: We introduce an Ising spin-glass model with correlated disorder which continuously interpolates between the pure ferromagnetic Ising model and the Edwards-Anderson model with symmetric disorder. For this model, we prove that physical quantities on the Nishimori line (NL) can be expressed exactly in terms of those of the pure Ising model at an effective temperature on any lattice in any dimension. For example, the energy on the NL is equal to the energy of the pure Ising model at the effective temperature up to a constant and a trivial factor. More remarkably, the specific heat on the NL equals the energy, not the specific heat, of the pure Ising model at the effective temperature, again up to a constant and a trivial factor. Gauge-noninvariant quantities such as the magnetization and correlation functions are exactly equal to the corresponding quantities of the pure Ising model at the effective temperature. These exact relations imply that the leading critical behavior at that multicritical point for the disorder-correlated model is pure-Ising-like, in contrast to the conventional multicritical universality class of the standard Edwards-Anderson model. Our results motivate further investigations of the relatively unexplored topic of correlations in disorder in spin glasses and related problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22657v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hidetoshi Nishimori</dc:creator>
    </item>
    <item>
      <title>Dynamics of neural scaling laws in random feature regression with powerlaw-distributed kernel eigenvalues</title>
      <link>https://arxiv.org/abs/2602.23039</link>
      <description>arXiv:2602.23039v1 Announce Type: new 
Abstract: Training large neural networks exposes neural scaling laws for the generalization error, which points to a universal behavior across network architectures of learning in high dimensions. It was also shown that this effect persists in the limit of highly overparametrized networks as well as the Neural network Gaussian process limit. We here develop a principled understanding of the typical behavior of generalization in Neural Network Gaussian process regression dynamics. We derive a dynamical mean-field theory that captures the typical case learning dynamics: This allows us to unify multiple existing regimes of learning studied in the current literature, namely Bayesian inference on Gaussian processes, gradient flow with or without weight-decay, and stochastic Langevin training dynamics. Employing tools from statistical physics, the unified framework we derive in either of these cases yields an effective description of the high-dimensional microscopic behavior of networks dynamics in terms of lower dimensional order parameters. We show that collective training dynamics may be separated into the dynamics of N independent eigenmodes, those evolution equations are only coupled through collective response functions and a common statistics of an effective, independent noise. Our approach allows us to quantitatively explain the dynamics of the generalization error by linking spectral and dynamical properties of learning on data with power law spectra, including phenomena such as neural scaling laws and the effect of early stopping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23039v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob Kramp, Javed Lindner, Moritz Helias</dc:creator>
    </item>
    <item>
      <title>Schwinger-Keldysh field theory for operator R\'{e}nyi entropy and entanglement growth in non-interacting systems with sub-ballistic transports</title>
      <link>https://arxiv.org/abs/2602.22331</link>
      <description>arXiv:2602.22331v1 Announce Type: cross 
Abstract: The notion of operator growth in quantum systems furnishes a bridge between transport and the generation of entanglement between different parts of the system under quantum dynamics. We define a measure of operator growth in terms of subsystem operator R\'{e}nyi entropy, which provides a state-independent measure of operator growth, unlike entanglement entropies, and the usual measures of operator growth like out-of-time-order correlators. We show that the subsystem operator R\'{e}nyi entropy encodes both spatial and temporal information, and thus can directly connect to transport for a local operator related to a conserved quantity. We construct a unified Schwinger-Keldysh (SK) field theory formalism for the time evolution of operator R\'{e}nyi entropy and entanglement entropies of initial pure states. We use the SK field theory to obtain the operator R\'{e}nyi and state entanglement entropies in terms of infinite-temperature and vacuum Keldysh Green's functions, respectively, for non-interacting systems. We apply the method to explore the connection between operator and entanglement growth, and transport in non-interacting systems with quasiperiodic and random disorder, like the one- and two-dimensional Aubry-Andr\'{e} models and the two-dimensional Anderson model. In particular, we show that the growth of subsystem operator R\'{e}nyi entropy and state von Neumann and R\'{e}nyi entanglement entropies can capture both ballistic and sub-ballistic transport behaviors, like diffusive and anomalous diffusive transport, as well as localization in these systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22331v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>hep-th</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Priesh Roy, Sumilan Banerjee</dc:creator>
    </item>
    <item>
      <title>Numerical Experiments with Parameter Setting of Trotterized Quantum Phase Estimation for Quantum Hamiltonian Ground State Computation</title>
      <link>https://arxiv.org/abs/2602.22349</link>
      <description>arXiv:2602.22349v1 Announce Type: cross 
Abstract: We numerically investigate quantum circuit elementary-gate level instantiations of the standard Quantum Phase Estimation (QPE) algorithm for the task of computing the ground-state energy of a quantum magnet; the disordered fully-connected quantum Heisenberg spin glass model. We consider (classical simulations of) QPE circuit computations on relatively small quantum Hamiltonians ($3$ qubits) with up to $10$ phase bits of precision, using up to Trotter order $10$. We systematically study the inputs of QPE, specifically time evolution, Trotter order, Trotter steps, and initial state, and illustrate how these inputs practically determine how QPE operates. From this we outline a coherent set of quantum algorithm input and tuning guidelines. One of the notable properties we characterize is that QPE sampling of the optimal digitized phase converges to a fixed rate. This results in strong diminishing returns of optimal phase sampling rates which can occur when the Trotter error is surprisingly high.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22349v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elijah Pelofske, Stephan Eidenbenz</dc:creator>
    </item>
    <item>
      <title>Enhancement of superconductivity by disorder in Remeika-type quasiskutterudites</title>
      <link>https://arxiv.org/abs/2602.22448</link>
      <description>arXiv:2602.22448v1 Announce Type: cross 
Abstract: Atomic-scale disorder is conventionally regarded as detrimental to superconductivity; however, under specific conditions, it can enhance superconducting properties. Here, we investigate the role of substitutional disorder in Remeika-type quasiskutterudites $R_3M_4$Sn$_{13}$ and $R_5M_6$Sn$_{18}$ ($R=$ Y, La, Lu; $M=$ Co, Rh, Ru) by combining measurements of magnetic susceptibility, electrical resistivity, and heat capacity with microscopic modeling. We demonstrate that increasing disorder leads to the emergence of locally superconducting regions characterized by an enhanced critical temperature $T_c^{\ast}$, exceeding the bulk transition temperature $T_c$.
  Both $T_c^\ast$ and $T_c$ exhibit a nonmonotonic dependence on dopant concentration and show a strong correlation with entropy isotherms measured as a function of disorder. The pronounced entropy maxima coincide with the largest separation between $T_c^{\ast}$ and $T_c$, establishing disorder as a thermodynamically controlled parameter governing superconductivity in these materials. Measurements of the upper critical field reveal distinct $H_{c2}(T)$ branches associated with the bulk and locally superconducting phases, providing direct experimental evidence for a percolative superconducting state.
  To interpret these observations, we propose a microscopic model that captures the interplay between the impurity-induced enhancement of local pairing and the disorder-driven suppression of global superconducting coherence. The model reproduces the experimentally observed nonmonotonic evolution of $T_c^{\ast}$ with disorder and supports a percolation-based interpretation of the superconducting transition. Our results demonstrate that controlled atomic disorder can serve as an effective materials-design parameter for tuning superconductivity in complex correlated systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22448v1</guid>
      <category>cond-mat.supr-con</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.str-el</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrzej \'Slebarski, Maciej M. Ma\'ska</dc:creator>
    </item>
    <item>
      <title>Collective Dynamics in Spiking Neural Networks Beyond Dale's Principle</title>
      <link>https://arxiv.org/abs/2602.23202</link>
      <description>arXiv:2602.23202v1 Announce Type: cross 
Abstract: Dale's Principle has historically guided neuroscience research as a valuable rule of thumb, namely that all synapses on each neuron release the same set of neurotransmitters. Most existing Spiking Neuron Network models share this dichotomous assumption that neurons are either excitatory or inhibitory; however, recent experimental evidence points towards co-release mechanisms that violate this assumption. Here, we introduce a minimal model of "Bilingual" neurons violating Dale's principle that can exert both excitatory and inhibitory effects. We identify parameter regimes in which this architecture exhibits transitions between synchronous and asynchronous dynamics that differ quantitatively from those observed in a matched monolingual control architecture. We report distinct information-processing signatures both at the level of neurons and higher-order interactions between them near the phase transitions. These results suggest that the population of neurons violating Dales principle may provide an alternative mechanism for regulating large-scale oscillatory activity in neural circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23202v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ross Ah-Weng, Hardik Rajpal</dc:creator>
    </item>
    <item>
      <title>Mesoscopic fluctuation theory of particle systems driven by Poisson noise: study of the $q$-TASEP</title>
      <link>https://arxiv.org/abs/2602.23209</link>
      <description>arXiv:2602.23209v1 Announce Type: cross 
Abstract: We pursue our study of integrable weak noise theories of directed polymer and interacting particle stochastic models in the 1D KPZ universality class. Here we focus on the $q$-TASEP in either continuous or discrete time. Each particle on $\mathbb{Z}$ jumps independently by $+1$ with a rate (or probability) depending on the gap to the next particle on its right. We consider initial conditions (either step or random) which are empty of particles on $\mathbb{Z}^+$, and focus on the dynamics of the $N$ rightmost particles. In the limit $q \to 1$ and at large time (and large gaps) we identify a new intermediate "mesoscopic" (i.e. finite $N$) regime which corresponds to weak noise. In that regime Poisson noise remains important. We obtain the large deviations of the position of a given particle by two methods. The first derives asymptotics of $q$-TASEP Fredholm determinant formula. The second maps the weak noise limit to a system of semi-discrete or fully discrete, non linear differential equations. These are obtained as saddle point classical equations of a dynamical field theory, and their solutions represent the optimal configurations in the large deviation regime. We show the classical integrability of these two systems, and exhibit their explicit Lax pair. In the case of the continuous time $q$-TASEP it provides the first instance of classical integrability arising in a stochastic system, with signatures of the Poisson noise persisting in the weak noise limit. For this model, we solve the scattering problem associated to its Lax pair and fully characterize the large deviations associated to the weak noise theory. Finally, we supplement this work with an Appendix on the first cumulant method to obtain the large deviations of several lattice polymer models (Strict Weak, Log Gamma, Beta).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23209v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <category>nlin.SI</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexandre Krajenbrink, Pierre Le Doussal</dc:creator>
    </item>
    <item>
      <title>Spin Glass Concepts in Computer Science, Statistics, and Learning</title>
      <link>https://arxiv.org/abs/2602.23326</link>
      <description>arXiv:2602.23326v1 Announce Type: cross 
Abstract: Spin glass theory studies the structure of sublevel sets and minima (or near-minima) of certain classes of random functions in high dimension. Near-minima of random functions also play an important role in high-dimensional statistics and statistical learning, where minimizing the empirical risk (which is a random function of the model parameters) is the method of choice for learning a statistical model from noisy data. Finally, near-minima of random functions are obviously central to average-case analysis of optimization algorithms. Computer science, statistics, and machine learning naturally lead to questions that are traditionally not addressed within physics and mathematical physics. I will try to explain how ideas from spin glass theory have seeded recent developments in these fields.
  (This article was written on the occasion of the 2024 Abel Prize to Michel Talagrand.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23326v1</guid>
      <category>math.PR</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Montanari</dc:creator>
    </item>
    <item>
      <title>Stark localization of interacting particles</title>
      <link>https://arxiv.org/abs/2602.23352</link>
      <description>arXiv:2602.23352v1 Announce Type: cross 
Abstract: We consider N interacting quantum particles on a one-dimensional lattice, and subjected to an external linear potential. For N = 1, the corresponding Hamiltonian is explicitly diagonalizable, with superexponentially localized eigenstates. This is called Stark localization. We prove that superexponential spectral localization persists for arbitrary N and every interaction strength.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23352v1</guid>
      <category>math-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>math.MP</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wojciech De Roeck, Amirali Hannani, Alessio Lerose, Nathan Vandenbosch</dc:creator>
    </item>
    <item>
      <title>From percolation transition to Anderson localization in one-dimensional speckle potentials</title>
      <link>https://arxiv.org/abs/2511.16460</link>
      <description>arXiv:2511.16460v2 Announce Type: replace 
Abstract: Classical particles in random potentials typically experience a percolation phase transition, being trapped in clusters of mean size $\chi$ that diverges algebraically at a percolation threshold. In contrast, quantum transport in random potentials is controlled by the Anderson localization length, which shows no distinct feature at this classical critical point. Here, we present a comprehensive theoretical analysis of the semi-classical crossover between these two regimes by studying particle propagation in a one-dimensional, red speckle potential, which hosts a percolation transition at its upper bound. As the system deviates from the classical limit, we find that the algebraic divergence of $\chi$ continuously connects to a smooth yet non-analytic increase of the localization length. We characterize this behavior both numerically and theoretically using a semi-classical approach. In this crossover regime, the correlated and non-Gaussian nature of the speckle potential becomes essential, causing the standard Dorokhov-Mello-Pereyra-Kumar (DPMK) description for uncorrelated disorder to break down. Instead, we predict the emergence of a bimodal transmission distribution, a behavior normally absent in one dimension, which we capture within our semi-classical analysis. Deep in the quantum regime, the DMPK framework is recovered and the universal features of Anderson localization reappear.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16460v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>quant-ph</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1367-2630/ae4531</arxiv:DOI>
      <arxiv:journal_reference>2026 New J. Phys. 28 024508</arxiv:journal_reference>
      <dc:creator>Margaux Vrech, Jan Major, Dominique Delande, Marcel Filoche, Nicolas Cherroret</dc:creator>
    </item>
    <item>
      <title>Statistical Advantage of Softmax Attention: Insights from Single-Location Regression</title>
      <link>https://arxiv.org/abs/2509.21936</link>
      <description>arXiv:2509.21936v2 Announce Type: replace-cross 
Abstract: Large language models rely on attention mechanisms with a softmax activation. Yet the dominance of softmax over alternatives (e.g., component-wise or linear) remains poorly understood, and many theoretical works have focused on the easier-to-analyze linearized attention. In this work, we address this gap through a principled study of the single-location regression task, where the output depends on a linear transformation of a single input token at a random location. Building on ideas from statistical physics, we develop an analysis of attention-based predictors in the high-dimensional limit, where generalization performance is captured by a small set of order parameters. At the population level, we show that softmax achieves the Bayes risk, whereas linear attention fundamentally falls short. We then examine other activation functions to identify which properties are necessary for optimal performance. Finally, we analyze the finite-sample regime: we provide an asymptotic characterization of the test error and show that, while softmax is no longer Bayes-optimal, it consistently outperforms linear attention. We discuss the connection with optimization by gradient-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21936v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>ICLR 2026</arxiv:journal_reference>
      <dc:creator>O. Duranthon, P. Marion, C. Boyer, B. Loureiro, L. Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>Symmetry in language statistics shapes the geometry of model representations</title>
      <link>https://arxiv.org/abs/2602.15029</link>
      <description>arXiv:2602.15029v2 Announce Type: replace-cross 
Abstract: The internal representations learned by language models consistently exhibit striking geometric structure: calendar months organize into a circle, historical years form a smooth one-dimensional manifold, and cities' latitudes and longitudes can be decoded using a linear probe. To explain this neural code, we first show that language statistics exhibit translation symmetry (for example, the frequency with which any two months co-occur in text depends only on the time interval between them). We prove that this symmetry governs these geometric structures in high-dimensional word embedding models, and we analytically derive the manifold geometry of word representations. These predictions empirically match large text embedding models and large language models. Moreover, the representational geometry persists at moderate embedding dimension even when the relevant statistics are perturbed (e.g., by removing all sentences in which two months co-occur). We prove that this robustness emerges naturally when the co-occurrence statistics are controlled by an underlying latent variable. These results suggest that representational manifolds have a universal origin: symmetry in the statistics of natural data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15029v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.CL</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dhruva Karkada, Daniel J. Korchinski, Andres Nava, Matthieu Wyart, Yasaman Bahri</dc:creator>
    </item>
    <item>
      <title>Discovering new photovoltaics using optimal transport theory</title>
      <link>https://arxiv.org/abs/2602.22036</link>
      <description>arXiv:2602.22036v2 Announce Type: replace-cross 
Abstract: Searching by chemical and structural analogy is one of the most commonly used and successful approaches to materials discovery. However, formulating this task for algorithmic implementation raises the question of how we define similar materials. Methods have been proposed for searching materials space using vectors based on chemical composition and functional fragments in the material. Descriptors for structural similarity have also been proposed. However, the question of how to incorporate and balance structural and compositional similarity measures in a single metric remains open. Here, we adapt methods developed for calculating distances between undirected graphs and apply them to crystalline materials similarity. The Fused Gromov-Wasserstein (FGW) metric uses optimal transport theory to map between two graphs considering a balance of the graph structure and the information present at the nodes of the graph (atoms in crystals). We apply the method to exploring new photovoltaic materials. We demonstrate that FGW is competitive with embeddings from an equivariant graph neural network, trained on $&gt; 10^6$ materials, despite minimal training. We then apply FGW to a discovery campaign to identify materials from the Materials Project database that have not previously been explored as photovoltaics, but have similarities to known high-efficiency materials. After validating predictions with hybrid density functional theory, we identify seven previously unexplored high-efficiency photovoltaic absorber candidates, including Cs$_5$Sb$_8$, which is found to have a predicted SLME of $&gt; 30\%$ and to be thermodynamically stable. The FGW approach demonstrates the power of strong inductive biases for developing metrics for materials exploration with minimal training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22036v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew A. H. Walker, Zibo Zhou, Junayd Ul Islam, Keith T. Butler</dc:creator>
    </item>
  </channel>
</rss>
