<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Aug 2025 02:29:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Riemannian Optimization for Distance Geometry: A Study of Convergence, Robustness, and Incoherence</title>
      <link>https://arxiv.org/abs/2508.00091</link>
      <description>arXiv:2508.00091v1 Announce Type: new 
Abstract: The problem of recovering a configuration of points from partial pairwise distances, referred to as the Euclidean Distance Geometry (EDG) problem, arises in a broad range of applications, including sensor network localization, molecular conformation, and manifold learning. In this paper, we propose a Riemannian optimization framework for solving the EDG problem by formulating it as a low-rank matrix completion task over the space of positive semi-definite Gram matrices. The available distance measurements are encoded as expansion coefficients in a non-orthogonal basis, and optimization over the Gram matrix implicitly enforces geometric consistency through the triangle inequality, a structure inherited from classical multidimensional scaling. Under a Bernoulli sampling model for observed distances, we prove that Riemannian gradient descent on the manifold of rank-$r$ matrices locally converges linearly with high probability when the sampling probability satisfies $p \geq \mathcal{O}(\nu^2 r^2 \log(n)/n)$, where $\nu$ is an EDG-specific incoherence parameter. Furthermore, we provide an initialization candidate using a one-step hard thresholding procedure that yields convergence, provided the sampling probability satisfies $p \geq \mathcal{O}(\nu r^{3/2} \log^{3/4}(n)/n^{1/4})$. A key technical contribution of this work is the analysis of a symmetric linear operator arising from a dual basis expansion in the non-orthogonal basis, which requires a novel application of the Hanson--Wright inequality to establish an optimal restricted isometry property in the presence of coupled terms. Empirical evaluations on synthetic data demonstrate that our algorithm achieves competitive performance relative to state-of-the-art methods. Moreover, we propose a novel notion of matrix incoherence tailored to the EDG setting and provide robustness guarantees for our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00091v1</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandler Smith, HanQin Cai, Abiy Tasissa</dc:creator>
    </item>
    <item>
      <title>Measuring leadership and productivity in an organisational structure</title>
      <link>https://arxiv.org/abs/2508.00181</link>
      <description>arXiv:2508.00181v1 Announce Type: new 
Abstract: This paper develops a novel methodological framework for assessing leadership potential and productivity within organisational structure represented by directed graphs. In this setting, individuals are modeled as nodes and asymmetric supervisory or reporting relationships as directed edges. Leveraging the theory of transferable utility cooperative games, we introduce the Average Forest (AF) measure, a marginalist leadership measure grounded in the enumeration of maximal spanning forests, where teams are hierarchically structured as arborescences. The AF measure captures each agent`s expected contribution across all feasible team configurations under the assumption of superadditivity of the underlying game. We further define a measure of organisational productivity as the expected aggregate value derived from these configurations. The paper investigates key theoretical properties of the AF measure -- such as linearity, component feasibility, and monotonicity -- and analyzes its sensitivity to structural modifications in the underlying digraph. To address computational challenges in large networks, a Monte Carlo simulation algorithm is proposed for practical estimation. This framework enables the identification of structurally optimal leaders and enhances understanding of how network design impacts collective performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00181v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ram\'on Flores, Elisenda Molina, Juan Tejada</dc:creator>
    </item>
    <item>
      <title>Paratransit Optimization with Constraint Programming: A Case Study in Savannah, Georgia</title>
      <link>https://arxiv.org/abs/2508.00241</link>
      <description>arXiv:2508.00241v1 Announce Type: new 
Abstract: Paratransit services are vital for individuals who cannot use fixed-route public transit, including those with disabilities. Optimizing these services is essential for transit agencies to deliver high-quality service efficiently. This paper introduces a constraint programming model to jointly optimize route planning and shift scheduling for paratransit operations, along with practical guidance for real-world implementation. A case study in Savannah, Georgia, demonstrates that the new approach is competitive with the state of the art and significantly increases the number of requests served compared to current practices. It is also significantly easier to implement and provides an inherently practical solution for transportation planners. An additional advantage is that the model allows for optimizing shifts without restricting start times to the top of the hour, yielding a further 5% improvement in requests served when applied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00241v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liam Jagrowski, Kevin Dalmeijer, Tinghan Ye, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Neighbor-Sampling Based Momentum Stochastic Methods for Training Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2508.00267</link>
      <description>arXiv:2508.00267v1 Announce Type: new 
Abstract: Graph convolutional networks (GCNs) are a powerful tool for graph representation learning. Due to the recursive neighborhood aggregations employed by GCNs, efficient training methods suffer from a lack of theoretical guarantees or are missing important practical elements from modern deep learning algorithms, such as adaptivity and momentum. In this paper, we present several neighbor-sampling (NS) based Adam-type stochastic methods for solving a nonconvex GCN training problem. We utilize the control variate technique proposed by [1] to reduce the stochastic error caused by neighbor sampling. Under standard assumptions for Adam-type methods, we show that our methods enjoy the optimal convergence rate. In addition, we conduct extensive numerical experiments on node classification tasks with several benchmark datasets. The results demonstrate superior performance of our methods over classic NS-based SGD that also uses the control-variate technique, especially for large-scale graph datasets. Our code is available at https://github.com/RPI-OPT/CV-ADAM-GNN .</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00267v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Molly Noel, Gabriel Mancino-Ball, Yangyang Xu</dc:creator>
    </item>
    <item>
      <title>Deterministic Structure of Vertical Configurations in Minimal Picker Tours for Rectangular Warehouses</title>
      <link>https://arxiv.org/abs/2508.00365</link>
      <description>arXiv:2508.00365v1 Announce Type: new 
Abstract: The picker routing problem involves finding the shortest length tour of a warehouse that collects all items in a given pick-list. In this work, we demonstrate that in a rectangular warehouse, the horizontal structure of a minimal tour subgraph can be used to determine the required vertical edges. This result directly reduces the number of stages in the dynamic programming algorithm for warehouses with one or two blocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00365v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Dunn, Elizabeth Stojanovski, Bishnu Lamichhane, Hadi Charkhgard, Ali Eshragh</dc:creator>
    </item>
    <item>
      <title>A linesearch-based derivative-free method for noisy black-box problems</title>
      <link>https://arxiv.org/abs/2508.00495</link>
      <description>arXiv:2508.00495v1 Announce Type: new 
Abstract: In this work we consider unconstrained optimization problems. The objective function is known through a zeroth order stochastic oracle that gives an estimate of the true objective function. To solve these problems, we propose a derivative-free algorithm based on extrapolation techniques. Under reasonable assumptions we are able to prove convergence properties for the proposed algorithms. Furthermore, we also give a worst-case complexity result stating that the total number of iterations where the expected value of the norm of the objective function gradient is above a prefixed $\epsilon&gt;0$ is ${\cal O}(n^2\epsilon^{-2}/\beta^2)$ in the worst case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00495v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto De Santis, Giampaolo Liuzzi, Stefano Lucidi</dc:creator>
    </item>
    <item>
      <title>A Distributionally Robust Optimization Approach to Quick Response Models under Demand Uncertainty</title>
      <link>https://arxiv.org/abs/2508.00541</link>
      <description>arXiv:2508.00541v1 Announce Type: new 
Abstract: Problem definition: Quick response, a strategy widely adopted to mitigate overproduction in the retail industry, is now at the center of a critical debate. Recent research reveals a counter-intuitive paradox: while quick response systems reduce waste from unsold finished goods, they may incentivize firms to procure more raw materials, potentially increasing total system waste. Additionally, existing models that guide quick response strategies rely on the assumption of a known demand distribution. In practice, demand patterns are complex and ambiguous, and historical data is often scarce, leaving managers without a reliable framework to determine quick response policies under data-driven settings. Methodology: We develop a distributionally robust quick response model to address demand uncertainty, building policies that are robust even with limited data. We further integrate a novel waste-to-consumption ratio constraint into this framework, empowering firms to explicitly control the environmental impact of quick response systems. Results: Numerical experiments show that policies optimized for a specific demand assumption suffer severe performance degradation when the real demand pattern changes even slightly. In contrast, our data-driven DRO approach consistently delivers robust and superior performance across a wide range of complex demand distributions. Moreover, we find that the constrained quick response model resolves the central paradox: it can achieve higher profits with verifiably less total waste than a traditional, non-flexible alternative. Managerial implications: Our research resolves the `quick response or not' debate by showing that the question is not whether to use quick response, but how to manage it. By incorporating socially responsible metrics as constraints, the quick response system delivers a `win-win' outcome for both profitability and the environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00541v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panayotis P. Papavassilopoulos, Grani A. Hanasusanto, Yijie Wang</dc:creator>
    </item>
    <item>
      <title>On the controllability of the Kuramoto-Sivashinsky equation on multi-dimensional cylindrical domains</title>
      <link>https://arxiv.org/abs/2508.00812</link>
      <description>arXiv:2508.00812v1 Announce Type: new 
Abstract: In this article, we investigate null controllability of the Kuramoto-Sivashinsky (KS) equation on a cylindrical domain $\Omega=\Omega_x\times \Omega_y$ in $\mathbb R^N$, where $\Omega_x=(0,a),$ $a&gt;0$ and $\Omega_y$ is a smooth domain in $\mathbb R^{N-1}$. We first study the controllability of this system by a control acting on $\{0\}\times \omega$, $\omega\subset \Omega_y$, through the boundary term associated with the Laplacian component. The null controllability of the linearized system is proved using a combination of two techniques: the method of moments and Lebeau-Robbiano strategy. We provide a necessary and sufficient condition for the null controllability of this system along with an explicit control cost estimate. Furthermore, we show that there exists minimal time $T_0(x_0)&gt;0$ such that the system is null controllable for all time $T &gt; T_0(x_0)$ by means of an interior control exerted on $\gamma = \{x_0\} \times \omega \subset \Omega$, where $x_0/a\in (0,1)\setminus \mathbb{Q}$ and it is not controllable if $T&lt;T_0(x_0).$
  If we assume $x_0/a$ is an algebraic real number of order $d &gt; 1$, then we prove the controllability for any time $T&gt;0.$
  Finally, for the case of $N=2 \text{ or } 3$, we show the local null controllability of the main nonlinear system by employing the source term method followed by the Banach fixed point theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00812v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'ictor Hern\'andez-Santamar\'ia, Subrata Majumdar</dc:creator>
    </item>
    <item>
      <title>Efficient Solving of Large Single Input Superstate Decomposable Markovian Decision Process</title>
      <link>https://arxiv.org/abs/2508.00816</link>
      <description>arXiv:2508.00816v1 Announce Type: new 
Abstract: Solving Markov Decision Processes (MDPs) remains a central challenge in sequential decision-making, especially when dealing with large state spaces and long-term optimization criteria. A key step in Bellman dynamic programming algorithms is the policy evaluation, which becomes computationally demanding in infinite-horizon settings such as average-reward or discounted-reward formulations. In the context of Markov chains, aggregation and disaggregation techniques have for a long time been used to reduce complexity by exploiting structural decompositions. In this work, we extend these principles to a structured class of MDPs. We define the Single-Input Superstate Decomposable Markov Decision Process (SISDMDP), which combines Chiu's single-input decomposition with Robertazzi's single-cycle recurrence property. When a policy induces this structure, the resulting transition graph can be decomposed into interacting components with centralized recurrence. We develop an exact and efficient policy evaluation method based on this structure. This yields a scalable solution applicable to both average and discounted reward MDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00816v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Youssef Ait El Mahjoub, Jean-Michel Fourneau, Salma Alouah</dc:creator>
    </item>
    <item>
      <title>Leveraging Operator Learning to Accelerate Convergence of the Preconditioned Conjugate Gradient Method</title>
      <link>https://arxiv.org/abs/2508.00101</link>
      <description>arXiv:2508.00101v1 Announce Type: cross 
Abstract: We propose a new deflation strategy to accelerate the convergence of the preconditioned conjugate gradient(PCG) method for solving parametric large-scale linear systems of equations. Unlike traditional deflation techniques that rely on eigenvector approximations or recycled Krylov subspaces, we generate the deflation subspaces using operator learning, specifically the Deep Operator Network~(DeepONet). To this aim, we introduce two complementary approaches for assembling the deflation operators. The first approach approximates near-null space vectors of the discrete PDE operator using the basis functions learned by the DeepONet. The second approach directly leverages solutions predicted by the DeepONet. To further enhance convergence, we also propose several strategies for prescribing the sparsity pattern of the deflation operator. A comprehensive set of numerical experiments encompassing steady-state, time-dependent, scalar, and vector-valued problems posed on both structured and unstructured geometries is presented and demonstrates the effectiveness of the proposed DeepONet-based deflated PCG method, as well as its generalization across a wide range of model parameters and problem resolutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00101v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alena Kopani\v{c}\'akov\'a, Youngkyu Lee, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis</title>
      <link>https://arxiv.org/abs/2508.00129</link>
      <description>arXiv:2508.00129v1 Announce Type: cross 
Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem that can greatly affect the results of a Multi-Criteria Decision Method against a particular set of alternatives. It is therefore useful to have a mechanism that allows one to measure the performance of a method on a set of alternatives. This idea could be taken further to build a global ranking of the effectiveness of different methods to solve a problem. In this paper, we present three tests that detect the presence of Rank Reversals, along with their implementation in the Scikit-Criteria library. We also address the complications that arise when implementing these tests for general scenarios and the design considerations we made to handle them. We close with a discussion about how these additions could play a major role in the judgment of multi-criteria decision methods for problem solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00129v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agust\'in Borda, Juan Bautista Cabral, Gonzalo Giarda, Diego Nicol\'as Gimenez Irusta, Paula Pacheco, Alvaro Roy Schachner</dc:creator>
    </item>
    <item>
      <title>Data-Driven Motion Planning for Uncertain Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2508.00154</link>
      <description>arXiv:2508.00154v1 Announce Type: cross 
Abstract: This paper proposes a data-driven motion-planning framework for nonlinear systems that constructs a sequence of overlapping invariant polytopes. Around each randomly sampled waypoint, the algorithm identifies a convex admissible region and solves data-driven linear-matrix-inequality problems to learn several ellipsoidal invariant sets together with their local state-feedback gains. The convex hull of these ellipsoids, still invariant under a piece-wise-affine controller obtained by interpolating the gains, is then approximated by a polytope. Safe transitions between nodes are ensured by verifying the intersection of consecutive convex-hull polytopes and introducing an intermediate node for a smooth transition. Control gains are interpolated in real time via simplex-based interpolation, keeping the state inside the invariant polytopes throughout the motion. Unlike traditional approaches that rely on system dynamics models, our method requires only data to compute safe regions and design state-feedback controllers. The approach is validated through simulations, demonstrating the effectiveness of the proposed method in achieving safe, dynamically feasible paths for complex nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00154v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Babak Esmaeili, Hamidreza Modares, Stefano Di Cairano</dc:creator>
    </item>
    <item>
      <title>Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power</title>
      <link>https://arxiv.org/abs/2508.00159</link>
      <description>arXiv:2508.00159v1 Announce Type: cross 
Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal, sudden or gradual disempowerment of humans, power balance in human-AI interaction and international AI governance. At the same time, power as the ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by forcing AI agents explicitly to empower humans and to manage the power balance between humans and AI agents in a desirable way. Using a principled, partially axiomatic approach, we design a parametrizable and decomposable objective function that represents an inequality- and risk-averse long-term aggregate of human power. It takes into account humans' bounded rationality and social norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or approximating it via a form of multi-agent reinforcement learning from a given world model. We exemplify the consequences of (softly) maximizing this metric in a variety of paradigmatic situations and describe what instrumental sub-goals it will likely imply. Our cautious assessment is that softly maximizing suitable aggregate metrics of human power might constitute a beneficial objective for agentic AI systems that is safer than direct utility-based objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00159v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jobst Heitzig, Ram Potham</dc:creator>
    </item>
    <item>
      <title>Optimal Messaging Strategy for Incentivizing Agents in Dynamic Systems</title>
      <link>https://arxiv.org/abs/2508.00188</link>
      <description>arXiv:2508.00188v1 Announce Type: cross 
Abstract: We consider a finite-horizon discrete-time dynamic system jointly controlled by a designer and one or more agents, where the designer can influence the agents' actions through selective information disclosure. At each time step, the designer sends a message to the agent(s) from a prespecified message space. The designer may also take an action that directly influences system dynamics and rewards. Each agent uses its received message (and its own information) to choose its action. We are interested in the setting where the designer would like to incentivize each agent to play a specific strategy. We consider a notion of incentive compatibility that is based on sequential rationality at each realization of the common information between the designer and the agent(s). Our objective is to find a messaging and action strategy for the designer that maximizes its total expected reward while incentivizing each agent to follow a prespecified strategy. Under certain assumptions on the information structure of the problem, we show that an optimal designer strategy can be computed using a backward inductive algorithm that solves a family of linear programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00188v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renyan Sun, Ashutosh Nayyar</dc:creator>
    </item>
    <item>
      <title>The hierarchical barycenter: conditional probability simulation with structured and unobserved covariates</title>
      <link>https://arxiv.org/abs/2508.00206</link>
      <description>arXiv:2508.00206v2 Announce Type: cross 
Abstract: This paper presents a new method for conditional probability density simulation. The method is design to work with unstructured data set when data are not characterized by the same covariates yet share common information. Specific examples considered in the text are relative to two main classes: homogeneous data characterized by samples with missing value for the covariates and data set divided in two or more groups characterized by covariates that are only partially overlapping. The methodology is based on the mathematical theory of optimal transport extending the barycenter problem to the newly defined hierarchical barycenter problem. A newly, data driven, numerical procedure for the solution of the hierarchical barycenter problem is proposed and its advantages, over the use of classical barycenter, are illustrated on synthetic and real world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00206v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Esteban G. Tabak, Giulio Trigila, Wenjun Zhao</dc:creator>
    </item>
    <item>
      <title>Sequential, Parallel and Consecutive Hybrid Evolutionary-Swarm Optimization Metaheuristics</title>
      <link>https://arxiv.org/abs/2508.00229</link>
      <description>arXiv:2508.00229v1 Announce Type: cross 
Abstract: The goal of this paper is twofold. First, it explores hybrid evolutionary-swarm metaheuristics that combine the features of PSO and GA in a sequential, parallel and consecutive manner in comparison with their standard basic form: Genetic Algorithm and Particle Swarm Optimization. The algorithms were tested on a set of benchmark functions, including Ackley, Griewank, Levy, Michalewicz, Rastrigin, Schwefel, and Shifted Rotated Weierstrass, across multiple dimensions. The experimental results demonstrate that the hybrid approaches achieve superior convergence and consistency, especially in higher-dimensional search spaces. The second goal of this paper is to introduce a novel consecutive hybrid PSO-GA evolutionary algorithm that ensures continuity between PSO and GA steps through explicit information transfer mechanisms, specifically by modifying GA's variation operators to inherit velocity and personal best information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00229v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-97554-7_15</arxiv:DOI>
      <arxiv:journal_reference>Computational Science - ICCS 2025 Workshops, Lecture Notes in Computer Science, 15907, 203-218</arxiv:journal_reference>
      <dc:creator>Piotr Urba\'nczyk, Aleksandra Urba\'nczyk, Magdalena Kr\'ol, Leszek Rutkowski, Marek Kisiel-Dorohinicki</dc:creator>
    </item>
    <item>
      <title>Low-dimensional observer design for stable linear systems by model reduction</title>
      <link>https://arxiv.org/abs/2508.00609</link>
      <description>arXiv:2508.00609v1 Announce Type: cross 
Abstract: This paper presents a low-dimensional observer design for stable, single-input single-output, continuous-time linear time-invariant (LTI) systems. Leveraging the model reduction by moment matching technique, we approximate the system with a reduced-order model. Based on this reduced-order model, we design a low-dimensional observer that estimates the states of the original system. We show that this observer establishes exact asymptotic state reconstruction for a given class of inputs tied to the observer's dimension. Furthermore, we establish an exponential input-to-state stability property for generic inputs, ensuring a bounded estimation error. Numerical simulations confirm the effectiveness of the approach for a benchmark model reduction problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00609v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. F. Shakib, M. Khalil, R. Postoyan</dc:creator>
    </item>
    <item>
      <title>Controllability of diffusive Lotka-Volterra strongly competitive systems under boundary constrained controls</title>
      <link>https://arxiv.org/abs/2508.00713</link>
      <description>arXiv:2508.00713v1 Announce Type: cross 
Abstract: We investigate the controllability of the competition-diffusion Lotka-Volterra system. Our primary focus is on the one-dimensional setting with Dirichlet boundary controls, interpreted as ecological management policies regulating the density of species at the habitat boundaries and satisfying bilateral constraints. We show that the system can be steered from any initial state to a constant steady state representing the extinction of the less competitive species. In contrast, we prove that controllability toward a steady state where the more competitive species vanishes is generally not achievable when the inter-species competition rates are too unbalanced. This obstruction is due to the existence of barrier solutions, which we explicitly construct based on the spectral properties of the associated reaction-diffusion operators. Our theoretical results are illustrated through numerical simulations and are accompanied by a discussion of open problems and potential directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00713v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elisa Affili, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Learning to optimize with guarantees: a complete characterization of linearly convergent algorithms</title>
      <link>https://arxiv.org/abs/2508.00775</link>
      <description>arXiv:2508.00775v1 Announce Type: cross 
Abstract: In high-stakes engineering applications, optimization algorithms must come with provable worst-case guarantees over a mathematically defined class of problems. Designing for the worst case, however, inevitably sacrifices performance on the specific problem instances that often occur in practice. We address the problem of augmenting a given linearly convergent algorithm to improve its average-case performance on a restricted set of target problems - for example, tailoring an off-the-shelf solver for model predictive control (MPC) for an application to a specific dynamical system - while preserving its worst-case guarantees across the entire problem class. Toward this goal, we characterize the class of algorithms that achieve linear convergence for classes of nonsmooth composite optimization problems. In particular, starting from a baseline linearly convergent algorithm, we derive all - and only - the modifications to its update rule that maintain its convergence properties. Our results apply to augmenting legacy algorithms such as gradient descent for nonconvex, gradient-dominated functions; Nesterov's accelerated method for strongly convex functions; and projected methods for optimization over polyhedral feasibility sets. We showcase effectiveness of the approach on solving optimization problems with tight iteration budgets in application to ill-conditioned systems of linear equations and MPC for linear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00775v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Martin, Ian R. Manchester, Luca Furieri</dc:creator>
    </item>
    <item>
      <title>Conditional Gradient Methods</title>
      <link>https://arxiv.org/abs/2211.14103</link>
      <description>arXiv:2211.14103v5 Announce Type: replace 
Abstract: The purpose of this survey is to serve both as a gentle introduction and a coherent overview of state-of-the-art Frank--Wolfe algorithms, also called conditional gradient algorithms, for function minimization. These algorithms are especially useful in convex optimization when linear optimization is cheaper than projections.
  The selection of the material has been guided by the principle of highlighting crucial ideas as well as presenting new approaches that we believe might become important in the future, with ample citations even of old works imperative in the development of newer methods. Yet, our selection is sometimes biased, and need not reflect consensus of the research community, and we have certainly missed recent important contributions. After all the research area of Frank--Wolfe is very active, making it a moving target. We apologize sincerely in advance for any such distortions and we fully acknowledge: We stand on the shoulder of giants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.14103v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\'abor Braun, Alejandro Carderera, Cyrille W. Combettes, Hamed Hassani, Amin Karbasi, Aryan Mokhtari, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Constrained Stochastic Recursive Momentum Successive Convex Approximation</title>
      <link>https://arxiv.org/abs/2404.11790</link>
      <description>arXiv:2404.11790v4 Announce Type: replace 
Abstract: We consider stochastic optimization problems with non-convex functional constraints, such as those arising in trajectory generation, sparse approximation, and robust classification. To this end, we put forth a recursive momentum-based accelerated successive convex approximation (SCA) algorithm. At each iteration, the proposed algorithm entails constructing convex surrogates of the stochastic objective and the constraint functions, and solving the resulting convex optimization problem. A recursive update rule is employed to track the gradient of the stochastic objective function, which contributes to variance reduction and hence accelerates the algorithm convergence. A key ingredient of the proof is a new parameterized version of the standard Mangasarian-Fromowitz Constraints Qualification, that allows us to bound the dual variables and hence obtain problem-dependent bounds on the rate at which the iterates approach an $\epsilon$-stationary point. Remarkably, the proposed algorithm achieves near-optimal stochastic first-order (SFO) complexity with adaptive step sizes closely matching that achieved by state-of-the-art stochastic optimization algorithms for solving unconstrained problems. As an example, we detail an obstacle-avoiding trajectory optimization problem that can be solved using the proposed algorithm and show that its performance is superior to that of the existing algorithms used for trajectory optimization. The performance of the proposed algorithm is also shown to be comparable to that of a specialized sparse classification algorithm applied to a binary classification problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11790v4</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Basil M. Idrees, Lavish Arora, Ketan Rajawat</dc:creator>
    </item>
    <item>
      <title>Single-loop methods for bilevel parameter learning in inverse imaging</title>
      <link>https://arxiv.org/abs/2408.08123</link>
      <description>arXiv:2408.08123v4 Announce Type: replace 
Abstract: Bilevel optimisation is used in inverse imaging problems for hyperparameter learning/identification and experimental design, for instance, to find optimal regularisation parameters and forward operators. However, computationally, the process is costly. To reduce this cost, recently so-called single-loop approaches have been introduced. On each step of an outer optimisation method, they take just a single gradient step towards the solution of the inner problem. In this paper, we flexibilise the inner algorithm to include standard methods in inverse imaging. Moreover, as we have recently shown, significant performance improvements can be obtained in PDE-constrained optimisation by interweaving the steps of conventional iterative linear system solvers with the optimisation method. We now demonstrate how the adjoint equation in bilevel problems can also benefit from such interweaving. We evaluate the performance of our approach on identifying the deconvolution kernel for image deblurring, and the subsampling operator for magnetic resonance imaging (MRI).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08123v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ensio Suonper\"a, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>Probabilistic Iterative Hard Thresholding for Sparse Learning</title>
      <link>https://arxiv.org/abs/2409.01413</link>
      <description>arXiv:2409.01413v2 Announce Type: replace 
Abstract: For statistical modeling wherein the data regime is unfavorable in terms of dimensionality relative to the sample size, finding hidden sparsity in the ground truth can be critical in formulating an accurate statistical model. The so-called "l0 norm" which counts the number of non-zero components in a vector, is a strong reliable mechanism of enforcing sparsity when incorporated into an optimization problem for minimizing the fit of a given model to a set of observations. However, in big data settings wherein noisy estimates of the gradient must be evaluated out of computational necessity, the literature is scant on methods that reliably converge. In this paper we present an approach towards solving expectation objective optimization problems with cardinality constraints. We prove convergence of the underlying stochastic process, and demonstrate the performance on two Machine Learning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01413v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Bergamaschi, Andrea Cristofari, Vyacheslav Kungurtsev, Francesco Rinaldi</dc:creator>
    </item>
    <item>
      <title>Augmenting Subspace Optimization Methods with Linear Bandits</title>
      <link>https://arxiv.org/abs/2412.14278</link>
      <description>arXiv:2412.14278v3 Announce Type: replace 
Abstract: We consider the framework of methods for unconstrained minimization that are, in each iteration, restricted to a model that is only a valid approximation to the objective function on some affine subspace containing an incumbent point. These methods are of practical interest in computational settings where derivative information is either expensive or impossible to obtain. Recent attention has been paid in the literature to employing randomized matrix sketching for generating the affine subspaces within this framework.
  We consider a relatively straightforward, deterministic augmentation of such a generic subspace optimization method. In particular, we consider a sequential optimization framework where actions consist of one-dimensional linear subspaces and rewards consist of (approximations to) the magnitudes of directional derivatives computed in the direction of the action subspace. Reward maximization in this context is consistent with maximizing lower bounds on descent guaranteed by first-order Taylor models. This sequential optimization problem can be analyzed through the lens of dynamic regret. We modify an existing linear upper confidence bound (UCB) bandit method and prove sublinear dynamic regret in the subspace optimization setting. We demonstrate the efficacy of employing this linear UCB method in a setting where forward-mode algorithmic differentiation can provide directional derivatives in arbitrary directions and in a derivative-free setting. For the derivative-free setting, we propose SS-POUNDers, an extension of the derivative-free optimization method POUNDers that employs the linear UCB mechanism to identify promising subspaces. Our numerical experiments suggest a preference, in either computational setting, for employing a linear UCB mechanism within a subspace optimization method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14278v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matt Menickelly</dc:creator>
    </item>
    <item>
      <title>System Identification from Partial Observations under Adversarial Attacks</title>
      <link>https://arxiv.org/abs/2504.00244</link>
      <description>arXiv:2504.00244v2 Announce Type: replace 
Abstract: This paper is concerned with the partially observed linear system identification, where the goal is to obtain reasonably accurate estimation of the balanced truncation of the true system up to order $k$ from output measurements. We consider the challenging case of system identification under adversarial attacks, where the probability of having an attack at each time is $\Theta(1/k)$ while the value of the attack is arbitrary. We first show that the $\ell_1$-norm estimator exactly identifies the true Markov parameter matrix for nilpotent systems under any type of attack. We then build on this result to extend it to general systems and show that the estimation error exponentially decays as $k$ grows. The estimated balanced truncation model accordingly shows an exponentially decaying error for the identification of the true system up to a similarity transformation. This work is the first to provide the input-output analysis of the system with partial observations under arbitrary attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00244v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Closed Bounded Rational Framing Motions</title>
      <link>https://arxiv.org/abs/2505.18199</link>
      <description>arXiv:2505.18199v3 Announce Type: replace 
Abstract: We present a method for constructing all bounded rational motions that frame a space curve $\mathbf{r}(t)$. This means that the motion guides an orthogonal frame along the curve such that one frame axis is in direction of the curve tangent. Existence of (bounded) framing motions is equivalent to $\mathbf{r}(t)$ being a (bounded) rational Pythagorean Hodograph curve. In contrast to previous constructions that rely on polynomial curves with smooth self-intersection, our motions and curves are infinitely differentiable. To this end, we develop the theory of Pythagorean hodograph curves parameterized over the projective line. We also provide a simple geometric necessary and sufficient condition on the spherical part of the motion, given by the homogeneous quaternionic preimage of the Pythagorean hodograph curve, that ensures the existence of a corresponding bounded, rational, and even regular framing motion. The translation part comes from the speed distribution, which must be a special positive rational function. This can in practice be ensured by semidefinite optimization methods. We illustrate our findings with a number of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18199v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hans-Peter Schr\"ocker, Zbyn\v{e}k \v{S}\'ir</dc:creator>
    </item>
    <item>
      <title>Singular Control in a Cash Management Model with Ambiguity</title>
      <link>https://arxiv.org/abs/2309.12014</link>
      <description>arXiv:2309.12014v2 Announce Type: replace-cross 
Abstract: We consider a singular control model of cash reserve management, driven by a diffusion under ambiguity. The manager is assumed to have maxmin preferences over a set of priors characterized by $\kappa$-ignorance. A verification theorem is established to determine the firm's cost function and the optimal cash policy; the latter taking the form of a control barrier policy. In a model driven by arithmetic Brownian motion, we use Dynkin games to show that an increase in ambiguity leads to higher expected costs under the worst-case prior and a narrower inaction region. The latter effect can be used to provide an ambiguity-driven explanation for observed cash management behavior. Our findings can be applied to broader applications of singular control in managing inventories under ambiguity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12014v2</guid>
      <category>q-fin.RM</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2025.07.023</arxiv:DOI>
      <dc:creator>Arnon Archankul, Giorgio Ferrari, Tobias Hellmann, Jacco J. J. Thijssen</dc:creator>
    </item>
    <item>
      <title>Dynamic Batching of Online Arrivals to Leverage Economies of Scale</title>
      <link>https://arxiv.org/abs/2309.16911</link>
      <description>arXiv:2309.16911v2 Announce Type: replace-cross 
Abstract: Many settings, such as matching riders to drivers in ride-hailing platforms or in-stream video advertising, require handling arrivals over time. In such applications, it is often beneficial to group the arriving orders or requests into batches and process the larger batches rather than individual arrivals. However, waiting too long to create larger batches incurs a waiting cost for past arrivals. On the other hand, processing the arrivals too soon leads to higher processing costs by missing the economies of scale of grouping larger numbers of arrivals into larger batches. Moreover, the timing of the next arrival is often unknown, meaning fixed-size batches or fixed waiting times tend to be poor choices. In this work, we consider the problem of finding the optimal batching schedule to minimize the sum of waiting time and processing cost under both offline and online settings. In the offline problem in which all arrival times are known a priori, we show that the optimal batching schedule can be found in polynomial time by reducing it to a shortest path problem on a weighted acyclic graph. For the online problem with unknown arrival times, we develop algorithms that are provably competitive for a broad range of processing-cost functions. We also provide a lower bound on the competitive ratio that no online algorithm can beat. Finally, we run numerical experiments on simulated and real data to demonstrate the effectiveness of our algorithms against the offline benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16911v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2025.07.044</arxiv:DOI>
      <dc:creator>Akhil Bhimaraju, S. Rasoul Etesami, Lav R. Varshney</dc:creator>
    </item>
    <item>
      <title>Convergence of Implicit Gradient Descent for Training Two-Layer Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2407.02827</link>
      <description>arXiv:2407.02827v3 Announce Type: replace-cross 
Abstract: The optimization algorithms are crucial in training physics-informed neural networks (PINNs), as unsuitable methods may lead to poor solutions. Compared to the common gradient descent (GD) algorithm, implicit gradient descent (IGD) outperforms it in handling certain multi-scale problems. In this paper, we provide convergence analysis for the IGD in training over-parameterized two-layer PINNs. We first derive the training dynamics of IGD in training two-layer PINNs. Then, over-parameterization allows us to prove that the randomly initialized IGD converges to a globally optimal solution at a linear convergence rate. Moreover, due to the distinct training dynamics of IGD compared to GD, the learning rate can be selected independently of the sample size and the least eigenvalue of the Gram matrix. Additionally, the novel approach used in our convergence analysis imposes a milder requirement on the network width. Finally, empirical results validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02827v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianliang Xu, Ting Du, Wang Kong, Bin Shan, Ye Li, Zhongyi Huang</dc:creator>
    </item>
    <item>
      <title>OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM</title>
      <link>https://arxiv.org/abs/2503.10009</link>
      <description>arXiv:2503.10009v3 Announce Type: replace-cross 
Abstract: With the rise of artificial intelligence (AI), applying large language models (LLMs) to mathematical problem-solving has attracted increasing attention. Most existing approaches attempt to improve Operations Research (OR) optimization problem-solving through prompt engineering or fine-tuning strategies for LLMs. However, these methods are fundamentally constrained by the limited capabilities of non-reasoning LLMs. To overcome these limitations, we propose OR-LLM-Agent, an AI agent framework built on reasoning LLMs for automated OR problem solving. The framework decomposes the task into three sequential stages: mathematical modeling, code generation, and debugging. Each task is handled by a dedicated sub-agent, which enables more targeted reasoning. We also construct BWOR, an OR dataset for evaluating LLM performance on OR tasks. Our analysis shows that in the benchmarks NL4OPT, MAMO, and IndustryOR, reasoning LLMs sometimes underperform their non-reasoning counterparts within the same model family. In contrast, BWOR provides a more consistent and discriminative assessment of model capabilities. Experimental results demonstrate that OR-LLM-Agent utilizing DeepSeek-R1 in its framework outperforms advanced methods, including GPT-o3, Gemini 2.5 Pro, DeepSeek-R1, and ORLM, by at least 7\% in accuracy. These results demonstrate the effectiveness of task decomposition for OR problem solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10009v3</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Zhang, Pengcheng Luo, Genke Yang, Boon-Hee Soong, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Asymptotic Optimality of Projected Inventory Level Policies for Lost Sales Inventory Systems with Large Leadtime and Penalty Cost</title>
      <link>https://arxiv.org/abs/2504.10132</link>
      <description>arXiv:2504.10132v4 Announce Type: replace-cross 
Abstract: We study the canonical periodic review lost sales inventory system with positive leadtime and independent and identically distributed (i.i.d.) demand under the average cost criterion. We demonstrate that the relative value function under the constant order policy satisfies the Wiener-Hopf equation. We employ ladder processes associated with a random walk featuring i.i.d. increments, to obtain an explicit solution for the relative value function. This solution can be expressed as a quadratic form and a term that grows sublinearly. Then we perform an approximate policy iteration step on the constant order policy and uniformly bound the gap relative to the otimal cost rate for large lead times. This leads to our main result that projected inventory level policies are asymptotically optimal as the leadtime grows when the cost of losing a sale is sufficiently large and demand has a finite second moment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10132v4</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Poulad Moradi, Joachim Arts, Melvin Drent</dc:creator>
    </item>
    <item>
      <title>Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination</title>
      <link>https://arxiv.org/abs/2507.01762</link>
      <description>arXiv:2507.01762v3 Announce Type: replace-cross 
Abstract: The quality of simplex mesh is crucial for the stability and accuracy of numerical simulations in finite element analysis and computational geometry. However, the presence of sliver elements in 3D simplex mesh can severely impact the results. This paper presents a novel method based on a radius ratio energy function to optimize the quality of simplex mesh elements. This method can effectively eliminate sliver elements, thereby enhancing mesh quality.The gradient of the proposed energy function can be decomposed into a matrix-vector product. With minor processing, the matrix becomes symmetric positive definite, and this symmetric positive definite matrix can serve as a preconditioner to significantly accelerate the optimization process. Experimental results demonstrate that this method has significant advantages in eliminating sliver elements and improving mesh quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01762v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong Wang, Chunyu Chen, Huayi Wei</dc:creator>
    </item>
    <item>
      <title>A Unified Toolbox for Multipartite Entanglement Certification</title>
      <link>https://arxiv.org/abs/2507.17435</link>
      <description>arXiv:2507.17435v2 Announce Type: replace-cross 
Abstract: We present a unified framework for multipartite entanglement characterization based on the conditional gradient (CG) method, incorporating both fast heuristic detection and rigorous witness construction with numerical error control. Our method enables entanglement certification in quantum systems of up to ten qubits and applies to arbitrary entanglement structures. We demonstrate its power by closing the gap between entanglement and separability bounds in white noise robustness benchmarks for a class of bound entangled states. Furthermore, the framework extends to entanglement robustness under general quantum noise channels, providing accurate thresholds in cases beyond the reach of previous algorithmic methods. These results position CG methods as a powerful tool for practical and scalable entanglement analysis in realistic experimental settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17435v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ye-Chao Liu, Jannis Halbey, Sebastian Pokutta, S\'ebastien Designolle</dc:creator>
    </item>
  </channel>
</rss>
