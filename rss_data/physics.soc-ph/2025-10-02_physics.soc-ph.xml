<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.soc-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.soc-ph</link>
    <description>physics.soc-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.soc-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Oct 2025 04:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Proximity-based cities emit less mobility-driven CO$_2$</title>
      <link>https://arxiv.org/abs/2510.00094</link>
      <description>arXiv:2510.00094v1 Announce Type: new 
Abstract: In the quest for more environmentally sustainable urban areas, the concept of the 15-minute city has been proposed to encourage active mobility, primarily through walking and cycling. An urban area is considered a ``15-minute city" if every resident can access essential services within a 15-minute walk or bike ride from their home. However, there is an ongoing debate about the effectiveness of this model in reducing car usage and carbon emissions. In this study, we conduct a large-scale data-driven analysis to evaluate the impact of service proximity to homes on CO$_2$ emissions. By examining nearly 400 cities worldwide, we discover that, within the same city, areas with services located closer to residents produce less CO$_2$ emissions per capita from transportation. We establish a clear relationship between the proximity of services and CO$_2$ emissions for each city. Additionally, we quantify the potential reduction in emissions for 30 cities if they optimise the location of their services. This optimisation maintains each city's total number of services while redistributing them to ensure equal accessibility throughout the entire urban area. Our findings indicate that improving the proximity of services can significantly reduce expected urban emissions related to transportation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00094v1</guid>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Marzolla, Matteo Bruno, Hygor P. M. Melo, Vittorio Loreto</dc:creator>
    </item>
    <item>
      <title>Campaign-spending driven polarization transition in a double-random field model of elections</title>
      <link>https://arxiv.org/abs/2510.00612</link>
      <description>arXiv:2510.00612v1 Announce Type: new 
Abstract: We model bipartisan elections where voters are exposed to two forces: local homophilic interactions and external influence from two political campaigns. The model is mathematically equivalent to the random field Ising model with a bimodal field. When both parties exceed a critical campaign spending, the system undergoes a phase transition to a highly polarized state where homophilic influence becomes negligible, and election outcomes mirror the proportion of voters aligned with each campaign, independent of total spending. The model predicts a hysteresis region, where the election results are not determined by campaign spending but by incumbency. Calibrating the model with historical data from US House elections between 1980 and 2020, we find the critical campaign spending to be $\sim 1.8$ million USD. Campaigns exceeding critical expenditures increased in 2018 and 2020, suggesting a boost in political polarization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00612v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Korbel, Remah Dahdoul, Stefan Thurner</dc:creator>
    </item>
    <item>
      <title>Controlling the spread of deception-based cyber-threats on time-varying networks</title>
      <link>https://arxiv.org/abs/2510.00731</link>
      <description>arXiv:2510.00731v1 Announce Type: new 
Abstract: We study the efficacy of strategies aimed at controlling the spread of deception-based cyber-threats unfolding on online social networks. We model directed and temporal interactions between users using a family of activity-driven networks featuring tunable homophily levels among gullibility classes. We simulate the spreading of cyber-threats using classic Susceptible-Infected-Susceptible (SIS) models. We explore and quantify the effectiveness of four control strategies. Akin to vaccination campaigns with a limited budget, each strategy selects a fraction of nodes with the aim to increase their awareness and provide protection from cyber-threats. The first strategy picks nodes randomly. The second assumes global knowledge of the system selecting nodes based on their activity. The third picks nodes via egocentric sampling. The fourth selects nodes based on the outcome of standard security awareness tests, customarily used by institutions to probe, estimate, and raise the awareness of their workforce. We quantify the impact of each strategy by deriving analytically how they affect the spreading threshold. Analytical expressions are validated via large-scale numerical simulations. Interestingly, we find that targeted strategies, focusing on key features of the population such as the activity, are extremely effective. Egocentric sampling strategies, though not as effective, emerge as clear second best despite not assuming any knowledge about the system. Interestingly, we find that networks characterized by highly homophilic interactions linked to gullibility might expand the range of transmissibility parameters that allows for macroscopic outbreaks. At the same time, they reduce the reach of these spreading events. Hence, rather isolated patches of the network formed by highly gullible individuals might provide fertile grounds for the propagation and survival of cyber-threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00731v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicol\`o Gozzi, Nicola Perra</dc:creator>
    </item>
    <item>
      <title>Symmetry breaking in collective decision-making through higher-order interactions</title>
      <link>https://arxiv.org/abs/2510.00853</link>
      <description>arXiv:2510.00853v1 Announce Type: new 
Abstract: Collective decision-making is a widespread phenomenon in both biological and artificial systems, where individuals reach a consensus through social interactions. While traditional models of opinion dynamics and contagion focus on pairwise interactions, recent research emphasizes the importance of including higher-order group interactions and autonomous behavior to better reflect real-world complexity. In this work, we introduce a collective decision-making model inspired by social insects. In our framework, uncommitted agents can explore options independently and become committed, while social interactions influence these agents to prefer options already accepted by the group. Our model extends classical contagion models by incorporating multiple, mutually exclusive options and distinguishing between pairwise and higher-order social influences. Using simulations and analytical mean-field solutions, we show that higher-order interactions are essential for breaking symmetry in systems with equally valid options. We find that pairwise communication alone can cause decision deadlock, but adding group interactions allows the system to overcome stalemates and reach consensus. Our results emphasize the important roles of autonomous behavior and higher-order structures in collective decision-making. These insights could help us better understand social systems and design decision protocols for artificial swarms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00853v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David March-Pons, Romualdo Pastor-Satorras, M. Carmen Miguel</dc:creator>
    </item>
    <item>
      <title>Balancing Cost Savings and Import Dependence in Germany's Industry Transformation</title>
      <link>https://arxiv.org/abs/2510.00918</link>
      <description>arXiv:2510.00918v1 Announce Type: new 
Abstract: Greenhouse gas emissions from the steel, fertiliser and plastic industries can be mitigated by producing their precursors with green hydrogen. In Germany, green production may be economically unviable due to high energy costs. This study quantifies the 'renewables pull' of cheaper production abroad and high-lights trade-offs between cost savings and import dependence. Using a detailed European energy system model coupled to global supply curves for hydrogen and industry precursors (hot briquetted iron, ammonia and methanol), we assess five scenarios with increasing degrees of freedom with respect to imports. We find that precursor import is preferred over hydrogen import because there are significant savings in hydrogen infrastructure. Cost savings in the German industry sector from shifting precursor production to European partners compared to domestic production are at 4.1 bnEUR/a or 11.2 %. This strategy captures 47.7 % of the cost savings achievable by precursor import from non-European countries, which lowers industry costs by 8.6 bnEUR/a (23.3 %). Moving energy-intensive precursor production abroad allows Germany to save costs while still retaining a substantial share of subsequent value-creating industry. However, cost savings must be weighed against the risks of import dependence, which can be mitigated by sourcing exclusively from regional partners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00918v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toni Seibold, Fabian Neumann, Falko Ueckerdt, Tom Brown</dc:creator>
    </item>
    <item>
      <title>Exploring the conditions for sustainability with open-ended innovation</title>
      <link>https://arxiv.org/abs/2510.01085</link>
      <description>arXiv:2510.01085v1 Announce Type: new 
Abstract: Can sustained open-ended technological progress preserve natural resources in a finite planet? We address this question on the basis of a stylized model with genuine open-ended technological innovation, where an innovation event corresponds to a random draw of a technology in the space of the parameters that define how it impacts the environment and how it interacts with the population. Technological innovation is endogenous because an innovation may invade if it satisfies constraints which depend on the state of the environment and of the population. We find that open-ended innovation leads either to a sustainable future where global population saturates and the environment is preserved, or to exploding population and a vanishing environment. What drives the transition between these two phases is not the level of environmental impact of technologies, but rather the demographic effects of technologies and labor productivity. Low demographic impact and high labor productivity (as in several western countries today) result in a Schumpeterian dynamics where new "greener" technologies displace older ones, thereby reducing the overall environmental impact. In this scenario, global population saturates to a finite value, imposing strong selective pressure on technological innovation. When technologies contribute significantly to demographic growth and/or labor productivity is low, technological innovation runs unrestrained, population grows unbounded, while the environment collapses. As such, our model captures subtle feedback effects between technological progress, demography and sustainability that rationalize and align with empirical observations of a demographic transition and the environmental Kuznets curve, without deriving it from profit maximization based on individual incentives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01085v1</guid>
      <category>physics.soc-ph</category>
      <category>econ.TH</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Debora Princepe, Cristobal Qui\~ninao, Cristina D\'iaz Faloh, Pablo A. Marquet, Matteo Marsili</dc:creator>
    </item>
    <item>
      <title>Exploring Network-Knowledge Graph Duality: A Case Study in Agentic Supply Chain Risk Analysis</title>
      <link>https://arxiv.org/abs/2510.01115</link>
      <description>arXiv:2510.01115v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) struggle with the complex, multi-modal, and network-native data underlying financial risk. Standard Retrieval-Augmented Generation (RAG) oversimplifies relationships, while specialist models are costly and static. We address this gap with an LLM-centric agent framework for supply chain risk analysis. Our core contribution is to exploit the inherent duality between networks and knowledge graphs (KG). We treat the supply chain network as a KG, allowing us to use structural network science principles for retrieval. A graph traverser, guided by network centrality scores, efficiently extracts the most economically salient risk paths. An agentic architecture orchestrates this graph retrieval alongside data from numerical factor tables and news streams. Crucially, it employs novel ``context shells'' -- descriptive templates that embed raw figures in natural language -- to make quantitative data fully intelligible to the LLM. This lightweight approach enables the model to generate concise, explainable, and context-rich risk narratives in real-time without costly fine-tuning or a dedicated graph database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01115v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Evan Heus, Rick Bookstaber, Dhruv Sharma</dc:creator>
    </item>
    <item>
      <title>Construct to Commitment: The Effect of Narratives on Economic Growth</title>
      <link>https://arxiv.org/abs/2504.21060</link>
      <description>arXiv:2504.21060v3 Announce Type: replace 
Abstract: We study how government-led narratives through mass media evolve from construct, a mechanism for framing expectations, into commitment, a sustainable pillar for growth. We propose the "Narratives-Construct-Commitment (NCC)" framework outlining the mechanism and institutionalization of narratives, and formalize it as a dynamic Bayesian game. Using the Innovation-Driven Development Strategy (2016) as a case study, we identify the narrative shock from high-frequency financial data and trace its impact using local projection method. By shaping expectations, credible narratives institutionalize investment incentives, channel resources into R&amp;D, and facilitate sustained improvements in total factor productivity (TFP). Our findings strive to provide insights into the New Quality Productive Forces initiative, highlighting the role of narratives in transforming vision into tangible economic growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21060v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hanyuan Jiang, Yi Man</dc:creator>
    </item>
    <item>
      <title>GenAI Models Capture Urban Science but Oversimplify Complexity</title>
      <link>https://arxiv.org/abs/2505.13803</link>
      <description>arXiv:2505.13803v3 Announce Type: replace 
Abstract: Generative artificial intelligence (GenAI) models are increasingly used for scientific data generation, yet their alignment with empirical knowledge in urban science remains unclear. Here, we introduce AI4US (Artificial Intelligence for Urban Science), a framework that systematically evaluates leading GenAI models by testing their fidelity in generating both symbolic and perceptual urban data. For the symbolic domain, we benchmark generated data against foundational urban theories concerning scale, space, and morphology. For the perceptual domain, we validate the models' visual judgments against human benchmarks and, critically, leverage their generative control to conduct in causal experiments on urban perception. Our findings show that while GenAI models reproduce core theoretical patterns, the generated data exhibit crucial limitations: poor diversity, systematic parametric deviations, and improvement from prompt engineering. To address this, we introduce a post-hoc calibration procedure using optimal transport, which produces synthetic symbolic datasets with demonstrably higher fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13803v3</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yecheng Zhang, Rong Zhao, Zimu Huang, Xinyu Wang, Yue Ma, Ying Long</dc:creator>
    </item>
    <item>
      <title>From reductionism to realism: Holistic mathematical modelling for complex biological systems</title>
      <link>https://arxiv.org/abs/2503.20511</link>
      <description>arXiv:2503.20511v2 Announce Type: replace-cross 
Abstract: At its core, the physics paradigm adopts a reductionist approach, aiming to understand fundamental phenomena by decomposing them into simpler, elementary processes. While this strategy has been tremendously successful in physics, it has often fallen short in addressing fundamental questions in the biological sciences. This arises from the inherent complexity of biological systems, characterised by heterogeneity, polyfunctionality and interactions across spatiotemporal scales. Nevertheless, the traditional framework of complex systems modelling falls short, as its emphasis on broad theoretical principles has often failed to produce predictive, empirically-grounded insights. To advance towards actionable mathematical models in biology, we argue, using neuroscience as a case study, that it is necessary to move beyond reductionist approaches and instead embrace the complexity of biological systems - leveraging the growing availability of high-resolution data and advances in high-performance computing. We advocate for a holistic mathematical modelling paradigm that harnesses rich representational structures such as annotated and multilayer networks, employs agent-based models and simulation-based approaches, and focuses on the inverse problem of inferring system dynamics from observations. We emphasise that this approach is fully compatible with the search for fundamental biophysical principles, and highlight the potential it holds to drive progress in mathematical biology over the next two decades.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20511v2</guid>
      <category>physics.bio-ph</category>
      <category>physics.soc-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ram\'on Nartallo-Kaluarachchi, Renaud Lambiotte, Alain Goriely</dc:creator>
    </item>
  </channel>
</rss>
