<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Dec 2025 05:01:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Phase transitions reveal hierarchical structure in deep neural networks</title>
      <link>https://arxiv.org/abs/2512.11866</link>
      <description>arXiv:2512.11866v1 Announce Type: cross 
Abstract: Training Deep Neural Networks relies on the model converging on a high-dimensional, non-convex loss landscape toward a good minimum. Yet, much of the phenomenology of training remains ill understood. We focus on three seemingly disparate observations: the occurrence of phase transitions reminiscent of statistical physics, the ubiquity of saddle points, and phenomenon of mode connectivity relevant for model merging. We unify these within a single explanatory framework, the geometry of the loss and error landscapes. We analytically show that phase transitions in DNN learning are governed by saddle points in the loss landscape. Building on this insight, we introduce a simple, fast, and easy to implement algorithm that uses the L2 regularizer as a tool to probe the geometry of error landscapes. We apply it to confirm mode connectivity in DNNs trained on the MNIST dataset by efficiently finding paths that connect global minima. We then show numerically that saddle points induce transitions between models that encode distinct digit classes. Our work establishes the geometric origin of key training phenomena in DNNs and reveals a hierarchy of accuracy basins analogous to phases in statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11866v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ibrahim Talha Ersoy, Andr\'es Fernando Cardozo Licha, Karoline Wiesner</dc:creator>
    </item>
    <item>
      <title>Data-driven modeling of multivariate stochastic trajectories -- Application to water waves</title>
      <link>https://arxiv.org/abs/2512.11948</link>
      <description>arXiv:2512.11948v1 Announce Type: cross 
Abstract: A data-driven methodology is proposed to model the distribution of multivariate stochastic trajectories from an observed sample. As a first step, each trajectory in the sample is reduced to a vector of features by means of Functional Principal Component Analysis. Next, the joint distribution of features is modeled using (i) a non-parametric vine copula approach for the bulk of the distribution, and (ii) the conditional modeling framework of Heffernan and Tawn (2004) for the multivariate tail. The method is applied to the modeling of water waves. The dataset used is the DeRisk database, which consists of numerical simulations of water waves. The analysis is restricted to the portion of the wave period between the free-surface zero-upcrossing and the wave crest. The kinematic variables considered are the free-surface slope, the normal component of the fluid velocity at the free surface, and the vertical Lagrangian acceleration of the fluid at the free surface. The stochastic trajectories of these three variables are modeled jointly. The vertical Lagrangian acceleration of the fluid is employed to enforce a wave-breaking filter in the stochastic model. The capabilities of the model are illustrated by predicting the distributions of selected response variables and by generating synthetic trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11948v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romain Hasco\"et</dc:creator>
    </item>
    <item>
      <title>MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater</title>
      <link>https://arxiv.org/abs/2512.12142</link>
      <description>arXiv:2512.12142v1 Announce Type: cross 
Abstract: The Greenland ice sheet is melting at an accelerated rate due to processes that are not fully understood and hard to measure. The distribution of surface meltwater can help understand these processes and is observable through remote sensing, but current maps of meltwater face a trade-off: They are either high-resolution in time or space, but not both. We develop a deep learning model that creates gridded surface meltwater maps at daily 100m resolution by fusing data streams from remote sensing observations and physics-based models. In particular, we spatiotemporally downscale regional climate model (RCM) outputs using synthetic aperture radar (SAR), passive microwave (PMW), and a digital elevation model (DEM) over the Helheim Glacier in Eastern Greenland from 2017-2023. Using SAR-derived meltwater as "ground truth", we show that a deep learning-based method that fuses all data streams is over 10 percentage points more accurate over our study area than existing non deep learning-based approaches that only rely on a regional climate model (83% vs. 95% Acc.) or passive microwave observations (72% vs. 95% Acc.). Alternatively, creating a gridded product through a running window calculation with SAR data underestimates extreme melt events, but also achieves notable accuracy (90%) and does not rely on deep learning. We evaluate standard deep learning methods (UNet and DeepLabv3+), and publish our spatiotemporally aligned dataset as a benchmark, MeltwaterBench, for intercomparisons with more complex data-driven downscaling methods. The code and data are available at $\href{https://github.com/blutjens/hrmelt}{github.com/blutjens/hrmelt}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12142v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bj\"orn L\"utjens, Patrick Alexander, Raf Antwerpen, Til Widmann, Guido Cervone, Marco Tedesco</dc:creator>
    </item>
    <item>
      <title>Rethinking massive multiplexing in whispering gallery mode biosensing</title>
      <link>https://arxiv.org/abs/2512.12421</link>
      <description>arXiv:2512.12421v1 Announce Type: cross 
Abstract: Accurate, label-free quantification of multiple analytes in complex biological media remains a major challenge due to limited multiplexing, signal cross-correlations, and inconsistency across sensor samples and measurement runs. We introduce a multiplexed whispering-gallery-mode (WGM) biosensing framework that overcomes these barriers by jointly advancing photonic integration and data analytics. Our glass-chip platform enables massive, parallelized and flexible multiplexing of &gt;10000 microresonators organized into up to 100 sensing channels, with universal and modular chip design and detection hardware, while maintaining loaded Q-factors of 10^6. Our novel hybrid deep-learning framework BioCCF that integrates domain adaptation with cross-channel fusion enables harmonization of responses across sensing chips and extraction of nonlinear correlations in complex mixtures. Using a highly heterogeneous dataset comprising over 200 hours of sensing data acquired from nine chips with different channel configurations, biological replicates, and repeated regeneration cycles, we demonstrate recalibration-free identification of solution (99.3\% accuracy) and quantification of immunoglobulin G components with relative prediction error of 10^-4 under 5 min. The affordability and modularity of the platform enable distributed data acquisition and aggregation into shared repositories, providing a pathway toward continuously improving model generalization, cross-validation and a scalable, community-driven paradigm for biosensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12421v1</guid>
      <category>physics.optics</category>
      <category>physics.bio-ph</category>
      <category>physics.chem-ph</category>
      <category>physics.data-an</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ivan Saetchnikov, Elina Tcherniavskaia, Andreas Ostendorf, Anton Saetchnikov</dc:creator>
    </item>
    <item>
      <title>Data-driven modelling of autonomous and forced dynamical systems</title>
      <link>https://arxiv.org/abs/2512.12432</link>
      <description>arXiv:2512.12432v1 Announce Type: cross 
Abstract: The paper demonstrates that invariant foliations are accurate, data-efficient and practical tools for data-driven modelling of physical systems. Invariant foliations can be fitted to data that either fill the phase space or cluster about an invariant manifold. Invariant foliations can be fitted to a single trajectory or multiple trajectories. Over and underfitting are eliminated by appropriately choosing a function representation and its hyperparameters, such as polynomial orders. The paper extends invariant foliations to forced and parameter dependent systems. It is assumed that forcing is provided by a volume preserving map, and therefore the forcing can be periodic, quasi-periodic or even chaotic. The method utilises full trajectories, hence it is able to predict long-term dynamics accurately. We take into account if a forced system is reducible to an autonomous system about a steady state, similar to how Floquet theory guarantees reducibility for periodically forced systems. In order to find an invariant manifold, multiple invariant foliations are calculated in the neighbourhood of the invariant manifold. Some of the invariant foliations can be linear, while others nonlinear but only defined in a small neighbourhood of an invariant manifold, which reduces the number of parameters to be identified. An invariant manifold is recovered as the zero level set of one or more of the foliations. To interpret the results, the identified mathematical models are transformed to a canonical form and instantaneous frequency and damping information are calculated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12432v1</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Robert Szalai</dc:creator>
    </item>
    <item>
      <title>Optimized Architectures for Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2512.12448</link>
      <description>arXiv:2512.12448v1 Announce Type: cross 
Abstract: Efforts to improve Kolmogorov-Arnold networks (KANs) with architectural enhancements have been stymied by the complexity those enhancements bring, undermining the interpretability that makes KANs attractive in the first place. Here we study overprovisioned architectures combined with sparsification to learn compact, interpretable KANs without sacrificing accuracy. Crucially, we focus on differentiable sparsification, turning architecture search into an end-to-end optimization problem. Across function approximation benchmarks, dynamical systems forecasting, and real-world prediction tasks, we demonstrate competitive or superior accuracy while discovering substantially smaller models. Overprovisioning and sparsification are synergistic, with the combination outperforming either alone. The result is a principled path toward models that are both more expressive and more interpretable, addressing a key tension in scientific machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12448v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Bagrow, Josh Bongard</dc:creator>
    </item>
    <item>
      <title>Bayesian Full-waveform Monitoring of CO2 Storage with Fluid-flow Priors via Generative Modeling</title>
      <link>https://arxiv.org/abs/2512.12482</link>
      <description>arXiv:2512.12482v1 Announce Type: cross 
Abstract: Quantitative monitoring of subsurface changes is essential for ensuring the safety of geological CO2 sequestration. Full-waveform monitoring (FWM) can resolve these changes at high spatial resolution, but conventional deterministic inversion lacks uncertainty quantification and incorporates only limited prior information. Deterministic approaches can also yield unreliable results with sparse and noisy seismic data. To address these limitations, we develop a Bayesian FWM framework that combines reservoir flow physics with generative prior modeling. Prior CO2 saturation realizations are constructed by performing multiphase flow simulations on prior geological realizations. Seismic velocity is related to saturation through rock physics modeling. A variational autoencoder (VAE) trained on the priors maps high-dimensional CO2 saturation fields onto a low-dimensional, approximately Gaussian latent space, enabling efficient Bayesian inference while retaining the key geometrical structure of the CO2 plume. Hamiltonian Monte Carlo (HMC) is used to infer CO2 saturation changes from time-lapse seismic data and to quantify associated uncertainties. Numerical results show that this approach improves inversion stability and accuracy under extremely sparse and noisy acquisition, whereas deterministic methods become unreliable. Statistical seismic monitoring provides posterior uncertainty estimates that identify where additional measurements would most reduce ambiguity and mitigate errors arising from biased rock physics parameters. The framework combines reservoir physics, generative priors, and Bayesian inference to provide uncertainty quantification for time-lapse monitoring of CO2 storage and other subsurface processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12482v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.data-an</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haipeng Li, Nanzhe Wang, Louis J. Durlofsky, Biondo L. Biondi</dc:creator>
    </item>
    <item>
      <title>Investigating High-Order Behaviors in Multivariate Cardiovascular Interactions via Nonlinear Prediction and Information-Theoretic Tools</title>
      <link>https://arxiv.org/abs/2512.12709</link>
      <description>arXiv:2512.12709v1 Announce Type: cross 
Abstract: Assessing the synergistic high-order behaviors (HOBs) that emerge from underlying structural mechanisms is crucial to characterize complex systems. This work leverages the combined use of predictability and information measures to detect and quantify HOBs in synthetic and physiological network systems. After providing formal definitions of mechanisms and behaviors in a complex system, measures of statistical synergy are defined as the whole-minus-sum excess of mutual predictability ($\Delta_\textrm{MP}$) or mutual information ($\Delta_\textrm{MI}$) obtained when considering the system as a whole rather than as a combination of its units. The two measures are computed using model-free methods based on nonlinear prediction and entropy estimation. The application to simulated linear Gaussian systems and nonlinear deterministic and stochastic dynamic systems shows that $\Delta_\textrm{MP}$ tends to vanish for target variables influenced by additive effects of single independent source variables and is positive in the presence of group interactions between sources, while $\Delta_\textrm{MI}$ exhibits a higher propensity to display positive values. The analysis of physiological variables shows significant values of $\Delta_\textrm{MI}$ when investigating the additive effect of systolic and diastolic arterial pressure on mean arterial pressure, and of both $\Delta_\textrm{MP}$ and $\Delta_\textrm{MI}$ when assessing how diastolic pressure is modulated by pre-ejection and left-ventricular ejection times. HOBs can be more clearly identified by information-theoretic measures, while prediction measures are more sensitive to synergy arising from the governing rules of the system analyzed rather than from pure statistical dependencies. Quantifying HOBs through measures sensitive to structural mechanisms can provide biomarkers to assess physio-pathological alterations of cardiovascular networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12709v1</guid>
      <category>q-bio.QM</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chiara Bar\`a, Yuri Antonacci, Laura Sparacino, Helder Pinto, Michal Javorka, Sebastiano Stramaglia, Luca Faes</dc:creator>
    </item>
    <item>
      <title>On the continuity of flows</title>
      <link>https://arxiv.org/abs/2512.12821</link>
      <description>arXiv:2512.12821v1 Announce Type: cross 
Abstract: Flow matching has emerged as a powerful framework for generative modeling through continuous normalizing flows. We investigate a potential topological constraint: when the prior distribution and target distribution have mismatched topology (e.g., unimodal to multimodal), the optimal velocity field under standard flow matching objectives may exhibit spatial discontinuities. We suggest that this discontinuity arises from the requirement that continuous flows must bifurcate to map a single mode to multiple modes, forcing particles to make discrete routing decisions at intermediate times. Through theoretical analysis on bimodal Gaussian mixtures, we demonstrate that the optimal velocity field exhibits jump discontinuities along decision boundaries, with magnitude approaching infinity as time approaches the target distribution. Our analysis suggests that this phenomenon is not specific to $L^2$ loss, but rather may be a consequence of topological mismatch between distributions. We validate our theory empirically and discuss potential implications for flow matching on manifolds, connecting our findings to recent work on Riemannian flow matching and the challenge of learning discontinuous representations in neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12821v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Congzhou M Sha</dc:creator>
    </item>
    <item>
      <title>Large Deviation Properties of Minimum Spanning Trees for Random Graphs</title>
      <link>https://arxiv.org/abs/2512.13418</link>
      <description>arXiv:2512.13418v1 Announce Type: cross 
Abstract: We study the large-deviation properties of minimum spanning trees for two ensembles of random graphs with $N$ nodes. First, we consider complete graphs. Second, we study Erd\H{o}s-R\'{e}nyi (ER) random graphs with edge probability $p=c/N$ conditioned to be connected. By using large-deviation Markov chain sampling, we are able to obtain the distribution $P(W)$ of the spanning-tree weight $W$ down to probability densities as small as $10^{-300}$. For the complete graph, we confirm analytical predictions with respect to the expectation value. For both ensembles, the large deviation principle is fulfilled. For the connected ER graphs, we observe a remarkable change of the distributions at the value of $c=1$, which is the percolation threshold for the original ER ensemble.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13418v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahdi Sarikhani, Alexander K. Hartmann</dc:creator>
    </item>
  </channel>
</rss>
