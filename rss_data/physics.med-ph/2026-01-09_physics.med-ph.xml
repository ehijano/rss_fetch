<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 05:01:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bi-level Multi-criteria Optimization for Risk-informed Radiotherapy</title>
      <link>https://arxiv.org/abs/2601.04821</link>
      <description>arXiv:2601.04821v1 Announce Type: new 
Abstract: In radiation therapy (RT) treatment planning, multi-criteria optimization (MCO) supports efficient plan selection but is usually solved for population-based dosimetric criteria and ignores patient-specific biological risk, potentially compromising outcomes in high-risk patients. We propose risk-guided MCO, a one-shot method that embeds a clinical risk model into conventional MCO, enabling interactive navigation between dosimetric and biological endpoints. The proposed algorithm uses a special order relation to fuse the classical MCO sandwiching algorithm with bi-level optimization, restricting the Pareto set to plans that achieve improvement in the secondary risk objective for user-defined, acceptable loss in primary clinical objectives. Thus, risk-guided MCO generates risk-optimized counterparts of clinical plans in a single run rather than by sequential or lexicographic planning. To assess the performance, we retrospectively analyzed 19 lung cancer patients treated with RT. The endpoint was the risk of grade 2+ radiation pneumonitis (RP), modeled using bootstrapped stepwise logistics regression with interaction terms, including baseline lung function, smoking history, and dosimetric factors. The risk-guided plans yielded a mean reduction of 8.0% in total lung V20 and 9.5% in right lung V5, translating into an average RP risk reduction of 7.7% (range=0.3%-20.1%), with small changes in target coverage (mean -1.2 D98[%] for CTV) and modest increase in heart dose (mean +1.74 Gy). This study presents the first proof-of-concept for integrating biological risk models directly within multi-criteria RT planning, enabling an interactive balance between established population-wide dose protocols and individualized outcome prediction. Our results demonstrate that the risk-informed MCO can reduce the risk of RP while maintaining target coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04821v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mara Schubert, Katrin Teichert, Zhongxing Liao, Thomas Bortfeld, Ali Ajdari</dc:creator>
    </item>
    <item>
      <title>Dosimetric Impact of Hidden Input Parameters in Inverse Optimization Algorithms for GYN HDR Brachytherapy</title>
      <link>https://arxiv.org/abs/2601.05045</link>
      <description>arXiv:2601.05045v1 Announce Type: new 
Abstract: Inverse optimization (IO) algorithms are used in GYN HDR brachytherapy planning, with user parameter settings embedded in commercial TPS. To examine the dosimetric influence of hidden input parameters in three IO algorithms-IPSA, HIPO, and MCO-for GYN HDR brachytherapy across two applicator types. In-house implementations of IPSA, HIPO, and MCO were implemented and evaluated against retrospectively generated commercial TPS plans (Oncentra Brachy) using identical clinical input parameters across 24 cervical cancer cases (18 T&amp;O; 6 T&amp;O+Needles (T&amp;O+N)). Each IO algorithm was assessed using 1k combinations of hidden parameters (e.g., dwell-time modulation constraints, convergence thresholds). Cumulative DVH curves and dosimetric indices (HR-CTV D98/D90, OAR D2cc) were compared with commercial plans. Standard deviations (SD) of DVH differences were used to characterize sensitivity to hidden parameters. For HR-CTV, SD values in T&amp;O+N cases reached 23.0 Gy and 7.1 Gy for MCO and HIPO, respectively, with corresponding average values of 55.8 Gy and 19.7 Gy. In T&amp;O cases, HR-CTV SD values reached 4.9 Gy and 3.3 Gy for HIPO and IPSA, respectively, with average values of 20.1 Gy and 8.6 Gy. MCO exhibited the highest sensitivity, followed by HIPO and IPSA. T&amp;O+N cases showed greater sensitivity than T&amp;O cases. Absolute differences in HR-CTV D90 (D98) relative to commercial algorithms reached up to 33.3 Gy (28.4) for T&amp;O+N cases and 10.8 Gy (8.5) for T&amp;O cases. For OARs, absolute D2cc differences in T&amp;O+N (T&amp;O) cases reached up to 8.6 Gy (2.3) for rectum, 17 Gy (10.2) for bladder, 14.8 Gy (3.9) for sigmoid, and 7.0 Gy (8.1) for bowel. Hidden input parameter settings significantly impact on GYN HDR plans, with target coverage up to 28.4 Gy across IO algorithms for both T&amp;O and T&amp;O+N cases. The findings in this study shown the potential to improve plans through hidden input parameter optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05045v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>YeongHyeon Park, Shiqin Su, Sarath Vijayan, Zhiqian Henry Yu, Mandy Cunningham, Yusung Kim</dc:creator>
    </item>
    <item>
      <title>Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset</title>
      <link>https://arxiv.org/abs/2601.05063</link>
      <description>arXiv:2601.05063v1 Announce Type: new 
Abstract: Magnetic resonance imaging (MRI) is a cornerstone of clinical neuroimaging, yet conventional MRIs provide qualitative information heavily dependent on scanner hardware and acquisition settings. While quantitative MRI (qMRI) offers intrinsic tissue parameters, the requirement for specialized acquisition protocols and reconstruction algorithms restricts its availability and impedes large-scale biomarker research. This study presents a self-supervised physics-guided deep learning framework to infer quantitative T1, T2, and proton-density (PD) maps directly from widely available clinical conventional T1-weighted, T2-weighted, and FLAIR MRIs. The framework was trained and evaluated on a large-scale, clinically heterogeneous dataset comprising 4,121 scan sessions acquired at our institution over six years on four different 3 T MRI scanner systems, capturing real-world clinical variability. The framework integrates Bloch-based signal models directly into the training objective. Across more than 600 test sessions, the generated maps exhibited white matter and gray matter values consistent with literature ranges. Additionally, the generated maps showed invariance to scanner hardware and acquisition protocol groups, with inter-group coefficients of variation $\leq$ 1.1%. Subject-specific analyses demonstrated excellent voxel-wise reproducibility across scanner systems and sequence parameters, with Pearson $r$ and concordance correlation coefficients exceeding 0.82 for T1 and T2. Mean relative voxel-wise differences were low across all quantitative parameters, especially for T2 ($&lt;$ 6%). These results indicate that the proposed framework can robustly transform diverse clinical conventional MRI data into quantitative maps, potentially paving the way for large-scale quantitative biomarker research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05063v1</guid>
      <category>physics.med-ph</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jelmer van Lune, Stefano Mandija, Oscar van der Heide, Matteo Maspero, Martin B. Schilder, Jan Willem Dankbaar, Cornelis A. T. van den Berg, Alessandro Sbrizzi</dc:creator>
    </item>
    <item>
      <title>Federated Learning: A new frontier in the exploration of multi-institutional medical imaging data</title>
      <link>https://arxiv.org/abs/2503.20107</link>
      <description>arXiv:2503.20107v2 Announce Type: replace-cross 
Abstract: Artificial intelligence has transformed the perspective of medical imaging, leading to a genuine technological revolution in modern computer-assisted healthcare systems. However, ubiquitously featured deep learning (DL) systems require access to a considerable amount of data, facilitating proper knowledge extraction and generalization. Access to such extensive resources may be hindered due to the time and effort required to convey ethical agreements, set up and carry the acquisition procedures through, and manage the datasets adequately with a particular emphasis on proper anonymization. One of the pivotal challenges in the DL field is data integration from various sources acquired using different hardware vendors, diverse acquisition protocols, experimental setups, and even inter-operator variabilities. In this paper, we review the federated learning (FL) concept that fosters the integration of large-scale heterogeneous datasets from multiple institutions in training DL models. In contrast to a centralized approach, the decentralized FL procedure promotes training DL models while preserving data privacy at each institution involved. We formulate the FL principle and comprehensively review general and specialized medical imaging aggregation and learning algorithms, enabling the generation of a globally generalized model. We meticulously go through the challenges in constructing FL-based systems, such as data and model heterogeneities across the institutions, resilience to potential attacks on data privacy, and the variability in computational and communication resources among the entangled sites that might induce efficiency issues of the entire system. Finally, we explore the up-to-date open frameworks for rapid FL-based algorithm prototyping, comprehensively present real-world implementations of FL systems and shed light on future directions in this intensively growing field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20107v2</guid>
      <category>eess.IV</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dominika Ciupek, Maciej Malawski, Tomasz Pieciak</dc:creator>
    </item>
  </channel>
</rss>
