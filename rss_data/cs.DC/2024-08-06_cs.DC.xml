<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Aug 2024 01:33:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exploring the Frontiers of Energy Efficiency using Power Management at System Scale</title>
      <link>https://arxiv.org/abs/2408.01552</link>
      <description>arXiv:2408.01552v1 Announce Type: new 
Abstract: In the face of surging power demands for exascale HPC systems, this work tackles the critical challenge of understanding the impact of software-driven power management techniques like Dynamic Voltage and Frequency Scaling (DVFS) and Power Capping. These techniques have been actively developed over the past few decades. By combining insights from GPU benchmarking to understand application power profiles, we present a telemetry data-driven approach for deriving energy savings projections. This approach has been demonstrably applied to the Frontier supercomputer at scale. Our findings based on three months of telemetry data indicate that, for certain resource-constrained jobs, significant energy savings (up to 8.5%) can be achieved without compromising performance. This translates to a substantial cost reduction, equivalent to 1438 MWh of energy saved. The key contribution of this work lies in the methodology for establishing an upper limit for these best-case scenarios and its successful application. This work sheds light on potential energy savings and empowers HPC professionals to optimize the power-performance trade-off within constrained power budgets, not only for the exascale era but also beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01552v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Maroof Karimi, Matthias Maiterth, Woong Shin, Naw Safrin Sattar, Hao Lu, Feiyi Wang</dc:creator>
    </item>
    <item>
      <title>Adelie: Detection and prevention of Byzantine behaviour in DAG-based consensus protocols</title>
      <link>https://arxiv.org/abs/2408.02000</link>
      <description>arXiv:2408.02000v1 Announce Type: new 
Abstract: Recent developments in the Byzantine Fault Tolerant consensus protocols have shown the DAG-based protocols to be a very promising technique. While early implementations of DAG-based protocols such as Narwhal/Bullshark trade high throughput for a low latency, the latest versions of DAG-based protocols such as Mysticeti and Shoal++ show that indeed a latency comparable to that of traditional consensus protocols such as HotStuff can be achieve with the DAG-based consensus protocols while still maintaining high throughput. Mysticeti in particular achieves a low latency by implementing a novel approach of using an uncertified DAG - a significant breakthrough comparing to the certified DAG used in the previous generations of the protocol. However, the uncertified DAG exposes the system to new vectors of attacks by Byzantine validators that did not exist in the certified DAG protocols. In this paper we describe those issues and present the Adelie protocol, that addresses issues that comes with an uncertified DAG. We also incorporate some of the techniques from the Shoal++ to reduce latency even further. This paper also presents an implementation of Adelie protocol - bftd that demonstrates yet another breakthrough in the maximum achieved TPS and low latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02000v1</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey Chursin</dc:creator>
    </item>
    <item>
      <title>Blockchain-Enabled Dynamic Spectrum Sharing for Satellite and Terrestrial Communication Networks</title>
      <link>https://arxiv.org/abs/2408.02013</link>
      <description>arXiv:2408.02013v1 Announce Type: new 
Abstract: Dynamic spectrum sharing (DSS) between satellite and terrestrial networks has increasingly engaged the academic and industrial sectors. Nevertheless, facilitating secure, efficient and scalable sharing continues to pose a pivotal challenge. Emerging as a promising technology to bridge the trust gap among multiple participants, blockchain has been envisioned to enable DSS in a decentralized manner. However, satellites with limited resources may struggle to support the frequent interactions required by blockchain networks. Additionally,given the extensive coverage of satellites, spectrum sharing needs vary by regions, challenging traditional blockchain approaches to accommodate differences. In this work, a partitioned, self-governed, and customized dynamic spectrum sharing approach (PSC-DSS) is proposed for spectrum sharing between satellite access networks and terrestrial access networks. This approach establishes a sharded and tiered architecture which allows various regions to manage spectrum autonomously while jointly maintaining a single blockchain ledger. Moreover, a spectrum-consensus integrated mechanism, which decouples DSS process and couples it with blockchain consensus protocol, is designed to enable regions to conduct DSS transactions in parallel and dynamically innovate spectrum sharing schemes without affecting others. Furthermore, a theoretical framework is derived to justify the stability performance of PSC-DSS. Finally, simulations and experiments are conducted to validate the advantageous performance of PSC-DSS in terms of low-overhead, high efficiency, and robust stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02013v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixin Wang, Mingrui Cao, Hao Jiang, Bin Cao, Shuo Wang, Chen Sun, Mugen Peng</dc:creator>
    </item>
    <item>
      <title>Enabling Practical Transparent Checkpointing for MPI: A Topological Sort Approach</title>
      <link>https://arxiv.org/abs/2408.02218</link>
      <description>arXiv:2408.02218v1 Announce Type: new 
Abstract: MPI is the de facto standard for parallel computing on a cluster of computers. Checkpointing is an important component in any strategy for software resilience and for long-running jobs that must be executed by chaining together time-bounded resource allocations. This work solves an old problem: a practical and general algorithm for transparent checkpointing of MPI that is both efficient and compatible with most of the latest network software. Transparent checkpointing is attractive due to its generality and ease of use for most MPI application developers. Earlier efforts at transparent checkpointing for MPI, one decade ago, had two difficult problems: (i) by relying on a specific MPI implementation tied to a specific network technology; and (ii) by failing to demonstrate sufficiently low runtime overhead.
  Problem (i) (network dependence) was already solved in 2019 by MANA's introduction of split processes. Problem (ii) (efficient runtime overhead) is solved in this work. This paper introduces an approach that avoids these limitations, employing a novel topological sort to algorithmically determine a safe future synchronization point. The algorithm is valid for both blocking and non-blocking collective communication in MPI. We demonstrate the efficacy and scalability of our approach through both micro-benchmarks and a set of five real-world MPI applications, notably including the widely used VASP (Vienna Ab Initio Simulation Package), which is responsible for 11% of the workload on the Perlmutter supercomputer at Lawrence Berkley National Laboratory. VASP was previously cited as a special challenge for checkpointing, in part due to its multi-algorithm codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02218v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yao Xu, Gene Cooperman</dc:creator>
    </item>
    <item>
      <title>Asynchronous Latency and Fast Atomic Snapshot</title>
      <link>https://arxiv.org/abs/2408.02562</link>
      <description>arXiv:2408.02562v1 Announce Type: new 
Abstract: The original goal of this paper was a novel, fast atomic-snapshot protocol for asynchronous message-passing systems. In the process of defining what fast means exactly, we faced a number of interesting issues that arise when conventional time metrics are applied to asynchronous implementations. We discovered some gaps in latency claims made in earlier work on snapshot algorithms, which hampers their comparative time-complexity analysis. We then came up with a new unifying time-complexity analysis that captures the latency of an operation in an asynchronous, long-lived implementation, which allowed us to formally grasp latency improvements of our solution with respect to the state-of-the-art protocols: optimal latency in fault-free runs without contention, short constant latency in fault-free runs with contention, the worst-case latency proportional to the number of failures, and constant, close to optimal amortized latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02562v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Paulo Bezerra, Luciano Freitas, Petr Kuznetsov</dc:creator>
    </item>
    <item>
      <title>Algebraic Geometry Codes for Distributed Matrix Multiplication Using Local Expansions</title>
      <link>https://arxiv.org/abs/2408.01806</link>
      <description>arXiv:2408.01806v1 Announce Type: cross 
Abstract: Code-based Distributed Matrix Multiplication (DMM) has been extensively studied in distributed computing for efficiently performing large-scale matrix multiplication using coding theoretic techniques. The communication cost and recovery threshold (i.e., the least number of successful worker nodes required to recover the product of two matrices) are two major challenges in coded DMM research. Several constructions based on Reed-Solomon (RS) codes are known, including Polynomial codes, MatDot codes, and PolyDot codes. However, these RS-based schemes are not efficient for small finite fields because the distributed order (i.e., the total number of worker nodes) is limited by the size of the underlying finite field. Algebraic geometry (AG) codes can have a code length exceeding the size of the finite field, which helps solve this problem. Some work has been done to generalize Polynomial and MatDot codes to AG codes, but the generalization of PolyDot codes to AGcodes still remains an open problem as far as we know. This is because functions of an algebraic curve do not behave as nicely as polynomials.
  In this work, by using local expansions of functions, we are able to generalize the three DMM schemes based on RS codes to AG codes. Specifically, we provide a construction of AG-based PolyDot codes for the first time. In addition, our AG-based Polynomial and MatDot codes achieve better recovery thresholds compared to previous AG-based DMM schemes while maintaining similar communication costs. Our constructions are based on a novel basis of the Riemann-Roch space using local expansions, which naturally generalizes the standard monomial basis of the univariate polynomial space in RS codes. In contrast, previous work used the non-gap numbers to construct a basis of the Riemann-Roch space, which can cause cancellation problems that prevent the conditions of PolyDot codes from being satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01806v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiang Li, Songsong Li, Chaoping Xing</dc:creator>
    </item>
    <item>
      <title>Characterizing the Performance of the Implicit Massively Parallel Particle-in-Cell iPIC3D Code</title>
      <link>https://arxiv.org/abs/2408.01983</link>
      <description>arXiv:2408.01983v1 Announce Type: cross 
Abstract: Optimizing iPIC3D, an implicit Particle-in-Cell (PIC) code, for large-scale 3D plasma simulations is crucial for space and astrophysical applications. This work focuses on characterizing iPIC3D's communication efficiency through strategic measures like optimal node placement, communication and computation overlap, and load balancing. Profiling and tracing tools are employed to analyze iPIC3D's communication efficiency and provide practical recommendations. Implementing optimized communication protocols addresses the Geospace Environmental Modeling (GEM) magnetic reconnection challenges in plasma physics with more precise simulations. This approach captures the complexities of 3D plasma simulations, particularly in magnetic reconnection, advancing space and astrophysical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01983v1</guid>
      <category>physics.plasm-ph</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy J. Williams, Daniel Medeiros, Ivy B. Peng, Stefano Markidis</dc:creator>
    </item>
    <item>
      <title>Large Language Model Aided QoS Prediction for Service Recommendation</title>
      <link>https://arxiv.org/abs/2408.02223</link>
      <description>arXiv:2408.02223v1 Announce Type: cross 
Abstract: Large language models (LLMs) have seen rapid improvement in the recent years, and are used in a wider range of applications. After being trained on large text corpus, LLMs obtain the capability of extracting rich features from textual data. Such capability is potentially useful for the web service recommendation task, where the web users and services have intrinsic attributes that can be described using natural language sentences and are useful for recommendation. In this paper, we explore the possibility and practicality of using LLMs for web service recommendation. We propose the large language model aided QoS prediction (llmQoS) model, which use LLMs to extract useful information from attributes of web users and services via descriptive sentences. This information is then used in combination with the QoS values of historical interactions of users and services, to predict QoS values for any given user-service pair. Our proposed model is shown to overcome the data sparsity issue for QoS prediction. We show that on the WSDream dataset, llmQoS outperforms comparable baseline models consistently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02223v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiying Liu, Zekun Zhang, Qilin Wu, Yiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Nonlinear Perturbation-based Non-Convex Optimization over Time-Varying Networks</title>
      <link>https://arxiv.org/abs/2408.02269</link>
      <description>arXiv:2408.02269v1 Announce Type: cross 
Abstract: Decentralized optimization strategies are helpful for various applications, from networked estimation to distributed machine learning. This paper studies finite-sum minimization problems described over a network of nodes and proposes a computationally efficient algorithm that solves distributed convex problems and optimally finds the solution to locally non-convex objective functions. In contrast to batch gradient optimization in some literature, our algorithm is on a single-time scale with no extra inner consensus loop. It evaluates one gradient entry per node per time. Further, the algorithm addresses link-level nonlinearity representing, for example, logarithmic quantization of the exchanged data or clipping of the exchanged data bits. Leveraging perturbation-based theory and algebraic Laplacian network analysis proves optimal convergence and dynamics stability over time-varying and switching networks. The time-varying network setup might be due to packet drops or link failures. Despite the nonlinear nature of the dynamics, we prove exact convergence in the face of odd sign-preserving sector-bound nonlinear data transmission over the links. Illustrative numerical simulations further highlight our contributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02269v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Zulfiya R. Gabidullina, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>Bike Assisted Evacuation on a Line of Robots with Communication Faults</title>
      <link>https://arxiv.org/abs/2307.15808</link>
      <description>arXiv:2307.15808v2 Announce Type: replace 
Abstract: Two autonomous mobile robots and a non-autonomous one, also called bike, are placed at the origin of an infinite line. The autonomous robots can travel with maximum speed $1$. When a robot rides the bike its speed increases to $v&gt;1$, however only exactly one robot at a time can ride the bike and the bike is non-autonomous in that it cannot move on its own. An Exit is placed on the line at an unknown location and at distance $d$ from the origin. The robots have limited communication behavior; one robot is a sender (denoted by S) in that it can send information wirelessly at any distance and receive messages only in F2F (Face-to-Face), while the other robot is a receiver (denoted by R) in that it can receive information wirelessly but can send information only F2F. The bike has no communication capabilities of its own. We refer to the resulting communication model of the ensemble of the two autonomous robots and the bike as S/R.
  Our general goal is to understand the impact of the non-autonomous robot in assisting the evacuation of the two autonomous faulty robots. Our main contribution is to provide a new evacuation algorithm that enables both robots to evacuate from the unknown Exit in the S/R model. We also analyze the resulting evacuation time as a function of the bike's speed $v$ and give upper and lower bounds on the competitive ratio of the resulting algorithm for the entire range of possible values of $v$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15808v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khaled Jawhar, Evangelos Kranakis</dc:creator>
    </item>
    <item>
      <title>Before and After Blockchain: Development and Principles of Distributed Fault-Tolerant Consensus</title>
      <link>https://arxiv.org/abs/2407.19863</link>
      <description>arXiv:2407.19863v2 Announce Type: replace 
Abstract: The concept of distributed consensus gained widespread attention following the publication of "Byzantine Generals Problem" by Leslie Lamport in the 1980s. This research topic has been active and extensively studied over the last four decades, particularly since the advent of blockchain technology in 2009. Blockchain technology employs Proof-of-X (PoX) or Byzantine-fault-tolerant (BFT) systems, where all participants follow a protocol to achieve a common state (i.e., consistency) eventually. However, because PoX consensus such as Proof-of-Work is is resource-intensive with high power consumption, most permissioned blockchains employ BFT to achieve consistency. In this article, we provide an introduction to the fundamental principles and history of distributed consensus. We then explore the well-known fault-tolerant state machine replication (SMR) in partially synchronous networks, as well as consensus protocols in asynchronous models and recently proposed DAG-based consensus. Additionally, we examine the relationship between BFT consensus and blockchain technology and discuss the following questions: What is the history and evolution of BFT? Why are BFT protocols designed in the way they are and what core components do they use? What is the connection between BFT and blockchain technology, and what are the driving needs for future BFT research?</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19863v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huanyu Wu, Chentao Yue, Yixuan Fan, Yonghui Li, Lei Zhang</dc:creator>
    </item>
    <item>
      <title>Vertical Federated Learning: Challenges, Methodologies and Experiments</title>
      <link>https://arxiv.org/abs/2202.04309</link>
      <description>arXiv:2202.04309v2 Announce Type: replace-cross 
Abstract: Recently, federated learning (FL) has emerged as a promising distributed machine learning (ML) technology, owing to the advancing computational and sensing capacities of end-user devices, however with the increasing concerns on users' privacy. As a special architecture in FL, vertical FL (VFL) is capable of constructing a hyper ML model by embracing sub-models from different clients. These sub-models are trained locally by vertically partitioned data with distinct attributes. Therefore, the design of VFL is fundamentally different from that of conventional FL, raising new and unique research issues. In this paper, we aim to discuss key challenges in VFL with effective solutions, and conduct experiments on real-life datasets to shed light on these issues. Specifically, we first propose a general framework on VFL, and highlight the key differences between VFL and conventional FL. Then, we discuss research challenges rooted in VFL systems under four aspects, i.e., security and privacy risks, expensive computation and communication costs, possible structural damage caused by model splitting, and system heterogeneity. Afterwards, we develop solutions to addressing the aforementioned challenges, and conduct extensive experiments to showcase the effectiveness of our proposed solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.04309v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kang Wei, Jun Li, Chuan Ma, Ming Ding, Sha Wei, Fan Wu, Guihai Chen, Thilina Ranbaduge</dc:creator>
    </item>
    <item>
      <title>A Framework for Evaluating Privacy-Utility Trade-off in Vertical Federated Learning</title>
      <link>https://arxiv.org/abs/2209.03885</link>
      <description>arXiv:2209.03885v4 Announce Type: replace-cross 
Abstract: Federated learning (FL) has emerged as a practical solution to tackle data silo issues without compromising user privacy. One of its variants, vertical federated learning (VFL), has recently gained increasing attention as the VFL matches the enterprises' demands of leveraging more valuable features to build better machine learning models while preserving user privacy. Current works in VFL concentrate on developing a specific protection or attack mechanism for a particular VFL algorithm. In this work, we propose an evaluation framework that formulates the privacy-utility evaluation problem. We then use this framework as a guide to comprehensively evaluate a broad range of protection mechanisms against most of the state-of-the-art privacy attacks for three widely deployed VFL algorithms. These evaluations may help FL practitioners select appropriate protection mechanisms given specific requirements. Our evaluation results demonstrate that: the model inversion and most of the label inference attacks can be thwarted by existing protection mechanisms; the model completion (MC) attack is difficult to be prevented, which calls for more advanced MC-targeted protection mechanisms. Based on our evaluation results, we offer concrete advice on improving the privacy-preserving capability of VFL systems. The code is available at https://github.com/yankang18/Attack-Defense-VFL</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03885v4</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Kang, Jiahuan Luo, Yuanqin He, Xiaojin Zhang, Lixin Fan, Qiang Yang</dc:creator>
    </item>
    <item>
      <title>Fusing Depthwise and Pointwise Convolutions for Efficient Inference on GPUs</title>
      <link>https://arxiv.org/abs/2404.19331</link>
      <description>arXiv:2404.19331v2 Announce Type: replace-cross 
Abstract: Depthwise and pointwise convolutions have fewer parameters and perform fewer operations than standard convolutions. As a result, they have become increasingly used in various compact DNNs, including convolutional neural networks (CNNs) and vision transformers (ViTs). However, they have a lower compute-to-memory-access ratio than standard convolutions, making their memory accesses often the performance bottleneck. This paper explores fusing depthwise and pointwise convolutions to overcome the memory access bottleneck. The focus is on fusing these operators on GPUs. The prior art on GPU-based fusion suffers from one or more of the following: (1) fusing either a convolution with an element-wise or multiple non-convolutional operators, (2) not explicitly optimizing for memory accesses, (3) not supporting depthwise convolutions. This paper proposes Fused Convolutional Modules (FCMs), a set of novel fused depthwise and pointwise GPU kernels. FCMs significantly reduce pointwise and depthwise convolutions memory accesses, improving execution time and energy efficiency. To evaluate the trade-offs associated with fusion and determine which convolutions are beneficial to fuse and the optimal FCM parameters, we propose FusePlanner. FusePlanner consists of cost models to estimate the memory accesses of depthwise, pointwise, and FCM kernels given GPU characteristics. Our experiments on three GPUs using representative CNNs and ViTs demonstrate that FCMs save up to 83\% of the memory accesses and achieve speedups of up to 3.7x compared to cuDNN. Complete model implementations of various CNNs using our modules outperform TVMs' achieving speedups of up to 1.8x and saving up to two-thirds of the energy. FCM and FusePlanner implementations are open source: https://github.com/fqararyah/Fusing_DW_and_PW_on_GPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19331v2</guid>
      <category>cs.PF</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fareed Qararyah, Muhammad Waqar Azhar, Mohammad Ali Maleki, Pedro Trancoso</dc:creator>
    </item>
    <item>
      <title>Understanding the Impact of openPMD on BIT1, a Particle-in-Cell Monte Carlo Code, through Instrumentation, Monitoring, and In-Situ Analysis</title>
      <link>https://arxiv.org/abs/2406.19058</link>
      <description>arXiv:2406.19058v2 Announce Type: replace-cross 
Abstract: Particle-in-Cell Monte Carlo simulations on large-scale systems play a fundamental role in understanding the complexities of plasma dynamics in fusion devices. Efficient handling and analysis of vast datasets are essential for advancing these simulations. Previously, we addressed this challenge by integrating openPMD with BIT1, a Particle-in-Cell Monte Carlo code, streamlining data streaming and storage. This integration not only enhanced data management but also improved write throughput and storage efficiency. In this work, we delve deeper into the impact of BIT1 openPMD BP4 instrumentation, monitoring, and in-situ analysis. Utilizing cutting-edge profiling and monitoring tools such as gprof, CrayPat, Cray Apprentice2, IPM, and Darshan, we dissect BIT1's performance post-integration, shedding light on computation, communication, and I/O operations. Fine-grained instrumentation offers insights into BIT1's runtime behavior, while immediate monitoring aids in understanding system dynamics and resource utilization patterns, facilitating proactive performance optimization. Advanced visualization techniques further enrich our understanding, enabling the optimization of BIT1 simulation workflows aimed at controlling plasma-material interfaces with improved data analysis and visualization at every checkpoint without causing any interruption to the simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19058v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>physics.plasm-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy J. Williams, Stefan Costea, Allen D. Malony, David Tskhakaya, Leon Kos, Ales Podolnik, Jakub Hromadka, Kevin Huck, Erwin Laure, Stefano Markidis</dc:creator>
    </item>
    <item>
      <title>Decentralized Intelligence Network (DIN)</title>
      <link>https://arxiv.org/abs/2407.02461</link>
      <description>arXiv:2407.02461v2 Announce Type: replace-cross 
Abstract: Decentralized Intelligence Network (DIN) is a theoretical framework addressing data fragmentation and siloing challenges, enabling scalable AI through data sovereignty. It facilitates effective AI utilization within sovereign networks by overcoming barriers to accessing diverse data sources, leveraging: 1) personal data stores to ensure data sovereignty, where data remains securely within Participants' control; 2) a scalable federated learning protocol implemented on a public blockchain for decentralized AI training, where only model parameter updates are shared, keeping data within the personal data stores; and 3) a scalable, trustless cryptographic rewards mechanism on a public blockchain to incentivize participation and ensure fair reward distribution through a decentralized auditing protocol. This approach guarantees that no entity can prevent or control access to training data or influence financial benefits, as coordination and reward distribution are managed on the public blockchain with an immutable record. The framework supports effective AI training by allowing Participants to maintain control over their data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02461v2</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abraham Nash</dc:creator>
    </item>
  </channel>
</rss>
