<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Apr 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Path integral control under McKean-Vlasov dynamics</title>
      <link>https://arxiv.org/abs/2404.17006</link>
      <description>arXiv:2404.17006v1 Announce Type: new 
Abstract: We investigate the complexities of the McKean-Vlasov optimal control problem, exploring its various formulations such as the strong and weak formulations, as well as both Markovian and non-Markovian setups within financial markets. Furthermore, we examine scenarios where the law governing the control process impacts the dynamics of options. By conceptualizing controls as probability measures on a fitting canonical space with filtrations, we unlock the potential to devise classical measurable selection methods, conditioning strategies, and concatenation arguments within this innovative framework. These tools enable us to establish the dynamic programming principle under a wide range of conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17006v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timothy Bennett</dc:creator>
    </item>
    <item>
      <title>An adaptive linearized alternating direction multiplier method with a relaxation step for convex programming</title>
      <link>https://arxiv.org/abs/2404.17109</link>
      <description>arXiv:2404.17109v1 Announce Type: new 
Abstract: Alternating direction multiplication is a powerful technique for solving convex optimisation problems. When challenging subproblems are encountered in the real world, it is useful to solve them by introducing neighbourhood terms. When the neighbourhood matrix is positive definite, the algorithm converges but at the same time makes the iteration step small. Recent studies have revealed the potential non-positive definiteness of the neighbourhood matrix. In this paper, we present an adaptive linearized alternating direction multiplier method with a relaxation step, combining the relaxation step with an adaptive technique. The novelty of the method is to use the information of the current iteration point to dynamically select the neighbourhood matrix, increase the iteration step size, and speed up the convergence of the algorithm.We prove the global convergence of the algorithm theoretically and illustrate the effectiveness of the algorithm using numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17109v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boran Wang</dc:creator>
    </item>
    <item>
      <title>Delay-tolerant distributed Bregman proximal algorithms</title>
      <link>https://arxiv.org/abs/2404.17190</link>
      <description>arXiv:2404.17190v1 Announce Type: new 
Abstract: Many problems in machine learning write as the minimization of a sum of individual loss functions over the training examples. These functions are usually differentiable but, in some cases, their gradients are not Lipschitz continuous, which compromises the use of (proximal) gradient algorithms. Fortunately, changing the geometry and using Bregman divergences can alleviate this issue in several applications, such as for Poisson linear inverse problems.However, the Bregman operation makes the aggregation of several points and gradients more involved, hindering the distribution of computations for such problems. In this paper, we propose an asynchronous variant of the Bregman proximal-gradient method, able to adapt to any centralized computing system. In particular, we prove that the algorithm copes with arbitrarily long delays and we illustrate its behavior on distributed Poisson inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17190v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Optimization Methods and Software, 2024, pp.1-17. \&amp;\#x27E8;10.1080/10556788.2023.2278089\&amp;\#x27E9</arxiv:journal_reference>
      <dc:creator>S. Chraibi (UGA, LJK), F. Iutzeler (UGA, LJK), J. Malick (UGA, LJK), A. Rogozin (MIPT)</dc:creator>
    </item>
    <item>
      <title>Properties of the complementarity set for the cone of copositive matrices</title>
      <link>https://arxiv.org/abs/2404.17375</link>
      <description>arXiv:2404.17375v1 Announce Type: new 
Abstract: For a proper cone $K$ and its dual cone $K^*$ in $\mathbb R^n$, the complementarity set of $K$ is defined as
  ${\mathbb C}(K)=\{(x,y): x\in K,\; y\in K^*,\, x^\top y=0\}$. It is known that ${\mathbb C}(K)$ is an $n$-dimensional manifold in the space $\mathbb R^{2n}$. If $ K$ is a symmetric cone, points in ${\mathbb C}(K)$ must satisfy at least $n$ linearly independent bi-linear identities. Since this knowledge comes in handy when optimizing over such cones, it makes sense to search for similar relationships for non-symmetric cones.
  In this paper, we study properties of the complementarity set for the dual cones of copositive and completely positive matrices. Despite these cones are of great interest due to their applications in optimization, they have not yet been sufficiently studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17375v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>O. I. Kostyukova</dc:creator>
    </item>
    <item>
      <title>Stochastic Bregman Subgradient Methods for Nonsmooth Nonconvex Optimization Problems</title>
      <link>https://arxiv.org/abs/2404.17386</link>
      <description>arXiv:2404.17386v1 Announce Type: new 
Abstract: This paper focuses on the problem of minimizing a locally Lipschitz continuous function. Motivated by the effectiveness of Bregman gradient methods in training nonsmooth deep neural networks and the recent progress in stochastic subgradient methods for nonsmooth nonconvex optimization problems \cite{bolte2021conservative,bolte2022subgradient,xiao2023adam}, we investigate the long-term behavior of stochastic Bregman subgradient methods in such context, especially when the objective function lacks Clarke regularity. We begin by exploring a general framework for Bregman-type methods, establishing their convergence by a differential inclusion approach. For practical applications, we develop a stochastic Bregman subgradient method that allows the subproblems to be solved inexactly. Furthermore, we demonstrate how a single timescale momentum can be integrated into the Bregman subgradient method with slight modifications to the momentum update. Additionally, we introduce a Bregman proximal subgradient method for solving composite optimization problems possibly with constraints, whose convergence can be guaranteed based on the general framework. Numerical experiments on training nonsmooth neural networks are conducted to validate the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17386v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuangyu Ding, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Averaged observations and turnpike phenomenon for parameter-dependent systems</title>
      <link>https://arxiv.org/abs/2404.17455</link>
      <description>arXiv:2404.17455v1 Announce Type: new 
Abstract: Our main contribution in this article is the achievement of the turnpike property in its integral and exponential forms for parameter-dependent systems with averaged observations in the cost functional. Namely, under suitable assumptions with respect to the matrices that defined the dynamics and the cost functional, we prove that the optimal control and state for the evolutionary problem converge in average to the optimal pair of an associated stationary problem. Moreover, we characterize the closeness between these two optimal solutions, proving that over a large time interval, they are exponentially close.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17455v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mart\'in Hern\'andez, Martin Lazar, Sebasti\'an Zamorano</dc:creator>
    </item>
    <item>
      <title>Applications of Lifted Nonlinear Cuts to Convex Relaxations of the AC Power Flow Equations</title>
      <link>https://arxiv.org/abs/2404.17541</link>
      <description>arXiv:2404.17541v1 Announce Type: new 
Abstract: We demonstrate that valid inequalities, or lifted nonlinear cuts (LNC), can be projected to tighten the Second Order Cone (SOC), Convex DistFlow (CDF), and Network Flow (NF) relaxations of the AC Optimal Power Flow (AC-OPF) problem. We conduct experiments on 36 cases from the PGLib-OPF library for two objective functions, (1) power generation maximization and (2) generation cost minimization. Significant optimality gap improvements are shown for the maximization problem, where the LNC strengthen the SOC and CDF relaxations in 100% of the test cases, with average and maximum differences in the optimality gaps of 23.1% and 93.5% respectively. The NF relaxation is strengthened in 79.2% of test cases, with average and maximum differences in the optimality gaps of 3.45% and 21.2% respectively. We also study the trade-off between relaxation quality and solve time, demonstrating that the strengthened CDF relaxation outperforms the strengthened SOC formulation in terms of runtime and number of iterations needed, while the strengthened NF formulation is the most scalable with the lowest relaxation quality provided by these LNC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17541v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio I. Bugosen, Robert B. Parker, Carleton Coffrin</dc:creator>
    </item>
    <item>
      <title>Complexity of Minimizing Regularized Convex Quadratic Functions</title>
      <link>https://arxiv.org/abs/2404.17543</link>
      <description>arXiv:2404.17543v1 Announce Type: new 
Abstract: In this work, we study the iteration complexity of gradient methods minimizing the class of uniformly convex regularized quadratic functions. We prove lower bounds on the functional residual of the form $\Omega(N^{-2p/(p-2)})$, where $p &gt; 2$ is the power of the regularization term, and $N$ is the number of calls to a first-order oracle. A special case of our problem class is $p=3$, which is the minimization of cubically regularized convex quadratic functions. It naturally appears as a subproblem at each iteration of the cubic Newton method. The corresponding lower bound for $p = 3$ becomes $\Omega(N^{-6})$. Our result matches the best-known upper bounds on this problem class, rendering a sharp analysis of the minimization of uniformly convex regularized quadratic functions. We also establish new lower bounds on minimizing the gradient norm within our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17543v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Berg Thomsen, Nikita Doikov</dc:creator>
    </item>
    <item>
      <title>Space-Variant Total Variation boosted by learning techniques in few-view tomographic imaging</title>
      <link>https://arxiv.org/abs/2404.16900</link>
      <description>arXiv:2404.16900v1 Announce Type: cross 
Abstract: This paper focuses on the development of a space-variant regularization model for solving an under-determined linear inverse problem. The case study is a medical image reconstruction from few-view tomographic noisy data. The primary objective of the proposed optimization model is to achieve a good balance between denoising and the preservation of fine details and edges, overcoming the performance of the popular and largely used Total Variation (TV) regularization through the application of appropriate pixel-dependent weights. The proposed strategy leverages the role of gradient approximations for the computation of the space-variant TV weights. For this reason, a convolutional neural network is designed, to approximate both the ground truth image and its gradient using an elastic loss function in its training. Additionally, the paper provides a theoretical analysis of the proposed model, showing the uniqueness of its solution, and illustrates a Chambolle-Pock algorithm tailored to address the specific problem at hand. This comprehensive framework integrates innovative regularization techniques with advanced neural network capabilities, demonstrating promising results in achieving high-quality reconstructions from low-sampled tomographic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16900v1</guid>
      <category>eess.IV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Morotti, Davide Evangelista, Andrea Sebastiani, Elena Loli Piccolomini</dc:creator>
    </item>
    <item>
      <title>Well-posedness and convergence of entropic approximation of semi-geostrophic equations</title>
      <link>https://arxiv.org/abs/2404.17387</link>
      <description>arXiv:2404.17387v1 Announce Type: cross 
Abstract: We prove existence and uniqueness of solutions for an entropic version of the semi-geostrophic equations. We also establish convergence to a weak solution of the semi-geostrophic equations as the entropic parameter vanishes. Convergence is also proved for discretizations that can be computed numerically in practice as shown recently in [6].</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17387v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Carlier, Hugo Malamut</dc:creator>
    </item>
    <item>
      <title>Establishing best practices for modeling long duration energy storage in deeply decarbonized energy systems</title>
      <link>https://arxiv.org/abs/2404.17474</link>
      <description>arXiv:2404.17474v1 Announce Type: cross 
Abstract: Long duration energy storage (LDES) may become a critical technology for the decarbonization of the power sector, as current commercially available Li-ion battery storage technologies cannot cost-effectively shift energy to address multi-day or seasonal variability in demand and renewable energy availability. LDES is difficult to model in existing energy system planning models (such as electricity system capacity expansion models), as it is much more dependent on an accurate representation of chronology than other resources. Techniques exist for modeling LDES in these planning models; however, it is not known how spatial and temporal resolution affect the performance of these techniques, creating a research gap. In this study we examine what spatial and temporal resolution is necessarily to accurately capture the full value of LDES, in the context of a continent-scale capacity expansion model. We use the results to draw conclusions and present best practices for modelers seeking to accurately model LDES in a macro-energy systems planning context. Our key findings are: 1) modeling LDES with linked representative periods is crucial to capturing its full value, 2) LDES value is highly sensitive to the cost and availability of other resources, and 3) temporal resolution is more important than spatial resolution for capturing the full value of LDES, although how much temporal resolution is needed will depend on the specific model context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17474v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Mantegna, Wilson Ricks, Aneesha Manocha, Neha Patankar, Dharik Mallapragada, Jesse Jenkins</dc:creator>
    </item>
    <item>
      <title>Decentralized State-Dependent Markov Chain Synthesis with an Application to Swarm Guidance</title>
      <link>https://arxiv.org/abs/2012.02303</link>
      <description>arXiv:2012.02303v2 Announce Type: replace 
Abstract: This paper introduces a decentralized state-dependent Markov chain synthesis (DSMC) algorithm for finite-state Markov chains. We present a state-dependent consensus protocol that achieves exponential convergence under mild technical conditions, without relying on any connectivity assumptions regarding the dynamic network topology. Utilizing the proposed consensus protocol, we develop the DSMC algorithm, updating the Markov matrix based on the current state while ensuring the convergence conditions of the consensus protocol. This result establishes the desired steady-state distribution for the resulting Markov chain, ensuring exponential convergence from all initial distributions while adhering to transition constraints and minimizing state transitions. The DSMC's performance is demonstrated through a probabilistic swarm guidance example, which interprets the spatial distribution of a swarm comprising a large number of mobile agents as a probability distribution and utilizes the Markov chain to compute transition probabilities between states. Simulation results demonstrate faster convergence for the DSMC based algorithm when compared to the previous Markov chain based swarm guidance algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.02303v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samet Uzun, Nazim Kemal Ure, Behcet Acikmese</dc:creator>
    </item>
    <item>
      <title>Robust Data-Driven CARA Optimization</title>
      <link>https://arxiv.org/abs/2107.06714</link>
      <description>arXiv:2107.06714v3 Announce Type: replace 
Abstract: We focus on data-driven, risk-averse optimization problems where decision-makers exhibit constant absolute risk aversion (CARA), represented by an exponential utility function. We consider payoff functions expressible as conic optimization problems, highlighting their expansive use in prescriptive analytics. Aiming to mitigate the overfitting issues inherent in empirical distribution-based optimization, we employ a robust satisficing strategy, which combines a target parameter with a Wasserstein distance metric, to define acceptable solutions, robustly. This target parameter could be determined via cross validation to mitigate overfitting and improve out-of-sample performance. Nevertheless, integrating an exponential utility function into a robust satisficing framework introduces substantial computational challenges. Traditional convex approximations, despite being safe and tractable, do not guarantee feasibility when applied to some appropriate target levels. We overcome this inconsistency by delineating specific conditions, namely, a scenario with complete and bounded recourse, polyhedral uncertainty support and polyhedral metric norm, under which a safe, tractable, and consistent approximation of the data-driven robust satisficing problem can be guaranteed for any reasonably specified target. To ensure compliance with the complete and bounded recourse conditions, we subsequently introduce the notion of augmented exponential utility by restricting the domain of the utility function. We validate our theoretical results with computational experiments in two applications: data-driven portfolio optimization and an optimal location problem. The numerical results underscore the efficacy of incorporating robustness into optimization models, significantly enhancing solution quality as compared to traditional empirical optimization approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.06714v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Chen, Arjun Ramachandra, Napat Rujeerapaiboon, Melvyn Sim</dc:creator>
    </item>
    <item>
      <title>Physics-informed neural networks via stochastic Hamiltonian dynamics learning</title>
      <link>https://arxiv.org/abs/2111.08108</link>
      <description>arXiv:2111.08108v3 Announce Type: replace 
Abstract: In this paper, we propose novel learning frameworks to tackle optimal control problems by applying the Pontryagin maximum principle and then solving for a Hamiltonian dynamical system. Applying the Pontryagin maximum principle to the original optimal control problem shifts the learning focus to reduced Hamiltonian dynamics and corresponding adjoint variables. Then, the reduced Hamiltonian networks can be learned by going backwards in time and then minimizing loss function deduced from the Pontryagin maximum principle's conditions. The learning process is further improved by progressively learning a posterior distribution of the reduced Hamiltonians. This is achieved through utilizing a variational autoencoder which leads to more effective path exploration process. We apply our learning frameworks called NeuralPMP to various control tasks and obtain competitive results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.08108v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandrajit Bajaj, Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Decision Making under Cumulative Prospect Theory: An Alternating Direction Method of Multipliers</title>
      <link>https://arxiv.org/abs/2210.02626</link>
      <description>arXiv:2210.02626v3 Announce Type: replace 
Abstract: This paper proposes a novel numerical method for solving the problem of decision making under cumulative prospect theory (CPT), where the goal is to maximize utility subject to practical constraints, assuming only finite realizations of the associated distribution are available. Existing methods for CPT optimization rely on particular assumptions that may not hold in practice. To overcome this limitation, we present the first numerical method with a theoretical guarantee for solving CPT optimization using an alternating direction method of multipliers (ADMM). One of its subproblems involves optimization with the CPT utility subject to a chain constraint, which presents a significant challenge. To address this, we develop two methods for solving this subproblem. The first method uses dynamic programming, while the second method is a modified version of the pooling-adjacent-violators algorithm that incorporates the CPT utility function. Moreover, we prove the theoretical convergence of our proposed ADMM method and the two subproblem-solving methods. Finally, we conduct numerical experiments to validate our proposed approach and demonstrate how CPT's parameters influence investor behavior using real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.02626v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyu Cui, Rujun Jiang, Yun Shi, Rufeng Xiao, Yifan Yan</dc:creator>
    </item>
    <item>
      <title>Dynamic Optimization on Quantum Hardware: Feasibility for a Process Industry Use Case</title>
      <link>https://arxiv.org/abs/2311.07310</link>
      <description>arXiv:2311.07310v3 Announce Type: replace 
Abstract: The quest for real-time dynamic optimization solutions in the process industry represents a formidable computational challenge, particularly within the realm of applications like model-predictive control, where rapid and reliable computations are critical. Conventional methods can struggle to surmount the complexities of such tasks. Quantum computing and quantum annealing emerge as \textit{avant-garde} contenders to transcend conventional computational constraints. We convert a dynamic optimization problem, {characterized by an optimization problem with a system of differential-algebraic equations embedded}, into a Quadratic Unconstrained Binary Optimization problem, enabling quantum computational approaches. The empirical findings synthesized from classical methods, simulated annealing, quantum annealing via D-Wave's quantum annealer, and hybrid solver methodologies, illuminate the intricate landscape of computational prowess essential for tackling complex and high-dimensional dynamic optimization problems. Our findings suggest that while quantum annealing is a maturing technology that currently does not outperform state-of-the-art classical solvers, continuous improvements could eventually aid in increasing efficiency within the chemical process industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07310v3</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compchemeng.2024.108704</arxiv:DOI>
      <arxiv:journal_reference>Computers and Chemical Engineering, 2024, 108704, ISSN 0098-1354</arxiv:journal_reference>
      <dc:creator>Dennis Michael Nenno, Adrian Caspari</dc:creator>
    </item>
    <item>
      <title>An Incentive Regulation Approach for Balancing Stakeholder Interests in Transmission Investment</title>
      <link>https://arxiv.org/abs/2401.03556</link>
      <description>arXiv:2401.03556v2 Announce Type: replace 
Abstract: The merchant-regulatory mechanism represents a promising tool that combines the benefits of merchant investment and regulated investment, thereby providing efficient incentives for merchant Transmission Companies (Transcos) subject to regulatory compliance. However, one of the drawbacks of the H-R-G-V merchant-regulated mechanism is that it allows the Transco to capture the entire surplus increase resulting from investment, without any economic benefits for consumers and generators. To address this issue, we propose an incentive tuning parameter, which is incorporated into the calculation of the incentive fee for the Transco. Accordingly, the regulatory framework can effectively manage the Transco's profit and allow market participants to access economic benefits, thus ensuring a fair distribution of economic advantages among the stakeholders, while the impact on overall social welfare remains relatively modest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03556v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>23rd Power Systems Computation Conference, PSCC2024</arxiv:journal_reference>
      <dc:creator>Yuxin Xia, Iacopo Savelli, Thomas Morstyn</dc:creator>
    </item>
    <item>
      <title>An optimal advertising model with carryover effect and mean field terms</title>
      <link>https://arxiv.org/abs/2402.01015</link>
      <description>arXiv:2402.01015v3 Announce Type: replace 
Abstract: We consider a class of optimal advertising problems under uncertainty for the introduction of a new product into the market, on the line of the seminal papers of Vidale and Wolfe, 1957, and Nerlove and Arrow, 1962. The main features of our model are that, on one side, we assume a carryover effect (i.e. the advertisement spending affects the goodwill with some delay); on the other side we introduce, in the state equation and in the objective, some mean field terms which take into account the presence of other agents. We take the point of view of a planner who optimizes the average profit of all agents, hence we fall into the family of the so-called "Mean Field Control" problems. The simultaneous presence of the carryover effect makes the problem infinite dimensional hence belonging to a family of problems which are very difficult in general and whose study started only very recently, see Cosso et Al, 2023. Here we consider, as a first step, a simple version of the problem providing the solutions in a simple case through a suitable auxiliary problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01015v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fausto Gozzi, Federica Masiero, Mauro Rosestolato</dc:creator>
    </item>
    <item>
      <title>A Computational Method for $H_2$-optimal Estimator and State Feedback Controller Synthesis for PDEs</title>
      <link>https://arxiv.org/abs/2403.08052</link>
      <description>arXiv:2403.08052v2 Announce Type: replace 
Abstract: In this paper, we present solvable, convex formulations of $H_2$-optimal state estimation and state-feedback control problems for a general class of linear Partial Differential Equations (PDEs) with one spatial dimension. These convex formulations are derived by using an analysis and control framework called the `Partial Integral Equation' (PIE) framework, which utilizes the PIE representation of infinite-dimensional systems. Since PIEs are parameterized by Partial Integral (PI) operators that form an algebra, $H_2$-optimal estimation and control problems for PIEs can be formulated as Linear PI Inequalities (LPIs). Furthermore, if a PDE admits a PIE representation, then the stability and $H_2$ performance of the PIE system implies that of the PDE system. Consequently, the optimal estimator and controller obtained for a PIE using LPIs provide the same stability and performance when applied to the corresponding PDE. These LPI optimization problems can be solved computationally using semi-definite programming solvers because such problems can be formulated using Linear Matrix Inequalities by using positive matrices to parameterize a cone of positive PI operators. We illustrate the application of these methods by constructing observers and controllers for some standard PDE examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08052v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sachin Shivakumar, Matthew Peet</dc:creator>
    </item>
    <item>
      <title>Why does the two-timescale Q-learning converge to different mean field solutions? A unified convergence analysis</title>
      <link>https://arxiv.org/abs/2404.04357</link>
      <description>arXiv:2404.04357v2 Announce Type: replace 
Abstract: We revisit the unified two-timescale Q-learning algorithm as initially introduced by Angiuli et al. \cite{angiuli2022unified}. This algorithm demonstrates efficacy in solving mean field game (MFG) and mean field control (MFC) problems, simply by tuning the ratio of two learning rates for mean field distribution and the Q-functions respectively. In this paper, we provide a comprehensive theoretical explanation of the algorithm's bifurcated numerical outcomes under fixed learning rates. We achieve this by establishing a diagram that correlates continuous-time mean field problems to their discrete-time Q-function counterparts, forming the basis of the algorithm. Our key contribution lies in the construction of a Lyapunov function integrating both mean field distribution and Q-function iterates. This Lyapunov function facilitates a unified convergence of the algorithm across the entire spectrum of learning rates, thus providing a cohesive framework for analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04357v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing An, Jianfeng Lu, Yue Wu, Yang Xiang</dc:creator>
    </item>
    <item>
      <title>Variational Dynamic Programming for Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2404.14806</link>
      <description>arXiv:2404.14806v2 Announce Type: replace 
Abstract: We consider the problem of stochastic optimal control where the state-feedback control policies take the form of a probability distribution, and where a penalty on the entropy is added. By viewing the cost function as a Kullback-Leibler (KL) divergence between two Markov chains, we bring the tools from variational inference to bear on our optimal control problem. This allows for deriving a dynamic programming principle, where the value function is defined as a KL divergence again. We then resort to Gaussian distributions to approximate the control policies, and apply the theory to control affine nonlinear systems with quadratic costs. This results in closed-form recursive updates, which generalize LQR control and the backward Riccati equation. We illustrate this novel method on the simple problem of stabilizing an inverted pendulum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14806v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Lambert (SIERRA), Francis Bach (SIERRA), Silv\`ere Bonnabel (CAOR)</dc:creator>
    </item>
    <item>
      <title>All You Need is Resistance: On the Equivalence of Effective Resistance and Certain Optimal Transport Problems on Graphs</title>
      <link>https://arxiv.org/abs/2404.15261</link>
      <description>arXiv:2404.15261v2 Announce Type: replace 
Abstract: The fields of effective resistance and optimal transport on graphs are filled with rich connections to combinatorics, geometry, machine learning, and beyond. In this article we put forth a bold claim: that the two fields should be understood as one and the same, up to a choice of $p$. We make this claim precise by introducing the parameterized family of $p$-Beckmann distances for probability measures on graphs and relate them sharply to certain Wasserstein distances. Then, we break open a suite of results including explicit connections to optimal stopping times and random walks on graphs, graph Sobolev spaces, and a Benamou-Brenier type formula for $2$-Beckmann distance. We further explore empirical implications in the world of unsupervised learning for graph data and propose further study of the usage of these metrics where Wasserstein distance may produce computational bottlenecks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15261v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sawyer Robertson, Zhengchao Wan, Alexander Cloninger</dc:creator>
    </item>
    <item>
      <title>A degree 4 sum-of-squares lower bound for the clique number of the Paley graph</title>
      <link>https://arxiv.org/abs/2211.02713</link>
      <description>arXiv:2211.02713v2 Announce Type: replace-cross 
Abstract: We prove that the degree 4 sum-of-squares (SOS) relaxation of the clique number of the Paley graph on a prime number $p$ of vertices has value at least $\Omega(p^{1/3})$. This is in contrast to the widely believed conjecture that the actual clique number of the Paley graph is $O(\mathrm{polylog}(p))$. Our result may be viewed as a derandomization of that of Deshpande and Montanari (2015), who showed the same lower bound (up to $\mathrm{polylog}(p)$ terms) with high probability for the Erd\H{o}s-R\'{e}nyi random graph on $p$ vertices, whose clique number is with high probability $O(\log(p))$. We also show that our lower bound is optimal for the Feige-Krauthgamer construction of pseudomoments, derandomizing an argument of Kelner. Finally, we present numerical experiments indicating that the value of the degree 4 SOS relaxation of the Paley graph may scale as $O(p^{1/2 - \epsilon})$ for some $\epsilon &gt; 0$, and give a matrix norm calculation indicating that the pseudocalibration proof strategy for SOS lower bounds for random graphs will not immediately transfer to the Paley graph. Taken together, our results suggest that degree 4 SOS may break the "$\sqrt{p}$ barrier" for upper bounds on the clique number of Paley graphs, but prove that it can at best improve the exponent from $1/2$ to $1/3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02713v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitriy Kunisky, Xifan Yu</dc:creator>
    </item>
    <item>
      <title>Assigning Stationary Distributions to Sparse Stochastic Matrices</title>
      <link>https://arxiv.org/abs/2312.16011</link>
      <description>arXiv:2312.16011v3 Announce Type: replace-cross 
Abstract: The target stationary distribution problem (TSDP) is the following: given an irreducible stochastic matrix $G$ and a target stationary distribution $\hat \mu$, construct a minimum norm perturbation, $\Delta$, such that $\hat G = G+\Delta$ is also stochastic and has the prescribed target stationary distribution, $\hat \mu$. In this paper, we revisit the TSDP under a constraint on the support of $\Delta$, that is, on the set of non-zero entries of $\Delta$. This is particularly meaningful in practice since one cannot typically modify all entries of $G$. We first show how to construct a feasible solution $\hat G$ that has essentially the same support as the matrix $G$. Then we show how to compute globally optimal and sparse solutions using the component-wise $\ell_1$ norm and linear optimization. We propose an efficient implementation that relies on a column-generation approach which allows us to solve sparse problems of size up to $10^5 \times 10^5$ in a few minutes. We illustrate the proposed algorithms with several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16011v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Gillis, Paul Van Dooren</dc:creator>
    </item>
    <item>
      <title>Optimal vaccination strategies on networks and in metropolitan areas</title>
      <link>https://arxiv.org/abs/2402.00207</link>
      <description>arXiv:2402.00207v2 Announce Type: replace-cross 
Abstract: This study presents a mathematical model for optimal vaccination strategies in interconnected metropolitan areas, considering commuting patterns. It is a compartmental model with a vaccination rate for each city, acting as a control function. The commuting patterns are incorporated through a weighted adjacency matrix and a parameter that selects day and night periods. The optimal control problem is formulated to minimize a functional cost that balances the number of hospitalizations and vaccines, including restrictions of a weekly availability cap and an application capacity of vaccines per unit of time. The key findings of this work are bounds for the basic reproduction number, particularly in the case of a metropolitan area, and the study of the optimal control problem. Theoretical analysis and numerical simulations provide insights into disease dynamics and the effectiveness of control measures. The research highlights the importance of prioritizing vaccination in the capital to better control the disease spread, as we depicted in our numerical simulations. This model serves as a tool to improve resource allocation in epidemic control across metropolitan regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00207v2</guid>
      <category>q-bio.PE</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lucas Machado Moschen, Mar\'ia Soledad Aronna</dc:creator>
    </item>
  </channel>
</rss>
