<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2025 03:01:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Variational empirical Bayes variable selection in high-dimensional logistic regression</title>
      <link>https://arxiv.org/abs/2502.10532</link>
      <description>arXiv:2502.10532v1 Announce Type: new 
Abstract: Logistic regression involving high-dimensional covariates is a practically important problem. Often the goal is variable selection, i.e., determining which few of the many covariates are associated with the binary response. Unfortunately, the usual Bayesian computations can be quite challenging and expensive. Here we start with a recently proposed empirical Bayes solution, with strong theoretical convergence properties, and develop a novel and computationally efficient variational approximation thereof. One such novelty is that we develop this approximation directly for the marginal distribution on the model space, rather than on the regression coefficients themselves. We demonstrate the method's strong performance in simulations, and prove that our variational approximation inherits the strong selection consistency property satisfied by the posterior distribution that it is approximating.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10532v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiqi Tang, Ryan Martin</dc:creator>
    </item>
    <item>
      <title>On a Semiparametric Stochastic Volatility Model</title>
      <link>https://arxiv.org/abs/2502.11954</link>
      <description>arXiv:2502.11954v1 Announce Type: new 
Abstract: This paper presents a novel approach to stochastic volatility (SV) modeling by utilizing nonparametric techniques that enhance our ability to capture the volatility of financial time series data, with a particular emphasis on the non-Gaussian behavior of asset return distributions. Although traditional parametric SV models can be useful, they often suffer from restrictive assumptions regarding errors, which may inadequately represent extreme values and tail behavior in financial returns. To address these limitations, we propose two semiparametric SV models that use data to better approximate error distributions. To facilitate the computation of model parameters, we developed a Markov Chain Monte Carlo (MCMC) method for estimating model parameters and volatility dynamics. Simulations and empirical tests on S&amp;P 500 data indicate that nonparametric models can minimize bias and variance in volatility estimation, providing a more accurate reflection of market expectations about volatility. This methodology serves as a promising alternative to conventional parametric models, improving precision in financial risk assessment and deepening our understanding of the volatility dynamics of financial returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11954v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yudong Feng, Ashis Gangopadhyay</dc:creator>
    </item>
    <item>
      <title>Cohering Disaggregation and Uncertainty Quantification for Spatially Misaligned Data</title>
      <link>https://arxiv.org/abs/2502.10584</link>
      <description>arXiv:2502.10584v1 Announce Type: cross 
Abstract: Spatial misalignments arise from data aggregation or attempts to align misaligned data, leading to information loss. We propose a disaggregation framework that combines the finite element method (FEM) with a first-order Taylor approximation via integrated nested Laplace approximation (INLA).
  In landslide studies, landslide occurrences are often aggregated into counts based on slope units, reducing spatial detail. Our framework examines point pattern and aggregated count models under four covariate field scenarios: \textit{Raster at Full Resolution (RastFull), Raster Aggregation (RastAgg), Polygon Aggregation (PolyAgg), and Point Values (PointVal)}. The first three involve aggregation, while the latter two have incomplete fields. For these, we estimate the full covariate field using \textit{Value Plugin, Joint Uncertainty, and Uncertainty Plugin} methods, with the latter two accounting for uncertainty propagation and showing superior performance. Even under model misspecification (i.e.\ modelling a nonlinear field as linear), these methods remain more robust.
  Whenever possible, point pattern observations and full-resolution covariate fields should be prioritized. For incomplete fields, methods incorporating uncertainty propagation are preferred. This framework supports landslide susceptibility and other spatial mapping, integrating seamlessly with R-INLA \ extension packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10584v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Man Ho Suen, Mark Naylor, Finn Lindgren</dc:creator>
    </item>
    <item>
      <title>Generative Adversarial Networks for High-Dimensional Item Factor Analysis: A Deep Adversarial Learning Algorithm</title>
      <link>https://arxiv.org/abs/2502.10650</link>
      <description>arXiv:2502.10650v1 Announce Type: cross 
Abstract: Advances in deep learning and representation learning have transformed item factor analysis (IFA) in the item response theory (IRT) literature by enabling more efficient and accurate parameter estimation. Variational Autoencoders (VAEs) have been one of the most impactful techniques in modeling high-dimensional latent variables in this context. However, the limited expressiveness of the inference model based on traditional VAEs can still hinder the estimation performance. This study introduces Adversarial Variational Bayes (AVB) algorithms as an improvement to VAEs for IFA with improved flexibility and accuracy. By bridging the strengths of VAEs and Generative Adversarial Networks (GANs), AVB incorporates an auxiliary discriminator network to reframe the estimation process as a two-player adversarial game and removes the restrictive assumption of standard normal distributions in the inference model. Theoretically, AVB can achieve similar or higher likelihood compared to VAEs. A further enhanced algorithm, Importance-weighted Adversarial Variational Bayes (IWAVB) is proposed and compared with Importance-weighted Autoencoders (IWAE). In an exploratory analysis of real empirical data, IWAVB demonstrated superior expressiveness by achieving a higher likelihood compared to IWAE. In confirmatory studies with simulated data, IWAVB achieved similar mean-square error results to IWAE while consistently achieving higher likelihoods. Moreover, in simulations where latent variables followed a multimodal distribution, IWAVB outperformed IWAE by providing more accurate parameter estimates. With its innovative use of GANs, IWAVB is shown to have the potential to extend IFA to handle large-scale data, facilitating the potential integration of psychometrics and multimodal data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10650v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nanyu Luo, Feng Ji</dc:creator>
    </item>
    <item>
      <title>LEAPS: A discrete neural sampler via locally equivariant networks</title>
      <link>https://arxiv.org/abs/2502.10843</link>
      <description>arXiv:2502.10843v1 Announce Type: cross 
Abstract: We propose LEAPS, an algorithm to sample from discrete distributions known up to normalization by learning a rate matrix of a continuous-time Markov chain (CTMC). LEAPS can be seen as a continuous-time formulation of annealed importance sampling and sequential Monte Carlo methods, extended so that the variance of the importance weights is offset by the inclusion of the CTMC. To derive these importance weights, we introduce a set of Radon-Nikodym derivatives of CTMCs over their path measures. Because the computation of these weights is intractable with standard neural network parameterizations of rate matrices, we devise a new compact representation for rate matrices via what we call locally equivariant functions. To parameterize them, we introduce a family of locally equivariant multilayer perceptrons, attention layers, and convolutional networks, and provide an approach to make deep networks that preserve the local equivariance. This property allows us to propose a scalable training algorithm for the rate matrix such that the variance of the importance weights associated to the CTMC are minimal. We demonstrate the efficacy of LEAPS on problems in statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10843v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Holderrieth, Michael S. Albergo, Tommi Jaakkola</dc:creator>
    </item>
    <item>
      <title>Advances in Bayesian Modeling: Applications and Methods</title>
      <link>https://arxiv.org/abs/2502.11321</link>
      <description>arXiv:2502.11321v1 Announce Type: cross 
Abstract: This paper explores the versatility and depth of Bayesian modeling by presenting a comprehensive range of applications and methods, combining Markov chain Monte Carlo (MCMC) techniques and variational approximations. Covering topics such as hierarchical modeling, spatial modeling, higher-order Markov chains, and Bayesian nonparametrics, the study emphasizes practical implementations across diverse fields, including oceanography, climatology, epidemiology, astronomy, and financial analysis. The aim is to bridge theoretical underpinnings with real-world applications, illustrating the formulation of Bayesian models, elicitation of priors, computational strategies, and posterior and predictive analyses. By leveraging different computational methods, this paper provides insights into model fitting, goodness-of-fit evaluation, and predictive accuracy, addressing computational efficiency and methodological challenges across various datasets and domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11321v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifei Yan, Juan Sosa, Carlos A. Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Here Be Dragons: Bimodal posteriors arise from numerical integration error in longitudinal models</title>
      <link>https://arxiv.org/abs/2502.11510</link>
      <description>arXiv:2502.11510v1 Announce Type: cross 
Abstract: Longitudinal models with dynamics governed by differential equations may require numerical integration alongside parameter estimation. We have identified a situation where the numerical integration introduces error in such a way that it becomes a novel source of non-uniqueness in estimation. We obtain two very different sets of parameters, one of which is a good estimate of the true values and the other a very poor one. The two estimates have forward numerical projections statistically indistinguishable from each other because of numerical error. In such cases, the posterior distribution for parameters is bimodal, with a dominant mode closer to the true parameter value, and a second cluster around the errant value. We demonstrate that bimodality exists both theoretically and empirically for an affine first order differential equation, that a simulation workflow can test for evidence of the issue more generally, and that Markov Chain Monte Carlo sampling with a suitable solution can avoid bimodality. The issue of bimodal posteriors arising from numerical error has consequences for Bayesian inverse methods that rely on numerical integration more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11510v1</guid>
      <category>stat.OT</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tess O'Brien, Matt Moores, David Warton, Daniel Falster</dc:creator>
    </item>
    <item>
      <title>CriteoPrivateAd: A Real-World Bidding Dataset to Design Private Advertising Systems</title>
      <link>https://arxiv.org/abs/2502.12103</link>
      <description>arXiv:2502.12103v1 Announce Type: cross 
Abstract: In the past years, many proposals have emerged in order to address online advertising use-cases without access to third-party cookies. All these proposals leverage some privacy-enhancing technologies such as aggregation or differential privacy. Yet, no public and rich-enough ground truth is currently available to assess the relevancy of aforementioned private advertising frameworks. We are releasing the largest, in terms of number of features, bidding dataset specifically built in alignment with the design of major browser vendors proposals such as Chrome Privacy Sandbox. This dataset, coined CriteoPrivateAd, stands for an anonymised version of Criteo production logs and provides sufficient data to learn bidding models commonly used in online advertising under many privacy constraints (delayed reports, display and user-level differential privacy, user signal quantisation or aggregated reports). We ensured that this dataset, while being anonymised, is able to provide offline results close to production performance of adtech companies including Criteo - making it a relevant ground truth to design private advertising systems. The dataset is available in Hugging Face: https://huggingface.co/datasets/criteo/CriteoPrivateAd.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12103v1</guid>
      <category>cs.CR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mehdi Sebbar, Corentin Odic, Mathieu L\'echine, Alo\"is Bissuel, Nicolas Chrysanthos, Anthony D'Amato, Alexandre Gilotte, Fabian H\"oring, Sarah Nogueira, Maxime Vono</dc:creator>
    </item>
    <item>
      <title>Generating Synthetic Data with Locally Estimated Distributions for Disclosure Control</title>
      <link>https://arxiv.org/abs/2210.00884</link>
      <description>arXiv:2210.00884v2 Announce Type: replace 
Abstract: Sensitive datasets are often underutilized in research and industry due to privacy concerns, limiting the potential of valuable data-driven insights. Synthetic data generation presents a promising solution to address this challenge by balancing privacy protection with data utility. This paper introduces a new approach to mitigate privacy risks associated with outlier observations in synthetic datasets: the Local Resampler (LR). The LR leverages the $k$-nearest neighbors algorithm to generate synthetic data while minimizing disclosure risks by underrepresenting outliers, even when they are not detectable in marginal distributions. Theoretical and empirical analyses demonstrate that the LR effectively mitigates outlier-driven disclosure risks, and accurately replicates multimodal, skewed, and non-convex support distributions. The semiparametric nature of the LR ensures a low computational burden and works efficiently even with small samples. By parameterizing the balance between privacy risks and data utility, this approach promotes broader access to sensitive datasets for research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00884v2</guid>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ali Furkan Kalay</dc:creator>
    </item>
    <item>
      <title>MM Algorithms for Statistical Estimation in Quantile Regression</title>
      <link>https://arxiv.org/abs/2407.12348</link>
      <description>arXiv:2407.12348v3 Announce Type: replace-cross 
Abstract: Quantile regression \parencite{Koenker1978} is a robust and practically useful way to efficiently model quantile varying correlation and predict varied response quantiles of interest. This article constructs and tests MM algorithms, which are simple to code and have been suggested superior to some other prominent quantile regression methods in nonregularized problems \parencite{Pietrosanu2017}, in an array of linear quantile regression settings. Simulation studies comparing MM to existing tested methods and applications to various real data sets have corroborated our algorithms' effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12348v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Cheng, Anthony Yung Cheung Kuk</dc:creator>
    </item>
    <item>
      <title>Provable Benefit of Annealed Langevin Monte Carlo for Non-log-concave Sampling</title>
      <link>https://arxiv.org/abs/2407.16936</link>
      <description>arXiv:2407.16936v2 Announce Type: replace-cross 
Abstract: We consider the outstanding problem of sampling from an unnormalized density that may be non-log-concave and multimodal. To enhance the performance of simple Markov chain Monte Carlo (MCMC) methods, techniques of annealing type have been widely used. However, quantitative theoretical guarantees of these techniques are under-explored. This study takes a first step toward providing a non-asymptotic analysis of annealed MCMC. Specifically, we establish, for the first time, an oracle complexity of $\widetilde{O}\left(\frac{d\beta^2{\cal A}^2}{\varepsilon^6}\right)$ for the simple annealed Langevin Monte Carlo algorithm to achieve $\varepsilon^2$ accuracy in Kullback-Leibler divergence to the target distribution $\pi\propto{\rm e}^{-V}$ on $\mathbb{R}^d$ with $\beta$-smooth potential $V$. Here, ${\cal A}$ represents the action of a curve of probability measures interpolating the target distribution $\pi$ and a readily sampleable distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16936v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Guo, Molei Tao, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Functional Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2410.03619</link>
      <description>arXiv:2410.03619v4 Announce Type: replace-cross 
Abstract: Heterogeneous functional data commonly arise in time series and longitudinal studies. To uncover the statistical structures of such data, we propose Functional Singular Value Decomposition (FSVD), a unified framework encompassing various tasks for the analysis of functional data with potential heterogeneity. We establish the mathematical foundation of FSVD by proving its existence and providing its fundamental properties. We then develop an implementation approach for noisy and irregularly observed functional data based on a novel alternating minimization scheme and provide theoretical guarantees for its convergence and estimation accuracy. The FSVD framework also introduces the concepts of intrinsic basis functions and intrinsic basis vectors, representing two fundamental structural aspects of random functions. These concepts enable FSVD to provide new and improved solutions to tasks including functional principal component analysis, factor models, functional clustering, functional linear regression, and functional completion, while effectively handling heterogeneity and irregular temporal sampling. Through extensive simulations, we demonstrate that FSVD-based methods consistently outperform existing methods across these tasks. To showcase the value of FSVD in real-world datasets, we apply it to extract temporal patterns from a COVID-19 case count dataset and perform data completion on an electronic health record dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03619v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jianbin Tan, Pixu Shi, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Cost-aware simulation-based inference</title>
      <link>https://arxiv.org/abs/2410.07930</link>
      <description>arXiv:2410.07930v2 Announce Type: replace-cross 
Abstract: Simulation-based inference (SBI) is the preferred framework for estimating parameters of intractable models in science and engineering. A significant challenge in this context is the large computational cost of simulating data from complex models, and the fact that this cost often depends on parameter values. We therefore propose \textit{cost-aware SBI methods} which can significantly reduce the cost of existing sampling-based SBI methods, such as neural SBI and approximate Bayesian computation. This is achieved through a combination of rejection and self-normalised importance sampling, which significantly reduces the number of expensive simulations needed. Our approach is studied extensively on models from epidemiology to telecommunications engineering, where we obtain significant reductions in the overall cost of inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07930v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayush Bharti, Daolang Huang, Samuel Kaski, Fran\c{c}ois-Xavier Briol</dc:creator>
    </item>
    <item>
      <title>Gaussian multi-target filtering with target dynamics driven by a stochastic differential equation</title>
      <link>https://arxiv.org/abs/2411.19814</link>
      <description>arXiv:2411.19814v2 Announce Type: replace-cross 
Abstract: This paper proposes multi-target filtering algorithms in which target dynamics are given in continuous time and measurements are obtained at discrete time instants. In particular, targets appear according to a Poisson point process (PPP) in time with a given Gaussian spatial distribution, targets move according to a general time-invariant linear stochastic differential equation, and the life span of each target is modelled with an exponential distribution. For this multi-target dynamic model, we derive the distribution of the set of new born targets and calculate closed-form expressions for the best fitting mean and covariance of each target at its time of birth by minimising the Kullback-Leibler divergence via moment matching. This yields a novel Gaussian continuous-discrete Poisson multi-Bernoulli mixture (PMBM) filter, and its approximations based on Poisson multi-Bernoulli and probability hypothesis density filtering. These continuous-discrete multi-target filters are also extended to target dynamics driven by nonlinear stochastic differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19814v2</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3535556</arxiv:DOI>
      <arxiv:journal_reference>\'A. F. Garc\'ia-Fern\'andez and S. S\"arkk\"a, "Gaussian Multi-Target Filtering With Target Dynamics Driven by a Stochastic Differential Equation," in IEEE Transactions on Signal Processing, vol. 73, pp. 664-675, 2025</arxiv:journal_reference>
      <dc:creator>\'Angel F. Garc\'ia-Fern\'andez, Simo S\"arkk\"a</dc:creator>
    </item>
    <item>
      <title>LITE: Efficiently Estimating Gaussian Probability of Maximality</title>
      <link>https://arxiv.org/abs/2501.13535</link>
      <description>arXiv:2501.13535v2 Announce Type: replace-cross 
Abstract: We consider the problem of computing the probability of maximality (PoM) of a Gaussian random vector, i.e., the probability for each dimension to be maximal. This is a key challenge in applications ranging from Bayesian optimization to reinforcement learning, where the PoM not only helps with finding an optimal action, but yields a fine-grained analysis of the action domain, crucial in tasks such as drug discovery. Existing techniques are costly, scaling polynomially in computation and memory with the vector size. We introduce LITE, the first approach for estimating Gaussian PoM with almost-linear time and memory complexity. LITE achieves SOTA accuracy on a number of tasks, while being in practice several orders of magnitude faster than the baselines. This also translates to a better performance on downstream tasks such as entropy estimation and optimal control of bandits. Theoretically, we cast LITE as entropy-regularized UCB and connect it to prior PoM estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13535v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Menet (ETH Z\"urich), Jonas H\"ubotter (ETH Z\"urich), Parnian Kassraie (ETH Z\"urich), Andreas Krause (ETH Z\"urich)</dc:creator>
    </item>
    <item>
      <title>From Clicks to Conversations: Evaluating the Effectiveness of Conversational Agents in Statistical Analysis</title>
      <link>https://arxiv.org/abs/2502.08114</link>
      <description>arXiv:2502.08114v2 Announce Type: replace-cross 
Abstract: The rapid proliferation of data science forced different groups of individuals with different backgrounds to adapt to statistical analysis. We hypothesize that conversational agents are better suited for statistical analysis than traditional graphical user interfaces (GUI). In this work, we propose a novel conversational agent, StatZ, for statistical analysis. We evaluate the efficacy of StatZ relative to established statistical software:SPSS, SAS, Stata, and JMP in terms of accuracy, task completion time, user experience, and user satisfaction. We combined the proposed analysis question from state-of-the-art language models with suggestions from statistical analysis experts and tested with 51 participants from diverse backgrounds. Our experimental design assessed each participant's ability to perform statistical analysis tasks using traditional statistical analysis tools with GUI and our conversational agent. Results indicate that the proposed conversational agents significantly outperform GUI statistical software in all assessed metrics, including quantitative (task completion time, accuracy, and user experience), and qualitative (user satisfaction) metrics. Our findings underscore the potential of using conversational agents to enhance statistical analysis processes, reducing cognitive load and learning curves and thereby proliferating data analysis capabilities, to individuals with limited knowledge of statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08114v2</guid>
      <category>cs.HC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qifu Wen, Prishita Kochhar, Sherif Zeyada, Tahereh Javaheri, Reza Rawassizadeh</dc:creator>
    </item>
  </channel>
</rss>
