<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 02:54:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>PoissonRatioUQ: An R package for band ratio uncertainty quantification</title>
      <link>https://arxiv.org/abs/2602.07165</link>
      <description>arXiv:2602.07165v1 Announce Type: cross 
Abstract: We introduce an R package for Bayesian modeling and uncertainty quantification for problems involving count ratios. The modeling relies on the assumption that the quantity of interest is the ratio of Poisson means rather than the ratio of counts. We provide multiple different options for retrieval of this quantity for problems with and without spatial information included. Some added capability for uncertainty quantification for problems of the form $Z=(mT+z_0)^{p}$, where $Z$ is the intensity ratio and $T$ the quantity of interest, is included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07165v1</guid>
      <category>stat.CO</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew LeDuc, Tomoko Matsuo</dc:creator>
    </item>
    <item>
      <title>Dichotomy of Feature Learning and Unlearning: Fast-Slow Analysis on Neural Networks with Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2602.07378</link>
      <description>arXiv:2602.07378v1 Announce Type: cross 
Abstract: The dynamics of gradient-based training in neural networks often exhibit nontrivial structures; hence, understanding them remains a central challenge in theoretical machine learning. In particular, a concept of feature unlearning, in which a neural network progressively loses previously learned features over long training, has gained attention. In this study, we consider the infinite-width limit of a two-layer neural network updated with a large-batch stochastic gradient, then derive differential equations with different time scales, revealing the mechanism and conditions for feature unlearning to occur. Specifically, we utilize the fast-slow dynamics: while an alignment of first-layer weights develops rapidly, the second-layer weights develop slowly. The direction of a flow on a critical manifold, determined by the slow dynamics, decides whether feature unlearning occurs. We give numerical validation of the result, and derive theoretical grounding and scaling laws of the feature unlearning. Our results yield the following insights: (i) the strength of the primary nonlinear term in data induces the feature unlearning, and (ii) an initial scale of the second-layer weights mitigates the feature unlearning. Technically, our analysis utilizes Tensor Programs and the singular perturbation theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07378v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shota Imai, Sota Nishiyama, Masaaki Imaizumi</dc:creator>
    </item>
    <item>
      <title>Linear Response and Optimal Fingerprinting for Nonautonomous Systems</title>
      <link>https://arxiv.org/abs/2602.08022</link>
      <description>arXiv:2602.08022v1 Announce Type: cross 
Abstract: We provide a link between response theory, pullback measures, and optimal fingerprinting method that paves the way for a) predicting the impact of acting forcings on time-dependent systems and b) attributing observed anomalies to acting forcings when the reference state in not time-independent. We first derive formulas for linear response theory for time-dependent Markov chains and diffusions processes. We discuss existence, uniqueness, and differentiability of the pullback measure under general (not necessarily slow or periodic) perturbations of the transition kernels. An explicit Green-Kubo-type formula for the linear response is derived. We analyze in detail the case of periodic reference dynamics, where the unperturbed pullback attractor is periodic but the response is generally not. Our formulas reduce to those of classic linear response if one considers a reference autonomous state. Finally, we show that our results allow for extending the theory of optimal fingerprinting for detection and attribution of climate change (or change in any complex system) for the case of time-dependent background state and for the case where the optimal solution is sought for multiple time slices at the same time. We provide strong numerical support for the findings by applying our theory to a modified version of the Ghil-Sellers energy balance model where we include explicit time dependence in the reference state as a result of natural forcings. We verify the accuracy of response theory in predicting the impact of increases of $CO_2$ in the temperature field even when we discretize the system using Markov state modelling approach. Additionally, we consider a more complex modelling scenario where a localized aerosol forcing is also included in the system and show that the optimal fingerprinting method developed here is able to attribute the climate change signal to the acting forcings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08022v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valerio Lucarini</dc:creator>
    </item>
    <item>
      <title>DerivKit: stable numerical derivatives bridging Fisher forecasts and MCMC</title>
      <link>https://arxiv.org/abs/2602.08078</link>
      <description>arXiv:2602.08078v1 Announce Type: cross 
Abstract: DerivKit is a Python package for derivative-based statistical inference. It implements stable numerical differentiation and derivative assembly utilities for Fisher-matrix forecasting and higher-order likelihood approximations in scientific applications, supporting scalar- and vector-valued models including black-box or tabulated functions where automatic differentiation is impractical or unavailable. These derivatives are used to construct Fisher forecasts, Fisher bias estimates, and non-Gaussian likelihood expansions based on the Derivative Approximation for Likelihoods (DALI). By extending derivative-based inference beyond the Gaussian approximation, DerivKit forms a practical bridge between fast Fisher forecasts and more computationally intensive sampling-based methods such as Markov chain Monte Carlo (MCMC).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08078v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolina \v{S}ar\v{c}evi\'c, Matthijs van der Wild, Cynthia Trendafilova</dc:creator>
    </item>
    <item>
      <title>Mutual information and task-relevant latent dimensionality</title>
      <link>https://arxiv.org/abs/2602.08105</link>
      <description>arXiv:2602.08105v1 Announce Type: cross 
Abstract: Estimating the dimensionality of the latent representation needed for prediction -- the task-relevant dimension -- is a difficult, largely unsolved problem with broad scientific applications. We cast it as an Information Bottleneck question: what embedding bottleneck dimension is sufficient to compress predictor and predicted views while preserving their mutual information (MI). This repurposes neural MI estimators for dimensionality estimation. We show that standard neural estimators with separable/bilinear critics systematically inflate the inferred dimension, and we address this by introducing a hybrid critic that retains an explicit dimensional bottleneck while allowing flexible nonlinear cross-view interactions, thereby preserving the latent geometry. We further propose a one-shot protocol that reads off the effective dimension from a single over-parameterized hybrid model, without sweeping over bottleneck sizes. We validate the approach on synthetic problems with known task-relevant dimension. We extend the approach to intrinsic dimensionality by constructing paired views of a single dataset, enabling comparison with classical geometric dimension estimators. In noisy regimes where those estimators degrade, our approach remains reliable. Finally, we demonstrate the utility of the method on multiple physics datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08105v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paarth Gulati, Eslam Abdelaleem, Audrey Sederberg, Ilya Nemenman</dc:creator>
    </item>
    <item>
      <title>An efficient method for spot-checking quantum properties with sequential trials</title>
      <link>https://arxiv.org/abs/2602.08114</link>
      <description>arXiv:2602.08114v1 Announce Type: cross 
Abstract: In practical situations, the reliability of quantum resources can be compromised due to complex generation processes or adversarial manipulations during transmission. Consequently, the trials generated sequentially in an experiment may exhibit non-independent and non-identically distributed (non-i.i.d.) behavior. This non-i.i.d. behavior can introduce security concerns and result in faulty estimates when performing information tasks such as quantum key distribution, self-testing, verifiable quantum computation, and resource allocation in quantum networks. To certify the performance of such tasks, one can make a random decision in each trial, either spot-checking some desired property or utilizing the quantum resource for the given task. However, a general method for certification with a sequence of non-i.i.d. spot-checking trials is still missing. Here, we develop such a method. This method not only works efficiently with a finite number of trials but also yields asymptotically tight certificates of performance. Our analysis shows that even as the total number of trials approaches infinity, only a constant number of trials needs to be spot-checked on average to certify the average performance of the remaining trials at a specified confidence level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08114v1</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanbao Zhang, Akshay Seshadri, Emanuel Knill</dc:creator>
    </item>
    <item>
      <title>Reproducing the first and second moments of empirical degree distributions</title>
      <link>https://arxiv.org/abs/2505.10373</link>
      <description>arXiv:2505.10373v4 Announce Type: replace-cross 
Abstract: The study of probabilistic models for the analysis of complex networks represents a flourishing research field. Among the former, Exponential Random Graphs (ERGs) have gained increasing attention over the years. So far, only linear ERGs have been extensively employed to gain insight into the structural organisation of real-world complex networks. None, however, is capable of accounting for the variance of the empirical degree distribution. To this aim, non-linear ERGs must be considered. After showing that the usual mean-field approximation forces the degree-corrected version of the two-star model to degenerate, we define a fitness-induced variant of it. Such a `softened' model is capable of reproducing the sample variance, while retaining the explanatory power of its linear counterpart, within a purely canonical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10373v4</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/3vtj-5nlt</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Research 8 (013141) (2026)</arxiv:journal_reference>
      <dc:creator>Mattia Marzi, Francesca Giuffrida, Diego Garlaschelli, Tiziano Squartini</dc:creator>
    </item>
  </channel>
</rss>
