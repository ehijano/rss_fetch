<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Feb 2025 02:38:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Effectiveness of Golden Tickets and Wooden Spoons for Budget-Feasible Mechanisms</title>
      <link>https://arxiv.org/abs/2502.12306</link>
      <description>arXiv:2502.12306v1 Announce Type: new 
Abstract: One of the main challenges in mechanism design is to carefully engineer incentives ensuring truthfulness while maintaining strong social welfare approximation guarantees. But these objectives are often in conflict, making it impossible to design effective mechanisms. An important class of mechanism design problems that belong to this category are budget-feasible mechanisms. Here, the designer needs to procure services of maximum value from a set of agents while being on a budget, i.e., having a limited budget to enforce truthfulness. However, as empirical studies suggest, factors like limited information and bounded rationality question the idealized assumption that the agents behave perfectly rationally. Motivated by this, Troyan and Morill in 2022 introduced non-obvious manipulability (NOM) as a more lenient incentive compatibility notion. In this paper, we investigate whether resorting to NOM enables us to derive improved mechanisms in budget-feasible domains. We establish a tight bound of 2 on the approximation guarantee of budget-feasible mechanisms satisfying NOM for the general class of monotone subadditive valuation functions. Our result thus establishes a clear separation between the achievable guarantees for DSIC (perfectly rational agents) and NOM (imperfectly rational agents) as no truthful mechanism can achieve a guarantee better than 2.41. Along the way, we fully characterize BNOM and WNOM (which together form NOM) and derive matching upper and lower bounds, respectively. Conceptually, our characterization results suggest "Golden Tickets" and "Wooden Spoons" as natural means to realize BNOM and WNOM, respectively. Additionally, we show that randomized budget-feasible mechanisms satisfying BNOM can achieve an expected approximation ratio arbitrarily close to 1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12306v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bart de Keijzer, Guido Sch\"afer, Artem Tsikiridis, Carmine Ventre</dc:creator>
    </item>
    <item>
      <title>Mechanisms for Selling an Item Among a Strategic Bidder and a Profiled Agent</title>
      <link>https://arxiv.org/abs/2502.12313</link>
      <description>arXiv:2502.12313v1 Announce Type: new 
Abstract: We consider a scenario where a single item can be sold to one of two agents. Both agents draw their valuation for the item from the same probability distribution. However, only one of them submits a bid to the mechanism. For the other, the mechanism receives a \textit{prediction} for her valuation, which can be true or false. Our goal is to design mechanisms for selling the item which make as high revenue as possible in cases of a correct or incorrect prediction. As benchmark for proving our revenue-approximation guarantees, we use the maximum expected revenue that can be obtained by a strategic and a honest bidder. We study two mechanisms. The first one yields optimal revenue when the prediction is guaranteed to be correct and a constant revenue approximation when the prediction is incorrect, assuming that the agent valuations are drawn from a monotone hazard rate (MHR) distribution. Our second mechanism ignores the prediction for the second agent and simulates the revenue-optimal mechanism when no bid information for the bidders is available. We prove, again assuming that valuations are drawn from MHR distributions, that this mechanism achieves a constant revenue approximation guarantee compared to the revenue-optimal mechanism for a honest and a strategic bidder. The MHR assumption is necessary; we show that there are regular probability distributions for which no constant revenue approximation is possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12313v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Georgios Kalantzis</dc:creator>
    </item>
    <item>
      <title>Computing Voting Rules with Improvement Feedback</title>
      <link>https://arxiv.org/abs/2502.12542</link>
      <description>arXiv:2502.12542v1 Announce Type: new 
Abstract: Aggregating preferences under incomplete or constrained feedback is a fundamental problem in social choice and related domains. While prior work has established strong impossibility results for pairwise comparisons, this paper extends the inquiry to improvement feedback, where voters express incremental adjustments rather than complete preferences. We provide a complete characterization of the positional scoring rules that can be computed given improvement feedback. Interestingly, while plurality is learnable under improvement feedback--unlike with pairwise feedback--strong impossibility results persist for many other positional scoring rules. Furthermore, we show that improvement feedback, unlike pairwise feedback, does not suffice for the computation of any Condorcet-consistent rule. We complement our theoretical findings with experimental results, providing further insights into the practical implications of improvement feedback for preference aggregation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12542v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Evi Micha, Vasilis Varsamis</dc:creator>
    </item>
    <item>
      <title>Computing Efficient Envy-Free Partial Allocations of Indivisible Goods</title>
      <link>https://arxiv.org/abs/2502.12644</link>
      <description>arXiv:2502.12644v1 Announce Type: new 
Abstract: Envy-freeness is one of the most prominent fairness concepts in the allocation of indivisible goods. Even though trivial envy-free allocations always exist, rich literature shows this is not true when one additionally requires some efficiency concept (e.g., completeness, Pareto-efficiency, or social welfare maximization). In fact, in such case even deciding the existence of an efficient envy-free allocation is notoriously computationally hard. In this paper, we explore the limits of efficient computability by relaxing standard efficiency concepts and analyzing how this impacts the computational complexity of the respective problems. Specifically, we allow partial allocations (where not all goods are allocated) and impose only very mild efficiency constraints, such as ensuring each agent receives a bundle with positive utility. Surprisingly, even such seemingly weak efficiency requirements lead to a diverse computational complexity landscape. We identify several polynomial-time solvable or fixed-parameter tractable cases for binary utilities, yet we also find NP-hardness in very restricted scenarios involving ternary utilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12644v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Bredereck, Andrzej Kaczmarczyk, Junjie Luo, Bin Sun</dc:creator>
    </item>
    <item>
      <title>Efficient Individually Rational Recommender System under Stochastic Order</title>
      <link>https://arxiv.org/abs/2502.12766</link>
      <description>arXiv:2502.12766v1 Announce Type: new 
Abstract: With the rise of online applications, recommender systems (RSs) often encounter constraints in balancing exploration and exploitation. Such constraints arise when exploration is carried out by agents whose individual utility should be balanced with overall welfare. Recent work suggests that recommendations should be individually rational. Specifically, if agents have a default arm they would use, relying on the RS should yield each agent at least the reward of the default arm, conditioned on the knowledge available to the RS. Under this individual rationality constraint, striking a balance between exploration and exploitation becomes a complex planning problem. We assume a stochastic order of the rewards (e.g., Bernoulli, unit-variance Gaussian, etc.), and derive an approximately optimal algorithm. Our technique is based on an auxiliary Goal Markov Decision Process problem that is of independent interest. Additionally, we present an incentive-compatible version of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12766v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gal Bahar, Omer Ben-Porat, Kevin Leyton-Brown, Moshe Tennenholtz</dc:creator>
    </item>
    <item>
      <title>Envious Explore and Exploit</title>
      <link>https://arxiv.org/abs/2502.12798</link>
      <description>arXiv:2502.12798v1 Announce Type: new 
Abstract: Explore-and-exploit tradeoffs play a key role in recommendation systems (RSs), aiming at serving users better by learning from previous interactions. Despite their commercial success, the societal effects of explore-and-exploit mechanisms are not well understood, especially regarding the utility discrepancy they generate between different users. In this work, we measure such discrepancy using the economic notion of envy. We present a multi-armed bandit-like model in which every round consists of several sessions, and rewards are realized once per round. We call the latter property reward consistency, and show that the RS can leverage this property for better societal outcomes. On the downside, doing so also generates envy, as late-to-arrive users enjoy the information gathered by early-to-arrive users. We examine the generated envy under several arrival order mechanisms and virtually any anonymous algorithm, i.e., any algorithm that treats all similar users similarly without leveraging their identities. We provide tight envy bounds on uniform arrival and upper bound the envy for nudged arrival, in which the RS can affect the order of arrival by nudging its users. Furthermore, we study the efficiency-fairness trade-off by devising an algorithm that allows constant envy and approximates the optimal welfare in restricted settings. Finally, we validate our theoretical results empirically using simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12798v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omer Ben-Porat, Yotam Gafni, Or Markovetzki</dc:creator>
    </item>
    <item>
      <title>Approximately Efficient Bilateral Trade with Samples</title>
      <link>https://arxiv.org/abs/2502.13122</link>
      <description>arXiv:2502.13122v1 Announce Type: new 
Abstract: We study the social efficiency of bilateral trade between a seller and a buyer. In the classical Bayesian setting, the celebrated Myerson-Satterthwaite impossibility theorem states that no Bayesian incentive-compatible, individually rational, and budget-balanced mechanism can achieve full efficiency. As a counterpoint, Deng, Mao, Sivan, and Wang (STOC 2022) show that if pricing power is delegated to the right person (either the seller or the buyer), the resulting mechanism can guarantee at least a constant fraction of the ideal (yet unattainable) gains from trade.
  In practice, the agent with pricing power may not have perfect knowledge of the value distribution of the other party, and instead may rely on samples of that distribution to set a price. We show that for a broad class of sampling and pricing behaviors, the resulting market still guarantees a constant fraction of the ideal gains from trade in expectation. Our analysis hinges on the insight that social welfare under sample-based pricing approximates the seller's optimal revenue -- a result we establish via a reduction to a random walk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13122v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Deng, Jieming Mao, Balasubramanian Sivan, Kangning Wang, Jinzhao Wu</dc:creator>
    </item>
    <item>
      <title>An Interpretable Automated Mechanism Design Framework with Large Language Models</title>
      <link>https://arxiv.org/abs/2502.12203</link>
      <description>arXiv:2502.12203v1 Announce Type: cross 
Abstract: Mechanism design has long been a cornerstone of economic theory, with traditional approaches relying on mathematical derivations. Recently, automated approaches, including differentiable economics with neural networks, have emerged for designing payments and allocations. While both analytical and automated methods have advanced the field, they each face significant weaknesses: mathematical derivations are not automated and often struggle to scale to complex problems, while automated and especially neural-network-based approaches suffer from limited interpretability. To address these challenges, we introduce a novel framework that reformulates mechanism design as a code generation task. Using large language models (LLMs), we generate heuristic mechanisms described in code and evolve them to optimize over some evaluation metrics while ensuring key design criteria (e.g., strategy-proofness) through a problem-specific fixing process. This fixing process ensures any mechanism violating the design criteria is adjusted to satisfy them, albeit with some trade-offs in performance metrics. These trade-offs are factored in during the LLM-based evolution process. The code generation capabilities of LLMs enable the discovery of novel and interpretable solutions, bridging the symbolic logic of mechanism design and the generative power of modern AI. Through rigorous experimentation, we demonstrate that LLM-generated mechanisms achieve competitive performance while offering greater interpretability compared to previous approaches. Notably, our framework can rediscover existing manually designed mechanisms and provide insights into neural-network based solutions through Programming-by-Example. These results highlight the potential of LLMs to not only automate but also enhance the transparency and scalability of mechanism design, ensuring safe deployment of the mechanisms in society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12203v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.NE</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayuan Liu, Mingyu Guo, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Multi-dimensional Test Design</title>
      <link>https://arxiv.org/abs/2502.12264</link>
      <description>arXiv:2502.12264v1 Announce Type: cross 
Abstract: How should one jointly design tests and the arrangement of agencies to administer these tests (testing procedure)? To answer this question, we analyze a model where a principal must use multiple tests to screen an agent with a multi-dimensional type, knowing that the agent can change his type at a cost. We identify a new tradeoff between setting difficult tests and using a difficult testing procedure. We compare two settings: (1) the agent only misrepresents his type (manipulation) and (2) the agent improves his actual type (investment). Examples include interviews, regulations, and data classification. We show that in the manipulation setting, stringent tests combined with an easy procedure, i.e., offering tests sequentially in a fixed order, is optimal. In contrast, in the investment setting, non-stringent tests with a difficult procedure, i.e., offering tests simultaneously, is optimal; however, under mild conditions offering them sequentially in a random order may be as good. Our results suggest that whether the agent manipulates or invests in his type determines which arrangement of agencies is optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12264v1</guid>
      <category>econ.TH</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyun Qiu, Liren Shan</dc:creator>
    </item>
    <item>
      <title>Sample Efficient Omniprediction and Downstream Swap Regret for Non-Linear Losses</title>
      <link>https://arxiv.org/abs/2502.12564</link>
      <description>arXiv:2502.12564v1 Announce Type: cross 
Abstract: We define "decision swap regret" which generalizes both prediction for downstream swap regret and omniprediction, and give algorithms for obtaining it for arbitrary multi-dimensional Lipschitz loss functions in online adversarial settings. We also give sample complexity bounds in the batch setting via an online-to-batch reduction. When applied to omniprediction, our algorithm gives the first polynomial sample-complexity bounds for Lipschitz loss functions -- prior bounds either applied only to linear loss (or binary outcomes) or scaled exponentially with the error parameter even under the assumption that the loss functions were convex. When applied to prediction for downstream regret, we give the first algorithm capable of guaranteeing swap regret bounds for all downstream agents with non-linear loss functions over a multi-dimensional outcome space: prior work applied only to linear loss functions, modeling risk neutral agents. Our general bounds scale exponentially with the dimension of the outcome space, but we give improved regret and sample complexity bounds for specific families of multidimensional functions of economic interest: constant elasticity of substitution (CES), Cobb-Douglas, and Leontief utility functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12564v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiuyao Lu, Aaron Roth, Mirah Shi</dc:creator>
    </item>
    <item>
      <title>Maximizing Value in Challenge the Champ Tournaments</title>
      <link>https://arxiv.org/abs/2502.12569</link>
      <description>arXiv:2502.12569v1 Announce Type: cross 
Abstract: A tournament is a method to decide the winner in a competition, and describes the overall sequence in which matches between the players are held. While deciding a worthy winner is the primary goal of a tournament, a close second is to maximize the value generated for the matches played, with value for a match measured either in terms of tickets sold, television viewership, advertising revenue, or other means. Tournament organizers often seed the players -- i.e., decide which matches are played -- to increase this value.
  We study the value maximization objective in a particular tournament format called Challenge the Champ. This is a simple tournament format where an ordering of the players is decided. The first player in this order is the initial champion. The remaining players in order challenge the current champion; if a challenger wins, she replaces the current champion. We model the outcome of a match between two players using a complete directed graph, called a strength graph, with each player represented as a vertex, and the direction of an edge indicating the winner in a match. The value-maximization objective has been recently explored for knockout tournaments when the strength graph is a directed acyclic graph (DAG).
  We extend the investigation to Challenge the Champ tournaments and general strength graphs. We study different representations of the value of each match, and completely characterize the computational complexity of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12569v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umang Bhaskar, Juhi Chaudhary, Palash Dey</dc:creator>
    </item>
    <item>
      <title>AI-Assisted Decision Making with Human Learning</title>
      <link>https://arxiv.org/abs/2502.13062</link>
      <description>arXiv:2502.13062v1 Announce Type: cross 
Abstract: AI systems increasingly support human decision-making. In many cases, despite the algorithm's superior performance, the final decision remains in human hands. For example, an AI may assist doctors in determining which diagnostic tests to run, but the doctor ultimately makes the diagnosis. This paper studies such AI-assisted decision-making settings, where the human learns through repeated interactions with the algorithm. In our framework, the algorithm -- designed to maximize decision accuracy according to its own model -- determines which features the human can consider. The human then makes a prediction based on their own less accurate model. We observe that the discrepancy between the algorithm's model and the human's model creates a fundamental tradeoff. Should the algorithm prioritize recommending more informative features, encouraging the human to recognize their importance, even if it results in less accurate predictions in the short term until learning occurs? Or is it preferable to forgo educating the human and instead select features that align more closely with their existing understanding, minimizing the immediate cost of learning? This tradeoff is shaped by the algorithm's time-discounted objective and the human's learning ability. Our results show that optimal feature selection has a surprisingly clean combinatorial characterization, reducible to a stationary sequence of feature subsets that is tractable to compute. As the algorithm becomes more "patient" or the human's learning improves, the algorithm increasingly selects more informative features, enhancing both prediction accuracy and the human's understanding. Notably, early investment in learning leads to the selection of more informative features than a later investment. We complement our analysis by showing that the impact of errors in the algorithm's knowledge is limited as it does not make the prediction directly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13062v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gali Noti, Kate Donahue, Jon Kleinberg, Sigal Oren</dc:creator>
    </item>
    <item>
      <title>Self-Resolving Prediction Markets for Unverifiable Outcomes</title>
      <link>https://arxiv.org/abs/2306.04305</link>
      <description>arXiv:2306.04305v2 Announce Type: replace 
Abstract: Prediction markets elicit and aggregate beliefs by paying agents based on how close their predictions are to a verifiable future outcome. However, outcomes of many important questions are difficult to verify or unverifiable, in that the ground truth may be hard or impossible to access. We present a novel incentive-compatible prediction market mechanism to elicit and efficiently aggregate information from a pool of agents without observing the outcome, by paying agents the negative cross-entropy between their prediction and that of a carefully chosen reference agent. Our key insight is that a reference agent with access to more information can serve as a reasonable proxy for the ground truth. We use this insight to propose self-resolving prediction markets that terminate with some probability after every report and pay all but a few agents based on the final prediction. The final agent is chosen as the reference agent since they observe the full history of market forecasts, and thus have more information by design. We show that it is a perfect Bayesian equilibrium (PBE) for all agents to report truthfully in our mechanism and to believe that all other agents report truthfully. Although primarily of interest for unverifiable outcomes, this design is also applicable for verifiable outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04305v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddarth Srinivasan, Ezra Karger, Yiling Chen</dc:creator>
    </item>
    <item>
      <title>Computing Perfect Bayesian Equilibria in Sequential Auctions with Verification</title>
      <link>https://arxiv.org/abs/2312.04516</link>
      <description>arXiv:2312.04516v2 Announce Type: replace 
Abstract: We present an algorithm for computing pure-strategy epsilon-perfect Bayesian equilibria in sequential auctions with continuous action and value spaces. Importantly, our algorithm includes a verification phase that computes an upper bound on the utility loss of the found strategies. Prior work on equilibrium computation in auctions with verification has focussed on the single-round case, but the methods do not work for sequential auctions because of two main challenges: (1) there are infinitely many subgames, and (2) the setting has no optimal substructure as bidders' beliefs and best response strategies depend on the strategies of previous rounds. We make two contributions. First, we introduce a tailor-made game abstraction that discretizes the auction and augments the state space with the public beliefs, such that an approximate equilibrium can be computed via dynamic programming. Second, we prove a decomposition theorem to upper bound the utility loss of the computed equilibrium. This is essential because it is neither guaranteed that the auction has an equilibrium nor that any algorithm converges to it. We validate our algorithm on multiple settings with known equilibria and apply it to a new multi-round combinatorial auction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04516v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinzenz Thoma, Vitor Bosshard, Sven Seuken</dc:creator>
    </item>
    <item>
      <title>Evaluation of Project Performance in Participatory Budgeting</title>
      <link>https://arxiv.org/abs/2312.14723</link>
      <description>arXiv:2312.14723v2 Announce Type: replace 
Abstract: We study ways of evaluating the performance of losing projects in participatory budgeting (PB) elections by seeking actions that would have led to their victory. We focus on lowering the projects' costs, obtaining additional approvals for them, and asking supporters to refrain from approving other projects: The larger a change is needed, the less successful is the given project. We seek efficient algorithms for computing our measures and we analyze and compare them experimentally. We focus on the greedyAV, Phragm\'en, and Equal-Shares PB rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14723v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niclas Boehmer, Piotr Faliszewski, {\L}ukasz Janeczko, Dominik Peters, Grzegorz Pierczy\'nski, \v{S}imon Schierreich, Piotr Skowron, Stanis{\l}aw Szufa</dc:creator>
    </item>
    <item>
      <title>Weighted Envy Freeness With Bounded Subsidies</title>
      <link>https://arxiv.org/abs/2411.12696</link>
      <description>arXiv:2411.12696v3 Announce Type: replace 
Abstract: We explore solutions for fairly allocating indivisible items among agents assigned weights representing their entitlements. Our fairness goal is weighted-envy-freeness (WEF), where each agent deems their allocated portion relative to their entitlement at least as favorable as any other's relative to their own. In many cases, achieving WEF necessitates monetary transfers, which can be modeled as third-party subsidies. The goal is to attain WEF with bounded subsidies.
  Previous work in the unweighted setting of subsidies relied on basic characterizations of EF that fail in the weighted settings. This makes our new setting challenging and theoretically intriguing. We present polynomial-time algorithms that compute WEF-able allocations with an upper bound on the subsidy per agent in three distinct additive valuation scenarios: (1) general, (2) identical, and (3) binary. When all weights are equal, our bounds reduce to the bounds derived in the literature for the unweighted setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12696v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noga Klein Elmalem, Rica Gonen, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>The Degree of (Extended) Justified Representation and Its Optimization</title>
      <link>https://arxiv.org/abs/2412.19933</link>
      <description>arXiv:2412.19933v2 Announce Type: replace 
Abstract: Justified Representation (JR)/Extended Justified Representation (EJR) is a desirable axiom in multiwinner approval voting. In contrast to that (E)JR only requires at least \emph{one} voter to be represented in every cohesive group, we study its optimization version that maximizes the \emph{number} of represented voters in each group. Given an instance, we say a winning committee provides a JR degree (EJR degree, resp.) of $c$ if at least $c$ voters in each $\ell$-cohesive group ($1$-cohesive group, resp.) have approved $\ell$ ($1$, resp.) winning candidates. Hence, every (E)JR committee provides the (E)JR degree of at least $1$. Besides proposing this new property, we propose the optimization problem of finding a winning committee that achieves the maximum possible (E)JR degree, called \MDJR and \MDEJR, corresponding to JR and EJR respectively.
  We study the computational complexity and approximability of \MDJR of \MDEJR. An (E)JR committee, which can be found in polynomial time, straightforwardly gives a $(k/n)$-approximation. We also show that the original algorithms for finding a JR and an EJR winner committee are also $1/k$ and $1/(k+1)$ approximation algorithms for \MDJR and \MDEJR respectively. On the other hand, we show that it is NP-hard to approximate \MDJR and \MDEJR to within a factor of $\left(k/n\right)^{1-\epsilon}$ and to within a factor of $(1/k)^{1-\varepsilon}$, for any $\epsilon&gt;0$, which complements the positive results. Next, we study the fixed-parameter-tractability of this problem. We show that both problems are W[2]-hard if $k$, the size of the winning committee, is specified as the parameter. However, when $c_{\text{max}}$, the maximum value of $c$ such that a committee that provides an (E)JR degree of $c$ exists, is additionally given as a parameter, we show that both \MDJR and \MDEJR are fixed-parameter-tractable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19933v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biaoshuai Tao, Chengkai Zhang, Houyu Zhou</dc:creator>
    </item>
    <item>
      <title>A new lower bound for multi-color discrepancy with applications to fair division</title>
      <link>https://arxiv.org/abs/2502.10516</link>
      <description>arXiv:2502.10516v2 Announce Type: replace 
Abstract: A classical problem in combinatorics seeks colorings of low discrepancy. More concretely, the goal is to color the elements of a set system so that the number of appearances of any color among the elements in each set is as balanced as possible. We present a new lower bound for multi-color discrepancy, showing that there is a set system with $n$ subsets over a set of elements in which any $k$-coloring of the elements has discrepancy at least $\Omega\left(\sqrt{\frac{n}{\ln{k}}}\right)$. This result improves the previously best-known lower bound of $\Omega\left(\sqrt{\frac{n}{k}}\right)$ of Doerr and Srivastav [2003] and may have several applications. Here, we explore its implications on the feasibility of fair division concepts for instances with $n$ agents having valuations for a set of indivisible items. The first such concept is known as consensus $1/k$-division up to $d$ items (\cd$d$) and aims to allocate the items into $k$ bundles so that no matter which bundle each agent is assigned to, the allocation is envy-free up to $d$ items. The above lower bound implies that \cd$d$ can be infeasible for $d\in \Omega\left(\sqrt{\frac{n}{\ln{k}}}\right)$. We furthermore extend our proof technique to show that there exist instances of the problem of allocating indivisible items to $k$ groups of $n$ agents in total so that envy-freeness and proportionality up to $d$ items are infeasible for $d\in \Omega\left(\sqrt{\frac{n}{k\ln{k}}}\right)$ and $d\in \Omega\left(\sqrt{\frac{n}{k^3\ln{k}}}\right)$, respectively. The lower bounds for fair division improve the currently best-known ones by Manurangsi and Suksompong [2022].</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10516v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Kasper Green Larsen, Sudarshan Shyam</dc:creator>
    </item>
    <item>
      <title>Tractable General Equilibrium</title>
      <link>https://arxiv.org/abs/2502.11449</link>
      <description>arXiv:2502.11449v2 Announce Type: replace 
Abstract: We study Walrasian economies (or general equilibrium models) and their solution concept, the Walrasian equilibrium. A key challenge in this domain is identifying price-adjustment processes that converge to equilibrium. One such process, t\^atonnement, is an auction-like algorithm first proposed in 1874 by L\'eon Walras. While continuous-time variants of t\^atonnement are known to converge to equilibrium in economies satisfying the Weak Axiom of Revealed Preferences (WARP), the process fails to converge in a pathological Walrasian economy known as the Scarf economy. To address these issues, we analyze Walrasian economies using variational inequalities (VIs), an optimization framework. We introduce the class of mirror extragradient algorithms, which, under suitable Lipschitz-continuity-like assumptions, converge to a solution of any VI satisfying the Minty condition in polynomial time. We show that the set of Walrasian equilibria of any balanced economy-which includes among others Arrow-Debreu economies-corresponds to the solution set of an associated VI that satisfies the Minty condition but is generally discontinuous. Applying the mirror extragradient algorithm to this VI we obtain a class of t\^atonnement-like processes, which we call the mirror extrat\^atonnement process. While our VI formulation is generally discontinuous, it is Lipschitz-continuous in variationally stable Walrasian economies with bounded elasticity-including those satisfying WARP and the Scarf economy-thus establishing the polynomial-time convergence of mirror extrat\^atonnement in these economies. We validate our approach through experiments on large Arrow-Debreu economies with Cobb-Douglas, Leontief, and CES consumers, as well as the Scarf economy, demonstrating fast convergence in all cases without failure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11449v2</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <category>econ.TH</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denizalp Goktas, Amy Greenwald</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Fisher Market Equilibrium</title>
      <link>https://arxiv.org/abs/2209.15422</link>
      <description>arXiv:2209.15422v3 Announce Type: replace-cross 
Abstract: Statistical inference under market equilibrium effects has attracted increasing attention recently. In this paper we focus on the specific case of linear Fisher markets. They have been widely use in fair resource allocation of food/blood donations and budget management in large-scale Internet ad auctions. In resource allocation, it is crucial to quantify the variability of the resource received by the agents (such as blood banks and food banks) in addition to fairness and efficiency properties of the systems. For ad auction markets, it is important to establish statistical properties of the platform's revenues in addition to their expected values. To this end, we propose a statistical framework based on the concept of infinite-dimensional Fisher markets. In our framework, we observe a market formed by a finite number of items sampled from an underlying distribution (the "observed market") and aim to infer several important equilibrium quantities of the underlying long-run market. These equilibrium quantities include individual utilities, social welfare, and pacing multipliers. Through the lens of sample average approximation (SSA), we derive a collection of statistical results and show that the observed market provides useful statistical information of the long-run market. In other words, the equilibrium quantities of the observed market converge to the true ones of the long-run market with strong statistical guarantees. These include consistency, finite sample bounds, asymptotics, and confidence. As an extension, we discuss revenue inference in quasilinear Fisher markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.15422v3</guid>
      <category>econ.EM</category>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luofeng Liao, Yuan Gao, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Incentivizing Information Acquisition</title>
      <link>https://arxiv.org/abs/2410.13978</link>
      <description>arXiv:2410.13978v3 Announce Type: replace-cross 
Abstract: I study a principal-agent model in which a principal hires an agent to collect information about an unknown continuous state. The agent acquires a signal whose distribution is centered around the state, controlling the signal's precision at a cost. The principal observes neither the precision nor the signal, but rather, using transfers that can depend on the state, incentivizes the agent to choose high precision and report the signal truthfully. I identify a sufficient and necessary condition on the agent's information structure which ensures that there exists an optimal transfer with a simple cutoff structure: the agent receives a fixed prize when his prediction is close enough to the state and receives nothing otherwise. This condition is mild and applies to all signal distributions commonly used in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13978v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu</dc:creator>
    </item>
  </channel>
</rss>
