<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Sep 2024 04:01:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Incentive-Compatible Navigational Route Recommendations in Urban Transportation Networks</title>
      <link>https://arxiv.org/abs/2409.00236</link>
      <description>arXiv:2409.00236v1 Announce Type: new 
Abstract: In urban transportation environments, drivers often encounter various path (route) options when navigating to their destinations. This emphasizes the importance of navigational recommendation systems (NRS), which simplify decision-making and reduce travel time for users while alleviating potential congestion for broader societal benefits. However, recommending the shortest path may cause the flash crowd effect, and system-optimal routes may not always align the preferences of human users, leading to non-compliance issues. It is also worth noting that universal NRS adoption is impractical. Therefore, in this study, we aim to address these challenges by proposing an incentive compatibility recommendation system from a game-theoretic perspective and accounts for non-user drivers with their own path choice behaviors. Additionally, recognizing the dynamic nature of traffic conditions and the unpredictability of accidents, this work introduces a dynamic NRS with parallel and random update schemes, enabling users to safely adapt to changing traffic conditions while ensuring optimal total travel time costs. The numerical studies indicate that the proposed parallel update scheme exhibits greater effectiveness in terms of user compliance, travel time reduction, and adaptability to the environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00236v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-Ting Yang, Haozhe Lei, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>PRADA: Proactive Risk Assessment and Mitigation of Misinformed Demand Attacks on Navigational Route Recommendations</title>
      <link>https://arxiv.org/abs/2409.00243</link>
      <description>arXiv:2409.00243v1 Announce Type: new 
Abstract: Leveraging recent advances in wireless communication, IoT, and AI, intelligent transportation systems (ITS) played an important role in reducing traffic congestion and enhancing user experience. Within ITS, navigational recommendation systems (NRS) are essential for helping users simplify route choices in urban environments. However, NRS are vulnerable to information-based attacks that can manipulate both the NRS and users to achieve the objectives of the malicious entities. This study aims to assess the risks of misinformed demand attacks, where attackers use techniques like Sybil-based attacks to manipulate the demands of certain origins and destinations considered by the NRS. We propose a game-theoretic framework for proactive risk assessment of demand attacks (PRADA) and treat the interaction between attackers and the NRS as a Stackelberg game. The attacker is the leader who conveys misinformed demands, while the NRS is the follower responding to the provided information. Specifically, we consider the case of local-targeted attacks, in which the attacker aims to make the NRS recommend the authentic users towards a specific road that favors certain groups. Our analysis unveils the equivalence between users' incentive compatibility and Wardrop equilibrium recommendations and shows that the NRS and its users are at high risk when encountering intelligent attackers who can significantly alter user routes by strategically fabricating non-existent demands. To mitigate these risks, we introduce a trust mechanism that leverages users' confidence in the integrity of the NRS, and show that it can effectively reduce the impact of misinformed demand attacks. Numerical experiments are used to corroborate the results and demonstrate a Resilience Paradox, where locally targeted attacks can sometimes benefit the overall traffic conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00243v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-Ting Yang, Haozhe Lei, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Skill Dominance Analysis of Two(Four) player, Four(Five) dice Variant of the Ludo Game</title>
      <link>https://arxiv.org/abs/2409.00376</link>
      <description>arXiv:2409.00376v1 Announce Type: new 
Abstract: This paper examines two different variants of the Ludo game, involving multiple dice and a fixed number of total turns. Within each variant, multiple game lengths (total no. of turns) are considered. To compare the two variants, a set of intuitive, rule-based strategies is designed, representing different broad methods of strategic play. Game play is simulated between bots (automated software applications executing repetitive tasks over a network) following these strategies. The expected results are computed using certain game theoretic and probabilistic explanations, helping to understand the performance of the different strategies. The different strategies are further analyzed using win percentage in a large number of simulations, and Nash Equilibrium strategies are computed for both variants for a varying number of total turns. The Nash Equilibrium strategies across different game lengths are compared. A clear distinction between performances of strategies is observed, with more sophisticated strategies beating the naive one. A gradual shift in optimal strategy profiles is observed with changing game length, and certain sophisticated strategies even confound each other's performance while playing against each other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00376v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tathagata Banerjee, Diganta Mukherjee</dc:creator>
    </item>
    <item>
      <title>Personalized Pricing Decisions Through Adversarial Risk Analysis</title>
      <link>https://arxiv.org/abs/2409.00444</link>
      <description>arXiv:2409.00444v1 Announce Type: new 
Abstract: Pricing decisions stand out as one of the most critical tasks a company faces, particularly in today's digital economy. As with other business decision-making problems, pricing unfolds in a highly competitive and uncertain environment. Traditional analyses in this area have heavily relied on game theory and its variants. However, an important drawback of these approaches is their reliance on common knowledge assumptions, which are hardly tenable in competitive business domains. This paper introduces an innovative personalized pricing framework designed to assist decision-makers in undertaking pricing decisions amidst competition, considering both buyer's and competitors' preferences. Our approach (i) establishes a coherent framework for modeling competition mitigating common knowledge assumptions; (ii) proposes a principled method to forecast competitors' pricing and customers' purchasing decisions, acknowledging major business uncertainties; and, (iii) encourages structured thinking about the competitors' problems, thus enriching the solution process. To illustrate these properties, in addition to a general pricing template, we outline two specifications - one from the retail domain and a more intricate one from the pension fund domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00444v1</guid>
      <category>cs.GT</category>
      <category>stat.AP</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Garc\'ia Rasines, Roi Naveiro, David R\'ios Insua, Sim\'on Rodr\'iguez Santana</dc:creator>
    </item>
    <item>
      <title>Prophet Inequality from Samples: Is the More the Merrier?</title>
      <link>https://arxiv.org/abs/2409.00559</link>
      <description>arXiv:2409.00559v1 Announce Type: new 
Abstract: We study a variant of the single-choice prophet inequality problem where the decision-maker does not know the underlying distribution and has only access to a set of samples from the distributions. Rubinstein et al. [2020] showed that the optimal competitive-ratio of $\frac{1}{2}$ can surprisingly be obtained by observing a set of $n$ samples, one from each of the distributions. In this paper, we prove that this competitive-ratio of $\frac{1}{2}$ becomes unattainable when the decision-maker is provided with a set of more samples. We then examine the natural class of ordinal static threshold algorithms, where the algorithm selects the $i$-th highest ranked sample, sets this sample as a static threshold, and then chooses the first value that exceeds this threshold. We show that the best possible algorithm within this class achieves a competitive-ratio of $0.433$. Along the way, we utilize the tools developed in the paper and provide an alternative proof of the main result of Rubinstein et al. [2020].</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00559v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomer Ezra</dc:creator>
    </item>
    <item>
      <title>The NTU Partitioned Matching Game for International Kidney Exchange Programs</title>
      <link>https://arxiv.org/abs/2409.01452</link>
      <description>arXiv:2409.01452v1 Announce Type: new 
Abstract: Motivated by the real-world problem of international kidney exchange (IKEP), [Bir\'o et al., Generalized Matching Games for International Kidney Exchange, 2019] introduced a generalized transferable utility matching game featuring a partition of the vertex set of a graph into players, and analyzed its complexity. We explore the non-transferable utility (NTU) variant of the game, where the utility of players is given by the number of their matched vertices. The NTU version is arguably a more natural model of the international kidney exchange program, as the utility of a participating country mostly depends on how many of its patients receive a kidney, which is non-transferable by nature. We study the core of this game, which suitably captures the notion of stability of an IKEP, as it precludes incentives to deviate from the proposed solution for any possible coalition of the players.
  We prove computational complexity results about the weak and strong cores under various assumptions on the players. In particular, we show that if every player has two vertices, which can be considered as an NTU matching game with couples, then the weak core is always non-empty, and the existence of a strong core solution can be decided in polynomial time. In contrast, it is NP-hard to decide whether the strong core is empty when each player has three vertices. We also show that if the number of players is constant, then the non-emptiness of the weak and strong cores is polynomial-time decidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01452v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gergely Cs\'aji, Tam\'as Kir\'aly, Zsuzsa M\'esz\'aros-Karkus</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap Between Central and Local Decision-Making: The Efficacy of Collaborative Equilibria in Altruistic Congestion Games</title>
      <link>https://arxiv.org/abs/2409.01525</link>
      <description>arXiv:2409.01525v1 Announce Type: new 
Abstract: Congestion games are popular models often used to study the system-level inefficiencies caused by selfish agents, typically measured by the price of anarchy. One may expect that aligning the agents' preferences with the system-level objective--altruistic behavior--would improve efficiency, but recent works have shown that altruism can lead to more significant inefficiency than selfishness in congestion games. In this work, we study to what extent the localness of decision-making causes inefficiency by considering collaborative decision-making paradigms that exist between centralized and distributed in altruistic congestion games. In altruistic congestion games with convex latency functions, the system cost is a super-modular function over the player's joint actions, and the Nash equilibria of the game are local optima in the neighborhood of unilateral deviations. When agents can collaborate, we can exploit the common-interest structure to consider equilibria with stronger local optimality guarantees in the system objective, e.g., if groups of k agents can collaboratively minimize the system cost, the system equilibria are the local optima over k-lateral deviations. Our main contributions are in constructing tractable linear programs that provide bounds on the price of anarchy of collaborative equilibria in altruistic congestion games. Our findings bridge the gap between the known efficiency guarantees of centralized and distributed decision-making paradigms while also providing insights into the benefit of inter-agent collaboration in multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01525v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bryce L Ferguson, Dario Paccagnan, Bary S R Pradelski, Jason R Marden</dc:creator>
    </item>
    <item>
      <title>Achieving Maximin Share and EFX/EF1 Guarantees Simultaneously</title>
      <link>https://arxiv.org/abs/2409.01963</link>
      <description>arXiv:2409.01963v1 Announce Type: new 
Abstract: We study the problem of computing \emph{fair} divisions of a set of indivisible goods among agents with \emph{additive} valuations. For the past many decades, the literature has explored various notions of fairness, that can be primarily seen as either having \emph{envy-based} or \emph{share-based} lens. For the discrete setting of resource-allocation problems, \emph{envy-free up to any good} (EFX) and \emph{maximin share} (MMS) are widely considered as the flag-bearers of fairness notions in the above two categories, thereby capturing different aspects of fairness herein. Due to lack of existence results of these notions and the fact that a good approximation of EFX or MMS does not imply particularly strong guarantees of the other, it becomes important to understand the compatibility of EFX and MMS allocations with one another.
  In this work, we identify a novel way to simultaneously achieve MMS guarantees with EFX/EF1 notions of fairness, while beating the best known approximation factors [Chaudhury et al., 2021, Amanatidis et al., 2020]. Our main contribution is to constructively prove the existence of (i) a partial allocation that is both $2/3$-MMS and EFX, and (ii) a complete allocation that is both $2/3$-MMS and EF1. Our algorithms run in pseudo-polynomial time if the approximation factor for MMS is relaxed to $2/3-\varepsilon$ for any constant $\varepsilon &gt; 0$ and in polynomial time if, in addition, the EFX (or EF1) guarantee is relaxed to $(1-\delta)$-EFX (or $(1-\delta)$-EF1) for any constant $\delta&gt;0$. In particular, we improve from the best approximation factor known prior to our work, which computes partial allocations that are $1/2$-MMS and EFX in pseudo-polynomial time [Chaudhury et al., 2021].</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01963v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Reinforcement Learning from Human Feedback: Data Coverage and Algorithmic Techniques</title>
      <link>https://arxiv.org/abs/2409.00717</link>
      <description>arXiv:2409.00717v1 Announce Type: cross 
Abstract: We initiate the study of Multi-Agent Reinforcement Learning from Human Feedback (MARLHF), exploring both theoretical foundations and empirical validations. We define the task as identifying Nash equilibrium from a preference-only offline dataset in general-sum games, a problem marked by the challenge of sparse feedback signals. Our theory establishes the upper complexity bounds for Nash Equilibrium in effective MARLHF, demonstrating that single-policy coverage is inadequate and highlighting the importance of unilateral dataset coverage. These theoretical insights are verified through comprehensive experiments. To enhance the practical performance, we further introduce two algorithmic techniques. (1) We propose a Mean Squared Error (MSE) regularization along the time axis to achieve a more uniform reward distribution and improve reward learning outcomes. (2) We utilize imitation learning to approximate the reference policy, ensuring stability and effectiveness in training. Our findings underscore the multifaceted approach required for MARLHF, paving the way for effective preference-based multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00717v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalia Zhang, Xinqi Wang, Qiwen Cui, Runlong Zhou, Sham M. Kakade, Simon S. Du</dc:creator>
    </item>
    <item>
      <title>Satisficing Equilibrium</title>
      <link>https://arxiv.org/abs/2409.00832</link>
      <description>arXiv:2409.00832v1 Announce Type: cross 
Abstract: In a $\textit{satisficing equilibrium}$ each agent plays one of their $k$ best pure actions, but not necessarily their best action. We show that satisficing equilibria in which agents play only their best or second-best action exist in almost all games. In fact, in almost all games, there exist satisficing equilibria in which all but one agent best-respond and the remaining agent plays at least a second-best action. By contrast, more than one third of games possess no pure Nash equilibrium. In addition to providing static foundations for satisficing equilibria, we show that a parsimonious dynamic converges to satisficing equilibria in almost all games. We apply our results to market design and show that a mediator who can control a single agent can enforce stability in most games. Finally, we use our results to study the existence of $\epsilon$-equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00832v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bary S. R. Pradelski, Bassel Tarbush</dc:creator>
    </item>
    <item>
      <title>Decidability of One-Clock Weighted Timed Games with Arbitrary Weights</title>
      <link>https://arxiv.org/abs/2207.01608</link>
      <description>arXiv:2207.01608v3 Announce Type: replace 
Abstract: Weighted Timed Games (WTG for short) are the most widely used model to describe controller synthesis problems involving real-time issues. Unfortunately, they are notoriously difficult, and undecidable in general. As a consequence, one-clock WTGs have attracted a lot of attention, especially because they are known to be decidable when only non-negative weights are allowed. However, when arbitrary weights are considered, despite several recent works, their decidability status was still unknown. In this paper, we solve this problem positively and show that the value function can be computed in exponential time (if weights are encoded in unary).</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.01608v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Benjamin Monmege, Julie Parreaux, Pierre-Alain Reynier</dc:creator>
    </item>
    <item>
      <title>Credible, Optimal Auctions via Public Broadcast</title>
      <link>https://arxiv.org/abs/2301.12532</link>
      <description>arXiv:2301.12532v2 Announce Type: replace 
Abstract: We study auction design in a setting where agents can communicate over a censorship-resistant broadcast channel like the ones we can implement over a public blockchain. We seek to design credible, strategyproof auctions in a model that differs from the traditional mechanism design framework because communication is not centralized via the auctioneer. We prove this allows us to design a larger class of credible auctions where the auctioneer has no incentive to be strategic. Intuitively, a decentralized communication model weakens the auctioneer's adversarial capabilities because they can only inject messages into the communication channel but not delete, delay, or modify the messages from legitimate buyers. Our main result is a separation in the following sense: we give the first instance of an auction that is credible only if communication is decentralized. Moreover, we construct the first two-round auction that is credible, strategyproof, and optimal when bidder valuations are $\alpha$-strongly regular, for $\alpha &gt; 0$. Our result relies on mild assumptions -- namely, the existence of a broadcast channel and cryptographic commitments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12532v2</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>AFT 2024</arxiv:journal_reference>
      <dc:creator>Tarun Chitra, Matheus V. X. Ferreira, Kshitij Kulkarni</dc:creator>
    </item>
    <item>
      <title>A Reduction from Chores Allocation to Job Scheduling</title>
      <link>https://arxiv.org/abs/2302.04581</link>
      <description>arXiv:2302.04581v4 Announce Type: replace 
Abstract: We consider allocating indivisible chores among agents with different cost functions, such that all agents receive a cost of at most a constant factor times their maximin share. The state-of-the-art was presented in In EC 2021 by Huang and Lu. They presented a non-polynomial-time algorithm, called HFFD, that attains an 11/9 approximation, and a polynomial-time algorithm that attains a 5/4 approximation.
  In this paper, we show that HFFD can be reduced to an algorithm called MultiFit, developed by Coffman, Garey and Johnson in 1978 for makespan minimization in job scheduling. Using this reduction, we prove that the approximation ratio of HFFD is in fact equal to that of MultiFit, which is known to be 13/11 in general, 20/17 for n at most 7, and 15/13 for n=3.
  Moreover, we develop an algorithm for (13/11+epsilon)-maximin-share allocation for any epsilon&gt;0, with run-time polynomial in the problem size and 1/epsilon. For n=3, we can improve the algorithm to find a 15/13-maximin-share allocation with run-time polynomial in the problem size. Thus, we have practical algorithms that attain the best known approximation to maximin-share chore allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04581v4</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Huang, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Existence of MMS Allocations with Mixed Manna</title>
      <link>https://arxiv.org/abs/2401.07490</link>
      <description>arXiv:2401.07490v3 Announce Type: replace 
Abstract: Maximin share (MMS) allocations are a popular relaxation of envy-free allocations that have received wide attention in the fair division of indivisible items. Although MMS allocations of goods can fail to exist, previous work has found conditions under which they exist. Specifically, MMS allocations of goods exist whenever $m \leq n+5$, and this bound is tight in the sense that they can fail to exist when $m = n+6$. The techniques used to obtain these results do not apply to the mixed manna setting, leaving the question of whether similar results hold for the general setting. This paper addresses this by introducing new techniques to handle these settings. In particular, we are able to answer this question completely for the chores setting, and partially for the mixed manna setting. An agent $i$ is a {\em chores agent} if it considers every item to be a chore and a {\em non-negative agent} if its MMS guarantee is non-negative. In this paper, we prove that an MMS allocation exists as long as $m \leq n+5$ and either (i) every agent is a chores agent, or (ii) there exists a non-negative agent. In addition, for $n \leq 3$, we also prove that an MMS allocation exists as long as $m \leq n+5$, regardless of the types of agents. To the best of our knowledge, these are the first non-trivial results pertaining to the existence of exact MMS allocations in the mixed manna setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07490v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Hsu</dc:creator>
    </item>
    <item>
      <title>Adaptive Incentive Design with Learning Agents</title>
      <link>https://arxiv.org/abs/2405.16716</link>
      <description>arXiv:2405.16716v2 Announce Type: replace 
Abstract: How can the system operator learn an incentive mechanism that achieves social optimality based on limited information about the agents' behavior, who are dynamically updating their strategies? To answer this question, we propose an \emph{adaptive} incentive mechanism. This mechanism updates the incentives of agents based on the feedback of each agent's externality, evaluated as the difference between the player's marginal cost and society's marginal cost at each time step. The proposed mechanism updates the incentives on a slower timescale compared to the agents' learning dynamics, resulting in a two-timescale coupled dynamical system. Notably, this mechanism is agnostic to the specific learning dynamics used by agents to update their strategies. We show that any fixed point of this adaptive incentive mechanism corresponds to the optimal incentive mechanism, ensuring that the Nash equilibrium coincides with the socially optimal strategy. Additionally, we provide sufficient conditions that guarantee the convergence of the adaptive incentive mechanism to a fixed point. Our results apply to both atomic and non-atomic games. To demonstrate the effectiveness of our proposed mechanism, we verify the convergence conditions in two practically relevant games: atomic networked quadratic aggregative games and non-atomic network routing games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16716v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chinmay Maheshwari, Kshitij Kulkarni, Manxi Wu, Shankar Sastry</dc:creator>
    </item>
    <item>
      <title>A General Framework for Optimizing and Learning Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2408.16260</link>
      <description>arXiv:2408.16260v2 Announce Type: replace 
Abstract: One key in real-life Nash equilibrium applications is to calibrate players' cost functions. To leverage the approximation ability of neural networks, we proposed a general framework for optimizing and learning Nash equilibrium using neural networks to estimate players' cost functions. Depending on the availability of data, we propose two approaches (a) the two-stage approach: we need the data pair of players' strategy and relevant function value to first learn the players' cost functions by monotonic neural networks or graph neural networks, and then solve the Nash equilibrium with the learned neural networks; (b) the joint approach: we use the data of partial true observation of the equilibrium and contextual information (e.g., weather) to optimize and learn Nash equilibrium simultaneously. The problem is formulated as an optimization problem with equilibrium constraints and solved using a modified Backpropagation Algorithm. The proposed methods are validated in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16260v2</guid>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Di Zhang, Wei Gu, Qing Jin</dc:creator>
    </item>
    <item>
      <title>Should the Timing of Inspections be Predictable?</title>
      <link>https://arxiv.org/abs/2304.01385</link>
      <description>arXiv:2304.01385v4 Announce Type: replace-cross 
Abstract: A principal hires an agent to work on a long-term project that culminates in a breakthrough or a breakdown. At each time, the agent privately chooses to work or shirk. Working increases the arrival rate of breakthroughs and decreases the arrival rate of breakdowns. To motivate the agent to work, the principal conducts costly inspections. She fires the agent if shirking is detected. We characterize the principal's optimal inspection policy. Predictable inspections are optimal if work primarily generates breakthroughs. Random inspections are optimal if work primarily prevents breakdowns. Crucially, the agent's actions determine his risk attitude over the timing of punishments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01385v4</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ian Ball, Jan Knoepfle</dc:creator>
    </item>
    <item>
      <title>Cost-sharing in Parking Games</title>
      <link>https://arxiv.org/abs/2309.12265</link>
      <description>arXiv:2309.12265v3 Announce Type: replace-cross 
Abstract: In this paper, we study the total displacement statistic of parking functions from the perspective of cooperative game theory. We introduce parking games, which are coalitional cost-sharing games in characteristic function form derived from the total displacement statistic. We show that parking games are supermodular cost-sharing games, indicating that cooperation is difficult (i.e., their core is empty). Next, we study their Shapley value, which formalizes a notion of "fair" cost-sharing and amounts to charging each car for its expected marginal displacement under a random arrival order. Our main contribution is a polynomial-time algorithm to compute the Shapley value of parking games, in contrast with known hardness results on computing the Shapley value of arbitrary games. The algorithm leverages the permutation-invariance of total displacement, combinatorial enumeration, and dynamic programming. We conclude with open questions around an alternative solution concept for supermodular cost-sharing games and connections to other areas in combinatorics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12265v3</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jennifer Elder, Pamela E. Harris, Jan Kretschmann, J. Carlos Mart\'inez Mori</dc:creator>
    </item>
    <item>
      <title>Voting power in the Council of the European Union: A comprehensive sensitivity analysis</title>
      <link>https://arxiv.org/abs/2312.16878</link>
      <description>arXiv:2312.16878v3 Announce Type: replace-cross 
Abstract: The Council of the European Union (EU) is one of the main decision-making bodies of the EU. Many decisions require a qualified majority: the support of 55% of the member states (currently 15) that represent at least 65% of the total population. We investigate how the power distribution, based on the Shapley-Shubik index, and the proportion of winning coalitions change if these criteria are modified within reasonable bounds. The power of the two countries with about 4% of the total population each is found to be almost flat. The level of decisiveness decreases if the population criterion is above 68\% or the states criterion is at least 17. The proportion of winning coalitions can be increased from 13.2% to 20.8% (30.1%) such that the maximal relative change in the Shapley-Shubik indices remains below 3.5% (5.5%). Our results are indispensable in evaluating any proposal for reforming the qualified majority voting system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16878v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D\'ora Gr\'eta Petr\'oczy, L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Strategic Negotiations in Endogenous Network Formation</title>
      <link>https://arxiv.org/abs/2402.08779</link>
      <description>arXiv:2402.08779v2 Announce Type: replace-cross 
Abstract: In network formation games, agents form edges with each other to maximize their utility. Each agent's utility depends on its private beliefs and its edges in the network. Strategic agents can misrepresent their beliefs to get a better resulting network. Most prior works in this area consider honest agents or a single strategic agent. Instead, we propose a model where any subset of agents can be strategic. We provide an efficient algorithm for finding the set of Nash equilibria, if any exist, and certify their nonexistence otherwise. We also show that when several strategic agents are present, their utilities can increase or decrease compared to when they are all honest. Small changes in the inter-agent correlations can cause such shifts. In contrast, the simpler one-strategic-agent setting explored in the literature lacks such complex patterns. Finally, we develop an algorithm by which new agents can learn the information needed for strategic behavior. Our algorithm works even when the (unknown) strategic agents deviate from the Nash-optimal strategies. We verify these results on both simulated networks and a real-world dataset on international trade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08779v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akhil Jalan, Deepayan Chakrabarti</dc:creator>
    </item>
    <item>
      <title>Permissible four-strategy quantum extensions of classical games</title>
      <link>https://arxiv.org/abs/2405.07380</link>
      <description>arXiv:2405.07380v2 Announce Type: replace-cross 
Abstract: The study focuses on strategic-form games extended in the Eisert-Wilkens-Lewenstein scheme by two unitary operations. Conditions are determined under which the pair of unitary operators, along with classical strategies, form a game invariant under isomorphic transformations of the input classical game. These conditions are then applied to determine these operators, resulting in five main classes of games satisfying the isomorphism criterion, and a theorem is proved providing a practical criterion for this isomorphism. The interdependencies between different classes of extensions are identified, including limit cases in which one class transforms into another.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07380v2</guid>
      <category>quant-ph</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Fr\k{a}ckiewicz, Anna Gorczyca-Goraj, Marek Szopa</dc:creator>
    </item>
    <item>
      <title>Eliciting Informative Text Evaluations with Large Language Models</title>
      <link>https://arxiv.org/abs/2405.15077</link>
      <description>arXiv:2405.15077v4 Announce Type: replace-cross 
Abstract: Peer prediction mechanisms motivate high-quality feedback with provable guarantees. However, current methods only apply to rather simple reports, like multiple-choice or scalar numbers. We aim to broaden these techniques to the larger domain of text-based reports, drawing on the recent developments in large language models. This vastly increases the applicability of peer prediction mechanisms as textual feedback is the norm in a large variety of feedback channels: peer reviews, e-commerce customer reviews, and comments on social media.
  We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM) and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms utilize LLMs as predictors, mapping from one agent's report to a prediction of her peer's report. Theoretically, we show that when the LLM prediction is sufficiently accurate, our mechanisms can incentivize high effort and truth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, we confirm the efficacy of our mechanisms through experiments conducted on two real datasets: the Yelp review dataset and the ICLR OpenReview dataset. We highlight the results that on the ICLR dataset, our mechanisms can differentiate three quality levels -- human-written reviews, GPT-4-generated reviews, and GPT-3.5-generated reviews in terms of expected scores. Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15077v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</dc:creator>
    </item>
  </channel>
</rss>
