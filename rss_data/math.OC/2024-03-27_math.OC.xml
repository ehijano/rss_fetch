<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Mar 2024 04:02:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Non-stationary Bandits with Habituation and Recover Dynamics and Knapsack Constraints</title>
      <link>https://arxiv.org/abs/2403.17073</link>
      <description>arXiv:2403.17073v1 Announce Type: new 
Abstract: Multi-armed bandit models have proven to be useful in modeling many real world problems in the areas of control and sequential decision making with partial information. However, in many scenarios, such as those prevalent in healthcare and operations management, the decision maker's expected reward will decrease if an action is selected too frequently while it may recover if they abstain from selecting this action. This scenario is further complicated when choosing a particular action also expends a random amount of a limited resource where the distribution is also initially unknown to the decision maker. In this paper we study a class of models that address this setting that we call reducing or gaining unknown efficacy bandits with stochastic knapsack constraints (ROGUEwK). We propose a combination upper confidence bound (UCB) and lower confidence bound (LCB) approximation algorithm for optimizing this model. Our algorithm chooses which action to play at each time point by solving a linear program (LP) with the UCB for the average rewards and LCB for the average costs as inputs. We show that the regret of our algorithm is sub-linear as a function of time and total constraint budget when compared to a dynamic oracle. We validate the performance of our algorithm against existing state of the art non-stationary and knapsack bandit approaches in a simulation study and show that our methods are able to on average achieve a 13% improvement in terms of total reward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17073v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinyang He, Yonatan Mintz</dc:creator>
    </item>
    <item>
      <title>Practical Acceleration of the Condat-V\~u Algorithm</title>
      <link>https://arxiv.org/abs/2403.17100</link>
      <description>arXiv:2403.17100v1 Announce Type: new 
Abstract: The Condat-V\~u algorithm is a widely used primal-dual method for optimizing composite objectives of three functions. Several algorithms for optimizing composite objectives of two functions are special cases of Condat-V\~u, including proximal gradient descent (PGD). It is well-known that PGD exhibits suboptimal performance, and a simple adjustment to PGD can accelerate its convergence rate from $\mathcal{O}(1/T)$ to $\mathcal{O}(1/T^2)$ on convex objectives, and this accelerated rate is optimal. In this work, we show that a simple adjustment to the Condat-V\~u algorithm allows it to recover accelerated PGD (APGD) as a special case, instead of PGD. We prove that this accelerated Condat--V\~u algorithm achieves optimal convergence rates and significantly outperforms the traditional Condat-V\~u algorithm in regimes where the Condat--V\~u algorithm approximates the dynamics of PGD. We demonstrate the effectiveness of our approach in various applications in machine learning and computational imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17100v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Derek Driggs, Matthias J. Ehrhardt, Carola-Bibiane Sch\"onlieb, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>Approximation with Random Shallow ReLU Networks with Applications to Model Reference Adaptive Control</title>
      <link>https://arxiv.org/abs/2403.17142</link>
      <description>arXiv:2403.17142v1 Announce Type: new 
Abstract: Neural networks are regularly employed in adaptive control of nonlinear systems and related methods o reinforcement learning. A common architecture uses a neural network with a single hidden layer (i.e. a shallow network), in which the weights and biases are fixed in advance and only the output layer is trained. While classical results show that there exist neural networks of this type that can approximate arbitrary continuous functions over bounded regions, they are non-constructive, and the networks used in practice have no approximation guarantees. Thus, the approximation properties required for control with neural networks are assumed, rather than proved. In this paper, we aim to fill this gap by showing that for sufficiently smooth functions, ReLU networks with randomly generated weights and biases achieve $L_{\infty}$ error of $O(m^{-1/2})$ with high probability, where $m$ is the number of neurons. It suffices to generate the weights uniformly over a sphere and the biases uniformly over an interval. We show how the result can be used to get approximations of required accuracy in a model reference adaptive control application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17142v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Lamperski, Tyler Lekang</dc:creator>
    </item>
    <item>
      <title>Output-feedback Synthesis Orbit Geometry: Quotient Manifolds and LQG Direct Policy Optimization</title>
      <link>https://arxiv.org/abs/2403.17157</link>
      <description>arXiv:2403.17157v1 Announce Type: new 
Abstract: In this paper, we consider direct policy optimization for the linear-quadratic Gaussian (LQG) setting. Over the past few years, it has been recognized that the landscape of stabilizing output-feedback controllers of relevance to LQG has an intricate geometry, particularly as it pertains to the existence of spurious stationary points. In order to address such challenges, in this paper, we first adopt a Riemannian metric for the space of stabilizing full-order minimal output-feedback controllers. We then proceed to prove that the orbit of such controllers modulo coordinate transformation admits a Riemannian quotient manifold structure. This geometric structure is then used to develop a Riemannian gradient descent for the direct LQG policy optimization. We prove a local convergence guarantee with linear rate and show the proposed approach exhibits significantly faster and more robust numerical performance as compared with ordinary gradient descent for LQG. Subsequently, we provide reasons for this observed behavior; in particular, we argue that optimizing over the orbit space of controllers is the right theoretical and computational setup for direct LQG policy optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17157v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spencer Kraisler, Mehran Mesbahi</dc:creator>
    </item>
    <item>
      <title>Robust Finite-time Stabilization of Linear Systems with Limited State Quantization</title>
      <link>https://arxiv.org/abs/2403.17184</link>
      <description>arXiv:2403.17184v1 Announce Type: new 
Abstract: This paper investigates the robust asymptotic stabilization of a linear time-invariant (LTI) system by a static feedback with a static state quantization. It is shown that the controllable LTI system can be stabilized to zero in a finite time by means of a nonlinear feedback with a quantizer having a limited (finite) number of values (quantization seeds) even when all parameters of the controller and the quantizer are time-invariant. The control design is based on generalized homogeneity. A homogeneous spherical quantizer is introduced. The static homogeneous feedback is shown to be local (or global) finite-time stabilizer for the linear system (dependently of the system matrix). The tuning rules for both the quantizer and the feedback law are obtained in the form of Linear Matrix Inequalities (LMIs). The closed-loop system is proven to be robust with respect to some bounded matched and vanishing mismatched perturbations. Theoretical results are supported by numerical simulations. \</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17184v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Zhou, Andrey Polyakov, Gang Zheng</dc:creator>
    </item>
    <item>
      <title>Tightness of the matrix Moment-SOS hierarchy</title>
      <link>https://arxiv.org/abs/2403.17241</link>
      <description>arXiv:2403.17241v1 Announce Type: new 
Abstract: This paper studies the matrix Moment-SOS hierarchy for solving polynomial matrix optimization. Our first result is to show the tightness (i.e., the finite convergence) of this hierarchy, if the nondegeneracy condition, strict complementarity condition and second order sufficient condition hold at every minimizer, under the usual archimedeanness assumption. A useful criterion for detecting tightness is the flat truncation. Our second result is to show that every minimizer of the moment relaxation must have a flat truncation when the relaxation order is big enough, under the above mentioned optimality assumptions. These results give connections between nonlinear semidefinite optimization theory and Moment-SOS methods for solving polynomial matrix optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17241v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Huang, Jiawang Nie</dc:creator>
    </item>
    <item>
      <title>A Moreau Envelope Approach for LQR Meta-Policy Estimation</title>
      <link>https://arxiv.org/abs/2403.17364</link>
      <description>arXiv:2403.17364v1 Announce Type: new 
Abstract: We study the problem of policy estimation for the Linear Quadratic Regulator (LQR) in discrete-time linear time-invariant uncertain dynamical systems. We propose a Moreau Envelope-based surrogate LQR cost, built from a finite set of realizations of the uncertain system, to define a meta-policy efficiently adjustable to new realizations. Moreover, we design an algorithm to find an approximate first-order stationary point of the meta-LQR cost function. Numerical results show that the proposed approach outperforms naive averaging of controllers on new realizations of the linear system. We also provide empirical evidence that our method has better sample complexity than Model-Agnostic Meta-Learning (MAML) approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17364v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Aravind, Mohammad Taha Toghani, C\'esar A. Uribe</dc:creator>
    </item>
    <item>
      <title>An inexact proximal MM method for a class of nonconvex composite image reconstruction models</title>
      <link>https://arxiv.org/abs/2403.17450</link>
      <description>arXiv:2403.17450v1 Announce Type: new 
Abstract: This paper concerns a class of composite image reconstruction models for impluse noise removal, which is rather general and covers existing convex and nonconvex models proposed for reconstructing images with impluse noise. For this nonconvex and nonsmooth optimization problem, we propose a proximal majorization-minimization (MM) algorithm with an implementable inexactness criterion by seeking in each step an inexact minimizer of a strongly convex majorization of the objective function, and establish the convergence of the iterate sequence under the KL assumption on the constructed potential function. This inexact proximal MM method is applied to handle gray image deblurring and color image inpainting problems, for which the associated potential function satisfy the required KL assumption. Numerical comparisons with two state-of-art solvers for image deblurring and inpainting tasks validate the efficiency of the proposed algorithm and models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17450v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bujin Li, Shaohua Pan, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>Minimum-Delay Opportunity Charging Scheduling for Electric Buses</title>
      <link>https://arxiv.org/abs/2403.17527</link>
      <description>arXiv:2403.17527v1 Announce Type: new 
Abstract: Transit agencies that operate battery-electric buses must carefully manage fast-charging infrastructure to extend daily bus range without degrading on-time performance. To support this need, we propose a mixed-integer linear programming model to schedule opportunity charging that minimizes the amount of departure delay in all trips served by electric buses. Our novel approach directly tracks queuing at chargers in order to set and propagate departure delays. Allowing but minimizing delays makes it possible to optimize performance when delays due to traffic conditions and charging needs are inevitable, in contrast with existing methods that require charging to occur during scheduled layover time. To solve the model, we develop two algorithms based on decomposition. The first is an exact solution method based on Combinatorial Benders (CB) decomposition, which avoids directly enumerating the model's logic-based "big M" constraints and their inevitable computational challenges. The second, inspired by the CB approach but more efficient, is a polynomial-time heuristic based on linear programming that we call 3S. Computational experiments on both a simple notional transit network and the real bus system of King County, Washington, USA demonstrate the performance of both methods. The 3S method appears particularly promising for creating good charging schedules quickly at real-world scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17527v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan McCabe (Jeff),  Xuegang (Jeff),  Ban, Balazs Kulcsar</dc:creator>
    </item>
    <item>
      <title>Nonsmooth convex-concave saddle point problems with cardinality penalties</title>
      <link>https://arxiv.org/abs/2403.17535</link>
      <description>arXiv:2403.17535v1 Announce Type: new 
Abstract: In this paper, we focus on a class of convexly constrained nonsmooth convex-concave saddle point problems with cardinality penalties. Although such nonsmooth nonconvex-nonconcave and discontinuous min-max problems may not have a saddle point, we show that they have a local saddle point and a global minimax point, and some local saddle points have the lower bound properties. We define a class of strong local saddle points based on the lower bound properties for stability of variable selection. Moreover, we give a framework to construct continuous relaxations of the discontinuous min-max problems based on the convolution, such that they have the same saddle points with the original problem. We also establish the relations between the continuous relaxation problems and the original problems regarding local saddle points, global minimax points, local minimax points and stationary points. Finally, we illustrate our results with distributionally robust sparse convex regression, sparse robust bond portfolio construction and sparse convex-concave logistic regression saddle point problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17535v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Bian, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>Robust Stability for Multiagent Systems with Spatio-Temporally Correlated Packet Loss</title>
      <link>https://arxiv.org/abs/2403.17554</link>
      <description>arXiv:2403.17554v1 Announce Type: new 
Abstract: A problem with considering correlations in the analysis of multiagent system with stochastic packet loss is that they induce dependencies between agents that are otherwise decoupled, preventing the application of decomposition methods required for efficient evaluation. To circumvent that issue, this paper is proposing an approach based on analysing sets of networks with independent communication links, only considering the correlations in an implicit fashion. Combining ideas from the robust stabilization of Markov jump linear systems with recently proposed techniques for analysing packet loss in multiagent systems, we obtain a linear matrix inequality based stability condition which is independent of the number of agents. The main result is that the set of stabilized probability distributions has non-empty interior such that small correlations cannot lead to instability, even though only distributions of independent links were analysed. Moreover, two examples are provided to demonstrate the applicability of the results to practically relevant scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17554v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christian Hespe, Adwait Datar, Herbert Werner</dc:creator>
    </item>
    <item>
      <title>A Globally Convergent Gradient Method with Momentum</title>
      <link>https://arxiv.org/abs/2403.17613</link>
      <description>arXiv:2403.17613v1 Announce Type: new 
Abstract: In this work, we consider smooth unconstrained optimization problems and we deal with the class of gradient methods with momentum, i.e., descent algorithms where the search direction is defined as a linear combination of the current gradient and the preceding search direction. This family of algorithms includes nonlinear conjugate gradient methods and Polyak's heavy-ball approach, and is thus of high practical and theoretical interest in large-scale nonlinear optimization. We propose a general framework where the scalars of the linear combination defining the search direction are computed simultaneously by minimizing the approximate quadratic model in the 2 dimensional subspace. This strategy allows us to define a class of gradient methods with momentum enjoying global convergence guarantees and an optimal worst-case complexity bound in the nonconvex setting. Differently than all related works in the literature, the convergence conditions are stated in terms of the Hessian matrix of the bi-dimensional quadratic model. To the best of our knowledge, these results are novel to the literature. Moreover, extensive computational experiments show that the gradient methods with momentum here presented outperform classical conjugate gradient methods and are (at least) competitive with the state-of-art method for unconstrained optimization, i.e, L-BFGS method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17613v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Giampaolo Liuzzi, Stefano Lucidi, Marco Sciandrone</dc:creator>
    </item>
    <item>
      <title>Chattering Phenomena in Time-Optimal Control for High-Order Chain-of-Integrators Systems with Full State Constraints</title>
      <link>https://arxiv.org/abs/2403.17675</link>
      <description>arXiv:2403.17675v1 Announce Type: new 
Abstract: Time-optimal control for high-order chain-of-integrators systems with full state constraints and arbitrary given terminal states remains an open and challenging problem in optimal control theory domain. However, optimal control's behaviors in high-order problems lack of precision characterization, even where the existence of chattering phenomena remain unknown and overlooked. This paper establishes a theoretical framework of chattering phenomena in the problem, focusing on the uniqueness of state constraints inducing chattering, the upper bound of switching times in an unconstrained arc during chattering, and the convergence of states and costates to the chattering limit point. For the first time, this paper proves the existence of chattering phenomena in the problems. The chattering optimal control for 4th order problems with velocity constraints is precisely solved, providing an approach to plan strictly time-optimal snap-limited trajectories, while other cases of order $n\leq4$ are proved to not allow chattering. The conclusions correct the longstanding misconception in the industry regarding the time-optimality of S-shaped trajectories with minimal switching times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17675v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunan Wang, Chuxiong Hu, Zeyang Li, Yujie Lin, Shize Lin, Suqin He, Yu Zhu</dc:creator>
    </item>
    <item>
      <title>On Structural Non-commutativity in Affine Feedback of SISO Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2403.17730</link>
      <description>arXiv:2403.17730v1 Announce Type: new 
Abstract: The affine feedback connection of SISO nonlinear systems modeled by Chen--Fliess series is shown to be a group action on the plant which is isomorphic to the semi-direct product of shuffle and additive group of non-commutative formal power series. The additive and multiplicative feedback loops in an affine feedback connection are thus proven to be structurally non-commutative. A flip in the order of these loops results in a net additive feedback loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17730v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Venkatesh G. S.</dc:creator>
    </item>
    <item>
      <title>Multi Agent Pathfinding for Noise Restricted Hybrid Fuel Unmanned Aerial Vehicles</title>
      <link>https://arxiv.org/abs/2403.17849</link>
      <description>arXiv:2403.17849v1 Announce Type: new 
Abstract: Multi Agent Path Finding (MAPF) seeks the optimal set of paths for multiple agents from respective start to goal locations such that no paths conflict. We address the MAPF problem for a fleet of hybrid-fuel unmanned aerial vehicles which are subject to location-dependent noise restrictions. We solve this problem by searching a constraint tree for which the subproblem at each node is a set of shortest path problems subject to the noise and fuel constraints and conflict zone avoidance. A labeling algorithm is presented to solve this subproblem, including the conflict zones which are treated as dynamic obstacles. We present the experimental results of the algorithms for various graph sizes and number of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17849v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Drew Scott, Satyanarayana G. Manyam, David W. Casbeer, Manish Kumar, Isaac E. Weintraub</dc:creator>
    </item>
    <item>
      <title>An Integer Linear Program to create the shifts in a supermarket</title>
      <link>https://arxiv.org/abs/2403.17850</link>
      <description>arXiv:2403.17850v1 Announce Type: new 
Abstract: The shift design and the personnel scheduling problem is known to be a difficult problem. It is a real-world problem which has lots of applications in the organization of companies. Solutions are usually found by dividing the problem in two steps: first the shifts are created, then the employees are assigned to them by respecting a bunch of constraints. The assignment of different tasks increases the complexity, since we have to consider the skills of the single employee necessary to perform any activity. In this paper we present aa integer linear programming formulation which models together the shift creation and the construction of rosters for employees, with the objective of minimizing the amount of uncovered demand. Finally we provide the results for three real-world instances, confirming that this approach is promising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17850v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolo Gusmeroli, Andrea Bettinelli</dc:creator>
    </item>
    <item>
      <title>Parallelizable Parametric Nonlinear System Identification via tuning of a Moving Horizon State Estimator</title>
      <link>https://arxiv.org/abs/2403.17858</link>
      <description>arXiv:2403.17858v1 Announce Type: new 
Abstract: This paper introduces a novel optimization-based approach for parametric nonlinear system identification. Building upon the prediction error method framework, traditionally used for linear system identification, we extend its capabilities to nonlinear systems. The predictions are computed using a moving horizon state estimator with a constant arrival cost. Eventually, both the system parameters and the arrival cost are estimated by minimizing the sum of the squared prediction errors. Since the predictions are induced by the state estimator, the method can be viewed as the tuning of a state estimator, based on its predictive capacities. The present extension of the prediction error method not only enhances performance for nonlinear systems but also enables learning from multiple trajectories with unknown initial states, broadening its applicability in practical scenarios. Additionally, the novel formulation leaves room for the design of efficient and parallelizable optimization algorithms, since each output prediction only depends on a fixed window of past actions and measurements. In the special case of linear time-invariant systems, we show an important property of the proposed method which suggests asymptotic consistency under reasonable assumptions. Numerical examples illustrate the effectiveness and practicality of the approach, and one of the examples also highlights the necessity for the arrival cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17858v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'eo Simpson, Jonas Asprion, Simon Muntwiler, Johannes K\"ohler, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Scaling Mixed-Integer Programming for Certification of Neural Network Controllers Using Bounds Tightening</title>
      <link>https://arxiv.org/abs/2403.17874</link>
      <description>arXiv:2403.17874v1 Announce Type: new 
Abstract: Neural networks offer a computationally efficient approximation of model predictive control, but they lack guarantees on the resulting controlled system's properties. Formal certification of neural networks is crucial for ensuring safety, particularly in safety-critical domains such as autonomous vehicles. One approach to formally certify properties of neural networks is to solve a mixed-integer program based on the network. This approach suffers from scalability issues due to the complexity of solving the resulting mixed-integer programs. Nevertheless, these issues can be (partially) mitigated via bound-tightening techniques prior to forming the mixed-integer program, which results in tighter formulations and faster optimisation. This paper presents bound-tightening techniques in the context of neural network explicit control policies. Bound tightening is particularly important when considering problems spanning multiple time steps of a controlled system, as the bounds must be propagated through the problem depth. Several strategies for bound tightening are evaluated in terms of both computational complexity and tightness of the bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17874v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Sosnin, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>The Solution to an Impulse Control Problem Motivated by Optimal Harvesting</title>
      <link>https://arxiv.org/abs/2403.17875</link>
      <description>arXiv:2403.17875v1 Announce Type: new 
Abstract: We consider a stochastic impulse control problem that is motivated by applications such as the optimal exploitation of a natural resource. In particular, we consider a stochastic system whose uncontrolled state dynamics are modelled by a non-explosive positive linear diffusion. The control that can be applied to this system takes the form of one-sided impulsive action. The objective of the control problem is to maximise a discounted performance criterion that rewards the effect of control action but involves a fixed cost at each time of a control intervention. We derive the complete solution to this problem under general assumptions. It turns out that the solution can take four qualitatively different forms, several of which have not been observed in the literature. In two of the four cases, there exist only $\varepsilon$-optimal control strategies. We also show that the boundary classification of 0 may play a critical role in the solution of the problem. Furthermore, we develop a way for establishing the strong solution to a stochastic impulse control problem's optimally controlled SDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17875v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhesheng Liu, Mihail Zervos</dc:creator>
    </item>
    <item>
      <title>Optimizing Vaccine Site Locations While Considering Travel Inconvenience and Public Health Outcomes</title>
      <link>https://arxiv.org/abs/2403.17923</link>
      <description>arXiv:2403.17923v1 Announce Type: new 
Abstract: During the COVID-19 pandemic, there were over three million infections in Los Angeles County (LAC). To facilitate distribution when vaccines first became available, LAC set up six mega-sites for dispensing a large number of vaccines to the public. To understand if another choice of mega-site location would have improved accessibility and health outcomes, and to provide insight into future vaccine allocation problems, we propose a multi-objective mixed integer linear programming model that balances travel convenience, infection reduction, and equitable distribution. We provide a tractable objective formulation that effectively proxies real-world public health goals of reducing infections while considering travel inconvenience and equitable distribution of resources. Compared with the solution empirically used in LAC in 2020, we recommend more dispersed mega-site locations that result in a 28% reduction in travel inconvenience and avert an additional 1,000 infections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17923v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suyanpeng Zhang, Sze-chuan Suen, Han Yu, Maged Dessouky, Fernando Ordonez</dc:creator>
    </item>
    <item>
      <title>Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction</title>
      <link>https://arxiv.org/abs/2403.17042</link>
      <description>arXiv:2403.17042v1 Announce Type: cross 
Abstract: In a great number of tasks in science and engineering, the goal is to infer an unknown image from a small number of measurements collected from a known forward model describing certain sensing or imaging modality. Due to resource constraints, this task is often extremely ill-posed, which necessitates the adoption of expressive prior information to regularize the solution space. Score-based diffusion models, due to its impressive empirical success, have emerged as an appealing candidate of an expressive prior in image reconstruction. In order to accommodate diverse tasks at once, it is of great interest to develop efficient, consistent and robust algorithms that incorporate {\em unconditional} score functions of an image prior distribution in conjunction with flexible choices of forward models.
  This work develops an algorithmic framework for employing score-based diffusion models as an expressive data prior in general nonlinear inverse problems. Motivated by the plug-and-play framework in the imaging community, we introduce a diffusion plug-and-play method (\textsf{DPnP}) that alternatively calls two samplers, a proximal consistency sampler based solely on the likelihood function of the forward model, and a denoising diffusion sampler based solely on the score functions of the image prior. The key insight is that denoising under white Gaussian noise can be solved {\em rigorously} via both stochastic (i.e., DDPM-type) and deterministic (i.e., DDIM-type) samplers using the unconditional score functions. We establish both asymptotic and non-asymptotic performance guarantees of \textsf{DPnP}, and provide numerical experiments to illustrate its promise in solving both linear and nonlinear image reconstruction tasks. To the best of our knowledge, \textsf{DPnP} is the first provably-robust posterior sampling method for nonlinear inverse problems using unconditional diffusion priors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17042v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyu Xu, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Belief Samples Are All You Need For Social Learning</title>
      <link>https://arxiv.org/abs/2403.17174</link>
      <description>arXiv:2403.17174v1 Announce Type: cross 
Abstract: In this paper, we consider the problem of social learning, where a group of agents embedded in a social network are interested in learning an underlying state of the world. Agents have incomplete, noisy, and heterogeneous sources of information, providing them with recurring private observations of the underlying state of the world. Agents can share their learning experience with their peers by taking actions observable to them, with values from a finite feasible set of states. Actions can be interpreted as samples from the beliefs which agents may form and update on what the true state of the world is. Sharing samples, in place of full beliefs, is motivated by the limited communication, cognitive, and information-processing resources available to agents especially in large populations. Previous work (Salhab et al.) poses the question as to whether learning with probability one is still achievable if agents are only allowed to communicate samples from their beliefs. We provide a definite positive answer to this question, assuming a strongly connected network and a ``collective distinguishability'' assumption, which are both required for learning even in full-belief-sharing settings. In our proposed belief update mechanism, each agent's belief is a normalized weighted geometric interpolation between a fully Bayesian private belief -- aggregating information from the private source -- and an ensemble of empirical distributions of the samples shared by her neighbors over time. By carefully constructing asymptotic almost-sure lower/upper bounds on the frequency of shared samples matching the true state/or not, we rigorously prove the convergence of all the beliefs to the true state, with probability one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17174v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahyar JafariNodeh, Amir Ajorlou, Ali Jadbabaie</dc:creator>
    </item>
    <item>
      <title>DASA: Delay-Adaptive Multi-Agent Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2403.17247</link>
      <description>arXiv:2403.17247v1 Announce Type: cross 
Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tmix$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA applications, including multi-agent and distributed temporal difference (TD) learning, Q-learning and stochastic optimization with correlated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17247v1</guid>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolo Dal Fabbro, Arman Adibi, H. Vincent Poor, Sanjeev R. Kulkarni, Aritra Mitra, George J. Pappas</dc:creator>
    </item>
    <item>
      <title>Investigations on Physics-Informed Neural Networks for Aerodynamics</title>
      <link>https://arxiv.org/abs/2403.17470</link>
      <description>arXiv:2403.17470v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) have recently emerged as a novel approach to simulate complex physical systems on the basis of both data observations and physical models. In this work, we investigate the use of PINNs for various applications in aerodynamics and we explain how to leverage their specific formulation to perform some tasks effectively. In particular, we demonstrate the ability of PINNs to construct parametric surrogate models, to achieve multiphysic couplings and to infer turbulence characteristics via data assimilation. The robustness and accuracy of the PINNs approach are analysed, then current issues and challenges are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17470v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>physics.class-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Coulaud (ACUMES), Maxime Le (ACUMES), R\'egis Duvigneau (ACUMES)</dc:creator>
    </item>
    <item>
      <title>Quantum Optimization for the Future Energy Grid: Summary and Quantum Utility Prospects</title>
      <link>https://arxiv.org/abs/2403.17495</link>
      <description>arXiv:2403.17495v1 Announce Type: cross 
Abstract: In this project summary paper, we summarize the key results and use-cases explored in the German Federal Ministry of Education and Research (BMBF) funded project "Q-GRID" which aims to assess potential quantum utility optimization applications in the electrical grid. The project focuses on two layers of optimization problems relevant to decentralized energy generation and transmission as well as novel energy transportation/exchange methods such as Peer-2-Peer energy trading and microgrid formation. For select energy grid optimization problems, we demonstrate exponential classical optimizer runtime scaling even for small problem instances, and present initial findings that variational quantum algorithms such as QAOA and hybrid quantum annealing solvers may provide more favourable runtime scaling to obtain similar solution quality. These initial results suggest that quantum computing may be a key enabling technology in the future energy transition insofar that they may be able to solve business problems which are already challenging at small problem instance sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17495v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Blenninger, David Bucher, Giorgio Cortiana, Kumar Ghosh, Naeimeh Mohseni, Jonas N\"u{\ss}lein, Corey O'Meara, Daniel Porawski, Benedikt Wimmer</dc:creator>
    </item>
    <item>
      <title>Enhancing Privacy in Federated Learning through Local Training</title>
      <link>https://arxiv.org/abs/2403.17572</link>
      <description>arXiv:2403.17572v1 Announce Type: cross 
Abstract: In this paper we propose the federated private local training algorithm (Fed-PLT) for federated learning, to overcome the challenges of (i) expensive communications and (ii) privacy preservation. We address (i) by allowing for both partial participation and local training, which significantly reduce the number of communication rounds between the central coordinator and computing agents. The algorithm matches the state of the art in the sense that the use of local training demonstrably does not impact accuracy. Additionally, agents have the flexibility to choose from various local training solvers, such as (stochastic) gradient descent and accelerated gradient descent. Further, we investigate how employing local training can enhance privacy, addressing point (ii). In particular, we derive differential privacy bounds and highlight their dependence on the number of local training epochs. We assess the effectiveness of the proposed algorithm by comparing it to alternative techniques, considering both theoretical analysis and numerical results from a classification task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17572v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Bastianello, Changxin Liu, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>An Exact Solution for Allocating Car Parking Spaces on Campus</title>
      <link>https://arxiv.org/abs/2403.17597</link>
      <description>arXiv:2403.17597v1 Announce Type: cross 
Abstract: All over the world, especially in the university environment, planning managers and traffic engineers are constantly faced with the problem of inadequate allocation of car parking spaces to demanded users. Users could either prefer reserved parking spaces to unreserved parking spaces or vice versa. This makes the campus parking manager to be faced with two basic problem which are: the problem of allocating the actual number of available reserved spaces to users without any conflict over the same parking space, and the problem of determining the number of parking permit to be issued for parking lot with unreserved spaces. Hence, an optimal or available solution to the problem is required. This paper investigates a model for allocating car parking spaces, adds a constraint to address the reserved parking policy in a university environment and solves the parking allocation problem using an exact solution method. The result obtained gives the value of the objective function and the optimal allocation of users to each parking lot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17597v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Luke Oluwaseye Joel, Sawyerr A. Babatunde, Adewumi O. Aderemi</dc:creator>
    </item>
    <item>
      <title>Manifold-Guided Lyapunov Control with Diffusion Models</title>
      <link>https://arxiv.org/abs/2403.17692</link>
      <description>arXiv:2403.17692v1 Announce Type: cross 
Abstract: This paper presents a novel approach to generating stabilizing controllers for a large class of dynamical systems using diffusion models. The core objective is to develop stabilizing control functions by identifying the closest asymptotically stable vector field relative to a predetermined manifold and adjusting the control function based on this finding. To achieve this, we employ a diffusion model trained on pairs consisting of asymptotically stable vector fields and their corresponding Lyapunov functions. Our numerical results demonstrate that this pre-trained model can achieve stabilization over previously unseen systems efficiently and rapidly, showcasing the potential of our approach in fast zero-shot control and generalizability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17692v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amartya Mukherjee, Thanin Quartz, Jun Liu</dc:creator>
    </item>
    <item>
      <title>Using quantum computers in control: interval matrix properties</title>
      <link>https://arxiv.org/abs/2403.17711</link>
      <description>arXiv:2403.17711v1 Announce Type: cross 
Abstract: Quantum computing provides a powerful framework for tackling computational problems that are classically intractable. The goal of this paper is to explore the use of quantum computers for solving relevant problems in systems and control theory. In the recent literature, different quantum algorithms have been developed to tackle binary optimization, which plays an important role in various control-theoretic problems. As a prototypical example, we consider the verification of interval matrix properties such as non-singularity and stability on a quantum computer. We present a quantum algorithm solving these problems and we study its performance in simulation. Our results demonstrate that quantum computers provide a promising tool for control whose applicability to further computationally complex problems remains to be explored.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17711v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Schneider, Julian Berberich</dc:creator>
    </item>
    <item>
      <title>LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning</title>
      <link>https://arxiv.org/abs/2403.17919</link>
      <description>arXiv:2403.17919v1 Announce Type: cross 
Abstract: The machine learning community has witnessed impressive advancements since the first appearance of large language models (LLMs), yet their huge memory consumption has become a major roadblock to large-scale training. Parameter Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been proposed to alleviate this problem, but their performance still fails to match full parameter training in most large-scale fine-tuning settings. Attempting to complement this deficiency, we investigate layerwise properties of LoRA on fine-tuning tasks and observe an uncommon skewness of weight norms across different layers. Utilizing this key observation, a surprisingly simple training strategy is discovered, which outperforms both LoRA and full parameter training in a wide range of settings with memory costs as low as LoRA. We name it Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA, which applies the idea of importance sampling to different layers in LLMs and randomly freeze most middle layers during optimization. Experimental results show that with similar or less GPU memory consumption, LISA surpasses LoRA or even full parameter tuning in downstream fine-tuning tasks, where LISA consistently outperforms LoRA by over $11\%$-$37\%$ in terms of MT-Bench scores. On large models, specifically LLaMA-2-70B, LISA achieves on-par or better performance than LoRA on MT-Bench, GSM8K, and PubMedQA, demonstrating its effectiveness across different domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17919v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Pan, Xiang Liu, Shizhe Diao, Renjie Pi, Jipeng Zhang, Chi Han, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>A Semismooth Newton Stochastic Proximal Point Algorithm with Variance Reduction</title>
      <link>https://arxiv.org/abs/2204.00406</link>
      <description>arXiv:2204.00406v3 Announce Type: replace 
Abstract: We develop an implementable stochastic proximal point (SPP) method for a class of weakly convex, composite optimization problems. The proposed stochastic proximal point algorithm incorporates a variance reduction mechanism and the resulting SPP updates are solved using an inexact semismooth Newton framework. We establish detailed convergence results that take the inexactness of the SPP steps into account and that are in accordance with existing convergence guarantees of (proximal) stochastic variance-reduced gradient methods. Numerical experiments show that the proposed algorithm competes favorably with other state-of-the-art methods and achieves higher robustness with respect to the step size selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.00406v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/22M1488181</arxiv:DOI>
      <dc:creator>Andre Milzarek, Fabian Schaipp, Michael Ulbrich</dc:creator>
    </item>
    <item>
      <title>Multilinear formulations for computing Nash equilibrium of multi-player matrix games</title>
      <link>https://arxiv.org/abs/2208.03406</link>
      <description>arXiv:2208.03406v2 Announce Type: replace 
Abstract: We present multilinear and mixed-integer multilinear programs to find a Nash equilibrium in multi-player noncooperative games. We compare the formulations to common algorithms in Gambit, and conclude that a multilinear feasibility program finds a Nash equilibrium faster than any of the methods we compare it to, including the quantal response equilibrium method, which is recommended for large games. Hence, the multilinear feasibility program is an alternative method to find a Nash equilibrium in multi-player games, and outperforms many common algorithms. The mixed-integer formulations are generalisations of known mixed-integer programs for two-player games, however unlike two-player games, these mixed-integer programs do not give better performance than existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.03406v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.SEA.2023.12</arxiv:DOI>
      <arxiv:journal_reference>21st International Symposium on Experimental Algorithms, SEA 2023. Leibniz International Proceedings in Informatics (LIPIcs), volume 265, 12:1 - 12:14, 2023</arxiv:journal_reference>
      <dc:creator>Miriam Fischer, Akshay Gupte</dc:creator>
    </item>
    <item>
      <title>Optimal Design of Volt/VAR Control Rules of Inverters using Deep Learning</title>
      <link>https://arxiv.org/abs/2211.09557</link>
      <description>arXiv:2211.09557v2 Announce Type: replace 
Abstract: Distribution grids are challenged by rapid voltage fluctuations induced by variable power injections from distributed energy resources (DERs). To regulate voltage, the IEEE Standard 1547 recommends each DER inject reactive power according to piecewise-affine Volt/VAR control rules. Although the standard suggests a default shape, the rule can be customized per bus. This task of optimal rule design (ORD) is challenging as Volt/VAR rules introduce nonlinear dynamics, and lurk trade-offs between stability and steady-state voltage profiles. ORD is formulated as a mixed-integer nonlinear program (MINLP), but scales unfavorably with the problem size. Towards a more efficient solution, we reformulate ORD as a deep learning problem. The idea is to design a DNN that emulates Volt/VAR dynamics. The DNN takes grid scenarios as inputs, rule parameters as weights, and outputs equilibrium voltages. Optimal rule parameters can be found by training the DNN so its output approaches unity for various scenarios. The DNN is only used to optimize rules and is never employed in the field. While dealing with ORD, we also review and expand on stability conditions and convergence rates for Volt/VAR dynamics on single- and multi-phase feeders. Tests showcase the merit of DNN-based ORD by benchmarking it against its MINLP counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09557v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarthak Gupta, Vassilis Kekatos, Spyros Chatzivasileiadis</dc:creator>
    </item>
    <item>
      <title>On the Geometric Convergence of Byzantine-Resilient Distributed Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2305.10810</link>
      <description>arXiv:2305.10810v2 Announce Type: replace 
Abstract: The problem of designing distributed optimization algorithms that are resilient to Byzantine adversaries has received significant attention. For the Byzantine-resilient distributed optimization problem, the goal is to (approximately) minimize the average of the local cost functions held by the regular (non adversarial) agents in the network. In this paper, we provide a general algorithmic framework for Byzantine-resilient distributed optimization which includes some state-of-the-art algorithms as special cases. We analyze the convergence of algorithms within the framework, and derive a geometric rate of convergence of all regular agents to a ball around the optimal solution (whose size we characterize). Furthermore, we show that approximate consensus can be achieved geometrically fast under some minimal conditions. Our analysis provides insights into the relationship among the convergence region, distance between regular agents' values, step-size, and properties of the agents' functions for Byzantine-resilient distributed optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10810v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kananart Kuwaranancharoen, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>Frequency Regulation with Storage: On Losses and Profits</title>
      <link>https://arxiv.org/abs/2306.02987</link>
      <description>arXiv:2306.02987v2 Announce Type: replace 
Abstract: Low-carbon societies will need to store vast amounts of electricity to balance intermittent generation from wind and solar energy, for example, through frequency regulation. Here, we derive an analytical solution to the decision-making problem of storage operators who sell frequency regulation power to grid operators and trade electricity on day-ahead markets. Mathematically, we treat future frequency deviation trajectories as functional uncertainties in a receding horizon robust optimization problem. We constrain the expected terminal state-of-charge to be equal to some target to allow storage operators to make good decisions not only for the present but also the future. Thanks to this constraint, the amount of electricity traded on day-ahead markets is an implicit function of the regulation power sold to grid operators. The implicit function quantifies the amount of power that needs to be purchased to cover the expected energy loss that results from providing frequency regulation. We show how the marginal cost associated with the expected energy loss decreases with roundtrip efficiency and increases with frequency deviation dispersion. We find that the profits from frequency regulation over the lifetime of energy-constrained storage devices are roughly inversely proportional to the length of time for which regulation power must be committed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02987v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.GN</category>
      <category>eess.SY</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2024.03.022</arxiv:DOI>
      <dc:creator>Dirk Lauinger, Fran\c{c}ois Vuille, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Harmonic Control Lyapunov Barrier Functions for Constrained Optimal Control with Reach-Avoid Specifications</title>
      <link>https://arxiv.org/abs/2310.02869</link>
      <description>arXiv:2310.02869v2 Announce Type: replace 
Abstract: This paper introduces harmonic control Lyapunov barrier functions (harmonic CLBF) that aid in constrained control problems such as reach-avoid problems. Harmonic CLBFs exploit the maximum principle that harmonic functions satisfy to encode the properties of control Lyapunov barrier functions (CLBFs). As a result, they can be initiated at the start of an experiment rather than trained based on sample trajectories. The control inputs are selected to maximize the inner product of the system dynamics with the steepest descent direction of the harmonic CLBF. Numerical results are presented with four different systems under different reach-avoid environments. Harmonic CLBFs show a significantly low risk of entering unsafe regions and a high probability of entering the goal region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02869v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amartya Mukherjee, Ruikun Zhou, Haocheng Chang, Jun Liu</dc:creator>
    </item>
    <item>
      <title>Long Solution Times or Low Solution Quality: On Trade-Offs in Choosing a Power Flow Formulation for the Optimal Power Shutoff Problem</title>
      <link>https://arxiv.org/abs/2310.13843</link>
      <description>arXiv:2310.13843v2 Announce Type: replace 
Abstract: The Optimal Power Shutoff (OPS) problem is an optimization problem that makes power line de-energization decisions in order to reduce the risk of igniting a wildfire, while minimizing the load shed of customers. This problem, with DC linear power flow equations, has been used in many studies in recent years. However, using linear approximations for power flow when making decisions on the network topology is known to cause challenges with AC feasibility of the resulting network, as studied in the related contexts of optimal transmission switching or grid restoration planning. This paper explores the accuracy of the DC OPS formulation and the ability to recover an AC-feasible power flow solution after de-energization decisions are made. We also extend the OPS problem to include variants with the AC, Second-Order-Cone, and Network-Flow power flow equations, and compare them to the DC approximation with respect to solution quality and time. The results highlight that the DC approximation overestimates the amount of load that can be served, leading to poor de-energization decisions. The AC and SOC-based formulations are better, but prohibitively slow to solve for even modestly sized networks thus demonstrating the need for new solution methods with better trade-offs between computational time and solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13843v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Haag, Noah Rhodes, Line Roald</dc:creator>
    </item>
    <item>
      <title>A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees</title>
      <link>https://arxiv.org/abs/2310.18841</link>
      <description>arXiv:2310.18841v2 Announce Type: replace 
Abstract: We consider minimization of a smooth nonconvex function with inexact oracle access to gradient and Hessian (without assuming access to the function value) to achieve approximate second-order optimality. A novel feature of our method is that if an approximate direction of negative curvature is chosen as the step, we choose its sense to be positive or negative with equal probability. We allow gradients to be inexact in a relative sense and relax the coupling between inexactness thresholds for the first- and second-order optimality conditions. Our convergence analysis includes both an expectation bound based on martingale analysis and a high-probability bound based on concentration inequalities. We apply our algorithm to empirical risk minimization problems and obtain improved gradient sample complexity over existing works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18841v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shuyao Li, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Gaussian smoothing gradient descent for minimizing functions (GSmoothGD)</title>
      <link>https://arxiv.org/abs/2311.00521</link>
      <description>arXiv:2311.00521v2 Announce Type: replace 
Abstract: This work analyzes the convergence of a class of smoothing-based gradient descent methods when applied to optimization problems. In particular, Gaussian smoothing is employed to define a nonlocal gradient that reduces high-frequency noise, small variations, and rapid fluctuations in the computation of the descent directions while preserving the structure and features of the loss landscape. The resulting Gaussian smoothing gradient descent (GSmoothGD) approach can facilitate gradient descent in navigating away from and avoiding local minima with increased ease, thereby substantially enhancing its overall performance even when applied to non-convex optimization problems. This work also provides rigorous theoretical error estimates on the rate of convergence of GSmoothGD iterates. These estimates exemplify the impact of underlying function convexity, smoothness, input dimension, and the Gaussian smoothing radius. To combat the curse of dimensionality, we numerically approximate the GSmoothGD nonlocal gradient using Monte Carlo (MC) sampling and provide a theory in which the iterates converge regardless of the function smoothness and dimension. Finally, we present several strategies to update the smoothing parameter aimed at diminishing the impact of local minima, thereby rendering the attainment of global minima more achievable. Computational evidence complements the present theory and shows the effectiveness of the MC-GSmoothGD method compared to other smoothing-based algorithms, momentum-based approaches, and classical gradient-based algorithms from numerical optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00521v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Starnes, Anton Dereventsov, Clayton Webster</dc:creator>
    </item>
    <item>
      <title>On the Diameter of a 2-Sum of Polyhedra</title>
      <link>https://arxiv.org/abs/2311.02047</link>
      <description>arXiv:2311.02047v2 Announce Type: replace 
Abstract: The study of the combinatorial diameter of a polyhedron is a classical topic in linear-programming theory due to its close connection with the possibility of a polynomial simplex-method pivot rule. The 2-sum operation is a classical operation for graphs, matrices, and matroids; we extend this definition to polyhedra. We analyze the diameters of 2-sum polyhedra, which are those polyhedra that arise from this operation. These polyhedra appear in matroid and integer-programming theory as a natural way to link two systems in a joint model with a single shared constraint and the 2-sum also appears as a key operation in Seymour's decomposition theorem for totally-unimodular matrices.
  We show that the diameter of a 2-sum polyhedron is quadratic in the diameters of its summands. The methods transfer to a linear bound for the addition of a unit column to an equality system, or equivalently, to the relaxation of an equality constraint to an inequality constraint. Further, we use our methods to analyze the distance between vertices on certain faces of a 3-sum polyhedron.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02047v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen Borgwardt, Weston Grewe, Jon Lee</dc:creator>
    </item>
    <item>
      <title>On the Post-Lie Structure in SISO Affine Feedback Control Systems</title>
      <link>https://arxiv.org/abs/2311.04070</link>
      <description>arXiv:2311.04070v2 Announce Type: replace 
Abstract: The main objective of this work is to show that the single-input, single-output (SISO) affine feedback group, a transformation group in the context of the affine feedback interconnection of Chen-Fliess series, is a post-group in the sense of Bai, Guo, Sheng and Tang.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04070v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kurusch Ebrahimi-Fard, W. Steven Gray, Venkatesh G. S.</dc:creator>
    </item>
    <item>
      <title>Discretized Distributed Optimization over Dynamic Digraphs</title>
      <link>https://arxiv.org/abs/2311.07939</link>
      <description>arXiv:2311.07939v2 Announce Type: replace 
Abstract: We consider a discrete-time model of continuous-time distributed optimization over dynamic directed-graphs (digraphs) with applications to distributed learning. Our optimization algorithm works over general strongly connected dynamic networks under switching topologies, e.g., in mobile multi-agent systems and volatile networks due to link failures. Compared to many existing lines of work, there is no need for bi-stochastic weight designs on the links. The existing literature mostly needs the link weights to be stochastic using specific weight-design algorithms needed both at the initialization and at all times when the topology of the network changes. This paper eliminates the need for such algorithms and paves the way for distributed optimization over time-varying digraphs. We derive the bound on the gradient-tracking step-size and discrete time-step for convergence and prove dynamic stability using arguments from consensus algorithms, matrix perturbation theory, and Lyapunov theory. This work, particularly, is an improvement over existing stochastic-weight undirected networks in case of link removal or packet drops. This is because the existing literature may need to rerun time-consuming and computationally complex algorithms for stochastic design, while the proposed strategy works as long as the underlying network is weight-symmetric and balanced. The proposed optimization framework finds applications to distributed classification and learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07939v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions on Automation science and Engineering 2024</arxiv:journal_reference>
      <dc:creator>Mohammadreza Doostmohammadian, Wei Jiang, Muwahida Liaquat, Alireza Aghasi, Houman Zarrabi</dc:creator>
    </item>
    <item>
      <title>Optimal Data Splitting in Distributed Optimization for Machine Learning</title>
      <link>https://arxiv.org/abs/2401.07809</link>
      <description>arXiv:2401.07809v2 Announce Type: replace 
Abstract: The distributed optimization problem has become increasingly relevant recently. It has a lot of advantages such as processing a large amount of data in less time compared to non-distributed methods. However, most distributed approaches suffer from a significant bottleneck - the cost of communications. Therefore, a large amount of research has recently been directed at solving this problem. One such approach uses local data similarity. In particular, there exists an algorithm provably optimally exploiting the similarity property. But this result, as well as results from other works solve the communication bottleneck by focusing only on the fact that communication is significantly more expensive than local computing and does not take into account the various capacities of network devices and the different relationship between communication time and local computing expenses. We consider this setup and the objective of this study is to achieve an optimal ratio of distributed data between the server and local machines for any costs of communications and local computations. The running times of the network are compared between uniform and optimal distributions. The superior theoretical performance of our solutions is experimentally validated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07809v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1134/S1064562423701600</arxiv:DOI>
      <dc:creator>Daniil Medyakov, Gleb Molodtsov, Aleksandr Beznosikov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Optimal Analysis of Method with Batching for Monotone Stochastic Finite-Sum Variational Inequalities</title>
      <link>https://arxiv.org/abs/2401.07858</link>
      <description>arXiv:2401.07858v2 Announce Type: replace 
Abstract: Variational inequalities are a universal optimization paradigm that is interesting in itself, but also incorporates classical minimization and saddle point problems. Modern realities encourage to consider stochastic formulations of optimization problems. In this paper, we present an analysis of a method that gives optimal convergence estimates for monotone stochastic finite-sum variational inequalities. In contrast to the previous works, our method supports batching and does not lose the oracle complexity optimality. The effectiveness of the algorithm, especially in the case of small but not single batches is confirmed experimentally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07858v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1134/S1064562423701582</arxiv:DOI>
      <dc:creator>Alexander Pichugin, Maksim Pechin, Aleksandr Beznosikov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Minimal covariance realization and system identification algorithm for a class of stochastic linear switched systems with i.i.d. switching</title>
      <link>https://arxiv.org/abs/2403.14259</link>
      <description>arXiv:2403.14259v2 Announce Type: replace 
Abstract: In this paper, we consider stochastic realization theory of Linear Switched Systems (LSS) with i.i.d. switching. We characterize minimality of stochastic LSSs and show existence and uniqueness (up to isomorphism) of minimal LSSs in innovation form. We present a realization algorithm to compute a minimal LSS in innovation form from output and input covariances. Finally, based on this realization algorithm, by replacing true covariances with empirical ones, we propose a statistically consistent system identification algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14259v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elie Rouphael, Manas Mejari, Mihaly Petreczky, Lotfi Belkoura</dc:creator>
    </item>
    <item>
      <title>A robust optimization approach model for a multi-vaccine multi-echelon supply chain</title>
      <link>https://arxiv.org/abs/2403.16173</link>
      <description>arXiv:2403.16173v2 Announce Type: replace 
Abstract: This research investigates a multi-product, multi-echelon, and multi-period vaccine supply chain network model under uncertainty and quality inspection errors. The objective function seeks optimizing the total cost of the supply chain. Moreover, the proposed model is formulated as a mixed integer linear programming problem under multiple sources of uncertain parameters including demand, inspection errors, vaccine waste generated in healthcare centers, and defective treatment rate of vaccine waste. To provide meaningful solutions that are robust against future fluctuation of parameters, the robust optimization approach is utilized to incorporate the decision maker risk attitude under different type of uncertainty sets. Namely, box, polyhedral and combination of interval polyhedral. The performance of the proposed model is demonstrated through an illustrative example. The results show the effect of different types of uncertainties on the overall objective function. Managerial insights and research implications in terms of vaccine supply chain is advised and future research directions are proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16173v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abderrahmen Bochenine, Ismail Almaraj</dc:creator>
    </item>
    <item>
      <title>An optimal control perspective on diffusion-based generative modeling</title>
      <link>https://arxiv.org/abs/2211.01364</link>
      <description>arXiv:2211.01364v3 Announce Type: replace-cross 
Abstract: We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton-Jacobi-Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback-Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approaches on multiple numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01364v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2024</arxiv:journal_reference>
      <dc:creator>Julius Berner, Lorenz Richter, Karen Ullrich</dc:creator>
    </item>
    <item>
      <title>Federated Learning Using Three-Operator ADMM</title>
      <link>https://arxiv.org/abs/2211.04152</link>
      <description>arXiv:2211.04152v3 Announce Type: replace-cross 
Abstract: Federated learning (FL) has emerged as an instance of distributed machine learning paradigm that avoids the transmission of data generated on the users' side. Although data are not transmitted, edge devices have to deal with limited communication bandwidths, data heterogeneity, and straggler effects due to the limited computational resources of users' devices. A prominent approach to overcome such difficulties is FedADMM, which is based on the classical two-operator consensus alternating direction method of multipliers (ADMM). The common assumption of FL algorithms, including FedADMM, is that they learn a global model using data only on the users' side and not on the edge server. However, in edge learning, the server is expected to be near the base station and have direct access to rich datasets. In this paper, we argue that leveraging the rich data on the edge server is much more beneficial than utilizing only user datasets. Specifically, we show that the mere application of FL with an additional virtual user node representing the data on the edge server is inefficient. We propose FedTOP-ADMM, which generalizes FedADMM and is based on a three-operator ADMM-type technique that exploits a smooth cost function on the edge server to learn a global model parallel to the edge devices. Our numerical experiments indicate that FedTOP-ADMM has substantial gain up to 33\% in communication efficiency to reach a desired test accuracy with respect to FedADMM, including a virtual user on the edge server.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.04152v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JSTSP.2022.3221681</arxiv:DOI>
      <dc:creator>Shashi Kant, Jos\'e Mairton B. da Silva Jr., Gabor Fodor, Bo G\"oransson, Mats Bengtsson, Carlo Fischione</dc:creator>
    </item>
    <item>
      <title>A distribution-free mixed-integer optimization approach to hierarchical modelling of clustered and longitudinal data</title>
      <link>https://arxiv.org/abs/2302.03157</link>
      <description>arXiv:2302.03157v2 Announce Type: replace-cross 
Abstract: Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired with hardware enhancements, have led to significant speedups in resolving MIO problems. These strategies have been utilized for optimal subset selection, specifically for choosing $k$ features out of $p$ in linear regression given $n$ observations. In this paper, we broaden this method to facilitate cluster-aware regression, where selection aims to choose $\lambda$ out of $K$ clusters in a linear mixed effects (LMM) model with $n_k$ observations for each cluster. Through comprehensive testing on a multitude of synthetic and real datasets, we exhibit that our method efficiently solves problems within minutes. Through numerical experiments, we also show that the MIO approach outperforms both Gaussian- and Laplace-distributed LMMs in terms of generating sparse solutions with high predictive power. Traditional LMMs typically assume that clustering effects are independent of individual features. However, we introduce an innovative algorithm that evaluates cluster effects for new data points, thereby increasing the robustness and precision of this model. The inferential and predictive efficacy of this approach is further illustrated through its application in student scoring and protein expression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03157v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Madhav Sankaranarayanan, Intekhab Hossain, Tom Chen</dc:creator>
    </item>
    <item>
      <title>Omega: Optimistic EMA Gradients</title>
      <link>https://arxiv.org/abs/2306.07905</link>
      <description>arXiv:2306.07905v2 Announce Type: replace-cross 
Abstract: Stochastic min-max optimization has gained interest in the machine learning community with the advancements in GANs and adversarial training. Although game optimization is fairly well understood in the deterministic setting, some issues persist in the stochastic regime. Recent work has shown that stochastic gradient descent-ascent methods such as the optimistic gradient are highly sensitive to noise or can fail to converge. Although alternative strategies exist, they can be prohibitively expensive. We introduce Omega, a method with optimistic-like updates that mitigates the impact of noise by incorporating an EMA of historic gradients in its update rule. We also explore a variation of this algorithm that incorporates momentum. Although we do not provide convergence guarantees, our experiments on stochastic games show that Omega outperforms the optimistic gradient method when applied to linear players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07905v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Ramirez, Rohan Sukumaran, Quentin Bertrand, Gauthier Gidel</dc:creator>
    </item>
    <item>
      <title>Continuous Non-monotone DR-submodular Maximization with Down-closed Convex Constraint</title>
      <link>https://arxiv.org/abs/2307.09616</link>
      <description>arXiv:2307.09616v3 Announce Type: replace-cross 
Abstract: We investigate the continuous non-monotone DR-submodular maximization problem subject to a down-closed convex solvable constraint. Our first contribution is to construct an example to demonstrate that (first-order) stationary points can have arbitrarily bad approximation ratios, and they are usually on the boundary of the feasible domain. These findings are in contrast with the monotone case where any stationary point yields a $1/2$-approximation (Hassani et al. (2017)). Moreover, this example offers insights on how to design improved algorithms by avoiding bad stationary points, such as the restricted continuous local search algorithm (Chekuri et al. (2014)) and the aided measured continuous greedy (Buchbinder and Feldman (2019)). However, the analyses in the last two algorithms only work for the discrete domain because both need to invoke the inequality that the multilinear extension of any submodular set function is bounded from below by its Lovasz extension. Our second contribution, therefore, is to remove this restriction and show that both algorithms can be extended to the continuous domain while retaining the same approximation ratios, and hence offering improved approximation ratios over those in Bian et al. (2017a). for the same problem. At last, we also include numerical experiments to demonstrate our algorithms on problems arising from machine learning and artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.09616v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shengminjie Chen, Donglei Du, Wenguo Yang, Dachuan Xu, Suixiang Gao</dc:creator>
    </item>
    <item>
      <title>Multi-Objective Optimization for Sparse Deep Multi-Task Learning</title>
      <link>https://arxiv.org/abs/2308.12243</link>
      <description>arXiv:2308.12243v4 Announce Type: replace-cross 
Abstract: Different conflicting optimization criteria arise naturally in various Deep Learning scenarios. These can address different main tasks (i.e., in the setting of Multi-Task Learning), but also main and secondary tasks such as loss minimization versus sparsity. The usual approach is a simple weighting of the criteria, which formally only works in the convex setting. In this paper, we present a Multi-Objective Optimization algorithm using a modified Weighted Chebyshev scalarization for training Deep Neural Networks (DNNs) with respect to several tasks. By employing this scalarization technique, the algorithm can identify all optimal solutions of the original problem while reducing its complexity to a sequence of single-objective problems. The simplified problems are then solved using an Augmented Lagrangian method, enabling the use of popular optimization techniques such as Adam and Stochastic Gradient Descent, while efficaciously handling constraints. Our work aims to address the (economical and also ecological) sustainability issue of DNN models, with a particular focus on Deep Multi-Task models, which are typically designed with a very large number of weights to perform equally well on multiple tasks. Through experiments conducted on two Machine Learning datasets, we demonstrate the possibility of adaptively sparsifying the model during training without significantly impacting its performance, if we are willing to apply task-specific adaptations to the network weights. Code is available at https://github.com/salomonhotegni/MDMTN</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12243v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. S. Hotegni, M. Berkemeier, S. Peitz</dc:creator>
    </item>
    <item>
      <title>Dual Conic Proxies for AC Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2310.02969</link>
      <description>arXiv:2310.02969v2 Announce Type: replace-cross 
Abstract: In recent years, there has been significant interest in the development of machine learning-based optimization proxies for AC Optimal Power Flow (AC-OPF). Although significant progress has been achieved in predicting high-quality primal solutions, no existing learning-based approach can provide valid dual bounds for AC-OPF. This paper addresses this gap by training optimization proxies for a convex relaxation of AC-OPF. Namely, the paper considers a second-order cone (SOC) relaxation of AC-OPF, and proposes \revision{a novel architecture} that embeds a fast, differentiable (dual) feasibility recovery, thus providing valid dual bounds. The paper combines this new architecture with a self-supervised learning scheme, which alleviates the need for costly training data generation. Extensive numerical experiments on medium- and large-scale power grids demonstrate the efficiency and scalability of the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02969v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guancheng Qiu, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Activations and Gradients Compression for Model-Parallel Training</title>
      <link>https://arxiv.org/abs/2401.07788</link>
      <description>arXiv:2401.07788v2 Announce Type: replace-cross 
Abstract: Large neural networks require enormous computational clusters of machines. Model-parallel training, when the model architecture is partitioned sequentially between workers, is a popular approach for training modern models. Information compression can be applied to decrease workers communication time, as it is often a bottleneck in such systems. This work explores how simultaneous compression of activations and gradients in model-parallel distributed training setup affects convergence. We analyze compression methods such as quantization and TopK compression, and also experiment with error compensation techniques. Moreover, we employ TopK with AQ-SGD per-batch error feedback approach. We conduct experiments on image classification and language model fine-tuning tasks. Our findings demonstrate that gradients require milder compression rates than activations. We observe that $K=10\%$ is the lowest TopK compression level, which does not harm model convergence severely. Experiments also show that models trained with TopK perform well only when compression is also applied during inference. We find that error feedback techniques do not improve model-parallel training compared to plain compression, but allow model inference without compression with almost no quality drop. Finally, when applied with the AQ-SGD approach, TopK stronger than with $ K=30\%$ worsens model performance significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07788v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1134/S1064562423701314</arxiv:DOI>
      <dc:creator>Mikhail Rudakov, Aleksandr Beznosikov, Yaroslav Kholodov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>A note on weak compactness of occupation measures for an absorbing Markov decision process</title>
      <link>https://arxiv.org/abs/2402.10672</link>
      <description>arXiv:2402.10672v2 Announce Type: replace-cross 
Abstract: We consider an absorbing Markov decision process with a discrete time parameter with Borel state and action spaces. We study the issue of the set of occupation measures being compact for the weak topology and its relation to the control model being uniformly absorbing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10672v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Dufour, Tom\'as Prieto-Rumeau</dc:creator>
    </item>
    <item>
      <title>Stochastic Approximation with Delayed Updates: Finite-Time Rates under Markovian Sampling</title>
      <link>https://arxiv.org/abs/2402.11800</link>
      <description>arXiv:2402.11800v2 Announce Type: replace-cross 
Abstract: Motivated by applications in large-scale and multi-agent reinforcement learning, we study the non-asymptotic performance of stochastic approximation (SA) schemes with delayed updates under Markovian sampling. While the effect of delays has been extensively studied for optimization, the manner in which they interact with the underlying Markov process to shape the finite-time performance of SA remains poorly understood. In this context, our first main contribution is to show that under time-varying bounded delays, the delayed SA update rule guarantees exponentially fast convergence of the \emph{last iterate} to a ball around the SA operator's fixed point. Notably, our bound is \emph{tight} in its dependence on both the maximum delay $\tau_{max}$, and the mixing time $\tau_{mix}$. To achieve this tight bound, we develop a novel inductive proof technique that, unlike various existing delayed-optimization analyses, relies on establishing uniform boundedness of the iterates. As such, our proof may be of independent interest. Next, to mitigate the impact of the maximum delay on the convergence rate, we provide the first finite-time analysis of a delay-adaptive SA scheme under Markovian sampling. In particular, we show that the exponent of convergence of this scheme gets scaled down by $\tau_{avg}$, as opposed to $\tau_{max}$ for the vanilla delayed SA rule; here, $\tau_{avg}$ denotes the average delay across all iterations. Moreover, the adaptive scheme requires no prior knowledge of the delay sequence for step-size tuning. Our theoretical findings shed light on the finite-time effects of delays for a broad class of algorithms, including TD learning, Q-learning, and stochastic gradient descent under Markovian sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11800v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arman Adibi, Nicolo Dal Fabbro, Luca Schenato, Sanjeev Kulkarni, H. Vincent Poor, George J. Pappas, Hamed Hassani, Aritra Mitra</dc:creator>
    </item>
  </channel>
</rss>
