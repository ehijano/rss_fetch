<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 Jan 2026 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-User Content Diversity in Wireless Networks</title>
      <link>https://arxiv.org/abs/2601.16323</link>
      <description>arXiv:2601.16323v1 Announce Type: new 
Abstract: Immersive applications such as eXtended Reality (XR), cloud gaming, and real-time video streaming are central to the vision of 6G networks. These applications require not only low latency and high data rates, but also consistent and high-quality User Experience (UX). Traditional rate allocation and congestion control mechanisms in wireless networks treat users uniformly based on channel conditions, rely only on network-centric Key Performance Indicators (KPIs), and ignore the content diversity, which can lead to inefficient resource utilization and degraded UX. In this paper, we introduce the concept of Multi-User Content Diversity, which recognizes that different users concurrently consume media with varying complexity, and therefore have different bitrate requirements to achieve satisfactory UX. We propose multiple different frameworks that exploit multi-user content diversity and lead to overall network-wide gains in terms of UX. For each framework, we demonstrate the required information exchange between Application Servers (ASs), Application Clients (ACs), and the network, and the algorithms that run in each of these components to optimize a network-wide UXbased objective. Simulation results demonstrate that exploiting multi-user content diversity leads to significant gains in UX capacity, UX fairness, and network utilization, when compared to conventional rate control methods. These findings highlight the potential of content-aware networking as a key enabler for emerging wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16323v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Belal Korany, Peerapol Tinnakornsrisuphap, Saadallah Kassir, Prashanth Hande, Hyun Yong Lee, Thomas Stockhammer, Hemanth Sampath</dc:creator>
    </item>
    <item>
      <title>UAV-Assisted Joint Data Collection and Wireless Power Transfer for Batteryless Sensor Networks</title>
      <link>https://arxiv.org/abs/2601.16533</link>
      <description>arXiv:2601.16533v1 Announce Type: new 
Abstract: The development of wireless power transfer (WPT) and Internet of Things (IoT) offers significant potential but faces challenges such as limited energy supply, dynamic environmental changes, and unstable transmission links. This paper presents an unmanned aerial vehicle (UAV)-assisted data collection and WPT scheme to support batteryless sensor (BLS) networks in remote areas. In this system, BLSs harvest energy from the UAV and utilize the harvested energy to transmit the collected data back to the UAV. The goal is to maximize the collected data volume and fairness index while minimizing the UAV energy consumption. To achieve these objectives, an optimization problem is formulated to jointly optimize the transmit power and UAV trajectory. Due to the non-convexity and dynamic nature of the problem, a deep reinforcement learning (DRL)-based algorithm is proposed to solve the problem. Specifically, this algorithm integrates prioritized experience replay and the performer module to enhance system stability and accelerate convergence. Simulation results demonstrate that the proposed approach consistently outperforms benchmark schemes in terms of collected data volume, fairness, and UAV energy consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16533v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Zhang, Aimin Wang, Geng Sun, Jiahui Li, Jiacheng Wang, Changyuan Zhao, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Predicting Networks Before They Happen: Experimentation on a Real-Time V2X Digital Twin</title>
      <link>https://arxiv.org/abs/2601.16559</link>
      <description>arXiv:2601.16559v1 Announce Type: new 
Abstract: Emerging safety-critical Vehicle-to-Everything (V2X) applications require networks to proactively adapt to rapid environmental changes rather than merely reacting to them. While Network Digital Twins (NDTs) offer a pathway to such predictive capabilities, existing solutions typically struggle to reconcile high-fidelity physical modeling with strict real-time constraints. This paper presents a novel, end-to-end real-time V2X Digital Twin framework that integrates live mobility tracking with deterministic channel simulation. By coupling the Tokyo Mobility Digital Twin-which provides live sensing and trajectory forecasting-with VaN3Twin-a full-stack simulator with ray tracing-we enable the prediction of network performance before physical events occur. We validate this approach through an experimental proof-of-concept deployed in Tokyo, Japan, featuring connected vehicles operating on 60 GHz links. Our results demonstrate the system's ability to predict Received Signal Strength (RSSI) with a maximum average error of 1.01 dB and reliably forecast Line-of-Sight (LoS) transitions within a maximum average end-to-end system latency of 250 ms, depending on the ray tracing level of detail. Furthermore, we quantify the fundamental trade-offs between digital model fidelity, computational latency, and trajectory prediction horizons, proving that high-fidelity and predictive digital twins are feasible in real-world urban environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16559v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Pegurri, Habu Shintaro, Francesco Linsalata, Wang Kui, Tao Yu, Eugenio Moro, Maiya Igarashi, Antonio Capone, Kei Sakaguchi</dc:creator>
    </item>
    <item>
      <title>Stochastic Modeling and Resource Dimensioning of Multi-Cellular Edge Intelligent Systems</title>
      <link>https://arxiv.org/abs/2601.16848</link>
      <description>arXiv:2601.16848v1 Announce Type: new 
Abstract: Edge intelligence enables AI inference at the network edge, co-located with or near the radio access network, rather than in centralized clouds or on mobile devices. It targets low-latency, resource-constrained applications with large data volumes, requiring tight integration of wireless access and on-site computing. Yet system performance and cost-efficiency hinge on joint pre-deployment dimensioning of radio and computational resources, especially under spatial and temporal uncertainty. Prior work largely emphasizes run-time allocation or relies on simplified models that decouple radio and computing, missing end-to-end correlations in large-scale deployments. This paper introduces a unified stochastic framework to dimension multi-cell edge-intelligent systems. We model network topology with Poisson point processes, capturing random user and base-station locations, inter-cell interference, distance-based fractional power control, and peak-power constraints. By combining this with queueing theory and empirical AI inference workload profiling, we derive tractable expressions for end-to-end offloading delay. These enable a non-convex joint optimization that minimizes deployment cost under statistical QoS guarantees, expressed through strict tail-latency and inference-accuracy constraints. We prove the problem decomposes into convex subproblems, yielding global optimality. Numerical results in noise- and interference-limited regimes identify cost-efficient design regions and configurations that cause under-utilization or user unfairness. Smaller cells reduce transmission delay but raise per-request computing cost due to weaker server multiplexing, whereas larger cells show the opposite trend. Densification reduces computational costs only when frequency reuse scales with base-station density; otherwise, sparser deployments improve fairness and efficiency in interference-limited settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16848v1</guid>
      <category>cs.NI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaume Anguera Peris, Joakim Jald\'en</dc:creator>
    </item>
    <item>
      <title>Evaluating Wi-Fi Performance for VR Streaming: A Study on Realistic HEVC Video Traffic</title>
      <link>https://arxiv.org/abs/2601.16950</link>
      <description>arXiv:2601.16950v1 Announce Type: new 
Abstract: Cloud-based Virtual Reality (VR) streaming presents significant challenges for 802.11 networks due to its high throughput and low latency requirements. When multiple VR users share a Wi-Fi network, the resulting uplink and downlink traffic can quickly saturate the channel. This paper investigates the capacity of 802.11 networks for supporting realistic VR streaming workloads across varying frame rates, bitrates, codec settings, and numbers of users. We develop an emulation framework that reproduces Air Light VR (ALVR) operation, where real HEVC video traffic is fed into an 802.11 simulation model. Our findings explore Wi-Fi's performance anomaly and demonstrate that Intra-refresh (IR) coding effectively reduces latency variability and improves QoS, supporting up to 4 concurrent VR users with Constant Bitrate (CBR) 100 Mbps before the channel is saturated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16950v1</guid>
      <category>cs.NI</category>
      <category>cs.MM</category>
      <category>eess.IV</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ferran Maura, Francesc Wilhelmi, Boris Bellalta</dc:creator>
    </item>
    <item>
      <title>A Large-Scale IPv6-Based Measurement of the Starlink Network</title>
      <link>https://arxiv.org/abs/2412.18243</link>
      <description>arXiv:2412.18243v3 Announce Type: replace 
Abstract: Low Earth Orbit (LEO) satellite networks have attracted considerable attention for their ability to deliver global, low-latency broadband Internet services. In this paper, we present a large-scale measurement study of the Starlink network, the largest LEO satellite constellation to date. We first propose an efficient method for discovering active Starlink user routers, identifying approximately 5.98 million IPv6 addresses across 208 regions in 165 countries. Compared to general-purpose IPv6 target generation algorithms, our router-centric approach achieves near-complete coverage and, to the best of our knowledge, yields the most comprehensive known set of active IPv6 addresses for Starlink user routers. Based on the discovered user routers, we further propose an efficient method for mapping the Starlink backbone network and uncover a topology consisting of 49 Points of Presence (PoPs) interconnected by 98 links. We conduct a detailed statistical analysis of active Starlink user routers and PoPs, and further characterize the IPv6 address assignment strategy adopted by the Starlink network. Finally, we analyze the latency of Starlink user routers, propose a method to distinguish different types of users within the same region using outside-in measurement, and identify the ongoing V2 Mini satellite deployment as a potential driver of the performance improvements. The dataset of the Starlink backbone network is publicly available at https://ki3.org.cn/#/starlink-network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18243v3</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingsen Wang, Xiaohui Zhang, Shuai Wang, Li Chen, Jinwei Zhao, Dan Li, Yong Jiang</dc:creator>
    </item>
    <item>
      <title>Can cloud-based VR streaming handle Wi-Fi OBSS contention?</title>
      <link>https://arxiv.org/abs/2507.07677</link>
      <description>arXiv:2507.07677v2 Announce Type: replace 
Abstract: This paper experimentally analyzes the negative impact of contention caused by neighboring Wi-Fi networks operating on overlapping channels on Virtual Reality (VR) streaming over Wi-Fi, focusing on scenarios of partial and full channel overlap within an 80 MHz channel. Our results show that (i) increasing the number of 80 MHz Overlapping Basic Service Sets (OBSSs) intensifies contention and degrades VR streaming performance; (ii) OBSS activity on the secondary-sided 40 MHz portion degrades performance more than activity on the primary-sided 40 MHz portion; (iii) for the same aggregate load, full channel overlap with two 40 MHz OBSS contenders is less detrimental than partial overlap with a single high-load 40 MHz contender, but more disruptive than full overlap with two 80 MHz contenders; and (iv) full channel overlap with two 40 MHz OBSS contenders has a smaller impact on VR streaming under symmetric traffic loads than under asymmetric loads. Moreover, our results demonstrate that our previously proposed Network-aware Step-wise adaptive bitrate algorithm for VR streaming (NeSt-VR) effectively mitigates performance degradation in OBSS environments, enabling VR streaming under heavier OBSS traffic conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07677v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Miguel Casasnovas, Marc Carrascosa-Zamacois, Boris Bellalta</dc:creator>
    </item>
    <item>
      <title>Optimal Oblivious Load-Balancing for Sparse Traffic in Large-Scale Satellite Networks</title>
      <link>https://arxiv.org/abs/2601.02537</link>
      <description>arXiv:2601.02537v2 Announce Type: replace 
Abstract: Oblivious load-balancing in networks involves routing traffic from sources to destinations using predetermined routes independent of the traffic, so that the maximum load on any link in the network is minimized. We investigate oblivious load-balancing schemes for a $N\times N$ torus network under sparse traffic where there are at most $k$ active source-destination pairs. We are motivated by the problem of load-balancing in large-scale LEO satellite networks, which can be modelled as a torus, where the traffic is known to be sparse and localized to certain hotspot areas. We formulate the problem as a linear program and show that no oblivious routing scheme can achieve a worst-case load lower than approximately $\frac{\sqrt{2k}}{4}$ when $1&lt;k \leq N^2/2$ and $\frac{N}{4}$ when $N^2/2\leq k\leq N^2$. Moreover, we demonstrate that the celebrated Valiant Load Balancing scheme is suboptimal under sparse traffic and construct an optimal oblivious load-balancing scheme that achieves the lower bound. Further, we discover a $\sqrt{2}$ multiplicative gap between the worst-case load of a non-oblivious routing and the worst-case load of any oblivious routing. The results can also be extended to general $N\times M$ tori with unequal link capacities along the vertical and horizontal directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02537v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rudrapatna Vallabh Ramakanth, Eytan Modiano</dc:creator>
    </item>
    <item>
      <title>Understanding Partial Reachability in the Internet Core</title>
      <link>https://arxiv.org/abs/2601.12196</link>
      <description>arXiv:2601.12196v2 Announce Type: replace 
Abstract: Routing strives to connect all the Internet, but compete: political pressure threatens routing fragmentation; architectural changes such as private clouds, carrier-grade NAT, and firewalls make connectivity conditional; and commercial disputes create partial reachability for days or years. This paper suggests *persistent, partial reachability is fundamental to the Internet* and an underexplored problem. We first *derive a conceptual definition of the Internet core* based on connectivity, not authority. We identify *peninsulas*: persistent, partial connectivity; and *islands*: when computers are partitioned from the Internet core. Second, we develop algorithms to observe each across the Internet, and apply them to two existing measurement systems: Trinocular, where 6 locations observe 5M networks frequently, and RIPE Atlas, where 13k locations scan the DNS roots frequently. Cross-validation shows our findings are stable over *three years of data*, and consistent with as few as 3 geographically-distributed observers. We validate peninsulas and islands against CAIDA Ark, showing good recall (0.94) and bounding precision between 0.42 and 0.82. Finally, our work has broad practical impact: we show that *peninsulas are more common than Internet outages*. Factoring out peninsulas and islands as noise can *improve existing measurement systems*; their ``noise'' is $5\times$ to $9.7\times$ larger than the operational events in RIPE's DNSmon. We show that most peninsula events are routing transients (45\%), but most peninsula-time (90\%) is due to a few (7\%) long-lived events. Our work helps inform Internet policy and governance, with our neutral definition showing no single country or organization can unilaterally control the Internet core.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12196v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.4230/OASIcs.NINeS.2026.4</arxiv:DOI>
      <dc:creator>Guillermo Baltra, Tarang Saluja, Yuri Pradkin, John Heidemann</dc:creator>
    </item>
  </channel>
</rss>
