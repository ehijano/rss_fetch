<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Apr 2024 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generalized multi-view model: Adaptive density estimation under low-rank constraints</title>
      <link>https://arxiv.org/abs/2404.17209</link>
      <description>arXiv:2404.17209v1 Announce Type: new 
Abstract: We study the problem of bivariate discrete or continuous probability density estimation under low-rank constraints.For discrete distributions, we assume that the two-dimensional array to estimate is a low-rank probability matrix.In the continuous case, we assume that the density with respect to the Lebesgue measure satisfies a generalized multi-view model, meaning that it is $\beta$-H{\"o}lder and can be decomposed as a sum of $K$ components, each of which is a product of one-dimensional functions.In both settings, we propose estimators that achieve, up to logarithmic factors, the minimax optimal convergence rates under such low-rank constraints.In the discrete case, the proposed estimator is adaptive to the rank $K$. In the continuous case, our estimator converges with the $L_1$ rate $\min((K/n)^{\beta/(2\beta+1)}, n^{-\beta/(2\beta+2)})$ up to logarithmic factors, and it is adaptive to the unknown support as well as to the smoothness $\beta$ and to the unknown number of separable components $K$.  We present efficient algorithms for computing our estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17209v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Chhor (TSE-R), Olga Klopp (CREST-INSEE), Alexandre Tsybakov (CREST-INSEE)</dc:creator>
    </item>
    <item>
      <title>Pseudo-Observations and Super Learner for the Estimation of the Restricted Mean Survival Time</title>
      <link>https://arxiv.org/abs/2404.17211</link>
      <description>arXiv:2404.17211v1 Announce Type: new 
Abstract: In the context of right-censored data, we study the problem of predicting the restricted time to event based on a set of covariates. Under a quadratic loss, this problem is equivalent to estimating the conditional Restricted Mean Survival Time (RMST). To that aim, we propose a flexible and easy-to-use ensemble algorithm that combines pseudo-observations and super learner. The classical theoretical results of the super learner are extended to right-censored data, using a new definition of pseudo-observations, the so-called split pseudo-observations. Simulation studies indicate that the split pseudo-observations and the standard pseudo-observations are similar even for small sample sizes. The method is applied to maintenance and colon cancer datasets, showing the interest of the method in practice, as compared to other prediction methods. We complement the predictions obtained from our method with our RMST-adapted risk measure, prediction intervals and variable importance measures developed in a previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17211v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariane Cwiling (MAP5 - UMR 8145), Vittorio Perduca (MAP5 - UMR 8145), Olivier Bouaziz (MAP5 - UMR 8145)</dc:creator>
    </item>
    <item>
      <title>Asymptotic analysis for covariance parameter estimation of Gaussian processes with functional inputs</title>
      <link>https://arxiv.org/abs/2404.17222</link>
      <description>arXiv:2404.17222v1 Announce Type: new 
Abstract: We consider covariance parameter estimation for Gaussian processes with functional inputs. From an increasing-domain asymptotics perspective, we prove the asymptotic consistency and normality of the maximum likelihood estimator. We extend these theoretical guarantees to encompass scenarios accounting for approximation errors in the inputs, which allows robustness of practical implementations relying on conventional sampling methods or projections onto a functional basis. Loosely speaking, both consistency and normality hold when the approximation error becomes negligible, a condition that is often achieved as the number of samples or basis functions becomes large. These later asymptotic properties are illustrated through analytical examples, including one that covers the case of non-randomly perturbed grids, as well as several numerical illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17222v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Reding (CERAMATHS), Andr\'es Felipe L\'opez-Lopera (CERAMATHS), Fran\c{c}ois Bachoc (IMT)</dc:creator>
    </item>
    <item>
      <title>Comparison results for Markov tree distributions</title>
      <link>https://arxiv.org/abs/2404.17441</link>
      <description>arXiv:2404.17441v1 Announce Type: new 
Abstract: We develop comparison results for Markov tree distributions extending ordering results from the literature on discrete time Markov processes and recently studied ordering results for conditionally independent factor models to tree structures. Based on fairly natural positive dependence conditions, our main contribution is a comparison result with respect to the supermodular order. Since this order is a pure dependence order, it has many applications in optimal transport, finance, and insurance. As an illustrative example, we consider hidden Markov models and study distributional robustness for functionals of the random walk under model uncertainty. Further, we show that, surprisingly, more general comparison results via the recently established rearrangement-based Schur order for conditional distributions, which implies an ordering of Chatterjee's rank correlation, do not carry over from star structures to trees. Several examples and a detailed discussion of the assumptions demonstrate the generality of our results and provide further insights into the behavior of multidimensional distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17441v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Ansari, Moritz Ritter</dc:creator>
    </item>
    <item>
      <title>On Elliptical and Inverse Elliptical Wishart distributions: Review, new results, and applications</title>
      <link>https://arxiv.org/abs/2404.17468</link>
      <description>arXiv:2404.17468v1 Announce Type: new 
Abstract: This paper deals with matrix-variate distributions, from Wishart to Inverse Elliptical Wishart distributions over the set of symmetric definite positive matrices. Similar to the multivariate scenario, (Inverse) Elliptical Wishart distributions form a vast and general family of distributions, encompassing, for instance, Wishart or $t$-Wishart ones. The first objective of this study is to present a unified overview of Wishart, Inverse Wishart, Elliptical Wishart, and Inverse Elliptical Wishart distributions through their fundamental properties. This involves leveraging the stochastic representation of these distributions to establish key statistical properties of the Normalized Wishart distribution. Subsequently, this enables the computation of expectations, variances, and Kronecker moments for Elliptical Wishart and Inverse Elliptical Wishart distributions. As an illustrative application, the practical utility of these generalized Elliptical Wishart distributions is demonstrated using a real electroencephalographic dataset. This showcases their effectiveness in accurately modeling heterogeneous data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17468v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Imen Ayadi, Florent Bouchard, Fr\'ed\'eric Pascal</dc:creator>
    </item>
    <item>
      <title>Computationally Efficient Algorithms for Simulating Isotropic Gaussian Random Fields on Graphs with Euclidean Edges</title>
      <link>https://arxiv.org/abs/2404.17491</link>
      <description>arXiv:2404.17491v1 Announce Type: new 
Abstract: This work addresses the problem of simulating Gaussian random fields that are continuously indexed over a class of metric graphs, termed graphs with Euclidean edges, being more general and flexible than linear networks. We introduce three general algorithms that allow to reconstruct a wide spectrum of random fields having a covariance function that depends on a specific metric, called resistance metric, and proposed in recent literature. The algorithms are applied to a synthetic case study consisting of a street network. They prove to be fast and accurate in that they reproduce the target covariance function and provide random fields whose finite-dimensional distributions are approximately Gaussian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17491v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alfredo Alegr\'ia, Xavier Emery, Tobia Filosi, Emilio Porcu</dc:creator>
    </item>
    <item>
      <title>On uncertainty-penalized Bayesian information criterion</title>
      <link>https://arxiv.org/abs/2404.16881</link>
      <description>arXiv:2404.16881v1 Announce Type: cross 
Abstract: The uncertainty-penalized information criterion (UBIC) has been proposed as a new model-selection criterion for data-driven partial differential equation (PDE) discovery. In this paper, we show that using the UBIC is equivalent to employing the conventional BIC to a set of overparameterized models derived from the potential regression models of different complexity measures. The result indicates that the asymptotic property of the UBIC and BIC holds indifferently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16881v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pongpisit Thanasutives, Ken-ichi Fukui</dc:creator>
    </item>
    <item>
      <title>A Notion of Uniqueness for the Adversarial Bayes Classifier</title>
      <link>https://arxiv.org/abs/2404.16956</link>
      <description>arXiv:2404.16956v1 Announce Type: cross 
Abstract: We propose a new notion of uniqueness for the adversarial Bayes classifier in the setting of binary classification. Analyzing this notion of uniqueness produces a simple procedure for computing all adversarial Bayes classifiers for a well-motivated family of one dimensional data distributions. This characterization is then leveraged to show that as the perturbation radius increases, certain notions of regularity improve for adversarial Bayes classifiers. We demonstrate with various examples that the boundary of the adversarial Bayes classifier frequently lies near the boundary of the Bayes classifier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16956v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natalie S. Frank</dc:creator>
    </item>
    <item>
      <title>Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier</title>
      <link>https://arxiv.org/abs/2404.17358</link>
      <description>arXiv:2404.17358v1 Announce Type: cross 
Abstract: Adversarial training is a common technique for learning robust classifiers. Prior work showed that convex surrogate losses are not statistically consistent in the adversarial context -- or in other words, a minimizing sequence of the adversarial surrogate risk will not necessarily minimize the adversarial classification error. We connect the consistency of adversarial surrogate losses to properties of minimizers to the adversarial classification risk, known as \emph{adversarial Bayes classifiers}. Specifically, under reasonable distributional assumptions, a convex loss is statistically consistent for adversarial learning iff the adversarial Bayes classifier satisfies a certain notion of uniqueness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17358v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natalie S. Frank</dc:creator>
    </item>
    <item>
      <title>Boosting e-BH via conditional calibration</title>
      <link>https://arxiv.org/abs/2404.17562</link>
      <description>arXiv:2404.17562v1 Announce Type: cross 
Abstract: The e-BH procedure is an e-value-based multiple testing procedure that provably controls the false discovery rate (FDR) under any dependence structure between the e-values. Despite this appealing theoretical FDR control guarantee, the e-BH procedure often suffers from low power in practice. In this paper, we propose a general framework that boosts the power of e-BH without sacrificing its FDR control under arbitrary dependence. This is achieved by the technique of conditional calibration, where we take as input the e-values and calibrate them to be a set of "boosted e-values" that are guaranteed to be no less -- and are often more -- powerful than the original ones. Our general framework is explicitly instantiated in three classes of multiple testing problems: (1) testing under parametric models, (2) conditional independence testing under the model-X setting, and (3) model-free conformalized selection. Extensive numerical experiments show that our proposed method significantly improves the power of e-BH while continuing to control the FDR. We also demonstrate the effectiveness of our method through an application to an observational study dataset for identifying individuals whose counterfactuals satisfy certain properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17562v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junu Lee, Zhimei Ren</dc:creator>
    </item>
    <item>
      <title>Minimax rate for multivariate data under componentwise local differential privacy constraints</title>
      <link>https://arxiv.org/abs/2305.10416</link>
      <description>arXiv:2305.10416v2 Announce Type: replace 
Abstract: Our research delves into the balance between maintaining privacy and preserving statistical accuracy when dealing with multivariate data that is subject to \textit{componentwise local differential privacy} (CLDP). With CLDP, each component of the private data is made public through a separate privacy channel. This allows for varying levels of privacy protection for different components or for the privatization of each component by different entities, each with their own distinct privacy policies. We develop general techniques for establishing minimax bounds that shed light on the statistical cost of privacy in this context, as a function of the privacy levels $\alpha_1, ... , \alpha_d$ of the $d$ components. We demonstrate the versatility and efficiency of these techniques by presenting various statistical applications. Specifically, we examine nonparametric density and covariance estimation under CLDP, providing upper and lower bounds that match up to constant factors, as well as an associated data-driven adaptive procedure. Furthermore, we quantify the probability of extracting sensitive information from one component by exploiting the fact that, on another component which may be correlated with the first, a smaller degree of privacy protection is guaranteed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10416v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Amorino, Arnaud Gloter</dc:creator>
    </item>
    <item>
      <title>Nonparametric consistency for maximum likelihood estimation and clustering based on mixtures of elliptically-symmetric distributions</title>
      <link>https://arxiv.org/abs/2311.06108</link>
      <description>arXiv:2311.06108v4 Announce Type: replace 
Abstract: The consistency of the maximum likelihood estimator for mixtures of elliptically-symmetric distributions for estimating its population version is shown, where the underlying distribution $P$ is nonparametric and does not necessarily belong to the class of mixtures on which the estimator is based. In a situation where $P$ is a mixture of well enough separated but nonparametric distributions it is shown that the components of the population version of the estimator correspond to the well separated components of $P$. This provides some theoretical justification for the use of such estimators for cluster analysis in case that $P$ has well separated subpopulations even if these subpopulations differ from what the mixture model assumes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06108v4</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pietro Coretto, Christian Hennig</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification and Confidence Intervals for Naive Rare-Event Estimators</title>
      <link>https://arxiv.org/abs/2305.02434</link>
      <description>arXiv:2305.02434v2 Announce Type: replace-cross 
Abstract: We consider the estimation of rare-event probabilities using sample proportions output by naive Monte Carlo or collected data. Unlike using variance reduction techniques, this naive estimator does not have a priori relative efficiency guarantee. On the other hand, due to the recent surge of sophisticated rare-event problems arising in safety evaluations of intelligent systems, efficiency-guaranteed variance reduction may face implementation challenges which, coupled with the availability of computation or data collection power, motivate the use of such a naive estimator. In this paper we study the uncertainty quantification, namely the construction, coverage validity and tightness of confidence intervals, for rare-event probabilities using only sample proportions. In addition to the known normality, Wilson's and exact intervals, we investigate and compare them with two new intervals derived from Chernoff's inequality and the Berry-Esseen theorem. Moreover, we generalize our results to the natural situation where sampling stops by reaching a target number of rare-event hits. Our findings show that the normality and Wilson's intervals are not always valid, but they are close to the newly developed valid intervals in terms of half-width. In contrast, the exact interval is conservative, but safely guarantees the attainment of the nominal confidence level. Our new intervals, while being more conservative than the exact interval, provide useful insights in understanding the tightness of the considered intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.02434v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanlu Bai, Henry Lam</dc:creator>
    </item>
  </channel>
</rss>
