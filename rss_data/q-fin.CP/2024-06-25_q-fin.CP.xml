<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Jun 2024 04:03:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Deep Bellman Hedging</title>
      <link>https://arxiv.org/abs/2207.00932</link>
      <description>arXiv:2207.00932v4 Announce Type: replace 
Abstract: We present an actor-critic-type reinforcement learning algorithm for solving the problem of hedging a portfolio of financial instruments such as securities and over-the-counter derivatives using purely historic data. The key characteristics of our approach are: the ability to hedge with derivatives such as forwards, swaps, futures, options; incorporation of trading frictions such as trading cost and liquidity constraints; applicability for any reasonable portfolio of financial instruments; realistic, continuous state and action spaces; and formal risk-adjusted return objectives. Most importantly, the trained model provides an optimal hedge for arbitrary initial portfolios and market states without the need for re-training. We also prove existence of finite solutions to our Bellman equation, and show the relation to our vanilla Deep Hedging approach</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.00932v4</guid>
      <category>q-fin.CP</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hans Buehler, Phillip Murray, Ben Wood</dc:creator>
    </item>
    <item>
      <title>Learning parameter dependence for Fourier-based option pricing with tensor trains</title>
      <link>https://arxiv.org/abs/2405.00701</link>
      <description>arXiv:2405.00701v5 Announce Type: replace 
Abstract: A long-standing issue in mathematical finance is the speed-up of pricing options, especially multi-asset options. A recent study has proposed to use tensor train learning algorithms to speed up Fourier transform (FT)-based option pricing, utilizing the ability of tensor networks to compress high-dimensional tensors. Another usage of the tensor network is to compress functions, including their parameter dependence. In this study, we propose a pricing method, where, by a tensor learning algorithm, we build tensor trains that approximate functions appearing in FT-based option pricing with their parameter dependence and efficiently calculate the option price for the varying input parameters. As a benchmark test, we run the proposed method to price a multi-asset option for the various values of volatilities and present asset prices. We show that, in the tested cases involving up to 11 assets, the proposed method is comparable to or outperforms Monte Carlo simulation with $10^5$ paths in terms of computational complexity, keeping the comparable accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00701v5</guid>
      <category>q-fin.CP</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rihito Sakurai, Haruto Takahashi, Koichi Miyamoto</dc:creator>
    </item>
  </channel>
</rss>
