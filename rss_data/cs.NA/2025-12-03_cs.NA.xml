<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Dec 2025 05:02:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Trefftz Continuous Galerkin method for Helmholtz problems</title>
      <link>https://arxiv.org/abs/2512.02145</link>
      <description>arXiv:2512.02145v1 Announce Type: new 
Abstract: This work introduces a novel Trefftz Continuous Galerkin (TCG) method for 2D Helmholtz problems based on evanescent plane waves (EPWs). We construct a new globally-conforming discrete space, departing from standard discontinuous Trefftz formulations, and investigate its approximation properties, providing wavenumber-explicit best-approximation error estimates. The mesh is defined by intersecting the domain with a Cartesian grid, and the basis functions are continuous in the whole computational domain, compactly supported, and can be expressed as simple linear combinations of EPWs within each element. This ensures they remain local solutions to the Helmholtz equation and allows the system matrix to be assembled in closed form for polygonal domains. The discrete space provides stable approximations with bounded coefficients and spectral accuracy for analytic Helmholtz solutions. The approximation error is proved to decay exponentially both at a fixed frequency, with respect to the discretization parameters, and along suitable sequences of increasing wavenumbers, with the number of degrees of freedom scaling linearly with the frequency. Numerical results confirm these theoretical estimates for the full Galerkin error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02145v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Galante, Bruno Despr\'es, Emile Parolin</dc:creator>
    </item>
    <item>
      <title>Sampling on Metric Graphs</title>
      <link>https://arxiv.org/abs/2512.02175</link>
      <description>arXiv:2512.02175v1 Announce Type: new 
Abstract: Metric graphs are structures obtained by associating edges in a standard graph with segments of the real line and gluing these segments at the vertices of the graph. The resulting structure has a natural metric that allows for the study of differential operators and stochastic processes on the graph. Brownian motions in these domains have been extensively studied theoretically using their generators. However, less work has been done on practical algorithms for simulating these processes. We introduce the first algorithm for simulating Brownian motions on metric graphs through a timestep splitting Euler-Maruyama-based discretization of their corresponding stochastic differential equation. By applying this scheme to Langevin diffusions on metric graphs, we also obtain the first algorithm for sampling on metric graphs. We provide theoretical guarantees on the number of timestep splittings required for the algorithm to converge to the underlying stochastic process. We also show that the exit probabilities of the simulated particle converge to the vertex-edge jump probabilities of the underlying stochastic differential equation as the timestep goes to zero. Finally, since this method is highly parallelizable, we provide fast, memory-aware implementations of our algorithm in the form of custom CUDA kernels that are up to ~8000x faster than a GPU implementation using PyTorch on simple star metric graphs. Beyond simple star graphs, we benchmark our algorithm on a real cortical vascular network extracted from a DuMuX tissue-perfusion model for tracer transport. Our algorithm is able to run stable simulations with timesteps significantly larger than the stable limit of the finite volume method used in DuMuX while also achieving speedups of up to ~1500x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02175v1</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajat Vadiraj Dwaraknath, Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Two Variations on the XTrace Algorithm</title>
      <link>https://arxiv.org/abs/2512.02316</link>
      <description>arXiv:2512.02316v1 Announce Type: new 
Abstract: This paper studies two potential modifications of XTrace (Epperly et al., SIMAX 45(1):1-23, 2024), a randomized algorithm for estimating the trace of a matrix. The first is a variance reduction step that averages the output of XTrace over right-multiplications of the test vectors by random orthogonal matrices. The second is to form a low-rank approximation to the matrix using the whole Krylov space produced by the test vectors, rather than the output of a single power iteration as is used by XTrace. Experiments on synthetic data show that the first modification offers only slight benefits in practice, while the second can lead to significant improvements depending on the spectrum of the matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02316v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Hallman</dc:creator>
    </item>
    <item>
      <title>Error estimates for semi-Lagrangian schemes with higher-order interpolation for conservation laws with dispersive terms</title>
      <link>https://arxiv.org/abs/2512.02390</link>
      <description>arXiv:2512.02390v1 Announce Type: new 
Abstract: We establish error estimates for semi-Lagrangian schemes for the initial value problem of one-dimensional conservation laws with a dispersive term, including the Korteweg--de Vries equation. The schemes considered in this paper are based on the semi-Lagrangian technique combined with spatial discretization by higher-order interpolation operators. For the semi-Lagrangian schemes equipped with the spline or Hermite interpolation operators of order $ 2 s - 1 $, we derive an $L^2$-error estimate of $ O (\Delta t^r + h^{2s} / \Delta t) $ and an $ H^s $-error estimate of $ O (\Delta t^r + h^{s} / \sqrt{\Delta t}) $, where $ h $ and $ \Delta t $ denote the spatial mesh size and the time step size, respectively, and $ r \in \lparen 0, 1\rbrack $ is a parameter determined by the discretization of the dispersive term. A key step in the analysis is to establish the stability of the interpolation operators. Under suitable assumptions, interpolation operators of order $ 2s - 1 $ are stable with respect to the $ H^s $-norm as well as a weighted $ H^s $-norm. The weighted $H^s$-norm depends on $h$ and $\Delta t$, and it reduces to the $L^2$-norm in the limit $ h \to 0 $.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02390v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haruki Takemura</dc:creator>
    </item>
    <item>
      <title>Numerical verification of PolyDG algebraic solvers for the pseudo-stress Stokes problem</title>
      <link>https://arxiv.org/abs/2512.02537</link>
      <description>arXiv:2512.02537v1 Announce Type: new 
Abstract: This work focuses on the development of efficient solvers for the pseudo-stress formulation of the unsteady Stokes problem, discretised by means of a discontinuous Galerkin method on polytopal grids (PolyDG). The introduction of the pseudo-stress variable is motivated by the growing interest in non-Newtonian flow models and coupled interface problems, where the stress field plays a fundamental role in the physical description. The space-time discretisation of the problem is obtained by combining the PolyDG approach in space with the implicit Euler method for time integration. The resulting linear system, characterised by a symmetric, positive, definite matrix, exhibits deteriorating convergence with standard solvers as the time step decreases. To address this issue, we investigate two tailored strategies: deflated Conjugate Gradient, which mitigates the effect of the most problematic eigenmodes, and collective Block-Jacobi, which exploits the block structure of the system matrix. Numerical experiments show that both approaches yield iteration counts effectively independent of $\Delta t$, ensuring robust performance with respect to the time step. Future work will focus on extending this robustness to the spatial discretisation parameter $h$ by integrating multigrid strategies with the time-robust solvers developed in this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02537v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paola F. Antonietti, Alessandra Cancrini, Gabriele Ciaramella</dc:creator>
    </item>
    <item>
      <title>Multigrid p-Robustness at Jacobi Speeds: Efficient Matrix-Free Implementation of Local p-Multigrid Solvers</title>
      <link>https://arxiv.org/abs/2512.02577</link>
      <description>arXiv:2512.02577v1 Announce Type: new 
Abstract: Vertex-patch smoothers are essential for the robust convergence of geometric multigrid methods in high-order finite element applications, yet their adoption is traditionally hindered by the prohibitive cost of solving local patch problems. This paper presents a high-performance, matrix-free implementation of a p-multigrid local solver that dismantles the trade-off between smoothing effectiveness and computational efficiency. We focus on the practical realization of this iterative approach, leveraging sum-factorization and explicit SIMD vectorization to minimize memory footprint and maximize arithmetic throughput. The performance analysis demonstrates that the solver effectively hides data-fetching latencies and maintains optimal $\mathcal{O}(p^d)$ memory scaling, even when dominated by geometric data on distorted meshes. The result is a robust smoother that rivals the execution speed of simple pointwise smoothers while preserving the convergence benefits of patch-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02577v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Micha{\l} Wichrowski</dc:creator>
    </item>
    <item>
      <title>An efficient fully decoupled finite element method with second-order accuracy for the micropolar Rayleigh-Benard convection system</title>
      <link>https://arxiv.org/abs/2512.02770</link>
      <description>arXiv:2512.02770v1 Announce Type: new 
Abstract: The micropolar Rayleigh-B{\'e}nard convection system, which consists of Navier-Stokes equations, the angular momentum equation, and the heat equation, is a strongly nonlinear, coupled, and saddle point structural multiphysics system. A second-order pressure projection finite element method, which is linear, fully decoupled, and second-order accurate in time, is proposed to simulate the system. Only a few decoupled linear elliptic problems with constant coefficients are solved at each time step, simplifying calculations significantly. The stability analysis of the method is established and the optimal error estimates are derived rigorously with the negative norm technique. Extensive numerical simulations, including 2D and 3D accuracy tests, the lid-driven cavity flow, and the passive-scalar mixing experiment, are carried out to illustrate the effectiveness of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02770v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Cui, Akang Hou, Xiaoyu Dong</dc:creator>
    </item>
    <item>
      <title>Preconditioning a hybridizable discontinuous Galerkin method for Navier-Stokes at high Reynolds number</title>
      <link>https://arxiv.org/abs/2512.02971</link>
      <description>arXiv:2512.02971v1 Announce Type: new 
Abstract: We introduce a preconditioner for a hybridizable discontinuous Galerkin discretization of the linearized Navier-Stokes equations at high Reynolds number. The preconditioner is based on an augmented Lagrangian approach of the full discretization. Unlike standard grad-div type augmentation, however, we consider augmentation based on divergence-conformity. With this augmentation we introduce two different, well-conditioned, and easy to solve matrices to approximate the trace pressure Schur complement. To introduce a completely algebraic solver, we propose to use multifrontal sparse LU solvers using butterfly compression to solve the trace velocity block. Numerical examples demonstrate that the trace pressure Schur complement is highly robust in mesh spacing and Reynolds number and that the multifrontal inexact LU performs well for a wide range of Reynolds numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02971v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alexander D. Lindsay, Sander Rhebergen, Ben S. Southworth</dc:creator>
    </item>
    <item>
      <title>Relaxation Schemes for Flows in Networks: Application to Shallow Water and Blood Flow Equations</title>
      <link>https://arxiv.org/abs/2512.02989</link>
      <description>arXiv:2512.02989v1 Announce Type: new 
Abstract: A numerical scheme of relaxation type is proposed to approximate hyperbolic conservation laws in canal networks. Physical conditions at the junction are given and a novel strategy based on [Briani, Natalini, Ribot, 2025] is introduced to approximate the solution, avoiding the use of approximate Riemann solvers. This general approach is applied to shallow water and blood flow equations, dealing both the subcritical and the supercritical case. The relaxation scheme is complemented with a well-balanced strategy to treat source terms. We investigate properties of the numerical scheme and we present many numerical tests in different settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02989v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tommaso Tenna</dc:creator>
    </item>
    <item>
      <title>Simulation and inference methods for non-Markovian stochastic biochemical reaction networks</title>
      <link>https://arxiv.org/abs/2512.02478</link>
      <description>arXiv:2512.02478v1 Announce Type: cross 
Abstract: Stochastic models of biochemical reaction networks are widely used to capture intrinsic noise in cellular systems. The typical formulation of these models are based on Markov processes for which there is extensive research on efficient simulation and inference. However, there are biological processes, such as gene transcription and translation, that introduce history dependent dynamics requiring non-Markovian processes to accurately capture the stochastic dynamics of the system. This greater realism comes with additional computational challenges for simulation and parameter inference. We develop efficient stochastic simulation algorithms for well-mixed non-Markovian stochastic biochemical reaction networks with delays that depend on system state and time. Our methods generalize the next reaction method and $\tau$-leaping method to support arbitrary inter-event time distributions while preserving computational scalability. We also introduce a coupling scheme to generate exact non-Markovian sample paths that are positively correlated to an approximate non-Markovian $\tau$-leaping sample path. This enables substantial computational gains for Bayesian inference of model parameters though multifidelity simulation-based inference schemes. We demonstrate the effectiveness of our approach on a gene regulation model with delayed auto-inhibition, showing substantial gains in both simulation accuracy and inference efficiency of two orders of magnitude. These results extend the practical applicability of non-Markovian models in systems biology and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02478v1</guid>
      <category>q-bio.MN</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas P. Steele, David J. Warne</dc:creator>
    </item>
    <item>
      <title>A Note on the Conditions for COS Convergence</title>
      <link>https://arxiv.org/abs/2512.02745</link>
      <description>arXiv:2512.02745v1 Announce Type: cross 
Abstract: We study the truncation error of the COS method and give simple, verifiable conditions that guarantee convergence. In one dimension, COS is admissible when the density belongs to both L1 and L2 and has a finite weighted L2 moment of order strictly greater than one. We extend the result to multiple dimensions by requiring the moment order to exceed the dimension. These conditions enlarge the class of densities covered by previous analyses and include heavy-tailed distributions such as Student t with small degrees of freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02745v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinling Wang, Xiaoyu Shen, Fang Fang</dc:creator>
    </item>
    <item>
      <title>Pruning AMR: Efficient Visualization of Implicit Neural Representations via Weight Matrix Analysis</title>
      <link>https://arxiv.org/abs/2512.02967</link>
      <description>arXiv:2512.02967v1 Announce Type: cross 
Abstract: An implicit neural representation (INR) is a neural network that approximates a spatiotemporal function. Many memory-intensive visualization tasks, including modern 4D CT scanning methods, represent data natively as INRs. While INRs are prized for being more memory-efficient than traditional data stored on a lattice, many visualization tasks still require discretization to a regular grid. We present PruningAMR, an algorithm that builds a mesh with resolution adapted to geometric features encoded by the INR. To identify these geometric features, we use an interpolative decomposition pruning method on the weight matrices of the INR. The resulting pruned network is used to guide adaptive mesh refinement, enabling automatic mesh generation tailored to the underlying resolution of the function. Starting from a pre-trained INR--without access to its training data--we produce a variable resolution visualization with substantial memory savings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02967v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jennifer Zvonek, Andrew Gillette</dc:creator>
    </item>
    <item>
      <title>Analysis of the Single Reference Coupled Cluster Method for Electronic Structure Calculations: The Discrete Coupled Cluster Equations</title>
      <link>https://arxiv.org/abs/2311.00637</link>
      <description>arXiv:2311.00637v3 Announce Type: replace 
Abstract: Coupled cluster methods are widely regarded as the gold standard of computational quantum chemistry as they are perceived to offer the best compromise between computational cost and a high-accuracy resolution of the ground state eigenvalue of the electronic Hamiltonian-- an unbounded, self-adjoint operator acting on a Hilbert space of antisymmetric functions that describes electronic properties of molecular systems. The present contribution is the second in a series of two articles where we introduce a new numerical analysis of the single-reference coupled cluster method based on the invertibility of the coupled cluster Fr\'echet derivative. In this contribution, we study discretisations of the single-reference coupled cluster equations based on a prior mean-field (Hartree-Fock) calculation. We show that under some structural assumptions on the associated discretisation spaces and assuming that the discretisation is fine enough, the discrete coupled cluster equations are locally well-posed, and we derive a priori and residual-based a posteriori error estimates for the discrete coupled cluster solutions. Preliminary numerical experiments indicate that the structural assumptions that we impose for our analysis can be expected to hold for several small molecules and the theoretical constants that appear in our error estimates are an improvement over those obtained from earlier approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00637v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Hassan, Yvon Maday</dc:creator>
    </item>
    <item>
      <title>Optimal sampling for least squares approximation with general dictionaries</title>
      <link>https://arxiv.org/abs/2407.07814</link>
      <description>arXiv:2407.07814v3 Announce Type: replace 
Abstract: We consider the problem of approximating an unknown function from point evaluations. This problem is a crucial subproblem in many modern (nonlinear) approximation schemes. When obtaining these point evaluations is costly, minimising the required sample size becomes crucial. Recently, an increasing focus has been on employing importance sampling strategies to achieve this. For the approximation in a $d$-dimensional linear space, an optimal i.i.d. sampling measure achieves a sampling complexity of $\mathcal{O}(d\log (d))$. However, the corresponding sampling measure depends on an orthonormal basis of the linear space, which is rarely known (in particular in the context of nonlinear approximation where the linear space arises as a local linearisation of a nonlinear model class like neural networks or tensor networks). Consequently, sampling from these measures is challenging in practice. This manuscript presents a strategy for estimating an orthonormal basis. This strategy can be performed offline and does not require evaluations of the sought function. We establish convergence and illustrate the practical performance through numerical experiments. Comparing the presented approach with standard Monte Carlo sampling demonstrates a significant reduction in the number of samples required to achieve a good estimation of an orthonormal basis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07814v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Trunschke, Anthony Nouy</dc:creator>
    </item>
    <item>
      <title>Lower Bound on the Representation Complexity of Antisymmetric Tensor Product Functions</title>
      <link>https://arxiv.org/abs/2501.05958</link>
      <description>arXiv:2501.05958v3 Announce Type: replace 
Abstract: Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings reveal that low-rank TPFs are fundamentally unsuitable for high-dimensional problems where antisymmetry is essential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05958v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyang Wang, Yukuan Hu, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Sampling, approximation, and interpolation of differential forms by admissible integral k-meshes</title>
      <link>https://arxiv.org/abs/2504.05266</link>
      <description>arXiv:2504.05266v2 Announce Type: replace 
Abstract: In this work we introduce the concept of admissible integral $k$-mesh for sampling differential forms with contiuous coefficients on a real body $E\subset \R^n$, and provide two techniques for the construction of admissible integral $k$-meshes on real bodies enjoying the Markov or the Bernstein inequality. Admissible integral $k$-meshes allow for the construction of robust approximation schemes, and are used to extract interpolation sets with high stability properties. To this end, the concepts of Fekete currents and Leja sequences of currents are formalized, and a numerical scheme for their approximation is proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05266v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovico Bruni Bruno, Federico Piazzon</dc:creator>
    </item>
    <item>
      <title>Kernel interpolation on generalized sparse grids</title>
      <link>https://arxiv.org/abs/2505.12282</link>
      <description>arXiv:2505.12282v2 Announce Type: replace 
Abstract: We consider scattered data approximation on product regions of equal and different dimensionality. On each of these regions, we assume quasi-uniform but unstructured data sites and construct optimal sparse grids for scattered data interpolation on the product region. For this, we derive new improved error estimates for the respective kernel interpolation error by invoking duality arguments. An efficient algorithm to solve the underlying linear system of equations is proposed. The algorithm is based on the sparse grid combination technique, where a sparse direct solver is used for the elementary anisotropic tensor product kernel interpolation problems. The application of the sparse direct solver is facilitated by applying a samplet matrix compression to each univariate kernel matrix, resulting in an essentially sparse representation of the latter. In this way, we obtain a method that is able to deal with large problems up to billions of interpolation points, especially in case of reproducing kernels of nonlocal nature. Numerical results are presented to qualify and quantify the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12282v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Griebel, Helmut Harbrecht, Michael Multerer</dc:creator>
    </item>
    <item>
      <title>Scalable ADER-DG Transport Method with Polynomial Order Independent CFL Limit</title>
      <link>https://arxiv.org/abs/2507.07304</link>
      <description>arXiv:2507.07304v2 Announce Type: replace 
Abstract: Discontinuous Galerkin (DG) methods are known to suffer from increasingly restrictive explicit time-step constraints as the polynomial order increases, limiting their efficiency at high orders for explicit time-stepping schemes. In this paper, we introduce a novel \emph{locally implicit}, but \emph{globally explicit} ADER-DG scheme designed for transport-dominated problems. The method achieves a maximum stable time step governed by an element-width based CFL condition that is independent of the polynomial degree. By solving a set of element-local implicit problems at each time step, our approach more effectively utilises the domain of dependence. As a result, our method remains stable for CFL numbers up to $\approx 1/\sqrt{d}$ in $d$ spatial dimensions. We provide a rigorous stability proof in one dimension, and extend the analysis to two and three dimensions using a semi-analytical von Neumann stability analysis. The accuracy and convergence of the method are demonstrated through numerical experiments for both linear and nonlinear test cases, including numerical simulations of a transport problem on a cubed sphere 2D manifold embedded in 3D.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07304v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>physics.ao-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kieran Ricardo, Kenneth Duru</dc:creator>
    </item>
    <item>
      <title>SFEM for the unsteady Navier-Stokes Equations on a stationary surface</title>
      <link>https://arxiv.org/abs/2508.09266</link>
      <description>arXiv:2508.09266v2 Announce Type: replace 
Abstract: In this paper we consider a fully discrete numerical method for the unsteady Navier-Stokes equations on a smooth closed stationary surface in $\mathbb{R}^3$. We use the surface finite element method (SFEM) with a generalized Taylor-Hood finite element pair $\mathrm{\mathbf{P}}_{k_u}$-- $\mathrm{P}_{k_{pr}}$-- $\mathrm{P}_{k_{\lambda}}$, where we enforce the tangential condition of the velocity field weakly, by introducing an extra Lagrange multiplier $\lambda$. Depending on the richness of the finite element space involving this extra Lagrange multiplier we present a fully discrete stability and error analysis. For the velocity, we establish optimal $L^{2}(a_h)$-norm bounds ($a_h$ - an energy norm) when $k_\lambda=k_u$ and suboptimal with respect to the geometric approximation error when $k_{\lambda} = k_u-1$ (optimal when \emph{super-parametric finite elements} are used). For the pressure, optimal $L^2(L^2)$-norm error bounds are established when $k_\lambda=k_u$. Assuming further regularity assumptions for our continuous problem, we are also able to show optimal convergence (using \emph{super-parametric finite elements} again) when $k_\lambda=k_u-1$. Numerical simulations that confirm the established theory are provided, along with a comparative analysis against a penalty approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09266v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles M. Elliott, Achilleas Mavrakis</dc:creator>
    </item>
    <item>
      <title>Anderson Acceleration For Perturbed Newton Methods</title>
      <link>https://arxiv.org/abs/2508.12513</link>
      <description>arXiv:2508.12513v2 Announce Type: replace 
Abstract: We present a convergence theory for Anderson acceleration (AA) applied to perturbed Newton methods (pNMs) for computing roots of nonlinear problems. Two important special cases are the classical Newton method and the Levenberg-Marquardt method. We prove that if a problem is 2-regular, then Anderson accelerated pNMs coupled with a safeguarding scheme, known as $\gamma$-safeguarding, converge locally linearly in a starlike domain of convergence, but with an improved rate of convergence compared to standard perturbed Newton methods. Since Levenberg-Marquardt methods are a special case of pNMs, we obtain a novel acceleration and local convergence result for Anderson accelerated Levenberg-Marquardt. We further show that $\gamma$-safeguarding can detect if the underlying perturbed Newton method is converging superlinearly, and respond by tuning the Anderson step down. We demonstrate the methods on several benchmark problems in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12513v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3934/acse.2025024</arxiv:DOI>
      <arxiv:journal_reference>M. Dallas, Anderson acceleration for perturbed Newton methods, Advances in Computational Science and Engineering, 6 (2025), p. 57-75</arxiv:journal_reference>
      <dc:creator>Matt Dallas</dc:creator>
    </item>
    <item>
      <title>A Variational Framework for the Algorithmic Complexity of PDE Solutions</title>
      <link>https://arxiv.org/abs/2510.21290</link>
      <description>arXiv:2510.21290v2 Announce Type: replace 
Abstract: Partial Differential Equations (PDEs) are fundamental tools for modeling physical phenomena, yet most PDEs of practical interest cannot be solved analytically and require numerical approximations. The feasibility of such numerical methods, however, is ultimately constrained by the limitations of existing computation models. Since digital computers constitute the primary physical realizations of numerical computation, and Turing machines define their theoretical limits, the question of Turing computability of PDE solutions arises as a problem of fundamental theoretical significance. The Turing computability of PDE solutions provides a rigorous framework to distinguish equations that are, in principle, algorithmically solvable from those that inherently encode undecidable or non-computable behavior. Once computability is established, complexity theory extends the analysis by quantifying the computational resources required to approximate the corresponding PDE solutions. In this work, we present a novel framework based on least-squares variational formulations and their associated gradient flows to study the computability and complexity of PDE solutions from an optimization perspective. Our approach enables the approximation of PDE solution operators via discrete gradient flows, linking structural properties of the PDE, such as coercivity, ellipticity, and convexity, to the inherent complexity of their solutions. This framework characterizes both regimes where PDEs admit effective numerical solvers in polynomial-time and those exhibiting complexity blowup, where the input data possess polynomial-time complexity, yet the solution itself scales super-polynomially.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21290v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Esteban Suarez Cardona, Holger Boche, Gitta Kutyniok</dc:creator>
    </item>
    <item>
      <title>Error analysis of an acceleration corrected diffusion approximation of Langevin dynamics with background flow</title>
      <link>https://arxiv.org/abs/2512.00685</link>
      <description>arXiv:2512.00685v2 Announce Type: replace 
Abstract: We consider the problem of approximating the Langevin dynamics of inertial particles being transported by a background flow. In particular, we study an acceleration corrected advection-diffusion approximation to the Langevin dynamics, a popular approximation in the study of turbulent transport. We prove error estimates in the averaging regime in which the dimensionless relaxation timescale $\varepsilon$ is the small parameter. We show that for any finite time interval, the approximation error is of order $\mathcal{O}(\varepsilon)$ in the strong sense and $\mathcal{O}(\varepsilon^2)$ in the weak sense, whose optimality is checked against computational experiment. Furthermore, we present numerical evidence suggesting that this approximation also captures the long-time behavior of the Langevin dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00685v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoichiro Mori, Chanoknun Sintavanuruk, Truong-Son P. Van</dc:creator>
    </item>
    <item>
      <title>Mixture of Experts Softens the Curse of Dimensionality in Operator Learning</title>
      <link>https://arxiv.org/abs/2404.09101</link>
      <description>arXiv:2404.09101v2 Announce Type: replace-cross 
Abstract: We study the approximation-theoretic implications of mixture-of-experts architectures for operator learning, where the complexity of a single large neural operator is distributed across many small neural operators (NOs), and each input is routed to exactly one NO via a decision tree. We analyze how this tree-based routing and expert decomposition affect approximation power, sample complexity, and stability. Our main result is a distributed universal approximation theorem for mixture of neural operators (MoNOs): any Lipschitz nonlinear operator between $L^2([0,1]^d)$ spaces can be uniformly approximated over the Sobolev unit ball to arbitrary accuracy $\varepsilon&gt;0$ by an MoNO, where each expert NO has a depth, width, and rank scaling as $\mathcal{O}(\varepsilon^{-1})$. Although the number of experts may grow with accuracy, each NO remains small, enough to fit within active memory of standard hardware for reasonable accuracy levels. Our analysis also yields new quantitative approximation rates for classical NOs approximating uniformly continuous nonlinear operators uniformly on compact subsets of $L^2([0,1]^d)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09101v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasis Kratsios, Takashi Furuya, Jose Antonio Lara Benitez, Matti Lassas, Maarten de Hoop</dc:creator>
    </item>
    <item>
      <title>Mixed precision accumulation for neural network inference guided by componentwise forward error analysis</title>
      <link>https://arxiv.org/abs/2503.15568</link>
      <description>arXiv:2503.15568v2 Announce Type: replace-cross 
Abstract: This work proposes a mathematically founded mixed precision accumulation strategy for the inference of neural networks. Our strategy is based on a new componentwise forward error analysis that explains the propagation of errors in the forward pass of neural networks. Specifically, our analysis shows that the error in each component of the output of a linear layer is proportional to the condition number of the inner product between the weights and the input, multiplied by the condition number of the activation function. These condition numbers can vary widely from one component to the other, thus creating a significant opportunity to introduce mixed precision: each component should be accumulated in a precision inversely proportional to the product of these condition numbers. We propose a numerical algorithm that exploits this observation: it first computes all components in low precision, uses this output to estimate the condition numbers, and recomputes in higher precision only the components associated with large condition numbers. We test our algorithm on various networks and datasets and confirm experimentally that it can significantly improve the cost--accuracy tradeoff compared with uniform precision accumulation baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15568v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>El-Mehdi El Arar (PEQUAN), Silviu-Ioan Filip (TARAN), Theo Mary (PEQUAN), Elisa Riccietti (OCKHAM)</dc:creator>
    </item>
    <item>
      <title>Optimization in Theory and Practice</title>
      <link>https://arxiv.org/abs/2510.15734</link>
      <description>arXiv:2510.15734v2 Announce Type: replace-cross 
Abstract: Algorithms for continuous optimization problems have a rich history of design and innovation over the past several decades, in which mathematical analysis of their convergence and complexity properties plays a central role. Besides their theoretical properties, optimization algorithms are interesting also for their practical usefulness as computational tools for solving real-world problems. There are often gaps between the practical performance of an algorithm and what can be proved about it. These two facets of the field -- the theoretical and the practical -- interact in fascinating ways, each driving innovation in the other. This work focuses on the development of algorithms in two areas -- linear programming and unconstrained minimization of smooth functions -- outlining major algorithm classes in each area along with their theoretical properties and practical performance, and highlighting how advances in theory and practice have influenced each other in these areas. In discussing theory, we focus mainly on non-asymptotic complexity, which are upper bounds on the amount of computation required by a given algorithm to find an approximate solution of problems in a given class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15734v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen J. Wright</dc:creator>
    </item>
  </channel>
</rss>
