<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 02:23:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Complexity of Abduction in \L{}ukasiewicz Logic</title>
      <link>https://arxiv.org/abs/2507.13847</link>
      <description>arXiv:2507.13847v1 Announce Type: new 
Abstract: We explore the problem of explaining observations in contexts involving statements with truth degrees such as `the lift is loaded', `the symptoms are severe', etc. To formalise these contexts, we consider infinitely-valued {\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction problems and explanations in the language of {\L}ukasiewicz logic expanded with `interval literals' of the form $p\geq\mathbf{c}$, $p\leq\mathbf{c}$, and their negations that express the set of values a variable can have. We analyse the complexity of standard abductive reasoning tasks (solution recognition, solution existence, and relevance / necessity of hypotheses) in {\L}ukasiewicz logic for the case of the full language and for the case of theories containing only disjunctive clauses and show that in contrast to classical propositional logic, the abduction in the clausal fragment has lower complexity than in the general case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13847v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katsumi Inoue, Daniil Kozhemiachenko</dc:creator>
    </item>
    <item>
      <title>Application Placement with Constraint Relaxation</title>
      <link>https://arxiv.org/abs/2507.13895</link>
      <description>arXiv:2507.13895v1 Announce Type: new 
Abstract: Novel utility computing paradigms rely upon the deployment of multi-service applications to pervasive and highly distributed cloud-edge infrastructure resources. Deciding onto which computational nodes to place services in cloud-edge networks, as per their functional and non-functional constraints, can be formulated as a combinatorial optimisation problem. Most existing solutions in this space are not able to deal with \emph{unsatisfiable} problem instances, nor preferences, i.e. requirements that DevOps may agree to relax to obtain a solution. In this article, we exploit Answer Set Programming optimisation capabilities to tackle this problem. Experimental results in simulated settings show that our approach is effective on lifelike networks and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13895v1</guid>
      <category>cs.LO</category>
      <category>cs.DC</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damiano Azzolini, Marco Duca, Stefano Forti, Francesco Gallo, Antonio Ielo</dc:creator>
    </item>
    <item>
      <title>Bounded Inquisitive Logics: Sequent Calculi and Schematic Validity</title>
      <link>https://arxiv.org/abs/2507.13946</link>
      <description>arXiv:2507.13946v1 Announce Type: new 
Abstract: Propositional inquisitive logic is the limit of its $n$-bounded approximations. In the predicate setting, however, this does not hold anymore, as discovered by Ciardelli and Grilletti, who also found complete axiomatizations of $n$-bounded inquisitive logics $\mathsf{InqBQ}_{n}$, for every fixed $n$. We introduce cut-free labelled sequent calculi for these logics. We illustrate the intricacies of \textit{schematic validity} in such systems by showing that the well-known Casari formula is \textit{atomically} valid in (a weak sublogic of) predicate inquisitive logic $\mathsf{InqBQ}$, fails to be schematically valid in it, and yet is schematically valid under the finite boundedness assumption. The derivations in our calculi, however, are guaranteed to be schematically valid whenever a single specific rule is not used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13946v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tadeusz Litak, Katsuhiko Sano</dc:creator>
    </item>
    <item>
      <title>ChemLog: Making MSOL Viable for Ontological Classification and Learning</title>
      <link>https://arxiv.org/abs/2507.13987</link>
      <description>arXiv:2507.13987v1 Announce Type: new 
Abstract: Despite its prevalence, in many domains, OWL is not expressive enough to define ontology classes. In this paper, we present an approach that allows to use monadic second-order formalisations for ontology classification. As a case study, we have applied our approach to 14 peptide-related classes from the chemistry ontology ChEBI. For these classes, a monadic second-order logic formalisation has been developed and applied both to ChEBI as well as to 119 million molecules from the chemistry database PubChem. While this logical approach alone is limited to classification for the specified classes (in our case, (sub)classes of peptides), transformer deep learning models scale classification to the whole of the ChEBI ontology. We show that when using the classifications obtained by the logical approach as training data, the performance of the deep learning models can be significantly enhanced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13987v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Fl\"ugel, Martin Glauer, Till Mossakowski, Fabian Neuhaus</dc:creator>
    </item>
    <item>
      <title>SAQR-QC: A Logic for Scalable but Approximate Quantitative Reasoning about Quantum Circuits</title>
      <link>https://arxiv.org/abs/2507.13635</link>
      <description>arXiv:2507.13635v1 Announce Type: cross 
Abstract: Reasoning about quantum programs remains a fundamental challenge, regardless of the programming model or computational paradigm. Despite extensive research, existing verification techniques are insufficient--even for quantum circuits, a deliberately restricted model that lacks classical control, but still underpins many current quantum algorithms. Many existing formal methods require exponential time and space to represent and manipulate (representations of) assertions and judgments, making them impractical for quantum circuits with many qubits. This paper presents a logic for reasoning in such settings, called SAQR-QC. The logic supports Scalable but Approximate Quantitative Reasoning about Quantum Circuits, whence the name. SAQR-QC has three characteristics: (i) some (deliberate) loss of precision is built into it; (ii) it has a mechanism to help the accumulated loss of precision during a sequence of reasoning steps remain small; and (iii) most importantly, to make reasoning scalable, all reasoning steps are local--i.e., they each involve just a small number of qubits. We demonstrate the effectiveness of SAQR-QC via two case studies: the verification of GHZ circuits involving non-Clifford gates, and the analysis of quantum phase estimation--a core subroutine in Shor's factoring algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13635v1</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nengkun Yu, Jens Palsberg, Thomas Reps</dc:creator>
    </item>
    <item>
      <title>Intuitionistic monotone modal logic via translation</title>
      <link>https://arxiv.org/abs/2507.13746</link>
      <description>arXiv:2507.13746v1 Announce Type: cross 
Abstract: We introduce a monotone modal analogue of the intuitionistic (normal) modal logic IK using a translation into a suitable (intuitionistic) first-order logic. We axiomatise the logic and give a semantics by means of intuitionistic neighbourhood models, which contain neighbourhoods whose value can change when moving along the intuitionistic accessibility relation. We compare the resulting logic with other intuitionistic monotone modal logics and show how it can be embedded into a multimodal version of IK.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13746v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jim de Groot</dc:creator>
    </item>
    <item>
      <title>AdapTT: Functoriality for Dependent Type Casts</title>
      <link>https://arxiv.org/abs/2507.13774</link>
      <description>arXiv:2507.13774v1 Announce Type: cross 
Abstract: The ability to cast values between related types is a leitmotiv of many flavors of dependent type theory, such as observational type theories, subtyping, or cast calculi for gradual typing. These casts all exhibit a common structural behavior that boils down to the pervasive functoriality of type formers. We propose and extensively study a type theory, called AdapTT, which makes systematic and precise this idea of functorial type formers, with respect to an abstract notion of adapters relating types. Leveraging descriptions for functorial inductive types in AdapTT, we derive structural laws for type casts on general inductive type formers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13774v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Adjedj, Meven Lennon-Bertrand, Thibaut Benjamin, Kenji Maillard</dc:creator>
    </item>
    <item>
      <title>Towards Constraint Temporal Answer Set Programming</title>
      <link>https://arxiv.org/abs/2507.13958</link>
      <description>arXiv:2507.13958v1 Announce Type: cross 
Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric resolution presents significant challenges for logic-based approaches like Answer Set Programming (ASP). To address this, we introduce and elaborate upon a novel temporal and constraint-based extension of the logic of Here-and-There and its nonmonotonic equilibrium extension, representing, to the best of our knowledge, the first approach to nonmonotonic temporal reasoning with constraints specifically tailored for ASP. This expressive system is achieved by a synergistic combination of two foundational ASP extensions: the linear-time logic of Here-and-There, providing robust nonmonotonic temporal reasoning capabilities, and the logic of Here-and-There with constraints, enabling the direct integration and manipulation of numeric constraints, among others. This work establishes the foundational logical framework for tackling complex dynamic systems with high resolution within the ASP paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13958v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Cabalar, Mart\'in Di\'eguez, Fran\c{c}ois Olivier, Torsten Schaub, Igor St\'ephan</dc:creator>
    </item>
    <item>
      <title>Asynchronous Composition of LTL Properties over Infinite and Finite Traces</title>
      <link>https://arxiv.org/abs/2312.14831</link>
      <description>arXiv:2312.14831v3 Announce Type: replace 
Abstract: The verification of asynchronous software components poses significant challenges due to the way components interleave and exchange input/output data concurrently. Compositional strategies aim to address this by separating the task of verifying individual components on local properties from the task of combining them to achieve global properties. This paper concentrates on employing symbolic model checking techniques to verify properties specified in Linear-time Temporal Logic (LTL) on asynchronous software components that interact through data ports. Unlike event-based composition, local properties can now impose constraints on input from other components, increasing the complexity of their composition. We consider both the standard semantics over infinite traces as well as the truncated semantics over finite traces to allow scheduling components only finitely many times.
  We propose a novel LTL rewriting approach, which converts a local property into a global one while considering the interleaving of infinite or finite execution traces of components. We prove the semantic equivalence of local properties and their rewritten version projected on the local symbols. The rewriting is also optimized to reduce formula size and to leave it unchanged when the temporal property is stutter invariant. These methods have been integrated into the OCRA tool, as part of the contract refinement verification suite. Finally, the different composition approaches were compared through an experimental evaluation that covers various types of specifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14831v3</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Bombardelli, Stefano Tonetta</dc:creator>
    </item>
    <item>
      <title>Extensional and Non-extensional Functions as Processes</title>
      <link>https://arxiv.org/abs/2405.03536</link>
      <description>arXiv:2405.03536v3 Announce Type: replace 
Abstract: Following Milner's seminal paper, the representation of functions as processes has received considerable attention. For pure $\lambda$-calculus, the process representations yield (at best) non-extensional $\lambda $-theories (i.e., $\beta$ rule holds, whereas $\eta$ does not).
  In the paper, we study how to obtain extensional representations, and how to move between extensional and non-extensional representations. Using Internal $\pi$, $\mathrm{I}\pi$ (a subset of the $\pi$-calculus in which all outputs are bound), we develop a refinement of Milner's original encoding of functions as processes that is parametric on certain abstract components called wires. These are, intuitively, processes whose task is to connect two end-point channels. We show that when a few algebraic properties of wires hold, the encoding yields a $\lambda$-theory. Exploiting the symmetries and dualities of $\mathrm{I}\pi$, we isolate three main classes of wires. The first two have a sequential behaviour and are dual of each other; the third has a parallel behaviour and is the dual of itself. We show the adoption of the parallel wires yields an extensional $\lambda$-theory; in fact, it yields an equality that coincides with that of B\"ohm trees with infinite $\eta$. In contrast, the other two classes of wires yield non-extensional $\lambda$-theories whose equalities are those of the L\'evy-Longo and B\"ohm trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03536v3</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ken Sakayori, Davide Sangiorgi</dc:creator>
    </item>
    <item>
      <title>A Strongly Normalising System of Dependent Types for Transparent and Opaque Probabilistic Computation</title>
      <link>https://arxiv.org/abs/2406.17082</link>
      <description>arXiv:2406.17082v2 Announce Type: replace 
Abstract: We define an extension of lambda-calculus with dependents types that enables us to encode transparent and opaque probabilistic programs and prove a strong normalisation result for it by a reducibility technique. While transparent nondeterministic programs are formalised by rather usual techniques, opaque nondeterministic programs are formalised by introducing in the syntax oracle constants, the behaviour of which is governed by oracular functions. The generality of these functions and the fact that their values are determined by the form of the whole term inside which the relative oracle occurs also enable us to simulate learning-like behaviours. We then extend the calculus in order to define a computational trustworthiness predicate. The extension of the calculus does not only enable us to precisely formalise a notion of trustworthiness and to encode the procedures required to test it on programs, but also to reason, by means of the type system, on the behaviour of programs with respect to trustworthiness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17082v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco A. Genco</dc:creator>
    </item>
    <item>
      <title>An Algebraic Extension of Intuitionistic Linear Logic: The $L_!^S$-Calculus and Its Categorical Model</title>
      <link>https://arxiv.org/abs/2504.12128</link>
      <description>arXiv:2504.12128v2 Announce Type: replace 
Abstract: We introduce the $L_!^S$-calculus, a linear lambda-calculus extended with scalar multiplication and term addition, that acts as a proof language for intuitionistic linear logic (ILL). These algebraic operations enable the direct expression of linearity at the syntactic level, a property not typically available in standard proof-term calculi. Building upon previous work, we develop the $L_!^S$-calculus as an extension of the $L^S$-calculus with the $!$ modality. We prove key meta-theoretical properties--subject reduction, confluence, strong normalisation, and an introduction property--as well as preserve the expressiveness of the original $L^S$-calculus, including the encoding of vectors and matrices, and the correspondence between proof-terms and linear functions. A denotational semantics is provided in the framework of linear categories with biproducts, ensuring a sound and adequate interpretation of the calculus. This work is part of a broader programme aiming to build a measurement-free quantum programming language grounded in linear logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12128v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro D\'iaz-Caro, Malena Ivnisky, Octavio Malherbe</dc:creator>
    </item>
    <item>
      <title>Characterizing Equivalence of Logically Constrained Terms via Existentially Constrained Terms (Full Version)</title>
      <link>https://arxiv.org/abs/2505.21986</link>
      <description>arXiv:2505.21986v2 Announce Type: replace 
Abstract: Logically constrained term rewriting is a rewriting framework that supports built-in data structures such as integers and bit vectors. Recently, constrained terms play a key role in various analyses and applications of logically constrained term rewriting. A fundamental question on constrained terms arising there is how to characterize equivalence between them. However, in the current literature only limited progress has been made on this. In this paper, we provide several sound and complete solutions to tackle this problem. Our key idea is the introduction of a novel concept, namely existentially constrained terms, into which the original form of constrained terms can be embedded. We present several syntactic characterizations of equivalence between existentially constrained terms. In particular, we provide two different kinds of complete characterizations: one is designed to facilitate equivalence checking, while the other is intended for theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21986v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanta Takahata, Jonas Sch\"opf, Naoki Nishida, Takahito Aoto</dc:creator>
    </item>
    <item>
      <title>Recovering Commutation of Logically Constrained Rewriting and Equivalence Transformations (Full Version)</title>
      <link>https://arxiv.org/abs/2507.09326</link>
      <description>arXiv:2507.09326v2 Announce Type: replace 
Abstract: Logically constrained term rewriting is a relatively new rewriting formalism that naturally supports built-in data structures, such as integers and bit vectors. In the analysis of logically constrained term rewrite systems (LCTRSs), rewriting constrained terms plays a crucial role. However, this combines rewrite rule applications and equivalence transformations in a closely intertwined way. This intertwining makes it difficult to establish useful theoretical properties for this kind of rewriting and causes problems in implementations -- namely, that impractically large search spaces are often required. To address this issue, we propose in this paper a novel notion of most general constrained rewriting, which operates on existentially constrained terms, a concept recently introduced by the authors. We define a class of left-linear, left-value-free LCTRSs that are general enough to simulate all left-linear LCTRSs and exhibit the desired key property: most general constrained rewriting commutes with equivalence. This property ensures that equivalence transformations can be deferred until after the application of rewrite rules, which helps mitigate the issue of large search spaces in implementations. In addition to that, we show that the original rewriting formalism on constrained terms can be embedded into our new rewriting formalism on existentially constrained terms. Thus, our results are expected to have significant implications for achieving correct and efficient implementations in tools operating on LCTRSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09326v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanta Takahata, Jonas Sch\"opf, Naoki Nishida, Takahito Aoto</dc:creator>
    </item>
    <item>
      <title>A Quantum Programming Language for Coherent Control</title>
      <link>https://arxiv.org/abs/2507.10466</link>
      <description>arXiv:2507.10466v2 Announce Type: replace 
Abstract: We introduce a programming language that allows for the coherent control of arbitrary quantum operations. The problem of defining coherent control beyond the unitary case, using, for example, a quantum conditional in the presence of recursion or iteration has long been known to be a major difficulty. We resolve this problem by defining an operational semantics based on appropriate Kraus decompositions and a denotational semantics based on vacuum-extensions. We show that the language is universal for vacuum-extensions and that the two semantics are adequate. Moreover, we define a notion of observational equivalence: two programs are equivalent if their probability of termination is the same in any context. The denotational semantics is shown to be fully abstract for observational equivalence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10466v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kathleen Barsse, Romain P\'echoux, Simon Perdrix</dc:creator>
    </item>
    <item>
      <title>Frex: dependently-typed algebraic simplification</title>
      <link>https://arxiv.org/abs/2306.15375</link>
      <description>arXiv:2306.15375v2 Announce Type: replace-cross 
Abstract: We present a new design for an algebraic simplification library structured around concepts from universal algebra: theories, models, homomorphisms, and universal properties of free algebras and free extensions of algebras. The library's dependently typed interface guarantees that both built-in and user-defined simplification modules are terminating, sound, and complete with respect to a well-specified class of equations. We have implemented the design in the Idris 2 and Agda dependently typed programming languages and shown that it supports modular extension to new theories, proof extraction and certification, goal extraction via reflection, and interactive development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15375v2</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3747506</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Program. Lang. 9, ICFP, Article 237 (August 2025), 36 pages</arxiv:journal_reference>
      <dc:creator>Guillaume Allais, Edwin Brady, Nathan Corbyn, Ohad Kammar, Jeremy Yallop</dc:creator>
    </item>
    <item>
      <title>No Scratch Quantum Computing by Reducing Qubit Overhead for Efficient Arithmetics</title>
      <link>https://arxiv.org/abs/2506.17135</link>
      <description>arXiv:2506.17135v2 Announce Type: replace-cross 
Abstract: Quantum arithmetic computation requires a substantial number of scratch qubits to stay reversible. These operations necessitate qubit and gate resources equivalent to those needed for the larger of the input or output registers due to state encoding. Quantum Hamiltonian Computing (QHC) introduces a novel approach by encoding input for logic operations within a single rotating quantum gate. This innovation reduces the required qubit register $ N $ to the size of the output states $ O $, where $ N = \log_2 O $. Leveraging QHC principles, we present reversible half-adder and full-adder circuits that compress the standard Toffoli + CNOT layout [Vedral et al., PRA, 54, 11, (1996)] from three-qubit and four-qubit formats for the Quantum half-adder circuit and five sequential Fredkin gates using five qubits [Moutinho et al., PRX Energy 2, 033002 (2023)] for full-adder circuit; into a two-qubit, 4$\times $4 Hilbert space. This scheme, presented here, is optimized for classical logic evaluated on quantum hardware, which due to unitary evolution can bypass classical CMOS energy limitations to certain degree. Although we avoid superposition of input and output states in this manuscript, this remains feasible in principle. We see the best application for QHC in finding the minimal qubit and gate resources needed to evaluate any truth table, advancing FPGA capabilities using integrated quantum circuits or photonics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17135v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omid Faizy, Norbert Wehn, Paul Lukowicz, Maximilian Kiefer-Emmanouilidis</dc:creator>
    </item>
  </channel>
</rss>
