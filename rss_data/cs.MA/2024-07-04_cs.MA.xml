<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Enhancing Automotive User Experience with Dynamic Service Orchestration for Software Defined Vehicles</title>
      <link>https://arxiv.org/abs/2407.02491</link>
      <description>arXiv:2407.02491v1 Announce Type: new 
Abstract: With the increasing demand for dynamic behaviors in automotive use cases, Software Defined Vehicles (SDVs) have emerged as a promising solution by bringing dynamic onboard service management capabilities. While users may request a wide range of services during vehicle operation, background tasks such as cooperative Vehicle-to-Everything (V2X) services can activate on-the-fly in response to real-time road conditions. In this dynamic environment, the efficient allocation of onboard resources becomes a complex challenge, in order to meet mixed-criticality onboard Quality-of-Service (QoS) network requirements while ensuring an optimal user experience. Additionally, the ever-evolving real-time network connectivity and computational availability conditions further complicate the process. In this context, we present a dynamic resource-based onboard service orchestration algorithm that considers real-time in-vehicle and V2X network health, along with onboard resource constraints, to select degraded modes for onboard applications and maximize user experience. To enable dynamic orchestration, we introduce the concept of Automotive eXperience Integrity Level (AXIL) which expresses a runtime priority for non-safety-critical applications. This algorithm produces near-optimal solutions while significantly reducing execution time compared to straightforward methods as demonstrated by simulation results. With this approach, we aim to enable efficient onboard execution for a user experience-focused service orchestration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02491v1</guid>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Laclau (Heudiasyc), St\'ephane Bonnet (Heudiasyc), Bertrand Ducourthial (Heudiasyc), Xiaoting Li, Trista Lin</dc:creator>
    </item>
    <item>
      <title>A multi-objective combinatorial optimisation framework for large scale hierarchical population synthesis</title>
      <link>https://arxiv.org/abs/2407.03180</link>
      <description>arXiv:2407.03180v1 Announce Type: new 
Abstract: In agent-based simulations, synthetic populations of agents are commonly used to represent the structure, behaviour, and interactions of individuals. However, generating a synthetic population that accurately reflects real population statistics is a challenging task, particularly when performed at scale. In this paper, we propose a multi objective combinatorial optimisation technique for large scale population synthesis. We demonstrate the effectiveness of our approach by generating a synthetic population for selected regions and validating it on contingency tables from real population data. Our approach supports complex hierarchical structures between individuals and households, is scalable to large populations and achieves minimal contigency table reconstruction error. Hence, it provides a useful tool for policymakers and researchers for simulating the dynamics of complex populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03180v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>In proceedings of The European Simulation and Modelling Conference 2023: ESM'2023, Toulouse, France October 24-26, 2023</arxiv:journal_reference>
      <dc:creator>Imran Mahmood, Nicholas Bishop, Anisoara Calinescu, Michael Wooldridge, Ioannis Zachos</dc:creator>
    </item>
    <item>
      <title>INDICT: Code Generation with Internal Dialogues of Critiques for Both Security and Helpfulness</title>
      <link>https://arxiv.org/abs/2407.02518</link>
      <description>arXiv:2407.02518v1 Announce Type: cross 
Abstract: Large language models (LLMs) for code are typically trained to align with natural language instructions to closely follow their intentions and requirements. However, in many practical scenarios, it becomes increasingly challenging for these models to navigate the intricate boundary between helpfulness and safety, especially against highly complex yet potentially malicious instructions. In this work, we introduce INDICT: a new framework that empowers LLMs with Internal Dialogues of Critiques for both safety and helpfulness guidance. The internal dialogue is a dual cooperative system between a safety-driven critic and a helpfulness-driven critic. Each critic provides analysis against the given task and corresponding generated response, equipped with external knowledge queried through relevant code snippets and tools like web search and code interpreter. We engage the dual critic system in both code generation stage as well as code execution stage, providing preemptive and post-hoc guidance respectively to LLMs. We evaluated INDICT on 8 diverse tasks across 8 programming languages from 5 benchmarks, using LLMs from 7B to 70B parameters. We observed that our approach can provide an advanced level of critiques of both safety and helpfulness analysis, significantly improving the quality of output codes ($+10\%$ absolute improvements in all models).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02518v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.MA</category>
      <category>cs.PL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hung Le, Yingbo Zhou, Caiming Xiong, Silvio Savarese, Doyen Sahoo</dc:creator>
    </item>
    <item>
      <title>Wildfire Autonomous Response and Prediction Using Cellular Automata (WARP-CA)</title>
      <link>https://arxiv.org/abs/2407.02613</link>
      <description>arXiv:2407.02613v1 Announce Type: cross 
Abstract: Wildfires pose a severe challenge to ecosystems and human settlements, exacerbated by climate change and environmental factors. Traditional wildfire modeling, while useful, often fails to adapt to the rapid dynamics of such events. This report introduces the (Wildfire Autonomous Response and Prediction Using Cellular Automata) WARP-CA model, a novel approach that integrates terrain generation using Perlin noise with the dynamism of Cellular Automata (CA) to simulate wildfire spread. We explore the potential of Multi-Agent Reinforcement Learning (MARL) to manage wildfires by simulating autonomous agents, such as UAVs and UGVs, within a collaborative framework. Our methodology combines world simulation techniques and investigates emergent behaviors in MARL, focusing on efficient wildfire suppression and considering critical environmental factors like wind patterns and terrain features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02613v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abdelrahman Ramadan</dc:creator>
    </item>
    <item>
      <title>Multi-Objective Multi-Agent Planning for Discovering and Tracking Multiple Mobile Objects</title>
      <link>https://arxiv.org/abs/2203.04551</link>
      <description>arXiv:2203.04551v4 Announce Type: replace 
Abstract: We consider the online planning problem for a team of agents to discover and track an unknown and time-varying number of moving objects from onboard sensor measurements with uncertain measurement-object origins. Since the onboard sensors have limited field-of-views, the usual planning strategy based solely on either tracking detected objects or discovering unseen objects is inadequate. To address this, we formulate a new information-based multi-objective multi-agent control problem, cast as a partially observable Markov decision process (POMDP). The resulting multi-agent planning problem is exponentially complex due to the unknown data association between objects and multi-sensor measurements; hence, computing an optimal control action is intractable. We prove that the proposed multi-objective value function is a monotone submodular set function, which admits low-cost suboptimal solutions via greedy search with a tight optimality bound. The resulting planning algorithm has a linear complexity in the number of objects and measurements across the sensors, and quadratic in the number of agents. We demonstrate the proposed solution via a series of numerical experiments with a real-world dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.04551v4</guid>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoa Van Nguyen, Ba-Ngu Vo, Ba-Tuong Vo, Hamid Rezatofighi, Damith C. Ranasinghe</dc:creator>
    </item>
    <item>
      <title>Multi-agent Reinforcement Learning: A Comprehensive Survey</title>
      <link>https://arxiv.org/abs/2312.10256</link>
      <description>arXiv:2312.10256v2 Announce Type: replace 
Abstract: Multi-agent systems (MAS) are widely prevalent and crucially important in numerous real-world applications, where multiple agents must make decisions to achieve their objectives in a shared environment. Despite their ubiquity, the development of intelligent decision-making agents in MAS poses several open challenges to their effective implementation. This survey examines these challenges, placing an emphasis on studying seminal concepts from game theory (GT) and machine learning (ML) and connecting them to recent advancements in multi-agent reinforcement learning (MARL), i.e. the research of data-driven decision-making within MAS. Therefore, the objective of this survey is to provide a comprehensive perspective along the various dimensions of MARL, shedding light on the unique opportunities that are presented in MARL applications while highlighting the inherent challenges that accompany this potential. Therefore, we hope that our work will not only contribute to the field by analyzing the current landscape of MARL but also motivate future directions with insights for deeper integration of concepts from related domains of GT and ML. With this in mind, this work delves into a detailed exploration of recent and past efforts of MARL and its related fields and describes prior solutions that were proposed and their limitations, as well as their applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10256v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dom Huh, Prasant Mohapatra</dc:creator>
    </item>
    <item>
      <title>Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits</title>
      <link>https://arxiv.org/abs/2305.18784</link>
      <description>arXiv:2305.18784v2 Announce Type: replace-cross 
Abstract: The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18784v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronshee Chawla, Daniel Vial, Sanjay Shakkottai, R. Srikant</dc:creator>
    </item>
    <item>
      <title>Multi-topic belief formation through bifurcations over signed social networks</title>
      <link>https://arxiv.org/abs/2308.02755</link>
      <description>arXiv:2308.02755v2 Announce Type: replace-cross 
Abstract: We propose and analyze a nonlinear dynamic model of continuous-time multi-dimensional belief formation over signed social networks. Our model accounts for the effects of a structured belief system, self-appraisal, internal biases, and various sources of cognitive dissonance posited by recent theories in social psychology. We prove that agents become opinionated as a consequence of a bifurcation. We analyze how the balance of social network effects in the model controls the nature of the bifurcation and, therefore, the belief-forming limit-set solutions. Our analysis provides constructive conditions on how multi-stable network belief equilibria and belief oscillations emerging at a belief-forming bifurcation depend on the communication network graph and belief system network graph. Our model and analysis provide new theoretical insights on the dynamics of social systems and a new principled framework for designing decentralized decision-making on engineered networks in the presence of structured relationships among alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02755v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anastasia Bizyaeva, Alessio Franci, Naomi Ehrich Leonard</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Probabilistic Ensembles with Trajectory Sampling for Connected Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2312.13910</link>
      <description>arXiv:2312.13910v2 Announce Type: replace-cross 
Abstract: Autonomous Vehicles (AVs) have attracted significant attention in recent years and Reinforcement Learning (RL) has shown remarkable performance in improving the autonomy of vehicles. In that regard, the widely adopted Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs (CAVs), contingent on the readiness of a significant amount of data samples for training. Nevertheless, it might be infeasible in practice and possibly lead to learning instability. In contrast, Model-Based RL (MBRL) manifests itself in sample-efficient learning, but the asymptotic performance of MBRL might lag behind the state-of-the-art MFRL algorithms. Furthermore, most studies for CAVs are limited to the decision-making of a single AV only, thus underscoring the performance due to the absence of communications. In this study, we try to address the decision-making problem of multiple CAVs with limited communications and propose a decentralized Multi-Agent Probabilistic Ensembles with Trajectory Sampling algorithm MA-PETS. In particular, in order to better capture the uncertainty of the unknown environment, MA-PETS leverages Probabilistic Ensemble (PE) neural networks to learn from communicated samples among neighboring CAVs. Afterwards, MA-PETS capably develops Trajectory Sampling (TS)-based model-predictive control for decision-making. On this basis, we derive the multi-agent group regret bound affected by the number of agents within the communication range and mathematically validate that incorporating effective information exchange among agents into the multi-agent learning scheme contributes to reducing the group regret bound in the worst case. Finally, we empirically demonstrate the superiority of MA-PETS in terms of the sample efficiency comparable to MFBL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13910v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoqi Wen, Jiahao Huang, Rongpeng Li, Guoru Ding, Zhifeng Zhao</dc:creator>
    </item>
    <item>
      <title>An extension of May's Theorem to three alternatives: axiomatizing Minimax voting</title>
      <link>https://arxiv.org/abs/2312.14256</link>
      <description>arXiv:2312.14256v2 Announce Type: replace-cross 
Abstract: May's Theorem [K. O. May, Econometrica 20 (1952) 680-684] characterizes majority voting on two alternatives as the unique preferential voting method satisfying several simple axioms. Here we show that by adding some desirable axioms to May's axioms, we can uniquely determine how to vote on three alternatives (setting aside tiebreaking). In particular, we add two axioms stating that the voting method should mitigate spoiler effects and avoid the so-called strong no show paradox. We prove a theorem stating that any preferential voting method satisfying our enlarged set of axioms, which includes some weak homogeneity and preservation axioms, must choose from among the Minimax winners in all three-alternative elections. When applied to more than three alternatives, our axioms also distinguish Minimax from other known voting methods that coincide with or refine Minimax for three alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14256v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Eric Pacuit</dc:creator>
    </item>
  </channel>
</rss>
