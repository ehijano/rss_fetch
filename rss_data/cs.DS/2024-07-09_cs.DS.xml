<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Decomposition Theorem for Dynamic Flows</title>
      <link>https://arxiv.org/abs/2407.04761</link>
      <description>arXiv:2407.04761v1 Announce Type: new 
Abstract: The famous edge flow decomposition theorem of Gallai (1958) states that any static edge $s$,$d$-flow in a directed graph can be decomposed into a linear combination of incidence vectors of paths and cycles. In this paper, we study the decomposition problem for the setting of dynamic edge $s$,$d$-flows assuming a quite general dynamic flow propagation model. We prove the following decomposition theorem: For any dynamic edge $s$,$d$-flow with finite support, there exists a decomposition into a linear combination of $s$,$d$-walk inflows and circulations, i.e. edge flows that circulate along cycles with zero transit time. We show that a variant of the classical algorithmic approach of iteratively subtracting walk inflows from the current dynamic edge flow converges to a dynamic circulation. The algorithm terminates in finite time, if there is a lower bound on the minimum edge travel times. We further characterize those dynamic edge flows which can be decomposed purely into linear combinations of $s$,$d$-walk inflows.
  The proofs rely on the new concept of parameterized network loadings which describe how particles of a different walk flow would hypothetically propagate throughout the network under the fixed travel times induced by the given edge flow. We show several technical properties of this type of network loading and as a byproduct we also derive some general results on dynamic flows which could be of interest outside the context of this paper as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04761v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Graf, Tobias Harks, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>The Submodular Santa Claus Problem</title>
      <link>https://arxiv.org/abs/2407.04824</link>
      <description>arXiv:2407.04824v1 Announce Type: new 
Abstract: We consider the problem of allocating indivisible resources to players so as to maximize the minimum total value any player receives. This problem is sometimes dubbed the Santa Claus problem and its different variants have been subject to extensive research towards approximation algorithms over the past two decades.
  In the case where each player has a potentially different additive valuation function, Chakrabarty, Chuzhoy, and Khanna [FOCS'09] gave an $O(n^{\epsilon})$-approximation algorithm with polynomial running time for any constant $\epsilon &gt; 0$ and a polylogarithmic approximation algorithm in quasi-polynomial time. We show that the same can be achieved for monotone submodular valuation functions, improving over the previously best algorithm due to Goemans, Harvey, Iwata, and Mirrokni [SODA'09], which has an approximation ratio of more than $\sqrt{n}$.
  Our result builds up on a sophisticated LP relaxation, which has a recursive block structure that allows us to solve it despite having exponentially many variables and constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04824v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Etienne Bamas, Sarah Morell, Lars Rohwedder</dc:creator>
    </item>
    <item>
      <title>Faster single-source shortest paths with negative real weights via proper hop distance</title>
      <link>https://arxiv.org/abs/2407.04872</link>
      <description>arXiv:2407.04872v1 Announce Type: new 
Abstract: The textbook algorithm for single-source shortest paths with real-valued edge weights runs in $O(m n)$ time on a graph with $m$ edges and $n$ vertices. A recent breakthrough algorithm by Fineman [Fin24] takes $\tilde O(m n^{8/9})$ randomized time. We present an $\tilde O(m n^{4/5})$ randomized time algorithm building on ideas from [Fin24].</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04872v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Huang, Peter Jin, Kent Quanrud</dc:creator>
    </item>
    <item>
      <title>A linear-time algorithm for $(1+\epsilon)\Delta$-edge-coloring</title>
      <link>https://arxiv.org/abs/2407.04887</link>
      <description>arXiv:2407.04887v1 Announce Type: new 
Abstract: We present a randomized algorithm that, given $\epsilon &gt; 0$, outputs a proper $(1+\epsilon)\Delta$-edge-coloring of an $m$-edge simple graph $G$ of maximum degree $\Delta \geq 1/\epsilon$ in $O(m\,\log(1/\epsilon)/\epsilon^4)$ time. For constant $\epsilon$, this is the first linear-time algorithm for this problem without any restrictions on $\Delta$ other than the necessary bound $\Delta \geq 1/\epsilon$. The best previous result in this direction, very recently obtained by Assadi, gives a randomized algorithm with expected running time $O(m \, \log(1/\epsilon))$ under the assumption $\Delta \gg \log n/\epsilon$; removing the lower bound on $\Delta$ was explicitly mentioned as a challenging open problem by Bhattacharya, Costa, Panski, and Solomon. Indeed, even for edge-coloring with $2\Delta - 1$ colors (i.e., meeting the "greedy" bound), no linear-time algorithm covering the full range of $\Delta$ has been known until now. Additionally, when $\epsilon = 1/\Delta$, our result yields an $O(m\,\Delta^4\log \Delta)$-time algorithm for $(\Delta+1)$-edge-coloring, improving the bound $O(m\, \Delta^{17})$ from the authors' earlier work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04887v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Bernshteyn, Abhishek Dhawan</dc:creator>
    </item>
    <item>
      <title>Universal Perfect Samplers for Incremental Streams</title>
      <link>https://arxiv.org/abs/2407.04931</link>
      <description>arXiv:2407.04931v1 Announce Type: new 
Abstract: If $G : \mathbb{R}_+ \to \mathbb{R}_+$, the $G$-moment of a vector $\mathbf{x}\in\mathbb{R}_+^n$ is $G(\mathbf{x}) = \sum_{v\in[n]} G(\mathbf{x}(v))$ and the $G$-sampling problem is to select an index $v_*\in [n]$ according to its contribution to the $G$-moment, i.e., such that $\Pr(v_*=v) = G(\mathbf{x}(v))/G(\mathbf{x})$. Approximate $G$-samplers may introduce multiplicative and/or additive errors to this probability, and some have a non-trivial probability of failure.
  In this paper we focus on the exact $G$-sampling problem, where $G$ is selected from the class $\mathcal{G}$ of Laplace exponents of non-negative, one-dimensional L\'evy processes, which includes several well studied classes such as $p$th moments $G(z)=z^p$, $p\in[0,1]$, logarithms $G(z)=\log(1+z)$, Cohen and Geri's soft concave sublinear functions, which are used to approximate concave sublinear functions, including cap statistics. We develop $G$-samplers for a vector $\mathbf{x} \in \mathbb{R}_+^n$ that is presented as an incremental stream of positive updates. In particular:
  * For any $G\in\mathcal{G}$, we give a very simple $G$-sampler that uses 2 words of memory and stores at all times a $v_*\in [n]$, such that $\Pr(v_*=v)$ is exactly $G(\mathbf{x}(v))/G(\mathbf{x})$.
  * We give a ``universal'' $\mathcal{G}$-sampler that uses $O(\log n)$ words of memory w.h.p., and given any $G\in \mathcal{G}$ at query time, produces an exact $G$-sample.
  With an overhead of a factor of $k$, both samplers can be used to $G$-sample a sequence of $k$ indices with or without replacement. Our sampling framework is simple and versatile, and can easily be generalized to sampling from more complex objects like graphs and hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04931v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seth Pettie, Dingyu Wang</dc:creator>
    </item>
    <item>
      <title>Counting Permutation Patterns with Multidimensional Trees</title>
      <link>https://arxiv.org/abs/2407.04971</link>
      <description>arXiv:2407.04971v1 Announce Type: new 
Abstract: We consider the well-studied pattern counting problem: given a permutation $\pi \in \mathbb{S}_n$ and an integer $k &gt; 1$, count the number of order-isomorphic occurrences of every pattern $\tau \in \mathbb{S}_k$ in $\pi$.
  Our first result is an $\widetilde{\mathcal{O}}(n^2)$-time algorithm for $k=6$ and $k=7$. The proof relies heavily on a new family of graphs that we introduce, called pattern-trees. Every such tree corresponds to an integer linear combination of permutations in $\mathbb{S}_k$, and is associated with linear extensions of partially ordered sets. We design an evaluation algorithm for these combinations, and apply it to a family of linearly-independent trees. For $k=8$, we show a barrier: the subspace spanned by trees in the previous family has dimension exactly $|\mathbb{S}_8| - 1$, one less than required.
  Our second result is an $\widetilde{\mathcal{O}}(n^{7/4})$-time algorithm for $k=5$. This algorithm extends the framework of pattern-trees by speeding-up their evaluation in certain cases. A key component of the proof is the introduction of pair-rectangle-trees, a data structure for dominance counting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04971v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gal Beniamini, Nir Lavee</dc:creator>
    </item>
    <item>
      <title>Congestion-Approximators from the Bottom Up</title>
      <link>https://arxiv.org/abs/2407.04976</link>
      <description>arXiv:2407.04976v1 Announce Type: new 
Abstract: We develop a novel algorithm to construct a congestion-approximator with polylogarithmic quality on a capacitated, undirected graph in nearly-linear time. Our approach is the first *bottom-up* hierarchical construction, in contrast to previous *top-down* approaches including that of Racke, Shah, and Taubig (SODA 2014), the only other construction achieving polylogarithmic quality that is implementable in nearly-linear time (Peng, SODA 2016). Similar to Racke, Shah, and Taubig, our construction at each hierarchical level requires calls to an approximate max-flow/min-cut subroutine. However, the main advantage to our bottom-up approach is that these max-flow calls can be implemented directly *without recursion*. More precisely, the previously computed levels of the hierarchy can be converted into a *pseudo-congestion-approximator*, which then translates to a max-flow algorithm that is sufficient for the particular max-flow calls used in the construction of the next hierarchical level. As a result, we obtain the first non-recursive algorithms for congestion-approximator and approximate max-flow that run in nearly-linear time, a conceptual improvement to the aforementioned algorithms that recursively alternate between the two problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04976v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Li, Satish Rao, Di Wang</dc:creator>
    </item>
    <item>
      <title>FPTAS for Holant Problems with Log-Concave Signatures</title>
      <link>https://arxiv.org/abs/2407.04989</link>
      <description>arXiv:2407.04989v1 Announce Type: new 
Abstract: For an integer $b\ge 0$, a $b$-matching in a graph $G=(V,E)$ is a set $S\subseteq E$ such that each vertex $v\in V$ is incident to at most $b$ edges in $S$. We design a fully polynomial-time approximation scheme (FPTAS) for counting the number of $b$-matchings in graphs with bounded degrees. Our FPTAS also applies to a broader family of counting problems, namely Holant problems with log-concave signatures. Our algorithm is based on Moitra's linear programming approach (JACM'19). Using a novel construction called the extended coupling tree, we derandomize the coupling designed by Chen and Gu (SODA'24).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04989v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun He, Zhidan Li, Guoliang Qiu, Chihao Zhang</dc:creator>
    </item>
    <item>
      <title>Competitive Analysis of Online Path Selection: Impacts of Path Length, Topology, and System-Level Costs</title>
      <link>https://arxiv.org/abs/2407.05239</link>
      <description>arXiv:2407.05239v1 Announce Type: new 
Abstract: Consider a communication network to which a sequence of self-interested users come and send requests for data transmission between nodes. This work studies the question of how to guide the path selection choices made by those online-arriving users and maximize the social welfare. Competitive analysis is the main technical tool. Specifically, the impacts of path length bounds and topology on the competitive ratio of the designed algorithm are analyzed theoretically and explored experimentally. We observe intricate and interesting relationships between the empirical performance and the studied network parameters, which shed some light on how to design the network. We also investigate the influence of system-level costs on the optimal algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05239v1</guid>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ying Cao, Siyuan Yu, Xiaoqi Tan, Danny H. K. Tsang</dc:creator>
    </item>
    <item>
      <title>Online Matching: A Brief Survey</title>
      <link>https://arxiv.org/abs/2407.05381</link>
      <description>arXiv:2407.05381v1 Announce Type: new 
Abstract: Matching, capturing allocation of items to unit-demand buyers, or tasks to workers, or pairs of collaborators, is a central problem in economics. Indeed, the growing prevalence of matching-based markets, many of which online in nature, has motivated much research in economics, operations research, computer science, and their intersection. This brief survey is meant as an introduction to the area of online matching, with an emphasis on recent trends, both technical and conceptual.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05381v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyi Huang, Zhihao Gavin Tang, David Wajc</dc:creator>
    </item>
    <item>
      <title>Hamming Distance Oracle</title>
      <link>https://arxiv.org/abs/2407.05430</link>
      <description>arXiv:2407.05430v1 Announce Type: new 
Abstract: In this paper, we present and study the \emph{Hamming distance oracle problem}. In this problem, the task is to preprocess two strings $S$ and $T$ of lengths $n$ and $m$, respectively, to obtain a data-structure that is able to answer queries regarding the Hamming distance between a substring of $S$ and a substring of $T$.
  For a constant size alphabet strings, we show that for every $x\le nm$ there is a data structure with $\tilde{O}(nm/x)$ preprocess time and $O(x)$ query time. We also provide a combinatorial conditional lower bound, showing that for every $\varepsilon &gt; 0$ and $x \le nm$ there is no data structure with query time $O(x)$ and preprocess time $O((\frac{nm}{x})^{1-\varepsilon})$ unless combinatorial fast matrix multiplication is possible.
  For strings over general alphabet, we present a data structure with $\tilde{O}(nm/\sqrt{x})$ preprocess time and $O(x)$ query time for every $x \le nm$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05430v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Itai Boneh, Dvir Fried, Shay Golan, Matan Kraus</dc:creator>
    </item>
    <item>
      <title>Polynomial Time Algorithms for Integer Programming and Unbounded Subset Sum in the Total Regime</title>
      <link>https://arxiv.org/abs/2407.05435</link>
      <description>arXiv:2407.05435v1 Announce Type: new 
Abstract: The Unbounded Subset Sum (USS) problem is an NP-hard computational problem where the goal is to decide whether there exist non-negative integers $x_1, \ldots, x_n$ such that $x_1 a_1 + \ldots + x_n a_n = b$, where $a_1 &lt; \cdots &lt; a_n &lt; b$ are distinct positive integers with $\text{gcd}(a_1, \ldots, a_n)$ dividing $b$. The problem can be solved in pseudopolynomial time, while specialized cases, such as when $b$ exceeds the Frobenius number of $a_1, \ldots, a_n$ simplify to a total problem where a solution always exists.
  This paper explores the concept of totality in USS. The challenge in this setting is to actually find a solution, even though we know its existence is guaranteed. We focus on the instances of USS where solutions are guaranteed for large $b$. We show that when $b$ is slightly greater than the Frobenius number, we can find the solution to USS in polynomial time.
  We then show how our results extend to Integer Programming with Equalities (ILPE), highlighting conditions under which ILPE becomes total. We investigate the \emph{diagonal Frobenius number}, which is the appropriate generalization of the Frobenius number to this context. In this setting, we give a polynomial-time algorithm to find a solution of ILPE. The bound obtained from our algorithmic procedure for finding a solution almost matches the recent existential bound of Bach, Eisenbrand, Rothvoss, and Weismantel (2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05435v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Divesh Aggarwal, Antoine Joux, Miklos Santha, Karol W\k{e}grzycki</dc:creator>
    </item>
    <item>
      <title>Agnostic Private Density Estimation via Stable List Decoding</title>
      <link>https://arxiv.org/abs/2407.04783</link>
      <description>arXiv:2407.04783v1 Announce Type: cross 
Abstract: We introduce a new notion of stability--which we call stable list decoding--and demonstrate its applicability in designing differentially private density estimators. This definition is weaker than global stability [ABLMM22] and is related to the notions of replicability [ILPS22] and list replicability [CMY23]. We show that if a class of distributions is stable list decodable, then it can be learned privately in the agnostic setting. As the main application of our framework, we prove the first upper bound on the sample complexity of private density estimation for Gaussian Mixture Models in the agnostic setting, extending the realizable result of Afzali et al. [AAL24].</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04783v1</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Afzali, Hassan Ashtiani, Christopher Liaw</dc:creator>
    </item>
    <item>
      <title>Fair Submodular Cover</title>
      <link>https://arxiv.org/abs/2407.04804</link>
      <description>arXiv:2407.04804v1 Announce Type: cross 
Abstract: Submodular optimization is a fundamental problem with many applications in machine learning, often involving decision-making over datasets with sensitive attributes such as gender or age. In such settings, it is often desirable to produce a diverse solution set that is fairly distributed with respect to these attributes. Motivated by this, we initiate the study of Fair Submodular Cover (FSC), where given a ground set $U$, a monotone submodular function $f:2^U\to\mathbb{R}_{\ge 0}$, a threshold $\tau$, the goal is to find a balanced subset of $S$ with minimum cardinality such that $f(S)\ge\tau$. We first introduce discrete algorithms for FSC that achieve a bicriteria approximation ratio of $(\frac{1}{\epsilon}, 1-O(\epsilon))$. We then present a continuous algorithm that achieves a $(\ln\frac{1}{\epsilon}, 1-O(\epsilon))$-bicriteria approximation ratio, which matches the best approximation guarantee of submodular cover without a fairness constraint. Finally, we complement our theoretical results with a number of empirical evaluations that demonstrate the effectiveness of our algorithms on instances of maximum coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04804v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenjing Chen, Shuo Xing, Samson Zhou, Victoria G. Crawford</dc:creator>
    </item>
    <item>
      <title>Nash Incentive-compatible Online Mechanism Learning via Weakly Differentially Private Online Learning</title>
      <link>https://arxiv.org/abs/2407.04898</link>
      <description>arXiv:2407.04898v1 Announce Type: cross 
Abstract: We study a multi-round mechanism design problem, where we interact with a set of agents over a sequence of rounds. We wish to design an incentive-compatible (IC) online learning scheme to maximize an application-specific objective within a given class of mechanisms, without prior knowledge of the agents' type distributions. Even if each mechanism in this class is IC in a single round, if an algorithm naively chooses from this class on each round, the entire learning process may not be IC against non-myopic buyers who appear over multiple rounds. On each round, our method randomly chooses between the recommendation of a weakly differentially private online learning algorithm (e.g., Hedge), and a commitment mechanism which penalizes non-truthful behavior. Our method is IC and achieves $O(T^{\frac{1+h}{2}})$ regret for the application-specific objective in an adversarial setting, where $h$ quantifies the long-sightedness of the agents. When compared to prior work, our approach is conceptually simpler,it applies to general mechanism design problems (beyond auctions), and its regret scales gracefully with the size of the mechanism class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04898v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joon Suk Huh, Kirthevasan Kandasamy</dc:creator>
    </item>
    <item>
      <title>Fr\'echet Distance in Subquadratic Time</title>
      <link>https://arxiv.org/abs/2407.05231</link>
      <description>arXiv:2407.05231v1 Announce Type: cross 
Abstract: Let $m$ and $n$ be the numbers of vertices of two polygonal curves in $\mathbb{R}^d$ for any fixed $d$ such that $m \leq n$. Since it was known in 1995 how to compute the Fr\'{e}chet distance of these two curves in $O(mn\log (mn))$ time, it has been an open problem whether the running time can be reduced to $o(n^2)$ when $m = \Omega(n)$. In the mean time, several well-known quadratic time barriers in computational geometry have been overcome: 3SUM, some 3SUM-hard problems, and the computation of some distances between two polygonal curves, including the discrete Fr\'{e}chet distance, the dynamic time warping distance, and the geometric edit distance. It is curious that the quadratic time barrier for Fr\'{e}chet distance still stands. We present an algorithm to compute the Fr\'echet distance in $O(mn(\log\log n)^{2+\mu}\log n/\log^{1+\mu} m)$ expected time for some constant $\mu \in (0,1)$. It is the first algorithm that returns the Fr\'{e}chet distance in $o(mn)$ time when $m = \Omega(n^{\varepsilon})$ for any fixed $\varepsilon \in (0,1]$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05231v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siu-Wing Cheng, Haoqiang Huang</dc:creator>
    </item>
    <item>
      <title>Privacy of the last iterate in cyclically-sampled DP-SGD on nonconvex composite losses</title>
      <link>https://arxiv.org/abs/2407.05237</link>
      <description>arXiv:2407.05237v1 Announce Type: cross 
Abstract: Differentially private stochastic gradient descent (DP-SGD) refers to a family of optimization algorithms that provide a guaranteed level of differential privacy (DP) through DP accounting techniques. However, current accounting techniques make assumptions that diverge significantly from practical DP-SGD implementations. For example, they may assume the loss function is Lipschitz continuous and convex, sample the batches randomly with replacement, or omit the gradient clipping step.
  In this work, we analyze the most commonly used variant of DP-SGD, in which we sample batches cyclically with replacement, perform gradient clipping, and only release the last DP-SGD iterate. More specifically - without assuming convexity, smoothness, or Lipschitz continuity of the loss function - we establish new R\'enyi differential privacy (RDP) bounds for the last DP-SGD iterate under the mild assumption that (i) the DP-SGD stepsize is small relative to the topological constants in the loss function, and (ii) the loss function is weakly-convex. Moreover, we show that our bounds converge to previously established convex bounds when the weak-convexity parameter of the objective function approaches zero. In the case of non-Lipschitz smooth loss functions, we provide a weaker bound that scales well in terms of the number of DP-SGD iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05237v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwei Kong, M\'onica Ribero</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Learning Sparse Functions with Statistical and Gradient Queries</title>
      <link>https://arxiv.org/abs/2407.05622</link>
      <description>arXiv:2407.05622v1 Announce Type: cross 
Abstract: The goal of this paper is to investigate the complexity of gradient algorithms when learning sparse functions (juntas). We introduce a type of Statistical Queries ($\mathsf{SQ}$), which we call Differentiable Learning Queries ($\mathsf{DLQ}$), to model gradient queries on a specified loss with respect to an arbitrary model. We provide a tight characterization of the query complexity of $\mathsf{DLQ}$ for learning the support of a sparse function over generic product distributions. This complexity crucially depends on the loss function. For the squared loss, $\mathsf{DLQ}$ matches the complexity of Correlation Statistical Queries $(\mathsf{CSQ})$--potentially much worse than $\mathsf{SQ}$. But for other simple loss functions, including the $\ell_1$ loss, $\mathsf{DLQ}$ always achieves the same complexity as $\mathsf{SQ}$. We also provide evidence that $\mathsf{DLQ}$ can indeed capture learning with (stochastic) gradient descent by showing it correctly describes the complexity of learning with a two-layer neural network in the mean field regime and linear scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05622v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nirmit Joshi, Theodor Misiakiewicz, Nathan Srebro</dc:creator>
    </item>
    <item>
      <title>Fractional Budget Allocation for Influence Maximization under General Marketing Strategies</title>
      <link>https://arxiv.org/abs/2407.05669</link>
      <description>arXiv:2407.05669v1 Announce Type: cross 
Abstract: We consider the fractional influence maximization problem, i.e., identifying users on a social network to be incentivized with potentially partial discounts to maximize the influence on the network. The larger the discount given to a user, the higher the likelihood of its activation (adopting a new product or innovation), who then attempts to activate its neighboring users, causing a cascade effect of influence through the network. Our goal is to devise efficient algorithms that assign initial discounts to the network's users to maximize the total number of activated users at the end of the cascade, subject to a constraint on the total sum of discounts given. In general, the activation likelihood could be any non-decreasing function of the discount, whereas, our focus lies on the case when the activation likelihood is an affine function of the discount, potentially varying across different users. As this problem is shown to be NP-hard, we propose and analyze an efficient (1-1/e)-approximation algorithm. Furthermore, we run experiments on real-world social networks to show the performance and scalability of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05669v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Akhil Bhimaraju, Eliot W. Robson, Lav R. Varshney, Abhishek K. Umrawal</dc:creator>
    </item>
    <item>
      <title>Random Order Set Cover is as Easy as Offline</title>
      <link>https://arxiv.org/abs/2111.06842</link>
      <description>arXiv:2111.06842v2 Announce Type: replace 
Abstract: We give a polynomial-time algorithm for OnlineSetCover with a competitive ratio of $O(\log mn)$ when the elements are revealed in random order, essentially matching the best possible offline bound of $O(\log n)$ and circumventing the $\Omega(\log m \log n)$ lower bound known in adversarial order. We also extend the result to solving pure covering IPs when constraints arrive in random order.
  The algorithm is a multiplicative-weights-based round-and-solve approach we call LearnOrCover. We maintain a coarse fractional solution that is neither feasible nor monotone increasing, but can nevertheless be rounded online to achieve the claimed guarantee (in the random order model). This gives a new offline algorithm for SetCover that performs a single pass through the elements, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.06842v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anupam Gupta, Gregory Kehne, Roie Levin</dc:creator>
    </item>
    <item>
      <title>Partitioning Problems with Splittings and Interval Targets</title>
      <link>https://arxiv.org/abs/2204.11753</link>
      <description>arXiv:2204.11753v4 Announce Type: replace 
Abstract: The $n$-way number partitioning problem is a classic problem in combinatorial optimization, with applications to diverse settings such as fair allocation and machine scheduling. All these problems are NP-hard, but various approximation algorithms are known. We consider three closely related kinds of approximations.
  The first two variants optimize the partition such that: in the first variant some fixed number $s$ of items can be \emph{split} between two or more bins and in the second variant we allow at most a fixed number $t$ of \emph{splittings}. The third variant is a decision problem: the largest bin sum must be within a pre-specified interval, parameterized by a fixed rational number $u$ times the largest item size.
  When the number of bins $n$ is unbounded, we show that every variant is strongly {\sf NP}-complete. When the number of bins $n$ is fixed, the running time depends on the fixed parameters $s,t,u$. For each variant, we give a complete picture of its running time.
  For $n=2$, the running time is easy to identify. Our main results consider any fixed integer $n \geq 3$. Using a two-way polynomial-time reduction between the first and the third variant, we show that $n$-way number-partitioning with $s$ split items can be solved in polynomial time if $s \geq n-2$, and it is {\sf NP}-complete otherwise. Also, $n$-way number-partitioning with $t$ splittings can be solved in polynomial time if $t \geq n-1$, and it is {\sf NP}-complete otherwise. Finally, we show that the third variant can be solved in polynomial time if $u \geq (n-2)/n$, and it is {\sf NP}-complete otherwise. Our positive results for the optimization problems consider both min-max and max-min versions.
  Using the same reduction, and we provide a fully polynomial-time approximation scheme for the case where the number of split items is lower than $n-2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.11753v4</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Bismuth, Vladislav Makarov, Erel Segal-Halevi, Dana Shapira</dc:creator>
    </item>
    <item>
      <title>Fully Scalable MPC Algorithms for Clustering in High Dimension</title>
      <link>https://arxiv.org/abs/2307.07848</link>
      <description>arXiv:2307.07848v3 Announce Type: replace 
Abstract: We design new parallel algorithms for clustering in high-dimensional Euclidean spaces. These algorithms run in the Massively Parallel Computation (MPC) model, and are fully scalable, meaning that the local memory in each machine may be $n^{\sigma}$ for arbitrarily small fixed $\sigma&gt;0$. Importantly, the local memory may be substantially smaller than the number of clusters $k$, yet all our algorithms are fast, i.e., run in $O(1)$ rounds.
  We first devise a fast MPC algorithm for $O(1)$-approximation of uniform facility location. This is the first fully-scalable MPC algorithm that achieves $O(1)$-approximation for any clustering problem in general geometric setting; previous algorithms only provide $\mathrm{poly}(\log n)$-approximation or apply to restricted inputs, like low dimension or small number of clusters $k$; e.g. [Bhaskara and Wijewardena, ICML'18; Cohen-Addad et al., NeurIPS'21; Cohen-Addad et al., ICML'22]. We then build on this facility location result and devise a fast MPC algorithm that achieves $O(1)$-bicriteria approximation for $k$-Median and for $k$-Means, namely, it computes $(1+\varepsilon)k$ clusters of cost within $O(1/\varepsilon^2)$-factor of the optimum for $k$ clusters.
  A primary technical tool that we introduce, and may be of independent interest, is a new MPC primitive for geometric aggregation, namely, computing for every data point a statistic of its approximate neighborhood, for statistics like range counting and nearest-neighbor search. Our implementation of this primitive works in high dimension, and is based on consistent hashing (aka sparse partition), a technique that was recently used for streaming algorithms [Czumaj et al., FOCS'22].</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07848v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artur Czumaj, Guichen Gao, Shaofeng H. -C. Jiang, Robert Krauthgamer, Pavel Vesel\'y</dc:creator>
    </item>
    <item>
      <title>Sparse Submodular Function Minimization</title>
      <link>https://arxiv.org/abs/2309.16632</link>
      <description>arXiv:2309.16632v2 Announce Type: replace 
Abstract: In this paper we study the problem of minimizing a submodular function $f : 2^V \rightarrow \mathbb{R}$ that is guaranteed to have a $k$-sparse minimizer. We give a deterministic algorithm that computes an additive $\epsilon$-approximate minimizer of such $f$ in $\widetilde{O}(\mathsf{poly}(k) \log(|f|/\epsilon))$ parallel depth using a polynomial number of queries to an evaluation oracle of $f$, where $|f| = \max_{S \subseteq V} |f(S)|$. Further, we give a randomized algorithm that computes an exact minimizer of $f$ with high probability using $\widetilde{O}(|V| \cdot \mathsf{poly}(k))$ queries and polynomial time. When $k = \widetilde{O}(1)$, our algorithms use either nearly-constant parallel depth or a nearly-linear number of evaluation oracle queries. All previous algorithms for this problem either use $\Omega(|V|)$ parallel depth or $\Omega(|V|^2)$ queries.
  In contrast to state-of-the-art weakly-polynomial and strongly-polynomial time algorithms for SFM, our algorithms use first-order optimization methods, e.g., mirror descent and follow the regularized leader. We introduce what we call {\em sparse dual certificates}, which encode information on the structure of sparse minimizers, and both our parallel and sequential algorithms provide new algorithmic tools for allowing first-order optimization methods to efficiently compute them. Correspondingly, our algorithm does not invoke fast matrix multiplication or general linear system solvers and in this sense is more combinatorial than previous state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16632v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Graur, Haotian Jiang, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Semi-Streaming Algorithms for Weighted $k$-Disjoint Matchings</title>
      <link>https://arxiv.org/abs/2311.02073</link>
      <description>arXiv:2311.02073v2 Announce Type: replace 
Abstract: We design and implement two single-pass semi-streaming algorithms for the maximum weight $k$-disjoint matching ($k$-DM) problem. Given an integer $k$, the $k$-DM problem is to find $k$ pairwise edge-disjoint matchings such that the sum of the weights of the matchings is maximized. For $k \geq 2$, this problem is NP-hard. Our first algorithm is based on the primal-dual framework of a linear programming relaxation of the problem and is $\frac{1}{3+\varepsilon}$-approximate. We also develop an approximation preserving reduction from $k$-DM to the maximum weight $b$-matching problem. Leveraging this reduction and an existing semi-streaming $b$-matching algorithm, we design a $(\frac{1}{2+\varepsilon})(1 - \frac{1}{k+1})$-approximate semi-streaming algorithm for $k$-DM. For any constant $\varepsilon &gt; 0$, both of these algorithms require $O(nk \log_{1+\varepsilon}^2 n)$ bits of space. To the best of our knowledge, this is the first study of semi-streaming algorithms for the $k$-DM problem.
  We compare our two algorithms to state-of-the-art offline algorithms on 95 real-world and synthetic test problems, including thirteen graphs generated from data center network traces. On these instances, our streaming algorithms used significantly less memory (ranging from 6$\times$ to 512$\times$ less) and were faster in runtime than the offline algorithms. Our solutions were often within 5% of the best weights from the offline algorithms. We highlight that the existing offline algorithms run out of 1 TB memory for most of the large instances ($&gt;1$ billion edges), whereas our streaming algorithms can solve these problems using only 100 GB memory for $k=8$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02073v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S M Ferdous, Bhargav Samineni, Alex Pothen, Mahantesh Halappanavar, Bala Krishnamoorthy</dc:creator>
    </item>
    <item>
      <title>Nearly Optimal Internal Dictionary Matching</title>
      <link>https://arxiv.org/abs/2312.11873</link>
      <description>arXiv:2312.11873v2 Announce Type: replace 
Abstract: We study the internal dictionary matching (IDM) problem where a dictionary $\mathcal{D}$ containing $d$ substrings of a text $T$ is given, and each query concerns the occurrences of patterns in $\mathcal{D}$ in another substring of $T.$
  We propose a novel $O(n)$-sized data structure named Basic Substring Structure (BASS) where $n$ is the length of the text $T.$ With BASS, we are able to handle all types of queries in the IDM problem in nearly optimal query and preprocessing time. Specifically, our results include:
  - The first algorithm that answers the *CountDistinct* query in $\tilde{O}(1)$ time with $\tilde{O}(n+d)$ preprocessing, where we need to compute the number of distinct patterns that exist in $T[i..j]$. Previously, the best result was $\tilde{O}(m)$ time per query after $\tilde{O}(n^2/m+d)$ or $\tilde{O}(nd/m+d)$ preprocessing, where $m$ is a chosen parameter. - Faster algorithms for two other types of internal queries. We improve the runtime for \textbf{(1)} Pattern counting (Count) queries to $O(\log n/\log\log n)$ time per query with $O(n+d\sqrt{\log n})$ preprocessing from $O(\log^2 n/\log\log n)$ time per query with $O(n\log n/\log \log n+d\log^{3/2} n)$ preprocessing. \textbf{(2)} Distinct pattern reporting (ReportDistinct) queries to $O(1+|\text{output}|)$ time per query from $O(\log n+|\text{output}|)$ per query.
  In addition, we match the optimal runtime in the remaining two types of queries, pattern existence (Exist), and pattern reporting (Report). We also show that BASS is more generally applicable to other internal query problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11873v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingbang Chen, Jiangqi Dai, Qiuyang Mang, Qingyu Shi, Tingqiang Xu</dc:creator>
    </item>
    <item>
      <title>A Textbook Solution for Dynamic Strings</title>
      <link>https://arxiv.org/abs/2403.13162</link>
      <description>arXiv:2403.13162v3 Announce Type: replace 
Abstract: We consider the problem of maintaining a collection of strings while efficiently supporting splits and concatenations on them, as well as comparing two substrings, and computing the longest common prefix between two suffixes. This problem can be solved in optimal time $\mathcal{O}(\log N)$ whp for the updates and $\mathcal{O}(1)$ worst-case time for the queries, where $N$ is the total collection size [Gawrychowski et al., SODA 2018]. We present here a much simpler solution based on a forest of enhanced splay trees (FeST), where both the updates and the substring comparison take $\mathcal{O}(\log n)$ amortized time, $n$ being the lengths of the strings involved. The longest common prefix of length $\ell$ is computed in $\mathcal{O}(\log n + \log^2\ell)$ amortized time. Our query results are correct whp. Our simpler solution enables other more general updates in $\mathcal{O}(\log n)$ amortized time, such as reversing a substring and/or mapping its symbols. We can also regard substrings as circular or as their omega extension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13162v3</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zsuzsanna Lipt\'ak, Francesco Masillo, Gonzalo Navarro</dc:creator>
    </item>
    <item>
      <title>Universal Harmonic Sketching over Turnstile Streams</title>
      <link>https://arxiv.org/abs/2403.15366</link>
      <description>arXiv:2403.15366v2 Announce Type: replace 
Abstract: In this work we take a new approach to constructing a universal sketch that focuses on a class of \emph{basis functions} $\{f_s(x)=1-\cos(sx)\mid s&gt;0\}$, so that any $f$-moment can be estimated if $f$ can be expressed as a linear combination of basis functions. We construct and analyze the $\mathsf{SymmetricPoissonTower}$ sketch, which occupies $O(\epsilon^{-2}\log^2(nM\epsilon^{-1}))$ bits and is $\mathcal{F}$-universal for the function class $$\mathcal{F}= \left\{f(x)=cx^2+\int_0^\infty (1-\cos (xs))\,\nu(ds) \mid c\geq 0, \text{$\nu$ is a positive measure}\right\},$$ i.e., given any $f\in \mathcal{F}$, the new sketch $(1\pm\epsilon)$-estimates the $f$-moment with probability 2/3. The family $\mathcal{F}$ includes all the classic frequency moments ($f(z)=|z|^p$, $p\in [0,2]$) as well as a large family of nearly-periodic functions that cannot be estimated with $L_2$-heavy hitter machinery. This new approach to universality requires significantly less space in comparison to previous universal schemes and sheds new light on the full characterization of the class $\mathcal{T}$ of tractable functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15366v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dingyu Wang</dc:creator>
    </item>
    <item>
      <title>#CFG and #DNNF admit FPRAS</title>
      <link>https://arxiv.org/abs/2406.18224</link>
      <description>arXiv:2406.18224v2 Announce Type: replace 
Abstract: We provide the first fully polynomial-time randomized approximation scheme for the following two counting problems: 1. Given a Context Free Grammar $G$ over alphabet $\Sigma$, count the number of words of length exactly $n$ generated by $G$. 2. Given a circuit $\varphi$ in Decomposable Negation Normal Form (DNNF) over the set of Boolean variables $X$, compute the number of assignments to $X$ such that $\varphi$ evaluates to 1.
  Finding polynomial time algorithms for the aforementioned problems has been a longstanding open problem. Prior work could either only obtain a quasi-polynomial runtime (SODA 1995) or a polynomial-time randomized approximation scheme for restricted fragments, such as non-deterministic finite automata (JACM 2021) or non-deterministic tree automata (STOC 2021).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18224v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kuldeep S. Meel, Alexis de Colnet</dc:creator>
    </item>
    <item>
      <title>Accelerated Algorithms for Constrained Nonconvex-Nonconcave Min-Max Optimization and Comonotone Inclusion</title>
      <link>https://arxiv.org/abs/2206.05248</link>
      <description>arXiv:2206.05248v5 Announce Type: replace-cross 
Abstract: We study constrained comonotone min-max optimization, a structured class of nonconvex-nonconcave min-max optimization problems, and their generalization to comonotone inclusion. In our first contribution, we extend the Extra Anchored Gradient (EAG) algorithm, originally proposed by Yoon and Ryu (2021) for unconstrained min-max optimization, to constrained comonotone min-max optimization and comonotone inclusion, achieving an optimal convergence rate of $O\left(\frac{1}{T}\right)$ among all first-order methods. Additionally, we prove that the algorithm's iterations converge to a point in the solution set. In our second contribution, we extend the Fast Extra Gradient (FEG) algorithm, as developed by Lee and Kim (2021), to constrained comonotone min-max optimization and comonotone inclusion, achieving the same $O\left(\frac{1}{T}\right)$ convergence rate. This rate is applicable to the broadest set of comonotone inclusion problems yet studied in the literature. Our analyses are based on simple potential function arguments, which might be useful for analyzing other accelerated algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05248v5</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Argyris Oikonomou, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Simple Opinion Dynamics for No-Regret Learning</title>
      <link>https://arxiv.org/abs/2306.08670</link>
      <description>arXiv:2306.08670v4 Announce Type: replace-cross 
Abstract: We study a cooperative multi-agent bandit setting in the distributed GOSSIP model: in every round, each of $n$ agents chooses an action from a common set, observes the action's corresponding reward, and subsequently exchanges information with a single randomly chosen neighbor, which may inform its choice in the next round. We introduce and analyze families of memoryless and time-independent protocols for this setting, inspired by opinion dynamics that are well-studied for other algorithmic tasks in the GOSSIP model. For stationary reward settings, we prove for the first time that these simple protocols exhibit best-of-both-worlds behavior, simultaneously obtaining constant cumulative regret scaling like $R(T)/T = \widetilde O(1/T)$, and also reaching consensus on the highest-mean action within $\widetilde O(\sqrt{n})$ rounds. We obtain these results by showing a new connection between the global evolution of these decentralized protocols and a class of zero-sum multiplicative weights update} processes. Using this connection, we establish a general framework for analyzing the population-level regret and other properties of our protocols. Finally, we show our protocols are also surprisingly robust to adversarial rewards, and in this regime we obtain sublinear regret scaling like $R(T)/T = \widetilde O(1/\sqrt{T})$ as long as the number of rounds does not grow too fast as a function of $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08670v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Lazarsfeld, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>The Low-Degree Hardness of Finding Large Independent Sets in Sparse Random Hypergraphs</title>
      <link>https://arxiv.org/abs/2404.03842</link>
      <description>arXiv:2404.03842v2 Announce Type: replace-cross 
Abstract: We study the algorithmic task of finding large independent sets in Erdos-Renyi $r$-uniform hypergraphs on $n$ vertices having average degree $d$. Krivelevich and Sudakov showed that the maximum independent set has density $\left(\frac{r\log d}{(r-1)d}\right)^{1/(r-1)}$. We show that the class of low-degree polynomial algorithms can find independent sets of density $\left(\frac{\log d}{(r-1)d}\right)^{1/(r-1)}$ but no larger. This extends and generalizes earlier results of Gamarnik and Sudan, Rahman and Virag, and Wein on graphs, and answers a question of Bal and Bennett. We conjecture that this statistical-computational gap holds for this problem.
  Additionally, we explore the universality of this gap by examining $r$-partite hypergraphs. A hypergraph $H=(V,E)$ is $r$-partite if there is a partition $V=V_1\cup\cdots\cup V_r$ such that each edge contains exactly one vertex from each set $V_i$. We consider the problem of finding large balanced independent sets (independent sets containing the same number of vertices in each partition) in random $r$-partite hypergraphs with $n$ vertices in each partition and average degree $d$. We prove that the maximum balanced independent set has density $\left(\frac{r\log d}{(r-1)d}\right)^{1/(r-1)}$ asymptotically. Furthermore, we prove an analogous low-degree computational threshold of $\left(\frac{\log d}{(r-1)d}\right)^{1/(r-1)}$. Our results recover and generalize recent work of Perkins and the second author on bipartite graphs.
  While the graph case has been extensively studied, this work is the first to consider statistical-computational gaps of optimization problems on random hypergraphs. Our results suggest that these gaps persist for larger uniformities as well as across many models. A somewhat surprising aspect of the gap for balanced independent sets is that the algorithm achieving the lower bound is a simple degree-1 polynomial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03842v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Dhawan, Yuzhou Wang</dc:creator>
    </item>
    <item>
      <title>Understanding Memory-Regret Trade-Off for Streaming Stochastic Multi-Armed Bandits</title>
      <link>https://arxiv.org/abs/2405.19752</link>
      <description>arXiv:2405.19752v2 Announce Type: replace-cross 
Abstract: We study the stochastic multi-armed bandit problem in the $P$-pass streaming model. In this problem, the $n$ arms are present in a stream and at most $m&lt;n$ arms and their statistics can be stored in the memory. We give a complete characterization of the optimal regret in terms of $m, n$ and $P$. Specifically, we design an algorithm with $\tilde O\left((n-m)^{1+\frac{2^{P}-2}{2^{P+1}-1}} n^{\frac{2-2^{P+1}}{2^{P+1}-1}} T^{\frac{2^P}{2^{P+1}-1}}\right)$ regret and complement it with an $\tilde \Omega\left((n-m)^{1+\frac{2^{P}-2}{2^{P+1}-1}} n^{\frac{2-2^{P+1}}{2^{P+1}-1}} T^{\frac{2^P}{2^{P+1}-1}}\right)$ lower bound when the number of rounds $T$ is sufficiently large. Our results are tight up to a logarithmic factor in $n$ and $P$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19752v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen He, Zichun Ye, Chihao Zhang</dc:creator>
    </item>
  </channel>
</rss>
