<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Nov 2025 05:01:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Energy-efficient recurrence quantification analysis</title>
      <link>https://arxiv.org/abs/2511.20684</link>
      <description>arXiv:2511.20684v1 Announce Type: cross 
Abstract: Recurrence quantification analysis (RQA) is a widely used tool for studying complex dynamical systems, but its standard implementation requires computationally expensive calculations of recurrence plots (RPs) and line length histograms. This study introduces strategies to compute RQA measures directly from time series or phase space vectors, avoiding the need to construct RPs. The calculations can be further accelerated and optimised by applying a random sampling procedure, in which only a subset of line structures is evaluated. These modifications result in shorter run times, less memory use and access, and lower overall energy consumption during analysis while maintaining accuracy. This makes them especially appealing for large-scale data analysis and machine learning applications. The ideas are not limited to diagonal line measures, but can likewise be applied to vertical line-based measures and to recurrence network measures. By lowering computational costs, the proposed strategies contribute to energy saving and sustainable data analysis, and broaden the applicability of recurrence-based methods in modern research contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20684v1</guid>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Norbert Marwan</dc:creator>
    </item>
    <item>
      <title>The Intrinsic Dimension of Collider Events and Model-Independent Searches in 100 Dimensions</title>
      <link>https://arxiv.org/abs/2511.20760</link>
      <description>arXiv:2511.20760v1 Announce Type: cross 
Abstract: The phase space of hadron collider events spans hundreds of dimensions, generating an intricate geometry that we are just starting to explore. The number of possible new physics signals is exponential in the number of dimensions and detecting all of them is currently impossible for any human or artificial intelligence. In this work we introduce a method to search for new physics model-independently in this high-dimensional space. It is based on the measurement of the most basic property of the manifold of collider events, its dimensionality. Our proposed technique does not suffer from a look-elsewhere effect that grows exponentially with the number of dimensions of the dataset, and by construction is insensitive to energy scale uncertainties. We illustrate its potential by finding new physics in simulated events with hundreds of phase space dimensions, taking as input single particles rather than jets. This study sets the stage for new model-independent search strategies based on global properties of collider data manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20760v1</guid>
      <category>hep-ph</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raffaele Tito D'Agnolo, Alfredo Glioti, Gabriele Rigo, Alessandro Valenti</dc:creator>
    </item>
    <item>
      <title>Transfer entropy for finite data</title>
      <link>https://arxiv.org/abs/2506.16215</link>
      <description>arXiv:2506.16215v3 Announce Type: replace 
Abstract: Transfer entropy is a widely used measure for quantifying directed information flows in complex systems. While the challenges of estimating transfer entropy for continuous data are well known, it has two major shortcomings for data of finite cardinality: it exhibits a substantial positive bias for sparse bin counts, and it has no clear means to assess statistical significance. By computing information content in finite data streams without explicitly considering symbols as instances of random variables, we derive a transfer entropy measure which is asymptotically equivalent to the standard plug-in estimator but remedies these issues for time series of small size and/or high cardinality, permitting a fully nonparametric assessment of statistical significance without simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16215v3</guid>
      <category>physics.data-an</category>
      <category>cs.SI</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alec Kirkley</dc:creator>
    </item>
    <item>
      <title>Reverse Stress Testing for Supply Chain Resilience</title>
      <link>https://arxiv.org/abs/2511.07289</link>
      <description>arXiv:2511.07289v2 Announce Type: replace 
Abstract: Supply chains' increasing globalization and complexity have recently produced unpredictable disruptions, ripple effects, and cascading resulting failures. Proposed practices for managing these concerns include the advanced field of forward stress testing, where threats and predicted impacts to the supply chain are evaluated to harden the system against the most damaging scenarios. Such approaches are limited by the almost endless number of potential threat scenarios and cannot capture residual risk. In contrast to forward stress testing, this paper develops a reverse stress testing (RST) methodology that allows to predict which changes, with probabilistic certainty, across the supply chain network are most likely to cause a specified level of disruption at a specific entity in the network. The methodology was applied to the case of copper wire imports into the USA, a simple good which may have significant implications for national security. Results show that Canada, Chile, and Mexico are predicted to consistently be sources of disruptions at multiple loss levels. Other countries (e.g., Papua New Guinea) may contribute to small disruptions but be less important for the catastrophic losses of concern for decision makers. Other countries' disruptions would be catastrophic (e.g., Chile). The proposed methodology is the first case of reverse stress testing application in complex multilayered supply chains and can be used to address both risk and resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07289v2</guid>
      <category>physics.data-an</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madison Smith, Michael Gaiewski, Sam Dulin, Laurel Williams, Jeffrey Keisler, Andrew Jin, Igor Linkov</dc:creator>
    </item>
    <item>
      <title>Eddy population based model for the wall-pressure spectrum at high Reynolds number</title>
      <link>https://arxiv.org/abs/2507.23098</link>
      <description>arXiv:2507.23098v2 Announce Type: replace-cross 
Abstract: Wall-pressure fluctuations beneath turbulent boundary layers drive noise and structural fatigue through interactions between fluid and structural modes. Conventional predictive models for the spectrum--such as the widely accepted Goody model (\textit{AIAA Journal} 42 (9), 2004, 1788--1794)--fail to capture the energetic growth in the {low-frequency range} that occurs at high Reynolds number, while at the same time over-predicting the variance. To address these shortcomings, two semi-empirical models are proposed for the wall-pressure spectrum in canonical turbulent boundary layers, pipes and channels for friction Reynolds numbers $\delta^+$ ranging from 180 to 47 000. Consistent with the approach outlined modelling the streamwise Reynolds stress in the recent work of Gustenyov et al. (\textit{J. Fluid Mech.} 1016, 2025, A23), the models are based on consideration of two eddy populations that broadly represent the contributions to the wall pressure fluctuations from inner-scale motions and outer-scale motions. The first model expresses the pre-multiplied spectrum as the sum of two overlapping log-normal populations: an inner-scaled term that is $\delta^+$-invariant and an outer-scaled term whose amplitude broadens smoothly with $\delta^+$. The model reproduces the 1-D convective signature and the emergence of an outer-scaled peak at large $\delta^+$. The second model, developed around newly available pipe data, uses theoretical arguments to prescribe the spectral shapes of the inner and outer populations. Embedding the $\delta^+$-dependence in smooth asymptotic functions yields a formulation that varies continuously with $\delta^+$ {and generalises beyond the calibration range}. Both models capture the full spectrum and {recover} the observed logarithmic growth of its variance, laying the groundwork for more accurate engineering predictions of wall-pressure fluctuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23098v2</guid>
      <category>physics.flu-dyn</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jonathan M. O. Massey, Alexander J. Smits, Beverley J. McKeon</dc:creator>
    </item>
    <item>
      <title>Assessing (im)balance in signed brain networks</title>
      <link>https://arxiv.org/abs/2508.00542</link>
      <description>arXiv:2508.00542v3 Announce Type: replace-cross 
Abstract: Many complex systems - be they financial, natural, or social - are composed of units - such as stocks, neurons, or agents - whose joint activity can be represented as a multivariate time series. An issue of both practical and theoretical importance concerns the possibility of inferring the presence of a static relationship between any two units solely from their dynamic state. The present contribution aims at tackling such an issue within the frame of traditional hypothesis testing: briefly speaking, our suggestion is that of linking any two units if behaving in a sufficiently similar way. To achieve such a goal, we project a multivariate time series onto a signed graph by i) comparing the empirical properties of the former with those expected under a suitable benchmark and ii) linking any two units with a positive (negative) edge in case the corresponding series shares a significantly large number of concordant (discordant) values. To define our benchmarks, we adopt an information-theoretic approach that is rooted into the constrained maximisation of Shannon entropy, a procedure inducing an ensemble of multivariate time series that preserves some of the empirical properties on average, while randomising everything else. We showcase the possible applications of our method by addressing one of the most timely issues in the domain of neurosciences, i.e. that of determining if brain networks are frustrated or not, and, if so, to what extent. As our results suggest, this is indeed the case, with the major contribution to the underlying negative subgraph coming from the subcortical structures (and, to a lesser extent, from the limbic regions). At the mesoscopic level, the minimisation of the Bayesian Information Criterion, instantiated with the Signed Stochastic Block Model, reveals that brain areas gather into modules aligning with the statistical variant of the Relaxed Balance Theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00542v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <category>physics.med-ph</category>
      <category>stat.ME</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marzio Di Vece, Emanuele Agrimi, Samuele Tatullo, Tommaso Gili, Miguel Ib\'a\~nez-Berganza, Tiziano Squartini</dc:creator>
    </item>
  </channel>
</rss>
