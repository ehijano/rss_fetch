<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Sep 2025 01:37:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Variational Gaussian Approximation in Replica Analysis of Parametric Models</title>
      <link>https://arxiv.org/abs/2509.11780</link>
      <description>arXiv:2509.11780v1 Announce Type: new 
Abstract: We revisit the replica method for analyzing inference and learning in parametric models, considering situations where the data-generating distribution is unknown or analytically intractable. Instead of assuming idealized distributions to carry out quenched averages analytically, we use a variational Gaussian approximation for the replicated system in grand canonical formalism in which the data average can be deferred and replaced by empirical averages, leading to stationarity conditions that adaptively determine the parameters of the trial Hamiltonian for each dataset. This approach clarifies how fluctuations affect information extraction and connects directly with the results of mathematical statistics or learning theory such as information criteria. As a concrete application, we analyze linear regression and derive learning curves. This includes cases with real-world datasets, where exact replica calculations are not feasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11780v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Takahashi</dc:creator>
    </item>
    <item>
      <title>(Un)biased data and spin glasses reveal clustering for Turing phase transitions within human-transformer interactions</title>
      <link>https://arxiv.org/abs/2505.02879</link>
      <description>arXiv:2505.02879v2 Announce Type: cross 
Abstract: This paper studies a Large Language Model's ability to exhibit intelligence equivalent to that of a human by analyzing temperature-induced phase transitions, abrupt changes in the macroscopic behavior of a system, in the Turing test. We utilize three approaches: statistical analysis and bias quantification of a human evaluation survey, information retrieval from real human-written versus AI-generated text data using cosine similarity as a comparison metric, and mathematical spin glass model and simulation. We collect text data in the case study of Flitzing, a tradition of emailing poem-like romantic invitations at Dartmouth College because of its richness in information. Across the three approaches, we obtain consistency in phase transition and clustering results, which also align with literature on the mathematics of transformers and metastability. Our work inspires utilizing spin glass theory for the mathematical foundations of artificial intelligence, especially under environmental stochasticity from human interactions, with justification from real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02879v2</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jackson George, Zachariah Yusaf, Stephanie Zoltick, Linh Huynh</dc:creator>
    </item>
    <item>
      <title>Metastable phase separation and information retrieval in multicomponent mixtures</title>
      <link>https://arxiv.org/abs/2509.10705</link>
      <description>arXiv:2509.10705v1 Announce Type: cross 
Abstract: Liquid mixtures can separate into phases with distinct composition. This phenomenon has recently come back to prominence due to its role in complex biological liquids, such as the cytoplasm, which contain thousands of components. For simple two-component mixtures phase-separated states are global free energy minima. However, local free energy minima, i.e. metastable states, are known to play a dominant role in complex systems with many components. For example, Hopfield neural networks can retrieve information from partial cues via relaxation to metastable states. Under what conditions can phase separated states be metastable, and what are the implications for information processing in multicomponent liquids? In this work we develop the general thermodynamic formalism of metastable phase separation. We then apply this formalism to an illustrative toy example inspired by recent experiments, binary mixtures with high-order interactions. Finally, as core application of the formalism, we study metastability in Hopfield liquids, a class of multicomponent mixtures capable of storing information on the composition of phases. We show that these phases can be retrieved from partial cues via metastable phase separation. Spatial simulations of liquids with a large number of components match our analytical solution. Our work suggests that complex biological mixtures can perform information retrieval through metastable phase separation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10705v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Braz Teixeira, Izaak Neri, Pablo Sartori</dc:creator>
    </item>
    <item>
      <title>Automated training of neural-network interatomic potentials</title>
      <link>https://arxiv.org/abs/2509.11703</link>
      <description>arXiv:2509.11703v1 Announce Type: cross 
Abstract: Neural-network interatomic potentials (NNIPs) have transformed atomistic simulations, by enabling molecular dynamics simulations with near ab initio accuracy at reduced computational costs and improved scalability. Despite these advances, crafting NNIPs remains complex, demanding specialized expertise in both machine learning and electronic-structure calculations. Here, we introduce an automated, open-source, and user-friendly workflow that streamlines the creation of accurate NNIPs. Our approach integrates density-functional theory, data augmentation strategies and classical molecular dynamics to systematically explore the potential energy landscape. Our active-learning strategy leverages on-the-fly calibration of committee disagreement against true errors to ensure reliable uncertainty estimates. We use electronic-structure descriptors and dimensionality reduction to analyze the efficiency of our active learning strategy, which is shown to minimize both false positives and false negatives when deciding what to relabel with ab initio calculations. The method is validated on the fully automated training of a NNIP for a diverse set of carbon allotropes, reaching state-of-the-art accuracy and data efficiency. This platform democratizes NNIP development, empowering users to achieve high-precision simulations with minimal human intervention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11703v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Bidoggia, Nataliia Manko, Maria Peressi, Antimo Marrazzo</dc:creator>
    </item>
    <item>
      <title>Spectral Small-Incremental-Entangling: Breaking Quasi-Polynomial Complexity Barriers in Long-Range Interacting Systems</title>
      <link>https://arxiv.org/abs/2509.12014</link>
      <description>arXiv:2509.12014v1 Announce Type: cross 
Abstract: A key challenge in quantum complexity is how entanglement structure emerges from dynamics, highlighted by advances in simulators and information processing. The Lieb--Robinson bound sets a locality-based speed limit on information propagation, while the Small-Incremental-Entangling (SIE) theorem gives a universal constraint on entanglement growth. Yet, SIE bounds only total entanglement, leaving open the fine entanglement structure. In this work, we introduce Spectral-Entangling Strength, measuring the structural entangling power of an operator, and prove a Spectral SIE theorem: a universal limit for R\'enyi entanglement growth at $\alpha \ge 1/2$, revealing a robust $1/s^2$ tail in the entanglement spectrum. At $\alpha=1/2$ the bound is qualitatively and quantitatively optimal, identifying the universal threshold beyond which growth is unbounded. This exposes the detailed structure of Schmidt coefficients, enabling rigorous truncation-based error control and linking entanglement to computational complexity. Our framework further establishes a generalized entanglement area law under adiabatic paths, extending a central principle of many-body physics to general interactions. Practically, we show that 1D long-range interacting systems admit polynomial bond-dimension approximations for ground, time-evolved, and thermal states. This closes the quasi-polynomial gap and proves such systems are simulable with polynomial complexity comparable to short-range models. By controlling R\'enyi entanglement, we also derive the first rigorous precision-guarantee bound for the time-dependent density-matrix-renormalization-group algorithm. Overall, our results extend SIE and provide a unified framework that reveals the detailed structure of quantum complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12014v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donghoon Kim, Yusuke Kimura, Hugo Mackay, Yosuke Mitsuhashi, Hideaki Nishikawa, Carla Rubiliani, Cheng Shang, Ayumi Ukai, Tomotaka Kuwahara</dc:creator>
    </item>
    <item>
      <title>High-capacity associative memory in a quantum-optical spin glass</title>
      <link>https://arxiv.org/abs/2509.12202</link>
      <description>arXiv:2509.12202v1 Announce Type: cross 
Abstract: The Hopfield model describes a neural network that stores memories using all-to-all-coupled spins. Memory patterns are recalled under equilibrium dynamics. Storing too many patterns breaks the associative recall process because frustration causes an exponential number of spurious patterns to arise as the network becomes a spin glass. Despite this, memory recall in a spin glass can be restored, and even enhanced, under quantum-optical nonequilibrium dynamics because spurious patterns can now serve as reliable memories. We experimentally observe associative memory with high storage capacity in a driven-dissipative spin glass made of atoms and photons. The capacity surpasses the Hopfield limit by up to seven-fold in a sixteen-spin network. Atomic motion boosts capacity by dynamically modifying connectivity akin to short-term synaptic plasticity in neural networks, realizing a precursor to learning in a quantum-optical system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12202v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.quant-gas</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.atom-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan P. Marsh, David Atri Schuller, Yunpeng Ji, Henry S. Hunt, Surya Ganguli, Sarang Gopalakrishnan, Jonathan Keeling, Benjamin L. Lev</dc:creator>
    </item>
    <item>
      <title>Simplified derivations for high-dimensional convex learning problems</title>
      <link>https://arxiv.org/abs/2412.01110</link>
      <description>arXiv:2412.01110v5 Announce Type: replace 
Abstract: Statistical-physics calculations in machine learning and theoretical neuroscience often involve lengthy derivations that obscure physical interpretation. Here, we give concise, non-replica derivations of several key results and highlight their underlying similarities. In particular, using a cavity approach, we analyze three high-dimensional learning problems: perceptron classification of points, perceptron classification of manifolds, and kernel ridge regression. These problems share a common structure--a bipartite system of interacting feature and datum variables--enabling a unified analysis. Furthermore, for perceptron-capacity problems, we identify a symmetry that allows derivation of correct capacities through a naive method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01110v5</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David G. Clark, Haim Sompolinsky</dc:creator>
    </item>
    <item>
      <title>Spin-glass dynamics: experiment, theory and simulation</title>
      <link>https://arxiv.org/abs/2412.08381</link>
      <description>arXiv:2412.08381v2 Announce Type: replace 
Abstract: The study of spin-glass dynamics, long considered the paradigmatic complex system, has reached important milestones. The availability of single crystals has allowed the experimental measurement of spin-glass coherence lengths of almost macroscopic dimensions, while the advent of special-purpose computers enables dynamical simulations that approach experimental scales. This review provides an account of the quantitative convergence of these two avenues of research, with precise experimental measurements of the expected scaling laws and numerical reproduction of classic experimental results, such as memory and rejuvenation. The article opens with a brief review of the defining spin-glass properties, randomness and frustration, and their experimental consequences. These apparently simple characteristics are shown to generate rich and complex physics. Models are introduced that enable quantitative dynamical descriptions. After a summary of the main numerical results in equilibrium, paying particular attention to temperature chaos, this review examines off-equilibrium dynamics in the absence of a magnetic field and shows how it can be related to equilibrium structures through the fluctuation-dissipation relations. The nonlinear response at a given temperature is then developed, including experiments and scaling in the vicinity of the transition temperature $T_\mathrm{g}$. The consequences of temperature change $\unicode{x2013}$including temperature chaos, rejuvenation, and memory$\unicode{x2013}$ are reviewed. The interpretation of these phenomena requires identifying several length scales relevant to dynamics, which, in turn, generate new insights. Finally, issues for future investigations are introduced, including what is to be nailed down theoretically, why the Ising Edwards-Anderson model is so successful at modeling spin-glass dynamics, and experiments yet to be undertaken.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08381v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. D. Dahlberg, I. Gonz\'alez-Adalid Pemart\'in, E. Marinari, V. Martin-Mayor, J. Moreno-Gordo, R. L. Orbach, I. Paga, G. Parisi, F. Ricci-Tersenghi, J. J. Ruiz-Lorenzo, D. Yllanes</dc:creator>
    </item>
    <item>
      <title>Learning Chaotic Dynamics with Neuromorphic Network Dynamics</title>
      <link>https://arxiv.org/abs/2506.10773</link>
      <description>arXiv:2506.10773v2 Announce Type: replace 
Abstract: This study investigates how dynamical systems may be learned and modelled with a neuromorphic network which is itself a dynamical system. The neuromorphic network used in this study is based on a complex electrical circuit comprised of memristive elements that produce neuro-synaptic nonlinear responses to input electrical signals. To determine how computation may be performed using the physics of the underlying system, the neuromorphic network was simulated and evaluated on autonomous prediction of a multivariate chaotic time series, implemented with a reservoir computing framework. Through manipulating only input electrodes and voltages, optimal nonlinear dynamical responses were found when input voltages maximise the number of memristive components whose internal dynamics explore the entire dynamical range of the memristor model. Increasing the network coverage with the input electrodes was found to suppress other nonlinear responses that are less conducive to learning. These results provide valuable insights into how a physical neuromorphic network device can be feasibly optimised for learning complex dynamical systems using only external control parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10773v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yinhao Xu, Georg A. Gottwald, Zdenka Kuncic</dc:creator>
    </item>
    <item>
      <title>Theory of the Anderson transition in three-dimensional chiral symmetry classes: Connection to type-II superconductors</title>
      <link>https://arxiv.org/abs/2506.21050</link>
      <description>arXiv:2506.21050v2 Announce Type: replace 
Abstract: Phase transitions governed by topological defects constitute a cornerstone of modern physics. Two-dimensional (2D) Anderson transitions in chiral symmetry classes are driven by the proliferation of vortex-antivortex pairs -- a mechanism analogous to the Berezinskii-Kosterlitz-Thouless (BKT) transition in the 2D XY model. In this work, we extend this paradigm to three-dimensional (3D) chiral symmetry classes, where vortex loops emerge as the key topological defects governing the Anderson transition. By deriving the dual representation of the 3D nonlinear sigma model for the chiral unitary class, we develop a mean-field theory of its Anderson transition and elucidate the role of 1D weak band topology in the Anderson transition. Strikingly, our dual representation of the 3D NLSM in the chiral symmetry class uncovers its connection to the magnetostatics of 3D type-II superconductors. The metal-to-quasilocalized and quasilocalized-to-insulating transitions in 3D chiral symmetry class share a unified theoretical framework with the normal-to-mixed and mixed-to-superconducting transitions in 3D type-II superconductors under an external magnetic field, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21050v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.supr-con</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengwei Zhao, Ryuichi Shindou</dc:creator>
    </item>
    <item>
      <title>Time-dependent correlations of the Edwards-Anderson order parameter above the spin-glass transition</title>
      <link>https://arxiv.org/abs/2509.08955</link>
      <description>arXiv:2509.08955v2 Announce Type: replace 
Abstract: In 1975 Edwards and Anderson introduced a new paradigm that interacting quenched systems, such as a spin-glass, have a phase transition in which long time memory of spatial patterns is realized without spatial correlations. We show here that the information about the time-dependent correlations above the spin-glass transition are embedded in the four spin correlations of the intensity of speckle pattern. This encodes the spin-orientation memory and can be measured by the technique of resonant magnetic x-ray photon correlation spectroscopy (RM- XPCS). We have implemented this method to observe and accurately characterize the critical slowing down of the spin orientation fluctuations in the classic metallic spin glass alloy $Cu_{1-x}{Mn}_x$ over time scales of ${2}$ sec. to $2 \times 10^{\mathbf{4}}$ secs. Remarkably the divergence of the correlation time as a function of temperature is consistent with the Vogel-Vulcher law, universally used to characterize the viscous relaxation time in structural glasses. Our method also opens the way for studying phase transitions in systems such as spin ices, quantum spin liquids, the structural glass transition, as well as possibly provide new perspectives on the multifarious problems in which spin-glass concepts have found applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08955v2</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingjin Song, Sheena K. K. Patel, Rupak Bhattacharya, Yi Yang, Sudip Pandey, Xiao M. Chen, Eric Lee-Wong, Kalyan Sasmal, M. Brian Maple, Eric E. Fullerton, Sujoy Roy, Claudio Mazzoli, Chandra M. Varma, Sunil K. Sinha</dc:creator>
    </item>
    <item>
      <title>Topological Phases of Many-Body Localized Systems: Beyond Eigenstate Order</title>
      <link>https://arxiv.org/abs/2408.00825</link>
      <description>arXiv:2408.00825v3 Announce Type: replace-cross 
Abstract: Many-body localization (MBL) lends remarkable robustness to nonequilibrium phases of matter. Such phases can show topological and symmetry breaking order in their ground and excited states, but they may also belong to an anomalous localized topological phase (ALT phase). All eigenstates in an ALT phase are trivial, in that they can be deformed to product states, but the entire Hamiltonian cannot be deformed to a trivial localized model without going through a delocalization transition. Using a correspondence between MBL phases with short-ranged entanglement and locality preserving unitaries - called quantum cellular automata (QCA) - we reduce the classification of ALT phases to that of QCA. This method extends to periodically (Floquet) and quasiperiodically driven ALT phases, and captures anomalous Floquet phases within the same framework as static phases. We considerably develop the study of the topology of QCA, allowing us to classify static and driven ALT phases in low dimensions. The QCA framework further generalizes to include symmetry-enriched ALT phases (SALT phases) - which we also classify in low dimensions - and provides a large class of soluble models suitable for realization in quantum simulators. In systematizing the study of ALT phases, we both greatly extend the classification of interacting nonequilibrium systems and clarify a confusion in the literature which implicitly equates nontrivial Hamiltonians with nontrivial ground states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00825v3</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.dis-nn</category>
      <category>quant-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David M. Long, Dominic V. Else</dc:creator>
    </item>
    <item>
      <title>Winding Number Statistics for Chiral Random Matrices: Universal Correlations and Statistical Moments in the Unitary Case</title>
      <link>https://arxiv.org/abs/2410.22808</link>
      <description>arXiv:2410.22808v2 Announce Type: replace-cross 
Abstract: The winding number is the topological invariant that classifies chiral symmetric Hamiltonians with one-dimensional parametric dependence. In this work we complete our study of the winding number statistics in a random matrix model belonging to the chiral unitary class AIII. We show that in the limit of large matrix dimensions the winding number distribution becomes Gaussian. Our results include expressions for the statistical moments of the winding number and for the k-point correlation function of the winding number density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22808v2</guid>
      <category>math-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>math.MP</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nico Hahn, Mario Kieburg, Omri Gat, Thomas Guhr</dc:creator>
    </item>
    <item>
      <title>Phase probabilities in first-order transitions using machine learning</title>
      <link>https://arxiv.org/abs/2411.00733</link>
      <description>arXiv:2411.00733v3 Announce Type: replace-cross 
Abstract: We set out to explore the possibility of investigating the critical behavior of systems with first-order phase transition using deep machine learning. We propose a machine learning protocol with ternary classification of instantaneous spin configurations using known values of disordered phase energy and ordered phase energy. The trained neural network is used to predict whether a given sample belong to one or another phase of matter. This allows us to estimate for the first time the probability that configurations with a certain energy belong to the ordered phase, coexistence phase, and disordered phase. Based on these probabilities, we obtained estimates of the values of the critical energies and latent heat for the Potts model with 10 and 20 components, which undergoes a strong discontinuous transition. We also found that the probabilities may reflect geometric transitions in the coexistence phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00733v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diana Sukhoverkhova, Vyacheslav Mozolenko, Lev Shchur</dc:creator>
    </item>
  </channel>
</rss>
