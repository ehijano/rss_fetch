<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Apr 2025 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Likelihood Level Adapted Estimation of Marginal Likelihood for Bayesian Model Selection</title>
      <link>https://arxiv.org/abs/2503.23018</link>
      <description>arXiv:2503.23018v1 Announce Type: new 
Abstract: In computational mechanics, multiple models are often present to describe a physical system. While Bayesian model selection is a helpful tool to compare these models using measurement data, it requires the computationally expensive estimation of a multidimensional integral -- known as the marginal likelihood or as the model evidence (\textit{i.e.}, the probability of observing the measured data given the model). This study presents efficient approaches for estimating this marginal likelihood by transforming it into a one-dimensional integral that is subsequently evaluated using a quadrature rule at multiple adaptively-chosen iso-likelihood contour levels. Three different algorithms are proposed to estimate the probability mass at each adapted likelihood level using samples from importance sampling, stratified sampling, and Markov chain Monte Carlo sampling, respectively. The proposed approach is illustrated through four numerical examples. The first example validates the algorithms against a known exact marginal likelihood. The second example uses an 11-story building subjected to an earthquake excitation with an uncertain hysteretic base isolation layer with two models to describe the isolation layer behavior. The third example considers flow past a cylinder when the inlet velocity is uncertain. Based on these examples, the method with stratified sampling is by far the most accurate and efficient method for complex model behavior in low dimension. In the fourth example, the proposed approach is applied to heat conduction in an inhomogeneous plate with uncertain thermal conductivity modeled through a 100 degree-of-freedom Karhunen-Lo\`{e}ve expansion. The results indicate that MultiNest cannot efficiently handle the high-dimensional parameter space, whereas the proposed MCMC-based method more accurately and efficiently explores the parameter space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23018v1</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhayan De, Reza Farzad, Patrick T. Brewick, Erik A. Johnson, Steven F. Wojtkiewicz</dc:creator>
    </item>
    <item>
      <title>Simulations in Statistical Workflows</title>
      <link>https://arxiv.org/abs/2503.24011</link>
      <description>arXiv:2503.24011v1 Announce Type: new 
Abstract: Simulations play important and diverse roles in statistical workflows, for example, in model specification, checking, validation, and even directly in model inference. Over the past decades, the application areas and overall potential of simulations in statistical workflows have expanded significantly, driven by the development of new simulation-based algorithms and exponentially increasing computational resources. In this paper, we examine past and current trends in the field and offer perspectives on how simulations may shape the future of statistical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24011v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul-Christian B\"urkner, Marvin Schmitt, Stefan T. Radev</dc:creator>
    </item>
    <item>
      <title>Estimating a graph's spectrum via random Kirchhoff forests</title>
      <link>https://arxiv.org/abs/2503.24236</link>
      <description>arXiv:2503.24236v1 Announce Type: new 
Abstract: Exact eigendecomposition of large matrices is very expensive, and it is practically impossible to compute exact eigenvalues. Instead, one may set a more modest goal of approaching the empirical distribution of the eigenvalues, recovering the overall shape of the eigenspectrum. Current approaches to spectral estimation typically work with \emph{moments} of the spectral distribution. These moments are first estimated using Monte Carlo trace estimators, then the estimates are combined to approximate the spectral density. In this article we show how \emph{Kirchhoff forests}, which are random forests on graphs, can be used to estimate certain non-linear moments of very large graph Laplacians. We show how to combine these moments into an estimate of the spectral density. If the estimate's desired precision isn't too high, our approach paves the way to the estimation of a graph's spectrum in time sublinear in the number of links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24236v1</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Barthelm\'e, Fabienne Castell, Alexandre Gaudilli\`ere, Clothilde Melot, Matteo Quattropani, Nicolas Tremblay</dc:creator>
    </item>
    <item>
      <title>Tree-Guided $L_1$-Convex Clustering</title>
      <link>https://arxiv.org/abs/2503.24012</link>
      <description>arXiv:2503.24012v1 Announce Type: cross 
Abstract: Convex clustering is a modern clustering framework that guarantees globally optimal solutions and performs comparably to other advanced clustering methods. However, obtaining a complete dendrogram (clusterpath) for large-scale datasets remains computationally challenging due to the extensive costs associated with iterative optimization approaches. To address this limitation, we develop a novel convex clustering algorithm called Tree-Guided $L_1$-Convex Clustering (TGCC). We first focus on the fact that the loss function of $L_1$-convex clustering with tree-structured weights can be efficiently optimized using a dynamic programming approach. We then develop an efficient cluster fusion algorithm that utilizes the tree structure of the weights to accelerate the optimization process and eliminate the issue of cluster splits commonly observed in convex clustering. By combining the dynamic programming approach with the cluster fusion algorithm, the TGCC algorithm achieves superior computational efficiency without sacrificing clustering performance. Remarkably, our TGCC algorithm can construct a complete clusterpath for $10^6$ points in $\mathbb{R}^2$ within 15 seconds on a standard laptop without the need for parallel or distributed computing frameworks. Moreover, we extend the TGCC algorithm to develop biclustering and sparse convex clustering algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24012v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingyuan Zhang, Yoshikazu Terada</dc:creator>
    </item>
    <item>
      <title>Selective Inference in Graphical Models via Maximum Likelihood</title>
      <link>https://arxiv.org/abs/2503.24311</link>
      <description>arXiv:2503.24311v1 Announce Type: cross 
Abstract: The graphical lasso is a widely used algorithm for fitting undirected Gaussian graphical models. However, for inference on functionals of edge values in the learned graph, standard tools lack formal statistical guarantees, such as control of the type I error rate. In this paper, we introduce a selective inference method for asymptotically valid inference after graphical lasso selection with added randomization. We obtain a selective likelihood, conditional on the event of selection, through a change of variable on the known density of the randomization variables. Our method enables interval estimation and hypothesis testing for a wide range of functionals of edge values in the learned graph using the conditional maximum likelihood estimate. Our numerical studies show that introducing a small amount of randomization: (i) greatly increases power and yields substantially shorter intervals compared to other conditional inference methods, including data splitting; (ii) ensures intervals of bounded length in high-dimensional settings where data splitting is infeasible due to insufficient samples for inference; (iii) enables inference for a wide range of inferential targets in the learned graph, including measures of node influence and connectivity between nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24311v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofia Guglielmini, Gerda Claeskens, Snigdha Panigrahi</dc:creator>
    </item>
    <item>
      <title>Langevin Bi-fidelity Importance Sampling for Failure Probability Estimation</title>
      <link>https://arxiv.org/abs/2503.17796</link>
      <description>arXiv:2503.17796v2 Announce Type: replace 
Abstract: Estimating failure probability is a key task in the field of uncertainty quantification. In this domain, importance sampling has proven to be an effective estimation strategy; however, its efficiency heavily depends on the choice of the biasing distribution. An improperly selected biasing distribution can significantly increase estimation error. One approach to address this challenge is to leverage a less expensive, lower-fidelity surrogate. Building on the accessibility to such a model and its derivative on the random uncertain inputs, we introduce an importance sampling-based estimator, termed the Langevin bi-fidelity importance sampling (L-BF-IS), which uses score-function-based sampling algorithms to generate new samples and substantially reduces the mean square error (MSE) of failure probability estimation. The proposed method demonstrates lower estimation error, especially in high-dimensional input spaces and when limited high-fidelity evaluations are available. The L-BF-IS estimator's effectiveness is validated through experiments with two synthetic functions and two real-world applications governed by partial differential equations. These real-world applications involve a composite beam, which is represented using a simplified Euler-Bernoulli equation as a low-fidelity surrogate, and a steady-state stochastic heat equation, for which a pre-trained neural operator serves as the low-fidelity surrogate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17796v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nuojin Cheng, Alireza Doostan</dc:creator>
    </item>
    <item>
      <title>Simulation-based Bayesian Inference from Privacy Protected Data</title>
      <link>https://arxiv.org/abs/2310.12781</link>
      <description>arXiv:2310.12781v4 Announce Type: replace-cross 
Abstract: Many modern statistical analysis and machine learning applications require training models on sensitive user data. Under a formal definition of privacy protection, differentially private algorithms inject calibrated noise into the confidential data or during the data analysis process to produce privacy-protected datasets or queries. However, restricting access to only privatized data during statistical analysis makes it computationally challenging to make valid statistical inferences. In this work, we propose simulation-based inference methods from privacy-protected datasets. In addition to sequential Monte Carlo approximate Bayesian computation, we adopt neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and with ordinary linear regression models. Illustrating the privacy-utility trade-off, our experiments and analysis demonstrate the necessity and feasibility of designing valid statistical inference procedures to correct for biases introduced by the privacy-protection mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12781v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifei Xiong, Nianqiao Phyllis Ju, Sanguo Zhang</dc:creator>
    </item>
    <item>
      <title>Constructing Bayesian Optimal Designs for Discrete Choice Experiments by Simulated Annealing</title>
      <link>https://arxiv.org/abs/2402.18533</link>
      <description>arXiv:2402.18533v2 Announce Type: replace-cross 
Abstract: Discrete choice experiments (DCEs) investigate the attributes that influence individuals' choices when selecting among various options. To enhance the quality of the estimated choice models, researchers opt for Bayesian optimal designs that utilize existing information about the attributes' preferences. Given the nonlinear nature of choice models, the construction of an appropriate design requires efficient algorithms. Among these, the coordinate-exchange (CE) algorithm is commonly employed for constructing designs based on the MNL model. However, as a hill-climbing method, the CE algorithm tends to quickly converge to local optima, potentially limiting the quality of the resulting designs. We propose the use of a simulated annealing (SA) algorithm to construct Bayesian optimal designs. This algorithm accepts both superior and inferior solutions, avoiding premature convergence and allowing a more thorough exploration of potential solutions. Consequently, it ultimately obtains higher-quality choice designs compared to the CE algorithm. Our work represents the first application of an SA algorithm in constructing Bayesian optimal designs for DCEs. Through extensive computational experiments, we demonstrate that the SA designs generally outperform the CE designs in terms of statistical efficiency, especially when the prior preference information is highly uncertain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18533v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yicheng Mao, Roselinde Kessels, Tom van der Zanden</dc:creator>
    </item>
    <item>
      <title>Towards a turnkey approach to unbiased Monte Carlo estimation of smooth functions of expectations</title>
      <link>https://arxiv.org/abs/2403.20313</link>
      <description>arXiv:2403.20313v3 Announce Type: replace-cross 
Abstract: Given a smooth function $f$, we develop a general approach to turn Monte Carlo samples with expectation $m$ into an unbiased estimate of $f(m)$. Specifically, we develop estimators that are based on randomly truncating the Taylor series expansion of $f$ and estimating the coefficients of the truncated series. We derive their properties and propose a strategy to set their tuning parameters -- which depend on $m$ -- automatically, with a view to make the whole approach simple to use. We develop our methods for the specific functions $f(x)=\log x$ and $f(x)=1/x$, as they arise in several statistical applications such as maximum likelihood estimation of latent variable models and Bayesian inference for un-normalised models. Detailed numerical studies are performed for a range of applications to determine how competitive and reliable the proposed approach is.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20313v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Chopin, Francesca R. Crucinio, Sumeetpal S. Singh</dc:creator>
    </item>
    <item>
      <title>Moments by Integrating the Moment-Generating Function</title>
      <link>https://arxiv.org/abs/2410.23587</link>
      <description>arXiv:2410.23587v3 Announce Type: replace-cross 
Abstract: We introduce a novel method for obtaining a wide variety of moments of a random variable with a well-defined moment-generating function (MGF). We derive new expressions for fractional moments and fractional absolute moments, both central and non-central moments. The new moment expressions are relatively simple integrals that involve the MGF, but do not require its derivatives. We label the new method CMGF because it uses a complex extension of the MGF and can be used to obtain complex moments. We illustrate the new method with three applications where the MGF is available in closed-form, while the corresponding densities and the derivatives of the MGF are either unavailable or very difficult to obtain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23587v3</guid>
      <category>econ.EM</category>
      <category>q-fin.CP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Reinhard Hansen, Chen Tong</dc:creator>
    </item>
    <item>
      <title>Optimal control under uncertainty with joint chance state constraints: almost-everywhere bounds, variance reduction, and application to (bi-)linear elliptic PDEs</title>
      <link>https://arxiv.org/abs/2412.05125</link>
      <description>arXiv:2412.05125v2 Announce Type: replace-cross 
Abstract: We study optimal control of PDEs under uncertainty with the state variable subject to joint chance constraints. The controls are deterministic, but the states are probabilistic due to random variables in the governing equation. Joint chance constraints ensure that the random state variable meets pointwise bounds with high probability. For linear governing PDEs and elliptically distributed random parameters, we prove existence and uniqueness results for almost-everywhere state bounds. Using the spherical-radial decomposition (SRD) of the uncertain variable, we prove that when the probability is very large or small, the resulting Monte Carlo estimator for the chance constraint probability exhibits substantially reduced variance compared to the standard Monte Carlo estimator. We further illustrate how the SRD can be leveraged to efficiently compute derivatives of the probability function, and discuss different expansions of the uncertain variable in the governing equation. Numerical examples for linear and bilinear PDEs compare the performance of Monte Carlo and quasi-Monte Carlo sampling methods, examining probability estimation convergence as the number of samples increases. We also study how the accuracy of the probabilities depends on the truncation of the random variable expansion, and numerically illustrate the variance reduction of the SRD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05125v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rene Henrion, Georg Stadler, Florian Wechsung</dc:creator>
    </item>
    <item>
      <title>Score-Based Metropolis-Hastings Algorithms</title>
      <link>https://arxiv.org/abs/2501.00467</link>
      <description>arXiv:2501.00467v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce a new approach for integrating score-based models with the Metropolis-Hastings algorithm. While traditional score-based diffusion models excel in accurately learning the score function from data points, they lack an energy function, making the Metropolis-Hastings adjustment step inaccessible. Consequently, the unadjusted Langevin algorithm is often used for sampling using estimated score functions. The lack of an energy function then prevents the application of the Metropolis-adjusted Langevin algorithm and other Metropolis-Hastings methods, limiting the wealth of other algorithms developed that use acceptance functions. We address this limitation by introducing a new loss function based on the \emph{detailed balance condition}, allowing the estimation of the Metropolis-Hastings acceptance probabilities given a learned score function. We demonstrate the effectiveness of the proposed method for various scenarios, including sampling from heavy-tail distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00467v2</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Aloui, Ali Hasan, Juncheng Dong, Zihao Wu, Vahid Tarokh</dc:creator>
    </item>
    <item>
      <title>Geometric Ergodicity of a Gibbs Algorithm for a Normal Model With a Horseshoe Prior</title>
      <link>https://arxiv.org/abs/2503.00538</link>
      <description>arXiv:2503.00538v2 Announce Type: replace-cross 
Abstract: In this paper, we consider a two-stage Gibbs sampler for a normal linear regression model with a horseshoe prior. Under some assumptions, we show that it produces a geometrically ergodic Markov chain. In particular, we prove geometric ergodicity under some three-parameter beta global prior which does not have a finite $(p / 5)$-th negative moment, where $p$ is the number of regression coefficients. This is in contrast to the case of a known general result which is applicable if the global parameter has a finite approximately $(p / 2)$-th negative moment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00538v2</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasuyuki Hamura</dc:creator>
    </item>
  </channel>
</rss>
