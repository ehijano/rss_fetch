<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Jun 2025 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Introduction to Solving the Least-Squares Problem in Variational Data Assimilation</title>
      <link>https://arxiv.org/abs/2506.09211</link>
      <description>arXiv:2506.09211v1 Announce Type: new 
Abstract: Variational data assimilation is a technique for combining measured data with dynamical models. It is a key component of Earth system state estimation and is commonly used in weather and ocean forecasting. The approach involves a large-scale generalized nonlinear least-squares problem. Solving the resulting sequence of sparse linear subproblems requires the use of sophisticated numerical linear algebra methods. In practical applications, the computational demands severely limit the number of iterations of a Krylov subspace solver that can be performed and so high-quality preconditioners are vital. In this paper, we introduce variational data assimilation from a numerical linear algebra perspective and review current solution techniques, with a focus on the challenges that arise in large-scale geophysical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09211v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>I. Dau\v{z}ickait\.e, M. A. Freitag, S. G\"urol, A. S. Lawless, A. Ramage, J. A. Scott, J. M. Tabeart</dc:creator>
    </item>
    <item>
      <title>Improved error bounds for Koopman operator and reconstructed trajectories approximations with kernel-based methods</title>
      <link>https://arxiv.org/abs/2506.09266</link>
      <description>arXiv:2506.09266v1 Announce Type: new 
Abstract: In this article, we propose a new error bound for Koopman operator approximation using Kernel Extended Dynamic Mode Decomposition. The new estimate is $O(N^{-1/2})$, with a constant related to the probability of success of the bound, given by Hoeffding's inequality, similar to other methodologies, such as Philipp et al. Furthermore, we propose a \textit{lifting back} operator to obtain trajectories generated by embedding the initial state and iterating a linear system in a higher dimension. This naturally yields an $O(N^{-1/2})$ error bound for mean trajectories. Finally, we show numerical results including an example of nonlinear system, exhibiting successful approximation with exponential decay faster than $-1/2$, as suggested by the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09266v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Olgu\'in, Axel Osses, H\'ector Ram\'irez</dc:creator>
    </item>
    <item>
      <title>A discontinuous Galerkin plane wave neural network method for Helmholtz equation and Maxwell's equations</title>
      <link>https://arxiv.org/abs/2506.09309</link>
      <description>arXiv:2506.09309v1 Announce Type: new 
Abstract: In this paper we propose a discontinuous Galerkin plane wave neural network (DGPWNN) method for approximately solving Helmholtz equation and Maxwell's equations. In this method, we define an elliptic-type variational problem as in the plane wave least square method with $h-$refinement and introduce the adaptive construction of recursively augmented discontinuous Galerkin subspaces whose basis functions are realizations of element-wise neural network functions with $hp-$refinement, where the activation function is chosen as a complex-valued exponential function like the plane wave function.
  A sequence of basis functions approaching the unit residuals are recursively generated by iteratively solving quasi-maximization problems associated with the underlying residual functionals and the intersection of the closed unit ball and discontinuous plane wave neural network spaces. The convergence results of the DGPWNN method are established without the assumption on the boundedness of the neural network parameters. Numerical experiments confirm the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09309v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Yuan, Menghui Wu, Qiya Hu</dc:creator>
    </item>
    <item>
      <title>Overcoming logarithmic singularities in the Cahn-Hilliard equation with Flory-Huggins potential: An unconditionally convergent ADMM approach</title>
      <link>https://arxiv.org/abs/2506.09361</link>
      <description>arXiv:2506.09361v1 Announce Type: new 
Abstract: The Cahn-Hilliard equation with Flory-Huggins potential serves as a fundamental phase field model for describing phase separation phenomena. Due to the presence of logarithmic singularities at $u=\pm 1$, the solution $u$ is constrained within the interval $(-1,1)$. While convex splitting schemes are commonly employed to preserve this bound and guarantee unconditional unique solvability, their practical implementation requires solving nonlinear systems containing singular logarithmic terms at each time step. This introduces significant challenges in both ensuring convergence of iterative solvers and maintaining the solution bounds throughout the iterations. Existing solvers often rely on restrictive conditions -- such as the strict separation property or small time step sizes -- to ensure convergence, which can limit their applicability. In this work, we introduce a novel iterative solver that is specifically designed for singular nonlinear systems, with the use of a variant of the alternating direction method of multipliers (ADMM). By developing a tailored variable splitting strategy within the ADMM framework, our method efficiently decouples the challenging logarithmic nonlinearity, enabling effective handling of singularities. Crucially, we rigorously prove the unconditional convergence of our ADMM-based solver, which removes the need for time step constraints or strict separation conditions. This allows us to fully leverage the unconditional solvability offered by convex splitting schemes. Comprehensive numerical experiments demonstrate the superior efficiency and robustness of our ADMM variant, strongly validating both our algorithmic design and theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09361v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruo Li, Shengtong Liang, Zhonghua Qiao</dc:creator>
    </item>
    <item>
      <title>Subspace-constrained randomized coordinate descent for linear systems with good low-rank matrix approximations</title>
      <link>https://arxiv.org/abs/2506.09394</link>
      <description>arXiv:2506.09394v1 Announce Type: new 
Abstract: The randomized coordinate descent (RCD) method is a classical algorithm with simple, lightweight iterations that is widely used for various optimization problems, including the solution of positive semidefinite linear systems. As a linear solver, RCD is particularly effective when the matrix is well-conditioned; however, its convergence rate deteriorates rapidly in the presence of large spectral outliers. In this paper, we introduce the subspace-constrained randomized coordinate descent (SC-RCD) method, in which the dynamics of RCD are restricted to an affine subspace corresponding to a column Nystr\"{o}m approximation, efficiently computed using the recently analyzed RPCholesky algorithm. We prove that SC-RCD converges at a rate that is unaffected by large spectral outliers, making it an effective and memory-efficient solver for large-scale, dense linear systems with rapidly decaying spectra, such as those encountered in kernel ridge regression. Experimental validation and comparisons with related solvers based on coordinate descent and the conjugate gradient method demonstrate the efficiency of SC-RCD. Our theoretical results are derived by developing a more general subspace-constrained framework for the sketch-and-project method. This framework generalizes popular algorithms such as randomized Kaczmarz and coordinate descent, and provides a flexible, implicit preconditioning strategy for a variety of iterative solvers, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09394v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jackie Lok, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>FNPF-SEM: A parallel spectral element model in Firedrake for fully nonlinear water wave simulations</title>
      <link>https://arxiv.org/abs/2506.09435</link>
      <description>arXiv:2506.09435v1 Announce Type: new 
Abstract: We present a new parallel spectral element solver, FNPF-SEM, for simulating linear and fully nonlinear potential flow-based water waves and their interaction with offshore structures. The tool is designed as a general-purpose wave model for offshore engineering applications. Built within the open-source framework Firedrake, the new FNPF-SEM model is designed as a computational tool capable of capturing both linear and nonlinear wave phenomena with high accuracy and efficiency, with support for high-order (spectral) finite elements. Additionally, Firedrake provides native support for MPI-based parallelism, allowing for efficient multi-CPU distributed computations needed for large-scale simulations. We demonstrate the capabilities of the high-order spectral element model through h- and p-convergence studies, and weak and strong scaling tests. Validation is performed against analytical solutions and experimental data for several benchmark cases, including nonlinear high-order harmonic generation and linear and nonlinear wave interactions with a cylinder and a breakwater. The new FNPF-SEM model offers a numerical framework for simulating wave propagation and wave-structure interactions, with the following key features: i) the ability to represent complex geometries through flexible, unstructured finite element meshes; ii) reduced numerical diffusion and dispersion by using high-order polynomial expansions; and iii) scalability to full- and large-scale simulations over long time periods through a parallel implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09435v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jens Visbech, Anders Melander, Allan Peter Engsig-Karup</dc:creator>
    </item>
    <item>
      <title>Segregated Runge-Kutta schemes for the time integration of the incompressible Navier-Stokes equations in presence of pressure stabilization</title>
      <link>https://arxiv.org/abs/2506.09519</link>
      <description>arXiv:2506.09519v1 Announce Type: new 
Abstract: Segregated Runge-Kutta (SRK) schemes are time integration methods for the incompressible Navier-Stokes equations. In this approach, convection and diffusion can be independently treated either explicitly or implicitly, which in particular allows to construct implicit-explicit (IMEX) methods. Original SRK schemes (Colomes, Badia, IJNME, 2015) are designed for finite-element methods that satisfy the inf-sup condition. In this paper, the idea of SRK schemes is generalized to spatial discretizations with pressure stabilization. In the numerical experiments, SRK schemes are demonstrated with both finite-difference and finite element spatial discretizations. Numerical results show that one of the SRK schemes outperforms the third-order multistep projection-based method in terms of accuracy while preserving the computational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09519v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pavel Bakhvalov</dc:creator>
    </item>
    <item>
      <title>Extensive Database of Spatial Ballistic Captures with Application to Lunar Trailblazer</title>
      <link>https://arxiv.org/abs/2506.09584</link>
      <description>arXiv:2506.09584v1 Announce Type: new 
Abstract: For low-energy missions to the Moon and beyond, Ballistic Capture has proven to be a valuable technique for enabling orbital insertion while alleviating propulsion system requirements. This approach offers two key advantages. First, it extends the insertion window, allowing multiple maneuver opportunities to mitigate potential failures at the nominal insertion point. Second, it enables the required insertion maneuver to be distributed across multiple revolutions, reducing propulsion system constraints in terms of single-burn thrust. Prior research introduced the concept of Energy Transition Domain to support the creation of a comprehensive database of Ballistic Captures in the planar Circular Restricted Three-Body Problem. However, to apply these trajectories to a real mission scenario, a three-dimensional, spatial analysis and transition to an ephemeris model are necessary. This paper first extends the Energy Transition Domain framework to the spatial case, constructing an extensive database of spatial Ballistic Captures. Then, using Lunar Trailblazer as a case study, a subset of the trajectories is filtered using a mission-specific distance metric, and transitioned into an ephemeris model. Finally, interesting features of this subset are analyzed, and sample high-fidelity trajectories are selected as potential backup options for Lunar Trailblazer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09584v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Ano\`e, Roberto Armellin, Gregory Lantoine, Claudio Bombardelli</dc:creator>
    </item>
    <item>
      <title>Geometric flow regularization in latent spaces for smooth dynamics with the efficient variations of curvature</title>
      <link>https://arxiv.org/abs/2506.09679</link>
      <description>arXiv:2506.09679v1 Announce Type: new 
Abstract: We design strategies in nonlinear geometric analysis to temper the effects of adversarial learning for sufficiently smooth data of numerical method-type dynamics in encoder-decoder methods, variational and deterministic, through the use of geometric flow regularization. We augment latent spaces with geometric flows to control structure. Our techniques rely on adaptations of curvature and Ricci flow. We invent new geometric flows or discover them neurally and non-parametrically. All of our flows are solved using physics-informed learning. Traditional geometric meaning is traded for computing ability, but we maintain key geometric invariants, the primary of which are maintained, intrinsically-low structure, canonicity or a lack of irregularity, nontriviality due to sufficient lower bounds on curvature, and distortion of volume element, that develop quality in the inference stage. Our primary contributions are fourfold. We develop a loss based on Gaussian curvature using closed path circulation integration for surfaces, bypassing automatic differentiation of the Christoffel symbols through use of Stokes' theorem. We invent a new parametric flow derived from a linear version of the Gauss equation and a Riemannian decomposition for a custom tensor defined with a normal Hessian and Weyl tensor proxies. We develop two strategies based on time differentiation of functionals, one with a special case of scalar curvature for conformally-changed metrics, and another with harmonic maps, their energy, and induced metrics. Our methods, while diminished analytically, maintain overall integral latent structure. We showcase that curvature flows and the formulation of geometric structure in intermediary encoded settings enhance learning and overall zero-shot and adversarial fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09679v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Gracyk</dc:creator>
    </item>
    <item>
      <title>Matrix best approximation in the spectral norm</title>
      <link>https://arxiv.org/abs/2506.09687</link>
      <description>arXiv:2506.09687v1 Announce Type: new 
Abstract: We derive, similar to Lau and Riha, a matrix formulation of a general best approximation theorem of Singer for the special case of spectral approximations of a given matrix from a given subspace. Using our matrix formulation we describe the relation of the spectral approximation problem to semidefinite programming, and we present a simple MATLAB code to solve the problem numerically. We then obtain geometric characterizations of spectral approximations that are based on the $k$-dimensional field of $k$ matrices, which we illustrate with several numerical examples. The general spectral approximation problem is a min-max problem, whose value is bounded from below by the corresponding max-min problem. Using our geometric characterizations of spectral approximations, we derive several necessary and sufficient as well as sufficient conditions for equality of the max-min and min-max values. Finally, we prove that the max-min and min-max values are always equal when we ``double'' the problem. Several results in this paper generalize results that have been obtained in the convergence analysis of the GMRES method for solving linear algebraic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09687v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vance Faber, J\"org Liesen, Petr Tich\'y</dc:creator>
    </item>
    <item>
      <title>Generative Models for Parameter Space Reduction applied to Reduced Order Modelling</title>
      <link>https://arxiv.org/abs/2506.09721</link>
      <description>arXiv:2506.09721v1 Announce Type: new 
Abstract: Solving and optimising Partial Differential Equations (PDEs) in geometrically parameterised domains often requires iterative methods, leading to high computational and time complexities. One potential solution is to learn a direct mapping from the parameters to the PDE solution. Two prominent methods for this are Data-driven Non-Intrusive Reduced Order Models (DROMs) and Parametrised Physics Informed Neural Networks (PPINNs). However, their accuracy tends to degrade as the number of geometric parameters increases. To address this, we propose adopting Generative Models to create new geometries, effectively reducing the number of parameters, and improving the performance of DROMs and PPINNs. The first section briefly reviews the general theory of Generative Models and provides some examples, whereas the second focusses on their application to geometries with fixed or variable points, emphasising their integration with DROMs and PPINNs. DROMs trained on geometries generated by these models demonstrate enhanced accuracy due to reduced parameter dimensionality. For PPINNs, we introduce a methodology that leverages Generative Models to reduce the parameter dimensions and improve convergence. This approach is tested on a Poisson equation defined over deformed Stanford Bunny domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09721v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guglielmo Padula, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Machine Learning-based quadratic closures for non-intrusive Reduced Order Models</title>
      <link>https://arxiv.org/abs/2506.09830</link>
      <description>arXiv:2506.09830v1 Announce Type: new 
Abstract: In the present work, we introduce a data-driven approach to enhance the accuracy of non-intrusive Reduced Order Models (ROMs). In particular, we focus on ROMs built using Proper Orthogonal Decomposition (POD) in an under-resolved and marginally-resolved regime, i.e. when the number of modes employed is not enough to capture the system dynamics. We propose a method to re-introduce the contribution of neglected modes through a quadratic correction term, given by the action of a quadratic operator on the POD coefficients. Differently from the state-of-the-art methodologies, where the operator is learned via least-squares optimisation, we propose to parametrise the operator by a Multi-Input Operators Network (MIONet). This way, we are able to build models with higher generalisation capabilities, where the operator itself is continuous in space -- thus agnostic of the domain discretisation -- and parameter-dependent. We test our model on two standard benchmarks in fluid dynamics and show that the correction term improves the accuracy of standard POD-based ROMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09830v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Codega, Anna Ivagnes, Nicola Demo, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>A Note on the Reliability of Goal-Oriented Error Estimates for Galerkin Finite Element Methods with Nonlinear Functionals</title>
      <link>https://arxiv.org/abs/2506.09913</link>
      <description>arXiv:2506.09913v1 Announce Type: new 
Abstract: We consider estimating the discretization error in a nonlinear functional $J(u)$ in the setting of an abstract variational problem: find $u \in \mathcal{V}$ such that $B(u,\varphi) = L(\varphi) \; \forall \varphi \in \mathcal{V}$, as approximated by a Galerkin finite element method. Here, $\mathcal{V}$ is a Hilbert space, $B(\cdot,\cdot)$ is a bilinear form, and $L(\cdot)$ is a linear functional. We consider well-known error estimates $\eta$ of the form $J(u) - J(u_h) \approx \eta = L(z) - B(u_h, z)$, where $u_h$ denotes a finite element approximation to $u$, and $z$ denotes the solution to an auxiliary adjoint variational problem. We show that there exist nonlinear functionals for which error estimates of this form are not reliable, even in the presence of an exact adjoint solution solution $z$. An estimate $\eta$ is said to be reliable if there exists a constant $C \in \mathbb{R}_{&gt;0}$ independent of $u_h$ such that $|J(u) - J(u_h)| \leq C|\eta|$. We present several example pairs of bilinear forms and nonlinear functionals where reliability of $\eta$ is not achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09913v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Brian N. Granzow, Stephen D. Bond, D. Thomas Seidl, Bernhard Endtmayer</dc:creator>
    </item>
    <item>
      <title>Efficient multigrid solvers for mixed-degree local discontinuous Galerkin multiphase Stokes problems</title>
      <link>https://arxiv.org/abs/2506.09933</link>
      <description>arXiv:2506.09933v1 Announce Type: new 
Abstract: We design and investigate efficient multigrid solvers for multiphase Stokes problems discretised via mixed-degree local discontinuous Galerkin methods. Using the template of a standard multigrid V-cycle, we develop a smoother analogous to element-wise block Gauss-Seidel, except the diagonal block inverses are replaced with an approximation that balances the smoothing of the velocity and pressure variables, factoring in the unequal scaling of the various Stokes system operators, and optimised via two-grid local Fourier analysis. We evaluate the performance of the multigrid solver across an extensive range of two- and three-dimensional test problems, including steady-state and unsteady, standard-form and stress-form, single-phase and high-contrast multiphase Stokes problems, with multiple kinds of boundary conditions and various choices of polynomial degree. In the lowest-degree case, i.e., that of piecewise constant pressure fields, we observe reliable multigrid convergence rates, though not especially fast. However, in every other case, we see rapid convergence rates matching those of classical Poisson-style geometric multigrid methods; e.g., 5 iterations reduce the Stokes system residual by 5 to 10 orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09933v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert I. Saye</dc:creator>
    </item>
    <item>
      <title>mLaSDI: Multi-stage latent space dynamics identification</title>
      <link>https://arxiv.org/abs/2506.09207</link>
      <description>arXiv:2506.09207v1 Announce Type: cross 
Abstract: Determining accurate numerical solutions of partial differential equations (PDEs) is an important task in many scientific disciplines. However, solvers can be computationally expensive, leading to the development of reduced-order models (ROMs). Recently, Latent Space Dynamics Identification (LaSDI) was proposed as a data-driven, non-intrusive ROM framework. LaSDI compresses the training data using an autoencoder and learns a system of user-chosen ordinary differential equations (ODEs), which govern the latent space dynamics. This allows for rapid predictions by interpolating and evolving the low-dimensional ODEs in the latent space. While LaSDI has produced effective ROMs for numerous problems, the autoencoder can have difficulty accurately reconstructing training data while also satisfying the imposed dynamics in the latent space, particularly in complex or high-frequency regimes. To address this, we propose multi-stage Latent Space Dynamics Identification (mLaSDI). With mLaSDI, several autoencoders are trained sequentially in stages, where each autoencoder learns to correct the error of the previous stages. We find that applying mLaSDI with small autoencoders results in lower prediction and reconstruction errors, while also reducing training time compared to LaSDI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09207v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Anderson, Kevin Chung, Youngsoo Choi</dc:creator>
    </item>
    <item>
      <title>TTrace: Lightweight Error Checking and Diagnosis for Distributed Training</title>
      <link>https://arxiv.org/abs/2506.09280</link>
      <description>arXiv:2506.09280v1 Announce Type: cross 
Abstract: Distributed training is essential for scaling the training of large neural network models, such as large language models (LLMs), across thousands of GPUs. However, the complexity of distributed training programs makes them particularly prone to silent bugs, which do not produce explicit error signal but lead to incorrect training outcome. Effectively detecting and localizing such silent bugs in distributed training is challenging. Common debugging practice using metrics like training loss or gradient norm curves can be inefficient and ineffective. Additionally, obtaining intermediate tensor values and determining whether they are correct during silent bug localization is difficult, particularly in the context of low-precision training.
  To address those challenges, we design and implement TTrace, the first system capable of detecting and localizing silent bugs in distributed training. TTrace collects intermediate tensors from distributing training in a fine-grained manner and compares them against those from a trusted single-device reference implementation. To properly compare the floating-point values in the tensors, we propose novel mathematical analysis that provides a guideline for setting thresholds, enabling TTrace to distinguish bug-induced errors from floating-point round-off errors. Experimental results demonstrate that TTrace effectively detects 11 existing bugs and 3 new bugs in the widely used Megatron-LM framework, while requiring fewer than 10 lines of code change. TTrace is effective in various training recipes, including low-precision recipes involving BF16 and FP8.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09280v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haitian Jiang, Shaowei Zhu, Zhen Zhang, Zhenyu Song, Xinwei Fu, Zhen Jia, Yida Wang, Jinyang Li</dc:creator>
    </item>
    <item>
      <title>A thorough study of Riemannian Newton's Method</title>
      <link>https://arxiv.org/abs/2506.09297</link>
      <description>arXiv:2506.09297v1 Announce Type: cross 
Abstract: This work presents a thorough numerical study of Riemannian Newton's Method (RNM) for optimization problems, with a focus on the Grassmannian and on the Stiefel manifold. We compare the Riemannian formulation of Newton's Method with its classical Euclidean counterpart based on Lagrange multipliers by applying both approaches to the important and challenging Hartree--Fock energy minimization problem from Quantum Chemistry. Experiments on a dataset of 125 molecules show that the Riemannian approaches achieve higher convergence rates, require fewer iterations, and exhibit greater robustness to the choice of initial guess. In this work we also analyze the numerical issues that arise from using Newton's Method on the total manifold when the cost function is defined on the quotient manifold. We investigate the performance of a modified RNM in which we ignore the small eigenvalues of the Hessian and the results indicate that this modified method is stable and performs on par with the RNM on the quotient manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09297v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Caio O. da Silva, Yuri A. Aoto, Felipe F. G. S. Costa, M\'arcio F. da Silva</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean dual gradient ascent for entropically regularized linear and semidefinite programming</title>
      <link>https://arxiv.org/abs/2506.09711</link>
      <description>arXiv:2506.09711v1 Announce Type: cross 
Abstract: We present an optimization framework that exhibits dimension-independent convergence on a broad class of semidefinite programs (SDPs). Our approach first regularizes the primal problem with the von Neumann entropy, then solve the regularized problem using dual gradient ascent with respect to a problem-adapted norm. In particular, we show that the dual gradient norm converges to zero at a rate independent of the ambient dimension and, via rounding arguments, construct primal-feasible solutions in certain special cases. We also derive explicit convergence rates for the objective. In order to achieve optimal computational scaling, we must accommodate the use of stochastic gradients constructed via randomized trace estimators. Throughout we illustrate the generality of our framework via three important special cases -- the Goemans-Williamson SDP relaxation of the Max-Cut problem, the optimal transport linear program, and several SDP relaxations of the permutation synchronization problem. Numerical experiments confirm that our methods achieve dimension-independent convergence in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09711v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Cai, Michael Lindsey</dc:creator>
    </item>
    <item>
      <title>The Intrinsic Riemannian Proximal Gradient Method for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2506.09775</link>
      <description>arXiv:2506.09775v1 Announce Type: cross 
Abstract: We consider the proximal gradient method on Riemannian manifolds for functions that are possibly not geodesically convex. Starting from the forward-backward-splitting, we define an intrinsic variant of the proximal gradient method that uses proximal maps defined on the manifold and therefore does not require or work in the embedding. We investigate its convergence properties and illustrate its numerical performance, particularly for nonconvex or nonembedded problems that are hence out of reach for other methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09775v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ronny Bergmann, Hajg Jasa, Paula John, Max Pfeffer</dc:creator>
    </item>
    <item>
      <title>Efficient implicit solvers for models of neuronal networks</title>
      <link>https://arxiv.org/abs/2210.01697</link>
      <description>arXiv:2210.01697v2 Announce Type: replace 
Abstract: We introduce economical versions of standard implicit ODE solvers that are specifically tailored for the efficient and accurate simulation of neural networks. These reformulations allow to achieve a significant increase in the efficiency of network simulations, by reducing the size of the algebraic systems effectively solved at each time step. While we focus here specifically on Explicit first step, Diagonally Implicit Runge Kutta methods (ESDIRK), similar simplifications can also be applied to any implicit ODE solver. In order to demonstrate the capabilities of the proposed methods, we consider networks based on three different single-cell models with slow-fast dynamics, including the classical FitzHugh-Nagumo model, a Intracellular Calcium Concentration model and the Hindmarsh-Rose model. Numerical experiments on the simulation of networks of increasing size based on these models demonstrate the superior efficiency of the proposed economical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.01697v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Bonaventura, Soledad Fern\'andez-Garc\'ia, Macarena G\'omez-M\'armol</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of Hermite approximations for analytic functions</title>
      <link>https://arxiv.org/abs/2312.07940</link>
      <description>arXiv:2312.07940v3 Announce Type: replace 
Abstract: In this paper, we present a rigorous analysis of root-exponential convergence of Hermite approximations, including projection and interpolation methods, for functions that are analytic in an infinite strip containing the real axis and satisfy certain restrictions on the asymptotic behavior at infinity within this strip. Asymptotically sharp error bounds in the weighted and maximum norms are derived. The key ingredients of our analysis are some remarkable contour integral representations for the Hermite coefficients and the remainder of Hermite spectral interpolations. Further extensions to Gauss--Hermite quadrature, Hermite spectral differentiations, generalized Hermite spectral approximations and the scaling factor of Hermite approximation are also discussed. Numerical experiments confirm our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07940v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyong Wang, Lun Zhang</dc:creator>
    </item>
    <item>
      <title>Pressure and convection robust Finite Elements for Magnetohydrodynamics</title>
      <link>https://arxiv.org/abs/2405.05434</link>
      <description>arXiv:2405.05434v2 Announce Type: replace 
Abstract: We propose and analyze two convection quasi-robust and pressure robust finite element methods for a fully nonlinear time-dependent magnetohydrodynamics problem. Both methods employ the $H_{\rm div}$ conforming BDM element coupled with an appropriate pressure space guaranteeing the exact diagram for the fluid part, and the $H^1$ conforming Lagrange element for the approximation of the magnetic fluxes, and make use of suitable DG upwind terms and CIP stabilizations to handle the fluid and magnetic convective terms.
  The main difference between the two approaches here proposed (labeled as three-field scheme and four field-scheme respectively) lies in the strategy adopted to enforce the divergence-free condition of the magnetic field.
  The three-filed scheme implements a grad-div stabilization, whereas the four-field scheme introduces a suitable Lagrange multiplier and additional stabilization terms in the formulation.
  The developed error estimates for the two schemes are uniform in both diffusion parameters and optimal with respect to the diffusive norm. Furthermore, in the convection dominated regime, being $k$ the degree of the method and $h$ the mesh size, we are able to prove $O(h^k)$ and $O(h^{k+1/2})$ pre-asymptotic error reduction rate for the three-field scheme and four-filed scheme respectively.
  A set of numerical tests support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05434v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. Beir\~ao da Veiga, F. Dassi, G. Vacca</dc:creator>
    </item>
    <item>
      <title>Sampling recovery in Bochner spaces and applications to parametric PDEs</title>
      <link>https://arxiv.org/abs/2409.05050</link>
      <description>arXiv:2409.05050v4 Announce Type: replace 
Abstract: We prove convergence rates of linear sampling recovery of functions in abstract Bochner spaces satisfying weighted summability of their generalized polynomial chaos expansion coefficients. The underlying algorithm is a function-valued extension of the least squares method widely used and thoroughly studied in scalar-valued function recovery. We apply our theory to collocation approximation of solutions to parametric elliptic or parabolic PDEs with log-normal random inputs and to relevant approximation of infinite dimensional holomorphic functions on $\mathbb R^\infty$. The application allows us to significantly improve known results in Computational Uncertainty Quantification for these problems. Our results are also applicable for parametric PDEs with affine inputs, where they match the known rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05050v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Bartel, Dinh D\~ung</dc:creator>
    </item>
    <item>
      <title>Mixed precision sketching for least-squares problems and its application in GMRES-based iterative refinement</title>
      <link>https://arxiv.org/abs/2410.06319</link>
      <description>arXiv:2410.06319v2 Announce Type: replace 
Abstract: Sketching-based preconditioners have been shown to accelerate the solution of dense least-squares problems with coefficient matrices having substantially more rows than columns. The cost of generating these preconditioners can be reduced by employing low precision floating-point formats for all or part of the computations. We perform finite precision analysis of a mixed precision algorithm that computes the $R$-factor of a QR factorization of the sketched coefficient matrix. Two precisions can be chosen and the analysis allows understanding how to set these precisions to exploit the potential benefits of low precision formats and still guarantee an effective preconditioner. If the nature of the least-squares problem requires a solution with a small forward error, then mixed precision iterative refinement (IR) may be needed. For ill-conditioned problems the GMRES-based IR approach can be used, but good preconditioner is crucial to ensure convergence. We theoretically show when the sketching-based preconditioner can guarantee that the GMRES-based IR reduces the relative forward error of the least-squares solution and the residual to the level of the working precision unit roundoff. Small numerical examples illustrate the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06319v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erin Carson, Ieva Dau\v{z}ickait\.e</dc:creator>
    </item>
    <item>
      <title>Unfitted finite element interpolated neural networks</title>
      <link>https://arxiv.org/abs/2501.17438</link>
      <description>arXiv:2501.17438v2 Announce Type: replace 
Abstract: We present a novel approach that integrates unfitted finite element methods and neural networks to approximate partial differential equations on complex geometries. Easy-to-generate background meshes (e.g., a simple Cartesian mesh) that cut the domain boundary (i.e., they do not conform to it) are used to build suitable trial and test finite element spaces. The method seeks a neural network that, when interpolated onto the trial space, minimises a discrete norm of the weak residual functional on the test space associated to the equation. As with unfitted finite elements, essential boundary conditions are weakly imposed by Nitsche's method. The method is robust to variations in Nitsche coefficient values, and to small cut cells. We experimentally demonstrate the method's effectiveness in solving both forward and inverse problems across various 2D and 3D complex geometries, including those defined by implicit level-set functions and explicit stereolithography meshes. For forward problems with smooth analytical solutions, the trained neural networks achieve several orders of magnitude smaller $H^1$ errors compared to their interpolation counterparts. These interpolations also maintain expected $h$- and $p$-convergence rates. Using the same amount of training points, the method is faster than standard PINNs (on both GPU and CPU architectures) while achieving similar or superior accuracy. Moreover, using a discrete dual norm of the residual (achieved by cut cell stabilisation) remarkably accelerates neural network training and further enhances robustness to the choice of Nitsche coefficient values. The experiments also show the method's high accuracy and reliability in solving inverse problems, even with incomplete observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17438v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Li, Alberto F. Mart\'in, Santiago Badia</dc:creator>
    </item>
    <item>
      <title>Dimension-independent convergence rate of propagation of chaos and numerical analysis for McKean-Vlasov stochastic differential equations with coefficients nonlinearly dependent on measure</title>
      <link>https://arxiv.org/abs/2502.20786</link>
      <description>arXiv:2502.20786v2 Announce Type: replace 
Abstract: In contrast to ordinary stochastic differential equations (SDEs), the numerical simulation of McKean-Vlasov stochastic differential equations (MV-SDEs) requires approximating the distribution law first. Based on the theory of propagation of chaos, particle approximation method is widely used. Then, a natural question is to investigate the convergence rate of the method (also referred to as the convergence rate of PoC). In fact, the PoC convergence rate is well understood for MV-SDEs with coefficients linearly dependent on the measure, but the rate deteriorates with dimension $d$ under the $L^p$-Wasserstein metric for nonlinear measure-dependent coefficients, even when Lipschitz continuity with respect to the measure is assumed. The main objective of this paper is to establish a dimension-independent convergence result of PoC for MV-SDEs whose coefficients are nonlinear with respect to the measure component but Lipschitz continuous. As a complement we further give the time discretization of the equations and thus verify the convergence rate of PoC using numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20786v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Zhang, Minghui Song</dc:creator>
    </item>
    <item>
      <title>Finite element form-valued forms: Construction</title>
      <link>https://arxiv.org/abs/2503.03243</link>
      <description>arXiv:2503.03243v2 Announce Type: replace 
Abstract: We provide a finite element discretization of $\ell$-form-valued $k$-forms on triangulation in $\mathbb{R}^{n}$ for general $k$, $\ell$ and $n$ and any polynomial degree. The construction generalizes finite element Whitney forms for the de~Rham complex and their higher-order and distributional versions, the Regge finite elements and the Christiansen--Regge elasticity complex, the TDNNS element for symmetric stress tensors, the MCS element for traceless matrix fields, the Hellan--Herrmann--Johnson (HHJ) elements for biharmonic equations, and discrete divdiv and Hessian complexes in [Hu, Lin, and Zhang, 2025]. The construction discretizes the Bernstein--Gelfand--Gelfand (BGG) diagrams. Applications of the construction include discretization of strain and stress tensors in continuum mechanics and metric and curvature tensors in differential geometry in any dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03243v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaibo Hu, Ting Lin</dc:creator>
    </item>
    <item>
      <title>Forecasting Public Sentiments via Mean Field Games</title>
      <link>https://arxiv.org/abs/2506.08465</link>
      <description>arXiv:2506.08465v2 Announce Type: replace 
Abstract: A mathematical model for forecasting of public sentiments via the Mean Field Games theory is proposed. A numerical method is developed. This is a version of the so-called convexification method. Convergence analysis demonstrates the global convergence of this method. Convergence rate is established. Numerical experiments demonstrate both an accurate performance of the convexification technique and some promising features of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08465v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael V. Klibanov, Kevin McGoff, Trung Truong</dc:creator>
    </item>
    <item>
      <title>Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension</title>
      <link>https://arxiv.org/abs/2502.05075</link>
      <description>arXiv:2502.05075v4 Announce Type: replace-cross 
Abstract: Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a strong (large) student model is trained on pseudo-labels generated by a weak teacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to understand this phenomenon through the observation that FT often occurs in intrinsically low-dimensional spaces. Leveraging the low intrinsic dimensionality of FT, we analyze W2S in the ridgeless regression setting from a variance reduction perspective. For a strong student-weak teacher pair with sufficiently expressive low-dimensional feature subspaces $\mathcal{V}_s, \mathcal{V}_w$, we provide an exact characterization of the variance that dominates the generalization error of W2S. This unveils a virtue of discrepancy between the strong and weak models in W2S: the variance of the weak teacher is inherited by the strong student in $\mathcal{V}_s \cap \mathcal{V}_w$, while reduced by a factor of $\mathrm{dim}(\mathcal{V}_s)/N$ in the subspace of discrepancy $\mathcal{V}_w \setminus \mathcal{V}_s$ with $N$ pseudo-labels for W2S. Our analysis further casts light on the sample complexities and the scaling of performance gap recovery in W2S. The analysis is supported by experiments on synthetic regression problems, as well as real vision and NLP tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05075v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijun Dong, Yicheng Li, Yunai Li, Jason D. Lee, Qi Lei</dc:creator>
    </item>
    <item>
      <title>Certified algebraic curve projections by path tracking</title>
      <link>https://arxiv.org/abs/2502.05357</link>
      <description>arXiv:2502.05357v2 Announce Type: replace-cross 
Abstract: We present a certified algorithm that takes a smooth algebraic curve in $\mathbb{R}^n$ and computes an isotopic approximation for a generic projection of the curve into $\mathbb{R}^2$. Our algorithm is designed for curves given implicitly by the zeros of $n-1$ polynomials, but it can be partially extended to parametrically defined curves. The main challenge in correctly computing the projection is to guarantee the topological correctness of crossings in the projection. Our approach combines certified path tracking and interval arithmetic in a two-step procedure: first, we construct an approximation to the curve in $\mathbb{R}^n$, and, second, we refine the approximation until the topological correctness of the projection can be guaranteed. We provide a proof-of-concept implementation illustrating the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05357v2</guid>
      <category>cs.SC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Burr, Michael Byrd, Kisun Lee</dc:creator>
    </item>
    <item>
      <title>Analytic adjoint solution for incompressible potential flows</title>
      <link>https://arxiv.org/abs/2503.15121</link>
      <description>arXiv:2503.15121v3 Announce Type: replace-cross 
Abstract: We obtain the analytic adjoint solution for two-dimensional (2D) incompressible potential flow for a cost function measuring aerodynamic force using the connection of the adjoint approach to Green's functions and also by establishing and exploiting its relation to the adjoint incompressible Euler equations. By comparison with the analytic solution, it is shown that the naive approach based on solving Laplace's equation for the adjoint variables can be ill-defined. The analysis of the boundary behavior of the analytic solution is used to discuss the proper formulation of the adjoint problem as well as the mechanism for incorporating the Kutta condition in the adjoint formulation</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15121v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0271828</arxiv:DOI>
      <arxiv:journal_reference>Physics of Fluids 37 (6), 1 June 2025 : 067127</arxiv:journal_reference>
      <dc:creator>Carlos Lozano, Jorge Ponsin</dc:creator>
    </item>
  </channel>
</rss>
