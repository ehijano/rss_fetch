<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On Reconfigurable Bisimulation, with an Application to the Distributed Synthesis Problem</title>
      <link>https://arxiv.org/abs/2505.21672</link>
      <description>arXiv:2505.21672v1 Announce Type: new 
Abstract: We consider the problem of distributing a centralised transition system to a set of asynchronous agents recognising the same language. Existing solutions are either manual or involve a huge explosion in the number of states from the centralised system. The difficulty arises from the need to keep a rigid communication scheme, specifying a fixed mapping from events to those who can participate in them. Thus, individual agents need to memorise seen events and their order to dynamically compare their knowledge with others when communicating. To bypass this, we rely on reconfigurable communication: agents decide locally ``by-need'' when to participate or discard specific events during execution while not impacting the progress of the joint computation. Our distribution relies on a novel notion of Parametric Reconfigurable Bisimulation, that identifies the only required participations. We show how to compute this bisimulation and that such minimisation produces a joint system that is bisimilar to the original centralised one. We use a case study to show its effectiveness by producing agents that are much smaller than the centralised system and jointly perform the same computations. As a notable application, we use this distribution in order to allow for distributed synthesis from global specifications. In this case, rigid communication leads to undecidability, which is bypassed by our ability to dynamically prune communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21672v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yehia Abd Alrahman, Nir Piterman</dc:creator>
    </item>
    <item>
      <title>Characterizing Equivalence of Logically Constrained Terms via Existentially Constrained Terms (Full Version)</title>
      <link>https://arxiv.org/abs/2505.21986</link>
      <description>arXiv:2505.21986v1 Announce Type: new 
Abstract: Logically constrained term rewriting is a rewriting framework that supports built-in data structures such as integers and bit vectors. Recently, constrained terms play a key role in various analyses and applications of logically constrained term rewriting. A fundamental question on constrained terms arising there is how to characterize equivalence between them. However, in the current literature only limited progress has been made on this. In this paper, we provide several sound and complete solutions to tackle this problem. Our key idea is the introduction of a novel concept, namely existentially constrained terms, into which the original form of constrained terms can be embedded. We present several syntactic characterizations of equivalence between existentially constrained terms. In particular, we provide two different kinds of complete characterizations: one is designed to facilitate equivalence checking, while the other is intended for theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21986v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanta Takahata, Jonas Sch\"opf, Naoki Nishida, Takahito Aoto</dc:creator>
    </item>
    <item>
      <title>Term Ordering Diagrams</title>
      <link>https://arxiv.org/abs/2505.22181</link>
      <description>arXiv:2505.22181v1 Announce Type: new 
Abstract: The superposition calculus for reasoning in first-order logic with equality relies on simplification orderings on terms. Modern saturation provers use the Knuth-Bendix order (KBO) and the lexicographic path order (LPO) for discovering redundant clauses and inferences. Implementing term orderings is however challenging. While KBO comparisons can be performed in linear time and LPO checks in quadratic time, using the best known algorithms for these orders is not enough. Indeed, our experiments show that for some examples term ordering checks may use about 98% of the overall proving time. The reason for this is that some equalities that cannot be ordered can become ordered after applying a substitution (post-ordered), and we have to check for post-ordering repeatedly for the same equalities. In this paper, we show how to improve post-ordering checks by introducing a new data structure called term ordering diagrams, in short TODs, which creates an index for these checks. We achieve efficiency by lazy modifications of the index and by storing and reusing information from previously performed checks to speed up subsequent checks. Our experiments demonstrate efficiency of TODs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22181v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M\'arton Hajdu, Robin Coutelier, Laura Kov\'acs, Andrei Voronkov</dc:creator>
    </item>
    <item>
      <title>Partial Redundancy in Saturation</title>
      <link>https://arxiv.org/abs/2505.22213</link>
      <description>arXiv:2505.22213v1 Announce Type: new 
Abstract: Redundancy elimination is one of the crucial ingredients of efficient saturation-based proof search. We improve redundancy elimination by introducing a new notion of redundancy, based on partial clauses and redundancy formulas, which is more powerful than the standard notion: there are both clauses and inferences that are redundant when we use our notions and not redundant when we use standard notions. In a way, our notion blurs the distinction between redundancy at the level of inferences and redundancy at the level of clauses. We present a superposition calculus PaRC on partial clauses. Our calculus is refutationally complete and is strong enough to capture some standard restrictions of the superposition calculus. We discuss the implementation of the calculus in the theorem prover Vampire. Our experiments show the power of the new approach: we were able to solve 24 TPTP problems not previously solved by any prover, including previous versions of Vampire.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22213v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M\'arton Hajdu, Laura Kov\'acs, Andrei Voronkov</dc:creator>
    </item>
    <item>
      <title>The complexity of deciding characteristic formulae modulo nested simulation</title>
      <link>https://arxiv.org/abs/2505.22277</link>
      <description>arXiv:2505.22277v1 Announce Type: new 
Abstract: This paper studies the complexity of determining whether a formula in the modal logics characterizing the nested-simulation semantics is characteristic for some process, which is equivalent to determining whether the formula is satisfiable and prime. The main results are that the problem of determining whether a formula is prime in the modal logic characterizing the 2-nested-simulation preorder is CoNP-complete and is PSPACE-complete in the case of the n-nested-simulation preorder, when n&gt;= 3. This establishes that deciding characteristic formulae for the n-nested simulation semantics, n&gt;= 3, is PSPACE-complete. In the case of the 2-nested simulation semantics, that problem lies in the complexity class DP, which consists of languages that can be expressed as the intersection of one language in NP and of one in CoNP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22277v1</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca Aceto, Antonis Achilleos, Aggeliki Chalki, Anna Ingolfsdottir</dc:creator>
    </item>
    <item>
      <title>Efficient Dynamic Shielding for Parametric Safety Specifications</title>
      <link>https://arxiv.org/abs/2505.22104</link>
      <description>arXiv:2505.22104v1 Announce Type: cross 
Abstract: Shielding has emerged as a promising approach for ensuring safety of AI-controlled autonomous systems. The algorithmic goal is to compute a shield, which is a runtime safety enforcement tool that needs to monitor and intervene the AI controller's actions if safety could be compromised otherwise. Traditional shields are designed statically for a specific safety requirement. Therefore, if the safety requirement changes at runtime due to changing operating conditions, the shield needs to be recomputed from scratch, causing delays that could be fatal. We introduce dynamic shields for parametric safety specifications, which are succinctly represented sets of all possible safety specifications that may be encountered at runtime. Our dynamic shields are statically designed for a given safety parameter set, and are able to dynamically adapt as the true safety specification (permissible by the parameters) is revealed at runtime. The main algorithmic novelty lies in the dynamic adaptation procedure, which is a simple and fast algorithm that utilizes known features of standard safety shields, like maximal permissiveness. We report experimental results for a robot navigation problem in unknown territories, where the safety specification evolves as new obstacles are discovered at runtime. In our experiments, the dynamic shields took a few minutes for their offline design, and took between a fraction of a second and a few seconds for online adaptation at each step, whereas the brute-force online recomputation approach was up to 5 times slower.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22104v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Corsi, Kaushik Mallik, Andoni Rodriguez, Cesar Sanchez</dc:creator>
    </item>
    <item>
      <title>Pareto Fronts for Compositionally Solving String Diagrams of Parity Games</title>
      <link>https://arxiv.org/abs/2406.17240</link>
      <description>arXiv:2406.17240v2 Announce Type: replace 
Abstract: Open parity games are proposed as a compositional extension of parity games with algebraic operations, forming string diagrams of parity games. A potential application of string diagrams of parity games is to describe a large parity game with a given compositional structure and solve it efficiently as a divide-and-conquer algorithm by exploiting its compositional structure. Building on our recent progress in open Markov decision processes, we introduce Pareto fronts of open parity games, offering a framework for multi-objective solutions. We establish the positional determinacy of open parity games with respect to their Pareto fronts through a novel translation method. Our translation converts an open parity game into a parity game tailored to a given single-objective. Furthermore, we present a simple algorithm for solving open parity games, derived from this translation that allows the application of existing efficient algorithms for parity games. Expanding on this foundation, we develop a compositional algorithm for string diagrams of parity games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17240v2</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kazuki Watanabe</dc:creator>
    </item>
    <item>
      <title>Non-Ground Congruence Closure</title>
      <link>https://arxiv.org/abs/2412.10066</link>
      <description>arXiv:2412.10066v2 Announce Type: replace 
Abstract: Congruence closure on ground equations is a well-established and efficient algorithm for deciding ground equalities. It constructs an explicit representation of ground equivalence classes based on a given set of input equations, allowing ground equalities to be decided by membership. In many applications, these ground equations originate from grounding non-ground equations.
  We propose an algorithm that directly computes a non-ground representation of ground congruence classes for non-ground equations. Our approach is sound and complete with respect to the corresponding ground congruence classes. Experimental results demonstrate that computing non-ground congruence classes often outperforms the classical ground congruence closure algorithm in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10066v2</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Leidinger, Christoph Weidenbach</dc:creator>
    </item>
    <item>
      <title>Interpolation for the two-way modal mu-calculus</title>
      <link>https://arxiv.org/abs/2505.12899</link>
      <description>arXiv:2505.12899v2 Announce Type: replace 
Abstract: The two-way modal mu-calculus is the extension of the (standard) one-way mu-calculus with converse (backward-looking) modalities. For this logic we introduce two new sequent-style proof calculi: a non-wellfounded system admitting infinite branches and a finitary, cyclic version of this that employs annotations. As is common in sequent systems for two-way modal logics, our calculi feature an analytic cut rule. What distinguishes our approach is the use of so-called trace atoms, which serve to apply Vardi's two-way automata in a proof-theoretic setting. We prove soundness and completeness for both systems and subsequently use the cyclic calculus to show that the two-way mu-calculus has the (local) Craig interpolation property, with respect to both propositions and modalities. Our proof uses a version of Maehara's method adapted to cyclic proof systems. As a corollary we prove that the two-way mu-calculus also enjoys Beth's definability property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12899v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Kloibhofer, Yde Venema</dc:creator>
    </item>
    <item>
      <title>Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping</title>
      <link>https://arxiv.org/abs/2505.13182</link>
      <description>arXiv:2505.13182v2 Announce Type: replace 
Abstract: [Objective] This study focuses on addressing the current lack of a unified formal theoretical framework in machine learning, as well as the deficiencies in interpretability and ethical safety assurance. [Methods] A formal information model is first constructed, utilizing sets of well-formed formulas to explicitly define the ontological states and carrier mappings of typical components in machine learning. Learnable and processable predicates, along with learning and processing functions, are introduced to analyze the logical deduction and constraint rules of the causal chains within models. [Results] A meta-framework for machine learning theory (MLT-MF) is established. Based on this framework, universal definitions for model interpretability and ethical safety are proposed. Furthermore, three key theorems are proved: the equivalence of model interpretability and information recoverability, the assurance of ethical safety, and the estimation of generalization error. [Limitations] The current framework assumes ideal conditions with noiseless information-enabling mappings and primarily targets model learning and processing logic in static scenarios. It does not yet address information fusion and conflict resolution across ontological spaces in multimodal or multi-agent systems. [Conclusions] This work overcomes the limitations of fragmented research and provides a unified theoretical foundation for systematically addressing the critical challenges currently faced in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13182v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Xu</dc:creator>
    </item>
    <item>
      <title>The Computability Path Order for Beta-Eta-Normal Higher-Order Rewriting (Full Version)</title>
      <link>https://arxiv.org/abs/2505.20121</link>
      <description>arXiv:2505.20121v2 Announce Type: replace 
Abstract: We lift the computability path order and its extensions from plain higher-order rewriting to higher-order rewriting on beta-eta-normal forms where matching modulo beta-eta is employed. The resulting order NCPO is shown to be useful on practical examples. In particular, it can handle systems where its cousin NHORPO fails even when it is used together with the powerful transformation technique of neutralization. We also argue that automating NCPO efficiently is straightforward using SAT/SMT solvers whereas this cannot be said about the transformation technique of neutralization. Our prototype implementation supports automatic termination proof search for NCPO and is also the first one to automate NHORPO with neutralization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20121v2</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Niederhauser, Aart Middeldorp</dc:creator>
    </item>
    <item>
      <title>The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games</title>
      <link>https://arxiv.org/abs/2505.07501</link>
      <description>arXiv:2505.07501v2 Announce Type: replace-cross 
Abstract: We study rational synthesis problems for concurrent games with $\omega$-regular objectives. Our model of rationality considers only pure strategy Nash equilibria that satisfy either a social welfare or Pareto optimality condition with respect to an $\omega$-regular objective for each agent. This extends earlier work on equilibria in concurrent games, without consideration about their quality. Our results show that the existence of Nash equilibria satisfying social welfare conditions can be computed as efficiently as the constrained Nash equilibrium existence problem. On the other hand, the existence of Nash equilibria satisfying the Pareto optimality condition possibly involves a higher upper bound, except in the case of B\"uchi and Muller games, for which all three problems are in the classes P and PSPACE-complete, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07501v2</guid>
      <category>cs.GT</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Purandar Bhaduri</dc:creator>
    </item>
  </channel>
</rss>
