<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Nov 2025 02:46:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Spectral LOD Method for Multiscale Problems with High Contrast</title>
      <link>https://arxiv.org/abs/2511.05776</link>
      <description>arXiv:2511.05776v1 Announce Type: new 
Abstract: We present a multiscale finite element method for a diffusion problem with rough and high contrast coefficients. The construction of the multiscale finite element space is based on the localized orthogonal decomposition methodology and it involves solutions of local finite element eigenvalue problems. We show that the performance of the multiscale finite element method is similar to the performance of standard finite element methods for the homogeneous Dirichlet boundary value problem for the Poisson equation on smooth or convex domains.} Simple explicit error estimates are established under conditions that can be verified from the outputs of the computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05776v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Susanne C. Brenner, Jos\'e C. Garay, Li-yeng Sung</dc:creator>
    </item>
    <item>
      <title>Learning solutions of parameterized stiff ODEs using Gaussian processes</title>
      <link>https://arxiv.org/abs/2511.05990</link>
      <description>arXiv:2511.05990v1 Announce Type: new 
Abstract: Stiff ordinary differential equations (ODEs) play an important role in many scientific and engineering applications. Often, the dependence of the solution of the ODE on additional parameters is of interest, e.g.\ when dealing with uncertainty quantification or design optimization. Directly studying this dependence can quickly become too computationally expensive, such that cheaper surrogate models approximating the solution are of interest. One popular class of surrogate models are Gaussian processes (GPs). They perform well when approximating stationary functions, functions which have a similar level of variation along any given parameter direction, however solutions to stiff ODEs are often characterized by a mixture of regions of rapid and slow variation along the time axis and when dealing with such nonstationary functions, GP performance frequently degrades drastically. We therefore aim to reparameterize stiff ODE solutions based on the available data, to make them appear more stationary and hence recover good GP performance. This approach comes with minimal computational overhead and requires no internal changes to the GP implementation, as it can be seen as a separate preprocessing step. We illustrate the achieved benefits using multiple examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05990v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Idoia Cortes Garcia, P. F\"orster, W. Schilders, S. Sch\"ops</dc:creator>
    </item>
    <item>
      <title>Variable-order fractional wave equation: Analysis, numerical approximation, and fast algorithm</title>
      <link>https://arxiv.org/abs/2511.06014</link>
      <description>arXiv:2511.06014v1 Announce Type: new 
Abstract: We investigate a local modification of a variable-order fractional wave equation, which describes the propagation of diffusive wave in viscoelastic media with evolving physical property. We incorporate an equivalent formulation to prove the well-posedness of the model as well as its high order regularity estimates. To accommodate the convolution term in the reformulated model, we adopt the Ritz-Volterra finite element projection and then derive the rigorous error estimate for the fully-discretized finite element scheme. To circumvent the high computational cost from the temporal integral term, we exploit the translational invariance of the discrete coefficients associated with the convolution structure and construct a fast divide-and-conquer algorithm which reduces the computational complexity from $O(MN^2)$ to $O(MN\log^2 N)$. Numerical experiments are provided to verify the theoretical results and to demonstrate the accuracy and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06014v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhong Jia, Chuanting Jiang, Yiqun Li, Mengmeng Liu, Wenlin Qiu</dc:creator>
    </item>
    <item>
      <title>Stability estimates for Interior Penalty D.G. Methods for the Nonlinear Dynamics of the complex Ginzburg Landau equation</title>
      <link>https://arxiv.org/abs/2511.06158</link>
      <description>arXiv:2511.06158v1 Announce Type: new 
Abstract: This study investigates the complex Landau equation, a reaction diffusion system with applications in nonlinear optics and fluid dynamics. The equation's nonlinear imaginary component introduces rich dynamics and significant computational challenges. We address these challenges using Discontinuous Galerkin (DG) finite element methods. A rigorous stability analysis and a comparative study are performed on three distinct DG schemes : Symmetric Interior Penalty Galerkin (SIPG), Nonsymmetric Interior Penalty Galerkin (NIPG), and Incomplete Interior Penalty Galerkin (IIPG). These methods are compared in terms of their stability and computational efficiency. Our numerical analysis and computational results demonstrate that all three discontinuous Galerkin (DG) schemes are stable. However, the Symmetric Interior Penalty Galerkin (SIPG) scheme proves to be the most robust, as its norm remains bounded even in the presence of nonlinear terms a property not shared by the others. A comparison between the Incomplete Interior Penalty Galerkin (IIPG) and Nonsymmetric Interior Penalty Galerkin (NIPG) schemes shows that IIPG has superior stability properties. For high values of the penalty parameter, all methods exhibit similar stability behavior. Our results highlight the suitability of DG methods for simulating complex nonlinear reaction-diffusion systems and provide a practical framework for selecting the most efficient scheme for a given problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06158v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dimitrios Kostas</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo time-splitting methods for Schr\"odinger equation with Gaussian random potential</title>
      <link>https://arxiv.org/abs/2511.06236</link>
      <description>arXiv:2511.06236v1 Announce Type: new 
Abstract: In this paper, we study the Schr\"odinger equation with a Gaussian random potential (SE-GP) and develop an efficient numerical method to approximate the expectation of physical observables. The unboundedness of Gaussian random variables poses significant difficulties in both sampling and error analysis. Under time-splitting discretizations of SE-GP, we establish the regularity of the semi-discrete solution in the random space. Then, we introduce a non-standard weighted Sobolev space with properly chosen weight functions, and obtain a randomly shifted lattice-based quasi-Monte Carlo (QMC) quadrature rule for efficient sampling. This approach leads to a QMC time-splitting (QMC-TS) scheme for solving the SE-GP. We prove that the proposed QMC-TS method achieves a dimension-independent convergence rate that is almost linear with respect to the number of QMC samples. Numerical experiments illustrate the sharpness of the error estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06236v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhizhang Wu, Zhiwen Zhang, Xiaofei Zhao</dc:creator>
    </item>
    <item>
      <title>GLT matrix-sequences and few emblematic applications</title>
      <link>https://arxiv.org/abs/2511.06312</link>
      <description>arXiv:2511.06312v1 Announce Type: new 
Abstract: This thesis advances the spectral theory of structured matrix-sequences within the framework of Generalized Locally Toeplitz (GLT) $*$-algebras, focusing on the geometric mean of Hermitian positive definite (HPD) GLT sequences and its applications in mathematical physics. For two HPD sequences $\{A_n\}_n \sim_{\mathrm{GLT}} \kappa$ and $\{B_n\}_n \sim_{\mathrm{GLT}} \xi$ in the same $d$-level, $r$-block GLT $*$-algebra, we prove that when $\kappa$ and $\xi$ commute, the geometric mean sequence $\{G(A_n,B_n)\}_n$ is GLT with symbol $(\kappa\xi)^{1/2}$, without requiring invertibility of either symbol, settling \cite[Conjecture 10.1]{garoni2017} for $r=1$, $d\ge1$. In degenerate cases, we identify conditions ensuring $\{G(A_n,B_n)\}_n \sim_{\mathrm{GLT}} G(\kappa,\xi)$. For $r&gt;1$ and non-commuting symbols, numerical evidence shows the sequence still admits a spectral symbol, indicating maximality of the commuting result. Numerical experiments in scalar and block settings confirm the theory and illustrate spectral behaviour. We also sketch the extension to $k\ge2$ sequences via the Karcher mean, obtaining $\{G(A_n^{(1)},\ldots,A_n^{(k)})\}_n \sim_{\mathrm{GLT}} G(\kappa_1,\ldots,\kappa_k)$. Finally, we apply the GLT framework to mean-field quantum spin systems, showing that matrices from the quantum Curie--Weiss model form GLT sequences with explicitly computable spectral distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06312v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Faisal Khan</dc:creator>
    </item>
    <item>
      <title>A framework of discontinuous Galerkin neural networks for iteratively approximating residuals</title>
      <link>https://arxiv.org/abs/2511.06349</link>
      <description>arXiv:2511.06349v1 Announce Type: new 
Abstract: We propose an abstract discontinuous Galerkin neural network (DGNN) framework for analyzing the convergence of least-squares methods based on the residual minimization when feasible solutions are neural networks. Within this framework, we define a quadratic loss functional as in the least square method with $h-$refinement and introduce new discretization sets spanned by element-wise neural network functions. The desired neural network approximate solution is recursively supplemented by solving a sequence of quasi-minimization problems associated with the underlying loss functionals and the adaptively augmented discontinuous neural network sets without the assumption on the boundedness of the neural network parameters. We further propose a discontinuous Galerkin Trefftz neural network discretization (DGTNN) only with a single hidden layer to reduce the computational costs. Moreover, we design a template based on the considered models for initializing nonlinear weights. Numerical experiments confirm that compared to existing PINN algorithms, the proposed DGNN method with one or two hidden layers is able to improve the relative $L^2$ error by at least one order of magnitude at low computational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06349v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Long Yuan, Hongxing Rui</dc:creator>
    </item>
    <item>
      <title>On a spectral solver for highly oscillatory and non-smooth solutions of a class of linear fractional differential systems</title>
      <link>https://arxiv.org/abs/2511.06410</link>
      <description>arXiv:2511.06410v1 Announce Type: new 
Abstract: This study discusses a class of linear systems of fractional differential equations with non-constant coefficients, with a particular focus on problems exhibiting highly oscillatory and non-smooth behavior. We first establish the regularity properties of the solutions under specific conditions on the input data. A spectral Galerkin method based on M\"{u}ntz-Jacobi functions is developed that efficiently handle the non-smooth and highly oscillatory solutions. A key advantage of the proposed approach is the ability to compute the approximate solution via recurrence relations, avoiding the need to solve complex algebraic systems. Moreover, the method remains stable even at higher approximation degrees, effectively capturing highly oscillatory solutions with high accuracy. The well-known exponential accuracy is established in the $L^2$-norm, and some numerical examples are provided to demonstrate both the validity of the theoretical analysis and the efficiency of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06410v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Faghih</dc:creator>
    </item>
    <item>
      <title>A generalization bound for exit wave reconstruction via deep unfolding</title>
      <link>https://arxiv.org/abs/2511.06413</link>
      <description>arXiv:2511.06413v1 Announce Type: new 
Abstract: Transmission Electron Microscopy enables high-resolution imaging of materials, but the resulting images are difficult to interpret directly. One way to address this is exit wave reconstruction, i.e., the recovery of the complex-valued electron wave at the specimen's exit plane from intensity-only measurements. This is an inverse problem with a nonlinear forward model. We consider a simplified forward model, making the problem equivalent to phase retrieval, and propose a discretized regularized variational formulation. To solve the resulting non-convex problem, we employ the proximal gradient algorithm (PGA) and unfold its iterations into a neural network, where each layer corresponds to one PGA step with learnable parameters. This unrolling approach, inspired by LISTA, enables improved reconstruction quality, interpretability, and implicit dictionary learning from data. We analyze the effect of parameter perturbations and show that they can accumulate exponentially with the number of layers $L$. Building on proof techniques of Behboodi et al., originally developed for LISTA, i.e., for a linear forward model, we extend the analysis to our nonlinear setting and establish generalization error bounds of order $\mathcal{O}(\sqrt{L})$. Numerical experiments support the exponential growth of parameter perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06413v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moussa Atwi, Benjamin Berkels</dc:creator>
    </item>
    <item>
      <title>A novel phase-field model for $N$-phase problems: modeling, asymptotic analysis and numerical simulations</title>
      <link>https://arxiv.org/abs/2511.06462</link>
      <description>arXiv:2511.06462v1 Announce Type: new 
Abstract: The classical phase-field modeling approaches for multiphase problems represent each phase using a regularized characteristic function, which necessarily introduces a simplex constraint for the phase-field variables. Additionally, the consistency requirement for phase-field modeling brings difficulties to the construction of nonlinear potentials in the energy functionals, posing significant challenges for classical phase-field modeling and its numerical methods for problems involving many phases. In this work, by adopting a dichotomic approach to represent multiphase, we propose a novel phase-field modeling framework without simplex constraint,in which the free energy is interpolated from the classical two-phase Ginzburg-Landau free energies. We systematically establish the interpolation rules and explicitly construct the interpolation functions, rendering the consistency properties of the model. The proposed model enjoys an energy dissipation property and is shown to be asymptotically consistent with its sharp interface limit, with the Neumann triangle condition recovered at the triple junction.Based on a mobility operator splitting technique, we develop a linear, decoupled, and energy stable scheme for efficiently solving the system of phase-field equations. The numerical stability and accuracy, as well as the consistency properties of the model, are validated through a large number of numerical examples. In particular, the model demonstrates its success in several benchmark simulations for multiphase problems, such as the formation of liquid lenses between two stratified fluids, the generation of double emulsions and Janus emulsions, showing good agreement with experimental observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06462v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lun Zhang, Chenxi Wang, Nan Lu, Zhen Zhang</dc:creator>
    </item>
    <item>
      <title>A B-spline-Heaviside collocation method for solving Fredholm integral equations with piecewise Holder-continuous right-hand sides</title>
      <link>https://arxiv.org/abs/2511.06590</link>
      <description>arXiv:2511.06590v1 Announce Type: new 
Abstract: This work presents a collocation method for solving linear Fredholm integral equations of the second kind defined on a closed contour in the complex plane. The right-hand side of the equation is a piecewise continuous function that may have a finite number of jump discontinuities and is known numerically at discrete points on the contour. The proposed approach employs a combination of B-spline functions and Heaviside step functions to ensure accurate approximation near discontinuity points and smooth behavior elsewhere on the contour. Convergence in the norm of piecewise Holder spaces is established, together with explicit error estimates. Numerical results illustrate the effectiveness and convergence rate of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06590v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Capcelea, Titu Capcelea</dc:creator>
    </item>
    <item>
      <title>Some p-robust a posteriori error estimates based on auxiliary spaces</title>
      <link>https://arxiv.org/abs/2511.06603</link>
      <description>arXiv:2511.06603v1 Announce Type: new 
Abstract: This work develops polynomial-degree-robust (p-robust) equilibrated a posteriori error estimates of finite element methods, based on $H^1$ auxiliary space decomposition. The proposed framework employs the fictitious space lemma for preconditioning and $H^1$ regular decomposition to decompose the finite element residual into $H^{-1}$ residuals that are further controlled by p-robust equilibrated a posteriori error analysis. As a result, we obtain novel p-robust a posteriori error estimates of conforming methods for the $H(\rm curl)$ and $H(\rm div)$ problems and the mixed method for the biharmonic equation. We also prove guaranteed a posteriori upper error bounds under convex domains or certain boundary conditions. Numerical experiments demonstrate the effectiveness and p-robustness of the proposed error estimators for the $H(\rm curl)$ conforming and the Hellan--Herrmann--Johnson methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06603v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwen Li</dc:creator>
    </item>
    <item>
      <title>A kernel method for the learning of Wasserstein geometric flows</title>
      <link>https://arxiv.org/abs/2511.06655</link>
      <description>arXiv:2511.06655v1 Announce Type: new 
Abstract: Wasserstein gradient and Hamiltonian flows have emerged as essential tools for modeling complex dynamics in the natural sciences, with applications ranging from partial differential equations (PDEs) and optimal transport to quantum mechanics and information geometry. Despite their significance, the inverse identification of potential functions and interaction kernels underlying these flows remains relatively unexplored. In this work, we tackle this challenge by addressing the inverse problem of simultaneously recovering the potential function and interaction kernel from discretized observations of the density flow. We formulate the problem as an optimization task that minimizes a loss function specifically designed to enforce the underlying variational structure of Wasserstein flows, ensuring consistency with the geometric properties of the density manifold. Our framework employs a kernel-based operator approach using the associated Reproducing Kernel Hilbert Space (RKHS), which provides a closed-form representation of the unknown components. Furthermore, a comprehensive error analysis is conducted, providing convergence rates under adaptive regularization parameters as the temporal and spatial discretization mesh sizes tend to zero. Finally, a stability analysis is presented to bridge the gap between discrete trajectory data and continuous-time flow dynamics for the Wasserstein Hamiltonian flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06655v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianyu Hu, Juan-Pablo Ortega, Daiying Yin</dc:creator>
    </item>
    <item>
      <title>An orthogonality-preserving approach for eigenvalue problems</title>
      <link>https://arxiv.org/abs/2511.06788</link>
      <description>arXiv:2511.06788v1 Announce Type: new 
Abstract: Solving large-scale eigenvalue problems poses a significant challenge due to the computational complexity and limitations on the parallel scalability of the orthogonalization operation, when many eigenpairs are required. In this paper, we propose an intrinsic orthogonality-preserving model, formulated as an evolution equation, and a corresponding numerical method for eigenvalue problems. The proposed approach automatically preserves orthogonality and exhibits energy dissipation during both time evolution and numerical iterations, provided that the initial data are orthogonal, thus offering an accurate and efficient approximation for the large-scale eigenvalue problems with orthogonality constraints. Furthermore, we rigorously prove the convergence of the scheme without the time step size restrictions imposed by the CFL conditions. Numerical experiments not only corroborate the validity of our theoretical analyses but also demonstrate the remarkably high efficiency of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06788v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyang Chu, Xiaoying Dai, Shengyue Wang, Aihui Zhou</dc:creator>
    </item>
    <item>
      <title>Pointwise A Posteriori Error Estimators for Elliptic Eigenvalue Problems</title>
      <link>https://arxiv.org/abs/2511.06815</link>
      <description>arXiv:2511.06815v1 Announce Type: new 
Abstract: In this work, we propose and analyze a pointwise a posteriori error estimator for simple eigenvalues of elliptic eigenvalue problems with adaptive finite element methods (AFEMs). We prove the reliability and efficiency of the residual-type a posteriori error estimator in the sense of $L^{\infty}$-norm, up to a logarithmic factor of the mesh size. For theoretical analysis, we also propose a theoretical and non-computable estimator, and then analyze the relationship between computable estimator and theoretical estimator. A key ingredient in the a posteriori error analysis is some new estimates for regularized derivative Green's functions. This methodology is also extended to the nonconforming finite element approximations. Some numerical experiments verify our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06815v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenglei Li, Qigang Liang, Xuejun Xu</dc:creator>
    </item>
    <item>
      <title>Multipoint stress mixed finite element methods for the linear Cosserat equations</title>
      <link>https://arxiv.org/abs/2511.06861</link>
      <description>arXiv:2511.06861v1 Announce Type: new 
Abstract: We propose mixed finite element methods for Cosserat materials that use suitable quadrature rules to eliminate the Cauchy and coupled stress variables locally. The reduced system consists of only the displacement and rotation variables. Four variants are proposed for which we show stability and convergence using a priori estimates. Numerical experiments verify the theoretical findings and higher order convergence is observed in some variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06861v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wietse M. Boon, Alessio Fumagalli, Jan M. Nordbotten, Ivan Yotov</dc:creator>
    </item>
    <item>
      <title>A Convergent Algorithm Based on Deterministic Approximation for a Large Class of Regime-Switching Generalized Stochastic Game-Theoretic Riccati Differential Equations</title>
      <link>https://arxiv.org/abs/2511.06920</link>
      <description>arXiv:2511.06920v1 Announce Type: new 
Abstract: This paper proposes a novel iterative algorithm to compute the stabilizing solution of regime-switching stochastic game-theoretic Riccati differential equations with periodic coefficients. The method decomposes the original complex stochastic problem into a sequence of deterministic subproblems. By sequentially solving for the minimal solutions of the Riccati differential equations in each subproblem, a sequence of matrix-valued functions is constructed. Leveraging the comparison theorem, the monotonicity, boundedness, and convergence of the iterative sequence are rigorously proven. Numerical experiments verifies algorithm effectiveness and stability. To the best of our knowledge, this is the first general computational approach developed for this class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06920v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyuan Wang</dc:creator>
    </item>
    <item>
      <title>A Provably-Correct and Robust Convex Model for Smooth Separable NMF</title>
      <link>https://arxiv.org/abs/2511.07109</link>
      <description>arXiv:2511.07109v1 Announce Type: new 
Abstract: Nonnegative matrix factorization (NMF) is a linear dimensionality reduction technique for nonnegative data, with applications such as hyperspectral unmixing and topic modeling. NMF is a difficult problem in general (NP-hard), and its solutions are typically not unique. To address these two issues, additional constraints or assumptions are often used. In particular, separability assumes that the basis vectors in the NMF are equal to some columns of the input matrix. In that case, the problem is referred to as separable NMF (SNMF) and can be solved in polynomial-time with robustness guarantees, while identifying a unique solution. However, in real-world scenarios, due to noise or variability, multiple data points may lie near the basis vectors, which SNMF does not leverage. In this work, we rely on the smooth separability assumption, which assumes that each basis vector is close to multiple data points. We explore the properties of the corresponding problem, referred to as smooth SNMF (SSNMF), and examine how it relates to SNMF and orthogonal NMF. We then propose a convex model for SSNMF and show that it provably recovers the sought-after factors, even in the presence of noise. We finally adapt an existing fast gradient method to solve this convex model for SSNMF, and show that it compares favorably with state-of-the-art methods on both synthetic and hyperspectral datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07109v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjun Pan, Valentin Leplat, Michael Ng, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>Towards a parallel Schwarz solver framework for virtual elements using GDSW coarse spaces</title>
      <link>https://arxiv.org/abs/2511.07144</link>
      <description>arXiv:2511.07144v1 Announce Type: new 
Abstract: The Virtual Element Method (VEM) is used to perform the discretization of the Poisson problem on polygonal and polyhedral meshes. This results in a symmetric positive definite linear system, which is solved iteratively using overlapping Schwarz domain decomposition preconditioners, where to ensure robustness and parallel scalability a second level has to be employed. The construction and numerical study of two-level overlapping Schwarz preconditioners with variants of the GDSW (Generalized Dryja-Smith-Widlund) coarse space are presented here. Our PETSc-based parallel implementation of GDSW and variants, combined with the Vem++ library, represent the first parallel application of these GDSW preconditioners to VEM. Numerical experiments in 2D and 3D demonstrate scalability of our preconditioners up to 1 000 parallel cores for VEM discretizations of degrees k=1,2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07144v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Bevilacqua, Axel Klawonn, Martin Lanser, Adam Wasiak</dc:creator>
    </item>
    <item>
      <title>Multicentric representation of piecewise constant holomorphic functions and Hermite interpolation</title>
      <link>https://arxiv.org/abs/2511.07174</link>
      <description>arXiv:2511.07174v1 Announce Type: new 
Abstract: In multicentric representation of piecewise holomorphic functions one combines Lagrange interpolation at roots of a polynomial $p$ with convergent power series of $p$ as the "coefficients" multiplying the Lagrange basis polynomials. When these power series are truncated one obtains Hermite interpolation polynomials. In this paper we first review different approaches to obtain multicentric representations with emphasis in piecewise constant holomorphic functions. When the polynomial is of degree $d$ and all power series are truncated after $n^{th}$ power, we formally arrive into a Hermite interpolation polynomial of degree $d(n+1)-1$. The natural way to represent Hermite interpolation is to have for each interpolation condition a basis polynomial which in this case leads to $d(n+1)$ basis polynomials. We then consider the numerical accumulation of errors in the different ways to represent and evaluate the Hermite interpolation. In the multicentric representation due to the convergence of the power series, numerical errors stay bounded as $n$ grows. When we assume that the piecewise constant holomorphic function takes the value $1$ in one of the components and vanishes in the other so that the Hermite interpolation agrees with just one basis polynomial, even then the truncated multicentric representation is favorable. In the general case one would take a linear combination of all $d(n+1)$ basis polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07174v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olavi Nevanlinna, Tiina Vesanen</dc:creator>
    </item>
    <item>
      <title>A General Probability Density Framework for Local Histopolation and Weighted Function Reconstruction from Mesh Line Integrals</title>
      <link>https://arxiv.org/abs/2511.07259</link>
      <description>arXiv:2511.07259v1 Announce Type: new 
Abstract: In this paper, we study the reconstruction of a bivariate function from weighted integrals along the edges of a triangular mesh, a problem of central importance in tomography, computer vision, and numerical approximation. Our approach relies on local histopolation methods defined through unisolvent triples, where the edge weights are induced by suitable probability densities. In particular, we introduce two new two-parameter families of generalized truncated normal distributions, which extend classical exponential-type laws and provide additional flexibility in capturing local features of the target function. These distributions give rise to new quadratic reconstruction operators that generalize the standard linear histopolation scheme, while retaining its simplicity and locality. We establish their theoretical foundations, proving unisolvency and deriving explicit basis functions, and we demonstrate their improved accuracy through extensive numerical tests. Moreover, we design an algorithm for the optimal selection of the distribution parameters, ensuring robustness and adaptivity of the reconstruction. Finally, we show that the proposed framework naturally extends to any bivariate function whose restriction to the edges defines a valid probability density, thus highlighting its generality and broad applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07259v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Dell'Accio, Allal Guessab, Mohammed Kbiri Alaoui, Federico Nudo</dc:creator>
    </item>
    <item>
      <title>High-dimensional Bayesian filtering through deep density approximation</title>
      <link>https://arxiv.org/abs/2511.07261</link>
      <description>arXiv:2511.07261v1 Announce Type: new 
Abstract: In this work, we benchmark two recently developed deep density methods for nonlinear filtering. Starting from the Fokker--Planck equation with Bayes updates, we model the filtering density of a discretely observed SDE. The two filters: the deep splitting filter and the deep BSDE filter, are both based on Feynman--Kac formulas, Euler--Maruyama discretizations and neural networks. The two methods are extended to logarithmic formulations providing sound and robust implementations in increasing state dimension. Comparing to the classical particle filters and ensemble Kalman filters, we benchmark the methods on numerous examples. In the low-dimensional examples the particle filters work well, but when we scale up to a partially observed 100-dimensional Lorenz-96 model the particle-based methods fail and the logarithmic deep density method prevails. In terms of computational efficiency, the deep density methods reduce inference time by roughly two to five orders of magnitude relative to the particle-based filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07261v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kasper B{\aa}gmark, Filip Rydin</dc:creator>
    </item>
    <item>
      <title>Quadratic Weighted Histopolation on Tetrahedral Meshes with Probabilistic Degrees of Freedom</title>
      <link>https://arxiv.org/abs/2511.07271</link>
      <description>arXiv:2511.07271v1 Announce Type: new 
Abstract: In this paper we introduce three complementary three-dimensional weighted quadratic enrichment strategies to improve the accuracy of local histopolation on tetrahedral meshes. The first combines face and interior weighted moments (face-volume strategy), the second uses only volumetric quadratic moments (purely volumetric strategy), and the third enriches the quadratic space through edge-supported probabilistic moments (edge-face strategy). All constructions are based on integral functionals defined by suitable probability densities and orthogonal polynomials within quadratic trial spaces. We provide a comprehensive analysis that establishes unisolvence and derives necessary and sufficient conditions on the densities to guarantee well-posedness. Representative density families, including two-parameter symmetric Dirichlet laws and convexly blended volumetric families, are examined in detail, and a general procedure for constructing the associated quadratic basis functions is outlined. For all admissible densities, an adaptive algorithm automatically selects optimal parameters. Extensive numerical experiments confirm that the proposed strategies yield substantial accuracy improvements over the classical linear histopolation scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07271v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allal Guessab, Federico Nudo</dc:creator>
    </item>
    <item>
      <title>Explainable Deep Learning-based Classification of Wolff-Parkinson-White Electrocardiographic Signals</title>
      <link>https://arxiv.org/abs/2511.05973</link>
      <description>arXiv:2511.05973v1 Announce Type: cross 
Abstract: Wolff-Parkinson-White (WPW) syndrome is a cardiac electrophysiology (EP) disorder caused by the presence of an accessory pathway (AP) that bypasses the atrioventricular node, faster ventricular activation rate, and provides a substrate for atrio-ventricular reentrant tachycardia (AVRT). Accurate localization of the AP is critical for planning and guiding catheter ablation procedures. While traditional diagnostic tree (DT) methods and more recent machine learning (ML) approaches have been proposed to predict AP location from surface electrocardiogram (ECG), they are often constrained by limited anatomical localization resolution, poor interpretability, and the use of small clinical datasets. In this study, we present a Deep Learning (DL) model for the localization of single manifest APs across 24 cardiac regions, trained on a large, physiologically realistic database of synthetic ECGs generated using a personalized virtual heart model. We also integrate eXplainable Artificial Intelligence (XAI) methods, Guided Backpropagation, Grad-CAM, and Guided Grad-CAM, into the pipeline. This enables interpretation of DL decision-making and addresses one of the main barriers to clinical adoption: lack of transparency in ML predictions. Our model achieves localization accuracy above 95%, with a sensitivity of 94.32% and specificity of 99.78%. XAI outputs are physiologically validated against known depolarization patterns, and a novel index is introduced to identify the most informative ECG leads for AP localization. Results highlight lead V2 as the most critical, followed by aVF, V1, and aVL. This work demonstrates the potential of combining cardiac digital twins with explainable DL to enable accurate, transparent, and non-invasive AP localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05973v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alice Ragonesi, Stefania Fresca, Karli Gillette, Stefan Kurath-Koller, Gernot Plank, Elena Zappon</dc:creator>
    </item>
    <item>
      <title>Simulating Clifford Circuits with Gaussian Elimination</title>
      <link>https://arxiv.org/abs/2511.06127</link>
      <description>arXiv:2511.06127v1 Announce Type: cross 
Abstract: Quantum circuits are considered more powerful than classical circuits and require exponential resources to simulate classically. Clifford circuits are a special class of quantum circuits that can be simulated in polynomial time but still show important quantum effects such as entanglement. In this work, we present an algorithm that simulates Clifford circuits by performing Gaussian elimination on a modified adjacency matrix derived from the circuit structure. Our work builds on an ZX-calculus tensor network representation of Clifford circuits that reduces to quantum graph states. We give a concise formula of amplitudes of graph states based on the LDL decomposition of matrices over GF(2), and use it to get efficient algorithms for strong and weak simulation of Clifford circuits using tree-decomposition-based fast LDL algorithm. The complexity of our algorithm matches the state of art for weak graph state simulation and improves the state of art for strong graph state simulation by taking advantage of Strassen-like fast matrix multiplication. Our algorithm is also efficient when computing many amplitudes or samples of a Clifford circuit. Further, our amplitudes formula provides a new characterization of locally Clifford equivalent graph states as well as an efficient protocol to learn graph states with low-rank adjacency matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06127v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Pang, Edgar Solomonik</dc:creator>
    </item>
    <item>
      <title>Sparsity via Hyperpriors: A Theoretical and Algorithmic Study under Empirical Bayes Framework</title>
      <link>https://arxiv.org/abs/2511.06235</link>
      <description>arXiv:2511.06235v1 Announce Type: cross 
Abstract: This paper presents a comprehensive analysis of hyperparameter estimation within the empirical Bayes framework (EBF) for sparse learning. By studying the influence of hyperpriors on the solution of EBF, we establish a theoretical connection between the choice of the hyperprior and the sparsity as well as the local optimality of the resulting solutions. We show that some strictly increasing hyperpriors, such as half-Laplace and half-generalized Gaussian with the power in $(0,1)$, effectively promote sparsity and improve solution stability with respect to measurement noise. Based on this analysis, we adopt a proximal alternating linearized minimization (PALM) algorithm with convergence guaranties for both convex and concave hyperpriors. Extensive numerical tests on two-dimensional image deblurring problems demonstrate that introducing appropriate hyperpriors significantly promotes the sparsity of the solution and enhances restoration accuracy. Furthermore, we illustrate the influence of the noise level and the ill-posedness of inverse problems to EBF solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06235v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhitao Li, Yiqiu Dong, Xueying Zeng</dc:creator>
    </item>
    <item>
      <title>DyKAF: Dynamical Kronecker Approximation of the Fisher Information Matrix for Gradient Preconditioning</title>
      <link>https://arxiv.org/abs/2511.06477</link>
      <description>arXiv:2511.06477v1 Announce Type: cross 
Abstract: Recently, optimizers that explicitly treat weights as matrices, rather than flattened vectors, have demonstrated their effectiveness. This perspective naturally leads to structured approximations of the Fisher matrix as preconditioners, where the matrix view induces a Kronecker-factorized form that enables memory-efficient representation. However, constructing such approximations both efficiently and accurately remains an open challenge, since obtaining the optimal factorization is resource-intensive and practical methods therefore rely on heuristic design choices. In this work, we introduce a novel approach that leverages projector-splitting integrators to construct effective preconditioners. Our optimizer, DyKAF (Dynamical Kronecker Approximation of the Fisher Matrix), consistently improves the Fisher matrix approximation quality. Experiments on large language model pre-training and fine-tuning demonstrate that DyKAF outperforms existing optimizers across a range of evaluation metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06477v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolay Yudin, Ekaterina Grishina, Andrey Veprikov, Alexandr Beznosikov, Maxim Rakhuba</dc:creator>
    </item>
    <item>
      <title>From LIF to QIF: Toward Differentiable Spiking Neurons for Scientific Machine Learning</title>
      <link>https://arxiv.org/abs/2511.06614</link>
      <description>arXiv:2511.06614v1 Announce Type: cross 
Abstract: Spiking neural networks (SNNs) offer biologically inspired computation but remain underexplored for continuous regression tasks in scientific machine learning. In this work, we introduce and systematically evaluate Quadratic Integrate-and-Fire (QIF) neurons as an alternative to the conventional Leaky Integrate-and-Fire (LIF) model in both directly trained SNNs and ANN-to-SNN conversion frameworks. The QIF neuron exhibits smooth and differentiable spiking dynamics, enabling gradient-based training and stable optimization within architectures such as multilayer perceptrons (MLPs), Deep Operator Networks (DeepONets), and Physics-Informed Neural Networks (PINNs). Across benchmarks on function approximation, operator learning, and partial differential equation (PDE) solving, QIF-based networks yield smoother, more accurate, and more stable predictions than their LIF counterparts, which suffer from discontinuous time-step responses and jagged activation surfaces. These results position the QIF neuron as a computational bridge between spiking and continuous-valued deep learning, advancing the integration of neuroscience-inspired dynamics into physics-informed and operator-learning frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06614v1</guid>
      <category>cs.NE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruyin Wan, George Em Karniadakis, Panos Stinis</dc:creator>
    </item>
    <item>
      <title>A Field Free Line 3D Reconstruction Model for Magnetic Particle Imaging for Improved Sensitivity, Resolution, and High Dynamic Range Imaging</title>
      <link>https://arxiv.org/abs/2511.06627</link>
      <description>arXiv:2511.06627v1 Announce Type: cross 
Abstract: Magnetic particle imaging (MPI) is a tracer-based imaging modality that detects superparamagnetic iron oxide nanoparticles in vivo, with applications in cancer cell tracking, lymph node mapping, and cell therapy monitoring. We introduce a new 3D image reconstruction framework for MPI data acquired using multi-angle field-free line (FFL) scans, demonstrating improvements in spatial resolution, quantitative accuracy, and high dynamic range performance over conventional sequential reconstruction pipelines. The framework is built by combining a physics-based FFL signal model with tomographic projection operators to form an efficient 3D forward operator, enabling the full dataset to be reconstructed jointly rather than as a series of independent 2D projections. A harmonic-domain compression step is incorporated naturally within this operator formulation, reducing memory overhead by over two orders of magnitude while preserving the structure and fidelity of the model, enabling volumetric reconstructions on standard desktop GPU hardware in only minutes. Phantom and in vivo results demonstrate substantially reduced background haze and improved visualization of low-intensity regions adjacent to bright structures, with an estimated $\sim$11$\times$ improvement in iron detection sensitivity relative to the conventional X-space CT approach. These advances enhance MPI image quality and quantitative reliability, supporting broader use of MPI in preclinical and future clinical imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06627v1</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Toby Sanders, Hayden Carlton, Preethi Korangath, Olivia C. Sehl, Robert Ivkov, Patrick W. Goodwill</dc:creator>
    </item>
    <item>
      <title>Fast Bayesian Updates via Harmonic Representations</title>
      <link>https://arxiv.org/abs/2511.06978</link>
      <description>arXiv:2511.06978v1 Announce Type: cross 
Abstract: Bayesian inference, while foundational to probabilistic reasoning, is often hampered by the computational intractability of posterior distributions, particularly through the challenging evidence integral. Conventional approaches like Markov Chain Monte Carlo (MCMC) and Variational Inference (VI) face significant scalability and efficiency limitations. This paper introduces a novel, unifying framework for fast Bayesian updates by leveraging harmonic analysis. We demonstrate that representing the prior and likelihood in a suitable orthogonal basis transforms the Bayesian update rule into a spectral convolution. Specifically, the Fourier coefficients of the posterior are shown to be the normalized convolution of the prior and likelihood coefficients. To achieve computational feasibility, we introduce a spectral truncation scheme, which, for smooth functions, yields an exceptionally accurate finite-dimensional approximation and reduces the update to a circular convolution. This formulation allows us to exploit the Fast Fourier Transform (FFT), resulting in a deterministic algorithm with O(N log N) complexity -- a substantial improvement over the O(N^2) cost of naive methods. We establish rigorous mathematical criteria for the applicability of our method, linking its efficiency to the smoothness and spectral decay of the involved distributions. The presented work offers a paradigm shift, connecting Bayesian computation to signal processing and opening avenues for real-time, sequential inference in a wide class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06978v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang</dc:creator>
    </item>
    <item>
      <title>Mathematical Modeling and Error Estimation for the Thermal Dunking Problem: A Hierarchical Approach</title>
      <link>https://arxiv.org/abs/2511.07138</link>
      <description>arXiv:2511.07138v1 Announce Type: cross 
Abstract: We consider the thermal dunking problem, in which a solid body is suddenly immersed in a fluid of different temperature, and study both the temporal evolution of the solid and the associated Biot number -- a non-dimensional heat transfer coefficient characterizing heat exchange across the solid-fluid interface. We focus on the small-Biot-number regime. The problem is accurately described by the conjugate heat transfer (CHT) formulation, which couples the Navier-Stokes and energy equations in the fluid with the heat equation in the solid through interfacial continuity conditions. Because full CHT simulations are computationally expensive, simplified models are often used in practice. Starting from the coupled equations, we systematically reduce the formulation to the lumped-capacitance model, a single ordinary differential equation with a closed-form solution, based on two assumptions: time scale separation and a spatially uniform solid temperature. The total modeling error is decomposed into time homogenization and lumping contributions. We derive an asymptotic error bound for the lumping error, valid for general heterogeneous solids and spatially varying heat transfer coefficients. Building on this theoretical result, we introduce a computable upper bound expressed in measurable quantities for practical evaluation. Time scale separation is analyzed theoretically and supported by physical arguments and simulations, showing that large separation yields small time homogenization errors. In practice, the Biot number must be estimated from so-called empirical correlations, which are typically limited to specific canonical geometries. We propose a data-driven framework that extends empirical correlations to a broader range of geometries through learned characteristic length scales. All results are validated by direct numerical simulations up to Reynolds numbers of 10,000.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07138v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Theron Guo, Kento Kaneko, Claude Le Bris, Anthony T. Patera</dc:creator>
    </item>
    <item>
      <title>Solving bilevel optimization via sequential minimax optimization</title>
      <link>https://arxiv.org/abs/2511.07398</link>
      <description>arXiv:2511.07398v1 Announce Type: cross 
Abstract: In this paper we propose a sequential minimax optimization (SMO) method for solving a class of constrained bilevel optimization problems in which the lower-level part is a possibly nonsmooth convex optimization problem, while the upper-level part is a possibly nonconvex optimization problem. Specifically, SMO applies a first-order method to solve a sequence of minimax subproblems, which are obtained by employing a hybrid of modified augmented Lagrangian and penalty schemes on the bilevel optimization problems. Under suitable assumptions, we establish an operation complexity of $O(\varepsilon^{-7}\log\varepsilon^{-1})$ and $O(\varepsilon^{-6}\log\varepsilon^{-1})$, measured in terms of fundamental operations, for SMO in finding an $\varepsilon$-KKT solution of the bilevel optimization problems with merely convex and strongly convex lower-level objective functions, respectively. The latter result improves the previous best-known operation complexity by a factor of $\varepsilon^{-1}$. Preliminary numerical results demonstrate significantly superior computational performance compared to the recently developed first-order penalty method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07398v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaosong Lu, Sanyou Mei</dc:creator>
    </item>
    <item>
      <title>The upper-crossing/solution (US) algorithm for root-finding with strongly stable convergence</title>
      <link>https://arxiv.org/abs/2212.00797</link>
      <description>arXiv:2212.00797v2 Announce Type: replace 
Abstract: In this paper, we propose a new and broadly applicable root-finding method, called as the upper-crossing/solution (US) algorithm, which belongs to the category of non-bracketing (or open domain) methods. The US algorithm is a general principle for iteratively seeking the unique root $\theta^{*}$ of a non-linear equation $g(\theta)=0$ and its each iteration consists of two steps: an upper-crossing step (U-step) and a solution step (S-step), where the U-step finds an upper-crossing function or a $U$-function $U(\theta|\theta^{(t)})$ [whose form depends on $\theta^{(t)}$ being the $t$-th iteration of $\theta^{*}$] based on a new notion of so-called changing direction inequality, and the S-step solves the simple $U$-equation $U(\theta|\theta^{(t)}) =0$ to obtain its explicit solution $\theta^{(t+1)}$. The US algorithm holds two major advantages: (i) It strongly stably converges to the root $\theta^{*}$; and (ii) it does not depend on any initial values, in contrast to Newton's method. The key step for applying the US algorithm is to construct one simple $U$-function $U(\theta|\theta^{(t)})$ such that an explicit solution to the $U$-equation $U(\theta|\theta^{(t)}) =0$ is available. Based on the first-, second- and third-derivative of $g(\theta)$, three methods are given for constructing such $U$-functions. We show various applications of the US algorithm in such as calculating quantile in continuous distributions, calculating exact $p$-values for skew null distributions, and finding maximum likelihood estimates of parameters in a class of continuous/discrete distributions. The analysis of the convergence rate of the US algorithm and some numerical experiments are also provided. Especially, because of the property of strongly stable convergence, the US algorithm could be one of the powerful tools for solving an equation with multiple roots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00797v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ME</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xun-Jian Li, Hua Zhou, Kenneth Lange, Guo-Liang Tian</dc:creator>
    </item>
    <item>
      <title>Quasi-optimal complexity $hp$-FEM for the Poisson Equation on a rectangle</title>
      <link>https://arxiv.org/abs/2402.11299</link>
      <description>arXiv:2402.11299v2 Announce Type: replace 
Abstract: We show, in one dimension, that an $hp$-Finite Element Method ($hp$-FEM) discretisation can be solved in optimal complexity because the discretisation has a special sparsity structure that ensures that the reverse Cholesky factorisation (Cholesky starting from the bottom right instead of the top left) remains sparse. Moreover, computing and inverting the factorisation may parallelise across different elements. By incorporating this approach into an Alternating Direction Implicit (ADI) method \`a la Fortunato and Townsend (2020) we can solve, within a prescribed tolerance, an $hp$-FEM discretisation of the (screened) Poisson equation on a rectangle with quasi-optimal complexity: $O(N^2 \log N)$ operations where $N$ is the maximal total degrees of freedom in each dimension. When combined with fast Legendre transforms we can also solve nonlinear time-evolution partial differential equations in a quasi-optimal complexity of $O(N^2 \log^2 N)$ operations, which we demonstrate on the (viscid) Burgers' equation. We also demonstrate how the solver can be used as an effective preconditioner for PDEs with variable coefficients, including coefficients that support a singularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11299v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kars Knook, Sheehan Olver, Ioannis P. A. Papadopoulos</dc:creator>
    </item>
    <item>
      <title>Computing large deviation rate functions of entropy production for diffusion processes by an interacting particle method</title>
      <link>https://arxiv.org/abs/2403.19223</link>
      <description>arXiv:2403.19223v5 Announce Type: replace 
Abstract: We develop an interacting particle method (IPM) for computing the large deviation rate function of entropy production for diffusion processes, with emphasis on the vanishing-noise limit and high dimensions. The crucial ingredient to obtain the rate function is the computation of the principal eigenvalue $\lambda$ of elliptic, non-self-adjoint operators. We show that this principal eigenvalue can be approximated in terms of the spectral radius of a discretized evolution operator, which is obtained from an operator splitting scheme and an Euler--Maruyama scheme with a small time step size. We also show that this spectral radius can be accessed through a large number of iterations of this discretized semigroup, which is suitable for computation using the IPM. The IPM applies naturally to problems in unbounded domains and scales easily to high dimensions. We show numerical examples of dimensions up to 16, and the results show that our numerical approximation of $\lambda$ converges to the analytical vanishing-noise limit within visual tolerance with a fixed number of particles and a fixed time step size. It is numerically shown that the IPM can adapt to singular behaviors in the vanishing-noise limit. We also apply the IPM to explore situations with no explicit formulas of the vanishing-noise limit. Our paper appears to be the first one to obtain numerical results of principal eigenvalue problems for non-self-adjoint operators in such high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19223v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1720172</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Scientific Computing, 47 (2025): pp. A3330--A3355</arxiv:journal_reference>
      <dc:creator>Zhizhang Wu, Renaud Raqu\'epas, Jack Xin, Zhiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Weighted sampling recovery of functions with mixed smoothness</title>
      <link>https://arxiv.org/abs/2405.16400</link>
      <description>arXiv:2405.16400v4 Announce Type: replace 
Abstract: We studied linear weighted sampling algorithms and their optimality for approximate recovery of functions with mixed smoothness on $\mathbb{R}^d$ from a set of $n$ their sampled values. Functions to be recovered are in weighted Sobolev spaces $W^r_{p,w}(\mathbb{R}^d)$ of mixed smoothness, and the approximation error is measured by the norm of the weighted Lebesgue space $L_{q,w}(\mathbb{R}^d)$. Here, the weight $w$ is a tensor-product Freud-type weight. The optimality of linear sampling algorithms is investigated in terms of sampling $n$-widths. We constructed linear sampling algorithms on sparse grids of sampled points which form a step hyperbolic cross in the function domain, and which give upper bounds for the corresponding sampling $n$-widths. We proved that in the one-dimensional case, these algorithms realize the exact convergence rate of the $n$-sampling widths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16400v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dinh D\~ung</dc:creator>
    </item>
    <item>
      <title>Sampling recovery in Bochner spaces and applications to parametric PDEs</title>
      <link>https://arxiv.org/abs/2409.05050</link>
      <description>arXiv:2409.05050v5 Announce Type: replace 
Abstract: We prove convergence rates of linear sampling recovery of functions in abstract Bochner spaces satisfying weighted summability of their generalized polynomial chaos expansion coefficients. The underlying algorithm is a function-valued extension of the least squares method widely used and thoroughly studied in scalar-valued function recovery. We apply our theory to two core problems in Computational Uncertainty Quantification. First, we address non-intrusive approximations of solutions to parametric elliptic or parabolic PDEs with log-normal inputs, using a finite set of particular solvers. Second, we consider approximating infinite-dimensional holomorphic functions that arise as solutions to more general parametric PDEs with Gaussian random field inputs. This approach yields substantial improvements in the state of the art for these problems. Importantly, our framework unifies log-normal and affine input models. In the affine case, we obtain convergence rates that improve known results by a logarithmic factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05050v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Bartel, Dinh D\~ung</dc:creator>
    </item>
    <item>
      <title>Dissipation-dispersion analysis of fully-discrete implicit discontinuous Galerkin methods and application to stiff hyperbolic problems</title>
      <link>https://arxiv.org/abs/2410.05901</link>
      <description>arXiv:2410.05901v3 Announce Type: replace 
Abstract: The application of discontinuous Galerkin (DG) schemes to hyperbolic systems of conservation laws requires a careful interplay between space discretization, carried out with local polynomials and numerical fluxes at inter-cells, and time-integration to yield the final update. An important concern is how the scheme modifies the solution through the notions of numerical dissipation-dispersion. As far as we know, no analysis of these artifacts has been considered for implicit integration of DG methods. The first part of this work intends to fill this gap, showing that the choice of the implicit Runge-Kutta impacts deeply on the quality of the solution. We analyze one-dimensional dissipation-dispersion to select the best combination of the space-time discretization for high Courant numbers.
  Then, we apply our findings to the integration of one-dimensional stiff hyperbolic systems. Implicit schemes leverage superior stability properties enabling the selection of time-steps based solely on accuracy requirements. High-order schemes require the introduction of local space limiters which make the whole implicit scheme highly nonlinear. To mitigate the numerical complexity, we propose to use appropriate space limiters that can be precomputed on a first-order prediction of the solution. Numerical experiments explore the performance of this technique on scalar equations and systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05901v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maya Briani, Gabriella Puppo, Giuseppe Visconti</dc:creator>
    </item>
    <item>
      <title>Helicity-preserving finite element discretization for magnetic relaxation</title>
      <link>https://arxiv.org/abs/2501.11654</link>
      <description>arXiv:2501.11654v2 Announce Type: replace 
Abstract: The Parker conjecture, which explores whether magnetic fields in perfectly conducting plasmas can develop tangential discontinuities during magnetic relaxation, remains an open question in astrophysics. Helicity conservation provides a topological barrier during relaxation, preventing topologically nontrivial initial data relaxing to trivial solutions; preserving this mechanism discretely over long time periods is therefore crucial for numerical simulation. This work presents an energy- and helicity-preserving finite element discretization for the magneto-frictional system for investigating the Parker conjecture. The algorithm preserves a discrete version of the topological barrier and a discrete Arnold inequality. We also propose extensions of the notion of helicity and the Arnold inequality to certain kinds of topologically nontrivial domains. Numerical experiments demonstrate that helicity preservation is crucial in obtaining physically meaningful simulations of magnetic relaxation, providing an example where structure-preserving schemes are necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11654v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingdong He, Patrick E. Farrell, Kaibo Hu, Boris D. Andrews</dc:creator>
    </item>
    <item>
      <title>Acoustic Propagation/Refraction Through Diffuse Interface Models</title>
      <link>https://arxiv.org/abs/2504.01727</link>
      <description>arXiv:2504.01727v2 Announce Type: replace 
Abstract: We present a novel approach for simulating acoustic (pressure) wave propagation across different media separated by a diffuse interface through the use of a weak compressibility formulation. Our method builds on our previous work on an entropy-stable discontinuous Galerkin spectral element method for the incompressible Navier-Stokes/Cahn-Hilliard system %\cite{manzanero2020entropyNSCH}% (Manzanero et al. (2020)), and incorporates a modified weak compressibility formulation that allows different sound speeds in each phase. We validate our method through numerical experiments, demonstrating spectral convergence for acoustic transmission and reflection coefficients in one dimension and for the angle defined by Snell's law in two dimensions. Special attention is given to quantifying the modeling errors introduced by the width of the diffuse interface. Our results show that the method successfully captures the behavior of acoustic waves across interfaces, allowing exponential convergence in transmitted waves. The transmitted angles in two dimensions are accurately captured for air-water conditions, up to the critical angle of $13^\circ$. In a final example, we show a three-dimensional wave transmission from air into water to demonstrate the potential of this methodology for addressing general multiphase acoustic problems. This work represents a step forward in modeling acoustic propagation in incompressible multiphase systems, with potential applications to marine aeroacoustics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01727v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2025.114478</arxiv:DOI>
      <dc:creator>Abbas Ballout, Oscar A. Marino, Gerasimos Ntoukas, Gonzalo Rubio, Esteban Ferrer</dc:creator>
    </item>
    <item>
      <title>Gautschi-type and implicit-explicit integrators for constrained wave equations</title>
      <link>https://arxiv.org/abs/2505.22532</link>
      <description>arXiv:2505.22532v2 Announce Type: replace 
Abstract: This paper deals with the construction and analysis of two integrators for (semi-linear) second-order partial differential-algebraic equations of semi-explicit type. More precisely, we consider an implicit-explicit Crank-Nicolson scheme as well as an exponential integrator of Gautschi type. For this, well-known wave integrators for unconstrained systems are combined with techniques known from the field of differential-algebraic equations. This results in efficient time stepping schemes that are provable of second order. Moreover, we discuss the practical implementation of the Gautschi-type method, which involves the solution of certain saddle point problems. The theoretical results are verified by a numerical experiment for the wave equation with kinetic boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22532v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Altmann, B. D\"orich, C. Zimmer</dc:creator>
    </item>
    <item>
      <title>DE-Sinc approximation for unilateral rapidly decreasing functions and its computational error bound</title>
      <link>https://arxiv.org/abs/2510.11411</link>
      <description>arXiv:2510.11411v4 Announce Type: replace 
Abstract: The Sinc approximation is known to be a highly efficient approximation formula for rapidly decreasing functions. For unilateral rapidly decreasing functions, which rapidly decrease as $x\to\infty$ but does not as $x\to-\infty$, an appropriate variable transformation makes the functions rapidly decreasing. As such a variable transformation, Stenger proposed $t = \sinh(\log(\operatorname{arsinh}(\exp x)))$, which enables the Sinc approximation to achieve root-exponential convergence. Recently, another variable transformation $t = 2\sinh(\log(\log(1+\exp x)))$ was proposed, which improved the convergence rate. Furthermore, its computational error bound was provided. However, this improvement was not significant because the convergence rate remained root-exponential. To improve the convergence rate significantly, this study proposes a new transformation, $t = 2\sinh(\log(\log(1+\exp(\pi\sinh x))))$, which is categorized as the double-exponential (DE) transformation. Furthermore, this study provides its computational error bound, which shows that the proposed approximation formula can achieve almost exponential convergence. Numerical experiments that confirm the theoretical result are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11411v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoaki Okayama</dc:creator>
    </item>
    <item>
      <title>A grad-curl conforming virtual element method for a grad-curl problem linking the 3D quad-curl problem and Stokes system</title>
      <link>https://arxiv.org/abs/2510.23425</link>
      <description>arXiv:2510.23425v2 Announce Type: replace 
Abstract: Based on the Stokes complex with vanishing boundary conditions and its dual complex, we reinterpret a grad-curl problem arising from the quad-curl problem as a new vector potential formulation of the three-dimensional Stokes system. By extending the analysis to the corresponding non-homogeneous problems and the accompanying trace complex, we construct a novel $\boldsymbol{H}(\operatorname{grad-curl})$-conforming virtual element space with arbitrary approximation order that satisfies the exactness of the associated discrete Stokes complex. In the lowest-order case, three degrees of freedom are assigned to each vertex and one to each edge. For the grad-curl problem, we rigorously establish the interpolation error estimates, the stability of discrete bilinear forms, and the convergence of the proposed element on polyhedral meshes. As a discrete vector potential formulation of the Stokes problem, the resulting system is pressure-decoupled and symmetric positive definite. Some numerical examples are presented to verify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23425v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojing Dong, Yibing Han, Yunqing Huang</dc:creator>
    </item>
    <item>
      <title>Read Between the Hyperplanes: On Spectral Projection and Sampling Approaches to Randomized Kaczmarz</title>
      <link>https://arxiv.org/abs/2511.03055</link>
      <description>arXiv:2511.03055v2 Announce Type: replace 
Abstract: Among recent developments centered around Randomized Kaczmarz (RK), a row-sampling iterative projection method for large-scale linear systems, several adaptions to the method have inspired faster convergence. Focusing solely on ill-conditioned and overdetermined linear systems, we highlight inter-row relationships that can be leveraged to guide directionally aware projections. In particular, we find that improved convergence rates can be made by (i) projecting onto pairwise row differences, (ii) sampling from partitioned clusters of nearly orthogonal rows, or (iii) more frequently sampling spectrally-diverse rows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03055v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>James Nguyen, Oleg Presnyakov, Adityakrishnan Radhakhrishnan</dc:creator>
    </item>
    <item>
      <title>Solving the Scattering Problem for Open Wave-Guide Networks, II Outgoing Estimates</title>
      <link>https://arxiv.org/abs/2310.05816</link>
      <description>arXiv:2310.05816v2 Announce Type: replace-cross 
Abstract: The paper continues the analysis, started in [1] (Part I,arXiv:2302.04353), of the model open wave-guide problem defined by 2 semi-infinite, rectangular wave-guides meeting along a common perpendicular line. In Part I we reduce the solution of the physical problem to a transmission problem rephrased as a system of integral equations on the common perpendicular line. In this part we show that solutions of the integral equations introduced in Part I have asymptotic expansions, if the data allows it. Using these expansions we show that the solutions to the PDE found in each half space satisfy appropriate outgoing radiation conditions. In Part III we show that these conditions imply uniqueness of the solution to the PDE as well as uniqueness for our system of integral equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05816v2</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles L. Epstein</dc:creator>
    </item>
    <item>
      <title>Solving the Scattering Problem for Open Wave-Guide Networks, III: Radiation Conditions and Uniqueness</title>
      <link>https://arxiv.org/abs/2401.04674</link>
      <description>arXiv:2401.04674v2 Announce Type: replace-cross 
Abstract: This paper continues the analysis of the scattering problem for a network of open wave-guides started in [arXiv:2302.04353, arXiv:2310.05816]. In this part we present explicit, physically motivated radiation conditions that ensure uniqueness of the solution to the scattering problem. These conditions stem from a 2000 paper of A. Vasy on 3-body Schrodinger operators; we discuss closely related conditions from a 1994 paper of H. Isozaki. Vasy's paper also proves the existence of the limiting absorption resolvents, and that the limiting solutions satisfy the radiation conditions. The statements of these results require a calculus of pseudodifferential operators, called the 3-body scattering calculus, which is briefly introduced here. We show that the solutions to the model problem obtained in arXiv:2302.04353 satisfy these radiation conditions, which makes it possible to prove uniqueness, and therefore existence, for the system of Fredholm integral equations introduced in that paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04674v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles L. Epstein, Rafe Mazzeo</dc:creator>
    </item>
    <item>
      <title>Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss</title>
      <link>https://arxiv.org/abs/2402.00152</link>
      <description>arXiv:2402.00152v3 Announce Type: replace-cross 
Abstract: Constructing the architecture of a neural network is a challenging pursuit for the machine learning community, and the dilemma of whether to go deeper or wider remains a persistent question. This paper explores a comparison between deeper neural networks (DeNNs) with a flexible number of layers and wider neural networks (WeNNs) with limited hidden layers, focusing on their optimal generalization error in Sobolev losses. Analytical investigations reveal that the architecture of a neural network can be significantly influenced by various factors, including the number of sample points, parameters within the neural networks, and the regularity of the loss function. Specifically, a higher number of parameters tends to favor WeNNs, while an increased number of sample points and greater regularity in the loss function lean towards the adoption of DeNNs. We ultimately apply this theory to address partial differential equations using deep Ritz and physics-informed neural network (PINN) methods, guiding the design of neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00152v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahong Yang, Juncai He</dc:creator>
    </item>
    <item>
      <title>Generalized local polynomial reproductions</title>
      <link>https://arxiv.org/abs/2410.12973</link>
      <description>arXiv:2410.12973v2 Announce Type: replace-cross 
Abstract: We present a general framework, treating Lipschitz domains in Riemannian manifolds, that provides conditions guaranteeing the existence of norming sets and generalized local polynomial reproduction - a powerful tool used in the analysis of various mesh-free methods and a mesh-free method in its own right. As a key application, we prove the existence of smooth local polynomial reproductions on compact subsets of algebraic manifolds in $\mathbb{R}^n$ with Lipschitz boundary. These results are then applied to derive new findings on the existence, stability, regularity, locality, and approximation properties of shape functions for a coordinate-free moving least squares approximation method on algebraic manifolds, which operates directly on point clouds without requiring tangent plane approximations.
  There are two appendices: the first derives high order Markov inequalities for polynomials on algebraic manifolds and the second gives instructions for calculating the dimension of the space of degree $m$ polynomials restricted to a real algebraic variety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12973v2</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Hangelbroek, Christian Rieger, Grady B. Wright</dc:creator>
    </item>
    <item>
      <title>A Generating Polynomial Based Two-Stage Optimization Method for Tensor Rank Decomposition</title>
      <link>https://arxiv.org/abs/2504.00313</link>
      <description>arXiv:2504.00313v3 Announce Type: replace-cross 
Abstract: The tensor rank decomposition, also known as canonical polyadic(CP) or simply tensor decomposition, has a long history in multilinear algebra. However, computing a rank decomposition becomes particularly challenging when the rank lies between its largest and second-largest dimensions. Moreover, for high-order tensor decompositions, a common approach is to first find a decomposition of its flattening order-3 tensor, where a significant gap often exists between the largest and the second-largest dimension, also making this case crucial in practice. For such a case, traditional optimization methods, such as the nonlinear least squares or alternating least squares methods, often fail to produce correct tensor decompositions. There are also direct methods that solve tensor decompositions algebraically. However, these methods usually require the tensor decomposition to be unique and can be computationally expensive, especially when the tensor rank is high. This paper introduces a new generating polynomial (GP) based two-stage algorithm for finding the order-3 nonsymmetric tensor decomposition, even when the tensor decomposition is not unique, assuming the rank does not exceed the largest dimension. The proposed method reformulates the tensor decomposition problem into two sequential optimization problems. Notably, if the first-stage optimization yields a partial solution, it will be effectively utilized in the second stage. We establish the theoretical equivalence between the CP decomposition and the global minimizers of those two-stage optimization problems. Numerical experiments demonstrate that our approach is very efficient and robust, capable of finding tensor decompositions in scenarios where the current state-of-the-art methods often fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00313v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zequn Zheng, Hongchao Zhang, Guangming Zhou</dc:creator>
    </item>
    <item>
      <title>Guided Diffusion Sampling on Function Spaces with Applications to PDEs</title>
      <link>https://arxiv.org/abs/2505.17004</link>
      <description>arXiv:2505.17004v2 Announce Type: replace-cross 
Abstract: We propose a general framework for conditional sampling in PDE-based inverse problems, targeting the recovery of whole solutions from extremely sparse or noisy measurements. This is accomplished by a function-space diffusion model and plug-and-play guidance for conditioning. Our method first trains an unconditional discretization-agnostic denoising model using neural operator architectures. At inference, we refine the samples to satisfy sparse observation data via a gradient-based guidance mechanism. Through rigorous mathematical analysis, we extend Tweedie's formula to infinite-dimensional Hilbert spaces, providing the theoretical foundation for our posterior sampling approach. Our method (FunDPS) accurately captures posterior distributions in function spaces under minimal supervision and severe data scarcity. Across five PDE tasks with only 3% observation, our method achieves an average 32% accuracy improvement over state-of-the-art fixed-resolution diffusion baselines while reducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning ensures strong cross-resolution generalizability. To the best of our knowledge, this is the first diffusion-based framework to operate independently of discretization, offering a practical and flexible solution for forward and inverse problems in the context of PDEs. Code is available at https://github.com/neuraloperator/FunDPS</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17004v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Yao, Abbas Mammadov, Julius Berner, Gavin Kerrigan, Jong Chul Ye, Kamyar Azizzadenesheli, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>Notes on Simplifying the Construction of Barabanov Norms</title>
      <link>https://arxiv.org/abs/2509.02230</link>
      <description>arXiv:2509.02230v2 Announce Type: replace-cross 
Abstract: To answer the question about the growth rate of matrix products, the concepts of joint and generalized spectral radius were introduced in the 1960s. A common tool for finding the joint/generalized spectral radius is the so-called extremal norms and, in particular, the Barabanov norm. The goal of this paper is to try to combine the advantages of different approaches based on the concept of extremality in order to obtain results that are simpler for everyday use. It is shown how the Dranishnikov-Konyagin theorem on the existence of a special invariant body for a set of matrices can be used to construct a Barabanov norm. A modified max-relaxation algorithm for constructing Barabanov norms, which follows from this theorem, is described. Additional techniques are also described that simplify the construction of Barabanov norms under the assumption that</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02230v2</guid>
      <category>math.RA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Kozyakin</dc:creator>
    </item>
    <item>
      <title>Analytic and Stochastic Approach to Quantum Advantages in Ground State and Quantum State Preparation Problems</title>
      <link>https://arxiv.org/abs/2510.01563</link>
      <description>arXiv:2510.01563v2 Announce Type: replace-cross 
Abstract: We study the problems of state preparation, ground state preparation and quantum state preparation. We propose an analytic approach to a stochastic quantum algorithm which prepares the ground state for $n$-qubit Hamiltonian that is represented by $\text{poly}(n)$ Pauli operators and has an inverse-polynomial gap, requiring only $\text{poly}(n)$ Pauli rotations, measurements, and classical time complexity when $n$ exceeds a threshold, to inverse-polynomial precision given the initial overlap being lower bounded by $\frac{1}{2^n}$. Extending this result, we prove that any $n$-qubit quantum state can be prepared in two regimes: (1) with a constant number of Pauli rotations to constant precision, or (2) with a polynomial number of rotations to inverse-polynomial precision. Our results improve over previous approaches to quantum state preparation in terms of gate complexity, thereby yielding quantum space advantage. As an application, we identify a practical condition under which quadratic unconstrained binary optimization (QUBO) problems can be solved with exponential quantum speedups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01563v2</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taehee Ko, Sungbin Lim</dc:creator>
    </item>
    <item>
      <title>Practicalities of State-Dependent and Threshold Delay Differential Equations</title>
      <link>https://arxiv.org/abs/2510.17126</link>
      <description>arXiv:2510.17126v2 Announce Type: replace-cross 
Abstract: Delays are ubiquitous in applied problems, but often do not arise as the simple constant discrete delays that analysts and numerical analysts like to treat. In this chapter we show how state-dependent delays arise naturally when modeling and the consequences that follow. We treat discrete state-dependent delays, and delays implicitly defined by threshold conditions. We will consider modeling, formulation as dynamical systems, linearization, and numerical techniques. For discrete state-dependent delays we show how breaking points can be tracked efficiently to preserve the order of numerical methods for simulating solutions. For threshold conditions we will discuss how a velocity ratio term arises in models, and present a heuristic linearization method that avoids Banach spaces and sun-star calculus, making the method accessible to a wider audience. We will also discuss numerical implementations of threshold and distributed delay problems which allows them to be treated numerically with standard software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17126v2</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. R. Humphries, A. S. Eremin, Z. Wang</dc:creator>
    </item>
    <item>
      <title>On Encoding Matrices using Quantum Circuits</title>
      <link>https://arxiv.org/abs/2510.20030</link>
      <description>arXiv:2510.20030v2 Announce Type: replace-cross 
Abstract: Over a decade ago, it was demonstrated that quantum computing has the potential to revolutionize numerical linear algebra by enabling algorithms with complexity superior to what is classically achievable, e.g., the seminal HHL algorithm for solving linear systems. Efficient execution of such algorithms critically depends on representing inputs (matrices and vectors) as quantum circuits that encode or implement these inputs. For that task, two common circuit representations emerged in the literature: block encodings and state preparation circuits. In this paper, we systematically study encodings matrices in the form of block encodings and state preparation circuits. We examine methods for constructing these representations from matrices given in classical form, as well as quantum two-way conversions between circuit representations. Two key results we establish (among others) are: (a) a general method for efficiently constructing a block encoding of an arbitrary matrix given in classical form (entries stored in classical random access memory); and (b) low-overhead, bidirectional conversion algorithms between block encodings and state preparation circuits, showing that these models are essentially equivalent. From a technical perspective, two central components of our constructions are: (i) a special constant-depth multiplexer that simultaneously multiplexes all higher-order Pauli matrices of a given size, and (ii) an algorithm for performing a quantum conversion between a matrix's expansion in the standard basis and its expansion in the basis of higher-order Pauli matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20030v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liron Mor Yosef, Haim Avron</dc:creator>
    </item>
  </channel>
</rss>
