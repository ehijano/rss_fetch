<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Apr 2025 04:00:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Modeling and solving an integrated periodic vehicle routing and capacitated facility location problem in the context of solid waste collection</title>
      <link>https://arxiv.org/abs/2504.10648</link>
      <description>arXiv:2504.10648v1 Announce Type: new 
Abstract: Few activities are as crucial in urban environments as waste management. Mismanagement of waste can cause significant economic, social, and environmental damage. However, waste management is often a complex system to manage and therefore where computational decision-support tools can play a pivotal role in assisting managers to make faster and better decisions. In this sense, this article proposes, on the one hand, a unified optimization model to address two common waste management system optimization problem: the determination of the capacity of waste bins in the collection network and the design and scheduling of collection routes. The integration of these two problems is not usual in the literature since each of them separately is already a major computational challenge. On the other hand, two improved exact formulations based on mathematical programming and a genetic algorithm (GA) are provided to solve this proposed unified optimization model. It should be noted that the GA considers a mixed chromosome representation of the solutions combining binary and integer alleles, in order to solve realistic instances of this complex problem. Also, different genetic operators have been tested to study which combination of them obtained better results in execution times on the order of that of the exact solvers. The obtained results show that the proposed GA is able to match the results of exact solvers on small instances and, in addition, can obtain feasible solutions on large instances, where exact formulations are not applicable, in reasonable computation times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10648v1</guid>
      <category>math.OC</category>
      <category>cs.NE</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bego\~na Gonz\'alez, Diego Rossit, Mariano Frutos, M\'aximo M\'endez</dc:creator>
    </item>
    <item>
      <title>A novel heuristic algorithm: adaptive and various learning-based algorithm</title>
      <link>https://arxiv.org/abs/2504.10788</link>
      <description>arXiv:2504.10788v1 Announce Type: new 
Abstract: A novel population-based heuristic algorithm called the adaptive and various learning-based algorithm (AVLA) is proposed for solving general optimization problems in this paper. The main idea of AVLA is inspired by the learning behaviors of individuals in a group, e.g. a school class. The algorithm formulates the following learning behaviors: a. Elite members will learn from each other; b. A common member will learn from some elite member and other common members; c. Members with unsatisfied performance will reflect their behavior after performance estimation; d. The whole group will reflect their behavior and try to improve if the performance of the group as a whole has not been improved for a long time. AVLA adopts the success-history based parameter adaptation to lighten the burden of parameter adjustment. To verify the efficiency of the AVLA, we apply it and its no-adaptation version with other eight well-known heuristics to 100 benchmark problems. The comparison clearly shows that AVLA performs as well as SHADE and the non-adaption version of AVLA outperforms others except AVLA and SHADE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10788v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sheng-Xue He</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Regret Optimization</title>
      <link>https://arxiv.org/abs/2504.10796</link>
      <description>arXiv:2504.10796v1 Announce Type: new 
Abstract: Distributionally Robust Optimization (DRO) is a popular framework for decision-making under uncertainty, but its adversarial nature can lead to overly conservative solutions. To address this, we study ex-ante Distributionally Robust Regret Optimization (DRRO), focusing on Wasserstein-based ambiguity sets which are popular due to their links to regularization and machine learning. We provide a systematic analysis of Wasserstein DRRO, paralleling known results for Wasserstein DRO. Under smoothness and regularity conditions, we show that Wasserstein DRRO coincides with Empirical Risk Minimization (ERM) up to first-order terms, and exactly so in convex quadratic settings. We revisit the Wasserstein DRRO newsvendor problem, where the loss is the maximum of two linear functions of demand and decision. Extending [25], we show that the regret can be computed by maximizing two one-dimensional concave functions. For more general loss functions involving the maximum of multiple linear terms in multivariate random variables and decision vectors, we prove that computing the regret and thus also the DRRO policy is NP-hard. We then propose a convex relaxation for these more general Wasserstein DRRO problems and demonstrate its strong empirical performance. Finally, we provide an upper bound on the optimality gap of our relaxation and show it improves over recent alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10796v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas-Benedikt Fiechtner, Jose Blanchet</dc:creator>
    </item>
    <item>
      <title>An Operator Splitting Method for Large-Scale CVaR-Constrained Quadratic Programs</title>
      <link>https://arxiv.org/abs/2504.10814</link>
      <description>arXiv:2504.10814v1 Announce Type: new 
Abstract: We introduce a fast and scalable method for solving quadratic programs with conditional value-at-risk (CVaR) constraints. While these problems can be formulated as standard quadratic programs, the number of variables and constraints grows linearly with the number of scenarios, making general-purpose solvers impractical for large-scale problems. Our method combines operator splitting with a specialized $O(m\log m)$ algorithm for projecting onto CVaR constraints, where $m$ is the number of scenarios. The method alternates between solving a linear system and performing parallel projections: onto CVaR constraints using our specialized algorithm and onto box constraints with a closed-form solution. Numerical examples from several application domains demonstrate that our method outperforms general-purpose solvers by several orders of magnitude on problems with up to millions of scenarios. Our method is implemented in an open-source package called CVQP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10814v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Luxenberg, David P\'erez-Pi\~neiro, Steven Diamond, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Designing optimal subsidy schemes and recycling plans for sustainable treatment of construction and demolition waste</title>
      <link>https://arxiv.org/abs/2504.10955</link>
      <description>arXiv:2504.10955v1 Announce Type: new 
Abstract: More than 10 billion tons of construction and demolition waste (CW) are generated globally each year, exerting a significant impact on the environment. In the CW recycling process, the government and the carrier are the two primary stakeholders. The carrier is responsible for transporting CW from production sites to backfill sites or processing facilities, with a primary focus on transport efficiency and revenue. Meanwhile, the government aims to minimize pollution from the recycling system, which is influenced by transport modes, shipment distances, and the processing methods used for CW. This paper develops a bi-objective, bi-level optimization model to address these challenges. The upper-level model is a linear programming model that optimizes the government's subsidy scheme, while the lower-level model is a minimum-cost flow model that optimizes the carrier's recycling plan. A hybrid heuristic solution method is proposed to tackle the problem's complexity. A case study in Chengdu, China, demonstrates the computational efficiency of the model and its small solution gap. With an optimized subsidy scheme and recycling plan, pollution can be reduced by over 29.29% through a relatively small investment in subsidies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10955v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yu, Qian Ge, Ke Han, Wen Ji, Yueqi Liu</dc:creator>
    </item>
    <item>
      <title>Splitting the Forward-Backward Algorithm: A Full Characterization</title>
      <link>https://arxiv.org/abs/2504.10999</link>
      <description>arXiv:2504.10999v1 Announce Type: new 
Abstract: We study frugal splitting algorithms with minimal lifting for solving monotone inclusion problems involving sums of maximal monotone and cocoercive operators. Building on a foundational result by Ryu, we fully characterize all methods that use only individual resolvent evaluations, direct evaluations of cocoercive operators, and minimal memory resources while ensuring convergence via averaged fixed-point iterations. We show that all such methods are captured by a unified framework, which includes known schemes and enables new ones with promising features. Systematic numerical experiments lead us to propose three design heuristics to achieve excellent performances in practice, yielding significant gains over existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10999v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton {\AA}kerman, Enis Chenchene, Pontus Giselsson, Emanuele Naldi</dc:creator>
    </item>
    <item>
      <title>An Inexact Variable Metric Proximal Gradient-subgradient Algorithm for a Class of Fractional Optimization Problems</title>
      <link>https://arxiv.org/abs/2504.11023</link>
      <description>arXiv:2504.11023v1 Announce Type: new 
Abstract: In this paper, we study a class of fractional optimization problems, in which the numerator of the objective is the sum of a convex function and a differentiable function with a Lipschitz continuous gradient, while the denominator is a nonsmooth convex function. This model has broad applicability and encompasses several important optimization problems in the literature. To address these problems, we propose an inexact variable metric proximal gradient-subgradient algorithm (iVPGSA), which, to our knowledge, is the first inexact proximal algorithm specifically designed for solving such type of fractional problems. By incorporating a variable metric proximal term and allowing for inexact solutions to the subproblem under a flexible error criterion, the proposed algorithm is highly adaptable to a broader range of problems while achieving favorable computational efficiency. Under mild assumptions, we establish that any accumulation point of the sequence generated by the iVPGSA is a critical point of the target problem. Moreover, we develop an improved Kurdyka-{\L}ojasiewicz (KL)-based analysis framework to prove the global convergence of the entire sequence and characterize its convergence rate, \textit{without} requiring a strict sufficient descent property. Our results offer detailed insights into how the KL exponent and inexactness influence the convergence rate. The proposed analysis framework also has the potential to serve as a theoretical tool for studying the convergence rates of a wide range of inexact algorithms beyond the iVPGSA. Finally, some numerical experiments on the $\ell_1/\ell_2$ Lasso problem and the constrained $\ell_1/\ell_2$ sparse optimization problem are conducted to show the superior performance of the iVPGSA in comparison to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11023v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yang, Xiangrui Kong, Min Zhang, Yaohua Hu</dc:creator>
    </item>
    <item>
      <title>Riemannian optimization for model order reduction of linear systems with quadratic outputs</title>
      <link>https://arxiv.org/abs/2504.11043</link>
      <description>arXiv:2504.11043v1 Announce Type: new 
Abstract: This paper investigates the optimal $H_2$ model order reduction for linear systems with quadratic outputs. In the framework of Galerkin projection, we first formulate the optimal $H_2$ MOR as an unconstrained Riemannian optimization problem on the Stiefel manifold. The Riemannian gradient of the specific cost function is derived with the aid of Gramians of systems, and the Dai-Yuan-type Riemannian conjugate gradient method is adopted to generate structure-preserving reduced models. We also consider the optimal $H_2$ MOR based on the product manifold, where some coefficient matrices of reduced models are determined directly via the iteration of optimization problem, instead of the Galerkin projection method. In addition, we provide a scheme to compute low-rank approximate solutions of Sylvester equations based on the truncated polynomial expansions, which fully exploits the specific structure of Sylvester equations in the optimization problems, and enables an efficient execution of our approach. Finally, two numerical examples are simulated to demonstrate the efficiency of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11043v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolong Wang, Tongtu Tian</dc:creator>
    </item>
    <item>
      <title>Uncertainty modeling method for wind and solar power output in building integrated energy systems under continuous anomalous weather</title>
      <link>https://arxiv.org/abs/2504.11100</link>
      <description>arXiv:2504.11100v1 Announce Type: new 
Abstract: The increasing occurrence of continuous anomalous weather events has intensified the uncertainty in wind and photovoltaic power generation, posing significant challenges to the operation and optimization of building integrated energy systems. Existing studies often neglect the interdependence between successive anomalous weather events and their collective impact on wind and solar power output. Additionally, conventional modeling approaches struggle to accurately capture the nonlinear fluctuations induced by these weather conditions. To address this gap, this study proposes an uncertainty modeling method based on stochastic optimization and scenario generation. The Weibull and Beta distributions characterize the probabilistic properties of wind speed and solar irradiance, respectively, while the Copula function captures the dependence between wind speed and precipitation, enabling the construction of a wind-solar power uncertainty model that incorporates the joint distribution of consecutive anomalous weather events. A Monte Carlo-based scenario generation approach is employed to construct a dataset representing anomalous weather characteristics, followed by a probabilistic distance-based scenario reduction technique to enhance modeling efficiency. Furthermore, the unscented transformation method is introduced to mitigate nonlinear propagation errors in wind and solar power state estimation. Case studies demonstrate that the proposed method effectively characterizes the fluctuation patterns of wind and solar power under continuous anomalous weather conditions while preserving the statistical properties of the original data. These findings provide a reliable basis for improving the operational resilience of building integrated energy systems under extreme weather scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11100v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deyi Shao, Hongru Li, Jingsheng Li, Xia Yu, Xiaoyu Sun, Bowen Han</dc:creator>
    </item>
    <item>
      <title>A definition of the background state of the atmosphere using optimal transport</title>
      <link>https://arxiv.org/abs/2504.11141</link>
      <description>arXiv:2504.11141v1 Announce Type: new 
Abstract: The dynamics of atmospheric disturbances are often described in terms of displacements of air parcels relative to their locations in a notional background state. Modified Lagrangian Mean (MLM) states have been proposed by M. E. McIntyre using the Lagrangian conserved variables potential vorticity and potential temperature to label air parcels, thus avoiding the need to calculate trajectories explicitly. Methven and Berrisford further defined a zonally symmetric MLM state for global atmospheric flow in terms of mass in zonal angular momentum ($z$) and potential temperature ($\theta$) coordinates. We prove that for any snapshot of an atmospheric flow in a single hemisphere, there exists a unique energy-minimising MLM state in geophysical coordinates (latitude and pressure). Since the state is an energy minimum, it is suitable for quantification of finite amplitude disturbances and examining atmospheric instability. This state is obtained by solving a free surface problem, which we frame as the minimisation of an optimal transport cost over a class of source measures. The solution consists of a source measure, encoding surface pressure, and an optimal transport map, connecting the distribution of mass in geophysical coordinates to the known distribution of mass in $(z, \theta)$. We show that this problem reduces to an optimal transport problem with a known source measure, which has a numerically feasible discretisation. Additionally, our results hold for a large class of cost functions, and generalise analogous results on free surface variants of the semi-geostrophic equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11141v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charlie Egan, John Methven, David P. Bourne, Mike J. P. Cullen</dc:creator>
    </item>
    <item>
      <title>Model Consistency of Iterative Regularization for Low-Complexity Regularization</title>
      <link>https://arxiv.org/abs/2504.11254</link>
      <description>arXiv:2504.11254v1 Announce Type: new 
Abstract: Regularization is a core component of modern inverse problems as it allows to establish well-posedness to the solution of interests. Popular regularization approaches include variational regularization and iterative regularization. The former one can be tackled by solving a variational optimization problem, which is the sum of a regularization term and a data-fidelity term balanced by a proper weight, while the latter one chooses a proper stopping time to avoid overfitting to the noise. In the study of regularization, an important topic is the relation between the solution obtained by regularization and the original ground truth. When the ground truth has low-complexity structure which is encoded as the "model", a sensitivity property shows that the solution obtained from proper regularization that promotes the same structure is robust to small perturbations, this is called "model consistency". For variational regularization, model consistency of linear inverse problem is studied in [1]. While, for iterative regularization, the existence of model consistency is an open problem. In this paper, based on a recent development of partial smoothness which is also considered in [1], we show that if the noise level is sufficiently small and a proper stopping time is chosen, the solution by iterative regularization also achieves model consistency and more exhibit local linear convergence behavior. Numerical simulations are provided to verify our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11254v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Gao, Cesare Molinari, Silvia Villa, Jingwei Liang</dc:creator>
    </item>
    <item>
      <title>A Composed Alternating Relaxed Projection Algorithm for Feasibility Problem</title>
      <link>https://arxiv.org/abs/2504.11313</link>
      <description>arXiv:2504.11313v1 Announce Type: new 
Abstract: Feasibility problem aims to find a common point of two or more closed (convex) sets whose intersection is nonempty. In the literature, projection based algorithms are widely adopted to solve the problem, such as the method of alternating projection (MAP), and Douglas--Rachford splitting method (DR). The performance of the methods are governed by the geometric properties of the underlying sets. For example, the fixed-point sequence of the Douglas--Rachford splitting method exhibits a spiraling behavior when solving the feasibility problem of two subspaces, leading to a slow convergence speed and slower than MAP. However, when the problem at hand is non-polyhedral, DR can demonstrate significant faster performance. Motivated by the behaviors of the DR method, in this paper we propose a new algorithm for solving convex feasibility problems. The method is designed based on DR method by further incorporating a composition of projection and reflection. A non-stationary version of the method is also designed, aiming to achieve faster practical performance. Theoretical guarantees of the proposed schemes are provided and supported by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11313v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuting Shen, Jingwei Liang</dc:creator>
    </item>
    <item>
      <title>The tangent cone to the real determinantal variety: various expressions and four proofs</title>
      <link>https://arxiv.org/abs/2504.11382</link>
      <description>arXiv:2504.11382v1 Announce Type: new 
Abstract: The set of real matrices of upper-bounded rank is a real algebraic variety called the real generic determinantal variety. An explicit description of the tangent cone to that variety is given in Theorem 3.2 of Schneider and Uschmajew [SIAM J. Optim., 25 (2015), pp. 622-646]. The present paper shows that the proof therein is incomplete and provides four proofs. It also reviews equivalent descriptions of the tangent cone to that variety. Moreover, it shows that the tangent cone and the algebraic tangent cone to that variety coincide, which is not true for all real algebraic varieties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11382v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, Petar Mlinari\'c, P. -A. Absil, Andr\'e Uschmajew</dc:creator>
    </item>
    <item>
      <title>GLL-type Nonmonotone Descent Methods Revisited under Kurdyka-{\L}ojasiewicz Property</title>
      <link>https://arxiv.org/abs/2504.11385</link>
      <description>arXiv:2504.11385v1 Announce Type: new 
Abstract: The purpose of this paper is to extend the full convergence results of the classic GLL-type (Grippo-Lampariello-Lucidi) nonmonotone methods to nonconvex and nonsmooth optimization. We propose a novel iterative framework for the minimization of a proper and lower semicontinuous function $\Phi$. The framework consists of the GLL-type nonmonotone decrease condition for a sequence, a relative error condition for its augmented sequence with respect to a Kurdyka-{\L}ojasiewicz (KL) function $\Theta$, and a relative gap condition for the partial maximum objective value sequence. The last condition is shown to be a product of the prox-regularity of $\Phi$ on the set of cluster points, and to hold automatically under a mild condition on the objective value sequence. We prove that for any sequence and its bounded augmented sequence together falling within the framework, the sequence itself is convergent. Furthermore, when $\Theta$ is a KL function of exponent $\theta\in(0, 1)$, the convergence admits a linear rate if $\theta\in(0, 1/2]$ and a sublinear rate if $\theta\in(1/2, 1)$. As applications, we prove, for the first time, that the two existing algorithms, namely the nonmonotone proximal gradient (NPG) method with majorization and NPG with extrapolation both enjoy the full convergence of the iterate sequences for nonconvex and nonsmooth KL composite optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11385v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yitian Qian, Ting Tao, Shaohua Pan, Houduo Qi</dc:creator>
    </item>
    <item>
      <title>Randomized block proximal method with locally Lipschitz continuous gradient</title>
      <link>https://arxiv.org/abs/2504.11410</link>
      <description>arXiv:2504.11410v1 Announce Type: new 
Abstract: Block-coordinate algorithms are recognized to furnish efficient iterative schemes for addressing large-scale problems, especially when the computation of full derivatives entails substantial memory requirements and computational efforts. In this paper, we investigate a randomized block proximal gradient algorithm for minimizing the sum of a differentiable function and a separable proper lower-semicontinuous function, both possibly nonconvex. In contrast to previous works, we only assume that the partial gradients of the differentiable function are locally Lipschitz continuous. At each iteration, the method adaptively selects a proximal stepsize to satisfy a sufficient decrease condition without prior knowledge of the local Lipschitz moduli of the partial gradients of the differentiable function. In addition, we incorporate the possibility of conducting an additional linesearch to enhance the performance of the algorithm. Our main result establishes subsequential convergence to a stationary point of the problem almost surely. Finally, we provide numerical validation of the method in an experiment in image compression using a nonnegative matrix factorization model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11410v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro P\'erez-Aros, David Torregrosa-Bel\'en</dc:creator>
    </item>
    <item>
      <title>Greedy Restart Schedules: A Baseline for Dynamic Algorithm Selection on Numerical Black-box Optimization Problems</title>
      <link>https://arxiv.org/abs/2504.11440</link>
      <description>arXiv:2504.11440v1 Announce Type: new 
Abstract: In many optimization domains, there are multiple different solvers that contribute to the overall state-of-the-art, each performing better on some, and worse on other types of problem instances. Meta-algorithmic approaches, such as instance-based algorithm selection, configuration and scheduling, aim to close this gap by extracting the most performance possible from a set of (configurable) optimizers. In this context, the best performing individual algorithms are often hand-crafted hybrid heuristics which perform many restarts of fast local optimization approaches. However, data-driven techniques to create optimized restart schedules have not yet been extensively studied.
  Here, we present a simple scheduling approach that iteratively selects the algorithm performing best on the distribution of unsolved training problems at time of selection, resulting in a problem-independent solver schedule. We demonstrate our approach using well-known optimizers from numerical black-box optimization on the BBOB testbed, bridging much of the gap between single and virtual best solver from the original portfolio across various evaluation protocols. Our greedy restart schedule presents a powerful baseline for more complex dynamic algorithm selection models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11440v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lennart Sch\"apermeier</dc:creator>
    </item>
    <item>
      <title>Beyond Coordinates: Meta-Equivariance in Statistical Inference</title>
      <link>https://arxiv.org/abs/2504.10667</link>
      <description>arXiv:2504.10667v1 Announce Type: cross 
Abstract: Optimal statistical decisions should transcend the language used to describe them. Yet, how do we guarantee that the choice of coordinates - the parameterisation of an optimisation problem - does not subtly dictate the solution? This paper reveals a fundamental geometric invariance principle. We first analyse the optimal combination of two asymptotically normal estimators under a strictly convex trace-AMSE risk. While methods for finding optimal weights are known, we prove that the resulting optimal estimator is invariant under direct affine reparameterisations of the weighting scheme. This exemplifies a broader principle we term meta-equivariance: the unique minimiser of any strictly convex, differentiable scalar objective over a matrix space transforms covariantly under any invertible affine reparameterisation of that space. Distinct from classical statistical equivariance tied to data symmetries, meta-equivariance arises from the immutable geometry of convex optimisation itself. It guarantees that optimality, in these settings, is not an artefact of representation but an intrinsic, coordinate-free truth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10667v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Cook</dc:creator>
    </item>
    <item>
      <title>Load Balancing with Network Latencies via Distributed Gradient Descent</title>
      <link>https://arxiv.org/abs/2504.10693</link>
      <description>arXiv:2504.10693v1 Announce Type: cross 
Abstract: Motivated by the growing demand for serving large language model inference requests, we study distributed load balancing for global serving systems with network latencies. We consider a fluid model in which continuous flows of requests arrive at different frontends and need to be routed to distant backends for processing whose processing rates are workload dependent. Network latencies can lead to long travel times for requests and delayed feedback from backends. The objective is to minimize the average latency of requests, composed of the network latency and the serving latency at the backends.
  We introduce Distributed Gradient Descent Load Balancing (DGD-LB), a probabilistic routing algorithm in which each frontend adjusts the routing probabilities dynamically using gradient descent. Our algorithm is distributed: there is no coordination between frontends, except by observing the delayed impact other frontends have on shared backends. The algorithm uses an approximate gradient that measures the marginal impact of an additional request evaluated at a delayed system state. Equilibrium points of our algorithm minimize the centralized optimal average latencies, and we provide a novel local stability analysis showing that our algorithm converges to an optimal solution when started sufficiently close to that point. Moreover, we present sufficient conditions on the step-size of gradient descent that guarantee convergence in the presence of network latencies. Numerical experiments show that our algorithm is globally stable and optimal, confirm our stability conditions are nearly tight, and demonstrate that DGD-LB can lead to substantial gains relative to other load balancers studied in the literature when network latencies are large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10693v1</guid>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Santiago R. Balseiro, Vahab S. Mirrokni, Bartek Wydrowski</dc:creator>
    </item>
    <item>
      <title>Robust Gittins for Stochastic Scheduling</title>
      <link>https://arxiv.org/abs/2504.10743</link>
      <description>arXiv:2504.10743v1 Announce Type: cross 
Abstract: A common theme in stochastic optimization problems is that, theoretically, stochastic algorithms need to "know" relatively rich information about the underlying distributions. This is at odds with most applications, where distributions are rough predictions based on historical data. Thus, commonly, stochastic algorithms are making decisions using imperfect predicted distributions, while trying to optimize over some unknown true distributions. We consider the fundamental problem of scheduling stochastic jobs preemptively on a single machine to minimize expected mean completion time in the setting where the scheduler is only given imperfect predicted job size distributions. If the predicted distributions are perfect, then it is known that this problem can be solved optimally by the Gittins index policy. The goal of our work is to design a scheduling policy that is robust in the sense that it produces nearly optimal schedules even if there are modest discrepancies between the predicted distributions and the underlying real distributions. Our main contributions are:
  (1) We show that the standard Gittins index policy is not robust in this sense. If the true distributions are perturbed by even an arbitrarily small amount, then running the Gittins index policy using the perturbed distributions can lead to an unbounded increase in mean completion time.
  (2) We explain how to modify the Gittins index policy to make it robust, that is, to produce nearly optimal schedules, where the approximation depends on a new measure of error between the true and predicted distributions that we define.
  Looking forward, the approach we develop here can be applied more broadly to many other stochastic optimization problems to better understand the impact of mispredictions, and lead to the development of new algorithms that are robust against such mispredictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10743v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Moseley, Heather Newman, Kirk Pruhs, Rudy Zhou</dc:creator>
    </item>
    <item>
      <title>Collaborative Bayesian Optimization via Wasserstein Barycenters</title>
      <link>https://arxiv.org/abs/2504.10770</link>
      <description>arXiv:2504.10770v1 Announce Type: cross 
Abstract: Motivated by the growing need for black-box optimization and data privacy, we introduce a collaborative Bayesian optimization (BO) framework that addresses both of these challenges. In this framework agents work collaboratively to optimize a function they only have oracle access to. In order to mitigate against communication and privacy constraints, agents are not allowed to share their data but can share their Gaussian process (GP) surrogate models. To enable collaboration under these constraints, we construct a central model to approximate the objective function by leveraging the concept of Wasserstein barycenters of GPs. This central model integrates the shared models without accessing the underlying data. A key aspect of our approach is a collaborative acquisition function that balances exploration and exploitation, allowing for the optimization of decision variables collaboratively in each iteration. We prove that our proposed algorithm is asymptotically consistent and that its implementation via Monte Carlo methods is numerically accurate. Through numerical experiments, we demonstrate that our approach outperforms other baseline collaborative frameworks and is competitive with centralized approaches that do not consider data privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10770v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donglin Zhan, Haoting Zhang, Rhonda Righter, Zeyu Zheng, James Anderson</dc:creator>
    </item>
    <item>
      <title>Virtual Contraction Approach to Decentralized Adaptive Stabilization of Nonlinear Time-Delayed Networks</title>
      <link>https://arxiv.org/abs/2504.10855</link>
      <description>arXiv:2504.10855v1 Announce Type: cross 
Abstract: In this paper, we utilize a diagonally dominant structure for the decentralized stabilization of unknown nonlinear time-delayed networks. Generalizing the idea of virtual contraction analysis to time-delayed systems, we demonstrate that nonlinear time-delayed networks can be stabilized by diagonal high-gains if the input matrices possess certain generalized (column/row) diagonally dominant properties. To achieve stabilization of unknown networks, we further propose a distributed adaptive tuning rule for each individual gain function, ensuring that all closed-loop trajectories converge to the origin. The effectiveness of the proposed decentralized adaptive control is verified in a case study on epidemic spreading control in SIS networks with transmission delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10855v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yu Kawano, Zhiyong Sun</dc:creator>
    </item>
    <item>
      <title>Offset-free Nonlinear MPC with Koopman-based Surrogate Models</title>
      <link>https://arxiv.org/abs/2504.10954</link>
      <description>arXiv:2504.10954v1 Announce Type: cross 
Abstract: In this paper, we design offset-free nonlinear Model Predictive Control (MPC) for surrogate models based on Extended Dynamic Mode Decomposition (EDMD). The model used for prediction in MPC is augmented with a disturbance term, that is estimated by an observer. If the full information about the equilibrium of the real system is not available, a reference calculator is introduced in the algorithm to compute the MPC state and input references. The control algorithm guarantees offset-free tracking of the controlled output under the assumption that the modeling errors are asymptotically constant. The effectiveness of the proposed approach is showcased with numerical simulations for two popular benchmark systems: the van-der-Pol oscillator and the four-tanks process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10954v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irene Schimperna, Lea Bold, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Mathematical Analysis of the PDE Model for the Consensus-based Optimization</title>
      <link>https://arxiv.org/abs/2504.10990</link>
      <description>arXiv:2504.10990v1 Announce Type: cross 
Abstract: In this paper, we develop an analytical framework for the partial differential equation underlying the consensus-based optimization model. The main challenge arises from the nonlinear, nonlocal nature of the consensus point, coupled with a diffusion term that is both singular and degenerate. By employing a regularization procedure in combination with a compactness argument, we establish the global existence and uniqueness of weak solutions in $L^\infty(0,T;L^1\cap L^\infty(\mathbb{R}^d))$. Furthermore, we show that the weak solutions exhibit improved $H^2$-regularity when the initial data is regular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10990v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinhuan Wang, Keyu Li, Hui Huang</dc:creator>
    </item>
    <item>
      <title>Obtuse almost-equiangular sets</title>
      <link>https://arxiv.org/abs/2504.11086</link>
      <description>arXiv:2504.11086v1 Announce Type: cross 
Abstract: For $t \in [-1, 1)$, a set of points on the $(n-1)$-dimensional unit sphere is called $t$-almost equiangular if among any three distinct points there is a pair with inner product $t$. We propose a semidefinite programming upper bound for the maximum cardinality $\alpha(n, t)$ of such a set based on an extension of the Lov\'asz theta number to hypergraphs. This bound is at least as good as previously known bounds and for many values of $n$ and $t$ it is better.
  We also refine existing spectral methods to show that $\alpha(n, t) \leq 2(n+1)$ for all $n$ and $t \leq 0$, with equality only at $t = -1/n$. This allows us to show the uniqueness of the optimal construction at $t = -1/n$ for $n \leq 5$ and to enumerate all possible constructions for $n \leq 3$ and $t \leq 0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11086v1</guid>
      <category>math.CO</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christine Bachoc, Bram Bekker, Philippe Moustrou, Fernando M\'ario de Oliveira Filho</dc:creator>
    </item>
    <item>
      <title>Improved approximation ratios for the Quantum Max-Cut problem on general, triangle-free and bipartite graphs</title>
      <link>https://arxiv.org/abs/2504.11120</link>
      <description>arXiv:2504.11120v1 Announce Type: cross 
Abstract: We study polynomial-time approximation algorithms for the Quantum Max-Cut (QMC) problem. Given an edge-weighted graph $G$ on n vertices, the QMC problem is to determine the largest eigenvalue of a particular $2^n \times 2^n$ matrix that corresponds to $G$. We provide a sharpened analysis of the currently best-known QMC approximation algorithm for general graphs. This algorithm achieves an approximation ratio of $0.599$, which our analysis improves to $0.603$. Additionally, we propose two new approximation algorithms for the QMC problem on triangle-free and bipartite graphs, that achieve approximation ratios of $0.61383$ and $0.8162$, respectively. These are the best-known approximation ratios for their respective graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11120v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sander Gribling, Lennart Sinjorgo, Renata Sotirov</dc:creator>
    </item>
    <item>
      <title>A mixed-integer framework for analyzing neural network-based controllers for piecewise affine systems with bounded disturbances</title>
      <link>https://arxiv.org/abs/2504.11125</link>
      <description>arXiv:2504.11125v1 Announce Type: cross 
Abstract: We present a method for representing the closed-loop dynamics of piecewise affine (PWA) systems with bounded additive disturbances and neural network-based controllers as mixed-integer (MI) linear constraints. We show that such representations enable the computation of robustly positively invariant (RPI) sets for the specified system class by solving MI linear programs. These RPI sets can subsequently be used to certify stability and constraint satisfaction. Furthermore, the approach allows to handle non-linear systems based on suitable PWA approximations and corresponding error bounds, which can be interpreted as the bounded disturbances from above.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11125v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dieter Teichrib, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Hessian stability and convergence rates for entropic and Sinkhorn potentials via semiconcavity</title>
      <link>https://arxiv.org/abs/2504.11133</link>
      <description>arXiv:2504.11133v1 Announce Type: cross 
Abstract: In this paper we determine quantitative stability bounds for the Hessian of entropic potentials, i.e., the dual solution to the entropic optimal transport problem. Up to authors' knowledge this is the first work addressing this second-order quantitative stability estimate in general unbounded settings. Our proof strategy relies on semiconcavity properties of entropic potentials and on the representation of entropic transport plans as laws of forward and backward diffusion processes, known as Schr\"odinger bridges. Moreover, our approach allows to deduce a stochastic proof of quantitative stability entropic estimates and integrated gradient estimates as well. Finally, as a direct consequence of these stability bounds, we deduce exponential convergence rates for gradient and Hessian of Sinkhorn iterates along Sinkhorn's algorithm, a problem that was still open in unbounded settings. Our rates have a polynomial dependence on the regularization parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11133v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Greco, Luca Tamanini</dc:creator>
    </item>
    <item>
      <title>Robust MPC for Uncertain Linear Systems -- Combining Model Adaptation and Iterative Learning</title>
      <link>https://arxiv.org/abs/2504.11261</link>
      <description>arXiv:2504.11261v1 Announce Type: cross 
Abstract: This paper presents a robust adaptive learning Model Predictive Control (MPC) framework for linear systems with parametric uncertainties and additive disturbances performing iterative tasks. The approach iteratively refines the parameter estimates using set membership estimation. Performance enhancement over iterations is achieved by learning the terminal cost from data. Safety is enforced using a terminal set, which is also learned iteratively. The proposed method guarantees recursive feasibility, constraint satisfaction, and a robust bound on the closed-loop cost. Numerical simulations on a mass-spring-damper system demonstrate improved computational efficiency and control performance compared to an existing robust adaptive MPC approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11261v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hannes Petrenz, Johannes K\"ohler, Francesco Borrelli</dc:creator>
    </item>
    <item>
      <title>Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints</title>
      <link>https://arxiv.org/abs/2504.11320</link>
      <description>arXiv:2504.11320v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are indispensable in today's applications, but their inference procedure -- generating responses by processing text in segments and using a memory-heavy Key-Value (KV) cache -- demands significant computational resources, particularly under memory constraints. This paper formulates LLM inference optimization as a multi-stage online scheduling problem where sequential prompt arrivals and KV cache growth render conventional scheduling ineffective. We develop a fluid dynamics approximation to provide a tractable benchmark that guides algorithm design. Building on this, we propose the Waiting for Accumulated Inference Threshold (WAIT) algorithm, which uses multiple thresholds to schedule incoming prompts optimally when output lengths are known, and extend it to Nested WAIT for cases with unknown output lengths. Theoretical analysis shows that both algorithms achieve near-optimal performance against the fluid benchmark in heavy traffic conditions, balancing throughput, latency, and Time to First Token (TTFT). Experiments with the Llama-7B model on an A100 GPU using both synthetic and real-world datasets demonstrate improved throughput and reduced latency relative to established baselines like vLLM and Sarathi. This work bridges operations research and machine learning, offering a rigorous framework for the efficient deployment of LLMs under memory constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11320v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruicheng Ao, Gan Luo, David Simchi-Levi, Xinshang Wang</dc:creator>
    </item>
    <item>
      <title>Inexact Bregman Proximal Gradient Method and its Inertial Variant with Absolute and Partial Relative Stopping Criteria</title>
      <link>https://arxiv.org/abs/2109.05690</link>
      <description>arXiv:2109.05690v5 Announce Type: replace 
Abstract: The Bregman proximal gradient method (BPGM), which uses the Bregman distance as a proximity measure in the iterative scheme, has recently been re-developed for minimizing convex composite problems without the global Lipschitz gradient continuity assumption. This makes the BPGM appealing for a wide range of applications, and hence it has received growing attention in recent years. However, most existing convergence results are only obtained under the assumption that the involved subproblems are solved exactly, which is unrealistic in many applications and limits the applicability of the BPGM. To make the BPGM implementable and practical, in this paper, we develop inexact versions of the BPGM (denoted by iBPGM) by employing either an absolute-type stopping criterion or a partial relative-type stopping criterion for solving the subproblems. The $\mathcal{O}(1/k)$ convergence rate and the convergence of the sequence are also established for our iBPGM under some conditions. Moreover, we develop an inertial variant of our iBPGM (denoted by v-iBPGM) and establish the $\mathcal{O}(1/k^{\gamma})$ convergence rate, where $\gamma\geq1$ is a restricted relative smoothness exponent depending on the smooth function in the objective and the kernel function. Specially, when the smooth function in the objective has a Lipschitz continuous gradient and the kernel function is strongly convex, we have $\gamma=2$ and thus the v-iBPGM improves the convergence rate of the iBPGM from $\mathcal{O}(1/k)$ to $\mathcal{O}(1/k^2)$, in accordance with the existing results on the exact accelerated BPGM. Finally, some preliminary numerical experiments for solving the discrete quadratic regularized optimal transport problem are conducted to illustrate the convergence behaviors of our iBPGM and v-iBPGM under different inexactness settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.05690v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Risk-averse decision strategies for influence diagrams using rooted junction trees</title>
      <link>https://arxiv.org/abs/2401.03734</link>
      <description>arXiv:2401.03734v3 Announce Type: replace 
Abstract: This paper presents how a mixed-integer programming (MIP) formulation for influence diagrams, based on a gradual rooted junction tree representation of the diagram, can be generalized to incorporate risk considerations such as conditional value-at-risk and chance constraints. We present two algorithms on how targeted modifications can be made to the underlying influence diagram or to the gradual rooted junction tree representation to enable our reformulations. We present computational results comparing our reformulation with another MIP formulation for influence diagrams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03734v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olli Herrala, Topias Terho, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>Source reconstruction algorithms for coupled parabolic systems from internal measurements of one scalar state</title>
      <link>https://arxiv.org/abs/2402.07593</link>
      <description>arXiv:2402.07593v2 Announce Type: replace 
Abstract: This paper is devoted to the study of source reconstruction algorithms for coupled systems of heat equations with constant or spatial-dependent coupling terms and whose internal measurements involve a reduced number of observed states. The analysis is developed for two kinds of systems: the first one consists of parabolic equations with constant zero-order coupling terms (coupling given by a matrix potential term, or, coupling through the diffusion matrix). The second type considers parabolic equations coupled by a matrix potential depending on spatial variables, which drives to analyze a non-self-adjoint operator. In all configurations, the source is decomposed into separate variables, where the temporal part is known and scalar, whereas the spatial dependence is an unknown vector field. Numerical algorithms through the finite element method in 1D and 2D are performed. Several examples show that the algorithms make it possible to recover space-dependent sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07593v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cristhian Montoya, Ignacio Brevis, David Bolivar</dc:creator>
    </item>
    <item>
      <title>A Relative Inexact Proximal Gradient Method with an Explicit Linesearch</title>
      <link>https://arxiv.org/abs/2404.10987</link>
      <description>arXiv:2404.10987v2 Announce Type: replace 
Abstract: This paper presents and investigates an inexact proximal gradient method for solving composite convex optimization problems characterized by an objective function composed of a sum of a full-domain differentiable convex function and a non-differentiable convex function. We introduce an explicit line search applied specifically to the differentiable component of the objective function, requiring only a relative inexact solution of the proximal subproblem per iteration. We prove the convergence of the sequence generated by our scheme and establish its iteration complexity, considering both the functional values and a residual associated with first-order stationary solutions. Additionally, we provide numerical experiments to illustrate the practical efficacy of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10987v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunier Bello-Cruz, Max L. N. Gon\c{c}alves, Jefferson G. Melo, Cassandra Mohr</dc:creator>
    </item>
    <item>
      <title>A Novel Privacy Enhancement Scheme with Dynamic Quantization for Federated Learning</title>
      <link>https://arxiv.org/abs/2405.16058</link>
      <description>arXiv:2405.16058v4 Announce Type: replace 
Abstract: Federated learning (FL) has been widely regarded as a promising paradigm for privacy preservation of raw data in machine learning. Although, the data privacy in FL is locally protected to some extent, it is still a desideratum to enhance privacy and alleviate communication overhead caused by repetitively transmitting model parameters. Typically, these challenges are addressed separately, or jointly via a unified scheme that consists of noise-injected privacy mechanism and communication compression, which may lead to model corruption due to the introduced composite noise. In this work, we propose a novel model-splitting privacy-preserving FL (MSP-FL) scheme to achieve private FL with precise accuracy guarantee. Based upon MSP-FL, we further propose a model-splitting privacy-preserving FL with dynamic quantization (MSPDQ-FL) to mitigate the communication overhead, which incorporates a shrinking quantization interval to reduce the quantization error. We provide privacy and convergence analysis for both MSP-FL and MSPDQ-FL under non-i.i.d. dataset, partial clients participation and finite quantization level. Numerical results are presented to validate the superiority of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16058v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wang, Xianghui Cao, Shi Jin, Mo-Yuen Chow</dc:creator>
    </item>
    <item>
      <title>Multicriteria Optimization and Decision Making: Principles, Algorithms and Case Studies</title>
      <link>https://arxiv.org/abs/2407.00359</link>
      <description>arXiv:2407.00359v5 Announce Type: replace 
Abstract: Real-world decision and optimization problems, often involve constraints and conflicting criteria. For example, choosing a travel method must balance speed, cost, environmental footprint, and convenience. Similarly, designing an industrial process must consider safety, environmental impact, and cost efficiency. Ideal solutions where all objectives are optimally met are rare; instead, we seek good compromises and aim to avoid lose-lose scenarios. Multicriteria optimization offers computational techniques to compute Pareto optimal solutions, aiding decision analysis and decision making. This reader offers an introduction to this topic and has been developed on the basis of the revised edition of the reader for the MSc computer science course "Multicriteria Optimization and Decision Analysis" at the Leiden Institute of Advanced Computer Science, Leiden University, The Netherlands. This course was taught annually by the first author from 2007 to 2023 as a single semester course with lectures and practicals. Our aim was to make the material accessible to MSc students who do not study mathematics as their core discipline by introducing basic numerical analysis concepts when necessary and providing numerical examples for interesting cases. The introduction is organized in a unique didactic manner developed by the authors, starting from more simple concepts such as linear programming and single-point methods, and advancing from these to more difficult concepts such as optimality conditions for nonlinear optimization and set-oriented solution algorithms. Besides, we focus on the mathematical modeling and foundations rather than on specific algorithms, though not excluding the discussion of some representative examples of solution algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00359v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Emmerich, Andr\'e Deutz</dc:creator>
    </item>
    <item>
      <title>Monotonicity in Quadratically Regularized Linear Programs</title>
      <link>https://arxiv.org/abs/2408.07871</link>
      <description>arXiv:2408.07871v2 Announce Type: replace 
Abstract: In optimal transport, quadratic regularization is a sparse alternative to entropic regularization: the solution measure tends to have small support. Computational experience suggests that the support decreases monotonically to the unregularized counterpart as the regularization parameter is relaxed. We find it useful to investigate this monotonicity more abstractly for linear programs over polytopes, regularized with the squared norm. Here, monotonicity can be stated as an invariance property of the curve mapping the regularization parameter to the solution: once the curve enters a face of the polytope, does it remain in that face forever? We show that this invariance is equivalent to a geometric property of the polytope, namely that each face contains the minimum norm point of its affine hull. Returning to the optimal transport problem and its associated Birkhoff polytope, we verify this property for low dimensions, but show that it fails for marginals with five or more point masses. As a consequence, the conjectured monotonicity of the support fails in general, even if experiments suggest that monotonicity holds for many cost matrices. Separately, we apply our geometric point of view to a problem of Erd\H{o}s, namely to characterize the doubly stochastic matrices whose maximal trace equals their squared norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07871v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Gonz\'alez-Sanz, Marcel Nutz, Andr\'es Riveros Valdevenito</dc:creator>
    </item>
    <item>
      <title>A Policy Iteration Method for Inverse Mean Field Games</title>
      <link>https://arxiv.org/abs/2409.06184</link>
      <description>arXiv:2409.06184v3 Announce Type: replace 
Abstract: We propose a policy iteration method to solve an inverse problem for a mean-field game (MFG) model, specifically to reconstruct the obstacle function in the game from the partial observation data of value functions, which represent the optimal costs for agents. The proposed approach decouples this complex inverse problem, which is an optimization problem constrained by a coupled nonlinear forward and backward PDE system in the MFG, into several iterations of solving linear PDEs and linear inverse problems. This method can also be viewed as a fixed-point iteration that simultaneously solves the MFG system and inversion. We prove its linear rate of convergence. In addition, numerical examples in 1D and 2D, along with performance comparisons to a direct least-squares method, demonstrate the superior efficiency and accuracy of the proposed method for solving inverse MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06184v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Ren, Nathan Soedjak, Shanyin Tong</dc:creator>
    </item>
    <item>
      <title>Second-Order Min-Max Optimization with Lazy Hessians</title>
      <link>https://arxiv.org/abs/2410.09568</link>
      <description>arXiv:2410.09568v2 Announce Type: replace 
Abstract: This paper studies second-order methods for convex-concave minimax optimization. Monteiro and Svaiter (2012) proposed a method to solve the problem with an optimal iteration complexity of $\mathcal{O}(\epsilon^{-3/2})$ to find an $\epsilon$-saddle point. However, it is unclear whether the computational complexity, $\mathcal{O}((N+ d^2) d \epsilon^{-2/3})$, can be improved. In the above, we follow Doikov et al. (2023) and assume the complexity of obtaining a first-order oracle as $N$ and the complexity of obtaining a second-order oracle as $dN$. In this paper, we show that the computation cost can be reduced by reusing Hessian across iterations. Our methods take the overall computational complexity of $ \tilde{\mathcal{O}}( (N+d^2)(d+ d^{2/3}\epsilon^{-2/3}))$, which improves those of previous methods by a factor of $d^{1/3}$. Furthermore, we generalize our method to strongly-convex-strongly-concave minimax problems and establish the complexity of $\tilde{\mathcal{O}}((N+d^2) (d + d^{2/3} \kappa^{2/3}) )$ when the condition number of the problem is $\kappa$, enjoying a similar speedup upon the state-of-the-art method. Numerical experiments on both real and synthetic datasets also verify the efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09568v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lesi Chen, Chengchang Liu, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>Large problems are not necessarily hard: A case study on distributed NMPC paying off</title>
      <link>https://arxiv.org/abs/2411.05627</link>
      <description>arXiv:2411.05627v2 Announce Type: replace 
Abstract: A key motivation in the development of Distributed Model Predictive Control (DMPC) is to accelerate centralized Model Predictive Control (MPC) for large-scale systems. DMPC has the prospect of scaling well by parallelizing computations among subsystems. However, communication delays may deteriorate the performance of decentralized optimization, if excessively many iterations are required per control step. Moreover, centralized solvers often exhibit faster asymptotic convergence rates and, by parallelizing costly linear algebra operations, they can also benefit from modern multicore computing architectures. On this canvas, we study the computational performance of cooperative DMPC for linear and nonlinear systems. To this end, we apply a tailored decentralized real-time iteration scheme to frequency control for power systems. DMPC scales well for the considered linear and nonlinear benchmarks, as the iteration number does not depend on the number of subsystems. Comparisons with multi-threaded centralized solvers demonstrate competitive performance of the proposed decentralized optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05627v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\"osta Stomberg, Maurice Raetsch, Alexander Engelmann, Timm Faulwasser</dc:creator>
    </item>
    <item>
      <title>Optimal Control of 1D Semilinear Heat Equations with Moment-SOS Relaxations</title>
      <link>https://arxiv.org/abs/2411.11528</link>
      <description>arXiv:2411.11528v2 Announce Type: replace 
Abstract: We use moment-SOS (Sum Of Squares) relaxations to address the optimal control problem of the 1D heat equation perturbed with a nonlinear term. We extend the current framework of moment-based optimal control of PDEs to consider a quadratic cost on the control. We develop a new method to extract a nonlinear controller from approximate moments of the solution. The control law acts on the boundary of the domain and depends on the solution over the whole domain. Our method is validated numerically and compared to a linear-quadratic controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11528v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charlie Lebarb\'e, Emilien Flayac, Michel Fourni\'e, Didier Henrion, Milan Korda</dc:creator>
    </item>
    <item>
      <title>Extended Set Difference : Inverse Operation of Minkowski Summation</title>
      <link>https://arxiv.org/abs/2412.19779</link>
      <description>arXiv:2412.19779v4 Announce Type: replace 
Abstract: This paper introduces the extended set difference, a generalization of the Hukuhara and generalized Hukuhara differences, defined for compact convex sets in $\mathbb{R}^d$. The proposed difference guarantees existence for any pair of such sets, offering a broader framework for set arithmetic. The difference may not be necessarily unique, but we offer a bound on the variety of solutions. The definition of the extended set difference is formulated through an optimization problem, which provides a constructive approach to its computation. The paper explores the properties of this new difference, including its stability under orthogonal transformations and its robustness to perturbations of the input sets. We propose a method to compute this difference through a formulated linear optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19779v4</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arie Beresteanu, Behrooz Moosavi Ramezanzadeh</dc:creator>
    </item>
    <item>
      <title>A two-stage search framework for constrained multi-gradient descent</title>
      <link>https://arxiv.org/abs/2502.14104</link>
      <description>arXiv:2502.14104v2 Announce Type: replace 
Abstract: The multi-gradient descent algorithm (MGDA) finds a common descent direction that can improve all objectives by identifying the minimum-norm point in the convex hull of the objective gradients. This method has become a foundational tool in large-scale multi-objective optimization, particularly in multi-task learning. However, MGDA may struggle with constrained problems, whether constraints are incorporated into the gradient hull or handled via projection onto the feasible region. To address this limitation, we propose a two-stage search algorithm for constrained multi-objective optimization. The first stage formulates a min-max problem that minimizes the upper bound of directional derivatives under constraints, yielding a weakly Pareto stationary solution with balanced progress across objectives. The second stage refines this solution by minimizing the lower bound of directional derivatives to achieve full Pareto stationarity. We evaluate the proposed method on three numerical examples. In a simple case with a known analytical Pareto front, our algorithm converges rapidly. In more complex real-world problems, it consistently outperforms the evolutionary baselines NSGA-II and NSGA-III.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14104v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan-Zheng Lei, Yaobang Gong, Xianfeng Terry Yang</dc:creator>
    </item>
    <item>
      <title>Some commutation principles for optimization problems over transformation groups and semi-FTvN systems</title>
      <link>https://arxiv.org/abs/2503.08654</link>
      <description>arXiv:2503.08654v2 Announce Type: replace 
Abstract: We introduce the concepts of commutativity relative to a transformation group and strong commutativity in the setting of a semi-FTvN system and show their appearance as optimality conditions in certain optimization problems. In the setting of a semi-FTvN system (in particular, in an FTvN system), we show that strong commutativity implies commutativity and observe that in the special case of Euclidean Jordan algebra, commutativity and strong commutativity concepts reduce, respectively, to those of operator and strong operator commutativity. We demonstrate that every complete hyperbolic polynomial induces a semi-FTvN system. By way of an application, we describe several commutation principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08654v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Seetharama Gowda, David Sossa</dc:creator>
    </item>
    <item>
      <title>Well-Posedness and Stability of Infinite-Dimensional Systems Under Monotone Feedback</title>
      <link>https://arxiv.org/abs/2503.16092</link>
      <description>arXiv:2503.16092v2 Announce Type: replace 
Abstract: We study the well-posedness and stability of an impedance passive infinite-dimensional linear system under nonlinear feedback of the form $u(t)=\phi(v(t)-y(t))$, where $\phi$ is a monotone function. Our first main result introduces conditions guaranteeing the existence of classical and generalised solutions in a situation where the original linear system is well-posed. In the absence of the external input $v$ we establish the existence of strong and generalised solutions under strictly weaker conditions. Finally, we introduce conditions guaranteeing that the origin is a globally asymptotically stable equilibrium point of the closed-loop system. Motivated by the analysis of partial differential equations with nonlinear boundary conditions, we use our results to investigate the well-posedness and stablility of abstract boundary control systems, port-Hamiltonian systems, a Timoshenko beam model, and a two-dimensional boundary controlled heat equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16092v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Hastir, Lassi Paunonen</dc:creator>
    </item>
    <item>
      <title>Tractable Characterization of Discrete-Time Periodic Monotonicity Preserving Systems</title>
      <link>https://arxiv.org/abs/2503.23520</link>
      <description>arXiv:2503.23520v2 Announce Type: replace 
Abstract: This paper studies three classes of discrete-time linear time-invariant systems, which differ by the set of periodic signals that they leave invariant. The first class preserves the property of periodic monotonicity, i.e., period-wise unimodality. The second class is invariant to signals with at most two sign changes per period, and the third class results from the second by additionally requiring that periodic signals with zero sign-changes are mapped to the same kind. We provide tractable characterizations for each system class by the use and extension of total positivity theory and combination with its geometric interpretations. In particular, central to our results is the characterization of sequentially convex contours.
  Moreover, as many static non-linearities, e.g., ideal relay, saturation, sigmoid function, quantizer, etc. also preserve these signal sets, our invariance characterizations also apply to the loop gain of Lur'e feedback systems. Thus, potentially forming the base for new developments of signal-based fixed-point theorems towards the prediction of self-sustained oscillations. In particular, our examples provide first indications for how the property of periodic monotonicity preservation is valuable to the study of relay feedback systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23520v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Christian Grussler</dc:creator>
    </item>
    <item>
      <title>Kernel Modelling of Fading Memory Systems</title>
      <link>https://arxiv.org/abs/2403.11945</link>
      <description>arXiv:2403.11945v2 Announce Type: replace-cross 
Abstract: The paper is a follow-up of the recently introduced kernel-based framework to identify nonlinear input-output systems regularized by desirable input-output incremental properties. Assuming that the system has fading memory, we propose to learn the functional that maps the past input to the present output rather than the operator mapping input trajectories to output trajectories. While retaining the benefits of the previously proposed framework, this modification simplifies the selection of the kernel, enforces causality, and enables temporal simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11945v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yongkang Huo, Thomas Chaffey, Rodolphe Sepulchre</dc:creator>
    </item>
    <item>
      <title>Verifying Properties of Binary Neural Networks Using Sparse Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2405.17049</link>
      <description>arXiv:2405.17049v2 Announce Type: replace-cross 
Abstract: This paper explores methods for verifying the properties of Binary Neural Networks (BNNs), focusing on robustness against adversarial attacks. Despite their lower computational and memory needs, BNNs, like their full-precision counterparts, are also sensitive to input perturbations. Established methods for solving this problem are predominantly based on Satisfiability Modulo Theories and Mixed-Integer Linear Programming techniques, which are characterized by NP complexity and often face scalability issues.
  We introduce an alternative approach using Semidefinite Programming relaxations derived from sparse Polynomial Optimization. Our approach, compatible with continuous input space, not only mitigates numerical issues associated with floating-point calculations but also enhances verification scalability through the strategic use of tighter first-order semidefinite relaxations. We demonstrate the effectiveness of our method in verifying robustness against both $\|.\|_\infty$ and $\|.\|_2$-based adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17049v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianting Yang, Sre\'cko {\DH}ura\v{s}inovi\'c, Jean-Bernard Lasserre, Victor Magron, Jun Zhao</dc:creator>
    </item>
    <item>
      <title>A characterization of positive spanning sets with ties to strongly connected digraphs</title>
      <link>https://arxiv.org/abs/2411.08994</link>
      <description>arXiv:2411.08994v2 Announce Type: replace-cross 
Abstract: Positive spanning sets (PSSs) are families of vectors that span a given linear space through non-negative linear combinations. Despite certain classes of PSSs being well understood, a complete characterization of PSSs remains elusive. In this paper, we explore a relatively understudied relationship between positive spanning sets and strongly edge-connected digraphs, in that the former can be viewed as a generalization of the latter. We leverage this connection to define a decomposition structure for positive spanning sets inspired by the ear decomposition from digraph theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08994v2</guid>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Denis Cornaz, S\'ebastien Kerleau, Cl\'ement W. Royer</dc:creator>
    </item>
    <item>
      <title>Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?</title>
      <link>https://arxiv.org/abs/2501.16371</link>
      <description>arXiv:2501.16371v2 Announce Type: replace-cross 
Abstract: Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. More recently, physics-informed Kolmogorv-Arnold networks (PIKANs) have also shown to be effective and comparable in accuracy with PINNs. In their current implementation, both PINNs and PIKANs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled BFGS (SSBFGS), Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies approaches. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers -- using both PINNs and PIKANs -- on key challenging linear, stiff, multi-scale and non-linear PDEs, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations. Our findings provide state-of-the-art results with orders-of-magnitude accuracy improvements without the use of adaptive weights or any other enhancements typically employed in PINNs. More broadly, our results reveal insights into the effectiveness of second-order optimization strategies in significantly improving the convergence and accurate generalization of PINNs and PIKANs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16371v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Elham Kiyani, Khemraj Shukla, Jorge F. Urb\'an, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Explainable and Class-Revealing Signal Feature Extraction via Scattering Transform and Constrained Zeroth-Order Optimization</title>
      <link>https://arxiv.org/abs/2502.05722</link>
      <description>arXiv:2502.05722v3 Announce Type: replace-cross 
Abstract: We propose a new method to extract discriminant and explainable features from a particular machine learning model, i.e., a combination of the scattering transform and the multiclass logistic regression. Although this model is well-known for its ability to learn various signal classes with high classification rate, it remains elusive to understand why it can generate such successful classification, mainly due to the nonlinearity of the scattering transform. In order to uncover the meaning of the scattering transform coefficients selected by the multiclass logistic regression (with the Lasso penalty), we adopt zeroth-order optimization algorithms to search an input pattern that maximizes the class probability of a class of interest given the learned model. In order to do so, it turns out that imposing sparsity and smoothness of input patterns is important. We demonstrate the effectiveness of our proposed method using a couple of synthetic time-series classification problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05722v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoki Saito, David Weber</dc:creator>
    </item>
    <item>
      <title>The effect of latency on optimal order execution policy</title>
      <link>https://arxiv.org/abs/2504.00846</link>
      <description>arXiv:2504.00846v2 Announce Type: replace-cross 
Abstract: Market participants regularly send bid and ask quotes to exchange-operated limit order books. This creates an optimization challenge where their potential profit is determined by their quoted price and how often their orders are successfully executed. The expected profit from successful execution at a favorable limit price needs to be balanced against two key risks: (1) the possibility that orders will remain unfilled, which hinders the trading agenda and leads to greater price uncertainty, and (2) the danger that limit orders will be executed as market orders, particularly in the presence of order submission latency, which in turn results in higher transaction costs. In this paper, we consider a stochastic optimal control problem where a risk-averse trader attempts to maximize profit while balancing risk. The market is modeled using Brownian motion to represent the price uncertainty. We analyze the relationship between fill probability, limit price, and order submission latency. We derive closed-form approximations of these quantities that perform well in the practical regime of interest. Then, we utilize a mean-variance method where our total reward function features a risk-tolerance parameter to quantify the combined risk and profit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00846v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chutian Ma, Giacinto Paolo Saggese, Paul Smith</dc:creator>
    </item>
    <item>
      <title>A Piecewise Lyapunov Analysis of Sub-quadratic SGD: Applications to Robust and Quantile Regression</title>
      <link>https://arxiv.org/abs/2504.08178</link>
      <description>arXiv:2504.08178v3 Announce Type: replace-cross 
Abstract: Motivated by robust and quantile regression problems, we investigate the stochastic gradient descent (SGD) algorithm for minimizing an objective function $f$ that is locally strongly convex with a sub--quadratic tail. This setting covers many widely used online statistical methods. We introduce a novel piecewise Lyapunov function that enables us to handle functions $f$ with only first-order differentiability, which includes a wide range of popular loss functions such as Huber loss. Leveraging our proposed Lyapunov function, we derive finite-time moment bounds under general diminishing stepsizes, as well as constant stepsizes. We further establish the weak convergence, central limit theorem and bias characterization under constant stepsize, providing the first geometrical convergence result for sub--quadratic SGD. Our results have wide applications, especially in online statistical methods. In particular, we discuss two applications of our results. 1) Online robust regression: We consider a corrupted linear model with sub--exponential covariates and heavy--tailed noise. Our analysis provides convergence rates comparable to those for corrupted models with Gaussian covariates and noise. 2) Online quantile regression: Importantly, our results relax the common assumption in prior work that the conditional density is continuous and provide a more fine-grained analysis for the moment bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08178v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixuan Zhang, Dongyan Huo, Yudong Chen, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Diversity-Fair Online Selection</title>
      <link>https://arxiv.org/abs/2504.10389</link>
      <description>arXiv:2504.10389v2 Announce Type: replace-cross 
Abstract: Online selection problems frequently arise in applications such as crowdsourcing and employee recruitment. Existing research typically focuses on candidates with a single attribute. However, crowdsourcing tasks often require contributions from individuals across various demographics. Further motivated by the dynamic nature of crowdsourcing and hiring, we study the diversity-fair online selection problem, in which a recruiter must make real-time decisions to foster workforce diversity across many dimensions. We propose two scenarios for this problem. The fixed-capacity scenario, suited for short-term hiring for crowdsourced workers, provides the recruiter with a fixed capacity to fill temporary job vacancies. In contrast, in the unknown-capacity scenario, recruiters optimize diversity across recruitment seasons with increasing capacities, reflecting that the firm honors diversity consideration in a long-term employee acquisition strategy. By modeling the diversity over $d$ dimensions as a max-min fairness objective, we show that no policy can surpass a competitive ratio of $O(1/d^{1/3})$ for either scenario, indicating that any achievable result inevitably decays by some polynomial factor in $d$. To this end, we develop bilevel hierarchical randomized policies that ensure compliance with the capacity constraint. For the fixed-capacity scenario, leveraging marginal information about the arriving population allows us to achieve a competitive ratio of $1/(4\sqrt{d} \lceil \log_2 d \rceil)$. For the unknown-capacity scenario, we establish a competitive ratio of $\Omega(1/d^{3/4})$ under mild boundedness conditions. In both bilevel hierarchical policies, the higher level determines ex-ante selection probabilities and then informs the lower level's randomized selection that ensures no loss in efficiency. Both policies prioritize core diversity and then adjust for underrepresented dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10389v2</guid>
      <category>econ.TH</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Hu, Yanzhi Li, Tongwen Wu</dc:creator>
    </item>
  </channel>
</rss>
