<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Generalist Brain Module: Module Repetition in Neural Networks in Light of the Minicolumn Hypothesis</title>
      <link>https://arxiv.org/abs/2507.12473</link>
      <description>arXiv:2507.12473v1 Announce Type: new 
Abstract: While modern AI continues to advance, the biological brain remains the pinnacle of neural networks in its robustness, adaptability, and efficiency. This review explores an AI architectural path inspired by the brain's structure, particularly the minicolumn hypothesis, which views the neocortex as a distributed system of repeated modules - a structure we connect to collective intelligence (CI). Despite existing work, there is a lack of comprehensive reviews connecting the cortical column to the architectures of repeated neural modules. This review aims to fill that gap by synthesizing historical, theoretical, and methodological perspectives on neural module repetition. We distinguish between architectural repetition - reusing structure - and parameter-shared module repetition, where the same functional unit is repeated across a network. The latter exhibits key CI properties such as robustness, adaptability, and generalization. Evidence suggests that the repeated module tends to converge toward a generalist module: simple, flexible problem solvers capable of handling many roles in the ensemble. This generalist tendency may offer solutions to longstanding challenges in modern AI: improved energy efficiency during training through simplicity and scalability, and robust embodied control via generalization. While empirical results suggest such systems can generalize to out-of-distribution problems, theoretical results are still lacking. Overall, architectures featuring module repetition remain an emerging and unexplored architectural strategy, with significant untapped potential for both efficiency, robustness, and adaptiveness. We believe that a system that adopts the benefits of CI, while adhering to architectural and functional principles of the minicolumns, could challenge the modern AI problems of scalability, energy consumption, and democratization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12473v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mia-Katrin Kvalsund, Mikkel Elle Lepper{\o}d</dc:creator>
    </item>
    <item>
      <title>Cognitive Modelling Aspects of Neurodevelopmental Disorders Using Standard and Oscillating Neighbourhood SOM Neural Networks</title>
      <link>https://arxiv.org/abs/2507.12567</link>
      <description>arXiv:2507.12567v1 Announce Type: new 
Abstract: Background/Introduction: In this paper, the neural network class of Self-Organising Maps (SOMs) is investigated in terms of its theoretical and applied validity for cognitive modelling, particularly of neurodevelopmental disorders.
  Methods: A modified SOM network type, with increased biological plausibility, incorporating a type of cortical columnar oscillation in the form of an oscillating Topological Neighbourhood (TN), is introduced and applied alongside the standard SOM. Aspects of two neurodevelopmental disorders, autism and schizophrenia, are modelled using SOM networks, based on existing neurocomputational theories. Both standard and oscillating-TN SOM training is employed with targeted modifications in the TN width function. Computer simulations are conducted using revised versions of a previously introduced model (IPSOM) based on a new modelling hypothesis.
  Results/Conclusions: The results demonstrate that there is strong similarity between standard and oscillating-TN SOM modelling in terms of map formation behaviour, output and structure, while the oscillating version offers a more realistic computational analogue of brain function. Neuroscientific and computational arguments are presented to validate the proposed SOM modification within a cognitive modelling framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12567v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spyridon Revithis, Nadine Marcus</dc:creator>
    </item>
    <item>
      <title>Mapping Emotions in the Brain: A Bi-Hemispheric Neural Model with Explainable Deep Learning</title>
      <link>https://arxiv.org/abs/2507.12625</link>
      <description>arXiv:2507.12625v1 Announce Type: new 
Abstract: Recent advances have shown promise in emotion recognition from electroencephalogram (EEG) signals by employing bi-hemispheric neural architectures that incorporate neuroscientific priors into deep learning models. However, interpretability remains a significant limitation for their application in sensitive fields such as affective computing and cognitive modeling. In this work, we introduce a post-hoc interpretability framework tailored to dual-stream EEG classifiers, extending the Local Interpretable Model-Agnostic Explanations (LIME) approach to accommodate structured, bi-hemispheric inputs. Our method adapts LIME to handle structured two-branch inputs corresponding to left and right-hemisphere EEG channel groups. It decomposes prediction relevance into per-channel contributions across hemispheres and emotional classes. We apply this framework to a previously validated dual-branch recurrent neural network trained on EmoNeuroDB, a dataset of EEG recordings captured during a VR-based emotion elicitation task. The resulting explanations reveal emotion-specific hemispheric activation patterns consistent with known neurophysiological phenomena, such as frontal lateralization in joy and posterior asymmetry in sadness. Furthermore, we aggregate local explanations across samples to derive global channel importance profiles, enabling a neurophysiologically grounded interpretation of the model's decisions. Correlation analysis between symmetric electrodes further highlights the model's emotion-dependent lateralization behavior, supporting the functional asymmetries reported in affective neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12625v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Freire-Obreg\'on, Agnieszka Dubiel, Prasoon Kumar Vinodkumar, Gholamreza Anbarjafari, Dorota Kami\'nska, Modesto Castrill\'on-Santana</dc:creator>
    </item>
    <item>
      <title>Emergence of Functionally Differentiated Structures via Mutual Information Optimization in Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2507.12858</link>
      <description>arXiv:2507.12858v1 Announce Type: new 
Abstract: Functional differentiation in the brain emerges as distinct regions specialize and is key to understanding brain function as a complex system. Previous research has modeled this process using artificial neural networks with specific constraints. Here, we propose a novel approach that induces functional differentiation in recurrent neural networks by minimizing mutual information between neural subgroups via mutual information neural estimation. We apply our method to a 2-bit working memory task and a chaotic signal separation task involving Lorenz and R\"ossler time series. Analysis of network performance, correlation patterns, and weight matrices reveals that mutual information minimization yields high task performance alongside clear functional modularity and moderate structural modularity. Importantly, our results show that functional differentiation, which is measured through correlation structures, emerges earlier than structural modularity defined by synaptic weights. This suggests that functional specialization precedes and probably drives structural reorganization within developing neural networks. Our findings provide new insights into how information-theoretic principles may govern the emergence of specialized functions and modular structures during artificial and biological brain development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12858v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuki Tomoda, Ichiro Tsuda, Yutaka Yamaguti</dc:creator>
    </item>
    <item>
      <title>Geometric Hyperscanning of Affect under Active Inference</title>
      <link>https://arxiv.org/abs/2506.08599</link>
      <description>arXiv:2506.08599v2 Announce Type: replace 
Abstract: Second-person neuroscience holds social cognition as embodied meaning co-regulation through reciprocal interaction, modeled here as coupled active inference with affect emerging as inference over identity-relevant surprise. Each agent maintains a self-model that tracks violations in its predictive coherence while recursively modeling the other. Valence is computed from self-model prediction error, weighted by self-relevance, and modulated by prior affective states and by what we term temporal aiming, which captures affective appraisal over time. This accommodates shifts in the self-other boundary, allowing affect to emerge at individual and dyadic levels. We propose a novel method termed geometric hyperscanning, based on the Forman-Ricci curvature, to empirically operationalize these processes: it tracks topological reconfigurations in inter-brain networks, with its entro-py serving as a proxy for affective phase transitions such as rupture, co-regulation, and re-attunement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08599v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Hinrichs, Mahault Albarracin, Dimitris Bolis, Yuyue Jiang, Leonardo Christov-Moore, Leonhard Schilbach</dc:creator>
    </item>
    <item>
      <title>Leveraging Quantum Superposition to Infer the Dynamic Behavior of a Spatial-Temporal Neural Network Signaling Model</title>
      <link>https://arxiv.org/abs/2403.18963</link>
      <description>arXiv:2403.18963v4 Announce Type: replace-cross 
Abstract: The exploration of new problem classes for quantum computation is an active area of research. In this paper, we introduce and solve a novel problem class related to dynamics on large-scale networks relevant to neurobiology and machine learning. Specifically, we ask if a network can sustain inherent dynamic activity beyond some arbitrary observation time or if the activity ceases through quiescence or saturation via an epileptic-like state. We show that this class of problems can be formulated and structured to take advantage of quantum superposition and solved efficiently using a coupled workflow between the Grover and Deutsch-Jozsa quantum algorithms. To do so, we extend their functionality to address the unique requirements of how input (sub)sets into the algorithms must be mathematically structured while simultaneously constructing the inputs so that measurement outputs can be interpreted as meaningful properties of the network dynamics. This, in turn, allows us to answer the question we pose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18963v4</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel A. Silva</dc:creator>
    </item>
  </channel>
</rss>
