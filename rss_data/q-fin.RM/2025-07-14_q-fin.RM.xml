<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Jul 2025 04:00:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quantifying Crypto Portfolio Risk: A Simulation-Based Framework Integrating Volatility, Hedging, Contagion, and Monte Carlo Modeling</title>
      <link>https://arxiv.org/abs/2507.08915</link>
      <description>arXiv:2507.08915v1 Announce Type: new 
Abstract: Extreme volatility, nonlinear dependencies, and systemic fragility are characteristics of cryptocurrency markets. The assumptions of normality and centralized control in traditional financial risk models frequently cause them to miss these changes. Four components-volatility stress testing, stablecoin hedging, contagion modeling, and Monte Carlo simulation-are integrated into this paper's modular simulation framework for crypto portfolio risk analysis. Every module is based on mathematical finance theory, which includes stochastic price path generation, correlation-based contagion propagation, and mean-variance optimization. The robustness and practical relevance of the framework are demonstrated through empirical validation utilizing 2020-2024 USDT, ETH, and BTC data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08915v1</guid>
      <category>q-fin.RM</category>
      <category>math.PR</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiarash Firouzi</dc:creator>
    </item>
    <item>
      <title>Generalized Orlicz premia</title>
      <link>https://arxiv.org/abs/2507.09181</link>
      <description>arXiv:2507.09181v1 Announce Type: new 
Abstract: We introduce a generalized version of Orlicz premia, based on possibly non-convex loss functions. We show that this generalized definition covers a variety of relevant examples, such as the geometric mean and the expectiles, while at the same time retaining a number of relevant properties. We establish that cash-additivity leads to $L^p$-quantiles, extending a classical result on 'collapse to the mean' for convex Orlicz premia.
  We then focus on the geometrically convex case, discussing the dual representation of generalized Orlicz premia and comparing it with a multiplicative form of the standard dual representation for the convex case. Finally, we show that generalized Orlicz premia arise naturally as the only elicitable, positively homogeneous, monotone and normalized functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09181v1</guid>
      <category>q-fin.RM</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>q-fin.MF</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M\"ucahit Ayg\"un, Fabio Bellini, Roger J. A. Laeven</dc:creator>
    </item>
    <item>
      <title>Norms Based on Generalized Expected-Shortfalls and Applications</title>
      <link>https://arxiv.org/abs/2507.09444</link>
      <description>arXiv:2507.09444v1 Announce Type: new 
Abstract: This paper proposes a novel class of generalized Expected-Shortfall (ES) norms constructed via distortion risk measures, establishing a unified analytical framework for risk quantification. The proposed norms extend conventional ES methodology by incorporating flexible distortion functions. Specifically, we develop the mathematical duality theory for generalized-ES norms to support portfolio optimization tasks, while demonstrating their practical utility through projection problem solutions. The generalizedES norms are also applied to detect anomalies of financial time series data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09444v1</guid>
      <category>q-fin.RM</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyu Gong, Taizhong Hu, Zhenfeng Zou</dc:creator>
    </item>
    <item>
      <title>Representation learning with a transformer by contrastive learning for money laundering detection</title>
      <link>https://arxiv.org/abs/2507.08835</link>
      <description>arXiv:2507.08835v1 Announce Type: cross 
Abstract: The present work tackles the money laundering detection problem. A new procedure is introduced which exploits structured time series of both qualitative and quantitative data by means of a transformer neural network. The first step of this procedure aims at learning representations of time series through contrastive learning (without any labels). The second step leverages these representations to generate a money laundering scoring of all observations. A two-thresholds approach is then introduced, which ensures a controlled false-positive rate by means of the Benjamini-Hochberg (BH) procedure. Experiments confirm that the transformer is able to produce general representations that succeed in exploiting money laundering patterns with minimal supervision from domain experts. It also illustrates the higher ability of the new procedure for detecting nonfraudsters as well as fraudsters, while keeping the false positive rate under control. This greatly contrasts with rule-based procedures or the ones based on LSTM architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08835v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harold Gu\'eneau (SAMM), Alain Celisse (LPP, MODAL), Pascal Delange</dc:creator>
    </item>
    <item>
      <title>Principal Component Copulas for Capital Modelling and Systemic Risk</title>
      <link>https://arxiv.org/abs/2312.13195</link>
      <description>arXiv:2312.13195v3 Announce Type: replace 
Abstract: We introduce a class of copulas that we call Principal Component Copulas (PCCs). This class combines the strong points of copula-based techniques with principal component analysis (PCA), which results in flexibility when modelling tail dependence along the most important directions in high-dimensional data. We obtain theoretical results for PCCs that are important for practical applications. In particular, we derive tractable expressions for the high-dimensional copula density, which can be represented in terms of characteristic functions. We also develop algorithms to perform Maximum Likelihood and Generalized Method of Moment estimation in high-dimensions and show very good performance in simulation experiments. Finally, we apply the copula to the international stock market to study systemic risk. We find that PCCs lead to excellent performance on measures of systemic risk due to their ability to distinguish between parallel and orthogonal movements in the global market, which have a different impact on systemic risk and diversification. As a result, we consider the PCC promising for capital models, which financial institutions use to protect themselves against systemic risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13195v3</guid>
      <category>q-fin.RM</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. B. Gubbels, J. Y. Ypma, C. W. Oosterlee</dc:creator>
    </item>
    <item>
      <title>QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection</title>
      <link>https://arxiv.org/abs/2404.02595</link>
      <description>arXiv:2404.02595v5 Announce Type: replace-cross 
Abstract: This study introduces the Quantum Federated Neural Network for Financial Fraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine Learning (QML) and quantum computing with Federated Learning (FL) for financial fraud detection. Using quantum technologies' computational power and the robust data privacy protections offered by FL, QFNN-FFD emerges as a secure and efficient method for identifying fraudulent transactions within the financial sector. Implementing a dual-phase training model across distributed clients enhances data integrity and enables superior performance metrics, achieving precision rates consistently above 95%. Additionally, QFNN-FFD demonstrates exceptional resilience by maintaining an impressive 80% accuracy, highlighting its robustness and readiness for real-world applications. This combination of high performance, security, and robustness against noise positions QFNN-FFD as a transformative advancement in financial technology solutions and establishes it as a new benchmark for privacy-focused fraud detection systems. This framework facilitates the broader adoption of secure, quantum-enhanced financial services and inspires future innovations that could use QML to tackle complex challenges in other areas requiring high confidentiality and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02595v5</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nouhaila Innan, Alberto Marchisio, Mohamed Bennai, Muhammad Shafique</dc:creator>
    </item>
    <item>
      <title>Insuring Uninsurable Risks from AI: Government as Insurer of Last Resort</title>
      <link>https://arxiv.org/abs/2409.06672</link>
      <description>arXiv:2409.06672v3 Announce Type: replace-cross 
Abstract: Many experts believe that AI systems will sooner or later pose uninsurable risks, including existential risks. This creates an extreme judgment-proof problem: few if any parties can be held accountable ex post in the event of such a catastrophe. This paper proposes a novel solution: a government-provided, mandatory indemnification program for AI developers. The program uses risk-priced indemnity fees to induce socially optimal levels of care. Risk-estimates are determined by surveying experts, including indemnified developers. The Bayesian Truth Serum mechanism is employed to incent honest and effortful responses. Compared to alternatives, this approach arguably better leverages all private information, and provides a clearer signal to indemnified developers regarding what risks they must mitigate to lower their fees. It's recommended that collected fees be used to help fund the safety research developers need, employing a fund matching mechanism (Quadratic Financing) to induce an optimal supply of this public good. Under Quadratic Financing, safety research projects would compete for private contributions from developers, signaling how much each is to be supplemented with public funds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06672v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristian Trout</dc:creator>
    </item>
    <item>
      <title>Discrimination-free Insurance Pricing with Privatized Sensitive Attributes</title>
      <link>https://arxiv.org/abs/2504.11775</link>
      <description>arXiv:2504.11775v2 Announce Type: replace-cross 
Abstract: Fairness has emerged as a critical consideration in the landscape of machine learning algorithms, particularly as AI continues to transform decision-making across societal domains. To ensure that these algorithms are free from bias and do not discriminate against individuals based on sensitive attributes such as gender and race, the field of algorithmic bias has introduced various fairness concepts, along with methodologies to achieve these notions in different contexts. Despite the rapid advancement, not all sectors have embraced these fairness principles to the same extent. One specific sector that merits attention in this regard is insurance. Within the realm of insurance pricing, fairness is defined through a distinct and specialized framework. Consequently, achieving fairness according to established notions does not automatically ensure fair pricing in insurance. In particular, regulators are increasingly emphasizing transparency in pricing algorithms and imposing constraints on insurance companies on the collection and utilization of sensitive consumer attributes. These factors present additional challenges in the implementation of fairness in pricing algorithms. To address these complexities and comply with regulatory demands, we propose an efficient method for constructing fair models that are tailored to the insurance domain, using only privatized sensitive attributes. Notably, our approach ensures statistical guarantees, does not require direct access to sensitive attributes, and adapts to varying transparency requirements, addressing regulatory demands while ensuring fairness in insurance pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11775v2</guid>
      <category>stat.ML</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianhe Zhang, Suhan Liu, Peng Shi</dc:creator>
    </item>
  </channel>
</rss>
