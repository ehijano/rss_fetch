<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Aug 2024 06:32:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Virtual Element Methods for HJB Equations with Cordes Coefficients</title>
      <link>https://arxiv.org/abs/2408.07153</link>
      <description>arXiv:2408.07153v1 Announce Type: new 
Abstract: In this paper, we propose and analyze both conforming and nonconforming virtual element methods (VEMs) for the fully nonlinear second-order elliptic Hamilton-Jacobi-Bellman (HJB) equations with Cordes coefficients. By incorporating stabilization terms, we establish the well-posedness of the proposed methods, thus avoiding the need to construct a discrete Miranda-Talenti estimate. We derive the optimal error estimate in the discrete $H^2$ norm for both numerical formulations. Furthermore, a semismooth Newton's method is employed to linearize the discrete problems. Several numerical experiments using the lowest-order VEMs are provided to demonstrate the efficacy of the proposed methods and to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07153v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Cai, Hailong Guo, Zhimin Zhang</dc:creator>
    </item>
    <item>
      <title>Analysis of error propagation in the RK3GL2 method</title>
      <link>https://arxiv.org/abs/2408.07186</link>
      <description>arXiv:2408.07186v1 Announce Type: new 
Abstract: The RK3GL2 method is a numerical method for solving initial value problems in ordinary differential equations, and is a hybrid of a third-order Runge-Kutta method and two-point Gauss-Legendre quadrature. In this paper we present an analytical study of the propagation of local errors in this method, and show that the global order of RK3GL2 is expected to be four.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07186v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. S. C. Prentice</dc:creator>
    </item>
    <item>
      <title>Lifting MGARD: construction of (pre)wavelets on the interval using polynomial predictors of arbitrary order</title>
      <link>https://arxiv.org/abs/2408.07212</link>
      <description>arXiv:2408.07212v1 Announce Type: new 
Abstract: MGARD (MultiGrid Adaptive Reduction of Data) is an algorithm for compressing and refactoring scientific data, based on the theory of multigrid methods. The core algorithm is built around stable multilevel decompositions of conforming piecewise linear $C^0$ finite element spaces, enabling accurate error control in various norms and derived quantities of interest. In this work, we extend this construction to arbitrary order Lagrange finite elements $\mathbb{Q}_p$, $p \geq 0$, and propose a reformulation of the algorithm as a lifting scheme with polynomial predictors of arbitrary order. Additionally, a new formulation using a compactly supported wavelet basis is discussed, and an explicit construction of the proposed wavelet transform for uniform dyadic grids is described.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07212v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Reshniak, Evan Ferguson, Qian Gong, Nicolas Vidal, Rick Archibald, Scott Klasky</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of a class of penalty discontinuous Galerkin methods for nonlocal diffusion problems</title>
      <link>https://arxiv.org/abs/2408.07261</link>
      <description>arXiv:2408.07261v1 Announce Type: new 
Abstract: In this paper, we consider a class of discontinuous Galerkin (DG) methods for one-dimensional nonlocal diffusion (ND) problems. The nonlocal models, which are integral equations, are widely used in describing many physical phenomena with long-range interactions. The ND problem is the nonlocal analog of the classic diffusion problem, and as the interaction radius (horizon) vanishes, then the nonlocality disappears and the ND problem converges to the classic diffusion problem. Under certain conditions, the exact solution to the ND problem may exhibit discontinuities, setting it apart from the classic diffusion problem. Since the DG method shows its great advantages in resolving problems with discontinuities in computational fluid dynamics over the past several decades, it is natural to adopt the DG method to compute the ND problems. Based on [Du-Ju-Lu-Tian-CAMC2020], we develop the DG methods with different penalty terms, ensuring that the proposed DG methods have local counterparts as the horizon vanishes. This indicates the proposed methods will converge to the existing DG schemes as the horizon vanishes, which is crucial for achieving asymptotic compatibility. Rigorous proofs are provided to demonstrate the stability, error estimates, and asymptotic compatibility of the proposed DG schemes. To observe the effect of the nonlocal diffusion, we also consider the time-dependent convection-diffusion problems with nonlocal diffusion. We conduct several numerical experiments, including accuracy tests and Burgers' equation with nonlocal diffusion, and various horizons are taken to show the good performance of the proposed algorithm and validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07261v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Du, Lili Ju, Jianfang Lu, Xiaochuan Tian</dc:creator>
    </item>
    <item>
      <title>An abstract approach to the Robin-Robin method</title>
      <link>https://arxiv.org/abs/2408.07392</link>
      <description>arXiv:2408.07392v1 Announce Type: new 
Abstract: Recently, their has been development of an abstract approach to the Robin--Robin method, enabling the treatment of linear and nonlinear elliptic and parabolic equations on Lipschitz domains within one framework. However, previously this setting has not been applicable to initial-boundary value problems. The aim of this short note is therefore to demonstrate that this general framework can be applied to such problems as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07392v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emil Engstr\"om, Eskil Hansen</dc:creator>
    </item>
    <item>
      <title>Two-level hybrid Schwarz Preconditioners for The Helmholtz Equation with high wave number</title>
      <link>https://arxiv.org/abs/2408.07669</link>
      <description>arXiv:2408.07669v1 Announce Type: new 
Abstract: In this work, we propose and analyze two two-level hybrid Schwarz preconditioners for solving the Helmholtz equation with high wave number in two and three dimensions. Both preconditioners are defined over a set of overlapping subdomains, with each preconditioner formed by a global coarse solver and one local solver on each subdomain. The global coarse solver is based on the localized orthogonal decomposition (LOD) technique, which was proposed in [27,28] originally for the discretization schemes for elliptic multiscale problems with heterogeneous and highly oscillating coefficients and Helmholtz problems with high wave number to eliminate the pollution effect. The local subproblems are Helmholtz problems in subdomains with homogeneous boundary conditions (the first preconditioner) or impedance boundary conditions (the second preconditioner). Both preconditioners are shown to be optimal under some reasonable conditions, that is, a uniform upper bound of the preconditioned operator norm and a uniform lower bound of the field of values are established in terms of all the key parameters, such as the fine mesh size, the coarse mesh size, the subdomain size and the wave numbers. It is the first time to show that the LOD solver can be a very effective coarse solver when it is used appropriately in the Schwarz method with multiple overlapping subdomains. Numerical experiments are presented to confirm the optimality and efficiency of the two proposed preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07669v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peipei Lu, Xuejun Xu, Bowen Zheng, Jun Zou</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Double Reconfigurable Intelligent Surfaces Assisted NOMA Networks</title>
      <link>https://arxiv.org/abs/2408.07670</link>
      <description>arXiv:2408.07670v1 Announce Type: new 
Abstract: This paper introduces double cascaded reconfigurable intelligent surfaces (RISs) to non-orthogonal multiple access (NOMA) networks over cascaded Rician fading and Nakagami-$m$ fading channels, where two kinds of passive RIS (PRIS) and active RIS (ARIS) are taken into consideration, called PRIS-ARIS-NOMA networks. Additionally, new closed-form and asymptotic expressions for outage probability and ergodic data rate of two non-orthogonal users are derived with the imperfect/perfect successive interference cancellation schemes. The scenario is modelled around two non-orthogonal users and focuses on analyzing their communication characteristics. Based on the approximate results, the diversity orders and ergodic data rate slopes of two users are obtained in the high signal-to-noise ratios. In addition, the system throughput of PRIS-ARIS-NOMA in delay-limited mode and delay-tolerant mode are discussed according to the outage probability and ergodic data rate. The simulation results verify the correctness of the formulas and yields the following insights: 1) The outage behaviors of PRIS-ARIS-NOMA outperforms than that of PRIS-ARIS assisted orthogonal multiple access (OMA); 2)Use of PRIS-ARIS-NOMA is better than use of PRIS-ARIS-OMA in small transmit power threshold scenarios 3) By increasing the number of reflecting elements of RISs, the PRIS-ARIS-NOMA is able to achieve the enhanced outage performance; and 4) The PRIS-ARIS-NOMA has the higher ergodic data rate and system throughput than double PRISs-NOMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07670v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuehua Li, Xuanhao Lian, Xinwei Yue, Zhiping Lu, Chongwen Huang, Tianwei Hou</dc:creator>
    </item>
    <item>
      <title>A family of high-order accurate contour integral methods for strongly continuous semigroups</title>
      <link>https://arxiv.org/abs/2408.07691</link>
      <description>arXiv:2408.07691v1 Announce Type: new 
Abstract: Exponential integrators based on contour integral representations lead to powerful numerical solvers for a variety of ODEs, PDEs, and other time-evolution equations. They are embarrassingly parallelizable and lead to global-in-time approximations that can be efficiently evaluated anywhere within a finite time horizon. In this article, we propose a family of new high-order quadrature schemes for strongly continuous semigroups based on regularized contour integral representations. Our algorithms are accompanied by explicit high-order error bounds and near-optimal parameter selection. We demonstrate key features of the schemes on singular first-order PDEs from Koopman operator theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07691v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Horning, Adam R. Gerlach</dc:creator>
    </item>
    <item>
      <title>Fast Unconstrained Optimization via Hessian Averaging and Adaptive Gradient Sampling Methods</title>
      <link>https://arxiv.org/abs/2408.07268</link>
      <description>arXiv:2408.07268v1 Announce Type: cross 
Abstract: We consider minimizing finite-sum and expectation objective functions via Hessian-averaging based subsampled Newton methods. These methods allow for gradient inexactness and have fixed per-iteration Hessian approximation costs. The recent work (Na et al. 2023) demonstrated that Hessian averaging can be utilized to achieve fast $\mathcal{O}\left(\sqrt{\tfrac{\log k}{k}}\right)$ local superlinear convergence for strongly convex functions in high probability, while maintaining fixed per-iteration Hessian costs. These methods, however, require gradient exactness and strong convexity, which poses challenges for their practical implementation. To address this concern we consider Hessian-averaged methods that allow gradient inexactness via norm condition based adaptive-sampling strategies. For the finite-sum problem we utilize deterministic sampling techniques which lead to global linear and sublinear convergence rates for strongly convex and nonconvex functions respectively. In this setting we are able to derive an improved deterministic local superlinear convergence rate of $\mathcal{O}\left(\tfrac{1}{k}\right)$. For the %expected risk expectation problem we utilize stochastic sampling techniques, and derive global linear and sublinear rates for strongly convex and nonconvex functions, as well as a $\mathcal{O}\left(\tfrac{1}{\sqrt{k}}\right)$ local superlinear convergence rate, all in expectation. We present novel analysis techniques that differ from the previous probabilistic results. Additionally, we propose scalable and efficient variations of these methods via diagonal approximations and derive the novel diagonally-averaged Newton (Dan) method for large-scale problems. Our numerical results demonstrate that the Hessian averaging not only helps with convergence, but can lead to state-of-the-art performance on difficult problems such as CIFAR100 classification with ResNets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07268v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas O'Leary-Roseberry, Raghu Bollapragada</dc:creator>
    </item>
    <item>
      <title>Posterior Covariance Structures in Gaussian Processes</title>
      <link>https://arxiv.org/abs/2408.07379</link>
      <description>arXiv:2408.07379v1 Announce Type: cross 
Abstract: In this paper, we present a comprehensive analysis of the posterior covariance field in Gaussian processes, with applications to the posterior covariance matrix. The analysis is based on the Gaussian prior covariance but the approach also applies to other covariance kernels. Our geometric analysis reveals how the Gaussian kernel's bandwidth parameter and the spatial distribution of the observations influence the posterior covariance as well as the corresponding covariance matrix, enabling straightforward identification of areas with high or low covariance in magnitude. Drawing inspiration from the a posteriori error estimation techniques in adaptive finite element methods, we also propose several estimators to efficiently measure the absolute posterior covariance field, which can be used for efficient covariance matrix approximation and preconditioning. We conduct a wide range of experiments to illustrate our theoretical findings and their practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07379v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Difeng Cai, Edmond Chow, Yuanzhe Xi</dc:creator>
    </item>
    <item>
      <title>An implicit DG solver for incompressible two-phase flows with an artificial compressibility formulation</title>
      <link>https://arxiv.org/abs/2307.04580</link>
      <description>arXiv:2307.04580v4 Announce Type: replace 
Abstract: We propose an implicit Discontinuous Galerkin (DG) discretization for incompressible two-phase flows using an artificial compressibility formulation. The conservative level set (CLS) method is employed in combination with a reinitialization procedure to capture the moving interface. A projection method based on the L-stable TR-BDF2 method is adopted for the time discretization of the Navier-Stokes equations and of the level set method. Adaptive Mesh Refinement (AMR) is employed to enhance the resolution in correspondence of the interface between the two fluids. The effectiveness of the proposed approach is shown in a number of classical benchmarks. A specific analysis on the influence of different choices of the mixture viscosity is also carried out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04580v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Orlando</dc:creator>
    </item>
    <item>
      <title>FEM for 1D-problems involving the logarithmic Laplacian: error estimates and numerical implementation</title>
      <link>https://arxiv.org/abs/2311.13079</link>
      <description>arXiv:2311.13079v2 Announce Type: replace 
Abstract: We present the numerical analysis of a finite element method (FEM) for one-dimensional Dirichlet problems involving the logarithmic Laplacian (the pseudo-differential operator that appears as a first-order expansion of the fractional Laplacian as the exponent $s\to 0^+$). Our analysis exhibits new phenomena in this setting; in particular, using recently obtained regularity results, we prove rigorous error estimates and provide a logarithmic order of convergence in the energy norm using suitable $\log$-weighted spaces. Numerical evidence suggests that this type of rate cannot be improved. Moreover, we show that the stiffness matrix of logarithmic problems can be obtained as the derivative of the fractional stiffness matrix evaluated at $s=0$. Lastly, we investigate the relationship between the discrete eigenvalue problem and its convergence to the continuous one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13079v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'ictor Hern\'andez-Santamar\'ia, Sven Jarohs, Alberto Salda\~na, Leonard Sinsch</dc:creator>
    </item>
    <item>
      <title>A spectral collocation method for functional and delay differential equations</title>
      <link>https://arxiv.org/abs/2402.12952</link>
      <description>arXiv:2402.12952v2 Announce Type: replace 
Abstract: A framework for Chebyshev spectral collocation methods for the numerical solution of functional and delay differential equations (FDEs and DDEs) is described. The framework combines interpolation via the barycentric resampling matrix with a multidomain approach used to resolve isolated discontinuities propagated by non-smooth initial data. Geometric convergence is demonstrated for several examples of linear and nonlinear FDEs and DDEs with various delay types, including discrete, proportional, continuous, and state-dependent delay. The framework is a natural extension of standard spectral collocation methods based on polynomial interpolants and can be readily incorporated into existing spectral discretisations, such as in Chebfun/Chebop, allowing the automated and efficient solution of a wide class of nonlinear functional and delay differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12952v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Hale</dc:creator>
    </item>
    <item>
      <title>A robust parameterized enhanced shift-splitting preconditioner for three-by-three block saddle point problems</title>
      <link>https://arxiv.org/abs/2402.17357</link>
      <description>arXiv:2402.17357v3 Announce Type: replace 
Abstract: This paper proposes a new parameterized enhanced shift-splitting (PESS) preconditioner to solve the three-by-three block saddle point problem (SPP). Additionally, we introduce a local PESS (LPESS) preconditioner by relaxing the PESS preconditioner. Necessary and sufficient criteria are established for the convergence of the proposed PESS iterative process for any initial guess. Furthermore, we meticulously investigate the spectral bounds of the PESS and LPESS preconditioned matrices. Moreover, empirical investigations have been performed for the sensitivity analysis of the proposed PESS preconditioner, which unveils its robustness. Numerical experiments are carried out to demonstrate the enhanced efficiency and robustness of the proposed PESS and LPESS preconditioners compared to the existing state-of-the-art preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17357v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sk. Safique Ahmad, Pinki Khatun</dc:creator>
    </item>
    <item>
      <title>Enhancing ASR Performance through OCR Word Frequency Analysis: Theoretical Foundations</title>
      <link>https://arxiv.org/abs/2405.02995</link>
      <description>arXiv:2405.02995v4 Announce Type: replace 
Abstract: As the interest in large language models grows, the importance of accuracy in automatic speech recognition has become more pronounced. This is particularly true for lectures that include specialized terminology, where the success rate of traditional ASR models tends to be low, posing a challenging problem. A method to improve ASR performance for specialized terminology using the word frequency difference approach has been proposed. Through experiments and data analysis, we investigated whether this proposal effectively addressed this issue. In addition, we introduced the power law as the theoretical foundation for the relative frequency methodology mentioned in this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02995v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SD</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyudan Jung, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee</dc:creator>
    </item>
    <item>
      <title>A Sequential Homotopy Method for Mathematical Programming Problems</title>
      <link>https://arxiv.org/abs/1902.06984</link>
      <description>arXiv:1902.06984v4 Announce Type: replace-cross 
Abstract: We propose a sequential homotopy method for the solution of mathematical programming problems formulated in abstract Hilbert spaces under the Guignard constraint qualification. The method is equivalent to performing projected backward Euler timestepping on a projected gradient/antigradient flow of the augmented Lagrangian. The projected backward Euler equations can be interpreted as the necessary optimality conditions of a primal-dual proximal regularization of the original problem. The regularized problems are always feasible, satisfy a strong constraint qualification guaranteeing uniqueness of Lagrange multipliers, yield unique primal solutions provided that the stepsize is sufficiently small, and can be solved by a continuation in the stepsize. We show that equilibria of the projected gradient/antigradient flow and critical points of the optimization problem are identical, provide sufficient conditions for the existence of global flow solutions, and show that critical points with emanating descent curves cannot be asymptotically stable equilibria of the projected gradient/antigradient flow, practically eradicating convergence to saddle points and maxima. The sequential homotopy method can be used to globalize any locally convergent optimization method that can be used in a homotopy framework. We demonstrate its efficiency for a class of highly nonlinear and badly conditioned control constrained elliptic optimal control problems with a semismooth Newton approach for the regularized subproblems. In contrast to the published article, this version contains a correction that the associate editor considers as too insignificant to justify publication in the journal.</description>
      <guid isPermaLink="false">oai:arXiv.org:1902.06984v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-020-01488-z</arxiv:DOI>
      <arxiv:journal_reference>Math. Program. 187, 459-486 (2021)</arxiv:journal_reference>
      <dc:creator>Andreas Potschka, Hans Georg Bock</dc:creator>
    </item>
    <item>
      <title>On the analysis of optimization with fixed-rank matrices: a quotient geometric view</title>
      <link>https://arxiv.org/abs/2203.06765</link>
      <description>arXiv:2203.06765v2 Announce Type: replace-cross 
Abstract: We study a type of Riemannian gradient descent (RGD) algorithm, designed through Riemannian preconditioning, for optimization on $\mathcal{M}_k^{m\times n}$ -- the set of $m\times n$ real matrices with a fixed rank $k$. Our analysis is based on a quotient geometric view of $\mathcal{M}_k^{m\times n}$: by identifying this set with the quotient manifold of a two-term product space $\mathbb{R}_*^{m\times k}\times \mathbb{R}_*^{n\times k}$ of matrices with full column rank via matrix factorization, we find an explicit form for the update rule of the RGD algorithm, which leads to a novel approach to analysing their convergence behavior in rank-constrained optimization. We then deduce some interesting properties that reflect how RGD distinguishes from other matrix factorization algorithms such as those based on the Euclidean geometry. In particular, we show that the RGD algorithm is not only faster than Euclidean gradient descent but also does not rely on balancing techniques to ensure its efficiency while the latter does. We further show that this RGD algorithm is guaranteed to solve matrix sensing and matrix completion problems with linear convergence rate under the restricted positive definiteness property. Numerical experiments on matrix sensing and completion are provided to demonstrate these properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.06765v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyu Dong, Bin Gao, Wen Huang, Kyle A. Gallivan</dc:creator>
    </item>
    <item>
      <title>On $O(n)$ Algorithms for Projection onto the Top-$k$-sum Sublevel Set</title>
      <link>https://arxiv.org/abs/2310.07224</link>
      <description>arXiv:2310.07224v2 Announce Type: replace-cross 
Abstract: The \emph{top-$k$-sum} operator computes the sum of the largest $k$ components of a given vector. The Euclidean projection onto the top-$k$-sum sublevel set serves as a crucial subroutine in iterative methods to solve composite superquantile optimization problems. In this paper, we introduce a solver that implements two finite-termination algorithms to compute this projection. Both algorithms have $O(n)$ complexity of floating point operations when applied to a sorted $n$-dimensional input vector, where the absorbed constant is \emph{independent of $k$}. This stands in contrast to an existing grid-search-inspired method that has $O(k(n-k))$ complexity, a partition-based method with $O(n+D\log D)$ complexity, where $D\leq n$ is the number of distinct elements in the input vector, and a semismooth Newon method with a finite termination property but unspecified floating point complexity. The improvement of our methods over the first method is significant when $k$ is linearly dependent on $n$, which is frequently encountered in practical superquantile optimization applications. In instances where the input vector is unsorted, an additional cost is incurred to (partially) sort the vector, whereas a full sort of the input vector seems unavoidable for the other two methods. To reduce this cost, we further derive a rigorous procedure that leverages approximate sorting to compute the projection, which is particularly useful when solving a sequence of similar projection problems. Numerical results show that our methods solve problems of scale $n=10^7$ and $k=10^4$ within $0.05$ seconds, whereas the most competitive alternative, the semismooth Newton-based method, takes about $1$ second. The existing grid-search method and Gurobi's QP solver can take from minutes to hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07224v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake Roth, Ying Cui</dc:creator>
    </item>
    <item>
      <title>Robust and accurate simulations of flows over orography using non-conforming meshes</title>
      <link>https://arxiv.org/abs/2402.07759</link>
      <description>arXiv:2402.07759v4 Announce Type: replace-cross 
Abstract: We systematically validate the static local mesh refinement capabilities of a recently proposed IMEX-DG scheme implemented in the framework of the deal.II library. Non-conforming meshes are employed in atmospheric flow simulations to increase the resolution around complex orography. A number of numerical experiments based on classical benchmarks with idealized as well as real orography profiles demonstrate that simulations with the refined mesh are stable for long lead times and no spurious effects arise at the interfaces of mesh regions with different resolutions. Moreover, correct values of the momentum flux are retrieved and the correct large-scale orographic response is established. Hence, large-scale orography-driven flow features can be simulated without loss of accuracy using a much lower total amount of degrees of freedom. In a context of spatial resolutions approaching the hectometric scale in numerical weather prediction models, these results support the use of locally refined, non-conforming meshes as a reliable and effective tool to greatly reduce the dependence of atmospheric models on orographic wave drag parametrizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07759v4</guid>
      <category>physics.ao-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Orlando, Tommaso Benacchio, Luca Bonaventura</dc:creator>
    </item>
    <item>
      <title>A boundary integral based particle initialization algorithm for Smooth Particle Hydrodynamics</title>
      <link>https://arxiv.org/abs/2403.07779</link>
      <description>arXiv:2403.07779v2 Announce Type: replace-cross 
Abstract: Algorithms for initializing particle distribution in SPH simulations are essential for enhancing simulation accuracy. However, no such algorithms exist for boundary integral SPH models, which can model complex geometries without requiring layers of virtual particles. This study introduces the Boundary Integral based Particle Initialization (BIPI) algorithm. It employs a particle shifting technique meticulously designed to redistribute particles to fit the geometry boundary. The BIPI algorithm directly utilizes the geometry's boundary information using the SPH boundary integral formulation. Special consideration is given to particles adjacent to the boundary to prevent artificial volume compression. Consequently, it can automatically generate a "uniform" particle distribution with reduced and stabilized concentration gradients for domains with complex geometrical shapes. Finally, several examples are presented to demonstrate the effectiveness of the proposed algorithm, including the application of the BIPI algorithm in flow problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07779v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parikshit Boregowda, G R Liu</dc:creator>
    </item>
    <item>
      <title>Layer-Specific Optimization: Sensitivity Based Convolution Layers Basis Search</title>
      <link>https://arxiv.org/abs/2408.06024</link>
      <description>arXiv:2408.06024v2 Announce Type: replace-cross 
Abstract: Deep neural network models have a complex architecture and are overparameterized. The number of parameters is more than the whole dataset, which is highly resource-consuming. This complicates their application and limits its usage on different devices. Reduction in the number of network parameters helps to reduce the size of the model, but at the same time, thoughtlessly applied, can lead to a deterioration in the quality of the network. One way to reduce the number of model parameters is matrix decomposition, where a matrix is represented as a product of smaller matrices. In this paper, we propose a new way of applying the matrix decomposition with respect to the weights of convolutional layers. The essence of the method is to train not all convolutions, but only the subset of convolutions (basis convolutions), and represent the rest as linear combinations of the basis ones. Experiments on models from the ResNet family and the CIFAR-10 dataset demonstrate that basis convolutions can not only reduce the size of the model but also accelerate the forward and backward passes of the network. Another contribution of this work is that we propose a fast method for selecting a subset of network layers in which the use of matrix decomposition does not degrade the quality of the final model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06024v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vasiliy Alekseev, Ilya Lukashevich, Ilia Zharikov, Ilya Vasiliev</dc:creator>
    </item>
  </channel>
</rss>
