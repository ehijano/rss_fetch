<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 01:31:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Approximate Sparsity Class and Minimax Estimation</title>
      <link>https://arxiv.org/abs/2508.09278</link>
      <description>arXiv:2508.09278v1 Announce Type: new 
Abstract: Motivated by the orthogonal series density estimation in $L^2([0,1],\mu)$, in this project we consider a new class of functions that we call the approximate sparsity class. This new class is characterized by the rate of decay of the individual Fourier coefficients for a given orthonormal basis. We establish the $L^2([0,1],\mu)$ metric entropy of such class, with which we show the minimax rate of convergence. For the density subset in this class, we propose an adaptive density estimator based on a hard-thresholding procedure that achieves this minimax rate up to a $\log$ term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09278v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Z. Zhang</dc:creator>
    </item>
    <item>
      <title>Machine Learning for Detecting Collusion and Capacity Withholding in Wholesale Electricity Markets</title>
      <link>https://arxiv.org/abs/2508.09885</link>
      <description>arXiv:2508.09885v1 Announce Type: new 
Abstract: Collusion and capacity withholding in electricity wholesale markets are important mechanisms of market manipulation. This study applies a refined machine learning-based cartel detection algorithm to two cartel cases in the Italian electricity market and evaluates its out-of-sample performance. Specifically, we consider an ensemble machine learning method that uses statistical screens constructed from the offer price distribution as predictors for the incidence of collusion among electricity providers in specific regions. We propose novel screens related to the capacity-withholding behavior of electricity providers and find that including such screens derived from the day-ahead spot market as predictors can improve cartel detection. We find that, under complete cartels - where collusion in a tender presumably involves all suppliers - the method correctly classifies up to roughly 95% of tenders in our data as collusive or competitive, improving classification accuracy compared to using only previously available screens. However, when trained on larger datasets including non-cartel members and applying algorithms tailored to detect incomplete cartels, the previously existing screens are sufficient to achieve 98% accuracy, and the addition of our newly proposed capacity-withholding screens does not further improve performance. Overall, this study highlights the promising potential of supervised machine learning techniques for detecting and dismantling cartels in electricity markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09885v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Proz, Martin Huber</dc:creator>
    </item>
    <item>
      <title>Inference in Cluster Randomized Trials with Matched Pairs</title>
      <link>https://arxiv.org/abs/2211.14903</link>
      <description>arXiv:2211.14903v5 Announce Type: replace 
Abstract: This paper studies inference in cluster randomized trials where treatment status is determined according to a "matched pairs" design. Here, by a cluster randomized experiment, we mean one in which treatment is assigned at the level of the cluster; by a "matched pairs" design, we mean that a sample of clusters is paired according to baseline, cluster-level covariates and, within each pair, one cluster is selected at random for treatment. We study the large-sample behavior of a weighted difference-in-means estimator and derive two distinct sets of results depending on if the matching procedure does or does not match on cluster size. We then propose a single variance estimator which is consistent in either regime. Combining these results establishes the asymptotic exactness of tests based on these estimators. Next, we consider the properties of two common testing procedures based on t-tests constructed from linear regressions, and argue that both are generally conservative in our framework. We additionally study the behavior of a randomization test which permutes the treatment status for clusters within pairs, and establish its finite-sample and asymptotic validity for testing specific null hypotheses. Finally, we propose a covariate-adjusted estimator which adjusts for additional baseline covariates not used for treatment assignment, and establish conditions under which such an estimator leads to strict improvements in precision. A simulation study confirms the practical relevance of our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.14903v5</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuehao Bai, Jizhou Liu, Azeem M. Shaikh, Max Tabord-Meehan</dc:creator>
    </item>
    <item>
      <title>Optimal Policy Choices Under Uncertainty</title>
      <link>https://arxiv.org/abs/2503.03910</link>
      <description>arXiv:2503.03910v3 Announce Type: replace 
Abstract: Policymakers often make changes to policies whose benefits and costs are unknown and must be inferred from statistical estimates in empirical studies. In this paper I consider the problem of a planner who changes upfront spending on a set of policies to maximize social welfare but faces statistical uncertainty about the impact of those changes. I set up a local optimization problem that is tractable under statistical uncertainty and solve for the local change in spending that maximizes the posterior expected rate of increase in welfare. I propose an empirical Bayes approach to approximating the optimal local spending rule, which solves the planner's local problem with posterior mean estimates of benefits and net costs. I show theoretically that the empirical Bayes approach performs well by deriving rates of convergence for the rate of increase in welfare. These rates converge for a large class of decision problems, including those where rates from a sample plug-in approach do not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03910v3</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Moon</dc:creator>
    </item>
  </channel>
</rss>
