<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 06 May 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dimensionality reduction of neuronal degeneracy reveals two interfering physiological mechanisms</title>
      <link>https://arxiv.org/abs/2405.02038</link>
      <description>arXiv:2405.02038v1 Announce Type: new 
Abstract: Neuronal systems maintain stable functions despite large variability in their physiological components. Ion channel expression, in particular, is highly variable in neurons exhibiting similar electrophysiological phenotypes, which poses questions regarding how specific ion channel subsets reliably shape neuron intrinsic properties. Here, we use detailed conductance-based modeling to explore the origin of stable neuronal function from variable channel composition. Using dimensionality reduction, we uncover two principal dimensions in the channel conductance space that capture most of the variance of the observed variability. Those two dimensions correspond to two physiologically relevant sources of variability that can be explained by feedback mechanisms underlying regulation of neuronal activity, providing quantitative insights into how channel composition links to neuronal electrophysiological activity. These insights allowed us to understand and design a model-independent, reliable neuromodulation rule for variable neuronal populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02038v1</guid>
      <category>q-bio.NC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>q-bio.CB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Fyon, Alessio Franci, Pierre Sacr\'e, Guillaume Drion</dc:creator>
    </item>
    <item>
      <title>Early-stage detection of cognitive impairment by hybrid quantum-classical algorithm using resting-state functional MRI time-series</title>
      <link>https://arxiv.org/abs/2405.01554</link>
      <description>arXiv:2405.01554v1 Announce Type: cross 
Abstract: Following the recent development of quantum machine learning techniques, the literature has reported several quantum machine learning algorithms for disease detection. This study explores the application of a hybrid quantum-classical algorithm for classifying region-of-interest time-series data obtained from resting-state functional magnetic resonance imaging in patients with early-stage cognitive impairment based on the importance of cognitive decline for dementia or aging. Classical one-dimensional convolutional layers are used together with quantum convolutional neural networks in our hybrid algorithm. In the classical simulation, the proposed hybrid algorithms showed higher balanced accuracies than classical convolutional neural networks under the similar training conditions. Moreover, a total of nine brain regions (left precentral gyrus, right superior temporal gyrus, left rolandic operculum, right rolandic operculum, left parahippocampus, right hippocampus, left medial frontal gyrus, right cerebellum crus, and cerebellar vermis) among 116 brain regions were found to be relatively effective brain regions for the classification based on the model performances. The associations of the selected nine regions with cognitive decline, as found in previous studies, were additionally validated through seed-based functional connectivity analysis. We confirmed both the improvement of model performance with the quantum convolutional neural network and neuroscientific validities of brain regions from our hybrid quantum-classical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01554v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junggu Choi, Tak Hur, Daniel K. Park, Na-Young Shin, Seung-Koo Lee, Hakbae Lee, Sanghoon Han</dc:creator>
    </item>
    <item>
      <title>Alternating Shrinking Higher-order Interactions for Sparse Neural Population Activity</title>
      <link>https://arxiv.org/abs/2308.13257</link>
      <description>arXiv:2308.13257v2 Announce Type: replace 
Abstract: Neurons in living things work cooperatively and efficiently to process incoming sensory information, often exhibiting sparse and widespread population activity involving structured higher-order interactions. While there are statistical models based on continuous probability distributions for neurons' sparse firing rates, how the spiking activities of a large number of interacting neurons result in the sparse and widespread population activity remains unknown. Here, for homogeneous (0,1) binary neurons, we provide sufficient conditions under which their spike-count population distribution converges to a sparse widespread distribution of the population spike rate in an infinitely large population of neurons. Following the conditions, we propose new models belonging to an exponential family distribution in which the sign and magnitude of neurons' higher-order interactions alternate and shrink as the order increases. The distributions exhibit parameter-dependent sparsity on a bounded support for the population firing rate. The theory serves as a building block for developing prior distributions and neurons' non-linearity for spike-based sparse coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13257v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulises Rodr\'iguez-Dom\'inguez, Hideaki Shimazaki</dc:creator>
    </item>
    <item>
      <title>Do the receptive fields in the primary visual cortex span a variability over the degree of elongation of the receptive fields?</title>
      <link>https://arxiv.org/abs/2404.04858</link>
      <description>arXiv:2404.04858v4 Announce Type: replace 
Abstract: This paper presents results of combining (i) theoretical analysis regarding connections between the orientation selectivity and the elongation of receptive fields for the affine Gaussian derivative model with (ii) biological measurements of orientation selectivity in the primary visual cortex, to investigate if (iii) the receptive fields can be regarded as spanning a variability in the degree of elongation.
  From an in-depth theoretical analysis of idealized models for the receptive fields of simple and complex cells in the primary visual cortex, we have established that the directional selectivity becomes more narrow with increasing elongation of the receptive fields. By comparison with previously established biological results, concerning broad vs. sharp orientation tuning of visual neurons in the primary visual cortex, we demonstrate that those underlying theoretical predictions, in combination with these biological results, are consistent with a previously formulated biological hypothesis, stating that the biological receptive field shapes should span the degrees of freedom in affine image transformations, to support affine covariance over the population of receptive fields in the primary visual cortex.
  Based on this possible indirect support for the working hypothesis concerning affine covariance, we formulate a set of testable predictions that could be used to, with neurophysiological experiments, judge if the receptive fields in the primary visual cortex of higher mammals could be regarded as spanning a variability over the eccentricity or the elongation of the receptive fields, and, if so, then also characterize if such a variability would, in a structured way, be related to the pinwheel structure in the visual cortex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04858v4</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Demixing fluorescence time traces transmitted by multimode fibers</title>
      <link>https://arxiv.org/abs/2306.00695</link>
      <description>arXiv:2306.00695v3 Announce Type: replace-cross 
Abstract: Fiber photometry is a significantly less invasive method compared to other deep brain imaging microendoscopy approaches due to the use of thin multimode fibers (MMF diameter $&lt;$ 500 $\mu$m). Nevertheless, the transmitted signals get scrambled upon propagation within the MMF, thus limiting the technique's potential in resolving temporal readouts with cellular resolution. Here, we demonstrate how to separate the time trace signals of several fluorescent sources probed by a thin ($\approx$ 200 $\mu$m) MMF with typical implantable length in a mouse brain. We disentangled several spatio-temporal fluorescence signals by using a general unconstrained non-negative matrix factorization (NMF) algorithm directly on the raw video data. Furthermore, we show that commercial and low-cost open-source miniscopes display enough sensitivity to image the same fluorescence patterns seen in our proof of principle experiment, suggesting that a new avenue for novel minimally invasive deep brain studies with multimode fibers in freely-behaving mice could be possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.00695v3</guid>
      <category>physics.optics</category>
      <category>physics.app-ph</category>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caio Vaz Rimoli, Claudio Moretti, Fernando Soldevila, Enora Br\'emont, Cathie Ventalon, Sylvain Gigan</dc:creator>
    </item>
    <item>
      <title>Early Autism Diagnosis based on Path Signature and Siamese Unsupervised Feature Compressor</title>
      <link>https://arxiv.org/abs/2307.06472</link>
      <description>arXiv:2307.06472v3 Announce Type: replace-cross 
Abstract: Autism Spectrum Disorder (ASD) has been emerging as a growing public health threat. Early diagnosis of ASD is crucial for timely, effective intervention and treatment. However, conventional diagnosis methods based on communications and behavioral patterns are unreliable for children younger than 2 years of age. Given evidences of neurodevelopmental abnormalities in ASD infants, we resort to a novel deep learning-based method to extract key features from the inherently scarce, class-imbalanced, and heterogeneous structural MR images for early autism diagnosis. Specifically, we propose a Siamese verification framework to extend the scarce data, and an unsupervised compressor to alleviate data imbalance by extracting key features. We also proposed weight constraints to cope with sample heterogeneity by giving different samples different voting weights during validation, and we used Path Signature to unravel meaningful developmental features from the two-time point data longitudinally. We further extracted machine learning focused brain regions for autism diagnosis. Extensive experiments have shown that our method performed well under practical scenarios, transcending existing machine learning methods and providing anatomical insights for autism early diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06472v3</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/cercor/bhae069</arxiv:DOI>
      <dc:creator>Zhuowen Yin, Xinyao Ding, Xin Zhang, Zhengwang Wu, Li Wang, Xiangmin Xu, Gang Li</dc:creator>
    </item>
    <item>
      <title>BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity</title>
      <link>https://arxiv.org/abs/2310.04420</link>
      <description>arXiv:2310.04420v3 Announce Type: replace-cross 
Abstract: Understanding the functional organization of higher visual cortex is a central focus in neuroscience. Past studies have primarily mapped the visual and semantic selectivity of neural populations using hand-selected stimuli, which may potentially bias results towards pre-existing hypotheses of visual cortex functionality. Moving beyond conventional approaches, we introduce a data-driven method that generates natural language descriptions for images predicted to maximally activate individual voxels of interest. Our method -- Semantic Captioning Using Brain Alignments ("BrainSCUBA") -- builds upon the rich embedding space learned by a contrastive vision-language model and utilizes a pre-trained large language model to generate interpretable captions. We validate our method through fine-grained voxel-level captioning across higher-order visual regions. We further perform text-conditioned image synthesis with the captions, and show that our images are semantically coherent and yield high predicted activations. Finally, to demonstrate how our method enables scientific discovery, we perform exploratory investigations on the distribution of "person" representations in the brain, and discover fine-grained semantic selectivity in body-selective areas. Unlike earlier studies that decode text, our method derives voxel-wise captions of semantic selectivity. Our results show that BrainSCUBA is a promising means for understanding functional preferences in the brain, and provides motivation for further hypothesis-driven investigation of visual cortex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04420v3</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew F. Luo, Margaret M. Henderson, Michael J. Tarr, Leila Wehbe</dc:creator>
    </item>
    <item>
      <title>Simplicity in Complexity : Explaining Visual Complexity using Deep Segmentation Models</title>
      <link>https://arxiv.org/abs/2403.03134</link>
      <description>arXiv:2403.03134v2 Announce Type: replace-cross 
Abstract: The complexity of visual stimuli plays an important role in many cognitive phenomena, including attention, engagement, memorability, time perception and aesthetic evaluation. Despite its importance, complexity is poorly understood and ironically, previous models of image complexity have been quite complex. There have been many attempts to find handcrafted features that explain complexity, but these features are usually dataset specific, and hence fail to generalise. On the other hand, more recent work has employed deep neural networks to predict complexity, but these models remain difficult to interpret, and do not guide a theoretical understanding of the problem. Here we propose to model complexity using segment-based representations of images. We use state-of-the-art segmentation models, SAM and FC-CLIP, to quantify the number of segments at multiple granularities, and the number of classes in an image respectively. We find that complexity is well-explained by a simple linear model with these two features across six diverse image-sets of naturalistic scene and art images. This suggests that the complexity of images can be surprisingly simple.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03134v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingke Shen, Surabhi S Nath, Aenne Brielmann, Peter Dayan</dc:creator>
    </item>
  </channel>
</rss>
