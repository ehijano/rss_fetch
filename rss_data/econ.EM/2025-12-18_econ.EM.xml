<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Dec 2025 02:42:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Environmental Policy and Firm Performance in Europe: A Difference-in-Differences Approach with Spillovers</title>
      <link>https://arxiv.org/abs/2512.15377</link>
      <description>arXiv:2512.15377v1 Announce Type: new 
Abstract: In this paper we investigate the causal impact of the European Union Emissions Trading System, a cap-and-trade scheme limiting greenhouse gas emissions of firms, on their environmental performance. Although previous studies have focused primarily on the effect of the emission cap imposed by the policy, we argue that the trading mechanism creates complex interdependencies among firms that can change the policy's intended effects. We develop a novel Difference-in-Differences approach that disentangles the direct causal effects of the scheme on regulated firms from the indirect spillover effects arising from trading among firms. By incorporating potential interference between treated units, our methodology allows a more comprehensive assessment of the policy's overall effectiveness. Monte Carlo simulations show that our proposed estimators perform well in finite samples, confirming the reliability of our approach. To assess the direct and indirect effects of the scheme, we construct a novel database on emissions of European industrial sites by matching information on treated plants from the European Commission's Community Independent Transaction Log with emission data from the European Pollutant Release and Transfer Register for the years from 2001 to 2017. We find that the scheme reduced emissions only for non-trading plants, but such reduction is entirely offset when accounting for spillovers from trading plants, thus suggesting that the trading mechanism neutralizes the environmental benefits of the policy. Our findings have important implications for the design of future environmental policies and the ongoing evaluation of cap and trade policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15377v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Ciaccio, Francesco Moscone, Elisa Tosetti</dc:creator>
    </item>
    <item>
      <title>Scaling Causal Mediation for Complex Systems: A Framework for Root Cause Analysis</title>
      <link>https://arxiv.org/abs/2512.14764</link>
      <description>arXiv:2512.14764v1 Announce Type: cross 
Abstract: Modern operational systems ranging from logistics and cloud infrastructure to industrial IoT, are governed by complex, interdependent processes. Understanding how interventions propagate through such systems requires causal inference methods that go beyond direct effects to quantify mediated pathways. Traditional mediation analysis, while effective in simple settings, fails to scale to the high-dimensional directed acyclic graphs (DAGs) encountered in practice, particularly when multiple treatments and mediators interact. In this paper, we propose a scalable mediation analysis framework tailored for large causal DAGs involving multiple treatments and mediators. Our approach systematically decomposes total effects into interpretable direct and indirect components. We demonstrate its practical utility through applied case studies in fulfillment center logistics, where complex dependencies and non-controllable factors often obscure root causes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14764v1</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Casadei, Sreyoshi Bhaduri, Rohit Malshe, Pavan Mullapudi, Raj Ratan, Ankush Pole, Arkajit Rakshit</dc:creator>
    </item>
    <item>
      <title>Non-parametric Causal Inference in Dynamic Thresholding Designs</title>
      <link>https://arxiv.org/abs/2512.15244</link>
      <description>arXiv:2512.15244v1 Announce Type: cross 
Abstract: Consider a setting where we regularly monitor patients' fasting blood sugar, and declare them to have prediabetes (and encourage preventative care) if this number crosses a pre-specified threshold. The sharp, threshold-based treatment policy suggests that we should be able to estimate the long-term benefit of this preventative care by comparing the health trajectories of patients with blood sugar measurements right above and below the threshold. A naive regression-discontinuity analysis, however, is not applicable here, as it ignores the temporal dynamics of the problem where, e.g., a patient just below the threshold on one visit may become prediabetic (and receive treatment) following their next visit. Here, we study thresholding designs in general dynamic systems, and show that simple reduced-form characterizations remain available for a relevant causal target, namely a dynamic marginal policy effect at the treatment threshold. We develop a local-linear-regression approach for estimation and inference of this estimand, and demonstrate promise of our approach in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15244v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Ghosh, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>Inference for Forecasting Accuracy: Pooled versus Individual Estimators in High-dimensional Panel Data</title>
      <link>https://arxiv.org/abs/2512.15592</link>
      <description>arXiv:2512.15592v1 Announce Type: cross 
Abstract: Panels with large time $(T)$ and cross-sectional $(N)$ dimensions are a key data structure in social sciences and other fields. A central question in panel data analysis is whether to pool data across individuals or to estimate separate models. Pooled estimators typically have lower variance but may suffer from bias, creating a fundamental trade-off for optimal estimation. We develop a new inference method to compare the forecasting performance of pooled and individual estimators. Specifically, we propose a confidence interval for the difference between their forecasting errors and establish its asymptotic validity. Our theory allows for complex temporal and cross-sectional dependence in the model errors and covers scenarios where $N$ can be much larger than $T$-including the independent case under the classical condition $N/T^2 \to 0$. The finite-sample properties of the proposed method are examined in an extensive simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15592v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim Kutta, Martin Schumann, Holger Dette</dc:creator>
    </item>
    <item>
      <title>Empirical Welfare Maximization with Constraints</title>
      <link>https://arxiv.org/abs/2103.15298</link>
      <description>arXiv:2103.15298v3 Announce Type: replace 
Abstract: Empirical Welfare Maximization (EWM) is a framework that can be used to select welfare program eligibility policies based on data. This paper extends EWM by allowing for uncertainty in estimating the budget needed to implement the selected policy, in addition to its welfare. Due to the additional estimation error, I show there exist no rules that achieve the highest welfare possible while satisfying a budget constraint uniformly over a wide range of DGPs. This differs from the setting without a budget constraint where uniformity is achievable. I propose an alternative trade-off rule and illustrate it with Medicaid expansion, a setting with imperfect take-up and varying program costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.15298v3</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liyang Sun</dc:creator>
    </item>
    <item>
      <title>Testing for equivalence of pre-trends in Difference-in-Differences estimation</title>
      <link>https://arxiv.org/abs/2310.15796</link>
      <description>arXiv:2310.15796v2 Announce Type: replace 
Abstract: The plausibility of the ``parallel trends assumption'' in Difference-in-Differences estimation is usually assessed by a test of the null hypothesis that the difference between the average outcomes of both groups is constant over time before the treatment. However, failure to reject the null hypothesis does not imply the absence of differences in time trends between both groups. We provide equivalence tests that allow researchers to find evidence in favor of the parallel trends assumption and thus increase the credibility of their treatment effect estimates. While we motivate our tests in the standard two-way fixed effects model, we discuss simple extensions to settings in which treatment adoption is staggered over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15796v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/07350015.2024.2308121</arxiv:DOI>
      <arxiv:journal_reference>Journal of Business &amp; Economic Statistics, 42(4), 1289-1301 (2024)</arxiv:journal_reference>
      <dc:creator>Holger Dette (Ruhr University Bochum), Martin Schumann (Maastricht University)</dc:creator>
    </item>
    <item>
      <title>Correcting Nonresponse Bias Using Panel Data on Data Requests and Responses</title>
      <link>https://arxiv.org/abs/2404.17693</link>
      <description>arXiv:2404.17693v3 Announce Type: replace 
Abstract: When subjects who respond to requests for data, such as in surveys or post-treatment follow-up, are not representative of the population as a whole, inferences drawn from the data can be misleading. We show that if subjects' accumulated requests and responses over time are recorded and organized as panel data, requests can be used as instruments to correct for nonresponse bias even if total requests are not randomized between subjects. We demonstrate our method by estimating an 18-percentage-point gender gap in entrepreneurial career intentions using a survey of undergraduates at the University of Wisconsin-Madison with a 15% response rate and a 20-percentage-point intention gap among respondents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17693v3</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clint Harris, Jonathan T. Eckhardt, Brent Goldfarb</dc:creator>
    </item>
    <item>
      <title>Spatial-Network Treatment Effects: A Continuous Functional Approach</title>
      <link>https://arxiv.org/abs/2512.12653</link>
      <description>arXiv:2512.12653v3 Announce Type: replace 
Abstract: This paper develops a continuous functional framework for treatment effects that propagate through geographic space and economic networks. We derive a master equation governing propagation from three economic foundations -- heterogeneous agent aggregation, market equilibrium, and cost minimization -- establishing that the framework rests on fundamental principles rather than ad hoc specifications. A key result shows that the spatial-network interaction coefficient equals the mutual information between geographic and market coordinates. The Feynman-Kac representation decomposes effects into inherited and accumulated components along stochastic paths representing economic linkages. The framework nests the no-spillover case as a testable restriction. Monte Carlo simulations demonstrate that conventional estimators -- two-way fixed effects, difference-in-differences, and generalized propensity score -- exhibit 25-38% bias and severe undercoverage when spillovers exist, while our estimator maintains correct inference regardless of whether spillovers are present. Applying the framework to U.S. minimum wage policy, we reject the no-spillover null and find total effects at state borders four times larger than direct effects -- conventional methods capture only one-quarter of policy impact. Structural estimates reveal spatial diffusion consistent with commuting-distance labor mobility, network diffusion consistent with quarterly supply chain adjustment, and significant spatial-network interaction reflecting geographic clustering of industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12653v3</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.ME</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Modified Delayed Acceptance MCMC for Quasi-Bayesian Inference with Linear Moment Conditions</title>
      <link>https://arxiv.org/abs/2511.17117</link>
      <description>arXiv:2511.17117v2 Announce Type: replace-cross 
Abstract: We develop a computationally efficient framework for quasi-Bayesian inference based on linear moment conditions. The approach employs a delayed acceptance Markov chain Monte Carlo (DA-MCMC) algorithm that uses a surrogate target kernel and a proposal distribution derived from an approximate conditional posterior, thereby exploiting the structure of the quasi-likelihood. Two implementations are introduced. DA-MCMC-Exact fully incorporates prior information into the proposal distribution and maximizes per-iteration efficiency, whereas DA-MCMC-Approx omits the prior in the proposal to reduce matrix inversions, improving numerical stability and computational speed in higher dimensions. Simulation studies on heteroskedastic linear regressions show substantial gains over standard MCMC and conventional DA-MCMC baselines, measured by multivariate effective sample size per iteration and per second. The Approx variant yields the best overall throughput, while the Exact variant attains the highest per-iteration efficiency. Applications to two empirical instrumental variable regressions corroborate these findings: the Approx implementation scales to larger designs where other methods become impractical, while still delivering precise inference. Although developed for moment-based quasi-posteriors, the proposed approach also extends to risk-based quasi-Bayesian formulations when first-order conditions are linear and can be transformed analogously. Overall, the proposed algorithms provide a practical and robust tool for quasi-Bayesian analysis in statistical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17117v2</guid>
      <category>stat.CO</category>
      <category>econ.EM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahiro Tanaka</dc:creator>
    </item>
  </channel>
</rss>
