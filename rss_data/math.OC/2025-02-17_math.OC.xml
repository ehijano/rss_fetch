<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 17 Feb 2025 05:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Contracting Strategies for Electrolyzers to Secure Grid Connection: The Dutch Case</title>
      <link>https://arxiv.org/abs/2502.09748</link>
      <description>arXiv:2502.09748v1 Announce Type: new 
Abstract: In response to increasing grid congestion in the Netherlands, non-firm connection and transport agreements (CTAs) and capacity restriction contracts (CRCs) have been introduced, allowing consumer curtailment in exchange for grid tariff discounts or per-MW compensations. This study examines the interaction between an electrolyzer project, facing sizing and contracting decisions, and a network operator, responsible for contract activations and determining grid connection capacity, under the new Dutch regulations. The interaction is modeled using two bilevel optimization problems with alternating leader-follower roles. Results highlight a trade-off between CRC income and non-firm CTA tariff discounts, showing that voluntary congestion management by the network operator increases electrolyzer profitability at CRC prices below 10 euro per MW but reduces it at higher prices. Furthermore, the network operator benefits more from reacting to the electrolyzer owner's CTA decisions than from leading the interaction at CRC prices above 10 euro per MW. Ignoring the other party's optimization problem overestimates profits for both the network operator and the electrolyzer owner, emphasizing the importance of coordinated decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09748v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Swarts, Jalal Kazempour, Wouter van den Akker, Johan Morren, Arjan van Voorden, Han Slootweg</dc:creator>
    </item>
    <item>
      <title>Fast Inexact Bilevel Optimization for Analytical Deep Image Priors</title>
      <link>https://arxiv.org/abs/2502.09758</link>
      <description>arXiv:2502.09758v1 Announce Type: new 
Abstract: The analytical deep image prior (ADP) introduced by Dittmer et al. (2020) establishes a link between deep image priors and classical regularization theory via bilevel optimization. While this is an elegant construction, it involves expensive computations if the lower-level problem is to be solved accurately. To overcome this issue, we propose to use adaptive inexact bilevel optimization to solve ADP problems. We discuss an extension of a recent inexact bilevel method called the method of adaptive inexact descent of Salehi et al.(2024) to an infinite-dimensional setting required by the ADP framework. In our numerical experiments we demonstrate that the computational speed-up achieved by adaptive inexact bilevel optimization allows one to use ADP on larger-scale problems than in the previous literature, e.g. in deblurring of 2D color images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09758v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>math.NA</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Salehi, Tatiana A. Bubba, Yury Korolev</dc:creator>
    </item>
    <item>
      <title>Stabilization of a Chain of Three Hyperbolic PDEs using a Time-Delay Representation</title>
      <link>https://arxiv.org/abs/2502.10002</link>
      <description>arXiv:2502.10002v1 Announce Type: new 
Abstract: This paper addresses the stabilization of a chain system consisting of three hyperbolic Partial Differential Equations (PDEs). The system is reformulated into a pure transport system of equations via an invertible backstepping transformation. Using the method of characteristics and exploiting the inherent cascade structure of the chain, the stabilization problem is reduced to that of an associated Integral Difference Equation (IDE). A dynamic controller is designed for the IDE, whose gains are computed by solving a system of Fredholm-type integral equations. This approach provides a systematic framework for achieving exponential stabilization of the chain of hyperbolic PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10002v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Braun (L2S), Jean Auriol (L2S), Lucas Brivadis (L2S)</dc:creator>
    </item>
    <item>
      <title>An adaptive importance sampling algorithm for risk-averse optimization</title>
      <link>https://arxiv.org/abs/2502.10084</link>
      <description>arXiv:2502.10084v1 Announce Type: new 
Abstract: Adaptive sampling algorithms are modern and efficient methods that dynamically adjust the sample size throughout the optimization process. However, they may encounter difficulties in risk-averse settings, particularly due to the challenge of accurately sampling from the tails of the underlying distribution of random inputs. This often leads to a much faster growth of the sample size compared to risk-neutral problems. In this work, we propose a novel adaptive sampling algorithm that adapts both the sample size and the sampling distribution at each iteration. The biasing distributions are constructed on the fly, leveraging a reduced-order model of the objective function to be minimized, and are designed to oversample a so-called risk region. As a result, a reduction of the variance of the gradients is achieved, which permits to use fewer samples per iteration compared to a standard algorithm, while still preserving the asymptotic convergence rate. Our focus is on the minimization of the Conditional Value-at-Risk (CVaR), and we establish the convergence of the proposed computational framework. Numerical experiments confirm the substantial computational savings achieved by our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10084v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandra Pieraccini, Tommaso Vanzan</dc:creator>
    </item>
    <item>
      <title>Evaluation of the Efficiency and Comparison of Different Numerical Differentiation Methods on Three Case Studies</title>
      <link>https://arxiv.org/abs/2502.10285</link>
      <description>arXiv:2502.10285v1 Announce Type: new 
Abstract: Without question regarding its pivotal significance, the computation of function derivatives carries substantial weight within a multitude of engineering and applied mathematical fields. These encompass optimization, the development of nonlinear control systems, and the assessment of noisy time signals, among others. In this study, we have chosen three illustrative cases: the logistic model for population dynamics, temperature variation within buildings, and the determination of market equilibrium prices. The primary objective is to assess the effectiveness of various numerical differentiation techniques and conduct a comparative analysis of the outcomes for each of these case studies. To achieve this objective, we employed three distinct numerical differentiation techniques: The Forward, Backward, and Centered FiniteDifference methods, each executed in two different levels of precision, totaling six variations. Our findings clearly indicate that, for the initial case study, the methods characterized by lower computational costs (specifically, the Forward and Backward Finite-Difference methods) yield superior outcomes. In contrast, for the second case study, the Centered Finite-Difference method delivers better results. In the case of the third case study, our results reveal that none of the methods produce estimations that meet acceptable standards. It is noteworthy that the empirical equations for each case study have been validated against previous literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10285v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <category>math.DG</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamidreza Moradi, Erfan Kefayat, Hamideh Hossei</dc:creator>
    </item>
    <item>
      <title>A Graph-Based Iterative Strategy for Solving the All-Line Transmission Switching Problem</title>
      <link>https://arxiv.org/abs/2502.10333</link>
      <description>arXiv:2502.10333v1 Announce Type: new 
Abstract: The transmission switching problem aims to determine the optimal network topology that minimizes the operating costs of a power system. This problem is typically formulated as a mixed-integer optimization model, which involves big-M constants that lead to weak relaxations and significant computational challenges, particularly when all lines are switchable. In this paper, we propose a two-fold approach: first, using graph theory to derive tighter big-M values by solving a relaxed longest path problem; second, introducing an iterative algorithm that incorporates a heuristic version of the switching problem to efficiently generate low-cost feasible solutions, thereby accelerating the search for optimal solutions in the integer optimization solver. Numerical results on the 118-bus network show that the proposed methodology significantly reduces the computational burden compared to conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10333v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marina Aguilar-Moreno, Salvador Pineda, Juan Miguel Morales</dc:creator>
    </item>
    <item>
      <title>Euclidean distance degree in manifold optimization</title>
      <link>https://arxiv.org/abs/2502.10336</link>
      <description>arXiv:2502.10336v1 Announce Type: new 
Abstract: We determine the Euclidean distance degrees of the three most common manifolds arising in manifold optimization: flag, Grassmann, and Stiefel manifolds. For the Grassmannian, we will also determine the Euclidean distance degree of an important class of Schubert varieties that often appear in applications. Our technique goes further than furnishing the value of the Euclidean distance degree; it will also yield closed-form expressions for all stationary points of the Euclidean distance function in each instance. We will discuss the implications of these results on the tractability of manifold optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10336v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <category>math.DG</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Lai, Lek-Heng Lim, Ke Ye</dc:creator>
    </item>
    <item>
      <title>Iterative quantum optimisation with a warm-started quantum state</title>
      <link>https://arxiv.org/abs/2502.09704</link>
      <description>arXiv:2502.09704v1 Announce Type: cross 
Abstract: We provide a method to prepare a warm-started quantum state from measurements with an iterative framework to enhance the quantum approximate optimisation algorithm (QAOA). The numerical simulations show the method can effectively address the "stuck issue" of the standard QAOA using a single-string warm-started initial state described in [Cain et al., 2023]. When applied to the $3$-regular MaxCut problem, our approach achieves an improved approximation ratio, with a lower bound that iteratively converges toward the best classical algorithms for $p=1$ standard QAOA. Additionally, in the context of the discrete global minimal variance portfolio (DGMVP) model, simulations reveal a more favourable scaling of identifying the global minimal compared to the QAOA standalone, the single-string warm-started QAOA and a classical constrained sampling approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09704v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haomu Yuan, Songqinghao Yang, Crispin H. W. Barnes</dc:creator>
    </item>
    <item>
      <title>Perch like a bird: bio-inspired optimal maneuvers and nonlinear control for Flapping-Wing Unmanned Aerial Vehicles</title>
      <link>https://arxiv.org/abs/2502.09728</link>
      <description>arXiv:2502.09728v1 Announce Type: cross 
Abstract: This research endeavors to design the perching maneuver and control in ornithopter robots. By analyzing the dynamic interplay between the robot's flight dynamics, feedback loops, and the environmental constraints, we aim to advance our understanding of the perching maneuver, drawing parallels to biological systems. Inspired by the elegant control strategies observed in avian flight, we develop an optimal maneuver and a corresponding controller to achieve stable perching. The maneuver consists of a deceleration and a rapid pitch-up (vertical turn), which arises from analytically solving the optimization problem of minimal velocity at perch, subject to kinematic and dynamic constraints. The controller for the flapping frequency and tail symmetric deflection is nonlinear and adaptive, ensuring robustly stable perching. Indeed, such adaptive behavior in a sense incorporates homeostatic principles of cybernetics into the control system, enhancing the robot's ability to adapt to unexpected disturbances and maintain a stable posture during the perching maneuver. The resulting autonomous perching maneuvers -- closed-loop descent and turn -- , have been verified and validated, demonstrating excellent agreement with real bird perching trajectories reported in the literature. These findings lay the theoretical groundwork for the development of future prototypes that better imitate the skillful perching maneuvers of birds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09728v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. Ruiz, J. \'A. Acosta</dc:creator>
    </item>
    <item>
      <title>Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games</title>
      <link>https://arxiv.org/abs/2502.09780</link>
      <description>arXiv:2502.09780v1 Announce Type: cross 
Abstract: Multi-agent reinforcement learning (MARL) lies at the heart of a plethora of applications involving the interaction of a group of agents in a shared unknown environment. A prominent framework for studying MARL is Markov games, with the goal of finding various notions of equilibria in a sample-efficient manner, such as the Nash equilibrium (NE) and the coarse correlated equilibrium (CCE). However, existing sample-efficient approaches either require tailored uncertainty estimation under function approximation, or careful coordination of the players. In this paper, we propose a novel model-based algorithm, called VMG, that incentivizes exploration via biasing the empirical estimate of the model parameters towards those with a higher collective best-response values of all the players when fixing the other players' policies, thus encouraging the policy to deviate from its current equilibrium for more exploration. VMG is oblivious to different forms of function approximation, and permits simultaneous and uncoupled policy updates of all players. Theoretically, we also establish that VMG achieves a near-optimal regret for finding both the NEs of two-player zero-sum Markov games and CCEs of multi-player general-sum Markov games under linear function approximation in an online environment, which nearly match their counterparts with sophisticated uncertainty quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09780v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tong Yang, Bo Dai, Lin Xiao, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Learning Fair Policies for Infectious Diseases Mitigation using Path Integral Control</title>
      <link>https://arxiv.org/abs/2502.09831</link>
      <description>arXiv:2502.09831v1 Announce Type: cross 
Abstract: Infectious diseases pose major public health challenges to society, highlighting the importance of designing effective policies to reduce economic loss and mortality. In this paper, we propose a framework for sequential decision-making under uncertainty to design fairness-aware disease mitigation policies that incorporate various measures of unfairness. Specifically, our approach learns equitable vaccination and lockdown strategies based on a stochastic multi-group SIR model. To address the challenges of solving the resulting sequential decision-making problem, we adopt the path integral control algorithm as an efficient solution scheme. Through a case study, we demonstrate that our approach effectively improves fairness compared to conventional methods and provides valuable insights for policymakers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09831v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuangzhuang Jia, Hyuk Park, G\"ok\c{c}e Dayan{\i}kl{\i}, Grani A. Hanasusanto</dc:creator>
    </item>
    <item>
      <title>Dual Control for Interactive Autonomous Merging with Model Predictive Diffusion</title>
      <link>https://arxiv.org/abs/2502.09918</link>
      <description>arXiv:2502.09918v1 Announce Type: cross 
Abstract: Interactive decision-making is essential in applications such as autonomous driving, where the agent must infer the behavior of nearby human drivers while planning in real-time. Traditional predict-then-act frameworks are often insufficient or inefficient because accurate inference of human behavior requires a continuous interaction rather than isolated prediction. To address this, we propose an active learning framework in which we rigorously derive predicted belief distributions. Additionally, we introduce a novel model-based diffusion solver tailored for online receding horizon control problems, demonstrated through a complex, non-convex highway merging scenario. Our approach extends previous high-fidelity dual control simulations to hardware experiments, which may be viewed at https://youtu.be/Q_JdZuopGL4, and verifies behavior inference in human-driven traffic scenarios, moving beyond idealized models. The results show improvements in adaptive planning under uncertainty, advancing the field of interactive decision-making for real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09918v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Knaup, Jovin D'sa, Behdad Chalaki, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari, Panagiotis Tsiotras</dc:creator>
    </item>
    <item>
      <title>Assortment Optimization for Patient-Provider Matching</title>
      <link>https://arxiv.org/abs/2502.10353</link>
      <description>arXiv:2502.10353v1 Announce Type: cross 
Abstract: Rising provider turnover forces healthcare administrators to frequently rematch patients to available providers, which can be cumbersome and labor-intensive. To reduce the burden of rematching, we study algorithms for matching patients and providers through assortment optimization. We develop a patient-provider matching model in which we simultaneously offer each patient a menu of providers, and patients subsequently respond and select providers. By offering assortments upfront, administrators can balance logistical ease and patient autonomy. We study policies for assortment optimization and characterize their performance under different problem settings. We demonstrate that the selection of assortment policy is highly dependent on problem specifics and, in particular, on a patient's willingness to match and the ratio between patients and providers. On real-world data, we show that our best policy can improve match quality by 13% over a greedy solution by tailoring assortment sizes based on patient characteristics. We conclude with recommendations for running a real-world patient-provider matching system inspired by our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10353v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naveen Raman, Holly Wiberg</dc:creator>
    </item>
    <item>
      <title>CISSIR: Beam Codebooks with Self-Interference Reduction Guarantees for Integrated Sensing and Communication Beyond 5G</title>
      <link>https://arxiv.org/abs/2502.10371</link>
      <description>arXiv:2502.10371v1 Announce Type: cross 
Abstract: We propose a beam codebook design to reduce self-interference (SI) in integrated sensing and communication (ISAC) systems. Our optimization methods, which can be applied to both tapered beamforming and phased arrays, adapt the codebooks to the SI channel such that a certain SI level is achieved. Furthermore, we derive an upper bound on the quantization noise in terms of the achieved SI level, which provides guidelines to pose the optimization problem in order to obtain performance guarantees for sensing. By selecting standard reference codebooks in our simulations, we show substantially improved sensing quality with little impact on 5G-NR communication. Our proposed method is not only less dependent on hyperparameters than other approaches in the literature, but it can also reduce SI further, and thus deliver better sensing and communication performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10371v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Hernang\'omez, Jochen Fink, Renato L. G. Cavalcante, S{\l}awomir Sta\'nczak</dc:creator>
    </item>
    <item>
      <title>A theory on the absence of spurious solutions for nonconvex and nonsmooth optimization</title>
      <link>https://arxiv.org/abs/1805.08204</link>
      <description>arXiv:1805.08204v5 Announce Type: replace 
Abstract: We study the set of continuous functions that admit no spurious local optima (i.e. local minima that are not global minima) which we term \textit{global functions}. They satisfy various powerful properties for analyzing nonconvex and nonsmooth optimization problems. For instance, they satisfy a theorem akin to the fundamental uniform limit theorem in the analysis regarding continuous functions. Global functions are also endowed with useful properties regarding the composition of functions and change of variables. Using these new results, we show that a class of nonconvex and nonsmooth optimization problems arising in tensor decomposition applications are global functions. This is the first result concerning nonconvex methods for nonsmooth objective functions. Our result provides a theoretical guarantee for the widely-used $\ell_1$ norm to avoid outliers in nonconvex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:1805.08204v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cedric Josz, Yi Ouyang, Richard Y. Zhang, Javad Lavaei, Somayeh Sojoudi</dc:creator>
    </item>
    <item>
      <title>Randomized Robust Price Optimization</title>
      <link>https://arxiv.org/abs/2306.09659</link>
      <description>arXiv:2306.09659v2 Announce Type: replace 
Abstract: The robust multi-product pricing problem is to determine the prices of a collection of products so as to maximize the worst-case revenue, where the worst case is taken over an uncertainty set of demand models that the firm expects could be realized in practice. A tacit assumption in this approach is that the pricing decision is a deterministic decision: the prices of the products are fixed and do not vary. In this paper, we consider a randomized approach to robust pricing, where a decision maker specifies a distribution over potential price vectors so as to maximize its worst-case revenue over an uncertainty set of demand models. We formally define this problem - the randomized robust price optimization problem - and analyze when a randomized price scheme performs as well as a deterministic scheme versus when it yields a benefit. We also propose solution methods for obtaining an optimal randomization scheme over a discrete set of candidate price vectors and show how these methods are applicable for common demand models, such as the linear, semi-log and log-log demand models. We numerically compare the randomized and deterministic approaches on a variety of synthetic and real problem instances; on instances derived from a real grocery retail scanner dataset, we show that the improvement in worst-case revenue can be as high as 92%. Using the same grocery retail scanner dataset, we also show that the randomized approach can produce price prescriptions that achieve higher out-of-sample revenue than the nominal and deterministic robust approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09659v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyi Guan, Velibor V. Mi\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>Stochastic optimal control in Hilbert spaces: $C^{1,1}$ regularity of the value function and optimal synthesis via viscosity solutions</title>
      <link>https://arxiv.org/abs/2310.03181</link>
      <description>arXiv:2310.03181v4 Announce Type: replace 
Abstract: We study optimal control problems governed by abstract infinite dimensional stochastic differential equations using the dynamic programming approach. In the first part, we prove Lipschitz continuity, semiconcavity and semiconvexity of the value function under several sets of assumptions, and thus derive its $C^{1,1}$ regularity in the space variable. Based on this regularity result, we construct optimal feedback controls using the notion of the $B$-continuous viscosity solutions for the associated Hamilton--Jacobi--Bellman equation. This is done in the case when the noise coefficient is independent of the control variable. We also discuss applications of our results to optimal control problems governed by stochastic reaction-diffusion equations and, under economic motivations, stochastic delay differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03181v4</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo, Andrzej \'Swi\k{e}ch, Lukas Wessels</dc:creator>
    </item>
    <item>
      <title>Duality-based single-level reformulations of bilevel optimization problems</title>
      <link>https://arxiv.org/abs/2405.07672</link>
      <description>arXiv:2405.07672v3 Announce Type: replace 
Abstract: Usually, bilevel optimization problems need to be transformed into single-level ones in order to derive optimality conditions and solution algorithms. Among the available approaches, the replacement of the lower-level problem by means of duality relations became popular quite recently. We revisit three realizations of this idea which are based on the lower-level Lagrange, Wolfe, and Mond--Weir dual problem. The resulting single-level surrogate problems are equivalent to the original bilevel optimization problem from the viewpoint of global minimizers under mild assumptions. However, all these reformulations suffer from the appearance of so-called implicit variables, i.e., surrogate variables which do not enter the objective function but appear in the feasible set for modeling purposes. Treating implicit variables as explicit ones has been shown to be problematic when locally optimal solutions, stationary points, and applicable constraint qualifications are compared to the original problem. Indeed, we illustrate that the same difficulties have to be faced when using these duality-based reformulations. Furthermore, we show that the Mangasarian-Fromovitz constraint qualification is likely to be violated at each feasible point of these reformulations, contrasting assertions in some recently published papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07672v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stephan Dempe, Patrick Mehlitz</dc:creator>
    </item>
    <item>
      <title>A Bregman firmly nonexpansive proximal operator for baryconvex optimization</title>
      <link>https://arxiv.org/abs/2411.00928</link>
      <description>arXiv:2411.00928v2 Announce Type: replace 
Abstract: We present a generalization of the proximal operator defined through a convex combination of convex objectives, where the coefficients are updated in a minimax fashion. We prove that this new operator is Bregman firmly nonexpansive with respect to a Bregman divergence that combines Euclidean and information geometries. Finally, we derive the associated continuous flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00928v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mastane Achab</dc:creator>
    </item>
    <item>
      <title>A Regularized Newton Method for Nonconvex Optimization with Global and Local Complexity Guarantees</title>
      <link>https://arxiv.org/abs/2502.04799</link>
      <description>arXiv:2502.04799v2 Announce Type: replace 
Abstract: We consider the problem of finding an $\epsilon$-stationary point of a nonconvex function with a Lipschitz continuous Hessian and propose a quadratic regularized Newton method incorporating a new class of regularizers constructed from the current and previous gradients. The method leverages a recently developed linear conjugate gradient approach with a negative curvature monitor to solve the regularized Newton equation. Notably, our algorithm is adaptive, requiring no prior knowledge of the Lipschitz constant of the Hessian, and achieves a global complexity of $O(\epsilon^{-\frac{3}{2}}) + \tilde O(1)$ in terms of the second-order oracle calls, and $\tilde O(\epsilon^{-\frac{7}{4}})$ for Hessian-vector products, respectively. Moreover, when the iterates converge to a point where the Hessian is positive definite, the method exhibits quadratic local convergence. Preliminary numerical results illustrate the competitiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04799v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Zhou, Jintao Xu, Chenglong Bao, Chao Ding, Jun Zhu</dc:creator>
    </item>
    <item>
      <title>Unique determination of cost functions in a multipopulation mean field game model</title>
      <link>https://arxiv.org/abs/2312.01622</link>
      <description>arXiv:2312.01622v2 Announce Type: replace-cross 
Abstract: This paper studies an inverse problem for a multipopulation mean field game (MFG) system where the objective is to reconstruct the running and terminal cost functions of the system that couples the dynamics of different populations. We derive uniqueness results for the inverse problem with different types of available data. In particular, we show that it is possible to uniquely reconstruct some simplified forms of the cost functions from data measured only on a single population component under mild additional assumptions on the coupling mechanism. The proofs are based on the standard multilinearization technique that allows us to reduce the inverse problems into simplified forms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01622v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Ren, Nathan Soedjak, Kewei Wang</dc:creator>
    </item>
    <item>
      <title>Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation</title>
      <link>https://arxiv.org/abs/2408.08192</link>
      <description>arXiv:2408.08192v2 Announce Type: replace-cross 
Abstract: Mean field games (MFGs) model interactions in large-population multi-agent systems through population distributions. Traditional learning methods for MFGs are based on fixed-point iteration (FPI), where policy updates and induced population distributions are computed separately and sequentially. However, FPI-type methods may suffer from inefficiency and instability due to potential oscillations caused by this forward-backward procedure. In this work, we propose a novel perspective that treats the policy and population as a unified parameter controlling the game dynamics. By applying stochastic parameter approximation to this unified parameter, we develop SemiSGD, a simple stochastic gradient descent (SGD)-type method, where an agent updates its policy and population estimates simultaneously and fully asynchronously. Building on this perspective, we further apply linear function approximation (LFA) to the unified parameter, resulting in the first population-aware LFA (PA-LFA) for learning MFGs on continuous state-action spaces. A comprehensive finite-time convergence analysis is provided for SemiSGD with PA-LFA, including its convergence to the equilibrium for linear MFGs -- a class of MFGs with a linear structure concerning the population -- under the standard contractivity condition, and to a neighborhood of the equilibrium under a more practical condition. We also characterize the approximation error for non-linear MFGs. We validate our theoretical findings with six experiments on three MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08192v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Zhang, Xu Chen, Xuan Di</dc:creator>
    </item>
    <item>
      <title>Increasing Both Batch Size and Learning Rate Accelerates Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2409.08770</link>
      <description>arXiv:2409.08770v4 Announce Type: replace-cross 
Abstract: The performance of mini-batch stochastic gradient descent (SGD) strongly depends on setting the batch size and learning rate to minimize the empirical loss in training the deep neural network. In this paper, we present theoretical analyses of mini-batch SGD with four schedulers: (i) constant batch size and decaying learning rate scheduler, (ii) increasing batch size and decaying learning rate scheduler, (iii) increasing batch size and increasing learning rate scheduler, and (iv) increasing batch size and warm-up decaying learning rate scheduler. We show that mini-batch SGD using scheduler (i) does not always minimize the expectation of the full gradient norm of the empirical loss, whereas it does using any of schedulers (ii), (iii), and (iv). Furthermore, schedulers (iii) and (iv) accelerate mini-batch SGD. The paper also provides numerical results of supporting analyses showing that using scheduler (iii) or (iv) minimizes the full gradient norm of the empirical loss faster than using scheduler (i) or (ii).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08770v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hikaru Umeda, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Learning Stochastic Dynamics from Snapshots through Regularized Unbalanced Optimal Transport</title>
      <link>https://arxiv.org/abs/2410.00844</link>
      <description>arXiv:2410.00844v2 Announce Type: replace-cross 
Abstract: Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learned directly from data. Theoretically, we explore the connections between the RUOT and Schr\"odinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network, high-dimensional Gaussian Mixture Model, and single-cell RNA-seq data from blood development. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape. Our code is available at: https://github.com/zhenyiizhang/DeepRUOT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00844v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhenyi Zhang, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>Variational Inference on the Boolean Hypercube with the Quantum Entropy</title>
      <link>https://arxiv.org/abs/2411.03759</link>
      <description>arXiv:2411.03759v2 Announce Type: replace-cross 
Abstract: In this paper, we derive variational inference upper-bounds on the log-partition function of pairwise Markov random fields on the Boolean hypercube, based on quantum relaxations of the Kullback-Leibler divergence. We then propose an efficient algorithm to compute these bounds based on primal-dual optimization. An improvement of these bounds through the use of ''hierarchies,'' similar to sum-of-squares (SoS) hierarchies is proposed, and we present a greedy algorithm to select among these relaxations. We carry extensive numerical experiments and compare with state-of-the-art methods for this inference problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03759v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eliot Beyler (SIERRA), Francis Bach (SIERRA)</dc:creator>
    </item>
    <item>
      <title>Schr\"odinger Bridge Problem for Jump Diffusions</title>
      <link>https://arxiv.org/abs/2411.13765</link>
      <description>arXiv:2411.13765v2 Announce Type: replace-cross 
Abstract: The Schr\"odinger bridge problem (SBP) seeks to find the measure $\hat{\mathbf{P}}$ on a certain path space which interpolates between state-space distributions $\rho_0$ at time $0$ and $\rho_T$ at time $T$ while minimizing the KL divergence (relative entropy) to a reference path measure $\mathbf{R}$. In this work, we tackle the SBP in the case when $\mathbf{R}$ is the path measure of a jump diffusion. Under mild assumptions, with both the operator theory approach and the stochastic calculus techniques, we establish an $h$-transform theory for jump diffusions and devise an approximation method to achieve the jump-diffusion SBP solution $\hat{\mathbf{P}}$ as the strong-convergence limit of a sequence of harmonic $h$-transforms. To the best of our knowledge, these results are novel in the study of SBP. Moreover, the $h$-transform framework and the approximation method developed in this work are robust and applicable to a relatively general class of jump diffusions. In addition, we examine the SBP of particular types of jump diffusions under additional regularity conditions and extend the existing results on the SBP from the diffusion case to the jump-diffusion setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13765v2</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Zlotchevski, Linan Chen</dc:creator>
    </item>
    <item>
      <title>Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions</title>
      <link>https://arxiv.org/abs/2502.06309</link>
      <description>arXiv:2502.06309v2 Announce Type: replace-cross 
Abstract: As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses. Among all the physical properties of resistive elements, the response to the pulses directly affects the training dynamics. This paper first provides a theoretical foundation for gradient-based training on AIMC hardware and studies the impact of response functions. We demonstrate that noisy update and asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty term on the objective. To overcome the issue, Tiki-Taka, a residual learning algorithm, converges exactly to a critical point by optimizing a main array and a residual array bilevelly. The conclusion is supported by simulations validating our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06309v2</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Omobayode Fagbohungbe, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>EIQP: Execution-time-certified and Infeasibility-detecting QP Solver</title>
      <link>https://arxiv.org/abs/2502.07738</link>
      <description>arXiv:2502.07738v2 Announce Type: replace-cross 
Abstract: Solving real-time quadratic programming (QP) is a ubiquitous task in control engineering, such as in model predictive control and control barrier function-based QP. In such real-time scenarios, certifying that the employed QP algorithm can either return a solution within a predefined level of optimality or detect QP infeasibility before the predefined sampling time is a pressing requirement. This article considers convex QP (including linear programming) and adopts its homogeneous formulation to achieve infeasibility detection. Exploiting this homogeneous formulation, this article proposes a novel infeasible interior-point method (IPM) algorithm with the best theoretical $O(\sqrt{n})$ iteration complexity that feasible IPM algorithms enjoy. The iteration complexity is proved to be \textit{exact} (rather than an upper bound), \textit{simple to calculate}, and \textit{data independent}, with the value $\left\lceil\frac{\log(\frac{n+1}{\epsilon})}{-\log(1-\frac{0.414213}{\sqrt{n+1}})}\right\rceil$ (where $n$ and $\epsilon$ denote the number of constraints and the predefined optimality level, respectively), making it appealing to certify the execution time of online time-varying convex QPs. The proposed algorithm is simple to implement without requiring a line search procedure (uses the full Newton step), and its C-code implementation (offering MATLAB, Julia, and Python interfaces) and numerical examples are publicly available at https://github.com/liangwu2019/EIQP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07738v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Wu, Wei Xiao, Richard D. Braatz</dc:creator>
    </item>
  </channel>
</rss>
