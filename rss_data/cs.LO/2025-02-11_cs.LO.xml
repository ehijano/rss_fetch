<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Complete Axiomatization of Branching Bisimilarity for a Simple Process Language with Probabilistic Choice</title>
      <link>https://arxiv.org/abs/2502.05631</link>
      <description>arXiv:2502.05631v1 Announce Type: new 
Abstract: This paper proposes a notion of branching bisimilarity for non-deterministic probabilistic processes. In order to characterize the corresponding notion of rooted branching probabilistic bisimilarity, an equational theory is proposed for a basic, recursion-free process language with non-deterministic as well as probabilistic choice. The proof of completeness of the axiomatization builds on the completeness of strong probabilistic bisimilarity on the one hand and on the notion of a concrete process, i.e. a process that does not display (partially) inert $\tau$-moves, on the other hand. The approach is first presented for the non-deterministic fragment of the calculus and next generalized to incorporate probabilistic choice, too.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05631v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rob van Glabbeek, Jan Friso Groote, Erik de Vink</dc:creator>
    </item>
    <item>
      <title>The memory of $\omega$-regular and BC($\Sigma_2^0$) objectives</title>
      <link>https://arxiv.org/abs/2502.05840</link>
      <description>arXiv:2502.05840v1 Announce Type: new 
Abstract: In the context of 2-player zero-sum infinite duration games played on (potentially infinite) graphs, we ask the following question: Given an objective $W$ in $\mathrm{BC}(\mathbf{\Sigma}_2^0)$, i.e. recognised by a potentially infinite deterministic parity automaton, what is its memory, meaning the smallest integer $k$ such that in any game won by Eve, she has a strategy with $\leq k$ states of memory. We provide a class of deterministic parity automata that exactly recognise objectives with memory $\leq k$. This leads to the following results:
  (1) For $\omega$-regular objectives, the memory can be computed in NP.
  (2) Given two objectives $W_1$ and $W_2$ in $\mathrm{BC}(\mathbf{\Sigma}_2^0)$ and assuming $W_1$ is prefix-independent, the memory of $W_1 \cup W_2$ is at most the product of the memories of $W_1$ and $W_2$.
  Our results also apply to chromatic memory, the variant where strategies can update their memory state only depending on which colour is seen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05840v1</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Casares, Pierre Ohlmann</dc:creator>
    </item>
    <item>
      <title>Complete Compositional Syntax for Finite Transducers on Finite and Bi-Infinite Words</title>
      <link>https://arxiv.org/abs/2502.06450</link>
      <description>arXiv:2502.06450v1 Announce Type: new 
Abstract: Minimizing finite automata, proving trace equivalence of labelled transition systems or representing sofic subshifts involve very similar arguments, which suggests the possibility of a unified formalism. We propose finite states non-deterministic transducer as a lingua franca for automata theory, transition systems, and sofic subshifts. We introduce a compositional diagrammatical syntax for transducers in form of string diagrams interpreted as relations. This syntax comes with sound rewriting rules allowing diagrammatical reasoning. Our main result is the completeness of our equational theory, ensuring that language-equivalence, trace-equivalence, or subshift equivalence can always be proved using our rewriting rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06450v1</guid>
      <category>cs.LO</category>
      <category>cs.DM</category>
      <category>cs.FL</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Titouan Carette, Marc de Visme, Vivien Ducros, Victor Lutfalla, Etienne Moutot</dc:creator>
    </item>
    <item>
      <title>Proving the Coding Interview: A Benchmark for Formally Verified Code Generation</title>
      <link>https://arxiv.org/abs/2502.05714</link>
      <description>arXiv:2502.05714v1 Announce Type: cross 
Abstract: We introduce the Formally Verified Automated Programming Progress Standards, or FVAPPS, a benchmark of 4715 samples for writing programs and proving their correctness, the largest formal verification benchmark, including 1083 curated and quality controlled samples. Previously, APPS provided a benchmark and dataset for programming puzzles to be completed in Python and checked against unit tests, of the kind seen in technical assessments in the software engineering industry. Building upon recent approaches for benchmarks in interactive theorem proving, we generalize the unit tests to Lean 4 theorems given without proof (i.e., using Lean's "sorry" keyword). On the 406 theorems of 100 randomly selected samples, Sonnet correctly proves 30% and Gemini correctly proves 18%. We challenge the machine learning and program synthesis communities to solve both each general purpose programming problem and its associated correctness specifications. The benchmark is available at https://huggingface.co/datasets/quinn-dougherty/fvapps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05714v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Quinn Dougherty, Ronak Mehta</dc:creator>
    </item>
    <item>
      <title>Three meta-questions on infinite-domain Constraint Satisfaction Problems</title>
      <link>https://arxiv.org/abs/2502.06621</link>
      <description>arXiv:2502.06621v1 Announce Type: cross 
Abstract: The Feder-Vardi dichotomy conjecture for Constraint Satisfaction Problems (CSPs) with finite templates, confirmed independently by Bulatov and Zhuk, has a counterpart for infinite templates due to Bodirsky and Pinsker which remains wide open. We resolve several meta-problems on the scope of their conjecture. Our first two main results provide two fundamental simplifications of this scope, one of structural, and the other one of algebraic nature. The former simplification implies that the conjecture is equivalent to its restriction to templates without algebraicity, a crucial assumption in the most powerful classification methods. The latter yields that the higher-arity invariants of any template within its scope can be assumed to be essentially injective, and hence any algebraic condition characterizing any complexity class within the conjecture must be satisfiable by injections, thus lifting the mystery of the better applicability of certain conditions over others. Our third main result uses the first one to show that any tractable template within the scope serves, up to a Datalog-computable modification of it, as the witness of the tractability of a finite-domain Promise Constraint Satisfaction Problem (PCSP) by the so-called sandwiching method. This provides a strong hitherto unknown connection between infinite-domain CSPs and finite-domain PCSPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06621v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Pinsker, Jakub Rydval, Moritz Sch\"obi, Christoph Spiess</dc:creator>
    </item>
    <item>
      <title>Conditional logic as a short-circuit logic</title>
      <link>https://arxiv.org/abs/2304.14821</link>
      <description>arXiv:2304.14821v3 Announce Type: replace 
Abstract: Three-valued conditional logic (CL) is defined by Guzm\'an and Squier (1990), and based on McCarthy's noncommutative connectives, axiomatises a short-circuit logic (SCL) that defines more identities than three-valued MSCL (Memorising SCL, which also has a two-valued variant). This follows from the fact that the definable connective that prescribes full left-sequential conjunction is commutative in CL. We show that in CL, the full left-sequential connectives and negation define Bochvar's three-valued strict logic. We observe that CL also has a two-valued variant of which the full left-sequential connectives and negation define a commutative logic that is weaker than propositional logic because the absorption laws do not hold.
  Next, we show that the original, equational axiomatisation of CL is not independent and give several alternative, independent axiomatisations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.14821v3</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan A. Bergstra, Alban Ponse</dc:creator>
    </item>
    <item>
      <title>Semiring Provenance for Lightweight Description Logics</title>
      <link>https://arxiv.org/abs/2310.16472</link>
      <description>arXiv:2310.16472v2 Announce Type: replace 
Abstract: We investigate semiring provenance--a successful framework originally defined in the relational database setting--for description logics. In this context, the ontology axioms are annotated with elements of a commutative semiring and these annotations are propagated to the ontology consequences in a way that reflects how they are derived. We define a provenance semantics for a language that encompasses several lightweight description logics and show its relationships with semantics that have been defined for ontologies annotated with a specific kind of annotation (such as fuzzy degrees). We show that under some restrictions on the semiring, the semantics satisfies desirable properties (such as extending the semiring provenance defined for databases). We then focus on the well-known why-provenance, for which we study the complexity of problems related to the provenance of an assertion or a conjunctive query answer. Finally, we consider two more restricted cases which correspond to the so-called positive Boolean provenance and lineage in the database setting. For these cases, we exhibit relationships with well-known notions related to explanations in description logics and complete our complexity analysis. As a side contribution, we provide conditions on an $\mathcal{ELHI}_\bot$ ontology that guarantee tractable reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16472v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camille Bourgaux, Ana Ozaki, Rafael Pe\~naloza</dc:creator>
    </item>
    <item>
      <title>On Decidable and Undecidable Extensions of Simply Typed Lambda Calculus</title>
      <link>https://arxiv.org/abs/2411.06086</link>
      <description>arXiv:2411.06086v2 Announce Type: replace 
Abstract: The decidability of the reachability problem for finitary PCF has been used as a theoretical basis for fully automated verification tools for functional programs. The reachability problem, however, often becomes undecidable for a slight extension of finitary PCF with side effects, such as exceptions, algebraic effects, and references, which hindered the extension of the above verification tools for supporting functional programs with side effects. In this paper, we first give simple proofs of the undecidability of four extensions of finitary PCF, which would help us understand and analyze the source of undecidability. We then focus on an extension with references, and give a decidable fragment using a type system. To our knowledge, this is the first non-trivial decidable fragment that features higher-order recursive functions containing reference cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06086v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3704875</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Program. Lang. 9(POPL): 1136-1166 (2025)</arxiv:journal_reference>
      <dc:creator>Naoki Kobayashi</dc:creator>
    </item>
    <item>
      <title>Coslice Colimits in Homotopy Type Theory</title>
      <link>https://arxiv.org/abs/2411.15103</link>
      <description>arXiv:2411.15103v2 Announce Type: replace 
Abstract: We contribute to the theory of (homotopy) colimits inside homotopy type theory. The heart of our work characterizes the connection between colimits in coslices of a universe, called coslice colimits, and colimits in the universe (i.e., ordinary colimits). To derive this characterization, we find an explicit construction of colimits in coslices that is tailored to reveal the connection. We use the construction to derive properties of colimits. Notably, we prove that the forgetful functor from a coslice creates colimits over trees. We also use the construction to examine how colimits interact with orthogonal factorization systems and with cohomology theories. As a consequence of their interaction with orthogonal factorization systems, all pointed colimits (special kinds of coslice colimits) preserve $n$-connectedness, which implies that higher groups are closed under colimits on directed graphs. We have formalized our main construction of the coslice colimit functor in Agda. The code for this paper is available at https://github.com/PHart3/colimits-agda .</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15103v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Perry Hart (Favonia), Kuen-Bang Hou (Favonia)</dc:creator>
    </item>
    <item>
      <title>LOCALINTEL: Generating Organizational Threat Intelligence from Global and Local Cyber Knowledge</title>
      <link>https://arxiv.org/abs/2401.10036</link>
      <description>arXiv:2401.10036v2 Announce Type: replace-cross 
Abstract: Security Operations Center (SoC) analysts gather threat reports from openly accessible global threat repositories and tailor the information to their organization's needs, such as developing threat intelligence and security policies. They also depend on organizational internal repositories, which act as private local knowledge database. These local knowledge databases store credible cyber intelligence, critical operational and infrastructure details. SoCs undertake a manual labor-intensive task of utilizing these global threat repositories and local knowledge databases to create both organization-specific threat intelligence and mitigation policies. Recently, Large Language Models (LLMs) have shown the capability to process diverse knowledge sources efficiently. We leverage this ability to automate this organization-specific threat intelligence generation. We present LocalIntel, a novel automated threat intelligence contextualization framework that retrieves zero-day vulnerability reports from the global threat repositories and uses its local knowledge database to determine implications and mitigation strategies to alert and assist the SoC analyst. LocalIntel comprises two key phases: knowledge retrieval and contextualization. Quantitative and qualitative assessment has shown effectiveness in generating up to 93% accurate organizational threat intelligence with 64% inter-rater agreement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10036v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shaswata Mitra, Subash Neupane, Trisha Chakraborty, Sudip Mittal, Aritran Piplai, Manas Gaur, Shahram Rahimi</dc:creator>
    </item>
    <item>
      <title>Tatami Printer: Physical ZKPs for Tatami Puzzles</title>
      <link>https://arxiv.org/abs/2408.13507</link>
      <description>arXiv:2408.13507v2 Announce Type: replace-cross 
Abstract: Tatami puzzles are pencil puzzles with an objective to partition a rectangular grid into rectangular regions such that no four regions share a corner point, as well as satisfying other constraints. In this paper, we develop a physical card-based protocol called Tatami printer that can help verify solutions of Tatami puzzles. We then use the Tatami printer to construct zero-knowledge proof protocols for two such puzzles: Tatamibari and Square Jam. These protocols enable a prover to show a verifier the existence of the puzzles' solutions without revealing them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13507v2</guid>
      <category>cs.CR</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suthee Ruangwises</dc:creator>
    </item>
    <item>
      <title>Aligning with Logic: Measuring, Evaluating and Improving Logical Preference Consistency in Large Language Models</title>
      <link>https://arxiv.org/abs/2410.02205</link>
      <description>arXiv:2410.02205v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are expected to be predictable and trustworthy to support reliable decision-making systems. Yet current LLMs often show inconsistencies in their judgments. In this work, we examine logical preference consistency as a foundational requirement for building more dependable LLM systems, ensuring stable and coherent decision-making while minimizing erratic or contradictory outputs. To quantify the logical preference consistency, we propose a universal evaluation framework based on three fundamental properties: transitivity, commutativity and negation invariance. Through extensive experimentation across diverse LLMs, we demonstrate that these properties serve as strong indicators of judgment robustness. Furthermore, we introduce a data refinement and augmentation technique, REPAIR, that enhances logical consistency while maintaining alignment with human preferences. Finally, we show that improving consistency leads to better performance in LLM-driven logic-based algorithms, reinforcing stability and coherence in decision-making systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02205v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinhong Liu, Zhijiang Guo, Tianya Liang, Ehsan Shareghi, Ivan Vuli\'c, Nigel Collier</dc:creator>
    </item>
    <item>
      <title>Can Transformers Reason Logically? A Study in SAT Solving</title>
      <link>https://arxiv.org/abs/2410.07432</link>
      <description>arXiv:2410.07432v2 Announce Type: replace-cross 
Abstract: We formally study the logical reasoning capabilities of decoder-only Transformers in the context of the boolean satisfiability (SAT) problem. First, we prove by construction that decoder-only Transformers can decide 3-SAT, in a non-uniform model of computation, using backtracking and deduction via Chain-of-Thought (CoT). %We prove its correctness by showing trace equivalence to the well-known DPLL SAT-solving algorithm. Second, we implement our construction as a PyTorch model with a tool (PARAT) that we designed to empirically demonstrate its correctness and investigate its properties. Third, rather than \textit{programming} a transformer to reason, we evaluate empirically whether it can be \textit{trained} to do so by learning directly from algorithmic traces (``reasoning paths'') from our theoretical construction. The trained models demonstrate strong out-of-distribution generalization on problem sizes seen during training but has limited length generalization, which is consistent with the implications of our theoretical result</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07432v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leyan Pan, Vijay Ganesh, Jacob Abernethy, Chris Esposo, Wenke Lee</dc:creator>
    </item>
    <item>
      <title>Structural temporal logic for mechanized program verification</title>
      <link>https://arxiv.org/abs/2410.14906</link>
      <description>arXiv:2410.14906v4 Announce Type: replace-cross 
Abstract: Mechanized verification of liveness properties for realistic programs, with effects, nondeterminism, and nontermination is challenging. Existing temporal reasoning frameworks operate on the level of models (traces, automata) not programs, creating a verification gap and losing the benefits of modularity and composition enjoyed by structural program logics (i.e: Hoare Logic). Reasoning about infinite traces and automata can be fairly low-level, requiring complex (co-)inductive proof techniques and familiarity with proof assistant mechanics (e.g., guardedness checker). We propose a modular approach to the verification of general temporal properties with a new temporal logic that we call Ticl. Using Ticl, we internalize complex (co-)inductive proof techniques to structural lemmas and reasoning about variants and invariants. We show that it is possible to perform modular proofs of general temporal properties in a proof assistant, while working in a high-level of abstraction. We demonstrate the benefits of Ticl by giving mechanized proofs of safety and liveness properties for programs with scheduling, shared memory and distributed consensus, exhibiting a low program-to-proof ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14906v4</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleftherios Ioannidis, Yannick Zakowski, Steve Zdancewic, Sebastian Angel</dc:creator>
    </item>
    <item>
      <title>Variants of Solovay reducibility</title>
      <link>https://arxiv.org/abs/2410.15563</link>
      <description>arXiv:2410.15563v2 Announce Type: replace-cross 
Abstract: Outside of the left-c.e. reals, Solovay reducibility is considered to be behaved badly [10.1007/978-0-387-68441-3]. Proposals for variants of Solovay reducibility that are better suited for the investigation of arbitrary, not necessarily left-c.e. reals were made by Rettinger and Zheng [10.1007/978-3-540-27798-9_39], and, recently, by Titov [10.11588/heidok.00034250] and by Kumabe and co-authors [10.4115/jla.2020.12.2; 10.3233/COM-230486]. These variants all coincide with the original version of Solovay reducibility on the left-c.e. reals. Furthermore, they are all defined in terms of translation functions. The latter translate between computable approximations in the case of Rettinger and Zheng, are monotone in the case of Titov, and are functions between reals in the case of Kumabe et al.
  Solovay reducibility and its variants mentioned so far have tight connections to Martin-L\"of randomness, the strongest and most central notion of a random sequence. For the investigation of Schnorr randomness, total variants of Solovay reducibility have been introduced by Merkle and Titov [10.48550/arXiv.2407.14869] in 2022 and, independently, by Kumabe et al. [10.3233/COM-230486] in 2024, the latter again via real-valued translation functions. In what follows, we show that total Solovay reducibility defined in terms of rational functions implies total Solovay reducibility defined in terms of real functions and is strictly stronger that the original version of Solovay reducibility.
  In what follows, we derive new results on the mentioned variants and their relation to each other. In particular, we obtain that Solovay reducibility defined in terms of translation function on rationals implies Solovay reducibility defined in terms of translation functions on reals, and we show that the original version of Solovay reducibility is strictly weaker than its monotone variant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15563v2</guid>
      <category>math.LO</category>
      <category>cs.IT</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Titov</dc:creator>
    </item>
    <item>
      <title>Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies</title>
      <link>https://arxiv.org/abs/2501.03888</link>
      <description>arXiv:2501.03888v2 Announce Type: replace-cross 
Abstract: Although deep reinforcement learning has been shown to be effective, the model's black-box nature presents barriers to direct policy interpretation. To address this problem, we propose a neuro-symbolic approach called neural DNF-MT for end-to-end policy learning. The differentiable nature of the neural DNF-MT model enables the use of deep actor-critic algorithms for training. At the same time, its architecture is designed so that trained models can be directly translated into interpretable policies expressed as standard (bivalent or probabilistic) logic programs. Moreover, additional layers can be included to extract abstract features from complex observations, acting as a form of predicate invention. The logic representations are highly interpretable, and we show how the bivalent representations of deterministic policies can be edited and incorporated back into a neural model, facilitating manual intervention and adaptation of learned policies. We evaluate our approach on a range of tasks requiring learning deterministic or stochastic behaviours from various forms of observations. Our empirical results show that our neural DNF-MT model performs at the level of competing black-box methods whilst providing interpretable policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03888v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Gu Baugh, Luke Dickens, Alessandra Russo</dc:creator>
    </item>
  </channel>
</rss>
