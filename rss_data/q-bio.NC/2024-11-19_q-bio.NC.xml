<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Nov 2024 07:09:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Pragmatic information of aesthetic appraisal</title>
      <link>https://arxiv.org/abs/2411.10561</link>
      <description>arXiv:2411.10561v1 Announce Type: new 
Abstract: A phenomenological model for aesthetic appraisal is proposed in terms of pragmatic information for a dynamic update semantics over belief states on an aesthetic appreciator. The model qualitatively correlates with aesthetic pleasure ratings in an experimental study on cadential effects in Western tonal music. Finally, related computational and neurodynamical accounts are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10561v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter beim Graben</dc:creator>
    </item>
    <item>
      <title>A minimalistic representation model for head direction system</title>
      <link>https://arxiv.org/abs/2411.10596</link>
      <description>arXiv:2411.10596v1 Announce Type: new 
Abstract: We present a minimalistic representation model for the head direction (HD) system, aiming to learn a high-dimensional representation of head direction that captures essential properties of HD cells. Our model is a representation of rotation group $U(1)$, and we study both the fully connected version and convolutional version. We demonstrate the emergence of Gaussian-like tuning profiles and a 2D circle geometry in both versions of the model. We also demonstrate that the learned model is capable of accurate path integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10596v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>stat.ML</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minglu Zhao, Dehong Xu, Deqian Kong, Wen-Hao Zhang, Ying Nian Wu</dc:creator>
    </item>
    <item>
      <title>In silico discovery of representational relationships across visual cortex</title>
      <link>https://arxiv.org/abs/2411.10872</link>
      <description>arXiv:2411.10872v1 Announce Type: new 
Abstract: Human vision is mediated by a complex interconnected network of cortical brain areas jointly representing visual information. While these areas are increasingly understood in isolation, their representational relationships remain elusive. Here we developed relational neural control (RNC), and used it to investigate the representational relationships for univariate and multivariate fMRI responses of early- and mid-level visual areas. RNC generated and explored in silico fMRI responses for large amounts of images, discovering controlling images that align or disentangle responses across areas, thus indicating their shared or unique representational content. A large portion of representational content was shared across areas, unique representational content increased with cortical distance, and we isolated the visual features determining these effects. Closing the empirical cycle, we validated the in silico discoveries on in vivo fMRI responses from independent subjects. Together, this reveals how visual areas jointly represent the world as an interconnected network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10872v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alessandro T. Gifford, Maya A. Jastrz\k{e}bowska, Johannes J. D. Singer, Radoslaw M. Cichy</dc:creator>
    </item>
    <item>
      <title>Integrated Ising Model with global inhibition for decision making</title>
      <link>https://arxiv.org/abs/2411.11143</link>
      <description>arXiv:2411.11143v1 Announce Type: new 
Abstract: Humans and other organisms make decisions choosing between different options, with the aim to maximize the reward and minimize the cost. The main theoretical framework for modeling the decision-making process has been based on the highly successful drift-diffusion model, which is a simple tool for explaining many aspects of this process. However, new observations challenge this model. Recently, it was found that inhibitory tone increases during high cognitive load and situations of uncertainty, but the origin of this phenomenon is not understood. Motivated by this observation, we extend a recently developed model for decision making while animals move towards targets in real space. We introduce an integrated Ising-type model, that includes global inhibition, and use it to explore its role in decision-making. This model can explain how the brain may utilize inhibition to improve its decision-making accuracy. Compared to experimental results, this model suggests that the regime of the brain's decision-making activity is in proximity to a critical transition line between the ordered and disordered. Within the model, the critical region near the transition line has the advantageous property of enabling a significant decrease in error with a small increase in inhibition and also exhibits unique properties with respect to learning and memory decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11143v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olga Tapinova, Tal Finkelman, Tamar Reitich-Stolero, Rony Paz, Assaf Tal, Nir S. Gov</dc:creator>
    </item>
    <item>
      <title>Reply to: Limitations in odour recognition and generalisation in a neuromorphic olfactory circuit</title>
      <link>https://arxiv.org/abs/2411.10456</link>
      <description>arXiv:2411.10456v1 Announce Type: cross 
Abstract: Dennler et al. submit that they have discovered limitations affecting some of the conclusions drawn in our 2020 paper, Rapid online learning and robust recall in a neuromorphic olfactory circuit. Specifically, they assert (1) that the public dataset we used suffers from sensor drift and a nonrandomized measurement protocol, (2) that our neuromorphic EPL network is limited in its ability to generalize over repeated presentations of an odorant, and (3) that our EPL network results can be performance matched by using a more computationally efficient distance measure. Though they are correct in their description of the limitations of that public dataset, they do not acknowledge in their first two assertions how our utilization of those data sidestepped these limitations. Their third claim arises from flaws in the method used to generate their distance measure. We respond below to each of these three claims in turn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10456v1</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Roy Moyal, Nabil Imam, Thomas A. Cleland</dc:creator>
    </item>
    <item>
      <title>Neural decoding from stereotactic EEG: accounting for electrode variability across subjects</title>
      <link>https://arxiv.org/abs/2411.10458</link>
      <description>arXiv:2411.10458v1 Announce Type: cross 
Abstract: Deep learning based neural decoding from stereotactic electroencephalography (sEEG) would likely benefit from scaling up both dataset and model size. To achieve this, combining data across multiple subjects is crucial. However, in sEEG cohorts, each subject has a variable number of electrodes placed at distinct locations in their brain, solely based on clinical needs. Such heterogeneity in electrode number/placement poses a significant challenge for data integration, since there is no clear correspondence of the neural activity recorded at distinct sites between individuals. Here we introduce seegnificant: a training framework and architecture that can be used to decode behavior across subjects using sEEG data. We tokenize the neural activity within electrodes using convolutions and extract long-term temporal dependencies between tokens using self-attention in the time dimension. The 3D location of each electrode is then mixed with the tokens, followed by another self-attention in the electrode dimension to extract effective spatiotemporal neural representations. Subject-specific heads are then used for downstream decoding tasks. Using this approach, we construct a multi-subject model trained on the combined data from 21 subjects performing a behavioral task. We demonstrate that our model is able to decode the trial-wise response time of the subjects during the behavioral task solely from neural data. We also show that the neural representations learned by pretraining our model across individuals can be transferred in a few-shot manner to new subjects. This work introduces a scalable approach towards sEEG data integration for multi-subject model training, paving the way for cross-subject generalization for sEEG decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10458v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Georgios Mentzelopoulos, Evangelos Chatzipantazis, Ashwin G. Ramayya, Michelle J. Hedlund, Vivek P. Buch, Kostas Daniilidis, Konrad P. Kording, Flavia Vitale</dc:creator>
    </item>
    <item>
      <title>Multi Scale Graph Neural Network for Alzheimer's Disease</title>
      <link>https://arxiv.org/abs/2411.10720</link>
      <description>arXiv:2411.10720v1 Announce Type: cross 
Abstract: Alzheimer's disease (AD) is a complex, progressive neurodegenerative disorder characterized by extracellular A\b{eta} plaques, neurofibrillary tau tangles, glial activation, and neuronal degeneration, involving multiple cell types and pathways. Current models often overlook the cellular context of these pathways. To address this, we developed a multiscale graph neural network (GNN) model, ALZ PINNACLE, using brain omics data from donors spanning the entire aging to AD spectrum. ALZ PINNACLE is based on the PINNACLE GNN framework, which learns context-aware protein, cell type, and tissue representations within a unified latent space. ALZ PINNACLE was trained on 14,951 proteins, 206,850 protein interactions, 7 cell types, and 48 cell subtypes or states. After pretraining, we investigated the learned embedding of APOE, the largest genetic risk factor for AD, across different cell types. Notably, APOE embeddings showed high similarity in microglial, neuronal, and CD8 cells, suggesting a similar role of APOE in these cell types. Fine tuning the model on AD risk genes revealed cell type contexts predictive of the role of APOE in AD. Our results suggest that ALZ PINNACLE may provide a valuable framework for uncovering novel insights into AD neurobiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10720v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anya Chauhan, Ayush Noori, Zhaozhi Li, Yingnan He, Michelle M Li, Marinka Zitnik, Sudeshna Das</dc:creator>
    </item>
    <item>
      <title>Beyond Human-Like Processing: Large Language Models Perform Equivalently on Forward and Backward Scientific Text</title>
      <link>https://arxiv.org/abs/2411.11061</link>
      <description>arXiv:2411.11061v1 Announce Type: cross 
Abstract: The impressive performance of large language models (LLMs) has led to their consideration as models of human language processing. Instead, we suggest that the success of LLMs arises from the flexibility of the transformer learning architecture. To evaluate this conjecture, we trained LLMs on scientific texts that were either in a forward or backward format. Despite backward text being inconsistent with the structure of human languages, we found that LLMs performed equally well in either format on a neuroscience benchmark, eclipsing human expert performance for both forward and backward orders. Our results are consistent with the success of transformers across diverse domains, such as weather prediction and protein design. This widespread success is attributable to LLM's ability to extract predictive patterns from any sufficiently structured input. Given their generality, we suggest caution in interpreting LLM's success in linguistic tasks as evidence for human-like mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11061v1</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoliang Luo, Michael Ramscar, Bradley C. Love</dc:creator>
    </item>
    <item>
      <title>Brain waves are a repetition of a pause and an activity</title>
      <link>https://arxiv.org/abs/2205.08734</link>
      <description>arXiv:2205.08734v4 Announce Type: replace 
Abstract: Brain waves still cannot reliably distinguish between awake and asleep states. Here, I present new original indices, voltage subthreshold wave $\tau$ and abovethreshold wave burst, for advanced LFP/EEG readings. Assuming that $\tau$ is a microwave that fluctuates every sample such as the equipotential, the total number of $\tau$ ($N\tau$) is inferred to be the maximum, and the amplitude of burst (Abst) is inferred to be the minimum. In fact, they invariably had a mean $\tau$ duration ($M\tau$) of 2-3 sample intervals in any case. In addition, $\tau$ and burst exhibited self-similarity for sample frequency while occupying approximately 30% and 70% of LFP in the natural state, respectively. Its threshold and Abst were correlated with the vigilance state and decreased to 70% by doubling the sample frequency. The dose of sevoflurane, which inhibits and synchronizes neural activity, was linearly correlated with decreases in the threshold and $N\tau$. Thus, $\tau$ could reflect the uncertainty of the membrane potential. I propose that $\tau$ and burst represent a pause and an activity such as the rhythm of the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.08734v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chika Koyama</dc:creator>
    </item>
    <item>
      <title>The Unbearable Slowness of Being: Why do we live at 10 bits/s?</title>
      <link>https://arxiv.org/abs/2408.10234</link>
      <description>arXiv:2408.10234v2 Announce Type: replace 
Abstract: This article is about the neural conundrum behind the slowness of human behavior. The information throughput of a human being is about 10 bits/s. In comparison, our sensory systems gather data at ~10^9 bits/s. The stark contrast between these numbers remains unexplained and touches on fundamental aspects of brain function: What neural substrate sets this speed limit on the pace of our existence? Why does the brain need billions of neurons to process 10 bits/s? Why can we only think about one thing at a time? The brain seems to operate in two distinct modes: the "outer" brain handles fast high-dimensional sensory and motor signals, whereas the "inner" brain processes the reduced few bits needed to control behavior. Plausible explanations exist for the large neuron numbers in the outer brain, but not for the inner brain, and we propose new research directions to remedy this.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10234v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jieyu Zheng, Markus Meister</dc:creator>
    </item>
    <item>
      <title>Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks</title>
      <link>https://arxiv.org/abs/2410.11064</link>
      <description>arXiv:2410.11064v2 Announce Type: replace 
Abstract: Divergent brain connectivity is thought to underlie the behavioral and cognitive symptoms observed in many neurodevelopmental disorders. Quantifying divergence from neurotypical connectivity patterns offers a promising pathway to inform diagnosis and therapeutic interventions. While advanced neuroimaging techniques, such as diffusion MRI (dMRI), have facilitated the mapping of brain's structural connectome, the challenge lies in accurately modeling developmental trajectories within these complex networked structures to create robust neurodivergence markers. In this work, we present the Brain Representation via Individualized Deep Generative Embedding (BRIDGE) framework, which integrates normative modeling with a bio-inspired deep generative model to create a reference trajectory of connectivity transformation as part of neurotypical development. This will enable the assessment of neurodivergence by comparing individuals to the established neurotypical trajectory. BRIDGE provides a global neurodivergence score based on the difference between connectivity-based brain age and chronological age, along with region-wise neurodivergence maps that highlight localized connectivity differences. Application of BRIDGE to a large cohort of children with autism spectrum disorder demonstrates that the global neurodivergence score correlates with clinical assessments in autism, and the regional map offers insights into the heterogeneity at the individual level in neurodevelopmental disorders. Together, the neurodivergence score and map form powerful tools for quantifying developmental divergence in connectivity patterns, advancing the development of imaging markers for personalized diagnosis and intervention in various clinical contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11064v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui Sherry Shen, Yusuf Osmanl{\i}o\u{g}lu, Drew Parker, Darien Aunapu, Benjamin E. Yerys, Birkan Tun\c{c}, Ragini Verma</dc:creator>
    </item>
    <item>
      <title>Elucidating the theoretical underpinnings of surrogate gradient learning in spiking neural networks</title>
      <link>https://arxiv.org/abs/2404.14964</link>
      <description>arXiv:2404.14964v3 Announce Type: replace-cross 
Abstract: Training spiking neural networks to approximate universal functions is essential for studying information processing in the brain and for neuromorphic computing. Yet the binary nature of spikes poses a challenge for direct gradient-based training. Surrogate gradients have been empirically successful in circumventing this problem, but their theoretical foundation remains elusive. Here, we investigate the relation of surrogate gradients to two theoretically well-founded approaches. On the one hand, we consider smoothed probabilistic models, which, due to the lack of support for automatic differentiation, are impractical for training multi-layer spiking neural networks but provide derivatives equivalent to surrogate gradients for single neurons. On the other hand, we investigate stochastic automatic differentiation, which is compatible with discrete randomness but has not yet been used to train spiking neural networks. We find that the latter gives surrogate gradients a theoretical basis in stochastic spiking neural networks, where the surrogate derivative matches the derivative of the neuronal escape noise function. This finding supports the effectiveness of surrogate gradients in practice and suggests their suitability for stochastic spiking neural networks. However, surrogate gradients are generally not gradients of a surrogate loss despite their relation to stochastic automatic differentiation. Nevertheless, we empirically confirm the effectiveness of surrogate gradients in stochastic multi-layer spiking neural networks and discuss their relation to deterministic networks as a special case. Our work gives theoretical support to surrogate gradients and the choice of a suitable surrogate derivative in stochastic spiking neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14964v3</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Gygax, Friedemann Zenke</dc:creator>
    </item>
    <item>
      <title>Self-Attention Limits Working Memory Capacity of Transformer-Based Models</title>
      <link>https://arxiv.org/abs/2409.10715</link>
      <description>arXiv:2409.10715v2 Announce Type: replace-cross 
Abstract: Recent work on Transformer-based large language models (LLMs) has revealed striking limits in their working memory capacity, similar to what has been found in human behavioral studies. Specifically, these models' performance drops significantly on N-back tasks as N increases. However, there is still a lack of mechanistic interpretability as to why this phenomenon would arise. Inspired by the executive attention theory from behavioral sciences, we hypothesize that the self-attention mechanism within Transformer-based models might be responsible for their working memory capacity limits. To test this hypothesis, we train vanilla decoder-only transformers to perform N-back tasks and find that attention scores gradually aggregate to the N-back positions over training, suggesting that the model masters the task by learning a strategy to pay attention to the relationship between the current position and the N-back position. Critically, we find that the total entropy of the attention score matrix increases as N increases, suggesting that the dispersion of attention scores might be the cause of the capacity limit observed in N-back tasks. Our findings thus offer insights into the shared role of attention in both human and artificial intelligence. Moreover, the limitations of the self-attention mechanism revealed in the current study could inform future efforts to design more powerful model architectures with enhanced working memory capacity and cognitive capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10715v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongyu Gong, Hantao Zhang</dc:creator>
    </item>
    <item>
      <title>Psycho Gundam: Electroencephalography based real-time robotic control system with deep learning</title>
      <link>https://arxiv.org/abs/2411.06414</link>
      <description>arXiv:2411.06414v2 Announce Type: replace-cross 
Abstract: The Psycho Frame, a sophisticated system primarily used in Universal Century (U.C.) series mobile suits for NEWTYPE pilots, has evolved as an integral component in harnessing the latent potential of mental energy. Its ability to amplify and resonate with the pilot's psyche enables real-time mental control, creating unique applications such as psychomagnetic fields and sensory-based weaponry. This paper presents the development of a novel robotic control system inspired by the Psycho Frame, combining electroencephalography (EEG) and deep learning for real-time control of robotic systems. By capturing and interpreting brainwave data through EEG, the system extends human cognitive commands to robotic actions, reflecting the seamless synchronization of thought and machine, much like the Psyco Frame's integration with a Newtype pilot's mental faculties. This research demonstrates how modern AI techniques can expand the limits of human-machine interaction, potentially transcending traditional input methods and enabling a deeper, more intuitive control of complex robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06414v2</guid>
      <category>cs.RO</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Wei-Sheng Wang</dc:creator>
    </item>
  </channel>
</rss>
