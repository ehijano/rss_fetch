<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 May 2025 04:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Sequent Calculus Perspective on Base-Extension Semantics</title>
      <link>https://arxiv.org/abs/2505.18589</link>
      <description>arXiv:2505.18589v1 Announce Type: new 
Abstract: We define base-extension semantics (Bes) using atomic systems based on sequent calculus rather than natural deduction. While traditional Bes aligns naturally with intuitionistic logic due to its constructive foundations, we show that sequent calculi with multiple conclusions yield a Bes framework more suited to classical semantics. The harmony in classical sequents leads to straightforward semantic clauses derived solely from right introduction rules. This framework enables a Sandqvist-style completeness proof that extracts a sequent calculus proof from any valid semantic consequence. Moreover, we show that the inclusion or omission of atomic cut rules meaningfully affects the semantics, yet completeness holds in both cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18589v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Barroso-Nascimento, Ekaterina Piotrovskaya, Elaine Pimentel</dc:creator>
    </item>
    <item>
      <title>Supermartingale Certificates for Quantitative Omega-regular Verification and Control</title>
      <link>https://arxiv.org/abs/2505.18833</link>
      <description>arXiv:2505.18833v1 Announce Type: new 
Abstract: We present the first supermartingale certificate for quantitative $\omega$-regular properties of discrete-time infinite-state stochastic systems. Our certificate is defined on the product of the stochastic system and a limit-deterministic B\"uchi automaton that specifies the property of interest; hence we call it a limit-deterministic B\"uchi supermartingale (LDBSM). Previously known supermartingale certificates applied only to quantitative reachability, safety, or reach-avoid properties, and to qualitative (i.e., probability 1) $\omega$-regular properties. We also present fully automated algorithms for the template-based synthesis of LDBSMs, for the case when the stochastic system dynamics and the controller can be represented in terms of polynomial inequalities. Our experiments demonstrate the ability of our method to solve verification and control tasks for stochastic systems that were beyond the reach of previous supermartingale-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18833v1</guid>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas A. Henzinger (Institute of Science and Technology Austria), Kaushik Mallik (IMDEA Software Institute), Pouya Sadeghi (Singapore Management University), {\DJ}or{\dj}e \v{Z}ikeli\'c (Singapore Management University)</dc:creator>
    </item>
    <item>
      <title>Property Directed Reachability with Extended Resolution</title>
      <link>https://arxiv.org/abs/2505.18998</link>
      <description>arXiv:2505.18998v1 Announce Type: new 
Abstract: Property Directed Reachability (\textsc{Pdr}), also known as IC3, is a state-of-the-art model checking algorithm widely used for verifying safety properties. While \textsc{Pdr} is effective in finding inductive invariants, its underlying proof system, Resolution, limits its ability to construct short proofs for certain verification problems.
  This paper introduces \textsc{PdrER}, a novel generalization of \textsc{Pdr} that uses Extended Resolution (ER), a proof system exponentially stronger than Resolution, when constructing a proof of correctness. \PdrEV leverages ER to construct shorter bounded proofs of correctness, enabling it to discover more compact inductive invariants. While \PdrEV is based on \textsc{Pdr}, it includes algorithmic enhancements that had to be made in order to efficiently use ER in the context of model checking.
  We implemented \textsc{PdrER} in a new open-source verification framework and evaluated it on the Hardware Model Checking Competition benchmarks from 2019, 2020 and 2024. Our experimental evaluation demonstrates that \textsc{PdrER} outperforms \textsc{Pdr}, solving more instances in less time and uniquely solving problems that \textsc{Pdr} cannot solve within a given time limit. We argue that this paper represents a significant step toward making strong proof systems practically usable in model checking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18998v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Luka, Yakir Vizel</dc:creator>
    </item>
    <item>
      <title>Failure divergence refinement for Event-B</title>
      <link>https://arxiv.org/abs/2505.19069</link>
      <description>arXiv:2505.19069v1 Announce Type: new 
Abstract: When validating formal models, sizable effort goes into ensuring two types of properties: safety properties (nothing bad happens) and liveness properties (something good occurs eventually. Event-B supports checking safety properties all through the refinement chain. The same is not valid for liveness properties. Liveness properties are commonly validated with additional techniques like animation, and results do not transfer quickly, leading to re-doing the validation process at every refinement stage. This paper promotes early validation by providing failure divergence refinement semantics for Event-B. We show that failure divergence refinement preserves trace properties, which comprise many liveness properties, under certain natural conditions. Consequently, re-validation of those properties becomes unnecessary. Our result benefits data refinements, where no abstract behavior should be removed during refinement. Furthermore, we lay out an algorithm and provide a tool for automatic failure divergence refinement checking, significantly decreasing the modeler's workload. The tool is compared and evaluated in the context of sizable case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19069v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Stock, Michael Leuschel, Atif Mashkoor</dc:creator>
    </item>
    <item>
      <title>A Real-Analytic Approach to Differential-Algebraic Dynamic Logic</title>
      <link>https://arxiv.org/abs/2505.19323</link>
      <description>arXiv:2505.19323v1 Announce Type: new 
Abstract: This paper introduces a proof calculus for real-analytic differential-algebraic dynamic logic, enabling correct transformations of differential-algebraic equations. Applications include index reductions from differential-algebraic equations to ordinary differential equations. The calculus ensures compatibility between differential-algebraic equation proof principles and (differential-form) differential dynamic logic for hybrid systems. One key contribution is ghost switching which establishes precise conditions that decompose multi-modal systems into hybrid systems, thereby correctly hybridizing sophisticated differential-algebraic dynamics. The calculus is demonstrated in a proof of equivalence for a Euclidean pendulum to index reduced form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19323v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Hellwig, Andr\'e Platzer</dc:creator>
    </item>
    <item>
      <title>Model Enumeration of Two-Variable Logic with Quadratic Delay Complexity</title>
      <link>https://arxiv.org/abs/2505.19648</link>
      <description>arXiv:2505.19648v1 Announce Type: new 
Abstract: We study the model enumeration problem of the function-free, finite domain fragment of first-order logic with two variables ($FO^2$). Specifically, given an $FO^2$ sentence $\Gamma$ and a positive integer $n$, how can one enumerate all the models of $\Gamma$ over a domain of size $n$? In this paper, we devise a novel algorithm to address this problem. The delay complexity, the time required between producing two consecutive models, of our algorithm is quadratic in the given domain size $n$ (up to logarithmic factors) when the sentence is fixed. This complexity is almost optimal since the interpretation of binary predicates in any model requires at least $\Omega(n^2)$ bits to represent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19648v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiaolan Meng, Juhua Pu, Hongting Niu, Yuyi Wang, Yuanhong Wang, Ond\v{r}ej Ku\v{z}elka</dc:creator>
    </item>
    <item>
      <title>A Formal Analysis of Algorithms for Matroids and Greedoids</title>
      <link>https://arxiv.org/abs/2505.19816</link>
      <description>arXiv:2505.19816v1 Announce Type: new 
Abstract: We present a formal analysis, in Isabelle/HOL, of optimisation algorithms for matroids, which are useful generalisations of combinatorial structures that occur in optimisation, and greedoids, which are a generalisation of matroids. Although some formalisation work has been done earlier on matroids, our work here presents the first formalisation of results on greedoids, and many results we formalise in relation to matroids are also formalised for the first time in this work. We formalise the analysis of a number of optimisation algorithms for matroids and greedoids. We also derive from those algorithms executable implementations of Kruskal's algorithm for minimum spanning trees, an algorithm for maximum cardinality matching for bi-partite graphs, and Prim's algorithm for computing minimum weight spanning trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19816v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abdulaziz, Thomas Ammer, Shriya Meenakshisundaram, Adem Rimpapa</dc:creator>
    </item>
    <item>
      <title>Axiomatizing approximate inclusion</title>
      <link>https://arxiv.org/abs/2505.19834</link>
      <description>arXiv:2505.19834v1 Announce Type: new 
Abstract: We introduce two approximate variants of inclusion dependencies and examine the axiomatization and computational complexity of their implication problems. The approximate variants allow for some imperfection in the database and differ in how this degree is measured. One considers the error relative to the database size, while the other applies a fixed threshold independent of size. We obtain complete axiomatizations for both under some arity restrictions. In particular, restricted to unary inclusion dependencies, the implication problem for each approximate variant is decidable in PTIME. We formalise the results using team semantics, where a team corresponds to a uni-relational database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19834v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matilda H\"aggblom</dc:creator>
    </item>
    <item>
      <title>Formalizing a classification theorem for low-dimensional solvable Lie algebras in Lean</title>
      <link>https://arxiv.org/abs/2505.19975</link>
      <description>arXiv:2505.19975v1 Announce Type: new 
Abstract: We present a formalization, in the theorem prover Lean, of the classification of solvable Lie algebras of dimension at most three over arbitrary fields. Lie algebras are algebraic objects which encode infinitesimal symmetries, and as such ubiquitous in geometry and physics. Our work involves explicit calculations on the level of the underlying vector spaces and provides a use case for the linear algebra and Lie theory routines in Lean's mathematical library mathlib. Along the way we formalize results about Lie algebras, define the semidirect product within this setting and add API for bases of vector spaces. In a wider context, this project aims to provide a complete mechanization of a classification theorem, covering both the statement and its full formal proof, and contribute to the development and broader adoption of such results in formalized mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19975v1</guid>
      <category>cs.LO</category>
      <category>math.RA</category>
      <category>math.RT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viviana del Barco, Gustavo Infanti, Exequiel Rivas, Paul Schwahn</dc:creator>
    </item>
    <item>
      <title>Proof Compression via Subatomic Logic and Guarded Substitutions</title>
      <link>https://arxiv.org/abs/2505.20009</link>
      <description>arXiv:2505.20009v1 Announce Type: new 
Abstract: Subatomic logic is a recent innovation in structural proof theory where atoms are no longer the smallest entity in a logical formula, but are instead treated as binary connectives. As a consequence, we can give a subatomic proof system for propositional classical logic such that all derivations are strictly linear: no inference step deletes or adds information, even units.
  In this paper, we introduce a powerful new proof compression mechanism that we call guarded substitutions, a variant of explicit substitutions, which substitute only guarded occurrences of a free variable, instead of all free occurrences. This allows us to construct ''superpositions'' of derivations, which simultaneously represent multiple subderivations. We show that a subatomic proof system with guarded substitution can p-simulate a Frege system with substitution, and moreover, the cut-rule is not required to do so.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20009v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victoria Barrett (Inria Saclay), Alessio Guglielmi (University of Bath), Benjamin Ralph (University of Bath), Lutz Stra{\ss}burger (Inria Saclay)</dc:creator>
    </item>
    <item>
      <title>Better Extension Variables in DQBF via Independence</title>
      <link>https://arxiv.org/abs/2505.20069</link>
      <description>arXiv:2505.20069v1 Announce Type: new 
Abstract: We show that extension variables in (D)QBF can be generalised by conditioning on universal assignments. The benefit of this is that the dependency sets of such conditioned extension variables can be made smaller to allow easier refutations. This simple modification instantly solves many challenges in p-simulating the QBF expansion rule, which cannot be p-simulated in proof systems that have strategy extraction. Simulating expansion is even more crucial in DQBF, where other methods are incomplete. In this paper we provide an overview of the strength of this new independent extension rule. We find that a new version of Extended Frege called IndExtFrege+Red can p-simulate a multitude of difficult QBF and DQBF techniques, even techniques that are difficult to approach with ExtFrege+Red. We show six p-simulations, that IndExtFrege+Red p-simulates QRAT, IR(D)-Calc, Q(Drrs)-Res, Fork Resolution, DQRAT and G, which together underpin most DQBF solving and preprocessing techniques. The p-simulations work despite these systems using complicated rules and our new extension rule being relatively simple. Moreover, unlike recent p-simulations by ExtFrege+Red we can simulate the proof rules line by line, which allows us to mix QBF rules more easily with other inference steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20069v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leroy Chew, Tom\'a\v{s} Peitl</dc:creator>
    </item>
    <item>
      <title>The Computability Path Order for Beta-Eta-Normal Higher-Order Rewriting (Full Version)</title>
      <link>https://arxiv.org/abs/2505.20121</link>
      <description>arXiv:2505.20121v1 Announce Type: new 
Abstract: We lift the computability path order and its extensions from plain higher-order rewriting to higher-order rewriting on beta-eta-normal forms where matching modulo beta-eta is employed. The resulting order NCPO is shown to be useful on practical examples. In particular, it can handle systems where its cousin NHORPO fails even when it is used together with the powerful transformation technique of neutralization. We also argue that automating NCPO efficiently is straightforward using SAT/SMT solvers whereas this cannot be said about the transformation technique of neutralization. Our prototype implementation supports automatic termination proof search for NCPO and is also the first one to automate NHORPO with neutralization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20121v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Niederhauser, Aart Middeldorp</dc:creator>
    </item>
    <item>
      <title>GPUMC: A Stateless Model Checker for GPU Weak Memory Concurrency</title>
      <link>https://arxiv.org/abs/2505.20207</link>
      <description>arXiv:2505.20207v1 Announce Type: new 
Abstract: GPU computing is embracing weak memory concurrency for performance improvement. However, compared to CPUs, modern GPUs provide more fine-grained concurrency features such as scopes, have additional properties like divergence, and thereby follow different weak memory consistency models. These features and properties make concurrent programming on GPUs more complex and error-prone. To this end, we present GPUMC, a stateless model checker to check the correctness of GPU shared-memory concurrent programs under scoped-RC11 weak memory concurrency model. GPUMC explores all possible executions in GPU programs to reveal various errors - races, barrier divergence, and assertion violations. In addition, GPUMC also automatically repairs these errors in the appropriate cases.
  We evaluate GPUMC with benchmarks and real-life GPU programs. GPUMC is efficient both in time and memory in verifying large GPU programs where state-of-the-art tools are timed out. In addition, GPUMC identifies all known errors in these benchmarks compared to the state-of-the-art tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20207v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soham Chakraborty, S. Krishna, Andreas Pavlogiannis, Omkar Tuppe</dc:creator>
    </item>
    <item>
      <title>Comparing Neural Network Encodings for Logic-based Explainability</title>
      <link>https://arxiv.org/abs/2505.20269</link>
      <description>arXiv:2505.20269v1 Announce Type: new 
Abstract: Providing explanations for the outputs of artificial neural networks (ANNs) is crucial in many contexts, such as critical systems, data protection laws and handling adversarial examples. Logic-based methods can offer explanations with correctness guarantees, but face scalability challenges. Due to these issues, it is necessary to compare different encodings of ANNs into logical constraints, which are used in logic-based explainability. This work compares two encodings of ANNs: one has been used in the literature to provide explanations, while the other will be adapted for our context of explainability. Additionally, the second encoding uses fewer variables and constraints, thus, potentially enhancing efficiency. Experiments showed similar running times for computing explanations, but the adapted encoding performed up to 18\% better in building logical constraints and up to 16\% better in overall time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20269v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-79029-4_20</arxiv:DOI>
      <arxiv:journal_reference>Intelligent Systems. BRACIS 2024. Lecture Notes in Computer Science, vol 15412</arxiv:journal_reference>
      <dc:creator>Levi Cordeiro Carvalho, Saulo A. F. Oliveira, Thiago Alves Rocha</dc:creator>
    </item>
    <item>
      <title>RvLLM: LLM Runtime Verification with Domain Knowledge</title>
      <link>https://arxiv.org/abs/2505.18585</link>
      <description>arXiv:2505.18585v1 Announce Type: cross 
Abstract: Large language models (LLMs) have emerged as a dominant AI paradigm due to their exceptional text understanding and generation capabilities. However, their tendency to generate inconsistent or erroneous outputs challenges their reliability, especially in high-stakes domains requiring accuracy and trustworthiness. Existing research primarily focuses on detecting and mitigating model misbehavior in general-purpose scenarios, often overlooking the potential of integrating domain-specific knowledge. In this work, we advance misbehavior detection by incorporating domain knowledge. The core idea is to design a general specification language that enables domain experts to customize domain-specific predicates in a lightweight and intuitive manner, supporting later runtime verification of LLM outputs. To achieve this, we design a novel specification language, ESL, and introduce a runtime verification framework, RvLLM, to validate LLM output against domain-specific constraints defined in ESL. We evaluate RvLLM on three representative tasks: violation detection against Singapore Rapid Transit Systems Act, numerical comparison, and inequality solving. Experimental results demonstrate that RvLLM effectively detects erroneous outputs across various LLMs in a lightweight and flexible manner. The results reveal that despite their impressive capabilities, LLMs remain prone to low-level errors due to limited interpretability and a lack of formal guarantees during inference, and our framework offers a potential long-term solution by leveraging expert domain knowledge to rigorously and efficiently verify LLM outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18585v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yedi Zhang, Sun Yi Emma, Annabelle Lee Jia En, Annabelle Lee Jia En, Jin Song Dong</dc:creator>
    </item>
    <item>
      <title>Automatic Verification of Floating-Point Accumulation Networks</title>
      <link>https://arxiv.org/abs/2505.18791</link>
      <description>arXiv:2505.18791v1 Announce Type: cross 
Abstract: Floating-point accumulation networks (FPANs) are key building blocks used in many floating-point algorithms, including compensated summation and double-double arithmetic. FPANs are notoriously difficult to analyze, and algorithms using FPANs are often published without rigorous correctness proofs. In fact, on at least one occasion, a published error bound for a widely used FPAN was later found to be incorrect. In this paper, we present an automatic procedure that produces computer-verified proofs of several FPAN correctness properties, including error bounds that are tight to the nearest bit. Our approach is underpinned by a novel floating-point abstraction that models the sign, exponent, and number of leading and trailing zeros and ones in the mantissa of each number flowing through an FPAN. We also present a new FPAN for double-double addition that is faster and more accurate than the previous best known algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18791v1</guid>
      <category>math.NA</category>
      <category>cs.LO</category>
      <category>cs.NA</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David K. Zhang, Alex Aiken</dc:creator>
    </item>
    <item>
      <title>Automated Verification of Monotonic Data Structure Traversals in C</title>
      <link>https://arxiv.org/abs/2505.18818</link>
      <description>arXiv:2505.18818v1 Announce Type: cross 
Abstract: Bespoke data structure operations are common in real-world C code. We identify one common subclass, monotonic data structure traversals (MDSTs), that iterate monotonically through the structure. For example, strlen iterates from start to end of a character array until a null byte is found, and a binary search tree insert iterates from the tree root towards a leaf. We describe a new automated verification tool, Shrinker, to verify MDSTs written in C. Shrinker uses a new program analysis strategy called scapegoating size descent, which is designed to take advantage of the fact that many MDSTs produce very similar traces when executed on an input (e.g., some large list) as when executed on a 'shrunk' version of the input (e.g., the same list but with its first element deleted). We introduce a new benchmark set containing over one hundred instances proving correctness, equivalence, and memory safety properties of dozens of MDSTs found in major C codebases including Linux, NetBSD, OpenBSD, QEMU, Git, and Musl. Shrinker significantly increases the number of monotonic string and list traversals that can be verified vs. a portfolio of state-of-the-art tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18818v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Sotoudeh</dc:creator>
    </item>
    <item>
      <title>Distributed Incremental SAT Solving with Mallob: Report and Case Study with Hierarchical Planning</title>
      <link>https://arxiv.org/abs/2505.18836</link>
      <description>arXiv:2505.18836v1 Announce Type: cross 
Abstract: This report describes an extension of the distributed job scheduling and SAT solving platform Mallob by incremental SAT solving, embedded in a case study on SAT-based hierarchical planning. We introduce a low-latency interface for incremental jobs and specifically for IPASIR-style incremental SAT solving to Mallob. This also allows to process many independent planning instances in parallel via Mallob's scheduling capabilities. In an experiment where 587 planning inputs are resolved in parallel on 2348 cores, we observe significant speedups for several planning domains where SAT solving constitutes a major part of the planner's running time. These findings indicate that our approach to distributed incremental SAT solving may be useful for a wide range of SAT applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18836v1</guid>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Schreiber</dc:creator>
    </item>
    <item>
      <title>Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments</title>
      <link>https://arxiv.org/abs/2505.19361</link>
      <description>arXiv:2505.19361v1 Announce Type: cross 
Abstract: The deployment of pre-trained perception models in novel environments often leads to performance degradation due to distributional shifts. Although recent artificial intelligence approaches for metacognition use logical rules to characterize and filter model errors, improving precision often comes at the cost of reduced recall. This paper addresses the hypothesis that leveraging multiple pre-trained models can mitigate this recall reduction. We formulate the challenge of identifying and managing conflicting predictions from various models as a consistency-based abduction problem. The input predictions and the learned error detection rules derived from each model are encoded in a logic program. We then seek an abductive explanation--a subset of model predictions--that maximizes prediction coverage while ensuring the rate of logical inconsistencies (derived from domain constraints) remains below a specified threshold. We propose two algorithms for this knowledge representation task: an exact method based on Integer Programming (IP) and an efficient Heuristic Search (HS). Through extensive experiments on a simulated aerial imagery dataset featuring controlled, complex distributional shifts, we demonstrate that our abduction-based framework outperforms individual models and standard ensemble baselines, achieving, for instance, average relative improvements of approximately 13.6% in F1-score and 16.6% in accuracy across 15 diverse test datasets when compared to the best individual model. Our results validate the use of consistency-based abduction as an effective mechanism to robustly integrate knowledge from multiple imperfect reasoners in challenging, novel scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19361v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Leiva, Noel Ngu, Joshua Shay Kricheli, Aditya Taparia, Ransalu Senanayake, Paulo Shakarian, Nathaniel Bastian, John Corcoran, Gerardo Simari</dc:creator>
    </item>
    <item>
      <title>Alpay Algebra III: Observer-Coupled Collapse and the Temporal Drift of Identity</title>
      <link>https://arxiv.org/abs/2505.19790</link>
      <description>arXiv:2505.19790v1 Announce Type: cross 
Abstract: This paper introduces a formal framework for modeling observer-dependent collapse dynamics and temporal identity drift within artificial and mathematical systems, grounded entirely in the symbolic foundations of Alpay Algebra. Building upon the fixed-point emergence structures developed in Alpay Algebra I and II, this third installment formalizes the observer-coupled {\phi}-collapse process through transfinite categorical flows and curvature-driven identity operators. We define a novel temporal drift mechanism as a recursive deformation of identity signatures under entangled observer influence, constructing categorical invariants that evolve across fold iterations. The proposed system surpasses conventional identity modeling in explainable AI (XAI) by encoding internal transformation history into a symbolic fixed-point structure, offering provable traceability and temporal coherence. Applications range from AI self-awareness architectures to formal logic systems where identity is not static but dynamically induced by observation. The theoretical results also offer a mathematically rigorous basis for future AI systems with stable self-referential behavior, positioning Alpay Algebra as a next-generation symbolic framework bridging category theory, identity logic, and observer dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19790v1</guid>
      <category>math.CT</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faruk Alpay</dc:creator>
    </item>
    <item>
      <title>Logic Gate Neural Networks are Good for Verification</title>
      <link>https://arxiv.org/abs/2505.19932</link>
      <description>arXiv:2505.19932v1 Announce Type: cross 
Abstract: Learning-based systems are increasingly deployed across various domains, yet the complexity of traditional neural networks poses significant challenges for formal verification. Unlike conventional neural networks, learned Logic Gate Networks (LGNs) replace multiplications with Boolean logic gates, yielding a sparse, netlist-like architecture that is inherently more amenable to symbolic verification, while still delivering promising performance. In this paper, we introduce a SAT encoding for verifying global robustness and fairness in LGNs. We evaluate our method on five benchmark datasets, including a newly constructed 5-class variant, and find that LGNs are both verification-friendly and maintain strong predictive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19932v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Fabian Kresse, Emily Yu, Christoph H. Lampert, Thomas A. Henzinger</dc:creator>
    </item>
    <item>
      <title>Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks</title>
      <link>https://arxiv.org/abs/2505.20047</link>
      <description>arXiv:2505.20047v1 Announce Type: cross 
Abstract: Large language models (LLMs) show remarkable promise for democratizing automated reasoning by generating formal specifications. However, a fundamental tension exists: LLMs are probabilistic, while formal verification demands deterministic guarantees. This paper addresses this epistemological gap by comprehensively investigating failure modes and uncertainty quantification (UQ) in LLM-generated formal artifacts. Our systematic evaluation of five frontier LLMs reveals Satisfiability Modulo Theories (SMT) based autoformalization's domain-specific impact on accuracy (from +34.8% on logical tasks to -44.5% on factual ones), with known UQ techniques like the entropy of token probabilities failing to identify these errors. We introduce a probabilistic context-free grammar (PCFG) framework to model LLM outputs, yielding a refined uncertainty taxonomy. We find uncertainty signals are task-dependent (e.g., grammar entropy for logic, AUROC&gt;0.93). Finally, a lightweight fusion of these signals enables selective verification, drastically reducing errors (14-100%) with minimal abstention, transforming LLM-driven formalization into a reliable engineering discipline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20047v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debargha Ganguly, Vikash Singh, Sreehari Sankar, Biyao Zhang, Xuecen Zhang, Srinivasan Iyengar, Xiaotian Han, Amit Sharma, Shivkumar Kalyanaraman, Vipin Chaudhary</dc:creator>
    </item>
    <item>
      <title>On Propositional Dynamic Logic and Concurrency</title>
      <link>https://arxiv.org/abs/2403.18508</link>
      <description>arXiv:2403.18508v3 Announce Type: replace 
Abstract: Dynamic logic is a powerful approach to reasoning about programs and their executions, obtained by extending classical logic with modalities that can express program executions as formulas. However, the use of dynamic logic in the setting of concurrency has proved problematic because of the challenge of capturing interleaving. This challenge stems from the fact that, traditionally, programs are represented by their sets of traces. These sets are then expressed as elements of a Kleene algebra, for which it is not possible to decide equality in the presence of the commutations required to model interleaving.
  In this work, we generalise propositional dynamic logic (PDL) to a logic framework we call operational propositional dynamic logic (OPDL), which departs from tradition by distinguishing programs from their traces. Traces are generated by an arbitrary operational semantics that we take as a parameter, making our approach applicable to different program syntaxes and semantics. To develop our framework, we provide the first proof of cut-elimination for a finitely-branching non-wellfounded sequent calculus for PDL. Thanks to this result we can effortlessly prove adequacy for PDL, and extend these results to OPDL. We conclude by discussing OPDL for two representative cases of concurrency: the Calculus of Communicating Systems (CCS), where interleaving is obtained by parallel composition, and Choreographic Programming, where interleaving is obtained by out-of-order execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18508v3</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Acclavio, Fabrizio Montesi, Marco Peressotti</dc:creator>
    </item>
    <item>
      <title>Formulas as Processes, Deadlock-Freedom as Choreographies (Extended Version)</title>
      <link>https://arxiv.org/abs/2501.08928</link>
      <description>arXiv:2501.08928v2 Announce Type: replace 
Abstract: We introduce a novel approach to studying properties of processes in the {\pi}-calculus based on a processes-as-formulas interpretation, by establishing a correspondence between specific sequent calculus derivations and computation trees in the reduction semantics of the recursion-free {\pi}-calculus. Our method provides a simple logical characterisation of deadlock-freedom for the recursion- and race-free fragment of the {\pi}-calculus, supporting key features such as cyclic dependencies and an independence of the name restriction and parallel operators. Based on this technique, we establish a strong completeness result for a nontrivial choreographic language: all deadlock-free and race-free finite {\pi}-calculus processes composed in parallel at the top level can be faithfully represented by a choreography. With these results, we show how the paradigm of computation-as-derivation extends the reach of logical methods for the study of concurrency, by bridging important gaps between logic, the expressiveness of the {\pi}-calculus, and the expressiveness of choreographic languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08928v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-91118-7_2</arxiv:DOI>
      <arxiv:journal_reference>In: Vafeiadis, V. (eds) Programming Languages and Systems. ESOP 2025. Lecture Notes in Computer Science, vol 15694</arxiv:journal_reference>
      <dc:creator>Matteo Acclavio, Giulia Manara, Fabrizio Montesi</dc:creator>
    </item>
    <item>
      <title>Entailment vs. Verification for Partial-assignment Satisfiability and Enumeration</title>
      <link>https://arxiv.org/abs/2503.01536</link>
      <description>arXiv:2503.01536v2 Announce Type: replace 
Abstract: Many procedures for SAT-related problems, in particular for those requiring the complete enumeration of satisfying truth assignments, rely their efficiency and effectiveness on the detection of (possibly small) partial assignments satisfying an input formula. Surprisingly, there seems to be no unique universally-agreed definition of formula satisfaction by a partial assignment in the literature. In this paper we analyze in deep the issue of satisfaction by partial assignments, raising a flag about some ambiguities and subtleties of this concept, and investigating their practical consequences. We identify two alternative notions that are implicitly used in the literature, namely verification and entailment, which coincide if applied to CNF formulas but differ and present complementary properties if applied to non-CNF or to existentially-quantified formulas. We show that, although the former is easier to check and as such is implicitly used by most current search procedures, the latter has better theoretical properties, and can improve the efficiency and effectiveness of enumeration procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01536v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Sebastiani</dc:creator>
    </item>
    <item>
      <title>Inclusion with repetitions and Boolean constants -- implication problems revisited</title>
      <link>https://arxiv.org/abs/2503.20647</link>
      <description>arXiv:2503.20647v2 Announce Type: replace 
Abstract: Inclusion dependencies form one of the most widely used dependency classes. We extend existing results on the axiomatization and computational complexity of their implication problem to two extended variants. We present an alternative completeness proof for standard inclusion dependencies and extend it to inclusion dependencies with repetitions that can express equalities between attributes. The proof uses only two values, enabling us to work in the Boolean setting. Furthermore, we study inclusion dependencies with Boolean constants, provide a complete axiomatization and show that no such system is k-ary. Additionally, the decision problems for both extended versions remain PSPACE-complete. The extended inclusion dependencies examined are common in team semantics, which serves as the formal framework for the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20647v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matilda H\"aggblom</dc:creator>
    </item>
    <item>
      <title>Lean-auto: An Interface between Lean 4 and Automated Theorem Provers</title>
      <link>https://arxiv.org/abs/2505.14929</link>
      <description>arXiv:2505.14929v2 Announce Type: replace 
Abstract: Proof automation is crucial to large-scale formal mathematics and software/hardware verification projects in ITPs. Sophisticated tools called hammers have been developed to provide general-purpose proof automation in ITPs such as Coq and Isabelle, leveraging the power of ATPs. An important component of a hammer is the translation algorithm from the ITP's logical system to the ATP's logical system. In this paper, we propose a novel translation algorithm for ITPs based on dependent type theory. The algorithm is implemented in Lean 4 under the name Lean-auto. When combined with ATPs, Lean-auto provides general-purpose, ATP-based proof automation in Lean 4 for the first time. Soundness of the main translation procedure is guaranteed, and experimental results suggest that our algorithm is sufficiently complete to automate the proof of many problems that arise in practical uses of Lean 4. We also find that Lean-auto solves more problems than existing tools on Lean 4's math library Mathlib4.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14929v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yicheng Qian, Joshua Clune, Clark Barrett, Jeremy Avigad</dc:creator>
    </item>
    <item>
      <title>Owicki--Gries Logic for Timestamp Semantics</title>
      <link>https://arxiv.org/abs/2505.15053</link>
      <description>arXiv:2505.15053v2 Announce Type: replace 
Abstract: Whereas an extension with non-interference of Hoare logic for sequential programs Owicki--Gries logic ensures the correctness of concurrent programs on strict consistency, it is unsound to weak memory models adopted by modern computer architectures and specifications of programming languages. This paper proposes a novel non-interference notion and provides concurrent program logic sound to timestamp semantics corresponding to a weak memory model that allows delays in the effects of store instructions. This paper reports three theoretically interesting techniques for modifying non-interference to support delays in the effects of store instructions. The techniques contribute to a better understanding of constructing concurrent program logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15053v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatsuya Abe</dc:creator>
    </item>
    <item>
      <title>HornStr: Invariant Synthesis for Regular Model Checking as Constrained Horn Clauses(Technical Report)</title>
      <link>https://arxiv.org/abs/2505.15959</link>
      <description>arXiv:2505.15959v2 Announce Type: replace 
Abstract: We present HornStr, the first solver for invariant synthesis for Regular Model Checking (RMC) with the specification provided in the SMT-LIB 2.6 theory of strings. It is well-known that invariant synthesis for RMC subsumes various important verification problems, including safety verification for parameterized systems. To achieve a simple and standardized file format, we treat the invariant synthesis problem as a problem of solving Constrained Horn Clauses (CHCs) over strings. Two strategies for synthesizing invariants in terms of regular constraints are supported: (1) L* automata learning, and (2) SAT-based automata learning. HornStr implements these strategies with the help of existing SMT solvers for strings, which are interfaced through SMT-LIB. HornStr provides an easy-to-use interface for string solver developers to apply their techniques to verification. At the same time, it allows verification researchers to painlessly tap into the wealth of modern string solving techniques. To assess the effectiveness of HornStr, we conducted a comprehensive evaluation using benchmarks derived from applications including parameterized verification and string rewriting tasks. Our experiments highlight HornStr's capacity to effectively handle these benchmarks, e.g., as the first solver to verify the challenging MU puzzle automatically. Finally, HornStr can be used to automatically generate a new class of interesting SMT-LIB 2.6 string constraint benchmarks, which might in the future be used in the SMT-COMP strings track. In particular, our experiments on the above invariant synthesis benchmarks produce more than 30000 new QF_S constraints. We also detail the performance of various integrated string solvers, providing insights into their effectiveness on our new benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15959v2</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjian Jiang, Anthony W. Lin, Oliver Markgraf, Philipp R\"ummer, Daniel Stan</dc:creator>
    </item>
    <item>
      <title>Notes on CSPs and Polymorphisms</title>
      <link>https://arxiv.org/abs/2210.07383</link>
      <description>arXiv:2210.07383v2 Announce Type: replace-cross 
Abstract: These are notes from a multi-year learning seminar on the algebraic approach to Constraint Satisfaction Problems (CSPs). The main topics covered are the theory of algebraic structures with few subpowers, the theory of absorbing subalgebras and its applications to studying CSP templates which can be solved by local consistency methods, and the dichotomy theorem for conservative CSP templates. Subsections and appendices cover supplementary material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.07383v2</guid>
      <category>math.RA</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zarathustra Brady</dc:creator>
    </item>
    <item>
      <title>Portus: Linking Alloy with SMT-based Finite Model Finding</title>
      <link>https://arxiv.org/abs/2411.15978</link>
      <description>arXiv:2411.15978v2 Announce Type: replace-cross 
Abstract: Alloy is a well-known, formal, declarative language for modelling systems early in the software development process. Currently, it uses the Kodkod library as a back-end for finite model finding. Kodkod translates the model to a SAT problem; however, this method can often handle only problems of fairly low-size sets and is inherently finite. We present Portus, a method for translating Alloy into an equivalent many-sorted first-order logic problem (MSFOL). Once in MSFOL, the problem can be evaluated by an SMT-based finite model finding method implemented in the Fortress library, creating an alternative back-end for the Alloy Analyzer. Fortress converts the MSFOL finite model finding problem into the logic of uninterpreted functions with equality (EUF), a decidable fragment of first-order logic that is well-supported in many SMT solvers. We compare the performance of Portus with Kodkod on a corpus of 64 Alloy models written by experts. Our method is fully integrated into the Alloy Analyzer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15978v2</guid>
      <category>cs.SE</category>
      <category>cs.LO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Dancy, Nancy A. Day, Owen Zila, Khadija Tariq, Joseph Poremba</dc:creator>
    </item>
    <item>
      <title>CLEVER: A Curated Benchmark for Formally Verified Code Generation</title>
      <link>https://arxiv.org/abs/2505.13938</link>
      <description>arXiv:2505.13938v3 Announce Type: replace-cross 
Abstract: We introduce ${\rm C{\small LEVER}}$, a high-quality, curated benchmark of 161 problems for end-to-end verified code generation in Lean. Each problem consists of (1) the task of generating a specification that matches a held-out ground-truth specification, and (2) the task of generating a Lean implementation that provably satisfies this specification. Unlike prior benchmarks, ${\rm C{\small LEVER}}$ avoids test-case supervision, LLM-generated annotations, and specifications that leak implementation logic or allow vacuous solutions. All outputs are verified post-hoc using Lean's type checker to ensure machine-checkable correctness. We use ${\rm C{\small LEVER}}$ to evaluate several few-shot and agentic approaches based on state-of-the-art language models. These methods all struggle to achieve full verification, establishing it as a challenging frontier benchmark for program synthesis and formal reasoning. Our benchmark can be found on GitHub(https://github.com/trishullab/clever) as well as HuggingFace(https://huggingface.co/datasets/amitayusht/clever). All our evaluation code is also available online(https://github.com/trishullab/clever-prover).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13938v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amitayush Thakur, Jasper Lee, George Tsoukalas, Meghana Sistla, Matthew Zhao, Stefan Zetzsche, Greg Durrett, Yisong Yue, Swarat Chaudhuri</dc:creator>
    </item>
  </channel>
</rss>
