<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 02:36:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Elastic-Net estimation for sparse diffusion processes</title>
      <link>https://arxiv.org/abs/2412.16659</link>
      <description>arXiv:2412.16659v1 Announce Type: new 
Abstract: Penalized estimation methods for diffusion processes and dependent data have recently gained significant attention due to their effectiveness in handling high-dimensional stochastic systems. In this work, we introduce an adaptive Elastic-Net estimator for ergodic diffusion processes observed under high-frequency sampling schemes. Our method combines the least squares approximation of the quasi-likelihood with adaptive $\ell_1$ and $\ell_2$ regularization. This approach allows to enhance prediction accuracy and interpretability while effectively recovering the sparse underlying structure of the model.
  In the spirit of analyzing high-dimensional scenarios, we provide finite-sample guarantees for the (block-diagonal) estimator's performance by deriving high-probability non-asymptotic bounds for the $\ell_2$ estimation error. These results complement the established oracle properties in the high-frequency asymptotic regime with mixed convergence rates, ensuring consistent selection of the relevant interactions and achieving optimal rates of convergence. Furthermore, we utilize our results to analyze one-step-ahead predictions, offering non-asymptotic control over the $\ell_1$ prediction error.
  The performance of our method is evaluated through simulations and real data applications, demonstrating its effectiveness, particularly in scenarios with strongly correlated variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16659v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro De Gregorio, Dario Frisardi, Francesco Iafrate, Stefano Iacus</dc:creator>
    </item>
    <item>
      <title>Gaussian and Bootstrap Approximation for Matching-based Average Treatment Effect Estimators</title>
      <link>https://arxiv.org/abs/2412.17181</link>
      <description>arXiv:2412.17181v1 Announce Type: new 
Abstract: We establish Gaussian approximation bounds for covariate and rank-matching-based Average Treatment Effect (ATE) estimators. By analyzing these estimators through the lens of stabilization theory, we employ the Malliavin-Stein method to derive our results. Our bounds precisely quantify the impact of key problem parameters, including the number of matches and treatment balance, on the accuracy of the Gaussian approximation. Additionally, we develop multiplier bootstrap procedures to estimate the limiting distribution in a fully data-driven manner, and we leverage the derived Gaussian approximation results to further obtain bootstrap approximation bounds. Our work not only introduces a novel theoretical framework for commonly used ATE estimators, but also provides data-driven methods for constructing non-asymptotically valid confidence intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17181v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoyang Shi, Chinmoy Bhattacharjee, Krishnakumar Balasubramanian, Wolfgang Polonik</dc:creator>
    </item>
    <item>
      <title>A Necessary and Sufficient Condition for Size Controllability of Heteroskedasticity Robust Test Statistics</title>
      <link>https://arxiv.org/abs/2412.17470</link>
      <description>arXiv:2412.17470v1 Announce Type: new 
Abstract: We revisit size controllability results in P\"otscher and Preinerstorfer (2021) concerning heteroskedasticity robust test statistics in regression models. For the special, but important, case of testing a single restriction (e.g., a zero restriction on a single coefficient), we povide a necessary and sufficient condition for size controllability, whereas the condition in P\"otscher and Preinerstorfer (2021) is, in general, only sufficient (even in the case of testing a single restriction).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17470v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benedikt M. P\"otscher, David Preinerstorfer</dc:creator>
    </item>
    <item>
      <title>Statistical Learning Theory for Neural Operators</title>
      <link>https://arxiv.org/abs/2412.17582</link>
      <description>arXiv:2412.17582v1 Announce Type: new 
Abstract: We present statistical convergence results for the learning of (possibly) non-linear mappings in infinite-dimensional spaces. Specifically, given a map $G_0:\mathcal X\to\mathcal Y$ between two separable Hilbert spaces, we analyze the problem of recovering $G_0$ from $n\in\mathbb N$ noisy input-output pairs $(x_i, y_i)_{i=1}^n$ with $y_i = G_0 (x_i)+\varepsilon_i$; here the $x_i\in\mathcal X$ represent randomly drawn 'design' points, and the $\varepsilon_i$ are assumed to be either i.i.d. white noise processes or subgaussian random variables in $\mathcal{Y}$. We provide general convergence results for least-squares-type empirical risk minimizers over compact regression classes $\mathbf G\subseteq L^\infty(X,Y)$, in terms of their approximation properties and metric entropy bounds, which are derived using empirical process techniques. This generalizes classical results from finite-dimensional nonparametric regression to an infinite-dimensional setting. As a concrete application, we study an encoder-decoder based neural operator architecture termed FrameNet. Assuming $G_0$ to be holomorphic, we prove algebraic (in the sample size $n$) convergence rates in this setting, thereby overcoming the curse of dimensionality. To illustrate the wide applicability, as a prototypical example we discuss the learning of the non-linear solution operator to a parametric elliptic partial differential equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17582v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niklas Reinhardt, Sven Wang, Jakob Zech</dc:creator>
    </item>
    <item>
      <title>Bivariate Matrix-valued Linear Regression (BMLR): Finite-sample performance under Identifiability and Sparsity Assumptions</title>
      <link>https://arxiv.org/abs/2412.17749</link>
      <description>arXiv:2412.17749v2 Announce Type: new 
Abstract: This study explores the estimation of parameters in a matrix-valued linear regression model, where the $T$ responses $(Y_t)_{t=1}^T \in \mathbb{R}^{n \times p}$ and predictors $(X_t)_{t=1}^T \in \mathbb{R}^{m \times q}$ satisfy the relationship $Y_t = A^* X_t B^* + E_t$ for all $t = 1, \ldots, T$. In this model, $A^* \in \mathbb{R}_+^{n \times m}$ has $L_1$-normalized rows, $B^* \in \mathbb{R}^{q \times p}$, and $(E_t)_{t=1}^T$ are independent noise matrices following a matrix Gaussian distribution. The primary objective is to estimate the unknown parameters $A^*$ and $B^*$ efficiently.
  We propose explicit optimization-free estimators and establish non-asymptotic convergence rates to quantify their performance. Additionally, we extend our analysis to scenarios where $A^*$ and $B^*$ exhibit sparse structures. To support our theoretical findings, we conduct numerical simulations that confirm the behavior of the estimators, particularly with respect to the impact of the dimensions $n, m, p, q$, and the sample size $T$ on finite-sample performances. We complete the simulations by investigating the denoising performances of our estimators on noisy real-world images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17749v2</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nayel Bettache</dc:creator>
    </item>
    <item>
      <title>To Study Properties of a Known Procedure in Adaptive Sequential Sampling Design</title>
      <link>https://arxiv.org/abs/2412.17791</link>
      <description>arXiv:2412.17791v1 Announce Type: new 
Abstract: We revisit the procedure proposed by Bhandari et al. (2009) in the context of two-treatment clinical trials, with the objective of minimizing the applications of a less effective drug to the least number of patients. Our focus is on an adaptive sequential procedure that is both simple and intuitive. Our findings show that the expected number of applications of the less effective drug remains finite. In contrast, Bhandari et al. (2009) observed that this number increases logarithmically with the total sample size. We attribute this discrepancy to differences in their choice of starting sample size and the method of analysis employed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17791v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sampurna Kundu, Jayant Jha, Subir Kumar Bhandari</dc:creator>
    </item>
    <item>
      <title>Low-rank matrix recovery via nonconvex optimization methods with application to errors-in-variables matrix regression</title>
      <link>https://arxiv.org/abs/2412.16263</link>
      <description>arXiv:2412.16263v1 Announce Type: cross 
Abstract: We consider the nonconvex regularized method for low-rank matrix recovery. Under the assumption on the singular values of the parameter matrix, we provide the recovery bound for any stationary point of the nonconvex method by virtue of regularity conditions on the nonconvex loss function and the regularizer. This recovery bound can be much tighter than that of the convex nuclear norm regularized method when some of the singular values are larger than a threshold defined by the nonconvex regularizer. In addition, we consider the errors-in-variables matrix regression as an application of the nonconvex optimization method. Probabilistic consequences and the advantage of the nonoconvex method are demonstrated through verifying the regularity conditions for specific models with additive noise and missing data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16263v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Dongya Wu</dc:creator>
    </item>
    <item>
      <title>Sharp Results for Hypothesis Testing with Risk-Sensitive Agents</title>
      <link>https://arxiv.org/abs/2412.16452</link>
      <description>arXiv:2412.16452v1 Announce Type: cross 
Abstract: Statistical protocols are often used for decision-making involving multiple parties, each with their own incentives, private information, and ability to influence the distributional properties of the data. We study a game-theoretic version of hypothesis testing in which a statistician, also known as a principal, interacts with strategic agents that can generate data. The statistician seeks to design a testing protocol with controlled error, while the data-generating agents, guided by their utility and prior information, choose whether or not to opt in based on expected utility maximization. This strategic behavior affects the data observed by the statistician and, consequently, the associated testing error. We analyze this problem for general concave and monotonic utility functions and prove an upper bound on the Bayes false discovery rate (FDR). Underlying this bound is a form of prior elicitation: we show how an agent's choice to opt in implies a certain upper bound on their prior null probability. Our FDR bound is unimprovable in a strong sense, achieving equality at a single point for an individual agent and at any countable number of points for a population of agents. We also demonstrate that our testing protocols exhibit a desirable maximin property when the principal's utility is considered. To illustrate the qualitative predictions of our theory, we examine the effects of risk aversion, reward stochasticity, and signal-to-noise ratio, as well as the implications for the Food and Drug Administration's testing protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16452v1</guid>
      <category>stat.ME</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flora C. Shi, Stephen Bates, Martin J. Wainwright</dc:creator>
    </item>
    <item>
      <title>Robust random graph matching in dense graphs via vector approximate message passing</title>
      <link>https://arxiv.org/abs/2412.16457</link>
      <description>arXiv:2412.16457v1 Announce Type: cross 
Abstract: In this paper, we focus on the matching recovery problem between a pair of correlated Gaussian Wigner matrices with a latent vertex correspondence. We are particularly interested in a robust version of this problem such that our observation is a perturbed input $(A+E,B+F)$ where $(A,B)$ is a pair of correlated Gaussian Wigner matrices and $E,F$ are adversarially chosen matrices supported on an unknown $\epsilon n * \epsilon n$ principle minor of $A,B$, respectively. We propose a vector-approximate message passing (vector-AMP) algorithm that succeeds in polynomial time as long as the correlation $\rho$ between $(A,B)$ is a non-vanishing constant and $\epsilon = o\big( \tfrac{1}{(\log n)^{20}} \big)$.
  The main methodological inputs for our result are the iterative random graph matching algorithm proposed in \cite{DL22+, DL23+} and the spectral cleaning procedure proposed in \cite{IS24+}. To the best of our knowledge, our algorithm is the first efficient random graph matching type algorithm that is robust under any adversarial perturbations of $n^{1-o(1)}$ size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16457v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>MATES: Multi-view Aggregated Two-Sample Test</title>
      <link>https://arxiv.org/abs/2412.16684</link>
      <description>arXiv:2412.16684v1 Announce Type: cross 
Abstract: The two-sample test is a fundamental problem in statistics with a wide range of applications. In the realm of high-dimensional data, nonparametric methods have gained prominence due to their flexibility and minimal distributional assumptions. However, many existing methods tend to be more effective when the two distributions differ primarily in their first and/or second moments. In many real-world scenarios, distributional differences may arise in higher-order moments, rendering traditional methods less powerful. To address this limitation, we propose a novel framework to aggregate information from multiple moments to build a test statistic. Each moment is regarded as one view of the data and contributes to the detection of some specific type of discrepancy, thus allowing the test statistic to capture more complex distributional differences. The novel multi-view aggregated two-sample test (MATES) leverages a graph-based approach, where the test statistic is constructed from the weighted similarity graphs of the pooled sample. Under mild conditions on the multi-view weighted similarity graphs, we establish theoretical properties of MATES, including a distribution-free limiting distribution under the null hypothesis, which enables straightforward type-I error control. Extensive simulation studies demonstrate that MATES effectively distinguishes subtle differences between distributions. We further validate the method on the S&amp;P100 data, showcasing its power in detecting complex distributional variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16684v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexi Cai, Wenbo Fei, Doudou Zhou</dc:creator>
    </item>
    <item>
      <title>Exploring the Multifractal Behavior of the Human Genome T2T-CHM13v2.0: Graphical Representations and Cytogenetics</title>
      <link>https://arxiv.org/abs/2412.16705</link>
      <description>arXiv:2412.16705v1 Announce Type: cross 
Abstract: In this work, we applied the Chaos Game Representation (CGR) to the complete human genomic sequence T2T-CHM13v2.0, analyzing the entire chromosome assembly and each chromosome separately, including mitochondrial DNA. Multifractal spectra were determined using two types of box-counting coverage, revealing slight variations across most chromosomes. While the geometric support remained consistent, distinct distributions were observed for each chromosome. Chromosomes 9 and Y exhibited the greatest differences in singularity (H\"older exponent), with minor variations in their fractal support. The CGR distributions generally demonstrated an approximate separation between coding and non-coding sections, as well as CpG or GpC islands. A base-by-base analysis of the fractal support of the CGR uncovered characteristic structural bands in chromosome sequences, which align with patterns identified in cytogenetic studies. Using the complete assembly as a reference, we compared two alternative representations: the Binary Genomic Representation (RGB) and the Markov Chain (MC) representation. Both methods tended toward the same fractal support but displayed differing distributions based on the assigned length parameter. Multifractal analysis highlighted quantitative differences between these representations: RGB aligned more closely with high-frequency components, while MC showed better correspondence with low frequencies. The optimal fit was achieved using MC for twelve-base chains, yielding an average percentage error of 2% relative to the full genomic assembly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16705v1</guid>
      <category>q-bio.OT</category>
      <category>math.DS</category>
      <category>math.ST</category>
      <category>nlin.CD</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuli\'an A. Alvarez-Ballesteros, Mario A. Quiroz-Juarez, Jos\'e L. Del-Rio-Correa, Adrian M. Escobar-Ruiz</dc:creator>
    </item>
    <item>
      <title>A Parameter-Efficient Quantum Anomaly Detection Method on a Superconducting Quantum Processor</title>
      <link>https://arxiv.org/abs/2412.16867</link>
      <description>arXiv:2412.16867v1 Announce Type: cross 
Abstract: Quantum machine learning has gained attention for its potential to address computational challenges. However, whether those algorithms can effectively solve practical problems and outperform their classical counterparts, especially on current quantum hardware, remains a critical question. In this work, we propose a novel quantum machine learning method, called Quantum Support Vector Data Description (QSVDD), for practical anomaly detection, which aims to achieve both parameter efficiency and superior accuracy compared to classical models. Emulation results indicate that QSVDD demonstrates favourable recognition capabilities compared to classical baselines, achieving an average accuracy of over 90% on benchmarks with significantly fewer trainable parameters. Theoretical analysis confirms that QSVDD has a comparable expressivity to classical counterparts while requiring only a fraction of the parameters. Furthermore, we demonstrate the first implementation of a quantum machine learning method for anomaly detection on a superconducting quantum processor. Specifically, we achieve an accuracy of over 80% with only 16 parameters on the device, providing initial evidence of QSVDD's practical viability in the noisy intermediate-scale quantum era and highlighting its significant reduction in parameter requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16867v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maida Wang, Jinyang Jiang, Peter V. Coveney</dc:creator>
    </item>
    <item>
      <title>Mixing phases of the Glauber dynamics for the $p$-spin Curie-Weiss model</title>
      <link>https://arxiv.org/abs/2412.16952</link>
      <description>arXiv:2412.16952v1 Announce Type: cross 
Abstract: The Glauber dynamics for the classical $2$-spin Curie-Weiss model on $N$ nodes with inverse temperature $\beta$ and zero external field is known to mix in time $\Theta(N\log N)$ for $\beta &lt; \frac{1}{2}$, in time $\Theta(N^{3/2})$ at $\beta = \frac{1}{2}$, and in time $\exp(\Omega(N))$ for $\beta &gt;\frac{1}{2}$. In this paper, we consider the $p$-spin generalization of the Curie-Weiss model with an external field $h$, and identify three disjoint regions almost exhausting the parameter space, with the corresponding Glauber dynamics exhibiting three different orders of mixing times in these regions. The construction of these disjoint regions depends on the number of local maximizers of a certain function $H_{\beta,h,p}$, and the behavior of the second derivative of $H_{\beta,h,p}$ at such a local maximizer. Specifically, we show that if $H_{\beta,h,p}$ has a unique local maximizer $m_*$ with $H_{\beta,h,p}''(m_*) &lt; 0$ and no other stationary point, then the Glauber dynamics mixes in time $\Theta(N\log N)$, and if $H_{\beta,h,p}$ has multiple local maximizers, then the mixing time is $\exp(\Omega(N))$. Finally, if $H_{\beta,h,p}$ has a unique local maximizer $m_*$ with $H_{\beta,h,p}''(m_*) = 0$, then the mixing time is $\Theta(N^{3/2})$. We provide an explicit description of the geometry of these three different phases in the parameter space, and observe that the only portion of the parameter plane that is left out by the union of these three regions, is a one-dimensional curve, on which the function $H_{\beta,h,p}$ has a stationary inflection point. Finding out the exact order of the mixing time on this curve remains an open question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16952v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ramkrishna Jyoti Samanta, Somabha Mukherjee, Jiang Zhang</dc:creator>
    </item>
    <item>
      <title>Low Rank Convex Clustering For Matrix-Valued Observations</title>
      <link>https://arxiv.org/abs/2412.17328</link>
      <description>arXiv:2412.17328v1 Announce Type: cross 
Abstract: Common clustering methods, such as $k$-means and convex clustering, group similar vector-valued observations into clusters. However, with the increasing prevalence of matrix-valued observations, which often exhibit low rank characteristics, there is a growing need for specialized clustering techniques for these data types. In this paper, we propose a low rank convex clustering model tailored for matrix-valued observations. Our approach extends the convex clustering model originally designed for vector-valued data to classify matrix-valued observations. Additionally, it serves as a convex relaxation of the low rank $k$-means method proposed by Z. Lyu, and D. Xia (arXiv:2207.04600). Theoretically, we establish exact cluster recovery for finite samples and asymptotic cluster recovery as the sample size approaches infinity. We also give a finite sample bound on prediction error in terms of centroid estimation, and further establish the prediction consistency. To make the model practically useful, we develop an efficient double-loop algorithm for solving it. Extensive numerical experiments are conducted to show the effectiveness of our proposed model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17328v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meixia Lin, Yangjing Zhang</dc:creator>
    </item>
    <item>
      <title>Growth-Optimal E-Variables and an extension to the multivariate Csisz\'ar-Sanov-Chernoff Theorem</title>
      <link>https://arxiv.org/abs/2412.17554</link>
      <description>arXiv:2412.17554v1 Announce Type: cross 
Abstract: We consider growth-optimal e-variables with maximal e-power, both in an absolute and relative sense, for simple null hypotheses for a $d$-dimensional random vector, and multivariate composite alternatives represented as a set of $d$-dimensional means $\meanspace_1$. These include, among others, the set of all distributions with mean in $\meanspace_1$, and the exponential family generated by the null restricted to means in $\meanspace_1$. We show how these optimal e-variables are related to Csisz\'ar-Sanov-Chernoff bounds, first for the case that $\meanspace_1$ is convex (these results are not new; we merely reformulate them) and then for the case that $\meanspace_1$ `surrounds' the null hypothesis (these results are new).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17554v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Gr\"unwald, Yunda Hao, Akshay Balsubramani</dc:creator>
    </item>
    <item>
      <title>Minimax Optimal Simple Regret in Two-Armed Best-Arm Identification</title>
      <link>https://arxiv.org/abs/2412.17753</link>
      <description>arXiv:2412.17753v1 Announce Type: cross 
Abstract: This study investigates an asymptotically minimax optimal algorithm in the two-armed fixed-budget best-arm identification (BAI) problem. Given two treatment arms, the objective is to identify the arm with the highest expected outcome through an adaptive experiment. We focus on the Neyman allocation, where treatment arms are allocated following the ratio of their outcome standard deviations. Our primary contribution is to prove the minimax optimality of the Neyman allocation for the simple regret, defined as the difference between the expected outcomes of the true best arm and the estimated best arm. Specifically, we first derive a minimax lower bound for the expected simple regret, which characterizes the worst-case performance achievable under the location-shift distributions, including Gaussian distributions. We then show that the simple regret of the Neyman allocation asymptotically matches this lower bound, including the constant term, not just the rate in terms of the sample size, under the worst-case distribution. Notably, our optimality result holds without imposing locality restrictions on the distribution, such as the local asymptotic normality. Furthermore, we demonstrate that the Neyman allocation reduces to the uniform allocation, i.e., the standard randomized controlled trial, under Bernoulli distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17753v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Ergodic Network Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2412.17779</link>
      <description>arXiv:2412.17779v1 Announce Type: cross 
Abstract: We propose a novel framework for Network Stochastic Differential Equations (N-SDE), where each node in a network is governed by an SDE influenced by interactions with its neighbors. The evolution of each node is driven by the interplay of three key components: the node's intrinsic dynamics (\emph{momentum effect}), feedback from neighboring nodes (\emph{network effect}), and a \emph{stochastic volatility} term modeled by Brownian motion.
  Our primary objective is to estimate the parameters of the N-SDE system from high-frequency discrete-time observations. The motivation behind this model lies in its ability to analyze very high-dimensional time series by leveraging the inherent sparsity of the underlying network graph.
  We consider two distinct scenarios: \textit{i) known network structure}: the graph is fully specified, and we establish conditions under which the parameters can be identified, considering the quadratic growth of the parameter space with the number of edges. \textit{ii) unknown network structure}: the graph must be inferred from the data. For this, we develop an iterative procedure using adaptive Lasso, tailored to a specific subclass of N-SDE models. In this work, we assume the network graph is oriented, paving the way for novel applications of SDEs in causal inference, enabling the study of cause-effect relationships in dynamic systems.
  Through extensive simulation studies, we demonstrate the performance of our estimators across various graph topologies in high-dimensional settings. We also showcase the framework's applicability to real-world datasets, highlighting its potential for advancing the analysis of complex networked systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17779v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Francesco Iafrate, Stefano Iacus</dc:creator>
    </item>
    <item>
      <title>Motif Estimation via Subgraph Sampling: The Fourth Moment Phenomenon</title>
      <link>https://arxiv.org/abs/2011.03026</link>
      <description>arXiv:2011.03026v2 Announce Type: replace 
Abstract: Network sampling is an indispensable tool for understanding features of large complex networks where it is practically impossible to search over the entire graph. In this paper, we develop a framework for statistical inference for counting network motifs, such as edges, triangles, and wedges, in the widely used subgraph sampling model, where each vertex is sampled independently, and the subgraph induced by the sampled vertices is observed. We derive necessary and sufficient conditions for the consistency and the asymptotic normality of the natural Horvitz-Thompson (HT) estimator, which can be used for constructing confidence intervals and hypothesis testing for the motif counts based on the sampled graph. In particular, we show that the asymptotic normality of the HT estimator exhibits an interesting fourth-moment phenomenon, which asserts that the HT estimator (appropriately centered and rescaled) converges in distribution to the standard normal whenever its fourth-moment converges to 3 (the fourth-moment of the standard normal distribution). As a consequence, we derive the exact thresholds for consistency and asymptotic normality of the HT estimator in various natural graph ensembles, such as sparse graphs with bounded degree, Erdos-Renyi random graphs, random regular graphs, and dense graphons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.03026v2</guid>
      <category>math.ST</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1214/21-AOS2134</arxiv:DOI>
      <arxiv:journal_reference>Ann. Statist. 50(2): 987-1011 (April 2022)</arxiv:journal_reference>
      <dc:creator>Bhaswar B. Bhattacharya, Sayan Das, Sumit Mukherjee</dc:creator>
    </item>
    <item>
      <title>Non-asymptotic Properties of Generalized Mondrian Forests in Statistical Learning</title>
      <link>https://arxiv.org/abs/2406.00660</link>
      <description>arXiv:2406.00660v2 Announce Type: replace 
Abstract: Since the publication of Breiman (2001), Random Forests (RF) have been widely used in both regression and classification. Later on, other forests are also proposed and studied in literature and Mondrian Forests are notable examples built on the Mondrian process; see Lakshminarayanan et al. (2014). In this paper, we propose an ensemble estimator in general statistical learning based on Mondrian Forests, which can be regarded as an extension of RF. This general framework includes many common learning problems, such as least squares regression, least $\ell_1$ regression, quantile regression and classification. Under mild conditions of loss functions, we give the upper bound of the regret/risk function of this forest estimator and show that such estimator is also statistically consistent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00660v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Zhan, Jingli Wang, Yingcun Xia</dc:creator>
    </item>
    <item>
      <title>On the impossibility of detecting a late change-point in the preferential attachment random graph model</title>
      <link>https://arxiv.org/abs/2407.18685</link>
      <description>arXiv:2407.18685v3 Announce Type: replace 
Abstract: We consider the problem of late change-point detection under the preferential attachment random graph model with time dependent attachment function. This can be formulated as a hypothesis testing problem where the null hypothesis corresponds to a preferential attachment model with a constant affine attachment parameter $\delta_0$ and the alternative corresponds to a preferential attachment model where the affine attachment parameter changes from $\delta_0$ to $\delta_1$ at a time $\tau_n = n - \Delta_n$ where $0\leq \Delta_n \leq n$ and $n$ is the size of the graph. It was conjectured in Bet et al. that when observing only the unlabeled graph, detection of the change is not possible for $\Delta_n = o(n^{1/2})$. In this work, we make a step towards proving the conjecture by proving the impossibility of detecting the change when $\Delta_n = o(n^{1/3})$. We also study change-point detection in the case where the labeled graph is observed and show that change-point detection is possible if and only if $\Delta_n \to \infty$, thereby exhibiting a strong difference between the two settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18685v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim Kaddouri, Zacharie Naulet, \'Elisabeth Gassiat</dc:creator>
    </item>
    <item>
      <title>Unified Algorithms for RL with Decision-Estimation Coefficients: PAC, Reward-Free, Preference-Based Learning, and Beyond</title>
      <link>https://arxiv.org/abs/2209.11745</link>
      <description>arXiv:2209.11745v4 Announce Type: replace-cross 
Abstract: Modern Reinforcement Learning (RL) is more than just learning the optimal policy; Alternative learning goals such as exploring the environment, estimating the underlying model, and learning from preference feedback are all of practical importance. While provably sample-efficient algorithms for each specific goal have been proposed, these algorithms often depend strongly on the particular learning goal and thus admit different structures correspondingly. It is an urging open question whether these learning goals can rather be tackled by a single unified algorithm.
  We make progress on this question by developing a unified algorithm framework for a large class of learning goals, building on the Decision-Estimation Coefficient (DEC) framework. Our framework handles many learning goals such as no-regret RL, PAC RL, reward-free learning, model estimation, and preference-based learning, all by simply instantiating the same generic complexity measure called "Generalized DEC", and a corresponding generic algorithm. The generalized DEC also yields a sample complexity lower bound for each specific learning goal. As applications, we propose "decouplable representation" as a natural sufficient condition for bounding generalized DECs, and use it to obtain many new sample-efficient results (and recover existing results) for a wide range of learning goals and problem classes as direct corollaries. Finally, as a connection, we re-analyze two existing optimistic model-based algorithms based on Posterior Sampling and Maximum Likelihood Estimation, showing that they enjoy sample complexity bounds under similar structural conditions as the DEC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11745v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Chen, Song Mei, Yu Bai</dc:creator>
    </item>
    <item>
      <title>Data-Driven Tuning Parameter Selection for High-Dimensional Vector Autoregressions</title>
      <link>https://arxiv.org/abs/2403.06657</link>
      <description>arXiv:2403.06657v2 Announce Type: replace-cross 
Abstract: Lasso-type estimators are routinely used to estimate high-dimensional time series models. The theoretical guarantees established for these estimators typically require the penalty level to be chosen in a suitable fashion often depending on unknown population quantities. Furthermore, the resulting estimates and the number of variables retained in the model depend crucially on the chosen penalty level. However, there is currently no theoretically founded guidance for this choice in the context of high-dimensional time series. Instead, one resorts to selecting the penalty level in an ad hoc manner using, e.g., information criteria or cross-validation. We resolve this problem by considering estimation of the perhaps most commonly employed multivariate time series model, the linear vector autoregressive (VAR) model, and propose versions of the Lasso, post-Lasso, and square-root Lasso estimators with penalization chosen in a fully data-driven way. The theoretical guarantees that we establish for the resulting estimation and prediction errors match those currently available for methods based on infeasible choices of penalization. We thus provide a first solution for choosing the penalization in high-dimensional time series models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06657v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anders Bredahl Kock, Rasmus S{\o}ndergaard Pedersen, Jesper Riis-Vestergaard S{\o}rensen</dc:creator>
    </item>
    <item>
      <title>Gaussian universality for approximately polynomial functions of high-dimensional data</title>
      <link>https://arxiv.org/abs/2403.10711</link>
      <description>arXiv:2403.10711v2 Announce Type: replace-cross 
Abstract: We establish an invariance principle for polynomial functions of $n$ independent, high-dimensional random vectors, and also show that the obtained rates are nearly optimal. Both the dimension of the vectors and the degree of the polynomial are permitted to grow with $n$. Specifically, we obtain a finite sample upper bound for the error of approximation by a polynomial of Gaussians, measured in Kolmogorov distance, and extend it to functions that are approximately polynomial in a mean squared error sense. We give a corresponding lower bound that shows the invariance principle holds up to polynomial degree $o(\log n)$. The proof is constructive and adapts an asymmetrisation argument due to V. V. Senatov. We also give a necessary and sufficient condition for asymptotic normality via the fourth moment phenomenon of Nualart and Peccati. As applications, we obtain a higher-order delta method with possibly non-Gaussian limits, and generalise a number of known results on high-dimensional and infinite-order U-statistics, and on fluctuations of subgraph counts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10711v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Han Huang, Morgane Austern, Peter Orbanz</dc:creator>
    </item>
    <item>
      <title>Saturation of the Multiparameter Quantum Cram\'er-Rao Bound at the Single-Copy Level with Projective Measurements</title>
      <link>https://arxiv.org/abs/2405.01471</link>
      <description>arXiv:2405.01471v2 Announce Type: replace-cross 
Abstract: Quantum parameter estimation theory is an important component of quantum information theory and provides the statistical foundation that underpins important topics such as quantum system identification and quantum waveform estimation. When there is more than one parameter the ultimate precision in the mean square error given by the quantum Cram\'er-Rao bound is not necessarily achievable. For non-full rank quantum states, it was not known when this bound can be saturated (achieved) when only a single copy of the quantum state encoding the unknown parameters is available. This single-copy scenario is important because of its experimental/practical tractability. Recently, necessary and sufficient conditions for saturability of the quantum Cram\'er-Rao bound in the multiparameter single-copy scenario have been established in terms of i) the commutativity of a set of projected symmetric logarithmic derivatives and ii) the existence of a unitary solution to a system of coupled nonlinear partial differential equations. New sufficient conditions were also obtained that only depend on properties of the symmetric logarithmic derivatives. In this paper, key structural properties of optimal measurements that saturate the quantum Cram\'er-Rao bound are illuminated. These properties are exploited to i) show that the sufficient conditions are in fact necessary and sufficient for an optimal measurement to be projective, ii) give an alternative proof of previously established necessary conditions, and iii) describe general POVMs, not necessarily projective, that saturate the multiparameter QCRB. Examples are given where a unitary solution to the system of nonlinear partial differential equations can be explicitly calculated when the required conditions are fulfilled.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01471v2</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendra I. Nurdin</dc:creator>
    </item>
    <item>
      <title>Subgradient Selection Convergence Implies Uniform Subdifferential Set Convergence: And Other Tight Convergences Rates in Stochastic Convex Composite Minimization</title>
      <link>https://arxiv.org/abs/2405.10289</link>
      <description>arXiv:2405.10289v4 Announce Type: replace-cross 
Abstract: In nonsmooth, nonconvex stochastic optimization, understanding the uniform convergence of subdifferential mappings is crucial for analyzing stationary points of sample average approximations of risk as they approach the population risk. Yet, characterizing this convergence remains a fundamental challenge. This work introduces a novel perspective by connecting the uniform convergence of subdifferential mappings to that of subgradient mappings as empirical risk converges to the population risk. We prove that, for stochastic weakly-convex objectives, and within any open set, a uniform bound on the convergence of subgradients -- chosen arbitrarily from the corresponding subdifferential sets -- translates to a uniform bound on the convergence of the subdifferential sets themselves, measured by the Hausdorff metric. Using this technique, we derive uniform convergence rates for subdifferential sets of stochastic convex-composite objectives. Our results do not rely on key distributional assumptions in the literature, such as the continuous differentiability of the population objective, yet still provide tight convergence rates. These guarantees lead to new insights into the nonsmooth landscapes of such objectives within finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10289v4</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Ruan</dc:creator>
    </item>
    <item>
      <title>Sharp bounds on aggregate expert error</title>
      <link>https://arxiv.org/abs/2407.16642</link>
      <description>arXiv:2407.16642v4 Announce Type: replace-cross 
Abstract: We revisit the classic problem of aggregating binary advice from conditionally independent experts, also known as the Naive Bayes setting. Our quantity of interest is the error probability of the optimal decision rule. In the case of symmetric errors (sensitivity = specificity), reasonably tight bounds on the optimal error probability are known. In the general asymmetric case, we are not aware of any nontrivial estimates on this quantity. Our contribution consists of sharp upper and lower bounds on the optimal error probability in the general case, which recover and sharpen the best known results in the symmetric special case. Since this turns out to be equivalent to estimating the total variation distance between two product distributions, our results also have bearing on this important and challenging problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16642v4</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aryeh Kontorovich, Ariel Avital</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Instrumental Variables Estimation</title>
      <link>https://arxiv.org/abs/2410.15634</link>
      <description>arXiv:2410.15634v2 Announce Type: replace-cross 
Abstract: Instrumental variables (IV) estimation is a fundamental method in econometrics and statistics for estimating causal effects in the presence of unobserved confounding. However, challenges such as untestable model assumptions and poor finite sample properties have undermined its reliability in practice. Viewing common issues in IV estimation as distributional uncertainties, we propose DRIVE, a distributionally robust IV estimation method. We show that DRIVE minimizes a square root variant of ridge regularized two stage least squares (TSLS) objective when the ambiguity set is based on a Wasserstein distance. In addition, we develop a novel asymptotic theory for this estimator, showing that it achieves consistency without requiring the regularization parameter to vanish. This novel property ensures that the estimator is robust to distributional uncertainties that persist in large samples. We further derive the asymptotic distribution of Wasserstein DRIVE and propose data-driven procedures to select the regularization parameter based on theoretical results. Simulation studies demonstrate the superior finite sample performance of Wasserstein DRIVE in terms of estimation error and out-of-sample prediction. Due to its regularization and robustness properties, Wasserstein DRIVE presents an appealing option when the practitioner is uncertain about model assumptions or distributional shifts in data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15634v2</guid>
      <category>econ.EM</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaonan Qu, Yongchan Kwon</dc:creator>
    </item>
    <item>
      <title>A partial likelihood approach to tree-based density modeling and its application in Bayesian inference</title>
      <link>https://arxiv.org/abs/2412.11692</link>
      <description>arXiv:2412.11692v2 Announce Type: replace-cross 
Abstract: Tree-based models for probability distributions are usually specified using a predetermined, data-independent collection of candidate recursive partitions of the sample space. To characterize an unknown target density in detail over the entire sample space, candidate partitions must have the capacity to expand deeply into all areas of the sample space with potential non-zero sampling probability. Such an expansive system of partitions often incurs prohibitive computational costs and makes inference prone to overfitting, especially in regions with little probability mass. Existing models typically make a compromise and rely on relatively shallow trees. This hampers one of the most desirable features of trees, their ability to characterize local features, and results in reduced statistical efficiency. Traditional wisdom suggests that this compromise is inevitable to ensure coherent likelihood-based reasoning, as a data-dependent partition system that allows deeper expansion only in regions with more observations would induce double dipping of the data and thus lead to inconsistent inference. We propose a simple strategy to restore coherency while allowing the candidate partitions to be data-dependent, using Cox's partial likelihood. This strategy parametrizes the tree-based sampling model according to the allocation of probability mass based on the observed data, and yet under appropriate specification, the resulting inference remains valid. Our partial likelihood approach is broadly applicable to existing likelihood-based methods and in particular to Bayesian inference on tree-based models. We give examples in density estimation in which the partial likelihood is endowed with existing priors on tree-based models and compare with the standard, full-likelihood approach. The results show substantial gains in estimation accuracy and computational efficiency from using the partial likelihood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11692v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Ma, Benedetta Bruni</dc:creator>
    </item>
  </channel>
</rss>
