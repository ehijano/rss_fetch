<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Jul 2025 02:13:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Cure Rate Joint Model for Time-to-Event Data and Longitudinal Tumor Burden with Potential Change Points</title>
      <link>https://arxiv.org/abs/2507.18773</link>
      <description>arXiv:2507.18773v1 Announce Type: new 
Abstract: In non-small cell lung cancer (NSCLC) clinical trials, tumor burden (TB) is a key longitudinal biomarker for assessing treatment effects. Typically, standard-of-care (SOC) therapies and some novel interventions initially decrease TB; however, many patients subsequently experience an increase-indicating disease progression-while others show a continuous decline. In patients with an eventual TB increase, the change point marks the onset of progression and must occur before the time of the event. To capture these distinct dynamics, we propose a novel joint model that integrates time-to-event and longitudinal TB data, classifying patients into a change-point group or a stable group. For the change-point group, our approach flexibly estimates an individualized change point by leveraging time-to-event information. We use a Monte Carlo Expectation-Maximization (MCEM) algorithm for efficient parameter estimation. Simulation studies demonstrate that our model outperforms traditional approaches by accurately capturing diverse disease progression patterns and handling censoring complexities, leading to robust marginal TB outcome estimates. When applied to a Phase 3 NSCLC trial comparing cemiplimab monotherapy to SOC, the treatment group shows prolonged TB reduction and consistently lower TB over time, highlighting the clinical utility of our approach. The implementation code is publicly available on https://github.com/quyixiang/JoCuR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18773v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yixiang Qu, Ethan M. Alt, Weibin Zhong, Jeen Liu, Chenguang Wang, Joseph G. Ibrahim</dc:creator>
    </item>
    <item>
      <title>A New Integrative Learning Framework for Integrating Multiple Secondary Outcomes into Primary Outcome Analysis: A Case Study on Liver Health</title>
      <link>https://arxiv.org/abs/2507.18865</link>
      <description>arXiv:2507.18865v1 Announce Type: new 
Abstract: In the era of big data, secondary outcomes have become increasingly important alongside primary outcomes. These secondary outcomes, which can be derived from traditional endpoints in clinical trials, compound measures, or risk prediction scores, hold the potential to enhance the analysis of primary outcomes. Our method is motivated by the challenge of utilizing multiple secondary outcomes, such as blood biochemistry markers and urine assays, to improve the analysis of the primary outcome related to liver health. Current integration methods often fall short, as they impose strong model assumptions or require prior knowledge to construct over-identified working functions. This paper addresses these statistical challenges and potentially opens a new avenue in data integration by introducing a novel integrative learning framework that is applicable in a general setting. The proposed framework allows for the robust, data-driven integration of information from multiple secondary outcomes, promotes the development of efficient learning algorithms, and ensures optimal use of available data. Extensive simulation studies demonstrate that the proposed method significantly reduces variance in primary outcome analysis, outperforming existing integration approaches. Additionally, applying this method to UK Biobank (UKB) reveals that cigarette smoking is associated with increased fatty liver measures, with these effects being particularly pronounced in the older adult cohort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18865v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daxuan Deng, Peisong Han, Shuo Chen, Ming Wang, Chixiang Chen</dc:creator>
    </item>
    <item>
      <title>A Non-Parametric Sensitivity Analysis for Bounding Bias in Hybrid Control Trials</title>
      <link>https://arxiv.org/abs/2507.18876</link>
      <description>arXiv:2507.18876v1 Announce Type: new 
Abstract: In the digital era, it is easier than ever to collect and exploit rich covariate information in trials. Recent work explores how to use this information to integrate external controls, including the use of hybrid control trials (HCTs) where a randomized controlled trial is augmented with external controls. HCTs are of particular interest due to their ability to preserve partial randomization while also improving trial efficiency. However, most HCT estimators rely on an unrealistic assumption: that the external controls are drawn from the same population as the trial subjects (perhaps conditionally on covariates). There has been little formal work to quantify the inevitable bias introduced from a violation of this assumption, slowing the acceptance of HCT designs. To address this, we introduce a non-parametric sensitivity analysis that recognizes that the assumption can be reframed as a "no unobserved confounders" assumption. We leverage omitted variable bias methodologies to estimate the maximum bias introduced from unmeasured covariates, allowing for a critical evaluation of the causal gap that can invalidate significant findings. We show that with a relatively weak understanding of the covariate-outcome relationship and the distinguishability of trial and external subjects, this method reliably bounds bias while also allowing for gains in efficiency. We conclude by discussing considerations for designing and evaluating HCTs, drawing on insights from simulations and theoretical analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18876v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alissa Gordon, Alejandro Schuler</dc:creator>
    </item>
    <item>
      <title>Functional Periodic ARMA Processes</title>
      <link>https://arxiv.org/abs/2507.18962</link>
      <description>arXiv:2507.18962v1 Announce Type: new 
Abstract: Periodicity is a common feature in functional time series analysis. While autoregressive models in Hilbert spaces have been extended to incorporate it, existing approaches often remain loosely specified or fail to capture inter-seasonal dependencies. This paper introduces periodic autoregressive moving average (fpARMA) processes in general separable Hilbert spaces that fully model inter-seasonal structure. We establish conditions for periodic stationarity, finite moments, and weak dependence, and propose consistent Yule-Walker-type estimators with convergence rates under Sobolev-type regularity. Examples demonstrate applicability and model assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18962v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sebastian K\"uhnert, Juhyun Park</dc:creator>
    </item>
    <item>
      <title>Nonparametric Linear Discriminant Analysis for High Dimensional Matrix-Valued Data</title>
      <link>https://arxiv.org/abs/2507.19028</link>
      <description>arXiv:2507.19028v2 Announce Type: new 
Abstract: This paper addresses classification problems with matrix-valued data, which commonly arises in applications such as neuroimaging and signal processing. Building on the assumption that the data from each class follows a matrix normal distribution, we propose a novel extension of Fisher's Linear Discriminant Analysis (LDA) tailored for matrix-valued observations. To effectively capture structural information while maintaining estimation flexibility, we adopt a nonparametric empirical Bayes framework based on Nonparametric Maximum Likelihood Estimation (NPMLE), applied to vectorized and scaled matrices. The NPMLE method has been shown to provide robust, flexible, and accurate estimates for vector-valued data with various structures in the mean vector or covariance matrix. By leveraging its strengths, our method is effectively generalized to the matrix setting, thereby improving classification performance. Through extensive simulation studies and real data applications, including electroencephalography (EEG) and magnetic resonance imaging (MRI) analysis, we demonstrate that the proposed method consistently outperforms existing approaches across a variety of data structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19028v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seungyeon Oh, Seongoh Park, Hoyoung Park</dc:creator>
    </item>
    <item>
      <title>Shift-generated $\alpha$-homogeneous classes of jointly measurable random fields</title>
      <link>https://arxiv.org/abs/2507.18835</link>
      <description>arXiv:2507.18835v1 Announce Type: cross 
Abstract: We consider a class of shift-generated alpha-homogeneous random fields (RFs) C[Z] defined through a functional identity involving a fixed positive alpha and a given jointly measurable R^d-valued RF Z(t),t in R^l. The significance of such classes lies in the fact that their elements generate max-stable and stationary RFs. We extend the original functional identity to a broad class of functionals, including the integral operator S(.) and prove that C[Z] contains at least one L^alpha-continuous element. Finally, we investigate properties of local RFs and their connections with spectral tail and tail RFs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18835v1</guid>
      <category>math.PR</category>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enkelejd Hashorva</dc:creator>
    </item>
    <item>
      <title>Weak convergence of predictive distributions</title>
      <link>https://arxiv.org/abs/2507.19169</link>
      <description>arXiv:2507.19169v1 Announce Type: cross 
Abstract: Let $(X_n)$ be a sequence of random variables with values in a standard Borel space $S$. We investigate the condition \begin{gather}\label{x56w1q} E\bigl\{f(X_{n+1})\mid X_1,\ldots,X_n\bigr\}\,\quad\text{converges in probability,}\tag{*} \\\text{as }n\rightarrow\infty,\text{ for each bounded Borel function }f:S\rightarrow\mathbb{R}.\notag \end{gather} Some consequences of \eqref{x56w1q} are highlighted and various sufficient conditions for it are obtained. In particular, \eqref{x56w1q} is characterized in terms of stable convergence. Since \eqref{x56w1q} holds whenever $(X_n)$ is conditionally identically distributed, three weak versions of the latter condition are investigated as well. For each of such versions, our main goal is proving (or disproving) that \eqref{x56w1q} holds. Several counterexamples are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19169v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabrizio Leisen, Luca Pratelli, Pietro Rigo</dc:creator>
    </item>
    <item>
      <title>Perfect Clustering in Very Sparse Diverse Multiplex Networks</title>
      <link>https://arxiv.org/abs/2507.19423</link>
      <description>arXiv:2507.19423v1 Announce Type: cross 
Abstract: The paper studies the DIverse MultiPLEx Signed Generalized Random Dot Product Graph (DIMPLE-SGRDPG) network model (Pensky (2024)), where all layers of the network have the same collection of nodes. In addition, all layers can be partitioned into groups such that the layers in the same group are embedded in the same ambient subspace but otherwise matrices of connection probabilities can be all different. This setting includes majority of multilayer network models as its particular cases. The key task in this model is to recover the groups of layers with unique subspace structures, since the case where all layers of the network are embedded in the same subspace has been fairly well studied. Until now, clustering of layers in such networks was based on the layer-per-layer analysis, which required the multilayer network to be sufficiently dense. Nevertheless, in this paper we succeeded in pooling information in all layers together and providing a tensor-based methodology that ensures perfect clustering for a much sparser network. Our theoretical results, established under intuitive non-restrictive assumptions, assert that the new technique achieves perfect clustering under sparsity conditions that, up to logarithmic factors, coincide with the computational lower bound derived for a much simpler model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19423v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marianna Pensky</dc:creator>
    </item>
    <item>
      <title>Super Ensemble Learning Using the Highly-Adaptive-Lasso</title>
      <link>https://arxiv.org/abs/2312.16953</link>
      <description>arXiv:2312.16953v2 Announce Type: replace 
Abstract: We introduce the Meta Highly-Adaptive-Lasso Minimum Loss Estimator (M-HAL-MLE), a novel ensemble approach for estimating functional parameters of realistically modeled data distribution from independent and identically distributed observations. Given $J$ initial estimators, candidate ensembles are generated by finite-sectional-variation cadlag functions. Using $V$-fold cross-validation, the M-HAL-MLE selects the optimal cadlag ensemble minimizing the cross-validated empirical risk, with the sectional variation bound as a tuning parameter. The final estimator, M-HAL super-learner, is obtained by averaging ensemble compositions across folds. In contrast, the oracle ensemble and oracle estimator are defined by minimizing the population excess risk relative to the true function. We establish following theoretical properties: 1) the M-HAL super-learner converges to the oracle estimator at rate $n^{-2/3}$ in excess risk, up to log-n factors; 2) by appropriate undersmoothing, target features of the M-HAL super-learner are asymptotically linear for corresponding target features of the oracle estimator; 3) the excess risk between the oracle estimator and true function, along with the difference between their target features, is generally second-order. Simulations validate the theoretical results, demonstrating effectiveness in high-dimensional settings. We further illustrate the method in a real-data application involving mediation analysis of functional MRI from human pain studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16953v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyi Wang, Wenxin Zhang, Brian S Caffo, Martin Lindquist, Mark van der Laan</dc:creator>
    </item>
    <item>
      <title>Estimation of conditional average treatment effects on distributed confidential data</title>
      <link>https://arxiv.org/abs/2402.02672</link>
      <description>arXiv:2402.02672v5 Announce Type: replace 
Abstract: The estimation of conditional average treatment effects (CATEs) is an important topic in many scientific fields. CATEs can be estimated with high accuracy if data distributed across multiple parties are centralized. However, it is difficult to aggregate such data owing to confidentiality or privacy concerns. To address this issue, we propose data collaboration double machine learning, a method for estimating CATE models using privacy-preserving fusion data constructed from distributed sources, and evaluate its performance through simulations. We make three main contributions. First, our method enables estimation and testing of semi-parametric CATE models without iterative communication on distributed data, providing robustness to model mis-specification compared to parametric approaches. Second, it enables collaborative estimation across different time points and parties by accumulating a knowledge base. Third, our method performs as well as or better than existing methods in simulations using synthetic, semi-synthetic, and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02672v5</guid>
      <category>stat.ME</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuji Kawamata, Ryoki Motai, Yukihiko Okada, Akira Imakura, Tetsuya Sakurai</dc:creator>
    </item>
    <item>
      <title>Continuous-time modeling and bootstrap for chain-ladder reserving</title>
      <link>https://arxiv.org/abs/2406.03252</link>
      <description>arXiv:2406.03252v2 Announce Type: replace 
Abstract: We revisit the famous Mack's model which gives an estimate for the conditional mean squared error of prediction of the chain-ladder claims reserves. We introduce a stochastic differential equation driven by a Brownian motion to model the accumulated total claims amount for the chain-ladder method. Within this continuous-time framework, we propose a bootstrap technique for estimating the distribution of claims reserves. It turns out that our approach leads to inherently capturing asymmetry and non-negativity, eliminating the necessity for additional assumptions. We conclude with a case study and comparative analysis against alternative methodologies based on Mack's model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03252v2</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Baradel</dc:creator>
    </item>
    <item>
      <title>Comparing Causal Inference Methods for Point Exposures with Missing Confounders: A Simulation Study</title>
      <link>https://arxiv.org/abs/2407.06038</link>
      <description>arXiv:2407.06038v4 Announce Type: replace 
Abstract: Causal inference methods based on electronic health record (EHR) databases must simultaneously handle confounding and missing data. Vast scholarship exists aimed at addressing these two issues separately, but surprisingly few papers attempt to address them simultaneously. In practice, when faced with simultaneous missing data and confounding, analysts may proceed by first imputing missing data and subsequently using outcome regression or inverse-probability weighting (IPW) to address confounding. However, little is known about the theoretical performance of such $\textit{ad hoc}$ methods. In a recent paper Levis $\textit{et al.}$ outline a robust framework for tackling these problems together under certain identifying conditions, and introduce a pair of estimators for the average treatment effect (ATE), one of which is non-parametric efficient. In this work we present a series of simulations, motivated by a published EHR based study of the long-term effects of bariatric surgery on weight outcomes, to investigate these new estimators and compare them to existing $\textit{ad hoc}$ methods. While the latter perform well in certain scenarios, no single estimator is uniformly best. We conclude with recommendations for good practice in the face of partially missing confounders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06038v4</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Benz, Alexander Levis, Sebastien Haneuse</dc:creator>
    </item>
    <item>
      <title>General Bayesian quantile regression for counts via generative modeling</title>
      <link>https://arxiv.org/abs/2410.23081</link>
      <description>arXiv:2410.23081v2 Announce Type: replace 
Abstract: Count data frequently arises in biomedical applications, such as the length of hospital stay. However, their discrete nature poses significant challenges for appropriately modeling conditional quantiles, which are crucial for understanding heterogeneous effects and variability in outcomes. To solve the practical difficulty, we propose a novel general Bayesian framework for quantile regression tailored to count data. We seek the regression parameter on the conditional quantile by minimizing the expected loss with respect to the distribution of the conditional quantile of the latent continuous variable associated with the observed count response variable. By modeling the unknown conditional distribution through a Bayesian nonparametric kernel mixture for the joint distribution of the count response and covariates, we obtain the posterior distribution of the regression parameter via a simple optimization. We numerically demonstrate that the proposed method improves bias and estimation accuracy of the existing crude approaches to count quantile regression. Furthermore, we analyze the length of hospital stay for acute myocardial infarction and demonstrate that the proposed method gives more interpretable and flexible results than the existing ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23081v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuta Yamauchi, Genya Kobayashi, Shonosuke Sugasawa</dc:creator>
    </item>
    <item>
      <title>A Liberating Framework from Truncation and Censoring, with Application to Learning Treatment Effects</title>
      <link>https://arxiv.org/abs/2411.18879</link>
      <description>arXiv:2411.18879v2 Announce Type: replace 
Abstract: Time-to-event outcomes are often subject to left truncation and right censoring. While many survival analysis methods have been developed to handle truncation and censoring, majority of the past works require strong independence assumptions. We relax these stringent assumptions through leveraging covariate information together with orthogonal learning, and develop a liberating framework from left truncation and right censoring so that desirable properties like double robustness can be immediately transferred from settings without truncation or censoring. To illustrate its generality and ease to use, the framework is applied to estimation of the average treatment effect (ATE) and the conditional average treatment effect (CATE). For the ATE, we establish both model and rate double robustness under confounding, truncation and censoring; for the CATE, we show that the orthogonal and the doubly robust learners under these three sources of bias can achieve oracle rate of convergence. We study the estimators both theoretically and through extensive simulation, and apply them to analyzing the effect of mid-life heavy drinking on late life cognitive impairment free survival, using data from the Honolulu Asia Aging Study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18879v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyao Wang, Andrew Ying, Ronghui Xu</dc:creator>
    </item>
    <item>
      <title>R2 priors for Grouped Variance Decomposition in High-dimensional Regression</title>
      <link>https://arxiv.org/abs/2507.11833</link>
      <description>arXiv:2507.11833v2 Announce Type: replace 
Abstract: We introduce the Group-R2 decomposition prior, a hierarchical shrinkage prior that extends R2-based priors to structured regression settings with known groups of predictors. By decomposing the prior distribution of the coefficient of determination R2 in two stages, first across groups, then within groups, the prior enables interpretable control over model complexity and sparsity. We derive theoretical properties of the prior, including marginal distributions of coefficients, tail behavior, and connections to effective model complexity. Through simulation studies, we evaluate the conditions under which grouping improves predictive performance and parameter recovery compared to priors that do not account for groups. Our results provide practical guidance for prior specification and highlight both the strengths and limitations of incorporating grouping into R2-based shrinkage priors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11833v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Javier Enrique Aguilar, David Kohns, Aki Vehtari, Paul-Christian B\"urkner</dc:creator>
    </item>
    <item>
      <title>Average partial effect estimation using double machine learning</title>
      <link>https://arxiv.org/abs/2308.09207</link>
      <description>arXiv:2308.09207v3 Announce Type: replace-cross 
Abstract: Single-parameter summaries of variable effects in regression settings are desirable for ease of interpretation. However (partially) linear models for example, which would deliver these, may fit poorly to the data. On the other hand, an interpretable summary of the contribution of a given predictor is provided by the so-called average partial effect: the average slope of the regression function with respect to the predictor of interest. Although one can construct a doubly robust procedure for estimating this quantity, it entails estimating the derivative of the conditional mean and also the conditional score of the predictor of interest given all others, tasks which can be very challenging in moderate dimensions: in particular, popular decision tree based regression methods cannot be used. In this work we introduce an approach for estimating the average partial effect whose accuracy depends primarily on the estimation of certain regression functions, which may be performed by user-chosen machine learning methods that produce potentially non-differentiable estimates. Our procedure involves resmoothing a given first-stage regression estimator to produce a differentiable version, and modelling the conditional distribution of the predictor of interest through a location--scale model. We show that with the latter assumption, surprisingly the overall error in estimating the conditional score is controlled by a sum of errors of estimating the conditional mean and conditional standard deviation, and the estimation error in a much more tractable univariate score estimation problem. Our theory makes use of a new result on the sub-Gaussianity of Lipschitz score functions that may be of independent interest. We demonstrate the attractive numerical performance of our approach in a variety of settings including ones with misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09207v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harvey Klyne, Rajen D. Shah</dc:creator>
    </item>
    <item>
      <title>Generalizability with ignorance in mind: learning what we do (not) know for archetypes discovery</title>
      <link>https://arxiv.org/abs/2501.13355</link>
      <description>arXiv:2501.13355v2 Announce Type: replace-cross 
Abstract: When studying policy interventions, researchers often pursue two goals: i) identifying for whom the program has the largest effects (heterogeneity) and ii) determining whether those patterns of treatment effects have predictive power across environments (generalizability). We develop a framework to learn when and how to partition observations into groups of individual and environmental characterstics within which treatment effects are predictively stable, and when instead extrapolation is unwarranted and further evidence is needed. Our procedure determines in which contexts effects are generalizable and when, instead, researchers should admit ignorance and collect more data. We provide a decision-theoretic foundation, derive finite-sample regret guarantees, and establish asymptotic inference results. We illustrate the benefits of our approach by reanalyzing a multifaceted anti-poverty program across six countries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13355v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Emily Breza, Arun G. Chandrasekhar, Davide Viviano</dc:creator>
    </item>
    <item>
      <title>From Conditional to Unconditional Independence: Testing Conditional Independence via Transport Maps</title>
      <link>https://arxiv.org/abs/2504.09567</link>
      <description>arXiv:2504.09567v3 Announce Type: replace-cross 
Abstract: Testing conditional independence between two random vectors given a third is a fundamental and challenging problem in statistics, particularly in multivariate nonparametric settings due to the complexity of conditional structures. We propose a novel method for testing conditional independence by transforming it to an unconditional independence test problem. We achieve this by constructing two transport maps that transform conditional independence into unconditional independence, this substantially simplifies the problem. These transport maps are estimated from data using conditional continuous normalizing flow models. Within this framework, we derive a test statistic and prove its asymptotic validity under both the null and alternative hypotheses. A permutation-based procedure is employed to evaluate the significance of the test. We validate the proposed method through extensive simulations and real-data analysis. Our numerical studies demonstrate the practical effectiveness of the proposed method for conditional independence</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09567v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenxuan He, Yuan Gao, Liping Zhu, Jian Huang</dc:creator>
    </item>
    <item>
      <title>On unbiased estimators for functions of the rate parameter of the exponential distribution</title>
      <link>https://arxiv.org/abs/2506.20005</link>
      <description>arXiv:2506.20005v2 Announce Type: replace-cross 
Abstract: In this paper, we explicitly derive unbiased estimators for various functions of the rate parameter of the exponential distribution in the absence of a location parameter, including powers of the rate parameter, the $q$th quantile, the $p$th moment, the survival function, the maximum, minimum, probability density function, mean past lifetime, moment generating function, and others. This work non-trivially complements established formulas for unbiased estimators of functions of parameters of the location-rate exponential distribution. Additionally, we establish a result demonstrating the asymptotic normality of the proposed unbiased estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20005v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Vila, Eduardo Yoshio Nakano</dc:creator>
    </item>
  </channel>
</rss>
