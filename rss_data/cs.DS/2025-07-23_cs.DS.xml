<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Jul 2025 01:26:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Online Combinatorial Optimization with Graphical Dependencies</title>
      <link>https://arxiv.org/abs/2507.16031</link>
      <description>arXiv:2507.16031v1 Announce Type: new 
Abstract: Most existing work in online stochastic combinatorial optimization assumes that inputs are drawn from independent distributions -- a strong assumption that often fails in practice. At the other extreme, arbitrary correlations are equivalent to worst-case inputs via Yao's minimax principle, making good algorithms often impossible. This motivates the study of intermediate models that capture mild correlations while still permitting non-trivial algorithms.
  In this paper, we study online combinatorial optimization under Markov Random Fields (MRFs), a well-established graphical model for structured dependencies. MRFs parameterize correlation strength via the maximum weighted degree $\Delta$, smoothly interpolating between independence ($\Delta = 0$) and full correlation ($\Delta \to \infty$). While na\"ively this yields $e^{O(\Delta)}$-competitive algorithms and $\Omega(\Delta)$ hardness, we ask: when can we design tight $\Theta(\Delta)$-competitive algorithms?
  We present general techniques achieving $O(\Delta)$-competitive algorithms for both minimization and maximization problems under MRF-distributed inputs. For minimization problems with coverage constraints (e.g., Facility Location and Steiner Tree), we reduce to the well-studied $p$-sample model. For maximization problems (e.g., matchings and combinatorial auctions with XOS buyers), we extend the "balanced prices" framework for online allocation problems to MRFs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16031v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhimeng Gao, Evangelia Gergatsouli, Kalen Patton, Sahil Singla</dc:creator>
    </item>
    <item>
      <title>Online Joint Replenishment Problem with Arbitrary Holding and Backlog Costs</title>
      <link>https://arxiv.org/abs/2507.16096</link>
      <description>arXiv:2507.16096v1 Announce Type: new 
Abstract: In their seminal paper Moseley, Niaparast, and Ravi introduced the Joint Replenishment Problem (JRP) with holding and backlog costs that models the trade-off between ordering costs, holding costs, and backlog costs in supply chain planning systems. Their model generalized the classical the make-to-order version as well make-to-stock version. For the case where holding costs function of all items are the same and all backlog costs are the same, they provide a constant competitive algorithm, leaving designing a constant competitive algorithm for arbitrary functions open. Moreover, they noticed that their algorithm does not work for arbitrary (request dependent) holding costs and backlog costs functions. We resolve their open problem and design a constant competitive algorithm that works for arbitrary request dependent functions. Specifically, we establish a 4-competitive algorithm for the single-item case and a 16-competitive for the general (multi-item) version. The algorithm of Moseley, Niaparast, and Ravi is based on fixed priority on the requests to items, and request to an item are always served by order of deadlines. In contrast, we design an algorithm with dynamic priority over the requests such that instead of servicing a prefix by deadline of requests, we may need to service a general subset of the requests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16096v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yossi Azar, Shahar Lewkowicz</dc:creator>
    </item>
    <item>
      <title>An Exact Solver for Maximizing a Submodular Function Subject to a Knapsack Constraint</title>
      <link>https://arxiv.org/abs/2507.16149</link>
      <description>arXiv:2507.16149v1 Announce Type: new 
Abstract: We study the problem of maximizing a monotone increasing submodular function over a set of weighted elements subject to a knapsack constraint.
  Although this problem is NP-hard, many applications require exact solutions, as approximate solutions are often insufficient in practice.
  To address this need, we propose an exact branch-and-bound algorithm tailored for the submodular knapsack problem and introduce several acceleration techniques to enhance its efficiency. We evaluate these techniques on instances of three benchmark problems and compare the proposed solvers to two solvers by Sakaue and Ishihata, which are considered state-of-the-art, demonstrating that the presented methods outperform the existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16149v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabine M\"unch, Stephen Raach</dc:creator>
    </item>
    <item>
      <title>Toward a Lightweight and Robust Design for Caching</title>
      <link>https://arxiv.org/abs/2507.16242</link>
      <description>arXiv:2507.16242v2 Announce Type: new 
Abstract: The online caching problem aims to minimize cache misses when serving a sequence of requests under a limited cache size. While naive learning-augmented caching algorithms achieve ideal $1$-consistency, they lack robustness guarantees. Existing robustification methods either sacrifice $1$-consistency or introduce significant computational overhead. In this paper, we introduce Guard, a lightweight robustification framework that enhances the robustness of a broad class of learning-augmented caching algorithms to $2H_k + 2$, while preserving their $1$-consistency. Guard achieves the current best-known trade-off between consistency and robustness, with only $O(1)$ additional per-request overhead, thereby maintaining the original time complexity of the base algorithm. Extensive experiments across multiple real-world datasets and prediction models validate the effectiveness of Guard in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16242v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Chen, Hailiang Zhao, Jiaji Zhang, Xueyan Tang, Yixuan Wang, Shuiguang Deng</dc:creator>
    </item>
    <item>
      <title>Longest Unbordered Factors on Run-Length Encoded Strings</title>
      <link>https://arxiv.org/abs/2507.16285</link>
      <description>arXiv:2507.16285v1 Announce Type: new 
Abstract: A border of a string is a non-empty proper prefix of the string that is also a suffix. A string is unbordered if it has no border. The longest unbordered factor is a fundamental notion in stringology, closely related to string periodicity. This paper addresses the longest unbordered factor problem: given a string of length $n$, the goal is to compute its longest factor that is unbordered. While recent work has achieved subquadratic and near-linear time algorithms for this problem, the best known worst-case time complexity remains $O(n \log n)$ [Kociumaka et al., ISAAC 2018]. In this paper, we investigate the problem in the context of compressed string processing, particularly focusing on run-length encoded (RLE) strings. We first present a simple yet crucial structural observation relating unbordered factors and RLE-compressed strings. Building on this, we propose an algorithm that solves the problem in $O(m^{1.5} \log^2 m)$ time and $O(m \log^2 m)$ space, where $m$ is the size of the RLE-compressed input string. To achieve this, our approach simulates a key idea from the $O(n^{1.5})$-time algorithm by [Gawrychowski et al., SPIRE 2015], adapting it to the RLE setting through new combinatorial insights. When the RLE size $m$ is sufficiently small compared to $n$, our algorithm may show linear-time behavior in $n$, potentially leading to improved performance over existing methods in such cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16285v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shoma Sekizaki, Takuya Mieno</dc:creator>
    </item>
    <item>
      <title>A Best Possible General Form of the Master Theorem for Divide-and-Conquer Recurrences</title>
      <link>https://arxiv.org/abs/2507.16064</link>
      <description>arXiv:2507.16064v1 Announce Type: cross 
Abstract: We give here a general, best-possible, and smoothly-derived form of the Master Theorem for divide-and-conquer recurrences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16064v1</guid>
      <category>math.CA</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carl D. Offner</dc:creator>
    </item>
    <item>
      <title>Best-of-Both-Worlds Guarantees with Fairer Endings</title>
      <link>https://arxiv.org/abs/2507.16209</link>
      <description>arXiv:2507.16209v1 Announce Type: cross 
Abstract: Fair allocation of indivisible goods is a fundamental problem at the interface of economics and computer science. Traditional approaches focus either on randomized allocations that are fair in expectation or deterministic allocations that are approximately fair. Recent work reconciles both these approaches via best-of-both-worlds guarantees, wherein one seeks randomized allocations that are fair in expectation (ex-ante fair) while being supported on approximately fair allocations (ex-post fair). Prior work has shown that under additive valuations, there always exists a randomized allocation that is ex-ante stochastic-dominance envy-free (sd-EF) and ex-post envy-free up to one good (EF1).
  Our work is motivated by the goal of achieving stronger ex-post fairness guarantees such as envy-freeness up to any good (EFX) along with meaningful ex-ante guarantees. We make the following contributions:
  1) We first consider lexicographic preferences, a subdomain of additive valuations where ex-post EFX allocations always exist and can be computed efficiently. On the negative side, we show that ex-ante sd-EF is fundamentally incompatible with ex-post EFX, prompting a relaxation of the ex-ante benchmark. We then present a poly. time algorithm that achieves ex-post EFX and PO together with ex-ante 9/10-EF. Our algorithm uses dependent rounding and leverages structural properties of EFX and PO allocations.
  2)For monotone valuations, we study EFX-with-charity: a relaxation of EFX where some goods remain unallocated, with no agent envying the unallocated pool. We show that ex-post EFX-with-charity can be achieved alongside ex-ante 0.5-EF.
  3)Finally, for subadditive valuations, we strengthen our previous ex-post guarantee to EFX-with-bounded-charity, where at most n-1 goods (n= no. of agents) remain unallocated, at the price of weakening the ex-ante guarantee to 0.5-proportionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16209v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Telikepalli Kavitha, Surya Panchapakesan, Rohit Vaish, Vignesh Viswanathan, Jatin Yadav</dc:creator>
    </item>
    <item>
      <title>The Cost of Compression: Tight Quadratic Black-Box Attacks on Sketches for $\ell_2$ Norm Estimation</title>
      <link>https://arxiv.org/abs/2507.16345</link>
      <description>arXiv:2507.16345v1 Announce Type: cross 
Abstract: Dimensionality reduction via linear sketching is a powerful and widely used technique, but it is known to be vulnerable to adversarial inputs. We study the black-box adversarial setting, where a fixed, hidden sketching matrix A in $R^{k X n}$ maps high-dimensional vectors v $\in R^n$ to lower-dimensional sketches A v in $R^k$, and an adversary can query the system to obtain approximate ell2-norm estimates that are computed from the sketch.
  We present a universal, nonadaptive attack that, using tilde(O)($k^2$) queries, either causes a failure in norm estimation or constructs an adversarial input on which the optimal estimator for the query distribution (used by the attack) fails. The attack is completely agnostic to the sketching matrix and to the estimator: It applies to any linear sketch and any query responder, including those that are randomized, adaptive, or tailored to the query distribution.
  Our lower bound construction tightly matches the known upper bounds of tilde(Omega)($k^2$), achieved by specialized estimators for Johnson Lindenstrauss transforms and AMS sketches. Beyond sketching, our results uncover structural parallels to adversarial attacks in image classification, highlighting fundamental vulnerabilities of compressed representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16345v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara Ahmadian, Edith Cohen, Uri Stemmer</dc:creator>
    </item>
    <item>
      <title>An unconditional lower bound for the active-set method in convex quadratic maximization</title>
      <link>https://arxiv.org/abs/2507.16648</link>
      <description>arXiv:2507.16648v1 Announce Type: cross 
Abstract: We prove that the active-set method needs an exponential number of iterations in the worst-case to maximize a convex quadratic function subject to linear constraints, regardless of the pivot rule used. This substantially improves over the best previously known lower bound [IPCO 2025], which needs objective functions of polynomial degrees $\omega(\log d)$ in dimension $d$, to a bound using a convex polynomial of degree 2. In particular, our result firmly resolves the open question [IPCO 2025] of whether a constant degree suffices, and it represents significant progress towards linear objectives, where the active-set method coincides with the simplex method and a lower bound for all pivot rules would constitute a major breakthrough.
  Our result is based on a novel extended formulation, recursively constructed using deformed products. Its key feature is that it projects onto a polygonal approximation of a parabola while preserving all of its exponentially many vertices. We define a quadratic objective that forces the active-set method to follow the parabolic boundary of this projection, without allowing any shortcuts along chords corresponding to edges of its full-dimensional preimage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16648v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleon Bach, Yann Disser, Sophie Huiberts, Nils Mosis</dc:creator>
    </item>
    <item>
      <title>Rapid Mixing at the Uniqueness Threshold</title>
      <link>https://arxiv.org/abs/2411.03413</link>
      <description>arXiv:2411.03413v2 Announce Type: replace 
Abstract: Over the past decades, a fascinating computational phase transition has been identified in sampling from Gibbs distributions. Though, the computational complexity at the critical point remains poorly understood, as previous algorithmic and hardness results all required a constant slack from this threshold.
  In this paper, we resolve this open question at the critical phase transition threshold, thus completing the picture of the computational phase transition. We show that for the hardcore model on graphs with maximum degree $\Delta\ge 3$ at the uniqueness threshold $\lambda = \lambda_c(\Delta)$, the mixing time of Glauber dynamics is upper bounded by a polynomial in $n$, but is not nearly linear in the worst case.
  For the Ising model (either antiferromagnetic or ferromagnetic), we establish similar results. For the Ising model on graphs with maximum degree $\Delta\ge 3$ at the critical temperature $\beta$ where $|\beta| = \beta_c(\Delta)$, with the tree-uniqueness threshold $\beta_c(\Delta)$, we show that the mixing time of Glauber dynamics is upper bounded by $\tilde{O}\left(n^{2 + O(1/\Delta)}\right)$ and lower bounded by $\Omega\left(n^{3/2}\right)$ in the worst case. For the Ising model specified by a critical interaction matrix $J$ with $\left \lVert J \right \rVert_2=1$, we obtain an upper bound $\tilde{O}(n^{3/2})$ for the mixing time, matching the lower bound $\Omega\left(n^{3/2}\right)$ on the complete graph up to a logarithmic factor.
  Our mixing time upper bounds are derived from a new interpretation and analysis of the localization scheme method introduced by Chen and Eldan (2022), applied to the field dynamics for the hardcore model and the proximal sampler for the Ising model. As key steps in both our upper and lower bounds, we establish sub-linear upper and lower bounds for spectral independence at the critical point for worst-case instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03413v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Chen, Zongchen Chen, Yitong Yin, Xinyuan Zhang</dc:creator>
    </item>
    <item>
      <title>LimTDD: A Compact Decision Diagram Integrating Tensor and Local Invertible Map Representations</title>
      <link>https://arxiv.org/abs/2504.01168</link>
      <description>arXiv:2504.01168v2 Announce Type: replace 
Abstract: Tensor networks serve as a powerful tool for efficiently representing and manipulating high-dimensional data in applications such as quantum physics, machine learning, and data compression. Tensor Decision Diagrams (TDDs) offer an efficient framework for tensor representation by leveraging decision diagram techniques. However, the current implementation of TDDs and other decision diagrams fail to exploit tensor isomorphisms, limiting their compression potential. This paper introduces Local Invertible Map Tensor Decision Diagrams (LimTDDs), an extension of TDDs that incorporates local invertible maps (LIMs) to achieve more compact representations. Unlike LIMDD, which uses Pauli operators for quantum states, LimTDD employs the $XP$-stabilizer group, enabling broader applicability across tensor-based tasks. We present efficient algorithms for normalization, slicing, addition, and contraction, critical for tensor network applications. Theoretical analysis demonstrates that LimTDDs achieve greater compactness than TDDs and, in best-case scenarios and for quantum state representations, offer exponential compression advantages over both TDDs and LIMDDs. Experimental results in quantum circuit tensor computation and simulation confirm LimTDD's superior efficiency. Open-source code is available at https://github.com/Veriqc/LimTDD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01168v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Hong, Aochu Dai, Dingchao Gao, Sanjiang Li, Zhengfeng Ji, Mingsheng Ying</dc:creator>
    </item>
    <item>
      <title>On Distributed Colouring of Hyperbolic Random Graphs</title>
      <link>https://arxiv.org/abs/2505.19109</link>
      <description>arXiv:2505.19109v2 Announce Type: replace 
Abstract: We analyse the performance of simple distributed colouring algorithms under the assumption that the input graph is a hyperbolic random graph (HRG), a generative model capturing key properties of real-world networks such as power-law degree distributions and large clustering coefficients. Motivated by the shift from worst-case analysis to more realistic network models, we study the number of rounds and size of the colour space required to colour HRGs in the distributed setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19109v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yannic Maus, Janosch Ruff</dc:creator>
    </item>
    <item>
      <title>A computational transition for detecting correlated stochastic block models by low-degree polynomials</title>
      <link>https://arxiv.org/abs/2409.00966</link>
      <description>arXiv:2409.00966v2 Announce Type: replace-cross 
Abstract: Detection of correlation in a pair of random graphs is a fundamental statistical and computational problem that has been extensively studied in recent years. In this work, we consider a pair of correlated (sparse) stochastic block models $\mathcal{S}(n,\tfrac{\lambda}{n};k,\epsilon;s)$ that are subsampled from a common parent stochastic block model $\mathcal S(n,\tfrac{\lambda}{n};k,\epsilon)$ with $k=O(1)$ symmetric communities, average degree $\lambda=O(1)$, divergence parameter $\epsilon$, and subsampling probability $s$.
  For the detection problem of distinguishing this model from a pair of independent Erd\H{o}s-R\'enyi graphs with the same edge density $\mathcal{G}(n,\tfrac{\lambda s}{n})$, we focus on tests based on \emph{low-degree polynomials} of the entries of the adjacency matrices, and we determine the threshold that separates the easy and hard regimes. More precisely, we show that this class of tests can distinguish these two models if and only if $s&gt; \min \{ \sqrt{\alpha}, \frac{1}{\lambda \epsilon^2} \}$, where $\alpha\approx 0.338$ is the Otter's constant and $\frac{1}{\lambda \epsilon^2}$ is the Kesten-Stigum threshold. Combining a reduction argument in \cite{Li25+}, our hardness result also implies low-degree hardness for partial recovery and detection (to independent block models) when $s&lt; \min \{ \sqrt{\alpha}, \frac{1}{\lambda \epsilon^2} \}$. Finally, our proof of low-degree hardness is based on a conditional variant of the low-degree likelihood calculation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00966v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanyi Chen, Jian Ding, Shuyang Gong, Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Differentially Private Set Representations</title>
      <link>https://arxiv.org/abs/2501.16680</link>
      <description>arXiv:2501.16680v2 Announce Type: replace-cross 
Abstract: We study the problem of differentially private (DP) mechanisms for representing sets of size $k$ from a large universe. Our first construction creates $(\epsilon,\delta)$-DP representations with error probability of $1/(e^\epsilon + 1)$ using space at most $1.05 k \epsilon \cdot \log(e)$ bits where the time to construct a representation is $O(k \log(1/\delta))$ while decoding time is $O(\log(1/\delta))$. We also present a second algorithm for pure $\epsilon$-DP representations with the same error using space at most $k \epsilon \cdot \log(e)$ bits, but requiring large decoding times. Our algorithms match our lower bounds on privacy-utility trade-offs (including constants but ignoring $\delta$ factors) and we also present a new space lower bound matching our constructions up to small constant factors. To obtain our results, we design a new approach embedding sets into random linear systems deviating from most prior approaches that inject noise into non-private solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16680v2</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sarvar Patel, Giuseppe Persiano, Joon Young Seo, Kevin Yeo</dc:creator>
    </item>
    <item>
      <title>Feature Selection and Junta Testing are Statistically Equivalent</title>
      <link>https://arxiv.org/abs/2505.04604</link>
      <description>arXiv:2505.04604v2 Announce Type: replace-cross 
Abstract: For a function $f \colon \{0,1\}^n \to \{0,1\}$, the junta testing problem asks whether $f$ depends on only $k$ variables. If $f$ depends on only $k$ variables, the feature selection problem asks to find those variables. We prove that these two tasks are statistically equivalent. Specifically, we show that the ``brute-force'' algorithm, which checks for any set of $k$ variables consistent with the sample, is simultaneously sample-optimal for both problems, and the optimal sample size is \[ \Theta\left(\frac 1 \varepsilon \left( \sqrt{2^k \log {n \choose k}} + \log {n \choose k}\right)\right). \]</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04604v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Beretta, Nathaniel Harms, Caleb Koch</dc:creator>
    </item>
  </channel>
</rss>
