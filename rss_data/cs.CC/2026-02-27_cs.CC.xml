<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dynamic Level Sets</title>
      <link>https://arxiv.org/abs/2602.22530</link>
      <description>arXiv:2602.22530v1 Announce Type: new 
Abstract: A mathematical concept is identified and analyzed that is implicit in the 2012 paper Turing Incomputable Computation, presented at the Alan Turing Centenary Conference (Turing 100, Manchester). The concept, called dynamic level sets, is distinct from mathematical concepts in the standard literature on dynamical systems, topology, and computability theory. A new mathematical object is explained and why it may have escaped prior characterizations, including the classical result of de Leeuw, Moore, Shannon, and Shapiro (1956) that probabilistic Turing machines compute no more than deterministic ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22530v1</guid>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.HO</category>
      <category>math.MP</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Stephen Fiske</dc:creator>
    </item>
    <item>
      <title>Faster algorithms for graph homomorphism via tractable constraint satisfaction</title>
      <link>https://arxiv.org/abs/2602.23000</link>
      <description>arXiv:2602.23000v1 Announce Type: new 
Abstract: We show that the existence of a homomorphism from an $n$-vertex graph $G$ to an $h$-vertex graph $H$ can be decided in time $2^{O(n)}h^{O(1)}$ and polynomial space if $H$ comes from a family of graphs that excludes a topological minor. The algorithm is based on a reduction to a single-exponential number of constraint satisfaction problems over tractable languages and can handle cost minimization. We also present an improved randomized algorithm for the special case where the graph $H$ is an odd cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23000v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Carbonnel</dc:creator>
    </item>
    <item>
      <title>Results on three problems on isolation of graphs</title>
      <link>https://arxiv.org/abs/2602.22856</link>
      <description>arXiv:2602.22856v1 Announce Type: cross 
Abstract: The graph isolation problem was introduced by Caro and Hansberg in 2015. It is a vast generalization of the classical graph domination problem and its study is expanding rapidly. In this paper, we address a number of questions that arise naturally. Let $F$ be a graph. We show that the $F$-isolating set problem is NP-complete if $F$ is connected. We investigate how the $F$-isolation number $\iota(G,F)$ of a graph $G$ is affected by the minimum degree $d$ of $G$, establishing a bounded range, in terms of $d$ and the orders of $F$ and $G$, for the largest possible value of $\iota(G,F)$ with $d$ sufficiently large. We also investigate how close $\iota(G,tF)$ is to $\iota(G,F)$, using domination and, in suitable cases, the Erdos-Posa property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22856v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Borg, Yair Caro</dc:creator>
    </item>
    <item>
      <title>Flip Distance of Triangulations of Convex Polygons / Rotation Distance of Binary Trees is NP-complete</title>
      <link>https://arxiv.org/abs/2602.22874</link>
      <description>arXiv:2602.22874v1 Announce Type: cross 
Abstract: Flips in triangulations of convex polygons arise in many different settings. They are isomorphic to rotations in binary trees, define edges in the 1-skeleton of the Associahedron and cover relations in the Tamari Lattice.
  The complexity of determining the minimum number of flips that transform one triangulation of a convex point set into another remained a tantalizing open question for many decades. We settle this question by proving that computing shortest flip sequences between triangulations of convex polygons, and therefore also computing the rotation distance of binary trees, is NP-hard.
  For our proof we develop techniques for flip sequences of triangulations whose counterparts were introduced for the study of flip sequences of non-crossing spanning trees by Bjerkevik, Kleist, Ueckerdt, and Vogtenhuber~[SODA25] and Bjerkevik, Dorfer, Kleist, Ueckerdt, and Vogtenhuber~[SoCG26].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22874v1</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Dorfer</dc:creator>
    </item>
    <item>
      <title>Dequantization Barriers for Guided Stoquastic Hamiltonians</title>
      <link>https://arxiv.org/abs/2602.23183</link>
      <description>arXiv:2602.23183v1 Announce Type: cross 
Abstract: We construct a probability distribution, induced by the Perron--Frobenius eigenvector of an exponentially large graph, which cannot be efficiently sampled by any classical algorithm, even when provided with the best-possible warm-start distribution. In the quantum setting, this problem can be viewed as preparing the ground state of a stoquastic Hamiltonian given a guiding state as input, and is known to be efficiently solvable on a quantum computer. Our result suggests that no efficient classical algorithm can solve a broad class of stoquastic ground-state problems.
  Our graph is constructed from a class of high-degree, high-girth spectral expanders to which self-similar trees are attached. This builds on and extends prior work of Gily\'en, Hastings, and Vazirani [Quantum 2021, STOC 2021], which ruled out dequantization for a specific stoquastic adiabatic path algorithm. We strengthen their result by ruling out any classical algorithm for guided ground-state preparation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23183v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassine Hamoudi, Yvan Le Borgne, Shrinidhi Teganahally Sridhara</dc:creator>
    </item>
    <item>
      <title>Equivalent Dichotomies for Triangle Detection in Subgraph, Induced, and Colored H-Free Graphs</title>
      <link>https://arxiv.org/abs/2602.23196</link>
      <description>arXiv:2602.23196v1 Announce Type: cross 
Abstract: A recent paper by the authors (ITCS'26) initiates the study of the Triangle Detection problem in graphs avoiding a fixed pattern $H$ as a subgraph and proposes a \emph{dichotomy hypothesis} characterizing which patterns $H$ make the Triangle Detection problem easier in $H$-free graphs than in general graphs.
  In this work, we demonstrate that this hypothesis is, in fact, equivalent to analogous hypotheses in two broader settings that a priori seem significantly more challenging: \emph{induced} $H$-free graphs and \emph{colored} $H$-free graphs.
  Our main contribution is a reduction from the induced $H$-free case to the non-induced $\H^+$-free case, where $\H^+$ preserves the structural properties of $H$ that are relevant for the dichotomy, namely $3$-colorability and triangle count. A similar reduction is given for the colored case.
  A key technical ingredient is a self-reduction to Unique Triangle Detection that preserves the induced $H$-freeness property, via a new color-coding-like reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23196v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Abboud, Ron Safier, Nathan Wallheimer</dc:creator>
    </item>
    <item>
      <title>Hardness of Maximum Likelihood Learning of DPPs</title>
      <link>https://arxiv.org/abs/2205.12377</link>
      <description>arXiv:2205.12377v4 Announce Type: replace 
Abstract: Determinantal Point Processes (DPPs) are a widely used probabilistic model for negatively correlated sets. DPPs have been successfully employed in Machine Learning applications to select a diverse, yet representative subset of data. In these applications, a set of parameters that maximize the likelihood of the data is typically desirable. The algorithms used for this task to date either optimize over a limited family of DPPs, or use local improvement heuristics that do not provide theoretical guarantees of optimality.
  In his seminal work on DPPs in Machine Learning, Kulesza (2011) conjectured that the problem is NP-complete. The lack of a formal proof prompted Brunel et al. (COLT 2017) to suggest that, in opposition to Kulesza's conjecture, there might exist a polynomial-time algorithm for computing a maximum-likelihood DPP. They also presented some preliminary evidence supporting a conjecture that they suggested might lead to such an algorithm.
  In this work we prove Kulesza's conjecture. In fact, we prove the following stronger hardness of approximation result: even computing a $\left(1-O(\frac{1}{\log^9{N}})\right)$-approximation to the maximum log-likelihood of a DPP on a ground set of $N$ elements is NP-complete.
  From a technical perspective, we reduce the problem of approximating the maximum log-likelihood of a DPP to solving a gap instance of a \textsc{$3$-Coloring} problem on a hypergraph. This hypergraph is based on the bounded-degree construction of Bogdanov et al. (FOCS 2002), which we enhance using the strong expanders of Alon and Capalbo (FOCS 2007). We demonstrate that if a rank-$3$ DPP achieves near-optimal log-likelihood, its marginal kernel must encode an almost perfect ``vector-coloring" of the hypergraph. Finally, we show that these continuous vectors can be decoded into a proper $3$-coloring after removing a small fraction of ``noisy" edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.12377v4</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Grigorescu, Brendan Juba, Karl Wimmer, Ning Xie</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Neural Computation in Superposition</title>
      <link>https://arxiv.org/abs/2409.15318</link>
      <description>arXiv:2409.15318v3 Announce Type: replace 
Abstract: Superposition, the ability of neural networks to represent more features than neurons, is increasingly seen as key to the efficiency of large models. This paper investigates the theoretical foundations of computing in superposition, establishing complexity bounds for explicit, provably correct algorithms. We present the first lower bounds for a neural network computing in superposition, showing that for a broad class of problems, including permutations and pairwise logical operations, computing $m'$ features in superposition requires at least $\Omega(\sqrt{m' \log m'})$ neurons and $\Omega(m' \log m')$ parameters. This implies an explicit limit on how much one can sparsify or distill a model while preserving its expressibility, and complements empirical scaling laws by implying the first subexponential bound on capacity: a network with $n$ neurons can compute at most $O(n^2 / \log n)$ features. Conversely, we provide a nearly tight constructive upper bound: logical operations like pairwise AND can be computed using $O(\sqrt{m'} \log m')$ neurons and $O(m' \log^2 m')$ parameters. There is thus an exponential gap between the complexity of computing in superposition (the subject of this work) versus merely representing features, which can require as little as $O(\log m')$ neurons based on the Johnson-Lindenstrauss Lemma. Our work analytically establishes that the number of parameters is a good estimator of the number of features a neural network computes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15318v3</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.NE</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micah Adler, Nir Shavit</dc:creator>
    </item>
    <item>
      <title>Prover-Adversary games for systems over (non-deterministic) branching programs</title>
      <link>https://arxiv.org/abs/2508.16014</link>
      <description>arXiv:2508.16014v3 Announce Type: replace 
Abstract: We introduce Pudlak-Buss style Prover-Adversary games to characterise proof systems reasoning over deterministic branching programs (BPs) and non-deterministic branching programs (NBPs). Our starting points are the proof systems eLDT and eLNDT, for BPs and NBPs respectively, previously introduced by Buss, Das and Knop. We prove polynomial equivalences between these proof systems and the corresponding games we introduce. This crucially requires access to a form of negation of branching programs which, for NBPs, requires us to formalise a non-uniform version of the Immerman-Szelepcsenyi theorem that coNL = NL. Thanks to the techniques developed, we further obtain a proof complexity theoretic version of Immerman-Szelepcsenyi, showing that eLNDT is polynomially equivalent to systems over boundedly alternating branching programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16014v3</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupam Das, Avgerinos Delkos</dc:creator>
    </item>
    <item>
      <title>Exact Quantum Circuit Optimization is co-NQP-hard</title>
      <link>https://arxiv.org/abs/2510.16420</link>
      <description>arXiv:2510.16420v2 Announce Type: replace-cross 
Abstract: As quantum computing resources remain scarce and error rates high, minimizing the resource consumption of quantum circuits is essential for achieving practical quantum advantage. Here we consider the natural problem of, given a circuit $C$, computing a circuit $C'$ which behaves equivalently on a desired subspace, and that minimizes a quantum resource type, expressed as the count or depth of (i) arbitrary gates, or (ii) non-Clifford gates, or (iii) superposition gates, or (iv) entanglement gates. We show that, when $C$ is expressed over any gate set that can implement the H and TOF gates exactly, each of the above optimization problems is hard for $\text{co-NQP}$, and hence outside the Polynomial Hierarchy, unless the Polynomial Hierarchy collapses. This complements recent results in the literature which established an $\text{NP}$-hardness lower bound when equivalence is over the full state space, and tightens the gap to the corresponding $\text{NP}^{\text{NQP}}$ upper bound known for cases (i)-(iii) over Clifford+T and (i)-(iv) over H+TOF circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16420v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Husted Kjelstr{\o}m, Andreas Pavlogiannis, Jaco van de Pol</dc:creator>
    </item>
    <item>
      <title>Connectivity-Preserving Important Separators: A Framework for Cut-Uncut Problems</title>
      <link>https://arxiv.org/abs/2511.15849</link>
      <description>arXiv:2511.15849v2 Announce Type: replace-cross 
Abstract: Graph separation problems are a cornerstone of parameterized complexity, often tackled using the "Important Separators" technique introduced by Marx. While this technique is powerful for standard separation problems, it is inapplicable to problems with connectivity constraints, where the goal is to separate terminal sets while maintaining the internal connectivity of specific components (e.g., Node Multiway Cut-Uncut and 2-sets cut-uncut). In such settings, the standard branching strategies for enumerating important separators fail, and the solution space becomes complex and seemingly unstructured.
  In this paper, we introduce the framework of Connectivity-Preserving (CP) Important Separators. We prove that the number of CP-important separators of size $k$ is $2^{O(k\log k)}$. Leveraging this bound, we present an efficient algorithm to enumerate all such separators. Our approach relies on a fundamental property regarding the union of minimum separators, which allows us to characterize valid separators by systematically "repairing" the connectivity violations of unconstrained separators.
  As a primary application, we present a new fixed-parameter tractable (FPT) algorithm for the Node Multiway Cut-Uncut (N-MWCU) problem. For the fundamental case of 2-Sets Cut-Uncut, and more generally whenever the number of equivalence classes is constant, we improve the running time from the previous best of $2^{O(k^2 \log k)}$ to $2^{O(k \log k)}$. Crucially, our approach avoids the heavy machinery of randomized contractions (and their expensive derandomization) employed by previous work, replacing it with a direct enumeration algorithm that reduces both the exponential dependence on the parameter $k$ and the polynomial overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15849v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Batya Kenig</dc:creator>
    </item>
  </channel>
</rss>
