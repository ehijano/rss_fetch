<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Mar 2025 02:54:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Can Diffusion Models Provide Rigorous Uncertainty Quantification for Bayesian Inverse Problems?</title>
      <link>https://arxiv.org/abs/2503.03007</link>
      <description>arXiv:2503.03007v1 Announce Type: new 
Abstract: In recent years, the ascendance of diffusion modeling as a state-of-the-art generative modeling approach has spurred significant interest in their use as priors in Bayesian inverse problems. However, it is unclear how to optimally integrate a diffusion model trained on the prior distribution with a given likelihood function to obtain posterior samples. While algorithms that have been developed for this purpose can produce high-quality, diverse point estimates of the unknown parameters of interest, they are often tested on problems where the prior distribution is analytically unknown, making it difficult to assess their performance in providing rigorous uncertainty quantification. In this work, we introduce a new framework, Bayesian Inverse Problem Solvers through Diffusion Annealing (BIPSDA), for diffusion model based posterior sampling. The framework unifies several recently proposed diffusion model based posterior sampling algorithms and contains novel algorithms that can be realized through flexible combinations of design choices. Algorithms within our framework were tested on model problems with a Gaussian mixture prior and likelihood functions inspired by problems in image inpainting, x-ray tomography, and phase retrieval. In this setting, approximate ground-truth posterior samples can be obtained, enabling principled evaluation of the performance of the algorithms. The results demonstrate that BIPSDA algorithms can provide strong performance on the image inpainting and x-ray tomography based problems, while the challenging phase retrieval problem, which is difficult to sample from even when the posterior density is known, remains outside the reach of the diffusion model based samplers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03007v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan Scope Crafts, Umberto Villa</dc:creator>
    </item>
    <item>
      <title>Optimal power procurement for green cellular wireless networks under uncertainty and chance constraints</title>
      <link>https://arxiv.org/abs/2503.03051</link>
      <description>arXiv:2503.03051v1 Announce Type: new 
Abstract: Given the increasing global emphasis on sustainable energy usage and the rising energy demands of cellular wireless networks, this work seeks an optimal short-term, continuous-time power procurement schedule to minimize operating expenditure and the carbon footprint of cellular wireless networks equipped with energy storage capacity, and hybrid energy systems comprising uncertain renewable energy sources. Despite the stochastic nature of wireless fading channels, the network operator must ensure a certain quality-of-service (QoS) constraint with high probability. This probabilistic constraint prevents using the dynamic programming principle to solve the stochastic optimal control problem. This work introduces a novel time-continuous Lagrangian relaxation approach tailored for real-time, near-optimal energy procurement in cellular networks, overcoming tractability problems associated with the probabilistic QoS constraint. The numerical solution procedure includes an efficient upwind finite-difference solver for the Hamilton--Jacobi--Bellman equation corresponding to the relaxed problem, and an effective combination of the limited memory bundle method (LMBM) for handling nonsmooth optimization and the stochastic subgradient method (SSM) to navigate the stochasticity of the dual problem. Numerical results, based on the German power system and daily cellular traffic data, demonstrate the computational efficiency of the proposed numerical approach, providing a near-optimal policy in a practical timeframe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03051v1</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadhir Ben Rached, Shyam Mohan Subbiah Pillai, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>Positive Definiteness of $4$th Order $3$-Dimensional Symmetric Tensors with entries $-1$, $0$, $1$</title>
      <link>https://arxiv.org/abs/2503.03127</link>
      <description>arXiv:2503.03127v1 Announce Type: new 
Abstract: It is well-known that a symmetric matrix with its entries $\pm1$ is not positive definite. But this is not ture for symmetric tensors (hyper-matrix). In this paper, we mainly dicuss the positive (semi-)definiteness criterion of a class of $4$th order $3$-dimensional symmetric tensors with entries $t_{ijkl}\in\{-1,0,1\}$. Through theoretical derivations and detailed classification discussions, the criterion for determining the positive (semi-)definiteness of such a class of tensors are provided based on the relationships and number values of its entries. Which establishes some unique properties of higher symmetric tensors that distinct from ones of matrces</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03127v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Ye, Yisheng Song</dc:creator>
    </item>
    <item>
      <title>A new fuzzy fractional differential variational inequality with Mittag-Leffler kernel of order $q \in (1,2]$</title>
      <link>https://arxiv.org/abs/2503.03169</link>
      <description>arXiv:2503.03169v1 Announce Type: new 
Abstract: This paper considers a new fuzzy fractional differential variational inequality with Mittag-Leffler kernel of order $q \in (1,2]$ comprising a fuzzy fractional differential inclusion with Mittag-Leffler kernel of order $q \in (1,2]$ and a variational inequality in Euclidean spaces. The existence of solutions for such a novel system is obtained under some mild conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03169v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeng-bao Wu, Tao Chen, Quan-guo Zhang, Yi-bin Xiao</dc:creator>
    </item>
    <item>
      <title>Characterizations of Tilt-Stable Local Minimizers of a Class of Matrix Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.03217</link>
      <description>arXiv:2503.03217v1 Announce Type: new 
Abstract: Tilt stability plays a pivotal role in understanding how local solutions of an optimization problem respond to small, targeted perturbations of the objective. Although quadratic bundles are a powerful tool for capturing second-order variational behavior, their characterization remains incomplete beyond well-known polyhedral and certain specialized nonpolyhedral settings. To help bridge this gap, we propose a new point-based criterion for tilt stability in prox-regular, subdifferentially continuous functions by exploiting the notion of minimal quadratic bundles. Furthermore, we derive an explicit formula for the minimal quadratic bundle associated with a broad class of general spectral functions, thus providing a practical and unifying framework that significantly extends existing results and offers broader applicability in matrix optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03217v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Ding, Ebrahim Sarabi, Shiwei Wang</dc:creator>
    </item>
    <item>
      <title>Mean Field Game of Controls with State Reflections: Existence and Limit Theory</title>
      <link>https://arxiv.org/abs/2503.03253</link>
      <description>arXiv:2503.03253v1 Announce Type: new 
Abstract: This paper studies mean field game (MFG) of controls by featuring the joint distribution of the state and the control with the reflected state process along an exogenous stochastic reflection boundary. We contribute to the literature with a customized relaxed formulation and some new compactification arguments to establish the existence of a Markovian mean field equilibrium (MFE) in the weak sense. We consider an enlarged canonical space, utilizing the dynamic Skorokhod mapping, to accommodate the stochastic reflection boundary process. A fixed-point argument on the extended space using an extension transformation technique is developed to tackle challenges from the joint measure flow of the state and the relaxed control that may not be continuous. Furthermore, the bidirectional connections between the MFG and the $N$-player game are also established in the context of joint law dependence and state reflections. We first show that any weak limit of empirical measures induced by $\boldsymbol{\epsilon}$-Nash equilibria in $N$-player games must be supported exclusively on the set of relaxed mean field equilibria, analogous to the propagation of chaos in mean field control problems. We then prove the convergence result that a Markovian MFE in the weak sense can be approximated by a sequence of constructed $\boldsymbol{\epsilon}$-Nash equilibria in the weak sense in $N$-player games when $N$ tends to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03253v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Linear-quadratic optimal control for non-exchangeable mean-field SDEs and applications to systemic risk</title>
      <link>https://arxiv.org/abs/2503.03318</link>
      <description>arXiv:2503.03318v1 Announce Type: new 
Abstract: We study the linear-quadratic control problem for a class of non-exchangeable mean-field systems,  which model large populations of heterogeneous interacting agents.  We explicitly characterize the optimal control in terms of a new infinite-dimensional system of Riccati equations, for which we establish existence and uniqueness. To illustrate our results, we apply this framework to a systemic risk model involving heterogeneous banks, demonstrating the impact of agent heterogeneity on optimal risk mitigation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03318v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna de Crescenzo (UPCit\'e, LPSM), Filippo de Feo (X, CMAP), Huy\^en Pham (X, CMAP)</dc:creator>
    </item>
    <item>
      <title>A Production Routing Problem with Mobile Inventories</title>
      <link>https://arxiv.org/abs/2503.03322</link>
      <description>arXiv:2503.03322v1 Announce Type: new 
Abstract: Hydrogen is an energy vector, and one possible way to reduce CO 2 emissions. This paper focuses on a hydrogen transport problem where mobile storage units are moved by trucks between sources to be refilled and destinations to meet demands, involving swap operations upon arrival. This contrasts with existing literature where inventories remain stationary. The objective is to optimize daily routing and refilling schedules of the mobile storages. We model the problem as a flow problem on a time-expanded graph, where each node of the graph is indexed by a time-interval and a location and then, we give an equivalent Mixed Integer Linear Programming (MILP) formulation of the problem. For small to medium-sized instances, this formulation can be efficiently solved using standard MILP solvers. However, for larger instances, the computational complexity increases significantly due to the highly combinatorial nature of the refilling process at the sources. To address this challenge, we propose a two-step heuristic that enhances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03322v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raian Lefgoum (CERMICS), Sezin Afsar (UMA), Pierre Carpentier (UMA), Jean-Philippe Chancelier (CERMICS), Michel de Lara (CERMICS)</dc:creator>
    </item>
    <item>
      <title>Controlled Invariance in Fully Actuated Max-plus Linear Systems with Precedence Semimodules</title>
      <link>https://arxiv.org/abs/2503.03357</link>
      <description>arXiv:2503.03357v1 Announce Type: new 
Abstract: Given a max-plus linear system and a semimodule, the problem of computing the maximal controlled invariant subsemimodule is still open to this day. In this paper, we consider this problem for the specific class of fully actuated systems and constraints in the form of precedence semimodules. The assumption of full actuation corresponds to the existence of an input for each component of the system state. A precedence semimodule is the set of solutions of inequalities typically used to represent time-window constraints. We prove that, in this setting, it is possible to (i) compute the maximal controlled invariant subsemimodule and (ii) decide the convergence of a fixed-point algorithm introduced by R.D. Katz in strongly polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03357v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Zorzenon, J\"org Raisch</dc:creator>
    </item>
    <item>
      <title>Using infinitesimal symmetries for determining the first Maxwell time of geometric control problem on SH(2)</title>
      <link>https://arxiv.org/abs/2503.03386</link>
      <description>arXiv:2503.03386v1 Announce Type: new 
Abstract: In this work, we utilize infinitesimal symmetries to compute Maxwell points which play a crucial role in studying sub-Riemannian control problems. By examining the infinitesimal symmetries of the geometric control problem on the SH(2) group, particularly through its Lie algebraic structure, we identify invariant quantities and constraints that streamline the Maxwell point computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03386v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soukaina Ezzeroual, Brahim Sadik</dc:creator>
    </item>
    <item>
      <title>Stability analysis for set-valued optimization in Geoffroy spaces</title>
      <link>https://arxiv.org/abs/2503.03405</link>
      <description>arXiv:2503.03405v1 Announce Type: new 
Abstract: In this work, we study the external and internal stability of minimal solutions to set-valued optimization problems in a new functional framework. We consider perturbations on both the objective function and the admissible domain. To address these problems, we introduce two variational convergences for sequences of set-valued maps, namely the Gamma-cone convergence and the sequential Gamma-cone convergence. The upper and the lower convergence of strong level sets are also studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03405v1</guid>
      <category>math.OC</category>
      <category>math.GN</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>James Larrouy</dc:creator>
    </item>
    <item>
      <title>A Novel First-order Method with Event-driven Objective Evaluations</title>
      <link>https://arxiv.org/abs/2503.03526</link>
      <description>arXiv:2503.03526v1 Announce Type: new 
Abstract: Arising in semi-parametric statistics, control applications, and as sub-problems in global optimization methods, certain optimization problems can have objective functions requiring numerical integration to evaluate, yet gradient function evaluations that are relatively cheap. For such problems, typical optimization methods that require multiple evaluations of the objective for each new iterate become computationally expensive. In light of this, optimization methods that avoid objective function evaluations are attractive, yet we show anti-convergence behavior for these methods on the problem class of interest. To address this gap, we develop a novel gradient algorithm that only evaluates the objective function when specific events are triggered and propose a step size scheme that greedily takes advantage of the properties induced by these triggering events. We prove that our methodology has global convergence guarantees under the most general smoothness conditions, and show through extensive numerical results that our method performs favorably on optimization problems arising in semi-parametric statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03526v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Varner, Vivak Patel</dc:creator>
    </item>
    <item>
      <title>imuQP: An Inverse-Matrix-Updates-Based Fast QP Solver Suitable for Real-Time MPC</title>
      <link>https://arxiv.org/abs/2503.03581</link>
      <description>arXiv:2503.03581v1 Announce Type: new 
Abstract: This paper presents a new fast active-set quadratic programming (QP) solver based on inverse matrix updates, which is suitable for real-time model predictive control (MPC). This QP solver, called imuQP (inverse matrix update QP), is based on Karush-Kuhn-Tucker (KKT) conditions and is inspired by Hildreth's QP solver. An extensive convergence and optimality analysis of imuQP, including infeasibility detection, is presented. The memory footprint and computational complexity of imuQP are analyzed and compared with qpOASES, a well-known active-set QP solver in literature. Speed and accuracy of imuQP are compared with state-of-the-art active-set QP solvers by simulating a chain of spring-connected masses in MATLAB. For illustration, MPC with integral action is used, to remove offset when tracking a constant reference, with a small sampling period of Ts = 4 ms. Simulation results show that imuQP is suitable for fast systems - with small Ts - and is competitive with state-of-the-art active-set QP solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03581v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Truong Thinh Lam, Mircea Lazar</dc:creator>
    </item>
    <item>
      <title>Carleman estimate for semi-discrete stochastic parabolic operators in arbitrary dimension and applications to controllability</title>
      <link>https://arxiv.org/abs/2503.03596</link>
      <description>arXiv:2503.03596v1 Announce Type: new 
Abstract: This paper considers a semi-discrete forward stochastic parabolic operator with homogeneous Dirichlet conditions in arbitrary dimensions. We show the lack of null controllability for a spatial semi-discretization of a null-controllable stochastic parabolic system from any initial datum. However, by proving a new Carleman estimate for its semi-discrete backward stochastic adjoint system, we achieve a relaxed observability inequality, which is applied to derivative $\phi$-null controllability by duality arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03596v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Lecaros, Ariel A. P\'erez, Manuel F. Prado</dc:creator>
    </item>
    <item>
      <title>Deterministic Global Optimization of the Acquisition Function in Bayesian Optimization: To Do or Not To Do?</title>
      <link>https://arxiv.org/abs/2503.03625</link>
      <description>arXiv:2503.03625v1 Announce Type: new 
Abstract: Bayesian Optimization (BO) with Gaussian Processes relies on optimizing an acquisition function to determine sampling. We investigate the advantages and disadvantages of using a deterministic global solver (MAiNGO) compared to conventional local and stochastic global solvers (L-BFGS-B and multi-start, respectively) for the optimization of the acquisition function. For CPU efficiency, we set a time limit for MAiNGO, taking the best point as optimal. We perform repeated numerical experiments, initially using the Muller-Brown potential as a benchmark function, utilizing the lower confidence bound acquisition function; we further validate our findings with three alternative benchmark functions. Statistical analysis reveals that when the acquisition function is more exploitative (as opposed to exploratory), BO with MAiNGO converges in fewer iterations than with the local solvers. However, when the dataset lacks diversity, or when the acquisition function is overly exploitative, BO with MAiNGO, compared to the local solvers, is more likely to converge to a local rather than a global ly near-optimal solution of the black-box function. L-BFGS-B and multi-start mitigate this risk in BO by introducing stochasticity in the selection of the next sampling point, which enhances the exploration of uncharted regions in the search space and reduces dependence on acquisition function hyperparameters. Ultimately, suboptimal optimization of poorly chosen acquisition functions may be preferable to their optimal solution. When the acquisition function is more exploratory, BO with MAiNGO, multi-start, and L-BFGS-B achieve comparable probabilities of convergence to a globally near-optimal solution (although BO with MAiNGO may require more iterations to converge under these conditions).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03625v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasia Georgiou, Daniel Jungen, Luise Kaven, Verena Hunstig, Constantine Frangakis, Ioannis Kevrekidis, Alexander Mitsos</dc:creator>
    </item>
    <item>
      <title>Regularization for Covariance Parameterization of Direct Data-Driven LQR Control</title>
      <link>https://arxiv.org/abs/2503.02985</link>
      <description>arXiv:2503.02985v1 Announce Type: cross 
Abstract: As the benchmark of data-driven control methods, the linear quadratic regulator (LQR) problem has gained significant attention. A growing trend is direct LQR design, which finds the optimal LQR gain directly from raw data and bypassing system identification. To achieve this, our previous work develops a direct LQR formulation parameterized by sample covariance. In this paper, we propose a regularization method for the covariance-parameterized LQR. We show that the regularizer accounts for the uncertainty in both the steady-state covariance matrix corresponding to closed-loop stability, and the LQR cost function corresponding to averaged control performance. With a positive or negative coefficient, the regularizer can be interpreted as promoting either exploitation or exploration, which are well-known trade-offs in reinforcement learning. In simulations, we observe that our covariance-parameterized LQR with regularization can significantly outperform the certainty-equivalence LQR in terms of both the optimality gap and the robust closed-loop stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02985v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Alessandro Chiuso, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Multi-Step Deep Koopman Network (MDK-Net) for Vehicle Control in Frenet Frame</title>
      <link>https://arxiv.org/abs/2503.03002</link>
      <description>arXiv:2503.03002v1 Announce Type: cross 
Abstract: The highly nonlinear dynamics of vehicles present a major challenge for the practical implementation of optimal and Model Predictive Control (MPC) approaches in path planning and following. Koopman operator theory offers a global linear representation of nonlinear dynamical systems, making it a promising framework for optimization-based vehicle control. This paper introduces a novel deep learning-based Koopman modeling approach that employs deep neural networks to capture the full vehicle dynamics-from pedal and steering inputs to chassis states-within a curvilinear Frenet frame. The superior accuracy of the Koopman model compared to identified linear models is shown for a double lane change maneuver. Furthermore, it is shown that an MPC controller deploying the Koopman model provides significantly improved performance while maintaining computational efficiency comparable to a linear MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03002v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abtahi, Mahdis Rabbani, Armin Abdolmohammadi, Shima Nazari</dc:creator>
    </item>
    <item>
      <title>On the uniform convexity of the squared distance</title>
      <link>https://arxiv.org/abs/2503.03442</link>
      <description>arXiv:2503.03442v1 Announce Type: cross 
Abstract: In 1983, Z\u{a}linescu showed that the squared norm of a uniformly convex normed space is uniformly convex on bounded subsets. We extend this result to the metric setting of uniformly convex hyperbolic spaces. We derive applications to the convergence of shadow sequences and to proximal minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03442v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Sipos</dc:creator>
    </item>
    <item>
      <title>Goh and Legendre-Clebsh conditions for nonsmooth control systems</title>
      <link>https://arxiv.org/abs/2308.06867</link>
      <description>arXiv:2308.06867v3 Announce Type: replace 
Abstract: Higher order necessary conditions for a minimizer of an optimal control problem are generally obtained for systems whose dynamics is at least continuously differentiable in the state variable. Here, by making use of the notion of set-valued Lie bracket introduced in "Set-valued differentials and a nonsmooth version of Chow-Rashevski's theorem" by F. Rampazzo and H.J.Sussmann and extended in "Iterated Lie brackets for nonsmooth vector fields" by E. Feleqi and F.Rampazzo , we obtain Goh and Legendre-Clebsh type conditions for a control affine system with Lipschitz continuous dynamics. In order to manage the simultaneous lack of smoothness of the adjoint equation and of the Lie bracket-like variations, we will exploit the notion of Quasi Differential Quotient, introduced in "A geometrically based criterion to avoid infimum-gaps in Optimal Control" by M. Palladino and F.Rampazzo. We finally exhibit an example where the established higher order condition is capable to rule out the optimality of a control verifying a first order Maximum Principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06867v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Angrisani, Franco Rampazzo</dc:creator>
    </item>
    <item>
      <title>Optimal transport of measures via autonomous vector fields</title>
      <link>https://arxiv.org/abs/2405.06503</link>
      <description>arXiv:2405.06503v2 Announce Type: replace 
Abstract: We study the problem of transporting one probability measure to another via an autonomous velocity field. We rely on tools from the theory of optimal transport. In one space-dimension, we solve a linear homogeneous functional equation to construct a suitable autonomous vector field that realizes the (unique) monotone transport map as the time-$1$ map of its flow. Generically, this vector field can be chosen to be Lipschitz continuous. We then use Sudakov's disintegration approach to deal with the multi-dimensional case by reducing it to a family of one-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06503v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.CA</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola De Nitti, Xavier Fern\'andez-Real</dc:creator>
    </item>
    <item>
      <title>Contraction Analysis of Continuation Method for Suboptimal Model Predictive Control</title>
      <link>https://arxiv.org/abs/2409.10970</link>
      <description>arXiv:2409.10970v2 Announce Type: replace 
Abstract: This letter analyzes the contraction property of the nonlinear systems controlled by suboptimal model predictive control (MPC) using the continuation method. We propose a contraction metric that reflects the hierarchical dynamics inherent in the continuation method. We derive a pair of matrix inequalities that elucidate the impact of suboptimality on the contraction of the optimally controlled closed-loop system. A numerical example is presented to verify our contraction analysis. Our results are applicable to other MPCs than stabilization, including economic MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10970v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3523584</arxiv:DOI>
      <dc:creator>Ryotaro Shima, Yuji Ito, Tatsuya Miyano</dc:creator>
    </item>
    <item>
      <title>Twice Epi-Differentiability of Orthogonally Invariant Matrix Functions and Application</title>
      <link>https://arxiv.org/abs/2412.09898</link>
      <description>arXiv:2412.09898v2 Announce Type: replace 
Abstract: In this paper, our focus lies on the study of the second-order variational analysis of orthogonally invariant matrix functions. It is well-known that an orthogonally invariant matrix function is an extended-real-value function defined on ${\mathbb M}_{m,n}\,(n \leqslant m)$ of the form $f \circ \sigma$ for an absolutely symmetric function $f \colon \R^n \rightarrow [-\infty,+\infty]$ and the singular values $\sigma \colon {\mathbb M}_{m,n} \rightarrow \R^{n}$. We establish several second-order properties of orthogonally invariant matrix functions, such as parabolic epi-differentiability, parabolic regularity, and twice epi-differentiability when their associated absolutely symmetric functions enjoy some properties. Specifically, we show that the nuclear norm of a real $m \times n$ matrix is twice epi-differentiable and we derive an explicit expression of its second-order epi-derivative. Moreover, for a convex orthogonally invariant matrix function, we calculate its second subderivative and present sufficient conditions for twice epi-differentiability. This enables us to establish second-order optimality conditions for a class of matrix optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09898v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahuan He, Chao Kan, Wen Song</dc:creator>
    </item>
    <item>
      <title>Extended Set Difference : Inverse Operation of Minkowski Summation</title>
      <link>https://arxiv.org/abs/2412.19779</link>
      <description>arXiv:2412.19779v2 Announce Type: replace 
Abstract: This paper introduces the extended set difference, a generalization of the Hukuhara and generalized Hukuhara differences, defined for compact convex sets in $\mathbb{R}^d$. The proposed difference guarantees existence for any pair of such sets, offering a broader framework for set arithmetic. The difference may not be necessarily unique, but we offer a bound on the variety of solutions. The definition of the extended set difference is formulated through an optimization problem, which provides a constructive approach to its computation. The paper explores the properties of this new difference, including its stability under orthogonal transformations and its robustness to perturbations of the input sets. We propose a method to compute this difference through a formulated linear optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19779v2</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arie Beresteanu, Behrooz Moosavi Ramezanzadeh</dc:creator>
    </item>
    <item>
      <title>Comments and extensions on "State-equivalent form and minimum-order compensator design for rectangular descriptor systems"</title>
      <link>https://arxiv.org/abs/2501.13445</link>
      <description>arXiv:2501.13445v3 Announce Type: replace 
Abstract: This technical note presents a counterexample showing that the equivalence conditions proposed by Geng et al. (IEEE Trans. Automat. Control, 2024), which use a minimum-order compensator (MOC) to achieve desired designs, including generalized regularity or both generalized regularity and free of impulse, are sufficient but not necessary. Furthermore, revised equivalence conditions are introduced, along with an equivalence condition ensuring the closed-loop system remains generalized regular, impulse-free, and stable using MOC. Additionally, it is shown that output feedback can replace the MOC, achieving the same design without increasing dimensionality. These findings are validated through a circuit example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13445v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Shi, Juan Zhang</dc:creator>
    </item>
    <item>
      <title>Parameter-Dependent Control Lyapunov Functions for Stabilizing Nonlinear Parameter-Varying Systems</title>
      <link>https://arxiv.org/abs/2502.06770</link>
      <description>arXiv:2502.06770v2 Announce Type: replace 
Abstract: This paper introduces the concept of parameter-dependent (PD) control Lyapunov functions (CLFs) for gain-scheduled stabilization of nonlinear parameter-varying (NPV) systems. It shows that given a PD-CLF, a min-norm control law can be constructed by solving a robust quadratic program. For polynomial control-affine NPV systems, it provides convex conditions, based on the sum of squares programming, to jointly synthesize a PD-CLF and a PD controller while maximizing the PD region of stabilization. Input constraints can be straightforwardly incorporated into the synthesis procedure. Unlike traditional linear parameter-varying (LPV) methods that rely on linearization or over-approximation to get an LPV model, the proposed framework fully captures the nonlinearities of the system dynamics. The theoretical results are validated through numerical simulations, including a 2D rocket landing case study under varying mass and inertia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06770v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pan Zhao</dc:creator>
    </item>
    <item>
      <title>Nonconvex optimization and convergence of stochastic gradient descent, and solution of asynchronous game</title>
      <link>https://arxiv.org/abs/2503.02155</link>
      <description>arXiv:2503.02155v2 Announce Type: replace 
Abstract: We review convergence and behavior of stochastic gradient descent for convex and nonconvex optimization, establishing various conditions for convergence to zero of the variance of the gradient of the objective function, and presenting a number of simple examples demonstrating the approximate evolution of the probability density under iteration, including applications to both classical two-player and asynchronous multiplayer games</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02155v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Buck, Jessica Babyak, Paolo Piersanti, Kevin Zumbrun, Christiane Gallos, Dorothea Gallos</dc:creator>
    </item>
    <item>
      <title>HiGrad: Uncertainty Quantification for Online Learning and Stochastic Approximation</title>
      <link>https://arxiv.org/abs/1802.04876</link>
      <description>arXiv:1802.04876v3 Announce Type: replace-cross 
Abstract: Stochastic gradient descent (SGD) is an immensely popular approach for online learning in settings where data arrives in a stream or data sizes are very large. However, despite an ever-increasing volume of work on SGD, much less is known about the statistical inferential properties of SGD-based predictions. Taking a fully inferential viewpoint, this paper introduces a novel procedure termed HiGrad to conduct statistical inference for online learning, without incurring additional computational cost compared with SGD. The HiGrad procedure begins by performing SGD updates for a while and then splits the single thread into several threads, and this procedure hierarchically operates in this fashion along each thread. With predictions provided by multiple threads in place, a $t$-based confidence interval is constructed by decorrelating predictions using covariance structures given by a Donsker-style extension of the Ruppert--Polyak averaging scheme, which is a technical contribution of independent interest. Under certain regularity conditions, the HiGrad confidence interval is shown to attain asymptotically exact coverage probability. Finally, the performance of HiGrad is evaluated through extensive simulation studies and a real data example. An R package \texttt{higrad} has been developed to implement the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:1802.04876v3</guid>
      <category>stat.ML</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijie J. Su, Yuancheng Zhu</dc:creator>
    </item>
    <item>
      <title>Simple Alternating Minimization Provably Solves Complete Dictionary Learning</title>
      <link>https://arxiv.org/abs/2210.12816</link>
      <description>arXiv:2210.12816v2 Announce Type: replace-cross 
Abstract: This paper focuses on the noiseless complete dictionary learning problem, where the goal is to represent a set of given signals as linear combinations of a small number of atoms from a learned dictionary. There are two main challenges faced by theoretical and practical studies of dictionary learning: the lack of theoretical guarantees for practically-used heuristic algorithms and their poor scalability when dealing with huge-scale datasets. Towards addressing these issues, we propose a simple and efficient algorithm that provably recovers the ground truth when applied to the nonconvex and discrete formulation of the problem in the noiseless setting. We also extend our proposed method to mini-batch and online settings where the data is huge-scale or arrives continuously over time. At the core of our proposed method lies an efficient preconditioning technique that transforms the unknown dictionary to a near-orthonormal one, for which we prove a simple alternating minimization technique converges linearly to the ground truth under minimal conditions. Our numerical experiments on synthetic and real datasets showcase the superiority of our method compared with the existing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12816v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geyu Liang, Gavin Zhang, Salar Fattahi, Richard Y. Zhang</dc:creator>
    </item>
    <item>
      <title>$\mu^2$-SGD: Stable Stochastic Optimization via a Double Momentum Mechanism</title>
      <link>https://arxiv.org/abs/2304.04172</link>
      <description>arXiv:2304.04172v2 Announce Type: replace-cross 
Abstract: We consider stochastic convex optimization problems where the objective is an expectation over smooth functions. For this setting we suggest a novel gradient estimate that combines two recent mechanism that are related to notion of momentum. Then, we design an SGD-style algorithm as well as an accelerated version that make use of this new estimator, and demonstrate the robustness of these new approaches to the choice of the learning rate. Concretely, we show that these approaches obtain the optimal convergence rates for both noiseless and noisy case with the same choice of fixed learning rate. Moreover, for the noisy case we show that these approaches achieve the same optimal bound for a very wide range of learning rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04172v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tehila Dahan, Kfir Y. Levy</dc:creator>
    </item>
    <item>
      <title>Nash Equilibrium and Learning Dynamics in Three-Player Matching $m$-Action Games</title>
      <link>https://arxiv.org/abs/2402.10825</link>
      <description>arXiv:2402.10825v3 Announce Type: replace-cross 
Abstract: Learning in games discusses the processes where multiple players learn their optimal strategies through the repetition of game plays. The dynamics of learning between two players in zero-sum games, such as Matching Pennies, where their benefits are competitive, have already been well analyzed. However, it is still unexplored and challenging to analyze the dynamics of learning among three players. In this study, we formulate a minimalistic game where three players compete to match their actions with one another. Although interaction among three players diversifies and complicates the Nash equilibria, we fully analyze the equilibria. We also discuss the dynamics of learning based on some famous algorithms categorized into Follow the Regularized Leader. From both theoretical and experimental aspects, we characterize the dynamics by categorizing three-player interactions into three forces to synchronize their actions, switch their actions rotationally, and seek competition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10825v3</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>Reusing Historical Trajectories in Natural Policy Gradient via Importance Sampling: Convergence and Convergence Rate</title>
      <link>https://arxiv.org/abs/2403.00675</link>
      <description>arXiv:2403.00675v2 Announce Type: replace-cross 
Abstract: Reinforcement learning provides a mathematical framework for learning-based control, whose success largely depends on the amount of data it can utilize. The efficient utilization of historical trajectories obtained from previous policies is essential for expediting policy optimization. Empirical evidence has shown that policy gradient methods based on importance sampling work well. However, existing literature often neglect the interdependence between trajectories from different iterations, and the good empirical performance lacks a rigorous theoretical justification. In this paper, we study a variant of the natural policy gradient method with reusing historical trajectories via importance sampling. We show that the bias of the proposed estimator of the gradient is asymptotically negligible, the resultant algorithm is convergent, and reusing past trajectories helps improve the convergence rate. We further apply the proposed estimator to popular policy optimization algorithms such as trust region policy optimization. Our theoretical results are verified on classical benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00675v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Lin, Yuhao Wang, Enlu Zhou</dc:creator>
    </item>
    <item>
      <title>Task-optimal data-driven surrogate models for eNMPC via differentiable simulation and optimization</title>
      <link>https://arxiv.org/abs/2403.14425</link>
      <description>arXiv:2403.14425v3 Announce Type: replace-cross 
Abstract: Mechanistic dynamic process models may be too computationally expensive to be usable as part of a real-time capable predictive controller. We present a method for end-to-end learning of Koopman surrogate models for optimal performance in a specific control task. In contrast to previous contributions that employ standard reinforcement learning (RL) algorithms, we use a training algorithm that exploits the differentiability of environments based on mechanistic simulation models to aid the policy optimization. We evaluate the performance of our method by comparing it to that of other training algorithms on an existing economic nonlinear model predictive control (eNMPC) case study of a continuous stirred-tank reactor (CSTR) model. Compared to the benchmark methods, our method produces similar economic performance while eliminating constraint violations. Thus, for this case study, our method outperforms the others and offers a promising path toward more performant controllers that employ dynamic surrogate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14425v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Mayfrank, Na Young Ahn, Alexander Mitsos, Manuel Dahmen</dc:creator>
    </item>
    <item>
      <title>Global Behavior of Learning Dynamics in Zero-Sum Games with Memory Asymmetry</title>
      <link>https://arxiv.org/abs/2405.14546</link>
      <description>arXiv:2405.14546v2 Announce Type: replace-cross 
Abstract: This study examines the global behavior of dynamics in learning in games between two players, X and Y. We consider the simplest situation for memory asymmetry between two players: X memorizes the other Y's previous action and uses reactive strategies, while Y has no memory. Although this memory complicates their learning dynamics, we characterize the global behavior of such complex dynamics by discovering and analyzing two novel quantities. One is an extended Kullback-Leibler divergence from the Nash equilibrium, a well-known conserved quantity from previous studies. The other is a family of Lyapunov functions of X's reactive strategy. One of the global behaviors we capture is that if X exploits Y, then their strategies converge to the Nash equilibrium. Another is that if Y's strategy is out of equilibrium, then X becomes more exploitative with time. Consequently, we suggest global convergence to the Nash equilibrium from both aspects of theory and experiment. This study provides a novel characterization of the global behavior in learning in games through a couple of indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14546v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>From Learning to Optimize to Learning Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2405.18222</link>
      <description>arXiv:2405.18222v2 Announce Type: replace-cross 
Abstract: Towards designing learned optimization algorithms that are usable beyond their training setting, we identify key principles that classical algorithms obey, but have up to now, not been used for Learning to Optimize (L2O). Following these principles, we provide a general design pipeline, taking into account data, architecture and learning strategy, and thereby enabling a synergy between classical optimization and L2O, resulting in a philosophy of Learning Optimization Algorithms. As a consequence our learned algorithms perform well far beyond problems from the training distribution. We demonstrate the success of these novel principles by designing a new learning-enhanced BFGS algorithm and provide numerical experiments evidencing its adaptation to many settings at test time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18222v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camille Castera, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>MDP Geometry, Normalization and Reward Balancing Solvers</title>
      <link>https://arxiv.org/abs/2407.06712</link>
      <description>arXiv:2407.06712v4 Announce Type: replace-cross 
Abstract: We present a new geometric interpretation of Markov Decision Processes (MDPs) with a natural normalization procedure that allows us to adjust the value function at each state without altering the advantage of any action with respect to any policy. This advantage-preserving transformation of the MDP motivates a class of algorithms which we call Reward Balancing, which solve MDPs by iterating through these transformations, until an approximately optimal policy can be trivially found. We provide a convergence analysis of several algorithms in this class, in particular showing that for MDPs for unknown transition probabilities we can improve upon state-of-the-art sample complexity results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06712v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsenii Mustafin, Aleksei Pakharev, Alex Olshevsky, Ioannis Ch. Paschalidis</dc:creator>
    </item>
    <item>
      <title>Synchronization in Learning in Periodic Zero-Sum Games Triggers Divergence from Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2408.10595</link>
      <description>arXiv:2408.10595v2 Announce Type: replace-cross 
Abstract: Learning in zero-sum games studies a situation where multiple agents competitively learn their strategy. In such multi-agent learning, we often see that the strategies cycle around their optimum, i.e., Nash equilibrium. When a game periodically varies (called a ``periodic'' game), however, the Nash equilibrium moves generically. How learning dynamics behave in such periodic games is of interest but still unclear. Interestingly, we discover that the behavior is highly dependent on the relationship between the two speeds at which the game changes and at which players learn. We observe that when these two speeds synchronize, the learning dynamics diverge, and their time-average does not converge. Otherwise, the learning dynamics draw complicated cycles, but their time-average converges. Under some assumptions introduced for the dynamical systems analysis, we prove that this behavior occurs. Furthermore, our experiments observe this behavior even if removing these assumptions. This study discovers a novel phenomenon, i.e., synchronization, and gains insight widely applicable to learning in periodic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10595v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>Two-person Positive Shortest Path Games Have Nash Equilibria in Pure Stationary Strategies</title>
      <link>https://arxiv.org/abs/2410.09257</link>
      <description>arXiv:2410.09257v2 Announce Type: replace-cross 
Abstract: We prove that every finite two-person shortest path game, where the local cost of every move is positive for each player, has a Nash equilibrium (NE) in pure stationary strategies, which can be computed in polynomial time. We also extend the existence result to infinite graphs with finite out-degrees. Moreover, our proof gives that a terminal NE (in which the play is a path from the initial position to a terminal) exists provided at least one of the two players can guarantee reaching a terminal. If none of the players can do it, in other words, if each of the two players has a strategy that separates all terminals from the initial position $s$, then, obviously, a cyclic NE exists, although its cost is infinite for both players, since we restrict ourselves to positive games. We conjecture that a terminal NE exists too, provided there exists a directed path from $s$ to a terminal. However, this is open.
  We extend our result to short paths interdiction games, where at each vertex, we allow one player to block some of the arcs and the other player to choose one of the non-blocked arcs. Assuming that blocking sets are chosen from an independence system given by an oracle, we give an algorithm for computing a NE in time $O(|E|(\log|V|+\tau))$, where $V$ is the set of vertices, $E$ is the set of arcs, and $\tau$ is the maximum time taken by the oracle on any input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09257v2</guid>
      <category>cs.DM</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Endre Boros, Khaled Elbassioni, Vladimir Gurvich, Mikhail Vyalyi</dc:creator>
    </item>
    <item>
      <title>Efficient Sparse PCA via Block-Diagonalization</title>
      <link>https://arxiv.org/abs/2410.14092</link>
      <description>arXiv:2410.14092v2 Announce Type: replace-cross 
Abstract: Sparse Principal Component Analysis (Sparse PCA) is a pivotal tool in data analysis and dimensionality reduction. However, Sparse PCA is a challenging problem in both theory and practice: it is known to be NP-hard and current exact methods generally require exponential runtime. In this paper, we propose a novel framework to efficiently approximate Sparse PCA by (i) approximating the general input covariance matrix with a re-sorted block-diagonal matrix, (ii) solving the Sparse PCA sub-problem in each block, and (iii) reconstructing the solution to the original problem. Our framework is simple and powerful: it can leverage any off-the-shelf Sparse PCA algorithm and achieve significant computational speedups, with a minor additive error that is linear in the approximation error of the block-diagonal matrix. Suppose $g(k, d)$ is the runtime of an algorithm (approximately) solving Sparse PCA in dimension $d$ and with sparsity constant $k$. Our framework, when integrated with this algorithm, reduces the runtime to $\mathcal{O}\left(\frac{d}{d^\star} \cdot g(k, d^\star) + d^2\right)$, where $d^\star \leq d$ is the largest block size of the block-diagonal matrix. For instance, integrating our framework with the Branch-and-Bound algorithm reduces the complexity from $g(k, d) = \mathcal{O}(k^3\cdot d^k)$ to $\mathcal{O}(k^3\cdot d \cdot (d^\star)^{k-1})$, demonstrating exponential speedups if $d^\star$ is small. We perform large-scale evaluations on many real-world datasets: for exact Sparse PCA algorithm, our method achieves an average speedup factor of 100.50, while maintaining an average approximation error of 0.61%; for approximate Sparse PCA algorithm, our method achieves an average speedup factor of 6.00 and an average approximation error of -0.91%, meaning that our method oftentimes finds better solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14092v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia, Dekun Zhou, Yinglun Zhu</dc:creator>
    </item>
    <item>
      <title>Grams: Gradient Descent with Adaptive Momentum Scaling</title>
      <link>https://arxiv.org/abs/2412.17107</link>
      <description>arXiv:2412.17107v3 Announce Type: replace-cross 
Abstract: We introduce $\mathbf{G}$radient Descent with $\mathbf{A}$daptive $\mathbf{M}$omentum $\mathbf{S}$caling ($\mathbf{Grams}$), a novel optimization algorithm that decouples the direction and magnitude of parameter updates in deep learning. Unlike traditional optimizers that directly integrate momentum into updates, Grams separates the update direction, derived from current gradients, from momentum, which is used solely for adaptive magnitude scaling. This approach enables Grams to achieve improved loss descent compared to state-of-the-art cautious and momentum-based optimizers. We theoretically demonstrate that Grams descents faster than other state-of-the-art optimizers and establish a global convergence guarantee for Grams. We also validate its effectiveness through extensive empirical evaluations. The results demonstrate Grams' superior performance, including faster convergence and better generalization, compared to widely-used optimizers such as Adam, Lion, and their cautious variants. Our results highlight Grams' potential as a transformative approach for efficiently training and fine-tuning large language models. Code is available at https://github.com/Gunale0926/Grams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17107v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yang Cao, Xiaoyu Li, Zhao Song</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Problem for Multi-armed Bandits via Convex Optimization</title>
      <link>https://arxiv.org/abs/2501.18945</link>
      <description>arXiv:2501.18945v2 Announce Type: replace-cross 
Abstract: We consider the inverse problem of multi-armed bandits (IMAB) that are widely used in neuroscience and psychology research for behavior modelling. We first show that the IMAB problem is not convex in general, but can be relaxed to a convex problem via variable transformation. Based on this result, we propose a two-step sequential heuristic for (approximately) solving the IMAB problem. We discuss a condition where our method provides global solution to the IMAB problem with certificate, as well as approximations to further save computing time. Numerical experiments indicate that our heuristic method is more robust than directly solving the IMAB problem via repeated local optimization, and can achieve the performance of Monte Carlo methods within a significantly decreased running time. We provide the implementation of our method based on CVXPY, which allows straightforward application by users not well versed in convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18945v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zhu, Joschka Boedecker</dc:creator>
    </item>
    <item>
      <title>Online Scheduling for LLM Inference with KV Cache Constraints</title>
      <link>https://arxiv.org/abs/2502.07115</link>
      <description>arXiv:2502.07115v3 Announce Type: replace-cross 
Abstract: Large Language Model (LLM) inference, where a trained model generates text one word at a time in response to user prompts, is a computationally intensive process requiring efficient scheduling to optimize latency and resource utilization. A key challenge in LLM inference is the management of the Key-Value (KV) cache, which reduces redundant computations but introduces memory constraints. In this work, we model LLM inference with KV cache constraints theoretically and propose novel batching and scheduling algorithms that minimize inference latency while effectively managing the KV cache's memory.
  We analyze both semi-online and fully online scheduling models, and our results are threefold. First, we provide a polynomial-time algorithm that achieves exact optimality in terms of average latency in the semi-online prompt arrival model. Second, in the fully online case with a stochastic prompt arrival, we introduce an efficient online scheduling algorithm with constant regret. Third, we prove that no algorithm (deterministic or randomized) can achieve a constant competitive ratio in fully online adversarial settings. Our empirical evaluations on a public LLM inference dataset, using the Llama-70B model on A100 GPUs, show that our approach significantly outperforms benchmark algorithms used currently in practice, achieving lower latency while reducing energy consumption. Overall, our results offer a path toward more sustainable and cost-effective LLM deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07115v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Jaillet, Jiashuo Jiang, Chara Podimata, Zijie Zhou</dc:creator>
    </item>
  </channel>
</rss>
