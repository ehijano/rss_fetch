<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Oct 2024 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Physics-informed Neural Networks for Functional Differential Equations: Cylindrical Approximation and Its Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2410.18153</link>
      <description>arXiv:2410.18153v1 Announce Type: new 
Abstract: We propose the first learning scheme for functional differential equations (FDEs). FDEs play a fundamental role in physics, mathematics, and optimal control. However, the numerical analysis of FDEs has faced challenges due to its unrealistic computational costs and has been a long standing problem over decades. Thus, numerical approximations of FDEs have been developed, but they often oversimplify the solutions. To tackle these two issues, we propose a hybrid approach combining physics-informed neural networks (PINNs) with the \textit{cylindrical approximation}. The cylindrical approximation expands functions and functional derivatives with an orthonormal basis and transforms FDEs into high-dimensional PDEs. To validate the reliability of the cylindrical approximation for FDE applications, we prove the convergence theorems of approximated functional derivatives and solutions. Then, the derived high-dimensional PDEs are numerically solved with PINNs. Through the capabilities of PINNs, our approach can handle a broader class of functional derivatives more efficiently than conventional discretization-based methods, improving the scalability of the cylindrical approximation. As a proof of concept, we conduct experiments on two FDEs and demonstrate that our model can successfully achieve typical $L^1$ relative error orders of PINNs $\sim 10^{-3}$. Overall, our work provides a strong backbone for physicists, mathematicians, and machine learning experts to analyze previously challenging FDEs, thereby democratizing their numerical analysis, which has received limited attention. Code is available at \url{https://github.com/TaikiMiyagawa/FunctionalPINN}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18153v1</guid>
      <category>math.NA</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>hep-th</category>
      <category>stat.ML</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taiki Miyagawa, Takeru Yokota</dc:creator>
    </item>
    <item>
      <title>The Zero Inertia Limit for the Q-Tensor Model of Liquid Crystals: Analysis and Numerics</title>
      <link>https://arxiv.org/abs/2410.18328</link>
      <description>arXiv:2410.18328v1 Announce Type: new 
Abstract: The goal of this work is to rigorously study the zero inertia limit for the Q-tensor model of liquid crystals. Though present in the original derivation of the Ericksen-Leslie equations for nematic liquid crystals, the inertia term of the model is often neglected in analysis and applications. We show wellposedness of the model including inertia and then show using the relative entropy method that solutions of the model with inertia converge to solutions of the model without inertia at a rate ${\sigma}$ in $L^\infty(0,T;H^1(\dom))$, where $\sigma$ is the inertial constant. Furthermore, we present an energy stable finite element scheme that is stable and convergent for all $\sigma$ and study the zero inertia limit numerically. We also present error estimates for the fully discrete scheme with respect to the discretization parameters in time and space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18328v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Max Hirsch, Franziska Weber, Yukun Yue</dc:creator>
    </item>
    <item>
      <title>The grad-div conforming virtual element method for the quad-div problem in three dimensions</title>
      <link>https://arxiv.org/abs/2410.18375</link>
      <description>arXiv:2410.18375v1 Announce Type: new 
Abstract: We propose a new stable variational formulation for the quad-div problem in three dimensions and prove its well-posedness. Using this weak form, we develop and analyze the $\boldsymbol{H}(\operatorname{grad-div})$-conforming virtual element method of arbitrary approximation orders on polyhedral meshes. Three families of $\boldsymbol{H}(\operatorname{grad-div})$-conforming virtual elements are constructed based on the structure of a de Rham sub-complex with enhanced smoothness, resulting in an exact discrete virtual element complex. In the lowest-order case, the simplest element has only one degree of freedom at each vertex and face, respectively. We rigorously prove the interpolation error estimates, the stability of discrete bilinear forms, the well-posedness of discrete formulation and the optimal error estimates. Some numerical examples are shown to verify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18375v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaojing Dong, Yibing Han, Yunqing Huang</dc:creator>
    </item>
    <item>
      <title>Conservative nonconforming virtual element method for stationary incompressible magnetohydrodynamics</title>
      <link>https://arxiv.org/abs/2410.18376</link>
      <description>arXiv:2410.18376v1 Announce Type: new 
Abstract: In this paper, we propose a conservative nonconforming virtual element method for the full stationary incompressible magnetohydrodynamics model. We leverage the virtual element satisfactory divergence-free property to ensure mass conservation for the velocity field. The condition of the well-posedness of the proposed method, as well as the stability are derived. We establish optimal error estimates in the discrete energy norm for both the velocity and magnetic field. Furthermore, by employing a new technique, we obtain the optimal error estimates in $L^2$-norm without any additional conditions. Finally, numerical experiments are presented to validate the theoretical analysis. In the implementation process, we adopt the effective Oseen iteration to handle the nonlinear system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18376v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaojing Dong, Yunqing Huang, Tianwen Wang</dc:creator>
    </item>
    <item>
      <title>A virtual element method with IMEX-SAV scheme for the incompressible magnetohydrodynamics equations</title>
      <link>https://arxiv.org/abs/2410.18384</link>
      <description>arXiv:2410.18384v1 Announce Type: new 
Abstract: This paper proposes a virtual element method (VEM) combined with a second-order implicit-explicit scheme based on the scalar auxiliary variable (SAV) method for the incompressible magnetohydrodynamics (MHD) equations. We employ the BDF2 scheme for time discretization and a conservative VEM for spatial discretization, in which the mass conservation in the velocity field is kept by taking advantage of the virtual element method's adaptability and its divergence-free characteristics. In our scheme, the nonlinear terms are handled explicitly using the SAV method, and the magnetic field is decoupled from the velocity and pressure. This decoupling only requires solving a sequence of linear systems with constant coefficient at each time step. The stability estimate of the fully discrete scheme is developed, demonstrating the scheme is unconditionally stable. Moreover, rigorous error estimates for the velocity and magnetic field are provided. Finally, numerical experiments are presented to verify the valid of theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18384v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaojing Dong, Yunqing Huang, Tianwen Wang</dc:creator>
    </item>
    <item>
      <title>Multiscale Neural Networks for Approximating Green's Functions</title>
      <link>https://arxiv.org/abs/2410.18439</link>
      <description>arXiv:2410.18439v1 Announce Type: new 
Abstract: Neural networks (NNs) have been widely used to solve partial differential equations (PDEs) in the applications of physics, biology, and engineering. One effective approach for solving PDEs with a fixed differential operator is learning Green's functions. However, Green's functions are notoriously difficult to learn due to their poor regularity, which typically requires larger NNs and longer training times. In this paper, we address these challenges by leveraging multiscale NNs to learn Green's functions. Through theoretical analysis using multiscale Barron space methods and experimental validation, we show that the multiscale approach significantly reduces the necessary NN size and accelerates training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18439v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenrui Hao, Rui Peng Li, Yuanzhe Xi, Tianshi Xu, Yahong Yang</dc:creator>
    </item>
    <item>
      <title>Nonconforming virtual element method for general second-order elliptic problems on curved domain</title>
      <link>https://arxiv.org/abs/2410.18526</link>
      <description>arXiv:2410.18526v1 Announce Type: new 
Abstract: This paper introduces a nonconforming virtual element method for general second-order elliptic problems with variable coefficients on domains with curved boundaries and curved internal interfaces. We prove arbitrary order optimal convergence in the energy and $L^2$ norms, confirmed by numerical experiments on a set of polygonal meshes. The accuracy of the numerical approximation provided by the method is shown to be comparable with the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18526v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Liu, Alessandro Russo</dc:creator>
    </item>
    <item>
      <title>Tensor-generated matrices and tensor H-eigenvalues distribution</title>
      <link>https://arxiv.org/abs/2410.18592</link>
      <description>arXiv:2410.18592v1 Announce Type: new 
Abstract: In this work, we introduce the concept of tensor-generated matrices, which transform an $m$-order $n$-dimensional tensor into an $n$-dimensional square matrix by grouping corresponding elements. We demonstrate that if the tensor-generated matrix from tensor $\mathcal{A}$ is an $H$-matrix, then $\mathcal{A}$ must be an $H$-tensor. While classical eigenvalue distributions for matrices are well-established, they do not directly apply to tensor eigenvalues, such as Brauer's Ovals of Cassini sets, Ostrowski sets, and $S$-type inclusion sets. To overcome this challenge, we aim to convert high-order tensor $H$-eigenvalue localization into tensor-generated matrix eigenvalue localization. By establishing connections, we successfully obtain higher-order tensor $H$-eigenvalue distributions based on the subclass of $H$-matrices and matrix eigenvalue distributions. This approach enables us to extend existing matrix eigenvalue localization sets to higher-order tensor eigenvalues, resulting in modified versions of Brauer's Ovals of Cassini sets, Ostrowski sets, and $S$-type inclusion sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18592v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Xiong, Jianzhou Liu</dc:creator>
    </item>
    <item>
      <title>Variational problems with gradient constraints: $\textit{A priori}$ and $\textit{a posteriori}$ error identities</title>
      <link>https://arxiv.org/abs/2410.18780</link>
      <description>arXiv:2410.18780v1 Announce Type: new 
Abstract: In this paper, on the basis of a (Fenchel) duality theory on the continuous level, we derive an $\textit{a posteriori}$ error identity for arbitrary conforming approximations of a primal formulation and a dual formulation of variational problems involving gradient constraints. In addition, on the basis of a (Fenchel) duality theory on the discrete level, we derive an $\textit{a priori}$ error identity that applies to the approximation of the primal formulation using the Crouzeix-Raviart element and to the approximation of the dual formulation using the Raviart-Thomas element, and leads to error decay rates that are optimal with respect to the regularity of a dual solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18780v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil, S\"oren Bartels, Alex Kaltenbach, Rohit Khandelwal</dc:creator>
    </item>
    <item>
      <title>Quantum linear system algorithm with optimal queries to initial state preparation</title>
      <link>https://arxiv.org/abs/2410.18178</link>
      <description>arXiv:2410.18178v1 Announce Type: cross 
Abstract: Quantum algorithms for linear systems produce the solution state $A^{-1}|b\rangle$ by querying two oracles: $O_A$ that block encodes the coefficient matrix and $O_b$ that prepares the initial state. We present a quantum linear system algorithm making $\mathbf{\Theta}\left(1/\sqrt{p}\right)$ queries to $O_b$, which is optimal in the success probability, and $\mathbf{O}\left(\kappa\log\left(1/p\right)\left(\log\log\left(1/p\right)+\log\left({1}/{\epsilon}\right)\right)\right)$ queries to $O_A$, nearly optimal in all parameters including the condition number and accuracy. Notably, our complexity scaling of initial state preparation holds even when $p$ is not known $\textit{a priori}$. This contrasts with recent results achieving $\mathbf{O}\left(\kappa\log\left({1}/{\epsilon}\right)\right)$ complexity to both oracles, which, while optimal in $O_A$, is highly suboptimal in $O_b$ as $\kappa$ can be arbitrarily larger than $1/\sqrt{p}$. In various applications such as solving differential equations, preparing ground states of operators with real spectra, and estimating and transforming eigenvalues of non-normal matrices, we can further improve the dependence on $p$ using a block preconditioning scheme to nearly match or outperform best previous results based on other methods, which also furnishes an extremely simple quantum linear system algorithm with an optimal query complexity to $O_A$. Underlying our results is a new Variable Time Amplitude Amplification algorithm with Tunable thresholds (Tunable VTAA), which fully characterizes generic nested amplitude amplifications, improves the $\ell_1$-norm input cost scaling of Ambainis to an $\ell_{\frac{2}{3}}$-quasinorm scaling, and admits a deterministic amplification schedule for the quantum linear system problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18178v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guang Hao Low, Yuan Su</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Matching for Symplectic Neural Integrators</title>
      <link>https://arxiv.org/abs/2410.18262</link>
      <description>arXiv:2410.18262v1 Announce Type: cross 
Abstract: Hamilton's equations of motion form a fundamental framework in various branches of physics, including astronomy, quantum mechanics, particle physics, and climate science. Classical numerical solvers are typically employed to compute the time evolution of these systems. However, when the system spans multiple spatial and temporal scales numerical errors can accumulate, leading to reduced accuracy. To address the challenges of evolving such systems over long timescales, we propose SympFlow, a novel neural network-based symplectic integrator, which is the composition of a sequence of exact flow maps of parametrised time-dependent Hamiltonian functions. This architecture allows for a backward error analysis: we can identify an underlying Hamiltonian function of the architecture and use it to define a Hamiltonian matching objective function, which we use for training. In numerical experiments, we show that SympFlow exhibits promising results, with qualitative energy conservation behaviour similar to that of time-stepping symplectic integrators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18262v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Priscilla Canizares, Davide Murari, Carola-Bibiane Sch\"onlieb, Ferdia Sherry, Zakhar Shumaylov</dc:creator>
    </item>
    <item>
      <title>GeoLoRA: Geometric integration for parameter efficient fine-tuning</title>
      <link>https://arxiv.org/abs/2410.18720</link>
      <description>arXiv:2410.18720v1 Announce Type: cross 
Abstract: Low-Rank Adaptation (LoRA) has become a widely used method for parameter-efficient fine-tuning of large-scale, pre-trained neural networks. However, LoRA and its extensions face several challenges, including the need for rank adaptivity, robustness, and computational efficiency during the fine-tuning process. We introduce GeoLoRA, a novel approach that addresses these limitations by leveraging dynamical low-rank approximation theory. GeoLoRA requires only a single backpropagation pass over the small-rank adapters, significantly reducing computational cost as compared to similar dynamical low-rank training methods and making it faster than popular baselines such as AdaLoRA. This allows GeoLoRA to efficiently adapt the allocated parameter budget across the model, achieving smaller low-rank adapters compared to heuristic methods like AdaLoRA and LoRA, while maintaining critical convergence, descent, and error-bound theoretical guarantees. The resulting method is not only more efficient but also more robust to varying hyperparameter settings. We demonstrate the effectiveness of GeoLoRA on several state-of-the-art benchmarks, showing that it outperforms existing methods in both accuracy and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18720v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steffen Schotth\"ofer, Emanuele Zangrando, Gianluca Ceruti, Francesco Tudisco, Jonas Kusch</dc:creator>
    </item>
    <item>
      <title>Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality</title>
      <link>https://arxiv.org/abs/2410.18784</link>
      <description>arXiv:2410.18784v1 Announce Type: cross 
Abstract: The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this prior work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Our theory is established based on a key observation: the DDPM update rule is equivalent to running a suitably parameterized SDE upon discretization, where the nonlinear component of the drift term is intrinsically low-dimensional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18784v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Huang, Yuting Wei, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>DL-Polycube: Deep learning enhanced polycube method for high-quality hexahedral mesh generation and volumetric spline construction</title>
      <link>https://arxiv.org/abs/2410.18852</link>
      <description>arXiv:2410.18852v1 Announce Type: cross 
Abstract: In this paper, we present a novel algorithm that integrates deep learning with the polycube method (DL-Polycube) to generate high-quality hexahedral (hex) meshes, which are then used to construct volumetric splines for isogeometric analysis. Our DL-Polycube algorithm begins by establishing a connection between surface triangular meshes and polycube structures. We employ deep neural network to classify surface triangular meshes into their corresponding polycube structures. Following this, we combine the acquired polycube structural information with unsupervised learning to perform surface segmentation of triangular meshes. This step addresses the issue of segmentation not corresponding to a polycube while reducing manual intervention. Quality hex meshes are then generated from the polycube structures, with employing octree subdivision, parametric mapping and quality improvement techniques. The incorporation of deep learning for creating polycube structures, combined with unsupervised learning for segmentation of surface triangular meshes, substantially accelerates hex mesh generation. Finally, truncated hierarchical B-splines are constructed on the generated hex meshes. We extract trivariate B\'ezier elements from these splines and apply them directly in isogeometric analysis. We offer several examples to demonstrate the robustness of our DL-Polycube algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18852v1</guid>
      <category>cs.CG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Yu, Yuzhuo Fang, Hua Tong, Yongjie Jessica Zhang</dc:creator>
    </item>
    <item>
      <title>Using Parametric PINNs for Predicting Internal and External Turbulent Flows</title>
      <link>https://arxiv.org/abs/2410.18917</link>
      <description>arXiv:2410.18917v1 Announce Type: cross 
Abstract: Computational fluid dynamics (CFD) solvers employing two-equation eddy viscosity models are the industry standard for simulating turbulent flows using the Reynolds-averaged Navier-Stokes (RANS) formulation. While these methods are computationally less expensive than direct numerical simulations, they can still incur significant computational costs to achieve the desired accuracy. In this context, physics-informed neural networks (PINNs) offer a promising approach for developing parametric surrogate models that leverage both existing, but limited CFD solutions and the governing differential equations to predict simulation outcomes in a computationally efficient, differentiable, and near real-time manner. In this work, we build upon the previously proposed RANS-PINN framework, which only focused on predicting flow over a cylinder. To investigate the efficacy of RANS-PINN as a viable approach to building parametric surrogate models, we investigate its accuracy in predicting relevant turbulent flow variables for both internal and external flows. To ensure training convergence with a more complex loss function, we adopt a novel sampling approach that exploits the domain geometry to ensure a proper balance among the contributions from various regions within the solution domain. The effectiveness of this framework is then demonstrated for two scenarios that represent a broad class of internal and external flow problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18917v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shinjan Ghosh, Amit Chakraborty, Georgia Olympia Brikis, Biswadip Dey</dc:creator>
    </item>
    <item>
      <title>A high order unfitted finite element method for time-Harmonic Maxwell interface problems</title>
      <link>https://arxiv.org/abs/2301.08944</link>
      <description>arXiv:2301.08944v3 Announce Type: replace 
Abstract: We propose a high order unfitted finite element method for solving timeharmonic Maxwell interface problems. The unfitted finite element method is based on a mixed formulation in the discontinuous Galerkin framework on a Cartesian mesh with possible hanging nodes. The $H^2$ regularity of the solution to Maxwell interface problems with $C^2$ interfaces in each subdomain is proved. Practical interface-resolving mesh conditions are introduced under which the hp inverse estimates on three-dimensional curved domains are proved. Stability and hp a priori error estimate of the unfitted finite element method are proved. Numerical results are included to illustrate the performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08944v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiming Chen, Ke Li, Maohui Lyu, Xueshuang Xiang</dc:creator>
    </item>
    <item>
      <title>Variational convergence of the Scharfetter-Gummel scheme to the aggregation-diffusion equation and vanishing diffusion limit</title>
      <link>https://arxiv.org/abs/2306.02226</link>
      <description>arXiv:2306.02226v2 Announce Type: replace 
Abstract: In this paper, we explore the convergence of the semi-discrete Scharfetter-Gummel scheme for the aggregation-diffusion equation using a variational approach. Our investigation involves obtaining a novel gradient structure for the finite volume space discretization that works consistently for any non-negative diffusion constant. This allows us to study the discrete-to-continuum and zero-diffusion limits simultaneously. The zero-diffusion limit for the Scharfetter-Gummel scheme corresponds to the upwind finite volume scheme for the aggregation equation. In both cases, we establish a convergence result in terms of gradient structures, recovering the Otto gradient flow structure for the aggregation-diffusion equation based on the 2-Wasserstein distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02226v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasiia Hraivoronska, Andr\'e Schlichting, Oliver Tse</dc:creator>
    </item>
    <item>
      <title>Learning-based approaches for reconstructions with inexact operators in nanoCT applications</title>
      <link>https://arxiv.org/abs/2307.10474</link>
      <description>arXiv:2307.10474v3 Announce Type: replace 
Abstract: Imaging problems such as the one in nanoCT require the solution of an inverse problem, where it is often taken for granted that the forward operator, i.e., the underlying physical model, is properly known. In the present work we address the problem where the forward model is inexact due to stochastic or deterministic deviations during the measurement process. We particularly investigate the performance of non-learned iterative reconstruction methods dealing with inexactness and learned reconstruction schemes, which are based on U-Nets and conditional invertible neural networks. The latter also provide the opportunity for uncertainty quantification. A synthetic large data set in line with a typical nanoCT setting is provided and extensive numerical experiments are conducted evaluating the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10474v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom L\"utjen, Fabian Sch\"onfeld, Alice Oberacker, Johannes Leuschner, Maximilian Schmidt, Anne Wald, Tobias Kluth</dc:creator>
    </item>
    <item>
      <title>Riemannian Acceleration with Preconditioning for symmetric eigenvalue problems</title>
      <link>https://arxiv.org/abs/2309.05143</link>
      <description>arXiv:2309.05143v2 Announce Type: replace 
Abstract: The analysis of the acceleration behavior of gradient-based eigensolvers with preconditioning presents a substantial theoretical challenge. In this work, we present a novel framework for preconditioning on Riemannian manifolds and introduce a metric, the leading angle, to evaluate preconditioners for symmetric eigenvalue problems. We extend the locally optimal Riemannian accelerated gradient method for Riemannian convex optimization to develop the Riemannian Acceleration with Preconditioning (RAP) method for symmetric eigenvalue problems, thereby providing theoretical evidence to support its acceleration. Our analysis of the Schwarz preconditioner for elliptic eigenvalue problems demonstrates that RAP achieves a convergence rate of $1-C\kappa^{-1/2}$, which is an improvement over the preconditioned steepest descent method's rate of $1-C\kappa^{-1}$. The exponent in $\kappa^{-1/2}$ is sharp, and numerical experiments confirm our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05143v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nian Shao, Wenbin Chen</dc:creator>
    </item>
    <item>
      <title>An Optimal Ansatz Space for Moving Least Squares Approximation on Spheres</title>
      <link>https://arxiv.org/abs/2310.15570</link>
      <description>arXiv:2310.15570v2 Announce Type: replace 
Abstract: We revisit the moving least squares (MLS) approximation scheme on the sphere $\mathbb S^{d-1} \subset \mathbb R^d$, where $d&gt;1$. It is well known that using the spherical harmonics up to degree $L \in \mathbb N$ as ansatz space yields for functions in $\mathcal C^{L+1}(\mathbb S^{d-1})$ the approximation order $\mathcal O \left( h^{L+1} \right)$, where $h$ denotes the fill distance of the sampling nodes. In this paper we show that the dimension of the ansatz space can be almost halved, by including only spherical harmonics of even or odd degree up to $L$, while preserving the same order of approximation. Numerical experiments indicate that using the reduced ansatz space is essential to ensure the numerical stability of the MLS approximation scheme as $h \to 0$. Finally, we compare our approach with an MLS approximation scheme that uses polynomials on the tangent space as ansatz space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15570v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10444-024-10201-z</arxiv:DOI>
      <arxiv:journal_reference>Adv Comput Math 50, 107 (2024)</arxiv:journal_reference>
      <dc:creator>Ralf Hielscher, Tim P\"oschl</dc:creator>
    </item>
    <item>
      <title>Space--time Isogeometric Analysis of cardiac electrophysiology</title>
      <link>https://arxiv.org/abs/2311.17500</link>
      <description>arXiv:2311.17500v2 Announce Type: replace 
Abstract: This work proposes a stable and efficient space-time method for the monodomain equation coupled with the Rogers--McCulloch ionic model, which is widely used to simulate electrophysiological wave propagation in the cardiac tissue. By extending the Spline Upwind method and exploiting low-rank matrix approximations, as well as preconditioned solvers, we achieve both significant computational efficiency and accuracy. In particular, we develop a formulation that is both simple and highly effective, designed to minimize spurious oscillations and ensuring computational efficiency. We rigorously validate the method's performance through a series of numerical experiments, showing its robustness and reliability in diverse scenarios.hod and also reasonable from the computational cost point of view. For these reasons we validate the method's capability with numerical experiments, focusing on accuracy and computational aspects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17500v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. F. Antonietti, L. Ded\`e, G. Loli, M. Montardini, G. Sangalli, P. Tesini</dc:creator>
    </item>
    <item>
      <title>Performance of linear solvers in tensor-train format on current multicore architectures</title>
      <link>https://arxiv.org/abs/2312.08006</link>
      <description>arXiv:2312.08006v2 Announce Type: replace 
Abstract: Tensor networks are a class of algorithms aimed at reducing the computational complexity of high-dimensional problems. They are used in an increasing number of applications, from quantum simulations to machine learning. Exploiting data parallelism in these algorithms is key to using modern hardware. However, there are several ways to map required tensor operations onto linear algebra routines ("building blocks"). Optimizing this mapping impacts the numerical behavior, so computational and numerical aspects must be considered hand-in-hand. In this paper we discuss the performance of solvers for low-rank linear systems in the tensor-train format (also known as matrix-product states). We consider three popular algorithms: TT-GMRES, MALS, and AMEn. We illustrate their computational complexity based on the example of discretizing a simple high-dimensional PDE in, e.g., $50^{10}$ grid points. This shows that the projection to smaller sub-problems for MALS and AMEn reduces the number of floating-point operations by orders of magnitude. We suggest optimizations regarding orthogonalization steps, singular value decompositions, and tensor contractions. In addition, we propose a generic preconditioner based on a TT-rank-1 approximation of the linear operator. Overall, we obtain roughly a 5x speedup over the reference algorithm for the fastest method (AMEn) on a current multicore CPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08006v2</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Melven R\"ohrig-Z\"ollner, Manuel Joey Becklas, Jonas Thies, Achim Basermann</dc:creator>
    </item>
    <item>
      <title>Randomized Preconditioned Solvers for Strong Constraint 4D-Var Data Assimilation</title>
      <link>https://arxiv.org/abs/2401.15758</link>
      <description>arXiv:2401.15758v2 Announce Type: replace 
Abstract: Strong Constraint 4D Variational (SC-4DVAR) is a data assimilation method that is widely used in climate and weather applications. SC-4DVAR involves solving a minimization problem to compute the maximum a posteriori estimate, which we tackle using the Gauss-Newton method. The computation of the descent direction is expensive since it involves the solution of a large-scale and potentially ill-conditioned linear system, solved using the preconditioned conjugate gradient (PCG) method. To address this cost, we efficiently construct scalable preconditioners using three different randomization techniques, which all rely on a certain low-rank structure involving the Gauss-Newton Hessian. The proposed techniques come with theoretical (probabilistic) guarantees on the condition number, and at the same time, are amenable to parallelization. We also develop an adaptive approach to estimate the sketch size and to choose between the reuse or recomputation of the preconditioner. We demonstrate the performance and effectiveness of our methodology on two representative model problems -- the Burgers and barotropic vorticity equation -- showing a drastic reduction in both the number of PCG iterations and the number of Gauss-Newton Hessian products (after including the preconditioner construction cost).</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15758v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit N. Subrahmanya, Vishwas Rao, Arvind K. Saibaba</dc:creator>
    </item>
    <item>
      <title>A Local Projection Stabilised HHO Method for the Oseen Problem</title>
      <link>https://arxiv.org/abs/2402.02727</link>
      <description>arXiv:2402.02727v2 Announce Type: replace 
Abstract: In this article, we consider a local projection stabilisation for a Hybrid High-Order (HHO) approximation of the Oseen problem. We prove an existence-uniqueness result under a stronger SUPG-like norm. We improve the stability and provide error estimation in stronger norm for convection dominated Oseen problem. We also derive an optimal order error estimate under the SUPG-like norm for equal-order polynomial discretisation of velocity and pressure spaces. Numerical experiments are performed to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02727v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gouranga Mallik, Rahul Biswas, Thirupathi Gudi</dc:creator>
    </item>
    <item>
      <title>A $p$-version of convolution quadrature in wave propagation</title>
      <link>https://arxiv.org/abs/2402.17712</link>
      <description>arXiv:2402.17712v2 Announce Type: replace 
Abstract: We consider a novel way of discretizing wave scattering problems using the general formalism of convolution quadrature, but instead of reducing the timestep size ($h$-method), we achieve accuracy by increasing the order of the method ($p$-method). We base this method on discontinuous Galerkin timestepping and use the Z-transform. We show that for a certain class of incident waves, the resulting schemes observes(root)-exponential convergence rate with respect to the number of boundary integral operators that need to be applied. Numerical experiments confirm the findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17712v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Rieder</dc:creator>
    </item>
    <item>
      <title>Stability of conforming space-time isogeometric methods for the wave equation</title>
      <link>https://arxiv.org/abs/2403.15043</link>
      <description>arXiv:2403.15043v2 Announce Type: replace 
Abstract: We consider a family of conforming space-time finite element discretizations for the wave equation based on splines of maximal regularity in time. Traditional techniques may require a CFL condition to guarantee stability. Recent works by O. Steinbach and M. Zank (2018), and S. Fraschini, G. Loli, A. Moiola, and G. Sangalli (2023), have introduced unconditionally stable schemes by adding non-consistent penalty terms to the underlying bilinear form. Stability and error analysis have been carried out for lowest order discrete spaces. While higher order methods have shown promising properties through numerical testing, their rigorous analysis was still missing. In this paper, we address this stability analysis by studying the properties of the condition number of a family of matrices associated with the time discretization. For each spline order, we derive explicit estimates of both the CFL condition required in the unstabilized case and the penalty term that minimises the consistency error in the stabilized case. Numerical tests confirm the sharpness of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15043v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Matteo Ferrari, Sara Fraschini</dc:creator>
    </item>
    <item>
      <title>Bound preserving Point-Average-Moment PolynomiAl-interpreted (PAMPA) scheme: one-dimensional case</title>
      <link>https://arxiv.org/abs/2410.14292</link>
      <description>arXiv:2410.14292v2 Announce Type: replace 
Abstract: We propose a bound preserving Point-Average-Moment PolynomiAl-interpreted (PAMPA) method by blending the third-order construction and first-order construction. The originality of the present construction is that it does not need any explicit reconstruction within each element, and therefore the construction is very flexible. The construction uses a classical blending approach between a first order bound preserving scheme and a high order scheme that is not bound preserving.
  We show its efficiency on many problems, ranging from scalar to system cases (Euler equations). In both cases, we provide optimal values of the blending parameter. In the system case, we use the recent geometric quasi-linearisation of [Wu and Shu, SIAM Review, 65 (2023), pp. 1031--1073].</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14292v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R\'emi Abgrall, Miaosen Jiao, Yongle Liu, Kailiang Wu</dc:creator>
    </item>
    <item>
      <title>Neural incomplete factorization: learning preconditioners for the conjugate gradient method</title>
      <link>https://arxiv.org/abs/2305.16368</link>
      <description>arXiv:2305.16368v3 Announce Type: replace-cross 
Abstract: The convergence of the conjugate gradient method for solving large-scale and sparse linear equation systems depends on the spectral properties of the system matrix, which can be improved by preconditioning. In this paper, we develop a computationally efficient data-driven approach to accelerate the generation of effective preconditioners. We, therefore, replace the typically hand-engineered preconditioners by the output of graph neural networks. Our method generates an incomplete factorization of the matrix and is, therefore, referred to as neural incomplete factorization (NeuralIF). Optimizing the condition number of the linear system directly is computationally infeasible. Instead, we utilize a stochastic approximation of the Frobenius loss which only requires matrix-vector multiplications for efficient training. At the core of our method is a novel message-passing block, inspired by sparse matrix theory, that aligns with the objective of finding a sparse factorization of the matrix. We evaluate our proposed method on both synthetic problem instances and on problems arising from the discretization of the Poisson equation on varying domains. Our experiments show that by using data-driven preconditioners within the conjugate gradient method we are able to speed up the convergence of the iterative procedure. The code is available at https://github.com/paulhausner/neural-incomplete-factorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16368v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul H\"ausner, Ozan \"Oktem, Jens Sj\"olund</dc:creator>
    </item>
    <item>
      <title>Discontinuous Galerkin scheme for elliptic equations on extremely stretched grids</title>
      <link>https://arxiv.org/abs/2405.06120</link>
      <description>arXiv:2405.06120v2 Announce Type: replace-cross 
Abstract: Discontinuous Galerkin (DG) methods for solving elliptic equations are gaining popularity in the computational physics community for their high-order spectral convergence and their potential for parallelization on computing clusters. However, problems in numerical relativity with extremely stretched grids, such as initial data problems for binary black holes that impose boundary conditions at large distances from the black holes, have proven challenging for DG methods. To alleviate this problem we have developed a primal DG scheme that is generically applicable to a large class of elliptic equations, including problems on curved and extremely stretched grids. The DG scheme accommodates two widely used initial data formulations in numerical relativity, namely the puncture formulation and the extended conformal thin-sandwich (XCTS) formulation. We find that our DG scheme is able to stretch the grid by a factor of $\sim 10^9$ and hence allows to impose boundary conditions at large distances. The scheme converges exponentially with resolution both for the smooth XCTS problem and for the nonsmooth puncture problem. With this method we are able to generate high-quality initial data for binary black hole problems using a parallelizable DG scheme. The code is publicly available in the open-source SpECTRE numerical relativity code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06120v2</guid>
      <category>gr-qc</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.110.084062</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 110, 084062 (2024)</arxiv:journal_reference>
      <dc:creator>Nils L. Vu</dc:creator>
    </item>
    <item>
      <title>Near-optimal hierarchical matrix approximation from matrix-vector products</title>
      <link>https://arxiv.org/abs/2407.04686</link>
      <description>arXiv:2407.04686v2 Announce Type: replace-cross 
Abstract: We describe a randomized algorithm for producing a near-optimal hierarchical off-diagonal low-rank (HODLR) approximation to an $n\times n$ matrix $\mathbf{A}$, accessible only though matrix-vector products with $\mathbf{A}$ and $\mathbf{A}^{\mathsf{T}}$. We prove that, for the rank-$k$ HODLR approximation problem, our method achieves a $(1+\beta)^{\log(n)}$-optimal approximation in expected Frobenius norm using $O(k\log(n)/\beta^3)$ matrix-vector products. In particular, the algorithm obtains a $(1+\varepsilon)$-optimal approximation with $O(k\log^4(n)/\varepsilon^3)$ matrix-vector products, and for any constant $c$, an $n^c$-optimal approximation with $O(k \log(n))$ matrix-vector products. Apart from matrix-vector products, the additional computational cost of our method is just $O(n \operatorname{poly}(\log(n), k, \beta))$. We complement the upper bound with a lower bound, which shows that any matrix-vector query algorithm requires at least $\Omega(k\log(n) + k/\varepsilon)$ queries to obtain a $(1+\varepsilon)$-optimal approximation.
  Our algorithm can be viewed as a robust version of widely used "peeling" methods for recovering HODLR matrices and is, to the best of our knowledge, the first matrix-vector query algorithm to enjoy theoretical worst-case guarantees for approximation by any hierarchical matrix class. To control the propagation of error between levels of hierarchical approximation, we introduce a new perturbation bound for low-rank approximation, which shows that the widely used Generalized Nystr\"om method enjoys inherent stability when implemented with noisy matrix-vector products. We also introduce a novel randomly perforated matrix sketching method to further control the error in the peeling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04686v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>SIAM Symposium on Discrete Algorithms (SODA 2025)</arxiv:journal_reference>
      <dc:creator>Tyler Chen, Feyza Duman Keles, Diana Halikias, Cameron Musco, Christopher Musco, David Persson</dc:creator>
    </item>
  </channel>
</rss>
