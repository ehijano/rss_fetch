<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 04:01:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Why Instant-Runoff Voting Is So Resilient to Coalitional Manipulation: Phase Transitions in the Perturbed Culture</title>
      <link>https://arxiv.org/abs/2510.14450</link>
      <description>arXiv:2510.14450v1 Announce Type: new 
Abstract: Previous studies have shown that Instant-Runoff Voting (IRV) is highly resistant to coalitional manipulation (CM), though the theoretical reasons for this remain unclear. To address this gap, we analyze the susceptibility to CM of three major voting rules-Plurality, Two-Round System, and IRV-within the Perturbed Culture model. Our findings reveal that each rule undergoes a phase transition at a critical value theta\_c of the concentration of preferences: the probability of CM for large electorates converges exponentially fast to 1 below theta\_c and to 0 above theta\_c. We introduce the Super Condorcet Winner (SCW), showing that its presence is a key factor of IRV's resistance to coalitional manipulation, both theoretically and empirically. Notably, we use this notion to prove that for IRV, theta\_c = 0, making it resistant to CM with even minimal preference concentration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14450v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2025), International Foundation for Autonomous Agents and Multiagent Systems, May 2025, Detroit (Michigan), United States. pp.658-666</arxiv:journal_reference>
      <dc:creator>Fran\c{c}ois Durand</dc:creator>
    </item>
    <item>
      <title>Co-Investment under Revenue Uncertainty Based on Stochastic Coalitional Game Theory</title>
      <link>https://arxiv.org/abs/2510.14555</link>
      <description>arXiv:2510.14555v1 Announce Type: new 
Abstract: The introduction of new services, such as Mobile Edge Computing (MEC), requires a massive investment that cannot be assumed by a single stakeholder, for instance the Infrastructure Provider (InP). Service Providers (SPs) however also have an interest in the deployment of such services. We hence propose a co-investment scheme in which all stakeholders, i.e., the InP and the SPs, form the so-called grand coalition composed of all the stakeholders with the aim of sharing costs and revenues and maximizing their payoffs. The challenge comes from the fact that future revenues are uncertain. We devise in this case a novel stochastic coalitional game formulation which builds upon robust game theory and derive a lower bound on the probability of the stability of the grand coalition, wherein no player can be better off outside of it. In the presence of some correlated fluctuations of revenues however, stability can be too conservative. In this case, we make use also of profitability, in which payoffs of players are non-negative, as a necessary condition for co-investment. The proposed framework is showcased for MEC deployment, where computational resources need to be deployed in nodes at the edge of a telecommunication network. Numerical results show high lower bound on the probability of stability when the SPs' revenues are of similar magnitude and the investment period is sufficiently long, even with high levels of uncertainty. In the case where revenues are highly variable however, the lower bound on stability can be trivially low whereas co-investment is still profitable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14555v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amal Sakr, Andrea Araldo, Tijani Chahed, Daniel Kofman</dc:creator>
    </item>
    <item>
      <title>The Bidding Games: Reinforcement Learning for MEV Extraction on Polygon Blockchain</title>
      <link>https://arxiv.org/abs/2510.14642</link>
      <description>arXiv:2510.14642v1 Announce Type: new 
Abstract: In blockchain networks, the strategic ordering of transactions within blocks has emerged as a significant source of profit extraction, known as Maximal Extractable Value (MEV). The transition from spam-based Priority Gas Auctions to structured auction mechanisms like Polygon Atlas has transformed MEV extraction from public bidding wars into sealed-bid competitions under extreme time constraints. While this shift reduces network congestion, it introduces complex strategic challenges where searchers must make optimal bidding decisions within a sub-second window without knowledge of competitor behavior or presence. Traditional game-theoretic approaches struggle in this high-frequency, partially observable environment due to their reliance on complete information and static equilibrium assumptions. We present a reinforcement learning framework for MEV extraction on Polygon Atlas and make three contributions: (1) A novel simulation environment that accurately models the stochastic arrival of arbitrage opportunities and probabilistic competition in Atlas auctions; (2) A PPO-based bidding agent optimized for real-time constraints, capable of adaptive strategy formulation in continuous action spaces while maintaining production-ready inference speeds; (3) Empirical validation demonstrating our history-conditioned agent captures 49\% of available profits when deployed alongside existing searchers and 81\% when replacing the market leader, significantly outperforming static bidding strategies. Our work establishes that reinforcement learning provides a critical advantage in high-frequency MEV environments where traditional optimization methods fail, offering immediate value for industrial participants and protocol designers alike.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14642v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Seoev, Leonid Gremyachikh, Anastasiia Smirnova, Yash Madhwal, Alisa Kalacheva, Dmitry Belousov, Ilia Zubov, Aleksei Smirnov, Denis Fedyanin, Vladimir Gorgadze, Yury Yanovich</dc:creator>
    </item>
    <item>
      <title>Online Proportional Apportionment</title>
      <link>https://arxiv.org/abs/2510.14752</link>
      <description>arXiv:2510.14752v1 Announce Type: new 
Abstract: Traditionally, the problem of apportioning the seats of a legislative body has been viewed as a one-shot process with no dynamic considerations. While this approach is reasonable for some settings, dynamic aspects play an important role in many others. We initiate the study of apportionment problems in an online setting. Specifically, we introduce a framework for proportional apportionment with no information about the future. In this model, time is discrete and there are $n$ parties that receive a certain share of the votes at each time step. An online algorithm needs to irrevocably assign a prescribed number of seats at each time, ensuring that each party receives its fractional share rounded up or down, and that the cumulative number of seats allocated to each party remains close to its cumulative share up to that time.
  We study deterministic and randomized online apportionment methods. For deterministic methods, we construct a family of adversarial instances that yield a lower bound, linear in $n$, on the worst-case deviation between the seats allocated to a party and its cumulative share. We show that this bound is best possible and is matched by a natural greedy method. As a consequence, a method guaranteeing that the cumulative number of seats assigned to each party up to any step equals its cumulative share rounded up or down (global quota) exists if and only if $n\leq 3$. Then, we turn to randomized allocations and show that, for $n\leq 3$, we can randomize over methods satisfying global quota with the additional guarantee that each party receives, in expectation, its proportional share in every step. Our proof is constructive: Any method satisfying these properties can be obtained from a flow on a recursively constructed network. We showcase the applicability of our results to obtain approximate solutions in the context of online dependent rounding procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14752v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Jose Correa, Svenja M. Griesbach, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Learnable Mixed Nash Equilibria are Collectively Rational</title>
      <link>https://arxiv.org/abs/2510.14907</link>
      <description>arXiv:2510.14907v1 Announce Type: new 
Abstract: We extend the study of learning in games to dynamics that exhibit non-asymptotic stability. We do so through the notion of uniform stability, which is concerned with equilibria of individually utility-seeking dynamics. Perhaps surprisingly, it turns out to be closely connected to economic properties of collective rationality. Under mild non-degeneracy conditions and up to strategic equivalence, if a mixed equilibrium is not uniformly stable, then it is not weakly Pareto optimal: there is a way for all players to improve by jointly deviating from the equilibrium. On the other hand, if it is locally uniformly stable, then the equilibrium must be weakly Pareto optimal. Moreover, we show that uniform stability determines the last-iterate convergence behavior for the family of incremental smoothed best-response dynamics, used to model individual and corporate behaviors in the markets. Unlike dynamics around strict equilibria, which can stabilize to socially-inefficient solutions, individually utility-seeking behaviors near mixed Nash equilibria lead to collective rationality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14907v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geelon So, Yi-An Ma</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Regret-Queue Length Tradeoff in Online Learning for Two-Sided Markets</title>
      <link>https://arxiv.org/abs/2510.14097</link>
      <description>arXiv:2510.14097v1 Announce Type: cross 
Abstract: We study a two-sided market, wherein, price-sensitive heterogeneous customers and servers arrive and join their respective queues. A compatible customer-server pair can then be matched by the platform, at which point, they leave the system. Our objective is to design pricing and matching algorithms that maximize the platform's profit, while maintaining reasonable queue lengths. As the demand and supply curves governing the price-dependent arrival rates may not be known in practice, we design a novel online-learning-based pricing policy and establish its near-optimality. In particular, we prove a tradeoff among three performance metrics: $\tilde{O}(T^{1-\gamma})$ regret, $\tilde{O}(T^{\gamma/2})$ average queue length, and $\tilde{O}(T^{\gamma})$ maximum queue length for $\gamma \in (0, 1/6]$, significantly improving over existing results [1]. Moreover, barring the permissible range of $\gamma$, we show that this trade-off between regret and average queue length is optimal up to logarithmic factors under a class of policies, matching the optimal one as in [2] which assumes the demand and supply curves to be known. Our proposed policy has two noteworthy features: a dynamic component that optimizes the tradeoff between low regret and small queue lengths; and a probabilistic component that resolves the tension between obtaining useful samples for fast learning and maintaining small queue lengths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14097v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixian Yang, Sushil Mahavir Varma, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Generating Fair Consensus Statements with Social Choice on Token-Level MDPs</title>
      <link>https://arxiv.org/abs/2510.14106</link>
      <description>arXiv:2510.14106v1 Announce Type: cross 
Abstract: Current frameworks for consensus statement generation with large language models lack the inherent structure needed to provide provable fairness guarantees when aggregating diverse free-form opinions. We model the task as a multi-objective, token-level Markov Decision Process (MDP), where each objective corresponds to an agent's preference. Token-level rewards for each agent are derived from their policy (e.g., a personalized language model). This approach utilizes the finding that such policies implicitly define optimal Q-functions, providing a principled way to quantify rewards at each generation step without a value function (Rafailov et al., 2024). This MDP formulation creates a formal structure amenable to analysis using principles from social choice theory. We propose two approaches grounded in social choice theory. First, we propose a stochastic generation policy guaranteed to be in the ex-ante core, extending core stability concepts from voting theory to text generation. This policy is derived from an underlying distribution over complete statements that maximizes proportional fairness (Nash Welfare). Second, for generating a single statement, we target the maximization of egalitarian welfare using search algorithms within the MDP framework. Empirically, experiments using language models to instantiate agent policies show that search guided by the egalitarian objective generates consensus statements with improved worst-case agent alignment compared to baseline methods, including the Habermas Machine (Tessler et al., 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14106v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carter Blair, Kate Larson</dc:creator>
    </item>
    <item>
      <title>Strategic Behavior in Crowdfunding: Insights from a Large-Scale Online Experiment</title>
      <link>https://arxiv.org/abs/2510.14872</link>
      <description>arXiv:2510.14872v1 Announce Type: cross 
Abstract: This study examines strategic behavior in crowdfunding using a large-scale online experiment. Building on the model of Arieli et. al 2023, we test predictions about risk aversion (i.e., opting out despite seeing a positive private signal) and mutual insurance (i.e., opting in despite seeing a negative private signal) in a static, single-shot crowdfunding game, focusing on informational incentives rather than dynamic effects. Our results validate key theoretical predictions: crowdfunding mechanisms induce distinct strategic behaviors compared to voting, where participants are more likely to follow private signals (odds ratio: 0.139, $p &lt; 0.001$). Additionally, the study demonstrates that higher signal accuracy (85\% vs. 55\%) decreases risk aversion (odds ratio: 0.414, $p = 0.024$) but increases reliance on mutual insurance (odds ratio: 2.532, $p = 0.026$). However, contrary to theory, increasing the required participation threshold (50\% to 80\%) amplifies risk aversion (odds ratio: 3.251, $p = 0.005$), which, pending further investigation, may indicate cognitive constraints.
  Furthermore, we show that while mutual insurance supports participation, it may hinder information aggregation, particularly as signal accuracy increases. These findings advance crowdfunding theory by confirming the impact of informational incentives and identifying behavioral deviations that challenge standard models, offering insights for platform design and mechanism refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14872v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Din Amir, Bar Hoter, Moran Koren</dc:creator>
    </item>
    <item>
      <title>Auction-based Adaptive Resource Allocation Optimization in Dense and Heterogeneous IoT Networks</title>
      <link>https://arxiv.org/abs/2409.17843</link>
      <description>arXiv:2409.17843v2 Announce Type: replace 
Abstract: Efficient and reliable resource allocation within densely-deployed massive IoT networks remains a key challenge due to resource constraints among low-size, weight, and power (SWaP) IoT devices and within the network and limitations of conventional centralized methods under incomplete information. We propose a novel auction-based framework for adaptive resource allocation, combining space-time-frequency spreading (STFS) techniques with Bayesian Game approaches. We introduce novel modified Simultaneous Ascending Auction (mSAA) mechanism tailored to densely-deployed and low-complexity IoT networks, enabling distributed computation and reduced power consumption. By incorporating Bayesian game-based bidding strategies and optimizing dispersion matrices for signal transmission, the proposed approach ensures enhanced channel throughput and energy efficiency. Comparative analysis against traditional auction types, including First-Price and Second-Price Sealed-Bid Auctions, as well as the Vickery-Clarke-Groves (VCG) mechanism, demonstrates the superiority of mSAA in terms of surplus maximization, revenue efficiency, and robustness in risk-prone bidding environments. Simulation results validate the model's adaptability to heterogeneous IoT nodes and its potential for dense deployment across different environments and verticals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17843v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nirmal D. Wickramasinghe, John Dooley, Dirk Pesch, Indrakshi Dey</dc:creator>
    </item>
    <item>
      <title>Polynomial-Time Algorithms for Fair Orientations of Chores</title>
      <link>https://arxiv.org/abs/2501.13481</link>
      <description>arXiv:2501.13481v3 Announce Type: replace 
Abstract: This paper addresses the problem of finding fair orientations of graphs of chores, in which each vertex corresponds to an agent, each edge corresponds to a chore, and a chore has zero marginal utility to an agent if its corresponding edge is not incident to the vertex corresponding to the agent. Recently, Zhou et al. (IJCAI, 2024) analyzed the complexity of deciding whether graphs containing a mixture of goods and chores have EFX orientations, and conjectured that deciding whether graphs containing only chores have EFX orientations is NP-complete. We resolve this conjecture by giving polynomial-time algorithms that find EF1 and EFX orientations of graphs containing only chores if they exist, even if there are self-loops. Remarkably, our result demonstrates a surprising separation between the case of goods and the case of chores, because deciding whether graphs containing only goods have EFX orientations was shown to be NP-complete by Christodoulou et al. (EC, 2023). In addition, we show the EF1 and EFX orientation problems for multigraphs to be NP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13481v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Hsu, Valerie King</dc:creator>
    </item>
    <item>
      <title>Inferring Foresightedness in Dynamic Noncooperative Games</title>
      <link>https://arxiv.org/abs/2412.01017</link>
      <description>arXiv:2412.01017v3 Announce Type: replace-cross 
Abstract: Dynamic game theory is an increasingly popular tool for modeling multi-agent, e.g. human-robot, interactions. Game-theoretic models presume that each agent wishes to minimize a private cost function that depends on others' actions. These games typically evolve over a fixed time horizon, specifying how far into the future each agent plans. In practical settings, however, decision-makers may vary in foresightedness, or how much they care about their current cost in relation to their past and future costs. We conjecture that quantifying and estimating each agent's foresightedness from online data will enable safer and more efficient interactions with other agents. To this end, we frame this inference problem as an inverse dynamic game. We consider a specific objective function parametrization that smoothly interpolates myopic and farsighted planning. Games of this form are readily transformed into parametric mixed complementarity problems; we exploit the directional differentiability of solutions to these problems with respect to their hidden parameters to solve for agents' foresightedness. We conduct three experiments: one with synthetically generated delivery robot motion, one with real-world data involving people walking, biking, and driving vehicles, and one using high-fidelity simulators. The results of these experiments demonstrate that explicitly inferring agents' foresightedness enables game-theoretic models to make 33% more accurate models for agents' behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01017v3</guid>
      <category>cs.RO</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cade Armstrong, Ryan Park, Xinjie Liu, Kushagra Gupta, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>No-Regret Learning in Stackelberg Games with an Application to Electric Ride-Hailing</title>
      <link>https://arxiv.org/abs/2504.03745</link>
      <description>arXiv:2504.03745v2 Announce Type: replace-cross 
Abstract: We consider the problem of efficiently learning to play single-leader multi-follower Stackelberg games when the leader lacks knowledge of the lower-level game. Such games arise in hierarchical decision-making problems involving self-interested agents. For example, in electric ride-hailing markets, a central authority aims to learn optimal charging prices to shape fleet distributions and charging patterns of ride-hailing companies. Existing works typically apply gradient-based methods to find the leader's optimal strategy. Such methods are impractical as they require that the followers share private utility information with the leader. Instead, we treat the lower-level game as a black box, assuming only that the followers' interactions approximate a Nash equilibrium while the leader observes the realized cost of the resulting approximation. Under kernel-based regularity assumptions on the leader's cost function, we develop a no-regret algorithm that converges to an $\epsilon$-Stackelberg equilibrium in $O(\sqrt{T})$ rounds. Finally, we validate our approach through a numerical case study on optimal pricing in electric ride-hailing markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03745v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MCS.2024.3467648</arxiv:DOI>
      <arxiv:journal_reference>64th IEEE Conference on Decision and Control: CDC 2025</arxiv:journal_reference>
      <dc:creator>Anna Maddux, Marko Maljkovic, Nikolas Geroliminis, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Make an Offer They Can't Refuse: Grounding Bayesian Persuasion in Real-World Dialogues without Pre-Commitment</title>
      <link>https://arxiv.org/abs/2510.13387</link>
      <description>arXiv:2510.13387v2 Announce Type: replace-cross 
Abstract: Persuasion, a fundamental social capability for humans, remains a challenge for AI systems such as large language models (LLMs). Current studies often overlook the strategic use of information asymmetry in message design or rely on strong assumptions regarding pre-commitment. In this work, we explore the application of Bayesian Persuasion (BP) in natural language within single-turn dialogue settings, to enhance the strategic persuasion capabilities of LLMs. Our framework incorporates a commitment-communication mechanism, where the persuader explicitly outlines an information schema by narrating their potential types (e.g., honest or dishonest), thereby guiding the persuadee in performing the intended Bayesian belief update. We evaluate two variants of our approach: Semi-Formal-Natural-Language (SFNL) BP and Fully-Natural-Language (FNL) BP, benchmarking them against both naive and strong non-BP (NBP) baselines within a comprehensive evaluation framework. This framework covers a diverse set of persuadees -- including LLM instances with varying prompts and fine-tuning and human participants -- across tasks ranging from specially designed persuasion scenarios to general everyday situations. Experimental results on LLM-based agents reveal three main findings: (1) LLMs guided by BP strategies consistently achieve higher persuasion success rates than NBP baselines; (2) SFNL exhibits greater credibility and logical coherence, while FNL shows stronger emotional resonance and robustness in naturalistic conversations; (3) with supervised fine-tuning, smaller models can attain BP performance comparable to that of larger models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13387v2</guid>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Buwei He, Yang Liu, Zhaowei Zhang, Zixia Jia, Huijia Wu, Zhaofeng He, Zilong Zheng, Yipeng Kang</dc:creator>
    </item>
  </channel>
</rss>
