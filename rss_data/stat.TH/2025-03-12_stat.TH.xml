<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Mar 2025 01:59:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Hidden Toll of COVID-19 on Opioid Mortality in Georgia: A Bayesian Excess Opioid Mortality Analysis</title>
      <link>https://arxiv.org/abs/2503.07918</link>
      <description>arXiv:2503.07918v1 Announce Type: new 
Abstract: COVID-19 has had a large scale negative impact on the health of opioid users exacerbating the health of an already vulnerable population. Critical information on the total impact of COVID-19 on opioid users is unknown due to a lack of comprehensive data on COVID-19 cases, inaccurate diagnostic coding, and lack of data coverage. To assess the impact of COVID-19 on small-area opioid mortality, we developed a Bayesian hierarchical excess opioid mortality modeling approach. We incorporate spatio-temporal autocorrelation structures to allow for sharing of information across small areas and time to reduce uncertainty in small area estimates. Excess mortality is defined as the difference between observed trends after a crisis and expected trends based on observed historical trends, which captures the total increase in observed mortality rates compared to what was expected prior to the crisis. We illustrate the application of our approach to assess excess opioid mortality risk estimates for 159 counties in GA. Using our proposed approach will help inform interventions in opioid-related public health responses, policies, and resource allocation. The application of this work also provides a general framework for improving the estimation and mapping of health indicators during crisis periods for the opioid user population.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07918v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyen Peterkin (Department of Biostatistics and Bioinformatics, Emory Rollins School of Public Health), Lance A. Waller (Department of Biostatistics and Bioinformatics, Emory Rollins School of Public Health), Emily N. Peterson (Department of Biostatistics and Bioinformatics, Emory Rollins School of Public Health)</dc:creator>
    </item>
    <item>
      <title>Pointwise Minimax Vector Field Reconstruction from Noisy ODE</title>
      <link>https://arxiv.org/abs/2503.08355</link>
      <description>arXiv:2503.08355v1 Announce Type: new 
Abstract: This work addresses the problem of estimating a vector field from a noisy Ordinary Differential Equation (ODE) in a non-parametric regression setting with a random design for initial values. More specifically, given a vector field $ f:\mathbb{R}^{D}\rightarrow \mathbb{R}^{D}$ governing a dynamical system defined by the autonomous ODE: $y' = f(y)$, we assume that the observations are $\tilde{y}_{X_{i}}(t_{j}) = y_{X_{i}}(t_{j}) + \varepsilon_{i,j}$ where $y_{X_{i}}(t_{j})$ is the solution of the ODE at time $t_{j}$ with initial condition $y(0) = X_{i}$, $X_{i}$ is sampled from a probability distribution $\mu$, and $\varepsilon_{i,j}$ some noise. In this context, we investigate, from a minimax perspective, the pointwise reconstruction of $f$ within the envelope of trajectories originating from the support of $\mu$. We propose an estimation strategy based on preliminary flow reconstruction and techniques from derivative estimation in non-parametric regression. Under mild assumptions on $f$, we establish convergence rates that depend on the temporal resolution, the number of sampled initial values and the mass concentration of $\mu$. Importantly, we show that these rates are minimax optimal. Furthermore, we discuss the implications of our results in a manifold learning setting, providing insights into how our approach can mitigate the curse of dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08355v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Henneuse</dc:creator>
    </item>
    <item>
      <title>TransPCA for Large-dimensional Factor Analysis with Weak Factors: Power Enhancement via Knowledge Transfer</title>
      <link>https://arxiv.org/abs/2503.08397</link>
      <description>arXiv:2503.08397v1 Announce Type: new 
Abstract: Early work established convergence of the principal component estimators of the factors and loadings up to a rotation for large dimensional approximate factor models with weak factors in that the factor loading $\Lambda^{(0)}$ scales sublinearly in the number $N$ of cross-section units, i.e., $\Lambda^{(0)\top}\Lambda^{(0)}/N^{\alpha}$ is positive definite in the limit for some $\alpha\in (0,1)$. However, the established convergence rates for weak factors can be much slower especially for small $\alpha$. This article proposes a Transfer Principal Component Analysis (TransPCA) method for enhancing the convergence rates for weak factors by transferring knowledge from large number of available informative panel datasets, which should not be turned a blind eye on in this big data era. We aggregate useful information by analyzing a weighted average projection matrix of the estimated loading spaces from all informative datasets which is highly flexible and computationally efficient. Theoretically, we derive the convergence rates of the estimators of weak/strong loading spaces and factor scores. The results indicate that as long as the auxiliary datasets are similar enough to the target dataset and the auxiliary sample size is sufficiently large, TransPCA estimators can achieve faster convergence rates in contrast to performing PCA solely on the target dataset. To avoid negative transfer, we also investigate the case that the informative datasets are unknown and provide a criterion for selecting useful datasets. Thorough simulation studies and {empirical analysis on real datasets in areas of macroeconomic and finance} are conducted to illustrate the usefulness of our proposed methods where large number of source panel datasets are naturally available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08397v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong He, Dong Liu, Yunjing Sun, Yalin Wang</dc:creator>
    </item>
    <item>
      <title>Personalized Convolutional Dictionary Learning of Physiological Time Series</title>
      <link>https://arxiv.org/abs/2503.07687</link>
      <description>arXiv:2503.07687v1 Announce Type: cross 
Abstract: Human physiological signals tend to exhibit both global and local structures: the former are shared across a population, while the latter reflect inter-individual variability. For instance, kinetic measurements of the gait cycle during locomotion present common characteristics, although idiosyncrasies may be observed due to biomechanical disposition or pathology. To better represent datasets with local-global structure, this work extends Convolutional Dictionary Learning (CDL), a popular method for learning interpretable representations, or dictionaries, of time-series data. In particular, we propose Personalized CDL (PerCDL), in which a local dictionary models local information as a personalized spatiotemporal transformation of a global dictionary. The transformation is learnable and can combine operations such as time warping and rotation. Formal computational and statistical guarantees for PerCDL are provided and its effectiveness on synthetic and real human locomotion data is demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07687v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>AISTATS 2025</arxiv:journal_reference>
      <dc:creator>Axel Roques, Samuel Gruffaz, Kyurae Kim, Alain Oliviero-Durmus, Laurent Oudre</dc:creator>
    </item>
    <item>
      <title>Empirical Error Estimates for Graph Sparsification</title>
      <link>https://arxiv.org/abs/2503.08031</link>
      <description>arXiv:2503.08031v1 Announce Type: cross 
Abstract: Graph sparsification is a well-established technique for accelerating graph-based learning algorithms, which uses edge sampling to approximate dense graphs with sparse ones. Because the sparsification error is random and unknown, users must contend with uncertainty about the reliability of downstream computations. Although it is possible for users to obtain conceptual guidance from theoretical error bounds in the literature, such results are typically impractical at a numerical level. Taking an alternative approach, we propose to address these issues from a data-driven perspective by computing empirical error estimates. The proposed error estimates are highly versatile, and we demonstrate this in four use cases: Laplacian matrix approximation, graph cut queries, graph-structured regression, and spectral clustering. Moreover, we provide two theoretical guarantees for the error estimates, and explain why the cost of computing them is manageable in comparison to the overall cost of a typical graph sparsification workflow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08031v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyao Wang, Miles E. Lopes</dc:creator>
    </item>
    <item>
      <title>Generation and Balancing Capacity in Future Electric Power Systems -- Scenario Analysis Using Bayesian Networks</title>
      <link>https://arxiv.org/abs/2503.08232</link>
      <description>arXiv:2503.08232v1 Announce Type: cross 
Abstract: This paper examines the evolution of the Finnish electric energy system up to 2035, focusing on the likelihood of different development paths. The primary contribution of this paper is the development of an extensive Bayesian Network, designed to model and analyse the evolution of power generation capacity mix, assess the likelihood of different grid management scenarios, and understand the causal relationships underlying these scenarios. A target optimisation was carried out using the constructed Bayesian Network to explore possibilities to minimise grid management complexity. The results of the optimisation reveal that the authorities and stakeholders should prioritise increasing demand response, gas power, and battery storage capacities. These mature technologies are well-suited to guarantee energy adequacy during peak consumption periods, which in Finland typically occur during consecutive cold, dark and windless winter weeks. Although this study focuses on the evolution of the Finnish power grid, the constructed Bayesian Network approach is broadly applicable and can be utilised to explore causal relationships in other countries by employing the designed questionnaire and engaging a panel of experts specific to the country's energy infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08232v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seppo Borenius, Pekka Kekolahti, Petri M\"ah\"onen, Matti Lehtonen</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Linear Functionals of Online SGD in High-dimensional Linear Regression</title>
      <link>https://arxiv.org/abs/2302.09727</link>
      <description>arXiv:2302.09727v3 Announce Type: replace 
Abstract: Stochastic gradient descent (SGD) has emerged as the quintessential method in a data scientist's toolbox. Using SGD for high-stakes applications requires, however, careful quantification of the associated uncertainty. Towards that end, in this work, we establish a high-dimensional Central Limit Theorem (CLT) for linear functionals of online SGD iterates for overparametrized least-squares regression with non-isotropic Gaussian inputs. We first show that a bias-corrected CLT holds when the number of iterations of the online SGD, $t$, grows sub-linearly in the dimensionality, $d$. In order to use the developed result in practice, we further develop an online approach for estimating the variance term appearing in the CLT, and establish high-probability bounds for the developed online estimator. Together with the CLT result, this provides a fully online and data-driven way to numerically construct confidence intervals. This enables practical high-dimensional algorithmic inference with SGD and to the best of our knowledge, is the first such result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09727v3</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bhavya Agrawalla, Krishnakumar Balasubramanian, Promit Ghosal</dc:creator>
    </item>
    <item>
      <title>Ledoit-Wolf linear shrinkage with unknown mean</title>
      <link>https://arxiv.org/abs/2304.07045</link>
      <description>arXiv:2304.07045v2 Announce Type: replace 
Abstract: This work addresses large dimensional covariance matrix estimation with unknown mean. The empirical covariance estimator fails when dimension and number of samples are proportional and tend to infinity, settings known as Kolmogorov asymptotics. When the mean is known, Ledoit and Wolf (2004) proposed a linear shrinkage estimator and proved its convergence under those asymptotics. To the best of our knowledge, no formal proof has been proposed when the mean is unknown. To address this issue, we propose to extend the linear shrinkage and its convergence properties to translation-invariant estimators. We expose four estimators respecting those conditions, proving their properties. Finally, we show empirically that a new estimator we propose outperforms other standard estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.07045v2</guid>
      <category>math.ST</category>
      <category>q-fin.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmva.2025.105429</arxiv:DOI>
      <arxiv:journal_reference>Journal of Multivariate Analysis, Volume 208, 2025, 105429, ISSN 0047-259X</arxiv:journal_reference>
      <dc:creator>Benoit Oriol, Alexandre Miot</dc:creator>
    </item>
    <item>
      <title>Wide stable neural networks: Sample regularity, functional convergence and Bayesian inverse problems</title>
      <link>https://arxiv.org/abs/2407.03909</link>
      <description>arXiv:2407.03909v2 Announce Type: replace 
Abstract: We study the large-width asymptotics of random fully connected neural networks with weights drawn from $\alpha$-stable distributions, a family of heavy-tailed distributions arising as the limiting distributions in the Gnedenko-Kolmogorov heavy-tailed central limit theorem. We show that in an arbitrary bounded Euclidean domain $\mathcal{U}$ with smooth boundary, the random field at the infinite-width limit, characterized in previous literature in terms of finite-dimensional distributions, has sample functions in the fractional Sobolev-Slobodeckij-type quasi-Banach function space $W^{s,p}(\mathcal{U})$ for integrability indices $p &lt; \alpha$ and suitable smoothness indices $s$ depending on the activation function of the neural network, and establish the functional convergence of the processes in the space of probability measures on $W^{s,p}(\mathcal{U})$. This convergence result is leveraged in the study of functional posteriors for edge-preserving Bayesian inverse problems with stable neural network priors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03909v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tom\'as Soto</dc:creator>
    </item>
    <item>
      <title>A simplified directional KeRF algorithm</title>
      <link>https://arxiv.org/abs/2407.04042</link>
      <description>arXiv:2407.04042v3 Announce Type: replace 
Abstract: Random forest methods belong to the class of non-parametric machine learning algorithms. They were first introduced in 2001 by Breiman and they perform with accuracy in high dimensional settings. In this article, we consider, a simplified kernel-based random forest algorithm called simplified directional KeRF (Kernel Random Forest). We establish the asymptotic equivalence between simplified directional KeRF and centered KeRF, with additional numerical experiments supporting our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04042v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iakovidis Isidoros, Nicola Arcozzi</dc:creator>
    </item>
    <item>
      <title>Affine calculus for constrained minima of the Kullback-Leibler divergence</title>
      <link>https://arxiv.org/abs/2502.02177</link>
      <description>arXiv:2502.02177v2 Announce Type: replace 
Abstract: The non-parametric version of Amari's dually affine Information Geometry provides a practical calculus to perform computations of interest in statistical machine learning. The method uses the notion of a statistical bundle, a mathematical structure that includes both probability densities and random variables to capture the spirit of Fisherian statistics. We focus on computations involving a constrained minimization of the Kullback-Leibler divergence. We show how to obtain neat and principled versions of known computation in applications such as mean-field approximation, adversarial generative models, and variational Bayes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02177v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Pistone</dc:creator>
    </item>
    <item>
      <title>Multiple Testing of Linear Forms for Noisy Matrix Completion</title>
      <link>https://arxiv.org/abs/2312.00305</link>
      <description>arXiv:2312.00305v2 Announce Type: replace-cross 
Abstract: Many important tasks of large-scale recommender systems can be naturally cast as testing multiple linear forms for noisy matrix completion. These problems, however, present unique challenges because of the subtle bias-and-variance tradeoff of and an intricate dependence among the estimated entries induced by the low-rank structure. In this paper, we develop a general approach to overcome these difficulties by introducing new statistics for individual tests with sharp asymptotics both marginally and jointly, and utilizing them to control the false discovery rate (FDR) via a data splitting and symmetric aggregation scheme. We show that valid FDR control can be achieved with guaranteed power under nearly optimal sample size requirements using the proposed methodology. Extensive numerical simulations and real data examples are also presented to further illustrate its practical merits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00305v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wanteng Ma, Lilun Du, Dong Xia, Ming Yuan</dc:creator>
    </item>
    <item>
      <title>Perfect Recovery for Random Geometric Graph Matching with Shallow Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2402.07340</link>
      <description>arXiv:2402.07340v2 Announce Type: replace-cross 
Abstract: We study the graph matching problem in the presence of vertex feature information using shallow graph neural networks. Specifically, given two graphs that are independent perturbations of a single random geometric graph with sparse binary features, the task is to recover an unknown one-to-one mapping between the vertices of the two graphs. We show under certain conditions on the sparsity and noise level of the feature vectors, a carefully designed two-layer graph neural network can, with high probability, recover the correct mapping between the vertices with the help of the graph structure. Additionally, we prove that our condition on the noise parameter is tight up to logarithmic factors. Finally, we compare the performance of the graph neural network to directly solving an assignment problem using the noisy vertex features and demonstrate that when the noise level is at least constant, this direct matching fails to achieve perfect recovery, whereas the graph neural network can tolerate noise levels growing as fast as a power of the size of the graph. Our theoretical findings are further supported by numerical studies as well as real-world data experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07340v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suqi Liu, Morgane Austern</dc:creator>
    </item>
    <item>
      <title>Maximal Inequalities for Separately Exchangeable Empirical Processes</title>
      <link>https://arxiv.org/abs/2502.11432</link>
      <description>arXiv:2502.11432v2 Announce Type: replace-cross 
Abstract: This paper derives new maximal inequalities for empirical processes associated with separately exchangeable random arrays. For fixed index dimension $K\ge 1$, we establish a global maximal inequality bounding the $q$-th moment ($q\in[1,\infty)$) of the supremum of these processes. We also obtain a refined local maximal inequality controlling the first absolute moment of the supremum. Both results are proved for a general pointwise measurable function class. Our approach uses a new technique partitioning the index set into transversal groups, decoupling dependencies and enabling more sophisticated higher moment bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11432v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harold D. Chiang</dc:creator>
    </item>
  </channel>
</rss>
