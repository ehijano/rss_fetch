<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DM</link>
    <description>cs.DM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Jun 2025 04:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Maximum Reachability Orientation of Mixed Graphs</title>
      <link>https://arxiv.org/abs/2506.16171</link>
      <description>arXiv:2506.16171v1 Announce Type: cross 
Abstract: We aim to find orientations of mixed graphs optimizing the total reachability, a problem that has applications in causality and biology. For given a digraph $D$, we use $P(D)$ for the set of ordered pairs of distinct vertices in $V(D)$ and we define $\kappa_D:P(D)\rightarrow \{0,1\}$ by $\kappa_D(u,v)=1$ if $v$ is reachable from $u$ in $D$, and $\kappa_D(u,v)=0$, otherwise. We use $R(D)=\sum_{(u,v)\in P(D)}\kappa_D(u,v)$.
  Now, given a mixed graph $G$, we aim to find an orientation $\vec{G}$ of $G$ that maximizes $R(\vec{G})$. Hakimi, Schmeichel, and Young proved that the problem can be solved in polynomial time when restricted to undirected inputs. They inquired about the complexity in mixed graphs.
  We answer this question by showing that this problem is NP-hard, and, moreover, APX-hard.
  We then develop a finer understanding of how quickly the problem becomes difficult when going from undirected to mixed graphs. To this end, we consider the parameterized complexity of the problem with respect to the number $k$ of preoriented arcs of $G$, a new form of parameterization.
  We show that the problem can be solved in $n^{O(k)}$ and that a $(1-\epsilon)$-approximation can be computed in $f(k,\epsilon)n^{O(1)}$ for any $\epsilon &gt; 0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16171v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian H\"orsch</dc:creator>
    </item>
    <item>
      <title>On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis</title>
      <link>https://arxiv.org/abs/2506.16732</link>
      <description>arXiv:2506.16732v1 Announce Type: cross 
Abstract: In unsupervised combinatorial optimization (UCO), during training, one aims to have continuous decisions that are promising in a probabilistic sense for each training instance, which enables end-to-end training on initially discrete and non-differentiable problems. At the test time, for each test instance, starting from continuous decisions, derandomization is typically applied to obtain the final deterministic decisions. Researchers have developed more and more powerful test-time derandomization schemes to enhance the empirical performance and the theoretical guarantee of UCO methods. However, we notice a misalignment between training and testing in the existing UCO methods. Consequently, lower training losses do not necessarily entail better post-derandomization performance, even for the training instances without any data distribution shift. Empirically, we indeed observe such undesirable cases. We explore a preliminary idea to better align training and testing in UCO by including a differentiable version of derandomization into training. Our empirical exploration shows that such an idea indeed improves training-test alignment, but also introduces nontrivial challenges into training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16732v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>math.PR</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fanchen Bu, Kijung Shin</dc:creator>
    </item>
    <item>
      <title>When does FTP become FPT?</title>
      <link>https://arxiv.org/abs/2506.17008</link>
      <description>arXiv:2506.17008v1 Announce Type: cross 
Abstract: In the problem Fault-Tolerant Path (FTP), we are given an edge-weighted directed graph G = (V, E), a subset U \subseteq E of vulnerable edges, two vertices s, t \in V, and integers k and \ell. The task is to decide whether there exists a subgraph H of G with total cost at most \ell such that, after the removal of any k vulnerable edges, H still contains an s-t-path. We study whether Fault-Tolerant Path is fixed-parameter tractable (FPT) and whether it admits a polynomial kernel under various parameterizations. Our choices of parameters include: the number of vulnerable edges in the input graph, the number of safe (i.e, invulnerable) edges in the input graph, the budget \ell, the minimum number of safe edges in any optimal solution, the minimum number of vulnerable edges in any optimal solution, the required redundancy k, and natural above- and below-guarantee parameterizations. We provide an almost complete description of the complexity landscape of FTP for these parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17008v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Bentert, Fedor V. Fomin, Petr A. Golovach, Laure Morelle</dc:creator>
    </item>
    <item>
      <title>Size-varying reversible causal graph dynamics</title>
      <link>https://arxiv.org/abs/1805.10330</link>
      <description>arXiv:1805.10330v3 Announce Type: replace 
Abstract: Consider a network that evolves according to a reversible, nearest neighbours dynamics. Is the dynamics allowed to vary the size of the network? On the one hand it seems that, being the principal carriers of information, nodes cannot be destroyed without jeopardising bijectivity. On the other hand, there are plenty of bijective functions from the set of graphs to the set of graphs that are non-vertex-preserving. The question has been settled negatively -- for three different reasons. Yet, in this paper we do obtain reversible local node creation/destruction -- in three relaxed settings, whose equivalence we prove for robustness. We motivate our work both by theoretical computer science considerations (reversible computing, cellular automata extensions) and theoretical physics concerns (basic formalisms towards discrete quantum gravity).</description>
      <guid isPermaLink="false">oai:arXiv.org:1805.10330v3</guid>
      <category>cs.DM</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pablo Arrighi, Am\'elia Durbec, Aur\'elien Emmanuel</dc:creator>
    </item>
    <item>
      <title>Complexity of Injectivity and Verification of ReLU Neural Networks</title>
      <link>https://arxiv.org/abs/2405.19805</link>
      <description>arXiv:2405.19805v3 Announce Type: replace-cross 
Abstract: Neural networks with ReLU activation play a key role in modern machine learning. Understanding the functions represented by ReLU networks is a major topic in current research as this enables a better interpretability of learning processes. Injectivity of a function computed by a ReLU network, that is, the question if different inputs to the network always lead to different outputs, plays a crucial role whenever invertibility of the function is required, such as, e.g., for inverse problems or generative models. The exact computational complexity of deciding injectivity was recently posed as an open problem (Puthawala et al. [JMLR 2022]). We answer this question by proving coNP-completeness. On the positive side, we show that the problem for a single ReLU-layer is still tractable for small input dimension; more precisely, we present a parameterized algorithm which yields fixed-parameter tractability with respect to the input dimension. In addition, we study the network verification problem which is to verify that certain inputs only yield specific outputs. This is of great importance since neural networks are increasingly used in safety-critical systems. We prove that network verification is coNP-hard for a general class of input domains. Our results also exclude constant-factor polynomial-time approximations for the maximum of a function computed by a ReLU network. In this context, we also characterize surjectivity of functions computed by ReLU networks with one-dimensional output which turns out to be the complement of a basic network verification task. We reveal interesting connections to computational convexity by formulating the surjectivity problem as a zonotope containment problem</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19805v3</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Froese, Moritz Grillo, Martin Skutella</dc:creator>
    </item>
    <item>
      <title>IID Prophet Inequality with Random Horizon: Going Beyond Increasing Hazard Rates</title>
      <link>https://arxiv.org/abs/2407.11752</link>
      <description>arXiv:2407.11752v4 Announce Type: replace-cross 
Abstract: Prophet inequalities are a central object of study in optimal stopping theory. In the iid model, a gambler sees values in an online fashion, sampled independently from a given distribution. Upon observing each value, the gambler either accepts it as a reward or irrevocably rejects it and proceeds to observe the next value. The goal of the gambler, who cannot see the future, is maximising the expected value of the reward while competing against the expectation of a prophet (the offline maximum). In other words, one seeks to maximise the gambler-to-prophet ratio of the expectations.
  This model has been studied with infinite, finite and unknown number of values. When the gambler faces a random number of values, the model is said to have random horizon. We consider the model in which the gambler is given a priori knowledge of the horizon's distribution. Alijani et al. (2020) designed a single-threshold algorithm achieving a ratio of $1/2$ when the random horizon has an increasing hazard rate and is independent of the values. We prove that with a single threshold, a ratio of $1/2$ is actually achievable for several larger classes of horizon distributions, with the largest being known as the $\mathcal{G}$ class in reliability theory. Moreover, we show that this does not extend to its dual, the $\overline{\mathcal{G}}$ class (which includes the decreasing hazard rate class), while it can be extended to low-variance horizons. Finally, we construct the first example of a family of horizons, for which multiple thresholds are necessary to achieve a nonzero ratio. We establish that the Secretary Problem optimal stopping rule provides one such algorithm, paving the way towards the study of the model beyond single-threshold algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11752v4</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giordano Giambartolomei, Frederik Mallmann-Trenn, Raimundo Saona</dc:creator>
    </item>
    <item>
      <title>Benford's Law from Turing Ensembles and Integer Partitions</title>
      <link>https://arxiv.org/abs/2502.16314</link>
      <description>arXiv:2502.16314v2 Announce Type: replace-cross 
Abstract: In this paper we investigate the information-theoretic and mathematical foundations of Benford's law, an important case of a statistical relationship that appears to constrain the information-theoretic behavior of numbers. In the present analysis we seek to deduce a general cause for Benford-like distributions to arise. We posit that they both follow from optimality and renormalization as applied to information-theoretical functionals. We also perform computational experiments that corroborate our conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16314v2</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Kolpakov, Aidan Rocke</dc:creator>
    </item>
  </channel>
</rss>
