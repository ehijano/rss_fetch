<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Apr 2025 02:47:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Pricing AI Model Accuracy</title>
      <link>https://arxiv.org/abs/2504.13375</link>
      <description>arXiv:2504.13375v1 Announce Type: new 
Abstract: This paper examines the market for AI models in which firms compete to provide accurate model predictions and consumers exhibit heterogeneous preferences for model accuracy. We develop a consumer-firm duopoly model to analyze how competition affects firms' incentives to improve model accuracy. Each firm aims to minimize its model's error, but this choice can often be suboptimal. Counterintuitively, we find that in a competitive market, firms that improve overall accuracy do not necessarily improve their profits. Rather, each firm's optimal decision is to invest further on the error dimension where it has a competitive advantage. By decomposing model errors into false positive and false negative rates, firms can reduce errors in each dimension through investments. Firms are strictly better off investing on their superior dimension and strictly worse off with investments on their inferior dimension. Profitable investments adversely affect consumers but increase overall welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13375v1</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Kumar</dc:creator>
    </item>
    <item>
      <title>Propagational Proxy Voting</title>
      <link>https://arxiv.org/abs/2504.13641</link>
      <description>arXiv:2504.13641v1 Announce Type: cross 
Abstract: This paper proposes a voting process in which voters allocate fractional votes to their expected utility in different domains: over proposals, other participants, and sets containing proposals and participants. This approach allows for a more nuanced expression of preferences by calculating the result and relevance within each node. We modeled this by creating a voting matrix that reflects their preference. We use absorbing Markov chains to gain the consensus, and also calculate the influence within the participating nodes. We illustrate this method in action through an experiment with 69 students using a budget allocation topic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13641v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasushi Sakai, Parfait Atchade-Adelomou, Ryan Jiang, Luis Alonso, Kent Larson, Ken Suzuki</dc:creator>
    </item>
    <item>
      <title>Information Sharing with Social Image Concerns and the Spread of Fake News</title>
      <link>https://arxiv.org/abs/2410.19557</link>
      <description>arXiv:2410.19557v3 Announce Type: replace 
Abstract: We study how social image concerns influence information sharing between peers. Individuals receive a signal about a binary state of the world, characterized by a direction and a veracity status. While the direction is freely observable, verifying veracity is costly and type-dependent. We examine two types of social image motives: a desire to appear talented -- i.e., able to distinguish real from fake news -- and a desire to signal one's worldview. For each motive, we characterize equilibrium sharing patterns and derive implications for the quality of shared information. We show that fake news may be shared more frequently than factual news (e.g., Vosoughi et al., 2018}). Both ability- and worldview-driven motives can rationalize this behavior, though they lead to empirically distinct sharing patterns and differing welfare implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19557v3</guid>
      <category>econ.TH</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dana Sisak, Philipp Denter</dc:creator>
    </item>
  </channel>
</rss>
