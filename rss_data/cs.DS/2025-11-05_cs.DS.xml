<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Nov 2025 02:43:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Disjoint Paths in Expanders in Deterministic Almost-Linear Time via Hypergraph Perfect Matching</title>
      <link>https://arxiv.org/abs/2511.02214</link>
      <description>arXiv:2511.02214v1 Announce Type: new 
Abstract: We design efficient deterministic algorithms for finding short edge-disjoint paths in expanders. Specifically, given an $n$-vertex $m$-edge expander $G$ of conductance $\phi$ and minimum degree $\delta$, and a set of pairs $\{(s_i,t_i)\}_i$ such that each vertex appears in at most $k$ pairs, our algorithm deterministically computes a set of edge-disjoint paths from $s_i$ to $t_i$, one for every $i$: (1) each of length at most $18 \log (n)/\phi$ and in $mn^{1+o(1)}\min\{k, \phi^{-1}\}$ total time, assuming $\phi^3\delta\ge (35\log n)^3 k$, or (2) each of length at most $n^{o(1)}/\phi$ and in total $m^{1+o(1)}$ time, assuming $\phi^3 \delta \ge n^{o(1)} k$. Before our work, deterministic polynomial-time algorithms were known only for expanders with constant conductance and were significantly slower. To obtain our result, we give an almost-linear time algorithm for \emph{hypergraph perfect matching} under generalizations of Hall-type conditions (Haxell 1995), a powerful framework with applications in various settings, which until now has only admitted large polynomial-time algorithms (Annamalai 2018).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02214v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matija Buci\'c, Zhongtian He, Shang-En Huang, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>Fast Approximation Algorithm for Non-Monotone DR-submodular Maximization under Size Constraint</title>
      <link>https://arxiv.org/abs/2511.02254</link>
      <description>arXiv:2511.02254v1 Announce Type: new 
Abstract: This work studies the non-monotone DR-submodular Maximization over a ground set of $n$ subject to a size constraint $k$. We propose two approximation algorithms for solving this problem named FastDrSub and FastDrSub++. FastDrSub offers an approximation ratio of $0.044$ with query complexity of $O(n \log(k))$. The second one, FastDrSub++, improves upon it with a ratio of $1/4-\epsilon$ within query complexity of $(n \log k)$ for an input parameter $\epsilon &gt;0$. Therefore, our proposed algorithms are the first constant-ratio approximation algorithms for the problem with the low complexity of $O(n \log(k))$.
  Additionally, both algorithms are experimentally evaluated and compared against existing state-of-the-art methods, demonstrating their effectiveness in solving the Revenue Maximization problem with DR-submodular objective function. The experimental results show that our proposed algorithms significantly outperform existing approaches in terms of both query complexity and solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02254v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tan D. Tran, Canh V. Pham</dc:creator>
    </item>
    <item>
      <title>Learning CNF formulas from uniform random solutions in the local lemma regime</title>
      <link>https://arxiv.org/abs/2511.02487</link>
      <description>arXiv:2511.02487v1 Announce Type: new 
Abstract: We study the problem of learning a $n$-variables $k$-CNF formula $\Phi$ from its i.i.d. uniform random solutions, which is equivalent to learning a Boolean Markov random field (MRF) with $k$-wise hard constraints. Revisiting Valiant's algorithm (Commun. ACM'84), we show that it can exactly learn (1) $k$-CNFs with bounded clause intersection size under Lov\'asz local lemma type conditions, from $O(\log n)$ samples; and (2) random $k$-CNFs near the satisfiability threshold, from $\widetilde{O}(n^{\exp(-\sqrt{k})})$ samples. These results significantly improve the previous $O(n^k)$ sample complexity. We further establish new information-theoretic lower bounds on sample complexity for both exact and approximate learning from i.i.d. uniform random solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02487v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiming Feng, Xiongxin Yang, Yixiao Yu, Yiyao Zhang</dc:creator>
    </item>
    <item>
      <title>A Simple and Fast $(3+\varepsilon)$-approximation for Constrained Correlation Clustering</title>
      <link>https://arxiv.org/abs/2511.02705</link>
      <description>arXiv:2511.02705v1 Announce Type: new 
Abstract: In Constrained Correlation Clustering, the goal is to cluster a complete signed graph in a way that minimizes the number of negative edges inside clusters plus the number of positive edges between clusters, while respecting hard constraints on how to cluster certain friendly or hostile node pairs. Fischer et al. [FKKT25a] recently developed a $\tilde{O}(n^3)$-time 16-approximation algorithm for this problem. We settle an open question posed by these authors by designing an algorithm that is equally fast but brings the approximation factor down to $(3+\varepsilon)$ for arbitrary constant $\varepsilon &gt; 0$. Although several new algorithmic steps are needed to obtain our improved approximation, our approach maintains many advantages in terms of simplicity. In particular, it relies mainly on rounding a (new) covering linear program, which can be approximated quickly and combinatorially. Furthermore, the rounding step amounts to applying the very familiar Pivot algorithm to an auxiliary graph. Finally, we develop much simpler algorithms for instances that involve only friendly or only hostile constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02705v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nate Veldt</dc:creator>
    </item>
    <item>
      <title>Probabilistic Graph Cuts</title>
      <link>https://arxiv.org/abs/2511.02272</link>
      <description>arXiv:2511.02272v2 Announce Type: cross 
Abstract: Probabilistic relaxations of graph cuts offer a differentiable alternative to spectral clustering, enabling end-to-end and online learning without eigendecompositions, yet prior work centered on RatioCut and lacked general guarantees and principled gradients. We present a unified probabilistic framework that covers a wide class of cuts, including Normalized Cut. Our framework provides tight analytic upper bounds on expected discrete cuts via integral representations and Gauss hypergeometric functions with closed-form forward and backward. Together, these results deliver a rigorous, numerically stable foundation for scalable, differentiable graph partitioning covering a wide range of clustering and contrastive learning objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02272v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ayoub Ghriss</dc:creator>
    </item>
    <item>
      <title>Accelerating Graph Similarity Search through Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2511.02611</link>
      <description>arXiv:2511.02611v1 Announce Type: cross 
Abstract: The Graph Edit Distance (GED) is an important metric for measuring the similarity between two (labeled) graphs. It is defined as the minimum cost required to convert one graph into another through a series of (elementary) edit operations. Its effectiveness in assessing the similarity of large graphs is limited by the complexity of its exact calculation, which is NP-hard theoretically and computationally challenging in practice. The latter can be mitigated by switching to the Graph Similarity Search under GED constraints, which determines whether the edit distance between two graphs is below a given threshold. A popular framework for solving Graph Similarity Search under GED constraints in a graph database for a query graph is the filter-and-verification framework. Filtering discards unpromising graphs, while the verification step certifies the similarity between the filtered graphs and the query graph. To improve the filtering step, we define a lower bound based on an integer linear programming formulation. We prove that this lower bound dominates the effective branch match-based lower bound and can also be computed efficiently. Consequently, we propose a graph similarity search algorithm that uses a hierarchy of lower bound algorithms and solves a novel integer programming formulation that exploits the threshold parameter. An extensive computational experience on a well-assessed test bed shows that our approach significantly outperforms the state-of-the-art algorithm on most of the examined thresholds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02611v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea D'Ascenzo, Julian Meffert, Petra Mutzel, Fabrizio Rossi</dc:creator>
    </item>
    <item>
      <title>Mixing of general biased adjacent transposition chains</title>
      <link>https://arxiv.org/abs/2511.02725</link>
      <description>arXiv:2511.02725v1 Announce Type: cross 
Abstract: We analyze the general biased adjacent transposition shuffle process, which is a well-studied Markov chain on the symmetric group $S_n$. In each step, an adjacent pair of elements $i$ and $j$ are chosen, and then $i$ is placed ahead of $j$ with probability $p_{ij}$. This Markov chain arises in the study of self-organizing lists in theoretical computer science, and has close connections to exclusion processes from statistical physics and probability theory. Fill (2003) conjectured that for general $p_{ij}$ satisfying $p_{ij} \ge 1/2$ for all $i&lt;j$ and a simple monotonicity condition, the mixing time is polynomial. We prove that for any fixed $\varepsilon&gt;0$, as long as $p_{ij} &gt;1/2+\varepsilon$ for all $i&lt;j$, the mixing time is $\Theta(n^2)$ and exhibits pre-cutoff. Our key technical result is a form of spatial mixing for the general biased transposition chain after a suitable burn-in period. In order to use this for a mixing time bound, we adapt multiscale arguments for mixing times from the setting of spin systems to the symmetric group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02725v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reza Gheissari, Holden Lee, Eric Vigoda</dc:creator>
    </item>
    <item>
      <title>Testing with Non-identically Distributed Samples</title>
      <link>https://arxiv.org/abs/2311.11194</link>
      <description>arXiv:2311.11194v2 Announce Type: replace 
Abstract: We examine the extent to which sublinear-sample property testing and estimation apply to settings where samples are independently but not identically distributed. Specifically, we consider the following distributional property testing framework: Suppose there is a set of distributions over a discrete support of size $k$, $p_1, p_2,\ldots,p_T$, and we obtain $c$ independent draws from each distribution. Suppose the goal is to learn or test a property of the average distribution, $p_{avg}$. This setup models a number of important practical settings where the individual distributions correspond to heterogeneous entities -- either individuals, chronologically distinct time periods, spatially separated data sources, etc. From a learning standpoint, even with $c=1$ samples from each distribution, $\Theta(k/\varepsilon^2)$ samples are necessary and sufficient to learn $p_{avg}$ to within error $\varepsilon$ in $\ell_1$ distance. To test uniformity or identity -- distinguishing the case that $p_{avg}$ is equal to some reference distribution, versus has $\ell_1$ distance at least $\varepsilon$ from the reference distribution, we show that a linear number of samples in $k$ is necessary given $c=1$ samples from each distribution. In contrast, for $c \ge 2$, we recover the usual sublinear sample testing guarantees of the i.i.d.\ setting: we show that $O(\sqrt{k}/\varepsilon^2 + 1/\varepsilon^4)$ total samples are sufficient, matching the optimal sample complexity in the i.i.d.\ case in the regime where $\varepsilon \ge k^{-1/4}$. Additionally, we show that in the $c=2$ case, there is a constant $\rho &gt; 0$ such that even in the linear regime with $\rho k$ samples, no tester that considers the multiset of samples (ignoring which samples were drawn from the same $p_i$) can perform uniformity testing. We also extend our techniques to the problem of testing "closeness" of two distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11194v2</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivam Garg, Chirag Pabbaraju, Kirankumar Shiragur, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Solving the Correlation Cluster LP in Sublinear Time</title>
      <link>https://arxiv.org/abs/2503.20883</link>
      <description>arXiv:2503.20883v5 Announce Type: replace 
Abstract: Correlation Clustering is a fundamental and widely-studied problem in unsupervised learning and data mining. The input is a graph and the goal is to construct a clustering minimizing the number of inter-cluster edges plus the number of missing intra-cluster edges.
  CCL+24 introduced the cluster LP for Correlation Clustering, which they argued captures the problem much more succinctly than previous linear programming formulations. However, the cluster LP has exponential size, with a variable for every possible set of vertices in the input graph. Nevertheless, CCL+24 showed how to find a feasible solution for the cluster LP in time $O(n^{\text{poly}(1/\epsilon)})$ with objective value at most $(1+\epsilon)$ times the value of an optimal solution for the respective Correlation Clustering instance. Furthermore, they showed how to round a solution to the cluster LP, yielding a $(1.485+\epsilon)$-approximation algorithm for the Correlation Clustering problem.
  The main technical result of this paper is a new approach to find a feasible solution for the cluster LP with objective value at most $(1+\epsilon)$ of the optimum in time $\widetilde O(2^{\text{poly}(1/\epsilon)} n)$, where $n$ is the number of vertices in the graph. We also show how to implement the rounding within the same time bounds, thus achieving a fast $(1.485+\epsilon)$-approximation algorithm for the Correlation Clustering problem. This bridges the gap between state-of-the-art methods for approximating Correlation Clustering and the recent focus on fast algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20883v5</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3717823.3718181</arxiv:DOI>
      <dc:creator>Nairen Cao, Vincent Cohen-Addad, Shi Li, Euiwoong Lee, David Rasmussen Lolck, Alantha Newman, Mikkel Thorup, Lukas Vogl, Shuyi Yan, Hanwen Zhang</dc:creator>
    </item>
    <item>
      <title>Sample and Expand: Discovering Low-rank Submatrices With Quality Guarantees</title>
      <link>https://arxiv.org/abs/2506.06456</link>
      <description>arXiv:2506.06456v2 Announce Type: replace 
Abstract: The problem of approximating a matrix by a low-rank one has been extensively studied. This problem assumes, however, that the whole matrix has a low-rank structure. This assumption is often false for real-world matrices. We consider the problem of discovering submatrices from the given matrix with bounded deviations from their low-rank approximations. We introduce an effective two-phase method for this task: first, we use sampling to discover small nearly low-rank submatrices, and then they are expanded while preserving proximity to a low-rank approximation. An extensive experimental evaluation confirms that the method we introduce compares favorably to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06456v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martino Ciaperoni, Aristides Gionis, Heikki Mannila</dc:creator>
    </item>
    <item>
      <title>$O(\log n)$-Approximation Algorithms for Bipartiteness Ratio</title>
      <link>https://arxiv.org/abs/2507.12847</link>
      <description>arXiv:2507.12847v2 Announce Type: replace 
Abstract: We propose an $O(\log n)$-approximation algorithm for the bipartiteness ratio of undirected graphs introduced by Trevisan (SIAM Journal on Computing, vol. 41, no. 6, 2012), where $n$ is the number of vertices. Our approach extends the cut-matching game framework for sparsest cut to the bipartiteness ratio, and requires only $\mathop{\mathrm{polylog}} n$ many single-commodity undirected maximum flow computations. Therefore, with the current fastest undirected max-flow algorithms, it runs in almost linear time. Along the way, we introduce the concept of well-linkedness for skew-symmetric graphs and prove a novel characterization of bipartiteness ratio in terms of well-linkedness in an auxiliary skew-symmetric graph, which may be of independent interest.
  As an application, we devise an $\tilde{O}(mn)$-time algorithm for the minimum uncut problem: given a graph whose optimal cut leaves an $\eta$ fraction of edges uncut, we find a cut that leaves only an $O(\log n \log(1/\eta)) \cdot \eta$ fraction of edges uncut, where $m$ is the number of edges.
  Finally, we propose a directed analogue of the bipartiteness ratio, and we give a polynomial-time algorithm that achieves an $O(\log n)$ approximation for this measure via a directed Leighton--Rao-style embedding. We also propose an algorithm for the minimum directed uncut problem with a guarantee similar to that for the minimum uncut problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12847v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tasuku Soma, Mingquan Ye, Yuichi Yoshida</dc:creator>
    </item>
    <item>
      <title>Constant Approximation for Weighted Nash Social Welfare with Submodular Valuations</title>
      <link>https://arxiv.org/abs/2411.02942</link>
      <description>arXiv:2411.02942v3 Announce Type: replace-cross 
Abstract: We study the problem of assigning items to agents so as to maximize the \emph{weighted} Nash Social Welfare (NSW) under submodular valuations. The best-known result for the problem is an $O(nw_{\max})$-approximation due to Garg, Husic, Li, V\'egh, and Vondr\'ak~[STOC 2023], where $w_{\max}$ is the maximum weight over all agents. Obtaining a constant approximation algorithm is an open problem in the field that has recently attracted considerable attention.
  We give the first such algorithm for the problem, thus solving the open problem in the affirmative. Our algorithm is based on the natural Configuration LP for the problem, which was introduced recently by Feng and Li~[ICALP 2024] for the additive valuation case. Our rounding algorithm is similar to that of Li~[SODA 2025] developed for the unrelated machine scheduling problem to minimize weighted completion time. Roughly speaking, we designate the largest item in each configuration as a large item and the remaining items as small items. So, every agent gets precisely 1 fractional large item in the configuration LP solution. With the rounding algorithm in Li~[SODA 2025], we can ensure that in the obtained solution, every agent gets precisely 1 large item, and the assignments of small items are negatively correlated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02942v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuda Feng, Yang Hu, Shi Li, Ruilong Zhang</dc:creator>
    </item>
    <item>
      <title>Nash Social Welfare with Submodular Valuations: Approximation Algorithms and Integrality Gaps</title>
      <link>https://arxiv.org/abs/2504.09669</link>
      <description>arXiv:2504.09669v3 Announce Type: replace-cross 
Abstract: We study the problem of allocating items to agents with submodular valuations with the goal of maximizing the weighted Nash social welfare (NSW). The best-known results for unweighted and weighted objectives are the $(4+\epsilon)$ approximation given by Garg, Husic, Li, V\'egh, and Vondr\'ak~[STOC 2023] and the $(233+\epsilon)$ approximation given by Feng, Hu, Li, and Zhang~[STOC 2025], respectively.
  In this work, we present a $(3.56+\epsilon)$-approximation algorithm for weighted NSW maximization with submodular valuations, simultaneously improving the previous approximation ratios of both the weighted and unweighted NSW problems. Our algorithm solves the configuration LP of Feng, Hu, Li, and Zhang~[STOC 2025] via a stronger separation oracle that loses an $e/(e-1)$ factor only on small items, and then rounds the solution via a new bipartite multigraph construction. Some key technical ingredients of our analysis include a greedy proxy function, additive within each configuration, that preserves the LP value while lower-bounding the rounded solution, together with refined concentration bounds and a series of mathematical programs analyzed partly by computer assistance.
  On the hardness side, we prove that the configuration LP for weighted NSW with submodular valuations has an integrality gap of at least $(2^{\ln 2}-\epsilon) \approx 1.617 - \epsilon$, which is larger than the current best-known $e/(e-1)-\epsilon \approx 1.582-\epsilon$ hardness~[SODA 2020]. For additive valuations, we show an integrality gap of $(e^{1/e}-\epsilon)$, which proves the tightness of the approximation ratio in~[ICALP 2024] for algorithms based on the configuration LP. For unweighted NSW with additive valuations, we show an integrality gap of $(2^{1/4}-\epsilon) \approx 1.189-\epsilon$, again larger than the current best-known $\sqrt{8/7} \approx 1.069$-hardness~[Math. Oper. Res. 2024].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09669v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaohui Bei, Yuda Feng, Yang Hu, Shi Li, Ruilong Zhang</dc:creator>
    </item>
    <item>
      <title>Discrete and Continuous Difference of Submodular Minimization</title>
      <link>https://arxiv.org/abs/2506.07952</link>
      <description>arXiv:2506.07952v3 Announce Type: replace-cross 
Abstract: Submodular functions, defined on continuous or discrete domains, arise in numerous applications. We study the minimization of the difference of two submodular (DS) functions, over both domains, extending prior work restricted to set functions. We show that all functions on discrete domains and all smooth functions on continuous domains are DS. For discrete domains, we observe that DS minimization is equivalent to minimizing the difference of two convex (DC) functions, as in the set function case. We propose a novel variant of the DC Algorithm (DCA) and apply it to the resulting DC Program, obtaining comparable theoretical guarantees as in the set function case. The algorithm can be applied to continuous domains via discretization. Experiments demonstrate that our method outperforms baselines in integer compressive sensing and integer least squares.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07952v3</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025</arxiv:journal_reference>
      <dc:creator>George Orfanides, Tim Hoheisel, Marwa El Halabi</dc:creator>
    </item>
    <item>
      <title>Shifted Composition IV: Toward Ballistic Acceleration for Log-Concave Sampling</title>
      <link>https://arxiv.org/abs/2506.23062</link>
      <description>arXiv:2506.23062v2 Announce Type: replace-cross 
Abstract: Acceleration is a celebrated cornerstone of convex optimization, enabling gradient-based algorithms to converge sublinearly in the condition number. A major open question is whether an analogous acceleration phenomenon is possible for log-concave sampling. Underdamped Langevin dynamics (ULD) has long been conjectured to be the natural candidate for acceleration, but a central challenge is that its degeneracy necessitates the development of new analysis approaches, e.g., the theory of hypocoercivity. Although recent breakthroughs established ballistic acceleration for the (continuous-time) ULD diffusion via space-time Poincare inequalities, (discrete-time) algorithmic results remain entirely open: the discretization error of existing analysis techniques dominates any continuous-time acceleration.
  In this paper, we give a new coupling-based local error framework for analyzing ULD and its numerical discretizations in KL divergence. This extends the framework in Shifted Composition III from uniformly elliptic diffusions to degenerate diffusions, and shares its virtues: the framework is user-friendly, applies to sophisticated discretization schemes, and does not require contractivity. Applying this framework to the randomized midpoint discretization of ULD establishes the first ballistic acceleration result for log-concave sampling (i.e., sublinear dependence on the condition number). Along the way, we also obtain the first $d^{1/3}$ iteration complexity guarantee for sampling to constant total variation error in dimension $d$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23062v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason M. Altschuler, Sinho Chewi, Matthew S. Zhang</dc:creator>
    </item>
    <item>
      <title>On the Parameterized Complexity of Grundy Domination and Zero Forcing Problems</title>
      <link>https://arxiv.org/abs/2508.18104</link>
      <description>arXiv:2508.18104v2 Announce Type: replace-cross 
Abstract: We consider two different problem families that deal with domination in graphs. On the one hand, we focus on dominating sequences. In such a sequence, every vertex dominates some vertex of the graph that was not dominated by any earlier vertex in the sequence. The problem of finding the longest dominating sequence is known as $\mathsf{Grundy~Domination}$. Depending on whether the closed or the open neighborhoods are used for domination, there are three other versions of this problem. We show that all four problem variants are $\mathsf{W[1]}$-complete when parameterized by the solution size. On the other hand, we consider the family of zero forcing problems which form the parameterized duals of the Grundy domination problems. In these problems, one looks for the smallest set of vertices initially colored blue such that certain color change rules are able to color all other vertices blue. Bhyravarapu et al. [IWOCA 2025] showed that one of these problems, known as $\mathsf{Zero~Forcing~Set}$, is in $\mathsf{FPT}$ when parameterized by the treewidth or the solution size. We extend their treewidth result to the other three variants of zero forcing and their respective Grundy domination problems. Our algorithm also implies an $\mathsf{FPT}$ algorithm for $\mathsf{Grundy~Domination}$ when parameterized by the number of vertices that are not in the dominating sequence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18104v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Scheffler</dc:creator>
    </item>
    <item>
      <title>Can Like Attract Like? A Study of Homonymous Gathering in Networks</title>
      <link>https://arxiv.org/abs/2510.25451</link>
      <description>arXiv:2510.25451v2 Announce Type: replace-cross 
Abstract: A team of mobile agents, starting from distinct nodes of a network, have to meet at the same node and declare that they all met. Agents execute the same algorithm, which they start when activated by an adversary or by an agent entering their initial node. When activated, agents traverse edges of the network in synchronous rounds. Their perception and communication are strictly local. This task, known as gathering, is a central problem in distributed mobile systems. Most prior work focuses on minimizing its time complexity, i.e., the worst-case number of rounds between the start of the earliest agent and the task completion. To break possible symmetries, deterministic solutions typically assume that agents have pairwise distinct IDs, called labels, known only to themselves. But must all labels be pairwise distinct to guarantee deterministic gathering?
  We address this question by considering agents that may share the same label. A team L is said to be gatherable if, for every initial setting of L, there is an algorithm that solves gathering. Our contribution is threefold. (1) We give a full characterization of the gatherable teams. (2) We design an algorithm that gathers all of them in poly$(n,\log\lambda)$ time, where $n$ (resp. $\lambda$) is the graph order (resp. the smallest label in L). This algorithm requires the agents to initially share only $O(\log \log \log \mu)$ bits of common knowledge, where $\mu$ is the largest label multiplicity in L. (3) We show this dependency is almost optimal to get a poly$(n,\log\lambda)$-time complexity.
  As a by-product, we get the first deterministic poly$(n,\log\lambda)$-time algorithm requiring no common knowledge to gather any team when all labels are distinct. Known to be achievable for two-agent teams, extending this to any team size faced a major challenge: termination detection. Our techniques to address it may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25451v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>St\'ephane Devismes, Yoann Dieudonn\'e, Arnaud Labourel</dc:creator>
    </item>
  </channel>
</rss>
