<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 02:36:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>DecodeX: Exploring and Benchmarking of LDPC Decoding across CPU, GPU, and ASIC Platforms</title>
      <link>https://arxiv.org/abs/2511.02952</link>
      <description>arXiv:2511.02952v1 Announce Type: new 
Abstract: Emerging virtualized radio access networks (vRANs) demand flexible and efficient baseband processing across heterogeneous compute substrates. In this paper, we present DecodeX, a unified benchmarking framework for evaluating low-density parity-check (LDPC) decoding acceleration across different hardware platforms. DecodeX integrates a comprehensive suite of LDPC decoder implementations, including kernels, APIs, and test vectors for CPUs (FlexRAN), GPUs (Aerial and Sionna-RK), and ASIC (ACC100), and can be readily extended to additional architectures and configurations. Using DecodeX, we systematically characterize how different platforms orchestrate computation-from threading and memory management to data movement and accelerator offload-and quantify the resulting decoding latency under varying Physical layer parameters. Our observations reveal distinct trade-offs in parallel efficiency and offload overhead, showing that accelerator gains strongly depend on data-movement and workload granularity. Building on these insights, we discuss how cross-platform benchmarking can inform adaptive scheduling and co-design for future heterogeneous vRANs, enabling scalable and energy-efficient baseband processing for NextG wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02952v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhenzhou Qi, Yuncheng Yao, Yiming Li, Chung-Hsuan Tung, Junyao Zheng, Danyang Zhuo, Tingjun Chen</dc:creator>
    </item>
    <item>
      <title>Distributed Incast Detection in Data Center Networks</title>
      <link>https://arxiv.org/abs/2511.03039</link>
      <description>arXiv:2511.03039v1 Announce Type: new 
Abstract: Incast traffic in data centers can lead to severe performance degradation, such as packet loss and increased latency. Effectively addressing incast requires prompt and accurate detection. Existing solutions, including MA-ECN, BurstRadar and Pulser, typically rely on fixed thresholds of switch port egress queue lengths or their gradients to identify microburst caused by incast flows. However, these queue length related methods often suffer from delayed detection and high error rates. In this study, we propose a distributed incast detection method for data center networks at the switch-level, leveraging a probabilistic hypothesis test with an optimal detection threshold. By analyzing the arrival intervals of new flows, our algorithm can immediately determine if a flow is part of an incast traffic from its initial packet. The experimental results demonstrate that our method offers significant improvements over existing approaches in both detection speed and inference accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03039v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Zheng, Haoran Qi, Lirui Yu, Zhan Shu, Qing Zhao</dc:creator>
    </item>
    <item>
      <title>CRSF: Enabling QoS-Aware Beyond-Connectivity Service Sharing in 6G Local Networks</title>
      <link>https://arxiv.org/abs/2511.03081</link>
      <description>arXiv:2511.03081v1 Announce Type: new 
Abstract: Sixth-generation (6G) networks are envisioned to support interconnected local subnetworks that can share specialized, beyond-connectivity services. However, a standardized architecture for discovering and selecting these services across network boundaries has not existed yet. To address this gap, this paper introduces the Central Repository and Selection Function (CRSF), a novel network function for the 6G core that facilitates efficient inter-subnetwork service discovery and selection. We formulate the selection process as a QoS-aware optimization problem designed to balance service quality metrics with user-defined priorities. We evaluate our system model through simulations for a sensing service scenario and observe a consistently higher aggregate Quality of Service (QoS) compared to the baseline selection strategy. The proposed CRSF provides a foundational and extensible mechanism for building standardized, collaborative, and service-centric interconnected networks essential for the 6G era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03081v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pragya Sharma, Amanda Xiang, Abbas Kiani, John Kaippallimalil, Tony Saboorian, Haining Wang</dc:creator>
    </item>
    <item>
      <title>Handover Configurations in Operational 5G Networks: Diversity, Evolution, and Impact on Performance</title>
      <link>https://arxiv.org/abs/2511.03116</link>
      <description>arXiv:2511.03116v1 Announce Type: new 
Abstract: Mobility management in cellular networks, especially the handover (HO) process, plays a key role in providing seamless and ubiquitous Internet access. The wide-scale deployment of 5G and the resulting co-existence of 4G/5G in the past six years have significantly changed the landscape of all mobile network operators and made the HO process much more complex than before. While several recent works have studied the impact of HOs on user experience, why and how HOs occur and how HO configurations affect performance in 5G operational networks remains largely unknown. Through four cross-country driving trips across the US spread out over a 27-month period, we conduct an in-depth measurement study of HO configurations across all three major US operators. Our study reveals (a) new types of HOs and new HO events used by operators to handle these new types of HOs, (b) overly aggressive HO configurations that result in unnecessarily high signaling overhead, (c) large diversity in HO configuration parameter values, which also differ across operators, but significantly lower diversity in 5G compared to LTE, and (d) sub-optimal HO configurations/decisions leading to poor pre- or post-HO performance. Our findings have many implications for mobile operators, as they keep fine-tuning their 5G HO configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03116v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moinak Ghoshal, Imran Khan, Phuc Dinh, Z. Jonny Kong, Omar Basit, Sizhe Wang, Yufei Feng, Y. Charlie Hu, Dimitrios Koutsonikolas</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2511.03159</link>
      <description>arXiv:2511.03159v1 Announce Type: new 
Abstract: Mobile edge computing (MEC) can pre-cache deep neural networks (DNNs) near end-users, providing low-latency services and improving users' quality of experience (QoE). However, caching all DNN models at edge servers with limited capacity is difficult, and the impact of model loading time on QoE remains underexplored. Hence, we introduce dynamic DNNs in edge scenarios, disassembling a complete DNN model into interrelated submodels for more fine-grained and flexible model caching and request routing solutions. This raises the pressing issue of jointly deciding request routing and submodel caching for dynamic DNNs to balance model inference precision and loading latency for QoE optimization. In this paper, we study the joint dynamic model caching and request routing problem in MEC networks, aiming to maximize user request inference precision under constraints of server resources, latency, and model loading time. To tackle this problem, we propose CoCaR, an offline algorithm based on linear programming and random rounding that leverages dynamic DNNs to optimize caching and routing schemes, achieving near-optimal performance. Furthermore, we develop an online variant of CoCaR, named CoCaR-OL, enabling effective adaptation to dynamic and unpredictable online request patterns. The simulation results demonstrate that the proposed CoCaR improves the average inference precision of user requests by 46\% compared to state-of-the-art baselines. In addition, in online scenarios, CoCaR-OL achieves an improvement of no less than 32.3\% in user QoE over competitive baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03159v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuting Qiu, Fang Dong, Siyu Tan, Ruiting Zhou, Dian Shen, Patrick P. C. Lee, Qilin Fan</dc:creator>
    </item>
    <item>
      <title>Integrity Under Siege: A Rogue gNodeB's Manipulation of 5G Network Slice Allocation</title>
      <link>https://arxiv.org/abs/2511.03312</link>
      <description>arXiv:2511.03312v1 Announce Type: new 
Abstract: The advent of 5G networks, with network slicing as a cornerstone technology, promises customized, high-performance services, but also introduces novel attack surfaces beyond traditional threats. This article investigates a critical and underexplored integrity vulnerability: the manipulation of network slice allocation to compromise Quality of Service (QoS) and resource integrity. We introduce a threat model, grounded in a risk analysis of permissible yet insecure configurations like null-ciphering (5G-EA0), demonstrating how a rogue gNodeB acting as a Man-in-the-Middle can exploit protocol weaknesses to forge slice requests and hijack a User Equipment's (UE) connection. Through a comprehensive experimental evaluation on a 5G testbed, we demonstrate the attack's versatile and severe impacts. Our findings show this integrity breach can manifest as obvious QoS degradation, such as a 95% bandwidth reduction and 150% latency increase when forcing UE to a suboptimal slice, or as stealthy slice manipulation that is indistinguishable from benign network operation and generates no core network errors. Furthermore, we validate a systemic resource contamination attack where redirecting a crowd of UE orchestrates a Denial-of-Service, causing packet loss to exceed 60% and inducing measurable CPU saturation (~80%) on core network User Plane Functions (UPFs). Based on these results, we discuss the profound implications for Service Level Agreements (SLAs) and critical infrastructure. We propose concrete, cross-layer mitigation strategies for network operators as future work, underscoring the urgent need to secure the integrity of dynamic resource management in 5G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03312v1</guid>
      <category>cs.NI</category>
      <category>cs.SE</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiali Xu, Valeria Loscri, Romain Rouvoy</dc:creator>
    </item>
    <item>
      <title>Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond</title>
      <link>https://arxiv.org/abs/2511.03434</link>
      <description>arXiv:2511.03434v1 Announce Type: cross 
Abstract: As the "agentic web" takes shape-billions of AI agents (often LLM-powered) autonomously transacting and collaborating-trust shifts from human oversight to protocol design. In 2025, several inter-agent protocols crystallized this shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2), and Ethereum's ERC-8004 "Trustless Agents," yet their underlying trust assumptions remain under-examined. This paper presents a comparative study of trust models in inter-agent protocol design: Brief (self- or third-party verifiable claims), Claim (self-proclaimed capabilities and identity, e.g. AgentCard), Proof (cryptographic verification, including zero-knowledge proofs and trusted execution environment attestations), Stake (bonded collateral with slashing and insurance), Reputation (crowd feedback and graph-based trust signals), and Constraint (sandboxing and capability bounding). For each, we analyze assumptions, attack surfaces, and design trade-offs, with particular emphasis on LLM-specific fragilities-prompt injection, sycophancy/nudge-susceptibility, hallucination, deception, and misalignment-that render purely reputational or claim-only approaches brittle. Our findings indicate no single mechanism suffices. We argue for trustless-by-default architectures anchored in Proof and Stake to gate high-impact actions, augmented by Brief for identity and discovery and Reputation overlays for flexibility and social signals. We comparatively evaluate A2A, AP2, ERC-8004 and related historical variations in academic research under metrics spanning security, privacy, latency/cost, and social robustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid trust model recommendations that mitigate reputation gaming and misinformed LLM behavior, and we distill actionable design guidelines for safer, interoperable, and scalable agent economies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03434v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Botao 'Amber' Hu, Helena Rong</dc:creator>
    </item>
    <item>
      <title>Mapping The Invisible Internet: Framework and Dataset</title>
      <link>https://arxiv.org/abs/2506.18159</link>
      <description>arXiv:2506.18159v2 Announce Type: replace 
Abstract: This article describes a novel dataset that maps the network layer of the Invisible Internet Project (I2P). The data was collected using SWARM-I2P framework, which deployed I2P routers as a network of mapping agents that gather information on the network's topology and traffic over an extended period. The dataset documents over 50,000 nodes, including subsets of high-performance (FastSet) nodes and high-capacity nodes characterized by metrics such as bandwidth, latency, and uptime. It also contains detailed records of network traffic and the geographic distribution of thousands of nodes. Data was collected using a combination of methods, including querying router consoles, analysing the network database (netDb), and passive network monitoring. All node identifiers were anonymized to maintain user privacy. The data is publicly available in CSV and TXT formats on Zenodo, with mapping scripts provided on GitHub. This resource provides a foundational understanding of the decentralized routing behaviours that underpin I2P's anonymity, making it suitable for reuse in analyses of tunnel node selection, anonymity network resilience, and adversarial modelling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18159v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.dib.2025.112175</arxiv:DOI>
      <dc:creator>Siddique Abubakr Muntaka, Jacques Bou Abdo, Kemi Akanbi, Sunkanmi Oluwadare, Faiza Hussein, Oliver Kronyo, Michael Asante</dc:creator>
    </item>
    <item>
      <title>Wireless Laser Power Transfer for Low-altitude Uncrewed Aerial Vehicle-assisted Internet of Things: Paradigms, Challenges, and Solutions</title>
      <link>https://arxiv.org/abs/2510.00477</link>
      <description>arXiv:2510.00477v2 Announce Type: replace 
Abstract: Low-altitude uncrewed aerial vehicles (UAVs) have become integral enablers for the Internet of Things (IoT) by offering enhanced coverage, improved connectivity and access to remote areas. A critical challenge limiting their operational capacity lies in the energy constraints of both aerial platforms and ground-based sensors. This paper explores WLPT as a transformative solution for sustainable energy provisioning in UAV-assisted IoT networks. We first systematically investigate the fundamental principles of WLPT and analysis the comparative advantages. Then, we introduce three operational paradigms for system integration, identify key challenges, and discuss corresponding potential solutions. In case study, we propose a multi-agent reinforcement learning framework to address the coordination and optimization challenges in WLPT-enabled UAV-assisted IoT data collection. Simulation results demonstrate that our framework significantly improves energy sustainability and data freshness. Finally, we discuss some future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00477v2</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengzhen Li, Likun Zhang, Chuang Zhang, Jiahui Li, Changyuan Zhao, Ruichen Zhang, Geng Sun</dc:creator>
    </item>
    <item>
      <title>Aerial Active STAR-RIS-assisted Satellite-Terrestrial Covert Communications</title>
      <link>https://arxiv.org/abs/2504.16146</link>
      <description>arXiv:2504.16146v2 Announce Type: replace-cross 
Abstract: An integration of satellites and terrestrial networks is crucial for enhancing performance of next generation communication systems. However, the networks are hindered by the long-distance path loss and security risks in dense urban environments. In this work, we propose a satellite-terrestrial covert communication system assisted by the aerial active simultaneous transmitting and reflecting reconfigurable intelligent surface (AASTAR-RIS) to improve the channel capacity while ensuring the transmission covertness. Specifically, we first derive the minimal detection error probability (DEP) under the worst condition that the Warden has perfect channel state information (CSI). Then, we formulate an AASTAR-RIS-assisted satellite-terrestrial covert communication optimization problem (ASCCOP) to maximize the sum of the fair channel capacity for all ground users while meeting the strict covert constraint, by jointly optimizing the trajectory and active beamforming of the AASTAR-RIS. Due to the challenges posed by the complex and high-dimensional state-action spaces as well as the need for efficient exploration in dynamic environments, we propose a generative deterministic policy gradient (GDPG) algorithm, which is a generative deep reinforcement learning (DRL) method to solve the ASCCOP. Concretely, the generative diffusion model (GDM) is utilized as the policy representation of the algorithm to enhance the exploration process by generating diverse and high-quality samples through a series of denoising steps. Moreover, we incorporate an action gradient mechanism to accomplish the policy improvement of the algorithm, which refines the better state-action pairs through the gradient ascent. Simulation results demonstrate that the proposed approach significantly outperforms important benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16146v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuang Zhang, Geng Sun, Jiahui Li, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Shiwen Mao, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving</title>
      <link>https://arxiv.org/abs/2506.09397</link>
      <description>arXiv:2506.09397v5 Announce Type: replace-cross 
Abstract: The growing gap between the increasing complexity of large language models (LLMs) and the limited computational budgets of edge devices poses a key challenge for efficient on-device inference, despite gradual improvements in hardware capabilities. Existing strategies, such as aggressive quantization, pruning, or remote inference, trade accuracy for efficiency or lead to substantial cost burdens. This position paper introduces a new framework that leverages speculative decoding, previously viewed primarily as a decoding acceleration technique for autoregressive generation of LLMs, as a promising approach specifically adapted for edge computing by orchestrating computation across heterogeneous devices. We propose \acronym, a framework that allows lightweight edge devices to draft multiple candidate tokens locally using diverse draft models, while a single, shared edge server verifies the tokens utilizing a more precise target model. To further increase the efficiency of verification, the edge server batch the diverse verification requests from devices. This approach supports device heterogeneity and reduces server-side memory footprint by sharing the same upstream target model across multiple devices. Our initial experiments with Jetson Orin Nano, Raspberry Pi 4B/5, and an edge server equipped with 4 Nvidia A100 GPUs indicate substantial benefits: 2.2 more system throughput, 2.8 more system capacity, and better cost efficiency, all without sacrificing model accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09397v5</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiangchen Li, Dimitrios Spatharakis, Saeid Ghafouri, Jiakun Fan, Hans Vandierendonck, Deepu John, Bo Ji, Dimitrios Nikolopoulos</dc:creator>
    </item>
    <item>
      <title>CardioForest: An Explainable Ensemble Learning Model for Automatic Wide QRS Complex Tachycardia Diagnosis from ECG</title>
      <link>https://arxiv.org/abs/2509.25804</link>
      <description>arXiv:2509.25804v2 Announce Type: replace-cross 
Abstract: This study aims to develop and evaluate an ensemble machine learning-based framework for the automatic detection of Wide QRS Complex Tachycardia (WCT) from ECG signals, emphasizing diagnostic accuracy and interpretability using Explainable AI. The proposed system integrates ensemble learning techniques, i.e., an optimized Random Forest known as CardioForest, and models like XGBoost and LightGBM. The models were trained and tested on ECG data from the publicly available MIMIC-IV dataset. The testing was carried out with the assistance of accuracy, balanced accuracy, precision, recall, F1 score, ROC-AUC, and error rate (RMSE, MAE) measures. In addition, SHAP (SHapley Additive exPlanations) was used to ascertain model explainability and clinical relevance. The CardioForest model performed best on all metrics, achieving a test accuracy of 95.19%, a balanced accuracy of 88.76%, a precision of 95.26%, a recall of 78.42%, and an ROC-AUC of 0.8886. SHAP analysis confirmed the model's ability to rank the most relevant ECG features, such as QRS duration, in accordance with clinical intuitions, thereby fostering trust and usability in clinical practice. The findings recognize CardioForest as an extremely dependable and interpretable WCT detection model. Being able to offer accurate predictions and transparency through explainability makes it a valuable tool to help cardiologists make timely and well-informed diagnoses, especially for high-stakes and emergency scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25804v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1101/2025.09.15.25335837</arxiv:DOI>
      <dc:creator>Vaskar Chakma, Ju Xiaolin, Heling Cao, Xue Feng, Ji Xiaodong, Pan Haiyan, Gao Zhan</dc:creator>
    </item>
  </channel>
</rss>
