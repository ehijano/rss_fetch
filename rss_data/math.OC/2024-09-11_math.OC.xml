<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Sep 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Simulation Models for Sustainable, Resilient, and Optimized Global Electric Vehicles Supply Chain</title>
      <link>https://arxiv.org/abs/2409.06004</link>
      <description>arXiv:2409.06004v1 Announce Type: new 
Abstract: While the transition to electric vehicles (EVs) is essential for decarbonizing the transportation system, the production and distribution of EVs entail substantial carbon costs. To ensure these emissions are accurately accounted for and effectively mitigated, this research introduces a digital twin of the EV's supply chain, addressing a critical gap in current EV life cycle analyses and providing the first comprehensive quantification of its environmental sustainability and resilience. This simulation model replicates global market dynamics and captures the complexity and uncertainty of the EV supply chain, enabling a thorough evaluation of its carbon footprint, sustainability, resilience, and what-if counterfactual scenarios for alternative market structures. The results reveal that average supply chain emissions range from 6.42 to 6.94 Kg e-CO2/KWh across different battery technologies. Additionally, the mass flow analysis shows unbalanced dependencies at all supply phases, with one geographical region significantly dominating the supply chain structure, highlighting the current supply chain architecture's low resilience and high vulnerability. In light of these findings, the study introduces an optimization model for hub and resource allocation configuration, effectively reducing vulnerability levels and supply chain emissions by up to 80%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06004v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tareq Alsaleh, Bilal Farooq</dc:creator>
    </item>
    <item>
      <title>Finite-time horizon, stopper vs. singular-controller games on the half-line</title>
      <link>https://arxiv.org/abs/2409.06049</link>
      <description>arXiv:2409.06049v1 Announce Type: new 
Abstract: We prove existence of a value for two-player zero-sum stopper vs. singular-controller games on finite-time horizon, when the underlying dynamics is one-dimensional, diffusive and bound to evolve in $[0,\infty)$. We show that the value is the maximal solution of a variational inequality with both obstacle and gradient constraint and satisfying a Dirichlet boundary condition at $[0,T)\times\{0\}$. Moreover, we obtain an optimal strategy for the stopper. Compared to the existing literature on this topic, we introduce new probabilistic methods to obtain gradient bounds and equi-continuity for the solutions of penalised partial differential equations (PDE) that approximate the variational inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06049v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Bovo, Tiziano De Angelis</dc:creator>
    </item>
    <item>
      <title>A Policy Iteration Method for Inverse Mean Field Games</title>
      <link>https://arxiv.org/abs/2409.06184</link>
      <description>arXiv:2409.06184v1 Announce Type: new 
Abstract: We propose a policy iteration method to solve an inverse problem for a mean-field game model, specifically to reconstruct the obstacle function in the game from the partial observation data of value functions, which represent the optimal costs for agents. The proposed approach decouples this complex inverse problem, which is an optimization problem constrained by a coupled nonlinear forward and backward PDE system in the MFG, into several iterations of solving linear PDEs and linear inverse problems. This method can also be viewed as a fixed-point iteration that simultaneously solves the MFG system and inversion. We further prove its linear rate of convergence. In addition, numerical examples in 1D and 2D, along with performance comparisons to a direct least-squares method, demonstrate the superior efficiency and accuracy of the proposed method for solving inverse MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06184v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Ren, Nathan Soedjak, Shanyin Tong</dc:creator>
    </item>
    <item>
      <title>Proceedings of the XIII International Workshop on Locational Analysis and Related Problems</title>
      <link>https://arxiv.org/abs/2409.06397</link>
      <description>arXiv:2409.06397v1 Announce Type: new 
Abstract: The topics of interest are location analysis and related problems. This includes location models, networks, transportation, logistics, exact and heuristic solution methods, and computational geometry, among many others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06397v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Baldomero-Naranjo, Ricardo G\'azquez, Miguel Mart\'inez-Ant\'on, Luisa I. Mart\'inez-Merino, Juan M. Mu\~noz-Oca\~na, Francisco Temprano, Alberto Torrej\'on, Carlos Valverde, Nicol\'as Zerega</dc:creator>
    </item>
    <item>
      <title>Functionally Constrained Algorithm Solves Convex Simple Bilevel Problems</title>
      <link>https://arxiv.org/abs/2409.06530</link>
      <description>arXiv:2409.06530v1 Announce Type: new 
Abstract: This paper studies simple bilevel problems, where a convex upper-level function is minimized over the optimal solutions of a convex lower-level problem. We first show the fundamental difficulty of simple bilevel problems, that the approximate optimal value of such problems is not obtainable by first-order zero-respecting algorithms. Then we follow recent works to pursue the weak approximate solutions. For this goal, we propose novel near-optimal methods for smooth and nonsmooth problems by reformulating them into functionally constrained problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06530v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huaqing Zhang, Lesi Chen, Jing Xu, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>Modelling Global Trade with Optimal Transport</title>
      <link>https://arxiv.org/abs/2409.06554</link>
      <description>arXiv:2409.06554v1 Announce Type: new 
Abstract: Global trade is shaped by a complex mix of factors beyond supply and demand, including tangible variables like transport costs and tariffs, as well as less quantifiable influences such as political and economic relations. Traditionally, economists model trade using gravity models, which rely on explicit covariates but often struggle to capture these subtler drivers of trade. In this work, we employ optimal transport and a deep neural network to learn a time-dependent cost function from data, without imposing a specific functional form. This approach consistently outperforms traditional gravity models in accuracy while providing natural uncertainty quantification. Applying our framework to global food and agricultural trade, we show that the global South suffered disproportionately from the war in Ukraine's impact on wheat markets. We also analyze the effects of free-trade agreements and trade disputes with China, as well as Brexit's impact on British trade with Europe, uncovering hidden patterns that trade volumes alone cannot reveal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06554v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Gaskin, Marie-Therese Wolfram, Andrew Duncan, Guven Demirel</dc:creator>
    </item>
    <item>
      <title>KANtrol: A Physics-Informed Kolmogorov-Arnold Network Framework for Solving Multi-Dimensional and Fractional Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2409.06649</link>
      <description>arXiv:2409.06649v1 Announce Type: new 
Abstract: In this paper, we introduce the KANtrol framework, which utilizes Kolmogorov-Arnold Networks (KANs) to solve optimal control problems involving continuous time variables. We explain how Gaussian quadrature can be employed to approximate the integral parts within the problem, particularly for integro-differential state equations. We also demonstrate how automatic differentiation is utilized to compute exact derivatives for integer-order dynamics, while for fractional derivatives of non-integer order, we employ matrix-vector product discretization within the KAN framework. We tackle multi-dimensional problems, including the optimal control of a 2D heat partial differential equation. The results of our simulations, which cover both forward and parameter identification problems, show that the KANtrol framework outperforms classical MLPs in terms of accuracy and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06649v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Afzal Aghaei</dc:creator>
    </item>
    <item>
      <title>Nonlinear Fenchel Conjugates</title>
      <link>https://arxiv.org/abs/2409.04492</link>
      <description>arXiv:2409.04492v1 Announce Type: cross 
Abstract: The classical concept of Fenchel conjugation is tailored to extended real-valued functions defined on linear spaces. In this paper we generalize this concept to functions defined on arbitrary sets that do not necessarily bear any structure at all. This generalization is obtained by replacing linear test functions by general nonlinear ones. Thus, we refer to it as nonlinear Fenchel conjugation. We investigate elementary properties including the Fenchel-Moreau biconjugation theorem. Whenever the domain exhibits additional structure, the restriction to a suitable subset of test functions allows further results to be derived. For example, on smooth manifolds, the restriction to smooth test functions allows us to state the Fenchel-Young theorem for the viscosity Fr\'echet subdifferential. On Lie groups, the restriction to real-valued group homomorphisms relates nonlinear Fenchel conjugation to infimal convolution and yields a notion of convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04492v1</guid>
      <category>math.FA</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anton Schiela, Roland Herzog, Ronny Bergmann</dc:creator>
    </item>
    <item>
      <title>Frequency range non-Lipschitz parametric optimization of a noise absorption</title>
      <link>https://arxiv.org/abs/2409.06292</link>
      <description>arXiv:2409.06292v1 Announce Type: cross 
Abstract: In the framework of the optimal wave energy absorption, we solve theoretically and numerically a parametric shape optimization problem to find the optimal distribution of absorbing material in the reflexive one defined by a characteristic function in the Robin-type boundary condition associated with the Helmholtz equation. Robin boundary condition can be given on a part or the all boundary of a bounded ($\epsilon$, $\infty$)-domain of R n . The geometry of the partially absorbing boundary is fixed, but allowed to be non-Lipschitz, for example, fractal. It is defined as the support of a d-upper regular measure with d $\in$]n -2, n[. Using the well-posedness properties of the model, for any fixed volume fraction of the absorbing material, we establish the existence of at least one optimal distribution minimizing the acoustical energy on a fixed frequency range of the relaxation problem. Thanks to the shape derivative of the energy functional, also existing for non-Lipschitz boundaries, we implement (in the two-dimensional case) the gradient descent method and find the optimal distribution with 50% of the absorbent material on a frequency range with better performances than the 100% absorbent boundary. The same type of performance is also obtained by the genetic method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06292v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frederic Magoules (MICS), Mathieu Menoux (MICS), Anna Rozanova-Pierrat (MICS)</dc:creator>
    </item>
    <item>
      <title>Geometry of the Space of Partitioned Networks: A Unified Theoretical and Computational Framework</title>
      <link>https://arxiv.org/abs/2409.06302</link>
      <description>arXiv:2409.06302v1 Announce Type: cross 
Abstract: Interactions and relations between objects may be pairwise or higher-order in nature, and so network-valued data are ubiquitous in the real world. The "space of networks", however, has a complex structure that cannot be adequately described using conventional statistical tools. We introduce a measure-theoretic formalism for modeling generalized network structures such as graphs, hypergraphs, or graphs whose nodes come with a partition into categorical classes. We then propose a metric that extends the Gromov-Wasserstein distance between graphs and the co-optimal transport distance between hypergraphs. We characterize the geometry of this space, thereby providing a unified theoretical treatment of generalized networks that encompasses the cases of pairwise, as well as higher-order, relations. In particular, we show that our metric is an Alexandrov space of non-negative curvature, and leverage this structure to define gradients for certain functionals commonly arising in geometric data analysis tasks. We extend our analysis to the setting where vertices have additional label information, and derive efficient computational schemes to use in practice. Equipped with these theoretical and computational tools, we demonstrate the utility of our framework in a suite of applications, including hypergraph alignment, clustering and dictionary learning from ensemble data, multi-omics alignment, as well as multiscale network alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06302v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephen Y Zhang, Fangfei Lan, Youjia Zhou, Agnese Barbensi, Michael P H Stumpf, Bei Wang, Tom Needham</dc:creator>
    </item>
    <item>
      <title>Modified Meta-Thompson Sampling for Linear Bandits and Its Bayes Regret Analysis</title>
      <link>https://arxiv.org/abs/2409.06329</link>
      <description>arXiv:2409.06329v1 Announce Type: cross 
Abstract: Meta-learning is characterized by its ability to learn how to learn, enabling the adaptation of learning strategies across different tasks. Recent research introduced the Meta-Thompson Sampling (Meta-TS), which meta-learns an unknown prior distribution sampled from a meta-prior by interacting with bandit instances drawn from it. However, its analysis was limited to Gaussian bandit. The contextual multi-armed bandit framework is an extension of the Gaussian Bandit, which challenges agent to utilize context vectors to predict the most valuable arms, optimally balancing exploration and exploitation to minimize regret over time. This paper introduces Meta-TSLB algorithm, a modified Meta-TS for linear contextual bandits. We theoretically analyze Meta-TSLB and derive an $ O\left( \left( m+\log \left( m \right) \right) \sqrt{n\log \left( n \right)} \right)$ bound on its Bayes regret, in which $m$ represents the number of bandit instances, and $n$ the number of rounds of Thompson Sampling. Additionally, our work complements the analysis of Meta-TS for linear contextual bandits. The performance of Meta-TSLB is evaluated experimentally under different settings, and we experimente and analyze the generalization capability of Meta-TSLB, showcasing its potential to adapt to unseen instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06329v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Li, Dong Liang, Zheng Xie</dc:creator>
    </item>
    <item>
      <title>Limit Order Book Simulation and Trade Evaluation with $K$-Nearest-Neighbor Resampling</title>
      <link>https://arxiv.org/abs/2409.06514</link>
      <description>arXiv:2409.06514v1 Announce Type: cross 
Abstract: In this paper, we show how $K$-nearest neighbor ($K$-NN) resampling, an off-policy evaluation method proposed in \cite{giegrich2023k}, can be applied to simulate limit order book (LOB) markets and how it can be used to evaluate and calibrate trading strategies. Using historical LOB data, we demonstrate that our simulation method is capable of recreating realistic LOB dynamics and that synthetic trading within the simulation leads to a market impact in line with the corresponding literature. Compared to other statistical LOB simulation methods, our algorithm has theoretical convergence guarantees under general conditions, does not require optimization, is easy to implement and computationally efficient. Furthermore, we show that in a benchmark comparison our method outperforms a deep learning-based algorithm for several key statistics. In the context of a LOB with pro-rata type matching, we demonstrate how our algorithm can calibrate the size of limit orders for a liquidation strategy. Finally, we describe how $K$-NN resampling can be modified for choices of higher dimensional state spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06514v1</guid>
      <category>q-fin.TR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Giegrich, Roel Oomen, Christoph Reisinger</dc:creator>
    </item>
    <item>
      <title>Deep Neural Networks: Multi-Classification and Universal Approximation</title>
      <link>https://arxiv.org/abs/2409.06555</link>
      <description>arXiv:2409.06555v1 Announce Type: cross 
Abstract: We demonstrate that a ReLU deep neural network with a width of $2$ and a depth of $2N+4M-1$ layers can achieve finite sample memorization for any dataset comprising $N$ elements in $\mathbb{R}^d$, where $d\ge1,$ and $M$ classes, thereby ensuring accurate classification.
  By modeling the neural network as a time-discrete nonlinear dynamical system, we interpret the memorization property as a problem of simultaneous or ensemble controllability. This problem is addressed by constructing the network parameters inductively and explicitly, bypassing the need for training or solving any optimization problem.
  Additionally, we establish that such a network can achieve universal approximation in $L^p(\Omega;\mathbb{R}_+)$, where $\Omega$ is a bounded subset of $\mathbb{R}^d$ and $p\in[1,\infty)$, using a ReLU deep neural network with a width of $d+1$. We also provide depth estimates for approximating $W^{1,p}$ functions and width estimates for approximating $L^p(\Omega;\mathbb{R}^m)$ for $m\geq1$. Our proofs are constructive, offering explicit values for the biases and weights involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06555v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mart\'in Hern\'andez, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Learn2Aggregate: Supervised Generation of Chv\'atal-Gomory Cuts Using Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2409.06559</link>
      <description>arXiv:2409.06559v1 Announce Type: cross 
Abstract: We present $\textit{Learn2Aggregate}$, a machine learning (ML) framework for optimizing the generation of Chv\'atal-Gomory (CG) cuts in mixed integer linear programming (MILP). The framework trains a graph neural network to classify useful constraints for aggregation in CG cut generation. The ML-driven CG separator selectively focuses on a small set of impactful constraints, improving runtimes without compromising the strength of the generated cuts. Key to our approach is the formulation of a constraint classification task which favours sparse aggregation of constraints, consistent with empirical findings. This, in conjunction with a careful constraint labeling scheme and a hybrid of deep learning and feature engineering, results in enhanced CG cut generation across five diverse MILP benchmarks. On the largest test sets, our method closes roughly $\textit{twice}$ as much of the integrality gap as the standard CG method while running 40$% faster. This performance improvement is due to our method eliminating 75% of the constraints prior to aggregation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06559v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnaud Deza, Elias B. Khalil, Zhenan Fan, Zirui Zhou, Yong Zhang</dc:creator>
    </item>
    <item>
      <title>Indirect Dynamic Negotiation in the Nash Demand Game</title>
      <link>https://arxiv.org/abs/2409.06566</link>
      <description>arXiv:2409.06566v1 Announce Type: cross 
Abstract: The paper addresses a problem of sequential bilateral bargaining with incomplete information. We proposed a decision model that helps agents to successfully bargain by performing indirect negotiation and learning the opponent's model. Methodologically the paper casts heuristically-motivated bargaining of a self-interested independent player into a framework of Bayesian learning and Markov decision processes. The special form of the reward implicitly motivates the players to negotiate indirectly, via closed-loop interaction. We illustrate the approach by applying our model to the Nash demand game, which is an abstract model of bargaining. The results indicate that the established negotiation: i) leads to coordinating players' actions; ii) results in maximising success rate of the game and iii) brings more individual profit to the players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06566v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatiana V. Guy, Jitka Homolov\'a, Aleksej Gaj</dc:creator>
    </item>
    <item>
      <title>Existence of augmented Lagrange multipliers: reduction to exact penalty functions and localization principle</title>
      <link>https://arxiv.org/abs/1802.03046</link>
      <description>arXiv:1802.03046v3 Announce Type: replace 
Abstract: In this article, we present new general results on existence of augmented Lagrange multipliers. We define a penalty function associated with an augmented Lagrangian, and prove that, under a certain growth assumption on the augmenting function, an augmented Lagrange multiplier exists if and only if this penalty function is exact. We also develop a new general approach to the study of augmented Lagrange multipliers called the localization principle. The localization principle allows one to study the local behaviour of the augmented Lagrangian near globally optimal solutions of the initial optimization problem in order to prove the existence of augmented Lagrange multipliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:1802.03046v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-017-1122-y</arxiv:DOI>
      <arxiv:journal_reference>Mathematical Programming, 166:1-2 (2017) 297-326</arxiv:journal_reference>
      <dc:creator>M. V. Dolgopolik</dc:creator>
    </item>
    <item>
      <title>Nonlinear Unknown Input Observability and Unknown Input Reconstruction: The General Analytical Solution</title>
      <link>https://arxiv.org/abs/2201.07610</link>
      <description>arXiv:2201.07610v5 Announce Type: replace 
Abstract: Observability is a fundamental structural property of any dynamic system and describes the possibility of reconstructing the state that characterizes the system from observing its inputs and outputs. Despite the huge effort made to study this property and to introduce analytical criteria able to check whether a dynamic system satisfies this property or not, there is no general analytical criterion to automatically check the state observability when the dynamics are also driven by unknown inputs. Here, we introduce the general analytical solution of this fundamental problem, often called the unknown input observability problem. This paper provides the general analytical solution of this problem, namely, it provides the systematic procedure, based on automatic computation (differentiation and matrix rank determination), that allows us to automatically check the state observability even in the presence of unknown inputs (Algorithm 6.1). A first solution of this problem was presented in the second part of the book: "Observability: A New Theory Based on the Group of Invariance" [45]. The solution presented by this paper completes the previous solution in [45]. In particular, the new solution exhaustively accounts for the systems that do not belong to the category of the systems that are "canonic with respect to their unknown inputs". The analytical derivations largely exploit several new concepts and analytical results introduced in [45]. Finally, as a simple consequence of the results here obtained, we also provide the answer to the problem of unknown input reconstruction which is intimately related to the problem of state observability. We illustrate the implementation of the new algorithm by studying the observability properties of a nonlinear system in the framework of visual-inertial sensor fusion, whose dynamics are driven by two unknown inputs and one known input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.07610v5</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.inffus.2022.03.004</arxiv:DOI>
      <arxiv:journal_reference>Journal of Information Fusion, Volume 85, September 2022, Pages 23-51</arxiv:journal_reference>
      <dc:creator>Agostino Martinelli</dc:creator>
    </item>
    <item>
      <title>Optimal Regularization for a Data Source</title>
      <link>https://arxiv.org/abs/2212.13597</link>
      <description>arXiv:2212.13597v4 Announce Type: replace 
Abstract: In optimization-based approaches to inverse problems and to statistical estimation, it is common to augment criteria that enforce data fidelity with a regularizer that promotes desired structural properties in the solution. The choice of a suitable regularizer is typically driven by a combination of prior domain information and computational considerations. Convex regularizers are attractive computationally but they are limited in the types of structure they can promote. On the other hand, nonconvex regularizers are more flexible in the forms of structure they can promote and they have showcased strong empirical performance in some applications, but they come with the computational challenge of solving the associated optimization problems. In this paper, we seek a systematic understanding of the power and the limitations of convex regularization by investigating the following questions: Given a distribution, what is the optimal regularizer for data drawn from the distribution? What properties of a data source govern whether the optimal regularizer is convex? We address these questions for the class of regularizers specified by functionals that are continuous, positively homogeneous, and positive away from the origin. We say that a regularizer is optimal for a data distribution if the Gibbs density with energy given by the regularizer maximizes the population likelihood (or equivalently, minimizes cross-entropy loss) over all regularizer-induced Gibbs densities. As the regularizers we consider are in one-to-one correspondence with star bodies, we leverage dual Brunn-Minkowski theory to show that a radial function derived from a data distribution is akin to a ``computational sufficient statistic'' as it is the key quantity for identifying optimal regularizers and for assessing the amenability of a data source to convex regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.13597v4</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar Leong, Eliza O'Reilly, Yong Sheng Soh, Venkat Chandrasekaran</dc:creator>
    </item>
    <item>
      <title>Further Development in Convex Conic Reformulation of Geometric Nonconvex Conic Optimization Problems</title>
      <link>https://arxiv.org/abs/2308.05922</link>
      <description>arXiv:2308.05922v2 Announce Type: replace 
Abstract: A geometric nonconvex conic optimization problem (COP) was recently proposed by Kim, Kojima and Toh as a unified framework for convex conic reformulation of a class of quadratic optimization problems and polynomial optimization problems. The nonconvex COP minimizes a linear function over the intersection of a nonconvex cone $\mathbb{K}$, a convex subcone $\mathbb{J}$ of the convex hull co$\mathbb{K}$ of $\mathbb{K}$, and an affine hyperplane with a normal vector $H$. Under the assumption co$(\mathbb{K} \cap \mathbb{J}) = \mathbb{J}$, the original nonconvex COP in their paper was shown to be equivalently formulated as a convex conic program by replacing the constraint set with the intersection of $\mathbb{J}$ and the affine hyperplane. This paper further studies some remaining issues, not fully investigated there, such as the key assumption co$(\mathbb{K} \cap \mathbb{J}) = \mathbb{J}$ in the framework. More specifically, we provide three sets of necessary-sufficient conditions for the assumption. As an application, we propose a new wide class of quadratically constrained quadratic programs with multiple nonconvex equality and inequality constraints that can be solved exactly by their semidefinite relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05922v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naohiko Arima, Sunyoung Kim, Masakazu Kojima</dc:creator>
    </item>
    <item>
      <title>Generalized open-loop Nash equilibria in linear-quadratic difference games with coupled-affine inequality constraints</title>
      <link>https://arxiv.org/abs/2310.01895</link>
      <description>arXiv:2310.01895v4 Announce Type: replace 
Abstract: In this note, we study a class of deterministic finite-horizon linear-quadratic difference games with coupled affine inequality constraints involving both state and control variables. We show that the necessary conditions for the existence of generalized open-loop Nash equilibria in this game class lead to two strongly coupled discrete-time linear complementarity systems. Subsequently, we derive sufficient conditions by establishing an equivalence between the solutions of these systems and convexity of the players' objective functions. These conditions are then reformulated as a solution to a linear complementarity problem, providing a numerical method to compute these equilibria. We illustrate our results using a network flow game with constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01895v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Partha Sarathi Mohapatra, Puduru Viswanadha Reddy</dc:creator>
    </item>
    <item>
      <title>Relative entropy-regularized robust optimal order execution</title>
      <link>https://arxiv.org/abs/2311.06476</link>
      <description>arXiv:2311.06476v2 Announce Type: replace 
Abstract: The problem of order execution is cast as a relative entropy-regularized robust optimal control problem in this article. The order execution agent's goal is to maximize an objective functional associated with his profit-and-loss of trading and simultaneously minimize the execution risk and the market's liquidity and uncertainty. We model the market's liquidity and uncertainty by the principle of least relative entropy associated with the market volume. The problem of order execution is made into a relative entropy-regularized stochastic differential game. Standard argument of dynamic programming yields that the value function of the differential game satisfies a relative entropy-regularized Hamilton-Jacobi-Isaacs (rHJI) equation. Under the assumptions of linear-quadratic model with Gaussian prior, the rHJI equation reduces to a system of Riccati and linear differential equations. Further imposing constancy of the corresponding coefficients, the system of differential equations can be solved in closed form, resulting in analytical expressions for optimal strategy and trajectory as well as the posterior distribution of market volume. Numerical examples illustrating the optimal strategies and the comparisons with conventional trading strategies are conducted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06476v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meng Wang, Tai-Ho Wang</dc:creator>
    </item>
    <item>
      <title>On a Generalization of Wasserstein Distance and the Beckmann Problem to Connection Graphs</title>
      <link>https://arxiv.org/abs/2312.10295</link>
      <description>arXiv:2312.10295v2 Announce Type: replace 
Abstract: In this paper, we explore the untapped intersection of the graph connection Laplacian and discrete optimal transport to propose a novel framework for studying optimal parallel transport between vector fields on graphs. Our study establishes feasibility conditions for the resulting convex optimization problem on connection graphs. Furthermore, we establish strong duality for the so-called connection Beckmann problem, and extend our analysis to encompass strong duality and duality correspondence for a quadratically regularized variant. Then, we implement the model across a selection of several examples leveraging both synthetic and real-world datasets drawn from computer graphics and meteorology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10295v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sawyer Robertson, Dhruv Kohli, Gal Mishne, Alexander Cloninger</dc:creator>
    </item>
    <item>
      <title>An inexact infeasible arc-search interior-point method for linear programming problems</title>
      <link>https://arxiv.org/abs/2403.18155</link>
      <description>arXiv:2403.18155v2 Announce Type: replace 
Abstract: Inexact interior-point methods (IPMs) are a type of interior-point methods that inexactly solve the linear equation system for obtaining the search direction. On the other hand, arc-search IPMs approximate the central path with an ellipsoidal arc obtained by solving two linear equation systems in each iteration, while conventional line-search
  IPMs solve one linear system. Therefore, the improvement due to the inexact solutions of the linear equation systems can be more beneficial in arc-search IPMs than conventional IPMs. In this paper, we propose an inexact infeasible arc-search interior-point method. We establish that the proposed method is a polynomial-time algorithm through its convergence analysis. The numerical experiments for the large benchmark problems show that the proposed method using the conjugate gradient method as the inexact linear system solver can reduce both of the number of iterations and the computation time compared to the existing inexact IPM due to the reduction in computational complexity by the arc-search. Andmore, it can reduce the computation time compared to the existing exact IPMs because the dependence of the computational complexity on the dimension $n$ of the coefficient matrix is smaller for the conjugate gradient method than for the Cholesky factorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18155v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Einosuke Iida, Makoto Yamashita</dc:creator>
    </item>
    <item>
      <title>Approximately Gaussian Replicator Flows: Nonconvex Optimization as a Nash-Convergent Evolutionary Game</title>
      <link>https://arxiv.org/abs/2406.19529</link>
      <description>arXiv:2406.19529v2 Announce Type: replace 
Abstract: This work leverages tools from evolutionary game theory to solve unconstrained nonconvex optimization problems. Specifically, we lift such a problem to an optimization over probability measures, whose minimizers exactly correspond to the Nash equilibria of a particular population game. To algorithmically solve for such Nash equilibria, we introduce approximately Gaussian replicator flows (AGRFs) as a tractable alternative to simulating the corresponding infinite-dimensional replicator dynamics. Our proposed AGRF dynamics can be integrated using off-the-shelf ODE solvers when considering objectives with closed-form integrals against a Gaussian measure. We theoretically analyze AGRF dynamics by explicitly characterizing their trajectories and stability on quadratic objective functions, in addition to analyzing their descent properties. Our methods are supported by illustrative experiments on a range of canonical nonconvex optimization benchmark functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19529v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendon G. Anderson, Samuel Pfrommer, Somayeh Sojoudi</dc:creator>
    </item>
    <item>
      <title>Restarted Halpern PDHG for Linear Programming</title>
      <link>https://arxiv.org/abs/2407.16144</link>
      <description>arXiv:2407.16144v2 Announce Type: replace 
Abstract: In this paper, we propose and analyze a new matrix-free primal-dual algorithm, called restarted Halpern primal-dual hybrid gradient (rHPDHG), for solving linear programming (LP). We show that rHPDHG can achieve optimal accelerated linear convergence on feasible and bounded LP. Furthermore, we present a refined analysis that demonstrates an accelerated two-stage convergence of rHPDHG over the vanilla PDHG with an improved complexity for identification and an accelerated eventual linear convergence that does not depend on the conservative global Hoffman constant. Regarding infeasible LP, we show that rHPDHG can recover infeasibility certificates with an accelerated linear rate, improving the previous convergence rates. Furthermore, we discuss an extension of rHPDHG by adding reflection operation (which is dubbed as $\mathrm{r^2HPDHG}$), and demonstrate that it shares all theoretical guarantees of rHPDHG with an additional factor of 2 speedup in the complexity bound. Lastly, we build up a GPU-based LP solver using rHPDHG/$\mathrm{r^2HPDHG}$, and the experiments on 383 MIPLIB instances showcase an improved numerical performance compared cuPDLP.jl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16144v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haihao Lu, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>Inverse Particle Filter</title>
      <link>https://arxiv.org/abs/2407.16623</link>
      <description>arXiv:2407.16623v2 Announce Type: replace 
Abstract: In cognitive systems, recent emphasis has been placed on studying the cognitive processes of the subject whose behavior was the primary focus of the system's cognitive response. This approach, known as inverse cognition, arises in counter-adversarial applications and has motivated the development of inverse Bayesian filters. In this context, a cognitive adversary, such as a radar, uses a forward Bayesian filter to track its target of interest. An inverse filter is then employed to infer the adversary's estimate of the target's or defender's state. Previous studies have addressed this inverse filtering problem by introducing methods like the inverse Kalman filter (I-KF), inverse extended KF (I-EKF), and inverse unscented KF (I-UKF). However, these filters typically assume additive Gaussian noise models and/or rely on local approximations of non-linear dynamics at the state estimates, limiting their practical application. In contrast, this paper adopts a global filtering approach and presents the development of an inverse particle filter (I-PF). The particle filter framework employs Monte Carlo (MC) methods to approximate arbitrary posterior distributions. Moreover, under mild system-level conditions, the proposed I-PF demonstrates convergence to the optimal inverse filter. Additionally, we propose the differentiable I-PF to address scenarios where system information is unknown to the defender. Using the recursive Cramer-Rao lower bound and non-credibility index (NCI), our numerical experiments for different systems demonstrate the estimation performance and time complexity of the proposed filter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16623v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Himali Singh, Arpan Chattopadhyay, Kumar Vijay Mishra</dc:creator>
    </item>
    <item>
      <title>Integer programs with bounded subdeterminants and two nonzeros per row</title>
      <link>https://arxiv.org/abs/2106.05947</link>
      <description>arXiv:2106.05947v4 Announce Type: replace-cross 
Abstract: We give a strongly polynomial-time algorithm for integer linear programs defined by integer coefficient matrices whose subdeterminants are bounded by a constant and that contain at most two nonzero entries in each row. The core of our approach is the first polynomial-time algorithm for the weighted stable set problem on graphs that do not contain more than $k$ vertex-disjoint odd cycles, where $k$ is any constant. Previously, polynomial-time algorithms were only known for $k=0$ (bipartite graphs) and for $k=1$.
  We observe that integer linear programs defined by coefficient matrices with bounded subdeterminants and two nonzeros per column can be also solved in strongly polynomial-time, using a reduction to $b$-matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.05947v4</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Fiorini, Gwena\"el Joret, Stefan Weltge, Yelena Yuditsky</dc:creator>
    </item>
    <item>
      <title>Efficient Private SCO for Heavy-Tailed Data via Averaged Clipping</title>
      <link>https://arxiv.org/abs/2206.13011</link>
      <description>arXiv:2206.13011v4 Announce Type: replace-cross 
Abstract: We consider stochastic convex optimization for heavy-tailed data with the guarantee of being differentially private (DP). Most prior works on differentially private stochastic convex optimization for heavy-tailed data are either restricted to gradient descent (GD) or performed multi-times clipping on stochastic gradient descent (SGD), which is inefficient for large-scale problems. In this paper, we consider a one-time clipping strategy and provide principled analyses of its bias and private mean estimation. We establish new convergence results and improved complexity bounds for the proposed algorithm called AClipped-dpSGD for constrained and unconstrained convex problems. We also extend our convergent analysis to the strongly convex case and non-smooth case (which works for generalized smooth objectives with H$\ddot{\text{o}}$lder-continuous gradients). All the above results are guaranteed with a high probability for heavy-tailed data. Numerical experiments are conducted to justify the theoretical improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.13011v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenhan Jin, Kaiwen Zhou, Bo Han, James Cheng, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>On {\L}ojasiewicz Inequalities and the Effective Putinar's Positivstellensatz</title>
      <link>https://arxiv.org/abs/2212.09551</link>
      <description>arXiv:2212.09551v2 Announce Type: replace-cross 
Abstract: The representation of positive polynomials on a semi-algebraic set in terms of sums of squares is a central question in real algebraic geometry, which the Positivstellensatz answers. In this paper, we study the effective Putinar's Positivestellensatz on a compact basic semi-algebraic set $S$ and provide a new proof and new improved bounds on the degree of the representation of positive polynomials. These new bounds involve a parameter $\epsilon$ measuring the non-vanishing of the positive function, the constant $\mathfrak{c}$ and exponent $L$ of a {\L}ojasiewicz inequality for the semi-algebraic distance function associated to the inequalities $\mathbf{g} = (g_1, \dots , g_r)$ defining $S$. They are polynomial in $\mathfrak{c}$ and $\epsilon^{-1}$ with an exponent depending only on $L$. We analyse in details the {\L}ojasiewicz inequality when the defining inequalities $\mathbf g$ satisfy the Constraint Qualification Condition. We show that, in this case, the {\L}ojasiewicz exponent $L$ is $1$ and we relate the {\L}ojasiewicz constant $\mathfrak{c}$ with the distance of $\mathbf g$ to the set of singular systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.09551v2</guid>
      <category>math.AC</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jalgebra.2024.08.022</arxiv:DOI>
      <dc:creator>Lorenzo Baldi (AROMATH, PolSys), Bernard Mourrain (AROMATH), Adam Parusinski (LJAD)</dc:creator>
    </item>
    <item>
      <title>Optimal Differentially Private Model Training with Public Data</title>
      <link>https://arxiv.org/abs/2306.15056</link>
      <description>arXiv:2306.15056v3 Announce Type: replace-cross 
Abstract: Differential privacy (DP) ensures that training a machine learning model does not leak private data. In practice, we may have access to auxiliary public data that is free of privacy concerns. In this work, we assume access to a given amount of public data and settle the following fundamental open questions: 1. What is the optimal (worst-case) error of a DP model trained over a private data set while having access to side public data? 2. How can we harness public data to improve DP model training in practice? We consider these questions in both the local and central models of pure and approximate DP. To answer the first question, we prove tight (up to log factors) lower and upper bounds that characterize the optimal error rates of three fundamental problems: mean estimation, empirical risk minimization, and stochastic convex optimization. We show that the optimal error rates can be attained (up to log factors) by either discarding private data and training a public model, or treating public data like it is private and using an optimal DP algorithm. To address the second question, we develop novel algorithms that are "even more optimal" (i.e. better constants) than the asymptotically optimal approaches described above. For local DP mean estimation, our algorithm is optimal including constants. Empirically, our algorithms show benefits over the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15056v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Lowy, Zeman Li, Tianjian Huang, Meisam Razaviyayn</dc:creator>
    </item>
    <item>
      <title>Discretization of Total Variation in Optimization with Integrality Constraints</title>
      <link>https://arxiv.org/abs/2403.08346</link>
      <description>arXiv:2403.08346v2 Announce Type: replace-cross 
Abstract: We introduce discretizations of infinite-dimensional optimization problems with total variation regularization and integrality constraints on the optimization variables. We advance the discretization of the dual formulation of the total variation term with Raviart--Thomas functions which is known from literature for certain convex problems. Since we have an integrality constraint, the previous analysis from Caillaud and Chambolle [10] does not hold anymore. Even weaker $\Gamma$-convergence results do not hold anymore because the recovery sequences generally need to attain non-integer values to recover the total variation of the limit function. We solve this issue by introducing a discretization of the input functions on an embedded, finer mesh. A superlinear coupling of the mesh sizes implies an averaging on the coarser mesh of the Raviart--Thomas ansatz, which enables to recover the total variation of integer-valued limit functions with integer-valued discretized input functions. Moreover, we are able to estimate the discretized total variation of the recovery sequence by the total variation of its limit and an error depending on the mesh size ratio. For the discretized optimization problems, we additionally add a constraint that vanishes in the limit and enforces compactness of the sequence of minimizers, which yields their convergence to a minimizer of the original problem. This constraint contains a degree of freedom whose admissible range is determined. Its choice may have a strong impact on the solutions in practice as we demonstrate with an example from imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08346v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annika Schiemann, Paul Manns</dc:creator>
    </item>
    <item>
      <title>Hybrid integrator-gain system based integral resonant controllers for negative imaginary systems</title>
      <link>https://arxiv.org/abs/2403.15140</link>
      <description>arXiv:2403.15140v2 Announce Type: replace-cross 
Abstract: We introduce a hybrid control system called a hybrid integrator-gain system (HIGS) based integral resonant controller (IRC) to stabilize negative imaginary (NI) systems. A HIGS-based IRC has a similar structure to an IRC, with the integrator replaced by a HIGS. We show that a HIGS-based IRC is an NI system. Also, for a SISO NI system with a minimal realization, we show there exists a HIGS-based IRC such that their closed-loop interconnection is asymptotically stable. Also, we propose a proportional-integral-double-integral resonant controller and a HIGS-based proportional-integral-double-integral resonant controller, and we show that both of them can be applied to asymptotically stabilize an NI system. An example is provided to illustrate the proposed results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15140v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanghong Shi, Ian R. Petersen</dc:creator>
    </item>
    <item>
      <title>Adaptive Economic Model Predictive Control for linear systems with performance guarantees</title>
      <link>https://arxiv.org/abs/2403.18398</link>
      <description>arXiv:2403.18398v2 Announce Type: replace-cross 
Abstract: We present a model predictive control (MPC) formulation to directly optimize economic criteria for linear constrained systems subject to disturbances and uncertain model parameters. The proposed formulation combines a certainty equivalent economic MPC with a simple least-squares parameter adaptation. For the resulting adaptive economic MPC scheme, we derive strong asymptotic and transient performance guarantees. We provide a numerical example involving building temperature control and demonstrate performance benefits of online parameter adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18398v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian Degner, Raffaele Soloperto, Melanie N. Zeilinger, John Lygeros, Johannes K\"ohler</dc:creator>
    </item>
    <item>
      <title>LibMOON: A Gradient-based MultiObjective OptimizatioN Library in PyTorch</title>
      <link>https://arxiv.org/abs/2409.02969</link>
      <description>arXiv:2409.02969v2 Announce Type: replace-cross 
Abstract: Multiobjective optimization problems (MOPs) are prevalent in machine learning, with applications in multi-task learning, learning under fairness or robustness constraints, etc. Instead of reducing multiple objective functions into a scalar objective, MOPs aim to optimize for the so-called Pareto optimality or Pareto set learning, which involves optimizing more than one objective function simultaneously, over models with millions of parameters. Existing benchmark libraries for MOPs mainly focus on evolutionary algorithms, most of which are zeroth-order methods that do not effectively utilize higher-order information from objectives and cannot scale to large-scale models with millions of parameters. In light of the above gap, this paper introduces LibMOON, the first multiobjective optimization library that supports state-of-the-art gradient-based methods, provides a fair benchmark, and is open-sourced for the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02969v2</guid>
      <category>cs.MS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyuan Zhang, Liang Zhao, Yingying Yu, Xi Lin, Zhenkun Wang, Han Zhao, Qingfu Zhang</dc:creator>
    </item>
  </channel>
</rss>
