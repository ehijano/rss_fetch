<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Feb 2025 02:52:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Empirical likelihood approach for high-dimensional moment restrictions with dependent data</title>
      <link>https://arxiv.org/abs/2502.18970</link>
      <description>arXiv:2502.18970v1 Announce Type: new 
Abstract: Economic and financial models -- such as vector autoregressions, local projections, and multivariate volatility models -- feature complex dynamic interactions and spillovers across many time series. These models can be integrated into a unified framework, with high-dimensional parameters identified by moment conditions. As the number of parameters and moment conditions may surpass the sample size, we propose adding a double penalty to the empirical likelihood criterion to induce sparsity and facilitate dimension reduction. Notably, we utilize a marginal empirical likelihood approach despite temporal dependence in the data. Under regularity conditions, we provide asymptotic guarantees for our method, making it an attractive option for estimating large-scale multivariate time series models. We demonstrate the versatility of our procedure through extensive Monte Carlo simulations and three empirical applications, including analyses of US sectoral inflation rates, fiscal multipliers, and volatility spillover in China's banking sector.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18970v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyuan Chang, Qiao Hu, Zhentao Shi, Jia Zhang</dc:creator>
    </item>
    <item>
      <title>Forecasting macroeconomic data with Bayesian VARs: Sparse or dense? It depends!</title>
      <link>https://arxiv.org/abs/2206.04902</link>
      <description>arXiv:2206.04902v5 Announce Type: replace 
Abstract: Vector autogressions (VARs) are widely applied when it comes to modeling and forecasting macroeconomic variables. In high dimensions, however, they are prone to overfitting. Bayesian methods, more concretely shrinkage priors, have shown to be successful in improving prediction performance. In the present paper, we introduce the semi-global framework, in which we replace the traditional global shrinkage parameter with group-specific shrinkage parameters. We show how this framework can be applied to various shrinkage priors, such as global-local priors and stochastic search variable selection priors. We demonstrate the virtues of the proposed framework in an extensive simulation study and in an empirical application forecasting data of the US economy. Further, we shed more light on the ongoing ``Illusion of Sparsity'' debate, finding that forecasting performances under sparse/dense priors vary across evaluated economic variables and across time frames. Dynamic model averaging, however, can combine the merits of both worlds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.04902v5</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ijforecast.2025.02.001</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Forecasting (2025)</arxiv:journal_reference>
      <dc:creator>Luis Gruber, Gregor Kastner</dc:creator>
    </item>
    <item>
      <title>Seemingly unrelated Bayesian additive regression trees for cost-effectiveness analyses in healthcare</title>
      <link>https://arxiv.org/abs/2404.02228</link>
      <description>arXiv:2404.02228v3 Announce Type: replace-cross 
Abstract: In recent years, theoretical results and simulation evidence have shown Bayesian additive regression trees to be a highly-effective method for nonparametric regression. Motivated by cost-effectiveness analyses in health economics, where interest lies in jointly modelling the costs of healthcare treatments and the associated health-related quality of life experienced by a patient, we propose a multivariate extension of BART which is applicable in regression analyses with several dependent outcome variables. Our framework allows for continuous or binary outcomes and overcomes some key limitations of existing multivariate BART models by allowing each individual response to be associated with different ensembles of trees, while still handling dependencies between the outcomes. In the case of continuous outcomes, our model is essentially a nonparametric version of seemingly unrelated regression. Likewise, our proposal for binary outcomes is a nonparametric generalisation of the multivariate probit model. We give suggestions for easily interpretable prior distributions, which allow specification of both informative and uninformative priors. We provide detailed discussions of MCMC sampling methods to conduct posterior inference. Our methods are implemented in the R package "subart". We showcase their performance through extensive simulation experiments and an application to an empirical case study from health economics. By also accommodating propensity scores in a manner befitting a causal analysis, we find substantial evidence for a novel trauma care intervention's cost-effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02228v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Esser, Mateus Maia, Andrew C. Parnell, Judith Bosmans, Hanneke van Dongen, Thomas Klausch, Keefe Murphy</dc:creator>
    </item>
  </channel>
</rss>
