<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 May 2025 02:29:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Notes on the discretization of TV-norm regularized inverse potential problems</title>
      <link>https://arxiv.org/abs/2505.00710</link>
      <description>arXiv:2505.00710v1 Announce Type: new 
Abstract: We describe a method to discretize optimization problems arising in the regularization of linear inverse problem having compact forward operator defined on 3-D valed measures, compactly supported on a fixed set. The criterion is a quadratic residual attached to the data, with an additive penalization of the total variation of the measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00710v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L Baratchart (FACTAS), D P Hardin, C Villalobos-Guill\'en</dc:creator>
    </item>
    <item>
      <title>Generalized $\theta$-Parametric Metric Spaces: Fixed Point Theorems and Applications to Fractional Economic Models</title>
      <link>https://arxiv.org/abs/2505.00722</link>
      <description>arXiv:2505.00722v2 Announce Type: new 
Abstract: The objective of this manuscript is to introduce and develop the concept of a generalized $\theta$-parametric metric space-a novel extension that enriches the modern metric fixed point theory. We study of its fundamental properties, including convergence and Cauchy sequences that establishes a solid theoretical foundation. A significant highlight of our work is the formulation of Suzuki-type fixed point theorem within this framework which extends classical results in a meaningful way. To demonstrate the depth and applicability of our findings, we construct non-trivial examples that illustrate the behavior of key concepts. Moreover, as a practical application, we apply our main theorem to analyze an economic growth model, demonstrating its utility in solving fractional differential equations that arise in dynamic economic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00722v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishikta Das, Hemanta Kalita, Mohammad Sajid, T. Bag</dc:creator>
    </item>
    <item>
      <title>Optimal Blackjack Betting Strategies Through Dynamic Programming and Expected Utility Theory</title>
      <link>https://arxiv.org/abs/2505.00724</link>
      <description>arXiv:2505.00724v1 Announce Type: new 
Abstract: This study presents a rigorous mathematical approach to the optimization of round and betting policies in Blackjack, using Markov Decision Processes (MDP) and Expected Utility Theory. The analysis considers a direct confrontation between a player and the dealer, simplifying the dynamics of the game. The objective is to develop optimal strategies that maximize expected utility for risk profiles defined by constant (CRRA) and absolute (CARA) aversion utility functions. Dynamic programming algorithms are implemented to estimate optimal gambling and betting policies with different levels of complexity. The evaluation is performed through simulations, analyzing histograms of final returns. The results indicate that the advantage of applying optimized round policies over the "basic strategy" is slight, highlighting the efficiency of the last one. In addition, betting strategies based on the exact composition of the deck slightly outperform the Hi-Lo counting system, showing its effectiveness. The optimized strategies include versions suitable for mental use in physical environments and more complex ones requiring computational processing. Although the computed strategies approximate the theoretical optimal performance, this study is limited to a specific configuration of rules. As a future challenge, it is proposed to explore strategies under other game configurations, considering additional players or deeper penetration of the deck, which could pose new technical challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00724v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Bordeu, Javier Castro</dc:creator>
    </item>
    <item>
      <title>Higher order necessary conditions for optimal controls not ranging in the interior</title>
      <link>https://arxiv.org/abs/2505.00790</link>
      <description>arXiv:2505.00790v1 Announce Type: new 
Abstract: Goh's and Legendre-Clebsch necessary conditions for optimal controls of affine-control systems are usually established under the hypothesis that the minimizing control lies in the interior of the control set $U$. In this paper we investigate the possibility of establishing Goh's and Legendre-Clebsch necessary conditions without this assumption, so that even control sets with empty interiors or optimal controls touching the boundary of $U$ can be taken into consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00790v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Angrisani, Franco Rampazzo</dc:creator>
    </item>
    <item>
      <title>Platoon Coordination and Leader Selection in Mixed Transportation Systems via Dynamic Programming</title>
      <link>https://arxiv.org/abs/2505.00847</link>
      <description>arXiv:2505.00847v1 Announce Type: new 
Abstract: With the growing penetration of electric trucks, freight transportation is transitioning toward a mixed system comprising both fuel-powered and electric trucks. Enhancing truck platoon formation in such a heterogeneous environment presents new challenges. This paper investigates the hub-based platoon coordination problem in a mixed truck fleet, where the focus is to optimize the trucks' waiting times, charging amounts for electric trucks, and platoon leader assignments. The objective is to maximize the overall platoon revenue of the fleet while accounting for the associated waiting and charging costs. We formulate the problem as a mixed-integer linear program and present a dynamic programming approach to compute its sub-optimal solution efficiently. The proposed method operates in polynomial time, ensuring scalable computational efficiency. Simulation studies involving 1,000 trucks traveling between two hubs in Sweden demonstrate the effectiveness and scalability of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00847v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Wang, Ting Bai, Andreas A. Malikopoulos</dc:creator>
    </item>
    <item>
      <title>Global controllability properties of linear control systems</title>
      <link>https://arxiv.org/abs/2505.01063</link>
      <description>arXiv:2505.01063v1 Announce Type: new 
Abstract: For linear control systems with bounded control range, the state space is compactified using the Poincar\'e sphere. The linearization of the induced control flow allows the construction of invariant manifolds on the sphere and of corresponding manifolds in the state space of the linear control system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01063v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fritz Colonius, Alexandre J. Santana</dc:creator>
    </item>
    <item>
      <title>Screening Cut Generation for Sparse Ridge Regression</title>
      <link>https://arxiv.org/abs/2505.01082</link>
      <description>arXiv:2505.01082v1 Announce Type: new 
Abstract: Sparse ridge regression is widely utilized in modern data analysis and machine learning. However, computing globally optimal solutions for sparse ridge regression is challenging, particularly when samples are arbitrarily given or generated under weak modeling assumptions. This paper proposes a novel cut-generation method, Screening Cut Generation (SCG), to eliminate non-optimal solutions for arbitrarily given samples. In contrast to recent safe variable screening approaches, SCG offers superior screening capability by identifying whether a specific $\{\pm 1\}$ combination of multiple features (binaries) lies in the set of optimal solutions. This identification is based on a convex relaxation solution rather than directly solving the original sparse ridge regression. Hence, the cuts generated by SCG can be applied in the pre-processing step of branch-and-bound and its variants to construct safe outer approximations of the optimal solution set. Numerical experiments are reported to validate the theoretical results and demonstrate the efficiency of SCG, particularly in hard real instances and synthetic instances with high dimensions, low ridge regularization parameters, or challenging modeling assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01082v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haozhe Tan, Guanyi Wang</dc:creator>
    </item>
    <item>
      <title>Convergence of linesearch-based generalized conditional gradient methods without smoothness assumptions</title>
      <link>https://arxiv.org/abs/2505.01092</link>
      <description>arXiv:2505.01092v1 Announce Type: new 
Abstract: The generalized conditional gradient method is a popular algorithm for solving composite problems whose objective function is the sum of a smooth function and a nonsmooth convex function. Many convergence analyses of the algorithm rely on smoothness assumptions, such as the Lipschitz continuity of the gradient of the smooth part. This paper provides convergence results of linesearch-based generalized conditional gradient methods without smoothness assumptions. In particular, we show that a parameter-free variant, which automatically adapts to the H\"older exponent, guarantees convergence even when the gradient of the smooth part of the objective is not H\"older continuous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01092v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shotaro Yagishita</dc:creator>
    </item>
    <item>
      <title>Discovering Mechanistic Causality from Time Series: A Behavioral-System Approach</title>
      <link>https://arxiv.org/abs/2505.01226</link>
      <description>arXiv:2505.01226v1 Announce Type: new 
Abstract: Identifying ``true causality'' is a fundamental challenge in complex systems research. Widely adopted methods, like the Granger causality test, capture statistical dependencies between variables rather than genuine driver-response mechanisms. This critical gap stems from the absence of mathematical tools that reliably reconstruct underlying system dynamics from observational time-series data. In this paper, we introduce a new control-based method for causality discovery through the behavior-system theory, which represents dynamical systems via trajectory spaces and has been widely used in data-driven control. Our core contribution is the \textbf{B}ehavior-\textbf{e}nabled \textbf{Caus}ality test (the BeCaus test), which transforms causality discovery into solving fictitious control problems. By exploiting the intrinsic asymmetry between system inputs and outputs, the proposed method operationalizes our conceptualization of mechanistic causality: variable $X$ is a cause of $Y$ if $X$ (partially) drives the evolution of $Y$. We establish conditions for linear time-invariant systems to be causality-discoverable, i.e., conditions for the BeCaus test to distinguish four basic causal structures (independence, full causality, partial causality, and latent-common-cause relation). Notably, our approach accommodates open systems with unobserved inputs. Moreover, an exploratory case study indicates the new method's potential extensibility to nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01226v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingzhu Liu, Shengyuan Huang, Zhongkui Li, Xiaoguang Yang, Wenjun Mei</dc:creator>
    </item>
    <item>
      <title>Asymptotic Linear Convergence of ADMM for Isotropic TV Norm Compressed Sensing</title>
      <link>https://arxiv.org/abs/2505.01240</link>
      <description>arXiv:2505.01240v1 Announce Type: new 
Abstract: We prove an explicit local linear rate for ADMM solving the isotropic Total Variation (TV) norm compressed sensing problem in multiple dimensions, by analyzing the auxiliary variable in the equivalent Douglas-Rachford splitting on a dual problem. Numerical verification on large 3D problems and real MRI data will be shown. Though the proven rate is not sharp, it is close to the observed ones in numerical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01240v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emmanuel Gil Torres, Matt Jacobs, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>A Provably Convergent Plug-and-Play Framework for Stochastic Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2505.01258</link>
      <description>arXiv:2505.01258v1 Announce Type: new 
Abstract: Bilevel optimization has recently attracted significant attention in machine learning due to its wide range of applications and advanced hierarchical optimization capabilities. In this paper, we propose a plug-and-play framework, named PnPBO, for developing and analyzing stochastic bilevel optimization methods. This framework integrates both modern unbiased and biased stochastic estimators into the single-loop bilevel optimization framework introduced in [9], with several improvements. In the implementation of PnPBO, all stochastic estimators for different variables can be independently incorporated, and an additional moving average technique is applied when using an unbiased estimator for the upper-level variable. In the theoretical analysis, we provide a unified convergence and complexity analysis for PnPBO, demonstrating that the adaptation of various stochastic estimators (including PAGE, ZeroSARAH, and mixed strategies) within the PnPBO framework achieves optimal sample complexity, comparable to that of single-level optimization. This resolves the open question of whether the optimal complexity bounds for solving bilevel optimization are identical to those for single-level optimization. Finally, we empirically validate our framework, demonstrating its effectiveness on several benchmark problems and confirming our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01258v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianshu Chu, Dachuan Xu, Wei Yao, Chengming Yu, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Differentiable Nonlinear Model Predictive Control</title>
      <link>https://arxiv.org/abs/2505.01353</link>
      <description>arXiv:2505.01353v1 Announce Type: new 
Abstract: The efficient computation of parametric solution sensitivities is a key challenge in the integration of learning-enhanced methods with nonlinear model predictive control (MPC), as their availability is crucial for many learning algorithms. While approaches presented in the machine learning community are limited to convex or unconstrained formulations, this paper discusses the computation of solution sensitivities of general nonlinear programs (NLPs) using the implicit function theorem (IFT) and smoothed optimality conditions treated in interior-point methods (IPM). We detail sensitivity computation within a sequential quadratic programming (SQP) method which employs an IPM for the quadratic subproblems. The publication is accompanied by an efficient open-source implementation within the framework, providing both forward and adjoint sensitivities for general optimal control problems, achieving speedups exceeding 3x over the state-of-the-art solver mpc.pytorch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01353v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Frey, Katrin Baumg\"artner, Gianluca Frison, Dirk Reinhardt, Jasper Hoffmann, Leonard Fichtner, Sebastien Gros, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Negative Stepsizes Make Gradient-Descent-Ascent Converge</title>
      <link>https://arxiv.org/abs/2505.01423</link>
      <description>arXiv:2505.01423v1 Announce Type: new 
Abstract: Efficient computation of min-max problems is a central question in optimization, learning, games, and controls. Arguably the most natural algorithm is gradient-descent-ascent (GDA). However, since the 1970s, conventional wisdom has argued that GDA fails to converge even on simple problems. This failure spurred an extensive literature on modifying GDA with additional building blocks such as extragradients, optimism, momentum, anchoring, etc. In contrast, we show that GDA converges in its original form by simply using a judicious choice of stepsizes.
  The key innovation is the proposal of unconventional stepsize schedules (dubbed slingshot stepsize schedules) that are time-varying, asymmetric, and periodically negative. We show that all three properties are necessary for convergence, and that altogether this enables GDA to converge on the classical counterexamples (e.g., unconstrained convex-concave problems). All of our results apply to the last iterate of GDA, as is typically desired in practice.
  The core algorithmic intuition is that although negative stepsizes make backward progress, they de-synchronize the min and max variables (overcoming the cycling issue of GDA), and lead to a slingshot phenomenon in which the forward progress in the other iterations is overwhelmingly larger. This results in fast overall convergence. Geometrically, the slingshot dynamics leverage the non-reversibility of gradient flow: positive/negative steps cancel to first order, yielding a second-order net movement in a new direction that leads to convergence and is otherwise impossible for GDA to move in. We interpret this as a second-order finite-differencing algorithm and show that, intriguingly, it approximately implements consensus optimization, an empirically popular algorithm for min-max problems involving deep neural networks (e.g., training GANs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01423v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Shugart, Jason M. Altschuler</dc:creator>
    </item>
    <item>
      <title>A compact implementation of a recently proposed strongly polynomial-time algorithm for the general LP problem</title>
      <link>https://arxiv.org/abs/2505.01426</link>
      <description>arXiv:2505.01426v1 Announce Type: new 
Abstract: This article presents a compact implementation of a recently proposed strongly polynomial-time algorithm for the general linear programming problem. Each iteration of the algorithm consists of applying a pair of complementary Gauss-Jordan (GJ) pivoting operations. In this compact implementation of the algorithm, the GJ pivoting operations are done inside a matrix that has half the size of the original matrix. A numerical illustration is given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01426v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Awoniyi</dc:creator>
    </item>
    <item>
      <title>A stabilized march approach to adjoint-based sensitivity analysis of chaotic flows</title>
      <link>https://arxiv.org/abs/2505.00838</link>
      <description>arXiv:2505.00838v1 Announce Type: cross 
Abstract: Adjoint-based sensitivity analysis is of interest in computational science due to its ability to compute sensitivities at a lower cost with respect to several design parameters. However, conventional sensitivity analysis methods fail in the presence of chaotic flows. Popular approaches to chaotic sensitivity analysis of flows involve the use of the shadowing trajectory. The state-of-the-art approach computes the shadowing trajectory by solving a least squares minimization problem, resulting in a space-time linear system of equations. The current paper computes the adjoint shadowing trajectory using the stabilized march, by specifying the adjoint boundary conditions instead of solving a minimization problem. This approach results in a space-time linear system that can be solved through a single backward substitution of order $\mathcal{O}(n_u^2)$ with $n_u$ being the dimension of the unstable subspace. It is proven to compute sensitivities that converge to the true sensitivity for large integration times and that the error in the sensitivity due to the discretization is of the order of the local truncation error of the scheme. The approach is numerically verified on the Lorentz 63 and Kuramoto-Sivasinsky equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00838v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pranshul Thakur, Siva Nadarajah</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Policy Iteration with Additive Schwarz Acceleration for Forward and Inverse HJB and Mean Field Game Problems</title>
      <link>https://arxiv.org/abs/2505.00909</link>
      <description>arXiv:2505.00909v1 Announce Type: cross 
Abstract: We propose a Gaussian Process (GP)-based policy iteration framework for addressing both forward and inverse problems in Hamilton--Jacobi--Bellman (HJB) equations and mean field games (MFGs). Policy iteration is formulated as an alternating procedure between solving the value function under a fixed control policy and updating the policy based on the resulting value function. By exploiting the linear structure of GPs for function approximation, each policy evaluation step admits an explicit closed-form solution, eliminating the need for numerical optimization. To improve convergence, we incorporate the additive Schwarz acceleration as a preconditioning step following each policy update. Numerical experiments demonstrate the effectiveness of Schwarz acceleration in improving computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00909v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xianjin Yang, Jingguo Zhang</dc:creator>
    </item>
    <item>
      <title>Virtual Force-Based Routing of Modular Agents on a Graph</title>
      <link>https://arxiv.org/abs/2505.00928</link>
      <description>arXiv:2505.00928v1 Announce Type: cross 
Abstract: Modular vehicles have become an area of academic interest in the field of multi-agent systems. Modularity allows vehicles to connect and disconnect with each other mid-transit which provides a balance between efficiency and flexibility when solving complex and large scale tasks in urban or aerial transportation. This paper details a generalized scheme to route multiple modular agents on a graph to a predetermined set of target nodes. The objective is to visit all target nodes while incurring minimum resource expenditure. Agents that are joined together will incur the equivalent cost of a single agent, which is motivated by the logistical benefits of traffic reduction and increased fuel efficiency. To solve this problem, we introduce a heuristic algorithm that seeks to balance the optimality of the path that an agent takes and the cost benefit of joining agents. Our approach models the agents and targets as point charges, where the agents take the path of highest attractive force from its target node and neighboring agents. We validate our approach by simulating multiple modular agents along real-world transportation routes in the road network of Champaign-Urbana, Illinois, USA. For two vehicles, it performed equally compared to an existing modular-agent routing algorithm. Three agents were then routed using our method and the performance was benchmarked against non-modular agents using a simple shortest path policy where it performs better than the non-modular implementation 81 percent of the time. Moreover, we show that the proposed algorithm operates faster than existing routing methods for modular agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00928v1</guid>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Casselman, Manav Vora, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>StablePCA: Learning Shared Representations across Multiple Sources via Minimax Optimization</title>
      <link>https://arxiv.org/abs/2505.00940</link>
      <description>arXiv:2505.00940v1 Announce Type: cross 
Abstract: When synthesizing multisource high-dimensional data, a key objective is to extract low-dimensional feature representations that effectively approximate the original features across different sources. Such general feature extraction facilitates the discovery of transferable knowledge, mitigates systematic biases such as batch effects, and promotes fairness. In this paper, we propose Stable Principal Component Analysis (StablePCA), a novel method for group distributionally robust learning of latent representations from high-dimensional multi-source data. A primary challenge in generalizing PCA to the multi-source regime lies in the nonconvexity of the fixed rank constraint, rendering the minimax optimization nonconvex. To address this challenge, we employ the Fantope relaxation, reformulating the problem as a convex minimax optimization, with the objective defined as the maximum loss across sources. To solve the relaxed formulation, we devise an optimistic-gradient Mirror Prox algorithm with explicit closed-form updates. Theoretically, we establish the global convergence of the Mirror Prox algorithm, with the convergence rate provided from the optimization perspective. Furthermore, we offer practical criteria to assess how closely the solution approximates the original nonconvex formulation. Through extensive numerical experiments, we demonstrate StablePCA's high accuracy and efficiency in extracting robust low-dimensional representations across various finite-sample scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00940v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenyu Wang, Molei Liu, Jing Lei, Francis Bach, Zijian Guo</dc:creator>
    </item>
    <item>
      <title>A Minimax-MDP Framework with Future-imposed Conditions for Learning-augmented Problems</title>
      <link>https://arxiv.org/abs/2505.00973</link>
      <description>arXiv:2505.00973v1 Announce Type: cross 
Abstract: We study a class of sequential decision-making problems with augmented predictions, potentially provided by a machine learning algorithm. In this setting, the decision-maker receives prediction intervals for unknown parameters that become progressively refined over time, and seeks decisions that are competitive with the hindsight optimal under all possible realizations of both parameters and predictions. We propose a minimax Markov Decision Process (minimax-MDP) framework, where the system state consists of an adversarially evolving environment state and an internal state controlled by the decision-maker. We introduce a set of future-imposed conditions that characterize the feasibility of minimax-MDPs and enable the design of efficient, often closed-form, robustly competitive policies. We illustrate the framework through three applications: multi-period inventory ordering with refining demand predictions, resource allocation with uncertain utility functions, and a multi-phase extension of the minimax-MDP applied to the inventory problem with time-varying ordering costs. Our results provide a tractable and versatile approach to robust online decision-making under predictive uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00973v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Chen, Yuze Chen, Yuan Zhou</dc:creator>
    </item>
    <item>
      <title>Bridging Statistical Scattering and Aberration Theory: Ray Deflection Function -- I: Theoretical Framework</title>
      <link>https://arxiv.org/abs/2505.01019</link>
      <description>arXiv:2505.01019v1 Announce Type: cross 
Abstract: This paper introduces a new conceptual framework that recasts surface roughness effects as a "ray deflection function" (RDF) which can be statistically represented through a modified Zernike-Fourier hybrid approach that directly connects the PSD with statistical aberration coefficients through spectral overlap integration. By establishing a direct mathematical relationship between the power spectral density (PSD) of surface imperfections and the statistical distribution of aberration coefficients, we develop a formalism that bridges known probabilistic scattering theory with deterministic aberration analysis. This transformation allows surface roughness to be seamlessly integrated with other optical aberrations by expressing its effects through equivalent modifications to the ideal mirror shape. This framework provides computational advantages for ray-tracing simulations while maintaining statistical fidelity to established scattering models, particularly for predicting the three-dimensional structure of imperfect focal bodies in optical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01019v1</guid>
      <category>physics.optics</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Netzer Moriya</dc:creator>
    </item>
    <item>
      <title>Bridging Statistical Scattering and Aberration Theory: Ray Deflection Function -- II: Numerical Validation</title>
      <link>https://arxiv.org/abs/2505.01026</link>
      <description>arXiv:2505.01026v1 Announce Type: cross 
Abstract: This paper presents a comprehensive experimental validation of a recently developed Ray Deflection Function (RDF) approach, which offers a new framework for modeling surface roughness effects in optical systems. Through detailed geometrical ray tracing simulations, we demonstrate that the RDF methodology successfully bridges two traditionally separate domains: statistical scattering models and deterministic aberration analysis. We implement and compare the two approaches for modeling a parabolic mirror with surface imperfections with three cases: (1) an ideal parabolic mirror baseline, (2) the conventional Harvey-Shack (HS) statistical scattering theory applied to ray perturbations, and (3) the newly proposed aberration term method based on the RDF theory. Our results confirm the statistical equivalence between the HS approach and the RDF-based aberration term method, with both producing close near-focal-plane distributions and focal volume characteristics. By establishing this equivalence, we validate that surface roughness effects can be accurately represented as deterministic aberration terms while maintaining fidelity to established statistical scattering models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01026v1</guid>
      <category>physics.optics</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Netzer Moriya</dc:creator>
    </item>
    <item>
      <title>Transforming physics-informed machine learning to convex optimization</title>
      <link>https://arxiv.org/abs/2505.01047</link>
      <description>arXiv:2505.01047v1 Announce Type: cross 
Abstract: Physics-Informed Machine Learning (PIML) offers a powerful paradigm of integrating data with physical laws to address important scientific problems, such as parameter estimation, inferring hidden physics, equation discovery, and state prediction, etc. However, PIML still faces many serious optimization challenges that significantly restrict its applications. In this study, we propose a comprehensive framework that transforms PIML to convex optimization to overcome all these limitations, referred to as Convex-PIML. The linear combination of B-splines is utilized to approximate the data, promoting the convexity of the loss function. By replacing the non-convex components of the loss function with convex approximations, the problem is further converted into a sequence of successively refined approximated convex optimization problems. This conversion allows the use of well-established convex optimization algorithms, obtaining solutions effectively and efficiently. Furthermore, an adaptive knot optimization method based on error estimate is introduced to mitigate the spectral bias issue of PIML, further improving the performance. The proposed theoretically guaranteed framework is tested in scenarios with distinct types of physical prior. The results indicate that optimization problems are effectively solved in these scenarios, highlighting the potential of the framework for broad applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01047v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>physics.app-ph</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Letian Yi, Siyuan Yang, Ying Cui, Zhilu Lai</dc:creator>
    </item>
    <item>
      <title>Integration Matters for Learning PDEs with Backwards SDEs</title>
      <link>https://arxiv.org/abs/2505.01078</link>
      <description>arXiv:2505.01078v1 Announce Type: cross 
Abstract: Backward stochastic differential equation (BSDE)-based deep learning methods provide an alternative to Physics-Informed Neural Networks (PINNs) for solving high-dimensional partial differential equations (PDEs), offering algorithmic advantages in settings such as stochastic optimal control, where the PDEs of interest are tied to an underlying dynamical system. However, existing BSDE-based solvers have empirically been shown to underperform relative to PINNs in the literature. In this paper, we identify the root cause of this performance gap as a discretization bias introduced by the standard Euler-Maruyama (EM) integration scheme applied to short-horizon self-consistency BSDE losses, which shifts the optimization landscape off target. We find that this bias cannot be satisfactorily addressed through finer step sizes or longer self-consistency horizons. To properly handle this issue, we propose a Stratonovich-based BSDE formulation, which we implement with stochastic Heun integration. We show that our proposed approach completely eliminates the bias issues faced by EM integration. Furthermore, our empirical results show that our Heun-based BSDE method consistently outperforms EM-based variants and achieves competitive results with PINNs across multiple high-dimensional benchmarks. Our findings highlight the critical role of integration schemes in BSDE-based PDE solvers, an algorithmic detail that has received little attention thus far in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01078v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungje Park, Stephen Tu</dc:creator>
    </item>
    <item>
      <title>Pattern formation using an intrinsic optimal control approach</title>
      <link>https://arxiv.org/abs/2505.01302</link>
      <description>arXiv:2505.01302v1 Announce Type: cross 
Abstract: This paper investigates a pattern formation control problem for a multi-agent system modeled with given interaction topology, in which $m$ of the $n$ agents are chosen as leaders and consequently a control signal is added to each of the leaders. These agents interact with each other by Laplacian dynamics on a graph. The pattern formation control problem is formulated as an intrinsic infinite time-horizon linear quadratic optimal control problem, namely, no error information is incorporated in the objective function. Under mild conditions, we show the existence of the optimal control strategy and the convergence to the desired pattern formation. Based on the optimal control strategy, we propose a distributed control strategy to achieve the given pattern. Finally, numerical simulation is given to illustrate theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01302v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhao Li, Yibei Li, Zhixin Liu, Xiaoming Hu</dc:creator>
    </item>
    <item>
      <title>A Normal Map-Based Proximal Stochastic Gradient Method: Convergence and Identification Properties</title>
      <link>https://arxiv.org/abs/2305.05828</link>
      <description>arXiv:2305.05828v2 Announce Type: replace 
Abstract: The proximal stochastic gradient method (PSGD) is one of the state-of-the-art approaches for stochastic composite-type problems. In contrast to its deterministic counterpart, PSGD has been found to have difficulties with the correct identification of underlying substructures (such as supports, low rank patterns, or active constraints) and it does not possess a finite-time manifold identification property. Existing solutions rely on convexity assumptions or on the additional usage of variance reduction techniques. In this paper, we address these limitations and present a simple variant of PSGD based on Robinson's normal map. The proposed normal map-based proximal stochastic gradient method (NSGD) is shown to converge globally, i.e., accumulation points of the generated iterates correspond to stationary points almost surely. In addition, we establish complexity bounds for NSGD that match the known results for PSGD and we prove that NSGD can almost surely identify active manifolds in finite-time in a general nonconvex setting. Our derivations are built on almost sure iterate convergence guarantees and utilize analysis techniques based on the Kurdyka-Lojasiewicz inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05828v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junwen Qiu, Li Jiang, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm</title>
      <link>https://arxiv.org/abs/2308.08852</link>
      <description>arXiv:2308.08852v2 Announce Type: replace 
Abstract: Graphical models have exhibited their performance in numerous tasks ranging from biological analysis to recommender systems. However, graphical models with hub nodes are computationally difficult to fit, particularly when the dimension of the data is large. To efficiently estimate the hub graphical models, we introduce a two-phase algorithm. The proposed algorithm first generates a good initial point via a dual alternating direction method of multipliers (ADMM), and then warm starts a semismooth Newton (SSN) based augmented Lagrangian method (ALM) to compute a solution that is accurate enough for practical tasks. We fully excavate the sparsity structure of the generalized Jacobian arising from the hubs in the graphical models, which ensures that the algorithm can obtain a nice solution very efficiently. Comprehensive experiments on both synthetic data and real data show that it obviously outperforms the existing state-of-the-art algorithms. In particular, in some high dimensional tasks, it can save more than 70\% of the execution time, meanwhile still achieves a high-quality estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08852v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chengjing Wang, Peipei Tang, Wenling He, Meixia Lin</dc:creator>
    </item>
    <item>
      <title>Relating Electric Vehicle Charging to Speed Scaling with Job-Specific Speed Limits</title>
      <link>https://arxiv.org/abs/2309.06174</link>
      <description>arXiv:2309.06174v4 Announce Type: replace 
Abstract: Due to the ongoing electrification of transport in combination with limited power grid capacities, efficient ways to schedule the charging of electric vehicles (EVs) are needed for the operation of, for example, large parking lots. Common approaches such as model predictive control repeatedly solve a corresponding offline problem. In this work, we first present and analyze the Flow-based Offline Charging Scheduler (FOCS), an offline algorithm to derive an optimal EV charging schedule for a fleet of EVs that minimizes an increasing, convex and differentiable function of the corresponding aggregated power profile. To this end, we relate EV charging to processor speed scaling models with job-specific speed limits. We prove our algorithm to be optimal and derive necessary and sufficient conditions for any EV charging profile to be optimal. Furthermore, we discuss two online algorithms and their competitive ratios for a specific class objective functions. In particular, we show that if those algorithms are applied and adapted to the presented EV scheduling problem, the competitive ratios for Average Rate and Optimal Available match those of the classical speed scaling problem. Finally, we present numerical results using real-world EV charging data to put the theoretical competitive ratios into a practical perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06174v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leoni Winschermann, Marco E. T. Gerards, Antonios Antoniadis, Gerwin Hoogsteen, Johann Hurink</dc:creator>
    </item>
    <item>
      <title>Virtual Linking Bids for Market Clearing with Non-Merchant Storage</title>
      <link>https://arxiv.org/abs/2309.14787</link>
      <description>arXiv:2309.14787v3 Announce Type: replace 
Abstract: In the context of energy market clearing, non-merchant assets are assets that do not submit bids but whose operational constraints are included. Integrating energy storage systems as non-merchant assets can maximize social welfare. However, the disconnection between consecutive market clearings poses challenges for market properties, and this is not well studied yet. We contribute to the literature on market clearing with non-merchant storage by proposing a market-clearing procedure that preserves desirable market properties, even under uncertainty. This approach is based on a novel representation of storage systems in which the energy available is discretized to reflect the different prices at which the storage system was charged. These prices are then included as virtual bids, establishing a link between different market clearings. We show that market clearing with such virtual linking bids has the advantage of guaranteeing cost recovery for market participants and can outperform traditional approaches in terms of social welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14787v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El\'ea Prat, Jonas Bodulv Broge, Richard M. Lusby</dc:creator>
    </item>
    <item>
      <title>Employing Federated Learning for Training Autonomous HVAC Systems</title>
      <link>https://arxiv.org/abs/2405.00389</link>
      <description>arXiv:2405.00389v2 Announce Type: replace 
Abstract: Buildings account for 40% of global energy consumption. A considerable portion of building energy consumption stems from heating, ventilation, and air conditioning (HVAC), and thus implementing smart, energy-efficient HVAC systems has the potential to significantly impact the course of climate change. In recent years, model-free reinforcement learning algorithms have been increasingly assessed for this purpose due to their ability to learn and adapt purely from experience. They have been shown to outperform classical controllers in terms of energy cost and consumption, as well as thermal comfort. However, their weakness lies in their relatively poor data efficiency, requiring long periods of training to reach acceptable policies, making them inapplicable to real-world controllers directly. In this paper, we demonstrate that using federated learning to train the reinforcement learning controller of HVAC systems can improve the learning speed, as well as improve their ability to generalize, which in turn facilitates transfer learning to unseen building environments. In our setting, a global control policy is learned by aggregating local policies trained on multiple data centers located in different climate zones. The goal of the policy is to minimize energy consumption and maximize thermal comfort. We perform experiments evaluating three different optimizers for local policy training, as well as three different federated learning algorithms against two alternative baselines. Our experiments show that these effects lead to a faster learning speed, as well as greater generalization capabilities in the federated policy compared to any individually trained policy. Furthermore, the learning stability is significantly improved, with the learning process and performance of the federated policy being less sensitive to the choice of parameters and the inherent randomness of reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00389v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.enbuild.2025.115761</arxiv:DOI>
      <dc:creator>Fredrik Hagstr\"om, Vikas Garg, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>Assessing solution quality in risk-averse stochastic programs</title>
      <link>https://arxiv.org/abs/2408.15690</link>
      <description>arXiv:2408.15690v2 Announce Type: replace 
Abstract: In optimization problems, the quality of a candidate solution can be characterized by the optimality gap. For most stochastic optimization problems, this gap must be statistically estimated. We show that for risk-averse problems, standard estimators are optimistically biased, which compromises the statistical guarantee on the optimality gap. We introduce estimators for risk-averse problems that do not suffer from this bias. Our method relies on using two independent samples, each estimating a different component of the optimality gap. Our approach extends a broad class of optimality gap estimation methods from the risk-neutral case to the risk-averse case, such as the multiple replications procedure and its one- and two-sample variants. We show that our approach is tractable and leads to high-quality optimality gap estimates for spectral and quadrangle risk measures. Our approach can further make use of existing bias and variance reduction techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15690v2</guid>
      <category>math.OC</category>
      <category>q-fin.RM</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Ruben van Beesten, Nick W. Koning, David P. Morton</dc:creator>
    </item>
    <item>
      <title>Accurate and Efficient Cardiac Digital Twin from surface ECGs: Insights into Identifiability of Ventricular Conduction System</title>
      <link>https://arxiv.org/abs/2411.00165</link>
      <description>arXiv:2411.00165v3 Announce Type: replace 
Abstract: Digital twins for cardiac electrophysiology are an enabling technology for precision cardiology. Current forward models are advanced enough to simulate the cardiac electric activity under different pathophysiological conditions and accurately replicate clinical signals like torso electrocardiograms (ECGs). In this work, we address the challenge of matching subject-specific QRS complexes using anatomically accurate, physiologically grounded cardiac digital twins. By fitting the initial conditions of a cardiac propagation model, our non-invasive method predicts activation patterns during sinus rhythm. For the first time, we demonstrate that distinct activation maps can generate identical surface ECGs. To address this non-uniqueness, we introduce a physiological prior based on the distribution of Purkinje-muscle junctions. Additionally, we develop a digital twin ensemble for probabilistic inference of cardiac activation. Our approach marks a significant advancement in the calibration of cardiac digital twins and enhances their credibility for clinical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00165v3</guid>
      <category>math.OC</category>
      <category>physics.med-ph</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Grandits, Karli Gillette, Gernot Plank, Simone Pezzuto</dc:creator>
    </item>
    <item>
      <title>Convex Data-Driven Contraction With Riemannian Metrics</title>
      <link>https://arxiv.org/abs/2412.20283</link>
      <description>arXiv:2412.20283v2 Announce Type: replace 
Abstract: The growing complexity of dynamical systems and advances in data collection necessitates robust data-driven control strategies without explicit system identification and robust synthesis. Data-driven stability has been explored in linear and nonlinear systems, often by turning the problem into a linear or positive semidefinite program. This paper focuses on a new emerging property called contractivity, which refers to the exponential convergence of all system trajectories toward each other under a specified metric. Data-driven closed loop contractivity has been studied for the case of the 2-norm and assuming nonlinearities are Lipschitz bounded in subsets of n dimensional euclidean space. We extend the analysis by considering Riemannian metrics for polynomial dynamics. The key to our derivation is to leverage the convex criteria for closed-loop contraction and duality results to efficiently check infinite dimensional membership constraints. Numerical examples demonstrate the effectiveness of the proposed method for both linear and nonlinear systems, highlighting its potential for robust data-driven contraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20283v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andreas Oliveira, Jian Zheng, Mario Sznaier</dc:creator>
    </item>
    <item>
      <title>On the equivalence of a Hessian-free inequality and Lipschitz continuous Hessian</title>
      <link>https://arxiv.org/abs/2504.17193</link>
      <description>arXiv:2504.17193v2 Announce Type: replace 
Abstract: It is known that if a twice differentiable function has a Lipschitz continuous Hessian, then its gradients satisfy a Jensen-type inequality. In particular, this inequality is Hessian-free in the sense that the Hessian does not actually appear in the inequality. In this paper, we show that the converse holds in a generalized setting: if a continuos function from a Hilbert space to a reflexive Banach space satisfies such an inequality, then it is Fr\'echet differentiable and its derivative is Lipschitz continuous. Our proof relies on the Baillon-Haddad theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17193v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Radu I. Bo\c{t}, Minh N. Dao, Tianxiang Liu, Bruno F. Louren\c{c}o, Naoki Marumo</dc:creator>
    </item>
    <item>
      <title>Asynchronous Push-sum Dual Gradient Algorithm in Distributed Model Predictive Control</title>
      <link>https://arxiv.org/abs/2504.18941</link>
      <description>arXiv:2504.18941v2 Announce Type: replace 
Abstract: This paper studies the distributed model predictive control (DMPC) problem for distributed discrete-time linear systems with both local and global constraints over directed communication networks. We establish an optimization problem to formulate the DMPC policy, including the design of terminal ingredients. To cope with the global constraint, we transform the primal optimization problem into its dual problem. Then, we propose a novel asynchronous push-sum dual gradient (APDG) algorithm with an adaptive step-size scheme to solve this dual problem in a fully asynchronous distributed manner. The proposed algorithm does not require synchronous waiting and any form of coordination, which greatly improves solving efficiency. We theoretically prove that the APDG algorithm converges at an R-linear rate as long as the step-size does not exceed the designed upper bound. Furthermore, we develop a distributed termination criterion to terminate the APDG algorithm when its output solution satisfies the specified suboptimality and the global constraint, thereby avoiding an infinite number of iterations. The recursive feasibility and the stability of the closed-loop system are also established. Finally, a numerical example clarifies and validates theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18941v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengbiao Wang, Xuemei Ren, Dongdong Zheng</dc:creator>
    </item>
    <item>
      <title>Constructing Magic Squares: an integer linear programming model and a fast heuristic</title>
      <link>https://arxiv.org/abs/2504.20017</link>
      <description>arXiv:2504.20017v2 Announce Type: replace 
Abstract: Magic squares are a fascinating mathematical challenge that has intrigued mathematicians for centuries. Given a positive (and possibly large) integer $n$, one of the main challenges that still remains is to find, within a reliable computational time, a magic square of order $n$, that is, a square matrix of order $n$ with unique integers from $a_{\min}$ to $a_{\max}$, such that the sum of each row, column, and diagonal equals a constant $\mathcal{C}(A)$. In this work, we first present an Integer Linear Programming (ILP) model for constructing a magic square of order $n$, which is formulated as a feasibility problem. Nonetheless, the solution time of this ILP model grows exponentially as the order increases. To overcome this limitation, we also propose a heuristic that constructs magic squares depending on whether $n$ is odd, singly even, or doubly even. Our numerical results show that the proposed heuristic can construct magic squares of order up to $70000$ in less than $140$ seconds, demonstrating its efficiency and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20017v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Vitor Pamplona, Maria Eduarda Pinheiro, Luiz-Rafael Santos</dc:creator>
    </item>
    <item>
      <title>Deterministic Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2302.08300</link>
      <description>arXiv:2302.08300v2 Announce Type: replace-cross 
Abstract: We study the complexity of optimizing nonsmooth nonconvex Lipschitz functions by producing $(\delta,\epsilon)$-stationary points. Several recent works have presented randomized algorithms that produce such points using $\tilde O(\delta^{-1}\epsilon^{-3})$ first-order oracle calls, independent of the dimension $d$. It has been an open problem as to whether a similar result can be obtained via a deterministic algorithm. We resolve this open problem, showing that randomization is necessary to obtain a dimension-free rate. In particular, we prove a lower bound of $\Omega(d)$ for any deterministic algorithm. Moreover, we show that unlike smooth or convex optimization, access to function values is required for any deterministic algorithm to halt within any finite time.
  On the other hand, we prove that if the function is even slightly smooth, then the dimension-free rate of $\tilde O(\delta^{-1}\epsilon^{-3})$ can be obtained by a deterministic algorithm with merely a logarithmic dependence on the smoothness parameter. Motivated by these findings, we turn to study the complexity of deterministically smoothing Lipschitz functions. Though there are efficient black-box randomized smoothings, we start by showing that no such deterministic procedure can smooth functions in a meaningful manner, resolving an open question. We then bypass this impossibility result for the structured case of ReLU neural networks. To that end, in a practical white-box setting in which the optimizer is granted access to the network's architecture, we propose a simple, dimension-free, deterministic smoothing that provably preserves $(\delta,\epsilon)$-stationary points. Our method applies to a variety of architectures of arbitrary depth, including ResNets and ConvNets. Combined with our algorithm, this yields the first deterministic dimension-free algorithm for optimizing ReLU networks, circumventing our lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08300v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael I. Jordan, Guy Kornowski, Tianyi Lin, Ohad Shamir, Manolis Zampetakis</dc:creator>
    </item>
    <item>
      <title>A Quadratic Speedup in Finding Nash Equilibria of Quantum Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2311.10859</link>
      <description>arXiv:2311.10859v2 Announce Type: replace-cross 
Abstract: Recent developments in domains such as non-local games, quantum interactive proofs, and quantum generative adversarial networks have renewed interest in quantum game theory and, specifically, quantum zero-sum games. Central to classical game theory is the efficient algorithmic computation of Nash equilibria, which represent optimal strategies for both players. In 2008, Jain and Watrous proposed the first classical algorithm for computing equilibria in quantum zero-sum games using the Matrix Multiplicative Weight Updates (MMWU) method to achieve a convergence rate of $\mathcal{O}(d/\epsilon^2)$ iterations to $\epsilon$-Nash equilibria in the $4^d$-dimensional spectraplex. In this work, we propose a hierarchy of quantum optimization algorithms that generalize MMWU via an extra-gradient mechanism. Notably, within this proposed hierarchy, we introduce the Optimistic Matrix Multiplicative Weights Update (OMMWU) algorithm and establish its average-iterate convergence complexity as $\mathcal{O}(d/\epsilon)$ iterations to $\epsilon$-Nash equilibria. This quadratic speed-up relative to Jain and Watrous' original algorithm sets a new benchmark for computing $\epsilon$-Nash equilibria in quantum zero-sum games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10859v2</guid>
      <category>quant-ph</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisca Vasconcelos, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Panayotis Mertikopoulos, Georgios Piliouras, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Asynchronous Stochastic Approximation and Average-Reward Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.03915</link>
      <description>arXiv:2409.03915v2 Announce Type: replace-cross 
Abstract: This paper studies asynchronous stochastic approximation (SA) algorithms and their theoretical application to reinforcement learning in semi-Markov decision processes (SMDPs) with an average-reward criterion. We first extend Borkar and Meyn's stability proof method to accommodate more general noise conditions, yielding broader convergence guarantees for asynchronous SA. To sharpen the convergence analysis, we further examine shadowing properties in the asynchronous setting, building on a dynamical-systems approach of Hirsch and Bena\"{i}m. Leveraging these SA results, we establish the convergence of an asynchronous SA analogue of Schweitzer's classical relative value iteration algorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs. Moreover, to make full use of these SA results in this application, we introduce new monotonicity conditions for estimating the optimal reward rate in RVI Q-learning. These conditions substantially expand the previously considered algorithmic framework, and we address them with novel arguments in the stability and convergence analysis of RVI Q-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03915v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huizhen Yu, Yi Wan, Richard S. Sutton</dc:creator>
    </item>
    <item>
      <title>End-to-End Learning Framework for Solving Non-Markovian Optimal Control</title>
      <link>https://arxiv.org/abs/2502.04649</link>
      <description>arXiv:2502.04649v4 Announce Type: replace-cross 
Abstract: Integer-order calculus often falls short in capturing the long-range dependencies and memory effects found in many real-world processes. Fractional calculus addresses these gaps via fractional-order integrals and derivatives, but fractional-order dynamical systems pose substantial challenges in system identification and optimal control due to the lack of standard control methodologies. In this paper, we theoretically derive the optimal control via linear quadratic regulator (LQR) for fractional-order linear time-invariant (FOLTI) systems and develop an end-to-end deep learning framework based on this theoretical foundation. Our approach establishes a rigorous mathematical model, derives analytical solutions, and incorporates deep learning to achieve data-driven optimal control of FOLTI systems. Our key contributions include: (i) proposing an innovative system identification method control strategy for FOLTI systems, (ii) developing the first end-to-end data-driven learning framework, Fractional-Order Learning for Optimal Control (FOLOC), that learns control policies from observed trajectories, and (iii) deriving a theoretical analysis of sample complexity to quantify the number of samples required for accurate optimal control in complex real-world problems. Experimental results indicate that our method accurately approximates fractional-order system behaviors without relying on Gaussian noise assumptions, pointing to promising avenues for advanced optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04649v4</guid>
      <category>cs.SY</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaole Zhang, Peiyu Zhang, Xiongye Xiao, Shixuan Li, Vasileios Tzoumas, Vijay Gupta, Paul Bogdan</dc:creator>
    </item>
  </channel>
</rss>
