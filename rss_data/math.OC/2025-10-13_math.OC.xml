<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Oct 2025 03:09:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Re$^3$MCN: Cubic Newton + Variance Reduction + Momentum + Quadratic Regularization for Finite-sum Non-convex Problems</title>
      <link>https://arxiv.org/abs/2510.08714</link>
      <description>arXiv:2510.08714v1 Announce Type: new 
Abstract: We analyze a stochastic cubic regularized Newton method for finite sum optimization $\textstyle\min_{x\in\mathbb{R}^d} F(x) \;=\; \frac{1}{n}\sum_{i=1}^n f_i(x)$, that uses SARAH-type recursive variance reduction with mini-batches of size $b\sim n^{1/2}$ and exponential moving averages (EMA) for gradient and Hessian estimators. We show that the method achieves a $(\varepsilon,\sqrt{L_2\varepsilon})$-second-order stationary point (SOSP) with total stochastic oracle calls $n + \widetilde{\mathcal{O}}(n^{1/2}\varepsilon^{-3/2})$ in the nonconvex case (Theorem 8.3) and convergence rate $\widetilde{\mathcal{O}}(\frac{L R^3}{T^2} + \frac{\sigma_2 R^2}{T^2} + \frac{\sigma_1 R}{\sqrt{T}})$ in the convex case (Theorem 6.1). We also treat the matrix-free variant based on Hutchinson's estimator for Hessian and present a fast inner solver for the cubic subproblem with provable attainment of the required inexactness level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08714v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitry Pasechnyuk-Vilensky, Dmitry Kamzolov, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>A complete classification of control sets for singular linear control systems on the Heisenberg group</title>
      <link>https://arxiv.org/abs/2510.08751</link>
      <description>arXiv:2510.08751v1 Announce Type: new 
Abstract: In this paper, we investigate the control sets of linear control systems on the Heisenberg group associated with singular derivations. Under the Lie algebra rank condition, we provide a complete characterization of these sets by analyzing the trace and determinant of an associated 2 \times 2 submatrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08751v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adriano Da Silva, Okan Duman, Anderson F. P. Rojas</dc:creator>
    </item>
    <item>
      <title>A generalized alternating NGMRES method for PDE-constrained optimization problems governed by transport equations</title>
      <link>https://arxiv.org/abs/2510.08782</link>
      <description>arXiv:2510.08782v1 Announce Type: new 
Abstract: In this work, we propose a generalized alternating nonlinear generalized minimal residual method (GA-NGMRES) to accelerate first-order optimization schemes for PDE-constrained optimization problems governed by transport equations. We apply GA-NGMRES to a preconditioned first-order optimization scheme by interpreting the update rule as a fixed-point (FP) iteration. Our approach introduces a novel periodic mixing strategy that integrates NGMRES updates with FP steps. This new scheme improves efficiency in terms of both iteration count and runtime compared to the state-of-the-art. We include a comparison to first-order preconditioned gradient descent and preconditioned, inexact Gauss--Newton--Krylov methods. Since the proposed optimization scheme only relies on first-order derivative information, its implementation is straightforward. We evaluate performance as a function of hyperparameters, the mesh size, and the regularization parameter. We consider advection, incompressible flows, and mass-preserving transport (i.e., optimal transport-type problems) as PDE models. Stipulating adequate smoothness requirements based on variational regularization of the control variable ensures that the computed transport maps are diffeomorphic. Numerical experiments on real-world and synthetic problems highlight the robustness and effectiveness of the proposed method. Our approach yields runtimes that are up to 5x faster than state-of-the-art Newton--Krylov methods, without sacrificing accuracy. Additionally, our GA-NGMRES algorithm outperforms the well-known Anderson acceleration for the models and numerical approach considered in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08782v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunhui He, Andreas Mang</dc:creator>
    </item>
    <item>
      <title>FORWARD: A Feasible Radial Reconfiguration Algorithm for Multi-Source Distribution Networks</title>
      <link>https://arxiv.org/abs/2510.08785</link>
      <description>arXiv:2510.08785v1 Announce Type: new 
Abstract: This paper considers an optimal radial reconfiguration problem in multi-source distribution networks, where the goal is to find a radial configuration that minimizes quadratic distribution costs while ensuring all sink demands are met. This problem arises in critical infrastructure systems such as power distribution, water networks, and gas distribution, where radial configurations are essential for operational safety and efficiency. Optimal solution for this problem is known to be NP-hard. In this paper, we prove further that constructing a feasible radial distribution configuration is weakly NP-complete, making exact solution methods computationally intractable for large-scale networks. We propose FORWARD (Feasibility Oriented Random-Walk Inspired Algorithm for Radial Reconfiguration in Distribution Networks), a polynomial-time algorithm that leverages graph-theoretic decomposition and random walk principles to construct feasible radial configurations. Our approach introduces novel techniques including strategic graph partitioning at articulation points, dual graph condensation to address greedy shortsightedness, and capacity-aware edge swapping for infeasibility resolution. We provide rigorous theoretical analysis proving feasibility guarantees and establish a compositional framework enabling parallel processing while preserving optimality properties. Comprehensive numerical evaluation on networks ranging from IEEE standard test systems to 400-node small-world networks demonstrates that FORWARD consistently outperforms commercial MINLP solvers, achieving optimal or near-optimal solutions in seconds where traditional methods require hours or fail entirely. The algorithm's polynomial-time complexity and scalability make it particularly suitable for real-time distribution network management and as an effective initialization strategy for iterative optimization solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08785v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joan Vendrell Gallart, Russell Bent, Solmaz Kia</dc:creator>
    </item>
    <item>
      <title>CoNeT-GIANT: A compressed Newton-type fully distributed optimization algorithm</title>
      <link>https://arxiv.org/abs/2510.08806</link>
      <description>arXiv:2510.08806v1 Announce Type: new 
Abstract: Compression techniques are essential in distributed optimization and learning algorithms with high-dimensional model parameters, particularly in scenarios with tight communication constraints such as limited bandwidth. This article presents a communication-efficient second-order distributed optimization algorithm, termed as CoNet-GIANT, equipped with a compression module, designed to minimize the average of local strongly convex functions. CoNet-GIANT incorporates two consensus-based averaging steps at each node: gradient tracking and approximate Newton-type iterations, inspired by the recently proposed Network-GIANT. Under certain sufficient conditions on the step size, CoNet-GIANT achieves significantly faster linear convergence, comparable to that of its first-order counterparts, both in the compressed and uncompressed settings. CoNet-GIANT is efficient in terms of data usage, communication cost, and run-time, making it a suitable choice for distributed optimization over a wide range of wireless networks. Extensive experiments on synthetic data and the widely used CovType dataset demonstrate its superior performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08806v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Souvik Das, Subhrakanti Dey</dc:creator>
    </item>
    <item>
      <title>Data-driven multifidelity and multiscale topology optimization based on phasor-based evolutionary de-homogenization</title>
      <link>https://arxiv.org/abs/2510.08830</link>
      <description>arXiv:2510.08830v1 Announce Type: new 
Abstract: Multiscale topology optimization is crucial for designing porous infill structures with high stiffness-to-weight ratios and excellent energy absorption. Although gradient-based methods provide a rigorous framework, they are computationally expensive and struggle to capture cross-scale sensitivities in nonlinear settings. Moreover, the resulting hierarchical geometries are often overly complex and lack macroscopically meaningful features. To overcome these issues, we propose an evolutionary de-homogenization framework that couples MultiFidelity Topology Design (MFTD) with a phasor-based de-homogenization technique. The framework translates low-dimensional geometric descriptors into manufacturable high-resolution structures through a hybrid evolutionary algorithm integrating NSGA-II selection, VAE-enabled latent space crossover, and a novel image deformation-based mutation operator. This gradient-free approach achieves efficient optimization while ensuring geometric continuity. Numerical results confirm that the method effectively balances efficiency and design flexibility, offering a scalable pathway for fabrication-aware multiscale structural optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08830v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuzhi Xu, Yifan Guo, Hiroki Kawabe, Kentaro Yaji</dc:creator>
    </item>
    <item>
      <title>Smooth Uncertainty Sets: Dependence of Uncertain Parameters via a Simple Polyhedral Set</title>
      <link>https://arxiv.org/abs/2510.08843</link>
      <description>arXiv:2510.08843v1 Announce Type: new 
Abstract: We propose a novel polyhedral uncertainty set for robust optimization, termed the smooth uncertainty set, which captures dependencies of uncertain parameters by constraining their pairwise differences. The bounds on these differences may be dictated by the underlying physics of the problem and may be expressed by domain experts. When correlations are available, the bounds can be set
  to ensure that the associated probabilistic constraints are satisfied for any given probability. We explore specialized solution methods for the resulting optimization problems, including compact reformulations that exploit special structures when
  they appear, a column generation algorithm, and a reformulation of the adversarial problem as a minimum-cost flow problem. Our numerical experiments, based on problems from literature, illustrate (i) that the performance of the smooth uncertainty set model solution is similar to that of the ellipsoidal uncertainty model solution, albeit, it is computed within significantly shorter running times, and (ii) our column-generation algorithm can outperform the classical cutting plane algorithm and dualized reformulation, respectively in terms of solution time and memory consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08843v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noam Goldberg, Michael Poss, Shimrit Shtern</dc:creator>
    </item>
    <item>
      <title>Optimal Control with Lyapunov Stability Guarantees for Space Applications</title>
      <link>https://arxiv.org/abs/2510.08854</link>
      <description>arXiv:2510.08854v1 Announce Type: new 
Abstract: This paper investigates the infinite horizon optimal control problem (OCP) for space applications characterized by nonlinear dynamics. The proposed approach divides the problem into a finite horizon OCP with a regularized terminal cost, guiding the system towards a terminal set, and an infinite horizon linear regulation phase within this set. This strategy guarantees global asymptotic stability under specific assumptions. Our method maintains the system's fully nonlinear dynamics until it reaches the terminal set, where the system dynamics is linearized. As the terminal set converges to the origin, the difference in optimal cost incurred reduces to zero, guaranteeing an efficient and stable solution. The approach is tested through simulations on three problems: spacecraft attitude control, rendezvous maneuver, and soft landing. In spacecraft attitude control, we focus on achieving precise orientation and stabilization. For rendezvous maneuvers, we address the navigation of a chaser to meet a target spacecraft. For the soft landing problem, we ensure a controlled descent and touchdown on a planetary surface. We provide numerical results confirming the effectiveness of the proposed method in managing these nonlinear dynamics problems, offering robust solutions essential for successful space missions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08854v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator> Abhijeet, Mohamed Naveed Gul Mohamed, Aayushman Sharma, Suman Chakravorty</dc:creator>
    </item>
    <item>
      <title>On the Strength of Linear Relaxations in Ordered Optimization</title>
      <link>https://arxiv.org/abs/2510.09166</link>
      <description>arXiv:2510.09166v1 Announce Type: new 
Abstract: We study the conditions under which the convex relaxation of a mixed-integer linear programming formulation for ordered optimization problems, where sorting is part of the decision process, yields integral optimal solutions. Thereby solving the problem exactly in polynomial time. Our analysis identifies structural properties of the input data that influence the integrality of the relaxation. We show that incorporating ordered components introduces additional layers of combinatorial complexity that invalidate the exactness observed in classical (non-ordered) settings. In particular, for certain ordered problems such as the min--max case, the linear relaxation never recovers the integral solution. These results clarify the intrinsic hardness introduced by sorting and reveal that the strength of the relaxation depends critically on the ``proximity'' of the ordered problem to its classical counterpart: problems closer to the non-ordered case tend to admit tighter relaxations, while those further away exhibit substantially weaker behavior. Computational experiments on benchmark instances confirm the predictive value of the integrality conditions and demonstrate the practical implications of exact relaxations for ordered location problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09166v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Diego Laborda, Miguel Mart\'inez-Ant\'on</dc:creator>
    </item>
    <item>
      <title>Directional Subdifferentials at Infinity and Its Applications</title>
      <link>https://arxiv.org/abs/2510.09179</link>
      <description>arXiv:2510.09179v1 Announce Type: new 
Abstract: This paper investigates the behavior of sets and functions at infinity by introducing new concepts, namely directional normal cones at infinity for unbounded sets, along with limiting and singular subdifferentials at infinity in the direction for extended real-valued functions. We develop several calculus rules for these concepts and then apply them to nonsmooth optimization problems. The applications include establishing directional optimality conditions at infinity, analyzing the coercivity, proving the compactness of the global solution set, and examining properties such as weak sharp minima and error bounds at infinity. To demonstrate the effectiveness of the proposed approach, illustrative examples are provided and compared with existing results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09179v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Le Ngoc Kien, Nguyen Van Tuyen, Tran Van Nghi</dc:creator>
    </item>
    <item>
      <title>What Are We Clustering For? Establishing Performance Guarantees for Time Series Aggregation in Generation Expansion Planning</title>
      <link>https://arxiv.org/abs/2510.09357</link>
      <description>arXiv:2510.09357v1 Announce Type: new 
Abstract: Generation expansion planning (GEP) is a prominent example of capacity expansion problems in operations research. Being generally NP-hard, GEP optimization models can become intractable when nonconvex dynamics, time-coupling constraints, and complex asset interactions are involved. Time series aggregation (TSA) tackles this by reducing temporal complexity via input data clustering. However, existing TSA methods either focus solely on preserving the statistical features of the input data, yielding heuristics without guarantees on the aggregated model's accuracy, or provide error bounds limited to linear models, neglecting time-coupling constraints and applying only to specific clustering techniques. Moreover, these bounds typically pertain solely to the GEP objective function and do not extend to other stakeholder-specific metrics, such as decision vector partitions. To tackle these issues, we demonstrate that an appropriately constructed aggregated model always provides a lower bound on the optimal objective function value of the full-scale GEP model in both mixed-integer linear and mixed-integer quadratic formulations with time-coupling, independent of the clustering technique employed. Building on this, we propose a performance-guaranteed TSA-based solution algorithm that iteratively refines objective function bounds while generating feasible solutions to the full-scale model at each iteration. We then discuss a comparison with Benders decomposition and demonstrate how the derived bounds can be extended to error estimates for stakeholder-specific metrics. Numerical results show the computational advantages of our method over both full-scale optimization and classical Benders decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09357v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Santosuosso, Bettina Klinz, Sonja Wogrin</dc:creator>
    </item>
    <item>
      <title>A Neural Surrogate-Enhanced Multi-Method Framework for Robust Wing Design Optimization</title>
      <link>https://arxiv.org/abs/2510.08582</link>
      <description>arXiv:2510.08582v1 Announce Type: cross 
Abstract: This paper introduces a modular and scalable design optimization framework for the wing design process that enables faster early-phase design while ensuring aerodynamic stability. The pipeline starts with the generation of initial wing geometries and then proceeds to optimize the wing using several algorithms. Aerodynamic performance is assessed using a Vortex Lattice Method (VLM) applied to a carefully selected dataset of wing configurations. These results are employed to develop surrogate neural network models, which can predict lift and drag rapidly and accurately. The stability evaluation is implemented by setting the control surfaces and components to fixed positions in order to have realistic flight dynamics. The approach unifies and compares several optimization techniques, including Particle Swarm Optimization (PSO), Genetic Algorithms (GA), gradient-based MultiStart methods, Bayesian optimization, and Lipschitz optimization. Each method ensures constraint management via adaptive strategies and penalty functions, where the targets for lift and design feasibility are enforced. The progression of aerodynamic characteristics and geometries over the optimization iterations will be investigated in order to clarify each algorithm's convergence characteristics and performance efficiency. Our results show improvement in aerodynamic qualities and robust stability properties, offering a mechanism for wing design at speed and precision. In the interest of reproducibility and community development, the complete implementation is publicly available at https://github.com/AmirHosseinGhaemi2000/CHIMERA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08582v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Fath Lipaei, AmirHossein Ghaemi, Melika Sabzikari</dc:creator>
    </item>
    <item>
      <title>Robust autobidding for noisy conversion prediction models</title>
      <link>https://arxiv.org/abs/2510.08788</link>
      <description>arXiv:2510.08788v1 Announce Type: cross 
Abstract: Managing millions of digital auctions is an essential task for modern advertising auction systems. The main approach to managing digital auctions is an autobidding approach, which depends on the Click-Through Rate and Conversion Rate values. While these quantities are estimated with ML models, their prediction uncertainty directly impacts advertisers' revenue and bidding strategies. To address this issue, we propose RobustBid, an efficient method for robust autobidding taking into account uncertainty in CTR and CVR predictions. Our approach leverages advanced, robust optimization techniques to prevent large errors in bids if the estimates of CTR/CVR are perturbed. We derive the analytical solution of the stated robust optimization problem, which leads to the runtime efficiency of the RobustBid method. The synthetic, iPinYou, and BAT benchmarks are used in our experimental evaluation of RobustBid. We compare our method with the non-robust baseline and the RiskBid algorithm in terms of total conversion volume (TCV) and average cost-per-click ($CPC_{avg}$) performance metrics. The experiments demonstrate that RobustBid provides bids that yield larger TCV and smaller $CPC_{avg}$ than competitors in the case of large perturbations in CTR/CVR predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08788v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrey Pudovikov, Alexandra Khirianova, Ekaterina Solodneva, Gleb Molodtsov, Aleksandr Katrutsa, Yuriy Dorn, Egor Samosvat</dc:creator>
    </item>
    <item>
      <title>A Frequency-Domain Analysis of the Multi-Armed Bandit Problem: A New Perspective on the Exploration-Exploitation Trade-off</title>
      <link>https://arxiv.org/abs/2510.08908</link>
      <description>arXiv:2510.08908v1 Announce Type: cross 
Abstract: The stochastic multi-armed bandit (MAB) problem is one of the most fundamental models in sequential decision-making, with the core challenge being the trade-off between exploration and exploitation. Although algorithms such as Upper Confidence Bound (UCB) and Thompson Sampling, along with their regret theories, are well-established, existing analyses primarily operate from a time-domain and cumulative regret perspective, struggling to characterize the dynamic nature of the learning process. This paper proposes a novel frequency-domain analysis framework, reformulating the bandit process as a signal processing problem. Within this framework, the reward estimate of each arm is viewed as a spectral component, with its uncertainty corresponding to the component's frequency, and the bandit algorithm is interpreted as an adaptive filter. We construct a formal Frequency-Domain Bandit Model and prove the main theorem: the confidence bound term in the UCB algorithm is equivalent in the frequency domain to a time-varying gain applied to uncertain spectral components, a gain inversely proportional to the square root of the visit count. Based on this, we further derive finite-time dynamic bounds concerning the exploration rate decay. This theory not only provides a novel and intuitive physical interpretation for classical algorithms but also lays a rigorous theoretical foundation for designing next-generation algorithms with adaptive parameter adjustment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08908v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence of optimizers implies eigenvalues filtering at equilibrium</title>
      <link>https://arxiv.org/abs/2510.09034</link>
      <description>arXiv:2510.09034v1 Announce Type: cross 
Abstract: Ample empirical evidence in deep neural network training suggests that a variety of optimizers tend to find nearly global optima. In this article, we adopt the reversed perspective that convergence to an arbitrary point is assumed rather than proven, focusing on the consequences of this assumption. From this viewpoint, in line with recent advances on the edge-of-stability phenomenon, we argue that different optimizers effectively act as eigenvalue filters determined by their hyperparameters. Specifically, the standard gradient descent method inherently avoids the sharpest minima, whereas Sharpness-Aware Minimization (SAM) algorithms go even further by actively favoring wider basins. Inspired by these insights, we propose two novel algorithms that exhibit enhanced eigenvalue filtering, effectively promoting wider minima. Our theoretical analysis leverages a generalized Hadamard--Perron stable manifold theorem and applies to general semialgebraic $C^2$ functions, without requiring additional non-degeneracy conditions or global Lipschitz bound assumptions. We support our conclusions with numerical experiments on feed-forward neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09034v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jerome Bolte (TSE-R), Quoc-Tung Le (UGA, LJK), Edouard Pauwels (TSE-R)</dc:creator>
    </item>
    <item>
      <title>Li-Yau-Hamilton Inequality on the JKO Scheme for the Granular-Medium Equation</title>
      <link>https://arxiv.org/abs/2510.09231</link>
      <description>arXiv:2510.09231v1 Announce Type: cross 
Abstract: We establish a version of the Li--Yau--Hamilton inequality for the Granular-Medium equation on the torus, both at the PDE level and for its time-discrete approximation given by the JKO scheme. We then apply this estimate to derive further quantitative results for the continuous and discrete JKO flows, including Lipschitz and $L^\infty$ bounds, as well as a quantitative Harnack inequality. Finally, we use the regularity provided by this estimate to show that the JKO scheme for the Fokker--Planck equation converges in $L^2_{\mathrm{loc}}((0,+\infty); H^2(\mathbb{T}^d))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09231v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fanch Coudreuse</dc:creator>
    </item>
    <item>
      <title>Characterizing Maximal Monotone Operators with Unique Representation</title>
      <link>https://arxiv.org/abs/2510.09368</link>
      <description>arXiv:2510.09368v1 Announce Type: cross 
Abstract: We study maximal monotone operators $A : X \rightrightarrows X^*$ whose Fitzpatrick family reduces to a singleton; such operators will be called uniquely representable. We show that every such operator is cyclically monotone (hence, $A=\partial f$ for some convex function $f$) if and only if it is 3-monotone. In Radon-Nikod\'{y}m spaces, under mild conditions (which become superfluous in finite dimensions), we prove that a subdifferential operator $A=\partial f$ is uniquely representable if and only if $f$ is the sum of a support and an indicator function of suitable convex sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09368v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sotiris Armeniakos, Aris Daniilidis</dc:creator>
    </item>
    <item>
      <title>Fast and robust parametric and functional learning with Hybrid Genetic Optimisation (HyGO)</title>
      <link>https://arxiv.org/abs/2510.09391</link>
      <description>arXiv:2510.09391v1 Announce Type: cross 
Abstract: The Hybrid Genetic Optimisation framework (HyGO) is introduced to meet the pressing need for efficient and unified optimisation frameworks that support both parametric and functional learning in complex engineering problems. Evolutionary algorithms are widely employed as derivative-free global optimisation methods but often suffer from slow convergence rates, especially during late-stage learning. HyGO integrates the global exploration capabilities of evolutionary algorithms with accelerated local search for robust solution refinement. The key enabler is a two-stage strategy that balances exploration and exploitation. For parametric problems, HyGO alternates between a genetic algorithm and targeted improvement through a degradation-proof Dowhill Simplex Method (DSM). For function optimisation tasks, HyGO rotates between genetic programming and DSM. Validation is performed on (a) parametric optimisation benchmarks, where HyGO demonstrates faster and more robust convergence than standard genetic algorithms, and (b) function optimisation tasks, including control of a damped Landau oscillator. Practical relevance is showcased through aerodynamic drag reduction of an Ahmed body via Reynolds-Averaged Navier-Stokes simulations, achieving consistently interpretable results and reductions exceeding 20% by controlled jet injection in the back of the body for flow reattachment and separation bubble reduction. Overall, HyGO emerges as a versatile hybrid optimisation framework suitable for a broad spectrum of engineering and scientific problems involving parametric and functional learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09391v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Isaac Robledo, Yiqing Li, Guy Y. Cornejo Maceda, Rodrigo Castellanos</dc:creator>
    </item>
    <item>
      <title>Multi-period Stochastic Network Design for Combined Natural Gas and Hydrogen Distribution</title>
      <link>https://arxiv.org/abs/2312.13388</link>
      <description>arXiv:2312.13388v4 Announce Type: replace 
Abstract: Hydrogen is produced from water using renewable electricity. Unlike electricity, hydrogen can be stored in large quantities for long periods. This storage ability acts as a green battery, allowing solar and wind energy to be generated and used at different times. As a result, green hydrogen plays a central role in facilitating a climate-neutral economy. However, the logistics for hydrogen are complex. As new pipelines are developed for hydrogen, there is a trend toward repurposing the natural gas network for hydrogen, due to its economic and environmental benefits. Yet, a rapid conversion could disrupt the balance of natural gas supply and demand. Furthermore, technical and economic developments surrounding the transition contribute additional complexity, which introduces uncertainty in future supply and demand levels for both commodities. To address these challenges, we introduce a multi-period stochastic network design problem for the transition of a natural gas pipeline network into a green hydrogen pipeline network. We develop a progressive-hedging-based metaheuristic to solve the problem. Results demonstrate our matheuristic is efficient, both in computation time and in solution quality. We show that factoring in uncertainty avoids premature expansion and ensures the development of an adequate pipeline network meeting long-term needs. In a case study in the Northern Netherlands for Hydrogen Energy Applications in Valley Environments for Northern Netherlands initiative, we focus on two key scenarios: local production and importation, exploring their impacts on performance indicators. Our case insights exemplify the solid foundation for strategic decision-making in energy transitions through our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13388v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umur Hasturk, Albert H. Schrotenboer, Kees Jan Roodbergen, Evrim Ursavas</dc:creator>
    </item>
    <item>
      <title>Existence and approximate controllability results for time-fractional stochastic Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2408.17173</link>
      <description>arXiv:2408.17173v3 Announce Type: replace 
Abstract: This paper deals with time-fractional stochastic Navier-Stokes equations, which are characterized by the coexistence of stochastic noise and a fractional power of the Laplacian. We establish sufficient conditions for the existence and approximate controllability of a unique mild solution to time-fractional stochastic Navier-Stokes equations. Using a fixed point technique, we first demonstrate the existence and uniqueness of a mild solution to the equation under consideration. We then establish approximate controllability results by using the concepts of fractional calculus, semigroup theory, functional analysis and stochastic analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17173v3</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renu Chaudhary, Simeon Reich, Juan J. Nieto</dc:creator>
    </item>
    <item>
      <title>Novel Numerical Method for Simultaneous Design and Control Optimization of Seasonal Thermal Energy Storage Systems</title>
      <link>https://arxiv.org/abs/2501.07427</link>
      <description>arXiv:2501.07427v2 Announce Type: replace 
Abstract: The transition to a carbon-neutral energy system requires widespread deployment of renewable energy sources and economically feasible energy storage solutions. This study presents a comprehensive optimization framework that jointly addresses the design and control of a nonlinear energy system supplying both heat and electricity to the Dietenbach district in Freiburg, Germany. The proposed system integrates solar and wind power with battery storage and seasonal thermal energy storage coupled via a heat pump, enhancing self-sufficiency and mitigating seasonal supply-demand mismatches. A multi-node lumped-parameter model captures heat transfer within the pit thermal energy storage, forming the basis of a periodic optimal control problem solved numerically. An averaging method reduces computation time by 80.5% while preserving fidelity for year-long optimization. A case study shows a projected total yearly energy cost of 5.93 EUR/m2 for combined heat and electricity, which is 73% lower than the German average. This study underscores the feasibility of designing economically viable, autonomous energy communities in real-world scenarios and provides an efficient, robust optimization framework for designing system components and operational control strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07427v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wonsun Song, Jakob Harzer, Christopher Jung, Leon Sander, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Major-Minor Mean Field Game of Stopping: An Entropy Regularization Approach</title>
      <link>https://arxiv.org/abs/2501.08770</link>
      <description>arXiv:2501.08770v2 Announce Type: replace 
Abstract: This paper studies a discrete-time major-minor mean field game of stopping where the major player can choose either an optimal control or stopping time. We look for the relaxed equilibrium as a randomized stopping policy, which is formulated as a fixed point of a set-valued mapping, whose existence is challenging by direct arguments. To overcome the difficulties caused by the presence of a major player, we propose to study an auxiliary problem by considering entropy regularization in the major player's problem while formulating the minor players' optimal stopping problems as linear programming over occupation measures. We first show the existence of regularized equilibria as fixed points of some simplified set-valued operator using the Kakutani-Fan-Glicksberg fixed-point theorem. Next, we prove that the regularized equilibrium converges as the regularization parameter $\lambda$ tends to 0, and the limit corresponds to a fixed point of the original operator, thereby confirming the existence of a relaxed equilibrium in the original mean field game problem. We also extend this entropy regularization method to the mean-field game problem where the minor players choose optimal controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08770v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Yu, Jiacheng Zhang, Keyu Zhang, Zhou Zhou</dc:creator>
    </item>
    <item>
      <title>Convergence of two-timescale gradient descent ascent dynamics: finite-dimensional and mean-field perspectives</title>
      <link>https://arxiv.org/abs/2501.17122</link>
      <description>arXiv:2501.17122v3 Announce Type: replace 
Abstract: The two-timescale gradient descent-ascent (GDA) is a canonical gradient algorithm designed to find Nash equilibria in min-max games. We analyze the two-timescale GDA by investigating the effects of learning rate ratios on convergence behavior in both finite-dimensional and mean-field settings. In particular, for finite-dimensional quadratic min-max games, we obtain long-time convergence in near quasi-static regimes through the hypocoercivity method. For mean-field GDA dynamics, we investigate convergence under a finite-scale ratio using a mixed synchronous-reflection coupling technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17122v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing An, Jianfeng Lu</dc:creator>
    </item>
    <item>
      <title>On the existence and the stability of solutions in nonconvex vector optimization</title>
      <link>https://arxiv.org/abs/2502.17974</link>
      <description>arXiv:2502.17974v2 Announce Type: replace 
Abstract: The paper is devoted to the existence of weak Pareto solutions and the weak sharp minima at infinity property for a general class of constrained nonconvex vector optimization problems with unbounded constraint set via asymptotic cones and generalized asymptotic functions. Then we show that these conditions are useful for studying the solution stability of nonconvex vector optimization problems with linear perturbation. We also provide some applications for a subclass of robustly quasiconvex vector optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17974v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10957-025-02831-0</arxiv:DOI>
      <arxiv:journal_reference>J. Optim. Theory Appl. 208:2 (2026)</arxiv:journal_reference>
      <dc:creator>Tran Van Nghi, Le Ngoc Kien, Nguyen Van Tuyen</dc:creator>
    </item>
    <item>
      <title>Safe and Optimal N-Spacecraft Swarm Reconfiguration in Non-Keplerian Cislunar Orbits</title>
      <link>https://arxiv.org/abs/2504.20386</link>
      <description>arXiv:2504.20386v2 Announce Type: replace 
Abstract: This paper presents a novel fuel-optimal guidance and control methodology for spacecraft swarm reconfiguration in Restricted Multi-Body Problems (RMBPs) with a guarantee of passive safety, maintaining miss distance even under abrupt loss of control authority. A new set of constraints exploits a quasi-periodic structure of RMBPs to guarantee passive safety. Particularly, the condition for passive safety is expressed as simple geometric constraints by solving optimal control in Local Toroidal Coordinates, which is based on a local eigenspace of a quasi-periodic motion around the corresponding periodic orbit. The proposed formulation enables a significant simplification of problem structure, which is applicable to large-scale swarm reconfiguration in cislunar orbits. The method is demonstrated in the Circular Restricted Three-Body Problem, the Elliptic Restricted Three-Body Problem, and the Bi-Circular Restricted Four-Body Problem. Furthermore, the optimized control profiles are validated in the full-ephemeris dynamics model. By extending and generalizing well-known concepts of relative orbital elements within the restricted two-body problem to the three- and four-body problems, this paper lays the foundation for practical control schemes of relative motion in cislunar space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20386v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuji Takubo, Walter Manuel, Ethan Foss, Simone D'Amico</dc:creator>
    </item>
    <item>
      <title>Convergence Rate for the Last Iterate of Stochastic Gradient Descent Schemes</title>
      <link>https://arxiv.org/abs/2507.07281</link>
      <description>arXiv:2507.07281v3 Announce Type: replace 
Abstract: We study the convergence rate for the last iterate of stochastic gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric setting when the objective function $F$ is globally convex or non-convex whose gradient is $\gamma$-H\"{o}lder. Using only discrete Gronwall's inequality without Robbins-Siegmund theorem, we recover results for both SGD and SHB: $\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$ for non-convex objectives and $F(w_{\tau \wedge t}) - F_* = o(t^{2\gamma/(1+\gamma) \cdot \max(p-1,-2p+1)-\eps})$ for $\beta \in (0, 1)$, $\tau := \inf \{ t &gt; 0 : F(w_t) = F_*\}$, and $\min_{s \leq t} F(w_s) - F_* = o(t^{p-1})$ for convex objectives $F$ whose minimum is $F_*$. In addition, we proved that SHB with constant momentum parameter $\beta \in (0, 1)$ attains a convergence rate of $F(w_t) - F_* = O(t^{\max(p-1,-2p+1)} \log^2 \frac{t}{\delta})$ with probability at least $1-\delta$ when $F$ is convex and $\gamma = 1$ and step size $\alpha_t = \Theta(t^{-p})$ with $p \in (\frac{1}{2}, 1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07281v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcel Hudiani</dc:creator>
    </item>
    <item>
      <title>A generalized Hurwitz stability criterion via rectangular block Hankel matrices for nonmonic matrix polynomials</title>
      <link>https://arxiv.org/abs/2508.14376</link>
      <description>arXiv:2508.14376v5 Announce Type: replace 
Abstract: We develop a Hurwitz stability criterion for nonmonic matrix polynomials via column reduction, generalizing existing approaches constrained by the monic assumption and thus serving as a more natural extension of Gantmacher's classical stability criterion via Markov parameters. Starting from redefining the associated Markov parameters through a column-wise adaptive splitting method, our framework constructs two structured matrices whose rectangular Hankel blocks are obtained via the extraction of these parameters. We establish an explicit interrelation between the inertias of column reduced matrix polynomials and the derived structured matrices. Furthermore, we demonstrate that the Hurwitz stability of column reduced matrix polynomials can be determined by the Hermitian positive definiteness of these rectangular block Hankel matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14376v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuzhou Zhan, Zixiang Ni</dc:creator>
    </item>
    <item>
      <title>Unifying HJB and Riccati equations: A Koopman operator approach to nonlinear optimal control</title>
      <link>https://arxiv.org/abs/2509.20122</link>
      <description>arXiv:2509.20122v2 Announce Type: replace 
Abstract: This paper proposes an operator-theoretic framework that recasts the minimal value function of a nonlinear optimal control problem as an abstract bilinear form on a suitable function space. The resulting bilinear form is shown to satisfy an operator equation with quadratic nonlinearity obtained by formulating the Lyapunov equation for a Koopman lift of the optimal closed-loop dynamics to an infinite-dimensional state space. It is proven that the minimal value function admits a rapidly convergent sum-of-squares expansion, a direct consequence of the fast spectral decay of the bilinear form. The framework thereby establishes a natural link between the Hamilton-Jacobi-Bellman and a Riccati-like operator equation and further motivates numerical low-rank schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20122v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Breiten, Bernhard H\"oveler</dc:creator>
    </item>
    <item>
      <title>An Augmented Lagrangian Value Function Method for Lower-level Constrained Stochastic Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2509.24249</link>
      <description>arXiv:2509.24249v2 Announce Type: replace 
Abstract: Recently, lower-level constrained bilevel optimization has attracted increasing attention. However, existing methods mostly focus on either deterministic cases or problems with linear constraints. The main challenge in stochastic cases with general constraints is the bias and variance of the hyper-gradient, arising from the inexact solution of the lower-level problem. In this paper, we propose a novel stochastic augmented Lagrangian value function method for solving stochastic bilevel optimization problems with nonlinear lower-level constraints. Our approach reformulates the original bilevel problem using an augmented Lagrangian-based value function and then applies a penalized stochastic gradient method that carefully manages the noise from stochastic oracles. We establish an equivalence between the stochastic single-level reformulation and the original constrained bilevel problem and provide a non-asymptotic rate of convergence for the proposed method. The rate is further enhanced by employing variance reduction techniques. Extensive experiments on synthetic problems and real-world applications demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24249v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hantao Nie, Jiaxiang Li, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Geometry of Distance Protection</title>
      <link>https://arxiv.org/abs/2510.04379</link>
      <description>arXiv:2510.04379v2 Announce Type: replace 
Abstract: Distance relays detect faults on transmission lines. They face uncertainty from the fault's location and resistance, as well as the current from the line's remote terminal. In this paper, we aggregate this uncertainty with the Minkowski sum. This allows us to explicitly model the power grid surrounding the relay's line, and in turn accommodate any mix of synchronous machines and inverter-based resources. To make the relay's task easier, inverters can inject perturbations, or auxiliary signals, such as negative-sequence current. We use Farkas' lemma to construct an optimization for designing inverter auxiliary signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04379v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josh A. Taylor, Alejandro D. Dom\'inguez-Garc\'ia</dc:creator>
    </item>
    <item>
      <title>Optimization via a Control-Centric Framework</title>
      <link>https://arxiv.org/abs/2510.05455</link>
      <description>arXiv:2510.05455v4 Announce Type: replace 
Abstract: Optimization plays a central role in intelligent systems and cyber-physical technologies, where speed and reliability of convergence directly impact performance. In control theory, optimization-centric methods are standard: controllers are designed by repeatedly solving optimization problems, as in linear quadratic regulation, $H_\infty$ control, and model predictive control. In contrast, this paper develops a control-centric framework for optimization itself, where algorithms are constructed directly from Lyapunov stability principles rather than being proposed first and analyzed afterward. A key element is the stationarity vector, which encodes first-order optimality conditions and enables Lyapunov-based convergence analysis. By pairing a Lyapunov function with a selectable decay law, we obtain continuous-time dynamics with guaranteed exponential, finite-time, fixed-time, or prescribed-time convergence. Within this framework, we introduce three feedback realizations of increasing restrictiveness: the Hessian-gradient, Newton, and gradient dynamics. Each realization shapes the decay of the stationarity vector to achieve the desired rate. These constructions unify unconstrained optimization, extend naturally to constrained problems via Lyapunov-consistent primal-dual dynamics, and broaden the results for minimax and generalized Nash equilibrium seeking problems beyond exponential stability. The framework provides systematic design tools for optimization algorithms in control and game-theoretic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05455v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liraz Mudrik, Isaac Kaminer, Sean Kragelund, Abram H. Clark</dc:creator>
    </item>
    <item>
      <title>From Contextual Data to Newsvendor Decisions: On the Actual Performance of Data-Driven Algorithms</title>
      <link>https://arxiv.org/abs/2302.08424</link>
      <description>arXiv:2302.08424v5 Announce Type: replace-cross 
Abstract: In this work, we study how the relevance/quality and quantity of past data influence performance by analyzing a contextual Newsvendor problem, in which a decision-maker trades off between underage and overage costs under uncertain demand. We consider a setting in which past demands observed under ``close by'' contexts come from close by distributions and analyze the performance of data-driven algorithms through a notion of context-dependent worst-case expected regret. We analyze the broad class of Weighted Empirical Risk Minimization (WERM) policies which weigh past data according to their similarity in the contextual space. This class includes classical policies such as ERM, k-Nearest Neighbors and kernel-based policies. Our main methodological contribution is to characterize exactly the worst-case regret of any WERM policy on any given configuration of contexts. To the best of our knowledge, this provides the first understanding of tight performance guarantees in any contextual decision-making problem, with past literature focusing on upper bounds via concentration inequalities. We instead take an optimization approach, and isolate a structure in the Newsvendor loss function that allows to reduce the infinite-dimensional optimization problem over worst-case distributions to a simple line search. This in turn allows us to unveil fundamental insights that were obfuscated by previous general-purpose bounds. We characterize actual guaranteed performance as a function of the contexts, as well as granular insights on the learning curve of algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08424v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Besbes, Will Ma, Omar Mouchtaki</dc:creator>
    </item>
    <item>
      <title>A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems</title>
      <link>https://arxiv.org/abs/2311.04014</link>
      <description>arXiv:2311.04014v4 Announce Type: replace-cross 
Abstract: This paper introduces a novel operator, termed the Y operator, to elevate control performance in Actor-Critic(AC) based reinforcement learning for systems governed by stochastic differential equations(SDEs). The Y operator ingeniously integrates the stochasticity of a class of child-mother system into the Critic network's loss function, yielding substantial advancements in the control performance of RL algorithms.Additionally, the Y operator elegantly reformulates the challenge of solving partial differential equations for the state-value function into a parallel problem for the drift and diffusion functions within the system's SDEs.A rigorous mathematical proof confirms the operator's validity.This transformation enables the Y Operator-based Reinforcement Learning(YORL) framework to efficiently tackle optimal control problems in both model-based and data-driven systems.The superiority of YORL is demonstrated through linear and nonlinear numerical examples showing its enhanced performance over existing methods post convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04014v4</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Yin, Yi Chen</dc:creator>
    </item>
    <item>
      <title>On the Interpolation Effect of Score Smoothing in Diffusion Models</title>
      <link>https://arxiv.org/abs/2502.19499</link>
      <description>arXiv:2502.19499v2 Announce Type: replace-cross 
Abstract: Score-based diffusion models have achieved remarkable progress in various domains with the ability to generate new data samples that do not exist in the training set. In this work, we study the hypothesis that such creativity arises from an interpolation effect caused by a smoothing of the empirical score function. Focusing on settings where the training set lies uniformly in a one-dimensional subspace, we show theoretically how regularized two-layer ReLU neural networks tend to learn approximately a smoothed version of the empirical score function, and further probe the interplay between score smoothing and the denoising dynamics with analytical solutions and numerical experiments. In particular, we demonstrate how a smoothed score function can lead to the generation of samples that interpolate the training data along their subspace while avoiding full memorization. Moreover, we present experimental evidence that learning score functions with neural networks indeed induces a score smoothing effect, including in simple nonlinear settings and without explicit regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19499v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengdao Chen</dc:creator>
    </item>
    <item>
      <title>Hierarchical Analysis and Control of Epidemic Spreading over Networks using Dissipativity and Mesh Stability</title>
      <link>https://arxiv.org/abs/2509.24665</link>
      <description>arXiv:2509.24665v3 Announce Type: replace-cross 
Abstract: Analyzing and controlling spreading processes are challenging problems due to the involved non-linear node (subsystem) dynamics, unknown disturbances, complex interconnections, and the large-scale and multi-level nature of the problems. The dissipativity concept provides a practical framework for addressing such concerns, thanks to the energy-based representation it offers for subsystems and the compositional properties it provides for the analysis and control of interconnected (networked) systems comprised of such subsystems. Therefore, in this paper, we utilize the dissipativity concept to analyze and control a spreading process that occurs over a hierarchy of nodes, groups, and a network (i.e., a spreading network). We start by generalizing several existing results on dissipativity-based topology design for networked systems. Next, we model the considered spreading network as a networked system and establish the dissipativity properties of its nodes. The generalized topology design method is then applied at multiple levels of the considered spreading network to formulate its analysis and control problems as Linear Matrix Inequality (LMI) problems. We identify and enforce localized necessary conditions to support the feasibility of the LMI problem solved at each subsequent hierarchical level of the spreading network. Consequently, the proposed method does not involve iterative multi-level optimization stages that are computationally inefficient. The proposed control solution ensures that the spreading network is not only stable but also dissipative and mesh-stable. Compared to conventional methods, such as threshold pruning and high-degree edge removal, our approach offers superior performance in terms of infection containment, control efficiency, and disturbance robustness. Extensive numerical results demonstrate the effectiveness of the proposed technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24665v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shirantha Welikala, Hai Lin, Panos J. Antsaklis</dc:creator>
    </item>
    <item>
      <title>On the optimization dynamics of RLVR: Gradient gap and step size thresholds</title>
      <link>https://arxiv.org/abs/2510.08539</link>
      <description>arXiv:2510.08539v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), which uses simple binary feedback to post-train large language models, has shown significant empirical success. However, a principled understanding of why it works has been lacking. This paper builds a theoretical foundation for RLVR by analyzing its training process at both the full-response (trajectory) and token levels. Central to our analysis is a quantity called the Gradient Gap, which formalizes the direction of improvement from low-reward to high-reward regions of the response space. We prove that convergence critically depends on aligning the update direction with this Gradient Gap. Moreover, we derive a sharp step-size threshold based on the magnitude of the Gradient Gap: below it, learning converges, whereas above it, performance collapses. Our theory further predicts how the critical step size must scale with response length and the success rate, thereby explaining why practical heuristics such as length normalization improve stability and showing that, with a fixed learning rate, the success rate can stagnate strictly below $100\%$. We validate these predictions through controlled bandit simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08539v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 13 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joe Suk, Yaqi Duan</dc:creator>
    </item>
  </channel>
</rss>
