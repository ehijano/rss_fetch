<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Oct 2025 01:41:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models</title>
      <link>https://arxiv.org/abs/2510.24242</link>
      <description>arXiv:2510.24242v1 Announce Type: new 
Abstract: Large vision-language models (LVLMs) have recently demonstrated great potential in remote sensing (RS) tasks (e.g., disaster monitoring) conducted by low Earth orbit (LEO) satellites. However, their deployment in real-world LEO satellite systems remains largely unexplored, hindered by limited onboard computing resources and brief satellite-ground contacts. We propose Grace, a satellite-ground collaborative system designed for near-realtime LVLM inference in RS tasks. Accordingly, we deploy compact LVLM on satellites for realtime inference, but larger ones on ground stations (GSs) to guarantee end-to-end performance. Grace is comprised of two main phases that are asynchronous satellite-GS Retrieval-Augmented Generation (RAG), and a task dispatch algorithm. Firstly, we still the knowledge archive of GS RAG to satellite archive with tailored adaptive update algorithm during limited satellite-ground data exchange period. Secondly, propose a confidence-based test algorithm that either processes the task onboard the satellite or offloads it to the GS. Extensive experiments based on real-world satellite orbital data show that Grace reduces the average latency by 76-95% compared to state-of-the-art methods, without compromising inference accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24242v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihan Li, Jiahao Yang, Yuxin Zhang, Zhe Chen, Yue Gao</dc:creator>
    </item>
    <item>
      <title>A New Hybrid Precoding Approach for Multi-user Massive MIMO over Fading Channels</title>
      <link>https://arxiv.org/abs/2510.24595</link>
      <description>arXiv:2510.24595v1 Announce Type: new 
Abstract: Hybrid precoding is an indispensable technique to harness the full potential of a multi-user massive multiple-input, multiple-output (MU-MMIMO) system. In this paper, we propose a new hybrid precoding approach that combines digital and analog precoding to optimize data transmission over multiple antennas. This approach steers signals in specific directions, leading to maximizing sum-rate and suppressing side-lobe interference. When dealing with complex signals, changes in phase are naturally associated with changes in angle, and these variations are inherently correlated. The correlation between the angle and phase is essential for accurately determining the channel characteristics. An important aspect of this approach is that we model the angle and phase as correlated variables following a bivariate Gaussian distribution, and for the first time, we define a joint angle and phase entropy to measure the uncertainty of angle and phase variations in wireless channels. This entropy is crucial to adapt the proposed precoding method with variations. Simulation result validate the accuracy of our analytical findings, demonstrating 18.31% increase in sum-rate and an 11.47% improvement in robustness compared to other state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24595v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azadeh Pourkabirian, Kai Li, Photios A. Stavrou, Wei Ni</dc:creator>
    </item>
    <item>
      <title>Strategic Task Offloading for Delay-Sensitive IoT Applications: A Game-Theory-Based Demand-Supply Mechanism with Participation Incentives</title>
      <link>https://arxiv.org/abs/2510.24611</link>
      <description>arXiv:2510.24611v1 Announce Type: new 
Abstract: Delay-sensitive Internet of Things (IoT) applications have drawn significant attention. Running many of these applications on IoT devices is challenging due to the limited processing resources of these devices and the need for real-time responses. Task offloading can minimize latency by transferring computationally intensive tasks from IoT devices to resource-rich edge servers, ensuring delay and performance guarantees. In this paper, we develop a task-offloading approach for delay-sensitive IoT applications in edge computing environments. Unlike existing schemes, we model the task offloading problem as an economic demand and supply model to achieve market balance. The proposed model avoids under- and over-supply, ensuring the computational resources at edge servers (supply) are allocated in a manner that best meets the processing and computational needs of user devices (demand). Given the multi-agent nature of task offloading involving users and service providers with different preferences and objectives, we design a game-theoretic framework using a Vickrey-Clarke-Groves (VCG) auction. This framework analyzes agent interactions and decision-making processes. Additionally, we develop an incentive mechanism to encourage both parties to participate in the auction. The mechanism maximizes user task offloading to edge servers and motivates edge servers to share their computational resources, achieving profitability for both IoT users and edge servers. Simulations demonstrate our method maximizes social welfare, ensures truthfulness, maintains market balance, and provides latency guarantees for delay-sensitive IoT applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24611v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azadeh Pourkabirian, Amir Masoud Rahmani, Kai Li, Wei Ni</dc:creator>
    </item>
    <item>
      <title>Uncovering Gaps Between RFC Updates and TCP/IP Implementations: LLM-Facilitated Differential Checks on Intermediate Representations</title>
      <link>https://arxiv.org/abs/2510.24408</link>
      <description>arXiv:2510.24408v1 Announce Type: cross 
Abstract: As the core of the Internet infrastructure, the TCP/IP protocol stack undertakes the task of network data transmission. However, due to the complexity of the protocol and the uncertainty of cross-layer interaction, there are often inconsistencies between the implementation of the protocol stack code and the RFC standard. This inconsistency may not only lead to differences in protocol functions but also cause serious security vulnerabilities. At present, with the continuous expansion of protocol stack functions and the rapid iteration of RFC documents, it is increasingly important to detect and fix these inconsistencies. With the rise of large language models, researchers have begun to explore how to extract protocol specifications from RFC documents through these models, including protocol stack modeling, state machine extraction, text ambiguity analysis, and other related content. However, existing methods rely on predefined patterns or rule-based approaches that fail to generalize across different protocol specifications. Automated and scalable detection of these inconsistencies remains a significant challenge. In this study, we propose an automated analysis framework based on LLM and differential models. By modeling the iterative relationship of the protocol and based on the iterative update relationship of the RFC standard, we perform incremental code function analysis on different versions of kernel code implementations to automatically perform code detection and vulnerability analysis. We conduct extensive evaluations to validate the effectiveness of our framework, demonstrating its effectiveness in identifying potential vulnerabilities caused by RFC code inconsistencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24408v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wu, Xuewei Feng, Yuxiang Yang, Ke Xu</dc:creator>
    </item>
    <item>
      <title>Fair Ordering</title>
      <link>https://arxiv.org/abs/2510.13664</link>
      <description>arXiv:2510.13664v2 Announce Type: replace 
Abstract: A growing class of applications demands \emph{fair ordering/sequencing} of events which ensures that events generated earlier by one client are processed before later events from other clients. However, achieving such sequencing is fundamentally challenging due to the inherent limitations of clock synchronization. We advocate for an approach that embraces, rather than eliminates, clock variability. Instead of attempting to remove error from a timestamp, Tommy, our proposed system, leverages a statistical model to compare two noisy timestamps probabilistically by learning per-clock offset distributions. Our preliminary statistical model computes the probability that one event precedes another w.r.t. the wall-clock time without access to the wall-clock. This serves as a foundation for a new relation: \emph{likely-happened-before} denoted by $\xrightarrow{p}$ where $p$ represents the probability of an event to have happened before another. The $\xrightarrow{p}$ relation provides a basis for ordering multiple events which are otherwise considered \emph{concurrent} by the typical \emph{happened-before} ($\rightarrow$) relation. We highlight various related challenges including intransitivity of $\xrightarrow{p}$ relation as opposed to the transitive $\rightarrow$ relation. We also outline several research directions: online fair sequencing, stochastically fair total ordering, host-level support for fairness and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13664v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Haseeb, Jinkun Geng, Radhika Mittal, Aurojit Panda, Srinivas Narayana, Anirudh Sivaraman</dc:creator>
    </item>
    <item>
      <title>PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM</title>
      <link>https://arxiv.org/abs/2509.24085</link>
      <description>arXiv:2509.24085v2 Announce Type: replace-cross 
Abstract: We present PEARL (Peer-Enhanced Adaptive Radio via On-Device LLM), a framework for cooperative cross-layer optimization in device-to-device (D2D) communication. Building on our previous work on single-device on-device LLMs, PEARL extends the paradigm by leveraging both publisher and subscriber states to guide Wi-Fi Aware (WA) parameter selection. A context-aware reward, which normalizes latency by application tolerances and modulates energy by device battery states, provides richer supervision for KL-based finetuning. We study two lightweight variants: PEARL (Head + Low-Rank Adaptation (LoRA)) achieves the best overall performance, while PEARL-Lite (Head-only) delivers sub-20 ms inference at near-identical objective scores. Across synthetic scenarios grounded in real measurements, PEARL improves objective scores over heuristic and compact model baselines and reduces energy by up to 16% in cooperative low-battery cases. These results demonstrate that peer-aware context, reward-aligned training, and head-based efficiency make LLMs practical for always-on, on-device cross-layer control. Code, real-world demo, and dataset are available at https://github.com/abman23/pearl</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24085v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ju-Hyung Lee, Yanqing Lu, Klaus Doppler</dc:creator>
    </item>
  </channel>
</rss>
