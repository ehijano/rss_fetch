<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 May 2024 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Selecting focused digital cohorts from social media using the metric backbone of biomedical knowledge graphs</title>
      <link>https://arxiv.org/abs/2405.07072</link>
      <description>arXiv:2405.07072v1 Announce Type: new 
Abstract: The abundance of social media data allows researchers to construct large digital cohorts to study the interplay between human behavior and medical treatment. Identifying the users most relevant to a specific health problem is, however, a challenge in that social media sites vary in the generality of their discourse. While X (formerly Twitter), Instagram, and Facebook cater to wide ranging topics, Reddit subgroups and dedicated patient advocacy forums trade in much more specific, biomedically-relevant discourse. To hone in on relevant users anywhere, we have developed a general framework and applied it to epilepsy discourse in social media as a test case. We analyzed the text from posts by users who mention epilepsy drugs in the general-purpose social media sites X and Instagram, the epilepsy-focused Reddit subgroup (r/Epilepsy), and the Epilepsy Foundation of America (EFA) forums. We curated a medical terms dictionary and used it to generate a knowledge graph (KG) for each online community. For each KG, we computed the metric backbone--the smallest subgraph that preserves all shortest paths in the network. By comparing the subset of users who contribute to the backbone to the subset who do not, we found that epilepsy-focused social media users contribute to the KG backbone in much higher proportion than do general-purpose social media users. Furthermore, using human annotation of Instagram posts, we demonstrated that users who do not contribute to the backbone are more than twice as likely to use dictionary terms in a manner inconsistent with their biomedical meaning. For biomedical research applications, our backbone-based approach thus has several benefits over simple engagement-based approaches: It can retain low-engagement users who nonetheless contribute meaningful biomedical insights. It can filter out very vocal users who contribute no relevant content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07072v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ziqi Guo, Jack Felag, Jordan C. Rozum, Rion Brattig Correia, Luis M. Rocha</dc:creator>
    </item>
    <item>
      <title>Multi-Relational Structural Entropy</title>
      <link>https://arxiv.org/abs/2405.07096</link>
      <description>arXiv:2405.07096v1 Announce Type: new 
Abstract: Structural Entropy (SE) measures the structural information contained in a graph. Minimizing or maximizing SE helps to reveal or obscure the intrinsic structural patterns underlying graphs in an interpretable manner, finding applications in various tasks driven by networked data. However, SE ignores the heterogeneity inherent in the graph relations, which is ubiquitous in modern networks. In this work, we extend SE to consider heterogeneous relations and propose the first metric for multi-relational graph structural information, namely, Multi-relational Structural Entropy (MrSE). To this end, we first cast SE through the novel lens of the stationary distribution from random surfing, which readily extends to multi-relational networks by considering the choices of both nodes and relation types simultaneously at each step. The resulting MrSE is then optimized by a new greedy algorithm to reveal the essential structures within a multi-relational network. Experimental results highlight that the proposed MrSE offers a more insightful interpretation of the structure of multi-relational graphs compared to SE. Additionally, it enhances the performance of two tasks that involve real-world multi-relational graphs, including node clustering and social event detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07096v1</guid>
      <category>cs.SI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwei Cao, Hao Peng, Angsheng Li, Chenyu You, Zhifeng Hao, Philip S Yu</dc:creator>
    </item>
    <item>
      <title>Mining Influential Spreaders in Complex Networks by an Effective Combination of the Degree and K-Shell</title>
      <link>https://arxiv.org/abs/2405.07277</link>
      <description>arXiv:2405.07277v1 Announce Type: new 
Abstract: Graph mining is an important technique that used in many applications such as predicting and understanding behaviors and information dissemination within networks. One crucial aspect of graph mining is the identification and ranking of influential nodes, which has applications in various fields including marketing, social communications, and disease control. However, existing models and methods come with high computational complexity and may not accurately distinguish and identify influential nodes. This paper develops a method based on the k-shell index and degree centrality of nodes and their neighbors. Comparisons to previous works, such as Degree and Neighborhood information Centrality (DNC) and Neighborhood and Path Information Centrality (NPIC), are conducted. The evaluations, which include the correctness with Kendall's Tau, resolution with monotonicity index, correlation plots, and time complexity, demonstrate its superior results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07277v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/AISP61396.2024.10475308</arxiv:DOI>
      <dc:creator>Shima Esfandiari, Seyed Mostafa Fakhrahmad</dc:creator>
    </item>
    <item>
      <title>Identifying Hate Speech Peddlers in Online Platforms. A Bayesian Social Learning Approach for Large Language Model Driven Decision-Makers</title>
      <link>https://arxiv.org/abs/2405.07417</link>
      <description>arXiv:2405.07417v1 Announce Type: new 
Abstract: This paper studies the problem of autonomous agents performing Bayesian social learning for sequential detection when the observations of the state belong to a high-dimensional space and are expensive to analyze. Specifically, when the observations are textual, the Bayesian agent can use a large language model (LLM) as a map to get a low-dimensional private observation. The agent performs Bayesian learning and takes an action that minimizes the expected cost and is visible to subsequent agents. We prove that a sequence of such Bayesian agents herd in finite time to the public belief and take the same action disregarding the private observations. We propose a stopping time formulation for quickest time herding in social learning and optimally balance privacy and herding. Structural results are shown on the threshold nature of the optimal policy to the stopping time problem. We illustrate the application of our framework when autonomous Bayesian detectors aim to sequentially identify if a user is a hate speech peddler on an online platform by parsing text observations using an LLM. We numerically validate our results on real-world hate speech datasets. We show that autonomous Bayesian agents designed to flag hate speech peddlers in online platforms herd and misclassify the users when the public prior is strong. We also numerically show the effect of a threshold policy in delaying herding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07417v1</guid>
      <category>cs.SI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adit Jain, Vikram Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>Can LLMs Help Predict Elections? (Counter)Evidence from the World's Largest Democracy</title>
      <link>https://arxiv.org/abs/2405.07828</link>
      <description>arXiv:2405.07828v1 Announce Type: new 
Abstract: The study of how social media affects the formation of public opinion and its influence on political results has been a popular field of inquiry. However, current approaches frequently offer a limited comprehension of the complex political phenomena, yielding inconsistent outcomes. In this work, we introduce a new method: harnessing the capabilities of Large Language Models (LLMs) to examine social media data and forecast election outcomes. Our research diverges from traditional methodologies in two crucial respects. First, we utilize the sophisticated capabilities of foundational LLMs, which can comprehend the complex linguistic subtleties and contextual details present in social media data. Second, we focus on data from X (Twitter) in India to predict state assembly election outcomes. Our method entails sentiment analysis of election-related tweets through LLMs to forecast the actual election results, and we demonstrate the superiority of our LLM-based method against more traditional exit and opinion polls. Overall, our research offers valuable insights into the unique dynamics of Indian politics and the remarkable impact of social media in molding public attitudes within this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07828v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pratik Gujral, Kshitij Awaldhi, Navya Jain, Bhavuk Bhandula, Abhijnan Chakraborty</dc:creator>
    </item>
    <item>
      <title>Exploring Social Media Posts for Depression Identification: A Study on Reddit Dataset</title>
      <link>https://arxiv.org/abs/2405.06656</link>
      <description>arXiv:2405.06656v1 Announce Type: cross 
Abstract: Depression is one of the most common mental disorders affecting an individual's personal and professional life. In this work, we investigated the possibility of utilizing social media posts to identify depression in individuals. To achieve this goal, we conducted a preliminary study where we extracted and analyzed the top Reddit posts made in 2022 from depression-related forums. The collected data were labeled as depressive and non-depressive using UMLS Metathesaurus. Further, the pre-processed data were fed to classical machine learning models, where we achieved an accuracy of 92.28\% in predicting the depressive and non-depressive posts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06656v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nandigramam Sai Harshit, Nilesh Kumar Sahu, Haroon R. Lone</dc:creator>
    </item>
    <item>
      <title>Exposing and Explaining Fake News On-the-Fly</title>
      <link>https://arxiv.org/abs/2405.06668</link>
      <description>arXiv:2405.06668v1 Announce Type: cross 
Abstract: Social media platforms enable the rapid dissemination and consumption of information. However, users instantly consume such content regardless of the reliability of the shared data. Consequently, the latter crowdsourcing model is exposed to manipulation. This work contributes with an explainable and online classification method to recognize fake news in real-time. The proposed method combines both unsupervised and supervised Machine Learning approaches with online created lexica. The profiling is built using creator-, content- and context-based features using Natural Language Processing techniques. The explainable classification mechanism displays in a dashboard the features selected for classification and the prediction confidence. The performance of the proposed solution has been validated with real data sets from Twitter and the results attain 80 % accuracy and macro F-measure. This proposal is the first to jointly provide data stream processing, profiling, classification and explainability. Ultimately, the proposed early detection, isolation and explanation of fake news contribute to increase the quality and trustworthiness of social media contents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06668v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10994-024-06527-w</arxiv:DOI>
      <arxiv:journal_reference>Mach Learn (2024)</arxiv:journal_reference>
      <dc:creator>Francisco de Arriba-P\'erez, Silvia Garc\'ia-M\'endez, F\'atima Leal, Benedita Malheiro, Juan Carlos Burguillo</dc:creator>
    </item>
    <item>
      <title>QuakeBERT: Accurate Classification of Social Media Texts for Rapid Earthquake Impact Assessment</title>
      <link>https://arxiv.org/abs/2405.06684</link>
      <description>arXiv:2405.06684v1 Announce Type: cross 
Abstract: Social media aids disaster response but suffers from noise, hindering accurate impact assessment and decision making for resilient cities, which few studies considered. To address the problem, this study proposes the first domain-specific LLM model and an integrated method for rapid earthquake impact assessment. First, a few categories are introduced to classify and filter microblogs considering their relationship to the physical and social impacts of earthquakes, and a dataset comprising 7282 earthquake-related microblogs from twenty earthquakes in different locations is developed as well. Then, with a systematic analysis of various influential factors, QuakeBERT, a domain-specific large language model (LLM), is developed and fine-tuned for accurate classification and filtering of microblogs. Meanwhile, an integrated method integrating public opinion trend analysis, sentiment analysis, and keyword-based physical impact quantification is introduced to assess both the physical and social impacts of earthquakes based on social media texts. Experiments show that data diversity and data volume dominate the performance of QuakeBERT and increase the macro average F1 score by 27%, while the best classification model QuakeBERT outperforms the CNN- or RNN-based models by improving the macro average F1 score from 60.87% to 84.33%. Finally, the proposed approach is applied to assess two earthquakes with the same magnitude and focal depth. Results show that the proposed approach can effectively enhance the impact assessment process by accurate detection of noisy microblogs, which enables effective post-disaster emergency responses to create more resilient cities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06684v1</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jin Han, Zhe Zheng, Xin-Zheng Lu, Ke-Yin Chen, Jia-Rui Lin</dc:creator>
    </item>
    <item>
      <title>Improved bounds for polylogarithmic graph distances in scale-free percolation and related models</title>
      <link>https://arxiv.org/abs/2405.07217</link>
      <description>arXiv:2405.07217v1 Announce Type: cross 
Abstract: In this paper, we study graph distances in the geometric random graph models scale-free percolation SFP, geometric inhomogeneous random graphs GIRG, and hyperbolic random graphs HRG. Despite the wide success of the models, the parameter regime in which graph distances are polylogarithmic is poorly understood. We provide new and improved lower bounds. In a certain portion of the parameter regime, those match the known upper bounds.
  Compared to the best previous lower bounds by Hao and Heydenreich, our result has several advantages: it gives matching bounds for a larger range of parameters, thus settling the question for a larger portion of the parameter space. It strictly improves the lower bounds by Hao and Heydenreich for all parameters settings in which those bounds were not tight. It gives tail bounds on the probability of having short paths, which imply shape theorems for the $k$-neighbourhood of a vertex whenever our lower bounds are tight, and tight bounds for the size of this $k$-neighbourhood. And last but not least, our proof is much simpler and not much longer than two pages, and we demonstrate that it generalizes well by showing that the same technique also works for first passage percolation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07217v1</guid>
      <category>math.PR</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kostas Lakis, Johannes Lengler, Kalina Petrova, Leon Schiller</dc:creator>
    </item>
    <item>
      <title>Is it getting harder to make a hit? Evidence from 65 years of US music chart history</title>
      <link>https://arxiv.org/abs/2405.07574</link>
      <description>arXiv:2405.07574v1 Announce Type: cross 
Abstract: Since the creation of the Billboard Hot 100 music chart in 1958, the chart has been a window into the music consumption of Americans. Which songs succeed on the chart is decided by consumption volumes, which can be affected by consumer music taste, and other factors such as advertisement budgets, airplay time, the specifics of ranking algorithms, and more. Since its introduction, the chart has documented music consumerism through eras of globalization, economic growth, and the emergence of new technologies for music listening. In recent years, musicians and other hitmakers have voiced their worry that the music world is changing: Many claim that it is getting harder to make a hit but until now, the claims have not been backed using chart data. Here we show that the dynamics of the Billboard Hot 100 chart have changed significantly since the chart's founding in 1958, and in particular in the past 15 years. Whereas most songs spend less time on the chart now than songs did in the past, we show that top-1 songs have tripled their chart lifetime since the 1960s, the highest-ranked songs maintain their positions for far longer than previously, and the lowest-ranked songs are replaced more frequently than ever. At the same time, who occupies the chart has also changed over the years: In recent years, fewer new artists make it into the chart and more positions are occupied by established hit makers. Finally, investigating how song chart trajectories have changed over time, we show that historical song trajectories cluster into clear trajectory archetypes characteristic of the time period they were part of. The results are interesting in the context of collective attention: Whereas recent studies have documented that other cultural products such as books, news, and movies fade in popularity quicker in recent years, music hits seem to last longer now than in the past.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07574v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marta Ewa Lech, Sune Lehmann, Jonas L. Juul</dc:creator>
    </item>
    <item>
      <title>LGDE: Local Graph-based Dictionary Expansion</title>
      <link>https://arxiv.org/abs/2405.07764</link>
      <description>arXiv:2405.07764v1 Announce Type: cross 
Abstract: Expanding a dictionary of pre-selected keywords is crucial for tasks in information retrieval, such as database query and online data collection. Here we propose Local Graph-based Dictionary Expansion (LGDE), a method that uses tools from manifold learning and network science for the data-driven discovery of keywords starting from a seed dictionary. At the heart of LGDE lies the creation of a word similarity graph derived from word embeddings and the application of local community detection based on graph diffusion to discover semantic neighbourhoods of pre-defined seed keywords. The diffusion in the local graph manifold allows the exploration of the complex nonlinear geometry of word embeddings and can capture word similarities based on paths of semantic association. We validate our method on a corpus of hate speech-related posts from Reddit and Gab and show that LGDE enriches the list of keywords and achieves significantly better performance than threshold methods based on direct word similarities. We further demonstrate the potential of our method through a real-world use case from communication science, where LGDE is evaluated quantitatively on data collected and analysed by domain experts by expanding a conspiracy-related dictionary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07764v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik J. Schindler, Sneha Jha, Xixuan Zhang, Kilian Buehling, Annett Heft, Mauricio Barahona</dc:creator>
    </item>
    <item>
      <title>Optimal accuracy for linear sets of equations with the graph Laplacian</title>
      <link>https://arxiv.org/abs/2405.07877</link>
      <description>arXiv:2405.07877v1 Announce Type: cross 
Abstract: We show that certain Graph Laplacian linear sets of equations exhibit optimal accuracy, guaranteeing that the relative error is no larger than the norm of the relative residual and that optimality occurs for carefully chosen right-hand sides. Such sets of equations arise in PageRank and Markov chain theory. We establish new relationships among the PageRank teleportation parameter, the Markov chain discount, and approximations to linear sets of equations. The set of optimally accurate systems can be separated into two groups for an undirected graph -- those that achieve optimality asymptotically with the graph size and those that do not -- determined by the angle between the right-hand side of the linear system and the vector of all ones. We provide supporting numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07877v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard B. Lehoucq, Michael Weylandt, Jonathan W. Berry</dc:creator>
    </item>
    <item>
      <title>Patterns of Patterns II</title>
      <link>https://arxiv.org/abs/2306.08426</link>
      <description>arXiv:2306.08426v3 Announce Type: replace 
Abstract: Our earlier paper "Patterns of Patterns" combined three techniques from training, futures studies, and design in a design pattern called PLACARD that helps groups of people work together effectively. We used that pattern in five hands-on workshop case studies which took place at various locations in the US and the UK. This experience report documents what we learned, including the way our thinking about PLACARD evolved, together with additional patterns our work generated. We evaluate the reproducibility of our methods and results, and consider the broader economic implications of this way of working. We discuss implications of our prototyping work for the design of future platforms, drawing connections with recent developments in cognitive science and artificial intelligence. This positions our patterns of patterns as a toolkit for the design and governance of systems that combine social dynamics with technical components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08426v3</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Joseph Corneli, Noorah Alhasan, Leo Vivier, Alex Murphy, Raymond S. Puzio, Abby Tabor, Sridevi Ayloo, Charlotte Pierce, Charles J. Danoff, Mary Tedeschi, Manvinder Singh, Kajol Khetan</dc:creator>
    </item>
    <item>
      <title>Precise influence evaluation in complex networks</title>
      <link>https://arxiv.org/abs/2310.12181</link>
      <description>arXiv:2310.12181v2 Announce Type: replace 
Abstract: Evaluating node influence is fundamental for identifying key nodes in complex networks. Existing methods typically rely on generic indicators to rank node influence across diverse networks, thereby ignoring the individualized features of each network itself. Actually, node influence stems not only from general features but the multi-scale individualized information encompassing specific network structure and task. Here we design an active learning architecture to predict node influence quantitively and precisely, which samples representative nodes based on graph entropy correlation matrix integrating multi-scale individualized information. This brings two intuitive advantages: (1) discovering potential high-influence but weak-connected nodes that are usually ignored in existing methods, (2) improving the influence maximization strategy by deducing influence interference. Significantly, our architecture demonstrates exceptional transfer learning capabilities across multiple types of networks, which can identify those key nodes with large disputation across different existing methods. Additionally, our approach, combined with a simple greedy algorithm, exhibits dominant performance in solving the influence maximization problem. This architecture holds great potential for applications in graph mining and prediction tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12181v2</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingyu Zhu, Qingyun Sun, Jianxin Li, Daqing Li</dc:creator>
    </item>
    <item>
      <title>Social Learning in Community Structured Graphs</title>
      <link>https://arxiv.org/abs/2312.12186</link>
      <description>arXiv:2312.12186v3 Announce Type: replace 
Abstract: Traditional social learning frameworks consider environments with a homogeneous state, where each agent receives observations conditioned on that true state of nature. In this work, we relax this assumption and study the distributed hypothesis testing problem in a heterogeneous environment, where each agent can receive observations conditioned on their own personalized state of nature (or truth). We particularly focus on community structured networks, where each community admits their own true hypothesis. This scenario is common in various contexts, such as when sensors are spatially distributed, or when individuals in a social network have differing views or opinions. We show that the adaptive social learning strategy is a preferred choice for nonstationary environments, and allows each cluster to discover its own truth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12186v3</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentina Shumovskaia, Mert Kayaalp, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>IRWE: Inductive Random Walk for Joint Inference of Identity and Position Network Embedding</title>
      <link>https://arxiv.org/abs/2401.00651</link>
      <description>arXiv:2401.00651v2 Announce Type: replace 
Abstract: Network embedding, which maps graphs to distributed representations, is a unified framework for various graph inference tasks. According to the topology properties (e.g., structural roles and community memberships of nodes) to be preserved, it can be categorized into the identity and position embedding. However, existing methods can only capture one type of property. Some approaches can support the inductive inference that generalizes the embedding model to new nodes or graphs but relies on the availability of attributes. Due to the complicated correlations between topology and attributes, it is unclear for some inductive methods which type of property they can capture. In this study, we explore a unified framework for the joint inductive inference of identity and position embeddings without attributes. An inductive random walk embedding (IRWE) method is proposed, which combines multiple attention units to handle the random walk on graph topology and simultaneously derives identity and position embeddings that are jointly optimized. In particular, we demonstrate that some random walk statistics can be informative features to characterize node identities and positions while supporting the inductive embedding inference. Experiments validate the superior performance of IRWE beyond various baselines for the transductive and inductive inference of identity and position embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00651v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Qin, Dit-Yan Yeung</dc:creator>
    </item>
    <item>
      <title>Expressivity of Geometric Inhomogeneous Random Graphs -- Metric and Non-Metric</title>
      <link>https://arxiv.org/abs/2402.03837</link>
      <description>arXiv:2402.03837v2 Announce Type: replace 
Abstract: Recently there has been increased interest in fitting generative graph models to real-world networks. In particular, Bl\"asius et al. have proposed a framework for systematic evaluation of the expressivity of random graph models. We extend this framework to Geometric Inhomogeneous Random Graphs (GIRGs). This includes a family of graphs induced by non-metric distance functions which allow capturing more complex models of partial similarity between nodes as a basis of connection - as well as homogeneous and non-homogeneous feature spaces. As part of the extension, we develop schemes for estimating the multiplicative constant and the long-range parameter in the connection probability. Moreover, we devise an algorithm for sampling Minimum-Component-Distance GIRGs whose runtime is linear both in the number of vertices and in the dimension of the underlying geometric space. Our results provide evidence that GIRGs are more realistic candidates with respect to various graph features such as closeness centrality, betweenness centrality, local clustering coefficient, and graph effective diameter, while they face difficulties to replicate higher variance and more extreme values of graph statistics observed in real-world networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03837v2</guid>
      <category>cs.SI</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Dayan, Marc Kaufmann, Ulysse Schaller</dc:creator>
    </item>
    <item>
      <title>Hidden Citations Obscure True Impact in Science</title>
      <link>https://arxiv.org/abs/2310.16181</link>
      <description>arXiv:2310.16181v2 Announce Type: replace-cross 
Abstract: References, the mechanism scientists rely on to signal previous knowledge, lately have turned into widely used and misused measures of scientific impact. Yet, when a discovery becomes common knowledge, citations suffer from obliteration by incorporation. This leads to the concept of hidden citation, representing a clear textual credit to a discovery without a reference to the publication embodying it. Here, we rely on unsupervised interpretable machine learning applied to the full text of each paper to systematically identify hidden citations. We find that for influential discoveries hidden citations outnumber citation counts, emerging regardless of publishing venue and discipline. We show that the prevalence of hidden citations is not driven by citation counts, but rather by the degree of the discourse on the topic within the text of the manuscripts, indicating that the more discussed is a discovery, the less visible it is to standard bibliometric analysis. Hidden citations indicate that bibliometric measures offer a limited perspective on quantifying the true impact of a discovery, raising the need to extract knowledge from the full text of the scientific corpus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16181v2</guid>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangyi Meng, Onur Varol, Albert-L\'aszl\'o Barab\'asi</dc:creator>
    </item>
    <item>
      <title>Exploring the Jungle of Bias: Political Bias Attribution in Language Models via Dependency Analysis</title>
      <link>https://arxiv.org/abs/2311.08605</link>
      <description>arXiv:2311.08605v2 Announce Type: replace-cross 
Abstract: The rapid advancement of Large Language Models (LLMs) has sparked intense debate regarding the prevalence of bias in these models and its mitigation. Yet, as exemplified by both results on debiasing methods in the literature and reports of alignment-related defects from the wider community, bias remains a poorly understood topic despite its practical relevance. To enhance the understanding of the internal causes of bias, we analyse LLM bias through the lens of causal fairness analysis, which enables us to both comprehend the origins of bias and reason about its downstream consequences and mitigation. To operationalize this framework, we propose a prompt-based method for the extraction of confounding and mediating attributes which contribute to the LLM decision process. By applying Activity Dependency Networks (ADNs), we then analyse how these attributes influence an LLM's decision process. We apply our method to LLM ratings of argument quality in political debates. We find that the observed disparate treatment can at least in part be attributed to confounding and mitigating attributes and model misalignment, and discuss the consequences of our findings for human-AI alignment and bias mitigation. Our code and data are at https://github.com/david-jenny/LLM-Political-Study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08605v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David F. Jenny, Yann Billeter, Mrinmaya Sachan, Bernhard Sch\"olkopf, Zhijing Jin</dc:creator>
    </item>
    <item>
      <title>"Here's Your Evidence": False Consensus in Public Twitter Discussions of COVID-19 Science</title>
      <link>https://arxiv.org/abs/2401.13248</link>
      <description>arXiv:2401.13248v2 Announce Type: replace-cross 
Abstract: The COVID-19 pandemic brought about an extraordinary rate of scientific papers on the topic that were discussed among the general public, although often in biased or misinformed ways. In this paper, we present a mixed-methods analysis aimed at examining whether public discussions were commensurate with the scientific consensus on several COVID-19 issues. We estimate scientific consensus based on samples of abstracts from preprint servers and compare against the volume of public discussions on Twitter mentioning these papers. We find that anti-consensus posts and users, though overall less numerous than pro-consensus ones, are vastly over-represented on Twitter, thus producing a false consensus effect. This transpires with favorable papers being disproportionately amplified, along with an influx of new anti-consensus user sign-ups. Finally, our content analysis highlights that anti-consensus users misrepresent scientific findings or question scientists' integrity in their efforts to substantiate their claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13248v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandros Efstratiou, Marina Efstratiou, Satrio Yudhoatmojo, Jeremy Blackburn, Emiliano De Cristofaro</dc:creator>
    </item>
    <item>
      <title>A Survey of Data-Efficient Graph Learning</title>
      <link>https://arxiv.org/abs/2402.00447</link>
      <description>arXiv:2402.00447v2 Announce Type: replace-cross 
Abstract: Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including self-supervised graph learning, semi-supervised graph learning, and few-shot graph learning. Also, we state promising directions for future research, contributing to the evolution of graph machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00447v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Ju, Siyu Yi, Yifan Wang, Qingqing Long, Junyu Luo, Zhiping Xiao, Ming Zhang</dc:creator>
    </item>
    <item>
      <title>A multidisciplinary framework for deconstructing bots' pluripotency in dualistic antagonism</title>
      <link>https://arxiv.org/abs/2402.15119</link>
      <description>arXiv:2402.15119v4 Announce Type: replace-cross 
Abstract: Anthropomorphic social bots are engineered to emulate human verbal communication and generate toxic or inflammatory content across social networking services (SNSs). Bot-disseminated misinformation could subtly yet profoundly reshape societal processes by complexly interweaving factors like repeated disinformation exposure, amplified political polarization, compromised indicators of democratic health, shifted perceptions of national identity, propagation of false social norms, and manipulation of collective memory over time. However, extrapolating bots' pluripotency across hybridized, multilingual, and heterogeneous media ecologies from isolated SNS analyses remains largely unknown, underscoring the need for a comprehensive framework to characterise bots' emergent risks to civic discourse. Here we propose an interdisciplinary framework to characterise bots' pluripotency, incorporating quantification of influence, network dynamics monitoring, and interlingual feature analysis. When applied to the geopolitical discourse around the Russo-Ukrainian conflict, results from interlanguage toxicity profiling and network analysis elucidated spatiotemporal trajectories of pro-Russian and pro-Ukrainian human and bots across hybrid SNSs. Weaponized bots predominantly inhabited X, while human primarily populated Reddit in the social media warfare. This rigorous framework promises to elucidate interlingual homogeneity and heterogeneity in bots' pluripotent behaviours, revealing synergistic human-bot mechanisms underlying regimes of information manipulation, echo chamber formation, and collective memory manifestation in algorithmically structured societies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15119v4</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wentao Xu, Kazutoshi Sasahara, Jianxun Chu, Bin Wang, Wenlu Fan, Zhiwen Hu</dc:creator>
    </item>
    <item>
      <title>Seed Selection in the Heterogeneous Moran Process</title>
      <link>https://arxiv.org/abs/2404.15986</link>
      <description>arXiv:2404.15986v2 Announce Type: replace-cross 
Abstract: The Moran process is a classic stochastic process that models the rise and takeover of novel traits in network-structured populations. In biological terms, a set of mutants, each with fitness $m\in(0,\infty)$ invade a population of residents with fitness $1$. Each agent reproduces at a rate proportional to its fitness and each offspring replaces a random network neighbor. The process ends when the mutants either fixate (take over the whole population) or go extinct. The fixation probability measures the success of the invasion. To account for environmental heterogeneity, we study a generalization of the Standard process, called the Heterogeneous Moran process. Here, the fitness of each agent is determined both by its type (resident/mutant) and the node it occupies. We study the natural optimization problem of seed selection: given a budget $k$, which $k$ agents should initiate the mutant invasion to maximize the fixation probability? We show that the problem is strongly inapproximable: it is $\mathbf{NP}$-hard to distinguish between maximum fixation probability 0 and 1. We then focus on mutant-biased networks, where each node exhibits at least as large mutant fitness as resident fitness. We show that the problem remains $\mathbf{NP}$-hard, but the fixation probability becomes submodular, and thus the optimization problem admits a greedy $(1-1/e)$-approximation. An experimental evaluation of the greedy algorithm along with various heuristics on real-world data sets corroborates our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15986v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.SI</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petros Petsinis, Andreas Pavlogiannis, Josef Tkadlec, Panagiotis Karras</dc:creator>
    </item>
    <item>
      <title>DF Louvain: Fast Incrementally Expanding Approach for Community Detection on Dynamic Graphs</title>
      <link>https://arxiv.org/abs/2404.19634</link>
      <description>arXiv:2404.19634v2 Announce Type: replace-cross 
Abstract: Community detection is the problem of recognizing natural divisions in networks. A relevant challenge in this problem is to find communities on rapidly evolving graphs. In this report we present our Parallel Dynamic Frontier (DF) Louvain algorithm, which given a batch update of edge deletions and insertions, incrementally identifies and processes an approximate set of affected vertices in the graph with minimal overhead, while using a novel approach of incrementally updating weighted-degrees of vertices and total edge weights of communities. We also present our parallel implementations of Naive-dynamic (ND) and Delta-screening (DS) Louvain. On a server with a 64-core AMD EPYC-7742 processor, our experiments show that DF Louvain obtains speedups of 179x, 7.2x, and 5.3x on real-world dynamic graphs, compared to Static, ND, and DS Louvain, respectively, and is 183x, 13.8x, and 8.7x faster, respectively, on large graphs with random batch updates. Moreover, DF Louvain improves its performance by 1.6x for every doubling of threads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19634v2</guid>
      <category>cs.DC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Subhajit Sahu</dc:creator>
    </item>
    <item>
      <title>Robust Reward Placement under Uncertainty</title>
      <link>https://arxiv.org/abs/2405.05433</link>
      <description>arXiv:2405.05433v2 Announce Type: replace-cross 
Abstract: We consider a problem of placing generators of rewards to be collected by randomly moving agents in a network. In many settings, the precise mobility pattern may be one of several possible, based on parameters outside our control, such as weather conditions. The placement should be robust to this uncertainty, to gain a competent total reward across possible networks. To study such scenarios, we introduce the Robust Reward Placement problem (RRP). Agents move randomly by a Markovian Mobility Model with a predetermined set of locations whose connectivity is chosen adversarially from a known set $\Pi$ of candidates. We aim to select a set of reward states within a budget that maximizes the minimum ratio, among all candidates in $\Pi$, of the collected total reward over the optimal collectable reward under the same candidate. We prove that RRP is NP-hard and inapproximable, and develop $\Psi$-Saturate, a pseudo-polynomial time algorithm that achieves an $\epsilon$-additive approximation by exceeding the budget constraint by a factor that scales as $O(\ln |\Pi|/\epsilon)$. In addition, we present several heuristics, most prominently one inspired by a dynamic programming algorithm for the max-min 0-1 KNAPSACK problem. We corroborate our analysis with an experimental evaluation of the methods in both synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05433v2</guid>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petros Petsinis, Kaichen Zhang, Andreas Pavlogiannis, Jingbo Zhou, Panagiotis Karras</dc:creator>
    </item>
  </channel>
</rss>
