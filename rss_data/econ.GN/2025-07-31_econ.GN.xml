<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Jul 2025 04:03:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Valuing Time in Silicon: Can Large Language Model Replicate Human Value of Travel Time</title>
      <link>https://arxiv.org/abs/2507.22244</link>
      <description>arXiv:2507.22244v1 Announce Type: new 
Abstract: As a key advancement in artificial intelligence, large language models (LLMs) are set to transform transportation systems. While LLMs offer the potential to simulate human travelers in future mixed-autonomy transportation systems, their behavioral fidelity in complex scenarios remains largely unconfirmed by existing research. This study addresses this gap by conducting a comprehensive analysis of the value of travel time (VOT) of a popular LLM, GPT-4o. We employ a full factorial experimental design to systematically examine the LLM's sensitivity to various transportation contexts, including the choice setting, travel purpose, income, and socio-demographic factors. Our results reveal a high degree of behavioral similarity between the LLM and humans. The LLM exhibits an aggregate VOT similar to that of humans, and demonstrates human-like sensitivity to travel purpose, income, and the time-cost trade-off ratios of the alternatives. Furthermore, the behavioral patterns of LLM are remarkably consistent across varied contexts. However, we also find that the LLM's context sensitivity is less pronounced than that observed in humans. Overall, this study provides a foundational benchmark for the future development of LLMs as proxies for human travelers, demonstrating their value and robustness while highlighting that their blunted contextual sensitivity requires careful consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22244v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingnan Yan, Tianming Liu, Yafeng Yin</dc:creator>
    </item>
    <item>
      <title>A Predictive Framework Integrating Multi-Scale Volatility Components and Time-Varying Quantile Spillovers: Evidence from the Cryptocurrency Market</title>
      <link>https://arxiv.org/abs/2507.22409</link>
      <description>arXiv:2507.22409v1 Announce Type: new 
Abstract: This paper investigates the dynamics of risk transmission in cryptocurrency markets and proposes a novel framework for volatility forecasting. The framework uncovers two key empirical facts: the asymmetric amplification of volatility spillovers in both tails, and a structural decoupling between market size and systemic importance. Building on these insights, we develop a state-adaptive volatility forecasting model by extracting time-varying quantile spillover features across different volatility components. These features are embedded into an extended Log-HAR structure, resulting in the SA-Log-HAR model. Empirical results demonstrate that the proposed model outperforms benchmark alternatives in both in-sample fitting and out-of-sample forecasting, particularly in capturing extreme volatility and tail risks with greater robustness and explanatory power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22409v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sicheng Fu, Fangfang Zhu, Xiangdong Liu</dc:creator>
    </item>
    <item>
      <title>How Exposed Are UK Jobs to Generative AI? Developing and Applying a Novel Task-Based Index</title>
      <link>https://arxiv.org/abs/2507.22748</link>
      <description>arXiv:2507.22748v1 Announce Type: new 
Abstract: We introduce the Generative AI Susceptibility Index (GAISI), a task-based measure of UK job exposure to large language models (LLMs), such as ChatGPT. GAISI is derived from probabilistic task ratings by LLMs and linked to worker-reported task data from the Skills and Employment Surveys. It reflects the share of job activities where an LLM or LLM-powered system can reduce task completion time by at least 25 per cent beyond existing productivity tools. The index demonstrates high reliability, strong alignment with AI capabilities, and superior predictive power compared to existing exposure measures. By 2023-24, nearly all UK jobs exhibited some exposure, yet only a minority were heavily affected. Aggregate exposure has risen since 2017, primarily due to occupational shifts rather than changes in task profiles. The price premium for AI-exposed tasks declined relative to 2017, measuring approximately 11 per cent lower in 2023-24. Job postings in high-exposure roles also fell by 6.5 per cent following the release of ChatGPT. GAISI offers a robust framework for assessing generative AI's impact on work, providing early evidence that displacement effects may already outweigh productivity gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22748v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Golo Henseke, Rhys Davies, Alan Felstead, Duncan Gallie, Francis Green, Ying Zhou</dc:creator>
    </item>
    <item>
      <title>The Impact of Acquisitions in the Biotechnology Sector on R&amp;D Productivity</title>
      <link>https://arxiv.org/abs/2203.12968</link>
      <description>arXiv:2203.12968v3 Announce Type: replace 
Abstract: This study examines the effects of acquisitions on the retention and R&amp;D productivity of inventors in the biotech sector, using data from 15,318 inventors involved in 1,375 acquisitions between 1990 and 2010. We employ a staggered difference-in-differences approach and find that acquisitions lead to a 13.5% decrease in inventor retention and a 35% drop in citation-weighted patent productivity post-acquisition. The productivity decline is more severe for inventors who remain with the acquiring firm, particularly for those whose expertise is closely tied to the target company. However, older inventors and those whose expertise aligns with the acquiring company's existing R&amp;D portfolio tend to retain higher productivity levels after the acquisition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.12968v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Verginer, Massimo Riccaboni</dc:creator>
    </item>
    <item>
      <title>A representation theorem for events within lattice structures of state-spaces</title>
      <link>https://arxiv.org/abs/2505.18615</link>
      <description>arXiv:2505.18615v2 Announce Type: replace 
Abstract: For the standard lattice model of information structures, we derive a reduced poset representation which provides the same informational content as the complete lattice structure which derives it. Rational agents can recover the complete lattice of events by means of the reduced poset alone. We find that both structures provide isomorphic models under mild conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18615v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex A. T. Rathke</dc:creator>
    </item>
    <item>
      <title>User Location Disclosure Fails to Deter Overseas Criticism but Amplifies Regional Divisions on Chinese Social Media</title>
      <link>https://arxiv.org/abs/2507.03238</link>
      <description>arXiv:2507.03238v2 Announce Type: replace 
Abstract: We examine the behavioral effects of a user location disclosure policy implemented by Sina Weibo, China's largest microblogging platform, using a high-frequency dataset of uncensored user engagement, including tens of thousands of comments, on 165 prominent government and media accounts. Exploiting the platform's abrupt rollout of IP-based location tags on April 28, 2022, we compare user behavior in comment sections before and after the policy change. Although the policy was publicly justified as a measure to curb misinformation and counter foreign influence, we find no decline in participation by overseas users. Instead, it significantly reduced domestic engagement with local issues outside users' home provinces, particularly among critical comments. Evidence suggests this effect was not driven by generalized fear or concerns about credibility, but by a rise in regionally discriminatory replies that increased the social cost of cross-provincial engagement. Our findings indicate that identity disclosure tools can produce unintended consequences by activating existing social divisions in ways that reinforce state control without direct censorship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03238v2</guid>
      <category>econ.GN</category>
      <category>cs.SI</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2139/ssrn.4560720</arxiv:DOI>
      <dc:creator>Leo Yang Yang, Yiqing Xu</dc:creator>
    </item>
    <item>
      <title>Strategic Integration of Artificial Intelligence in the C-Suite: The Role of the Chief AI Officer</title>
      <link>https://arxiv.org/abs/2407.10247</link>
      <description>arXiv:2407.10247v2 Announce Type: replace-cross 
Abstract: The integration of Artificial Intelligence (AI) into corporate strategy has become critical for organizations seeking to maintain a competitive advantage in the digital age. As AI transforms business models, operations, and decision-making, the need for dedicated executive leadership to guide, govern, and orchestrate this transformation becomes increasingly evident. This paper examines emerging future scenarios across three domains: the AI Economy, the AI Organization, and Competition in the Age of AI. These domains reveal environmental, structural, and strategic tensions that existing C-suite roles struggle to resolve. In response, the paper develops a theory-informed framework for the Chief AI Officer (CAIO), outlining the distinct functions and capabilities required to guide and govern AI at scale. Drawing on illustrative cases and emerging practice, this conceptualization clarifies the CAIOs unique role within the executive landscape and presents a forward-looking research agenda. This paper advances the discourse on AI leadership by offering a theory-driven rationale for the strategic integration of AI at the executive level and by positioning the Chief AI Officer as a distinct and necessary role within modern organizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10247v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Schmitt</dc:creator>
    </item>
    <item>
      <title>Modeling Story Expectations to Understand Engagement: A Generative Framework Using LLMs</title>
      <link>https://arxiv.org/abs/2412.15239</link>
      <description>arXiv:2412.15239v3 Announce Type: replace-cross 
Abstract: Understanding when and why consumers engage with stories is crucial for content creators and platforms. While existing theories suggest that audience beliefs of what is going to happen should play an important role in engagement decisions, empirical work has mostly focused on developing techniques to directly extract features from actual content, rather than capturing forward-looking beliefs, due to the lack of a principled way to model such beliefs in unstructured narrative data. To complement existing feature extraction techniques, this paper introduces a novel framework that leverages large language models to model audience forward-looking beliefs about how stories might unfold. Our method generates multiple potential continuations for each story and extracts features related to expectations, uncertainty, and surprise using established content analysis techniques. Applying our method to over 30,000 book chapters, we demonstrate that our framework complements existing feature engineering techniques by amplifying their marginal explanatory power on average by 31%. The results reveal that different types of engagement-continuing to read, commenting, and voting-are driven by distinct combinations of current and anticipated content features. Our framework provides a novel way to study and explore how audience forward-looking beliefs shape their engagement with narrative media, with implications for marketing strategy in content-focused industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15239v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hortense Fong, George Gui</dc:creator>
    </item>
  </channel>
</rss>
