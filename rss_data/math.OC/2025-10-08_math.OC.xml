<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Oct 2025 04:00:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generalized Multi-Constraint Extremum Seeking</title>
      <link>https://arxiv.org/abs/2510.06403</link>
      <description>arXiv:2510.06403v1 Announce Type: new 
Abstract: We generalize the Safe Extremum Seeking algorithm to address the minimization of an unknown objective function subject to multiple unknown inequality and equality constraints, relying on recent results of gradient flow systems. These constraints may represent safety or other critical conditions. The proposed ES algorithm functions as a general nonlinear programming tool, offering practical maintenance of all constraints and semiglobal practical asymptotic stability, utilizing a Lyapunov argument on the penalty function and the set-valued Lie derivative. The efficacy of the algorithm is demonstrated on a 2D problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06403v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alan Williams, Jorge Cort\'es, Alexander Scheinker</dc:creator>
    </item>
    <item>
      <title>Understanding the Impact of Hydro-Reservoirs and Inverters on Frequency-Constrained Operation</title>
      <link>https://arxiv.org/abs/2510.06422</link>
      <description>arXiv:2510.06422v1 Announce Type: new 
Abstract: The increasing participation of renewable energy sources in power systems has entailed a series of challenges resulting from the replacement of conventional synchronous machines with carbon-free Inverter-Based-Resources (IBRs). In this context, the present work contributes to the existing literature on Frequency-Constrained Unit Commitment (FCUC) models by studying the role of hydro-reservoirs in the ongoing decarbonization of power systems. For this purpose, a novel FCUC model is developed, which captures hydro-reservoir dynamics and their impact on frequency Nadir requirements through a data-driven approach. Moreover, the proposed FCUC model is used to simulate a series of future scenarios in the Chilean power system, and to understand the role that hydro-power units, thermal units, Grid-Forming (GFM) inverters, and Synchronous Condensers (SCs) will play in the future in terms of frequency regulation. Exhaustive simulations on the Chilean power system for years 2024 (current scenario) and 2035 (carbon-free scenario) illustrate the benefits of the proposed approach, which include: (i) significant cost-savings resulting from the using the proposed FCUC model relative to the industry standard, achieving operational cost reductions of up to 28% without compromising system security; and (ii) providing insights into the key role that hydro-reservoirs will play in the future. As a final analysis, the developed FCUC model is used to evaluate the financial benefits of incorporating SCs and GFM inverters to provide frequency regulation support to the grid in 2035. The results show that, while both technologies contribute to reducing the system's annual operational costs, GFM inverters significantly outperform SCs in terms of investment return.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06422v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valeria Aravena, Samuel Cordova, Maximiliano Kairath, Matias Negrete-Pincetic</dc:creator>
    </item>
    <item>
      <title>Safe Stabilization of the Stefan Problem with a High-Order Moving Boundary Dynamics by PDE Backstepping</title>
      <link>https://arxiv.org/abs/2510.06571</link>
      <description>arXiv:2510.06571v1 Announce Type: new 
Abstract: This paper presents a safe stabilization of the Stefan PDE model with a moving boundary governed by a high-order dynamics. We consider a parabolic PDE with a time-varying domain governed by a second-order response with respect to the Neumann boundary value of the PDE state at the moving boundary. The objective is to design a boundary heat flux control to stabilize the moving boundary at a desired setpoint, with satisfying the required conditions of the model on PDE state and the moving boundary. We apply a PDE backstepping method for the control design with considering a constraint on the control law. The PDE and moving boundary constraints are shown to be satisfied by applying the maximum principle for parabolic PDEs. Then the closed-loop system is shown to be globally exponentially stable by performing Lyapunov analysis. The proposed control is implemented in numerical simulation, which illustrates the desired performance in safety and stability. An outline of the extension to third-order moving boundary dynamics is also presented. Code is released at https://github.com/shumon0423/HighOrderStefan_CDC2025.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06571v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shumon Koga, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Approximate Bregman proximal gradient algorithm with variable metric Armijo--Wolfe line search</title>
      <link>https://arxiv.org/abs/2510.06615</link>
      <description>arXiv:2510.06615v1 Announce Type: new 
Abstract: We propose a variant of the approximate Bregman proximal gradient (ABPG) algorithm for minimizing the sum of a smooth nonconvex function and a nonsmooth convex function. Although ABPG is known to converge globally to a stationary point even when the smooth part of the objective function lacks globally Lipschitz continuous gradients, and its iterates can often be expressed in closed form, ABPG relies on an Armijo line search to guarantee global convergence. Such reliance can slow down performance in practice. To overcome this limitation, we propose the ABPG with a variable metric Armijo--Wolfe line search. Under the variable metric Armijo--Wolfe condition, we establish the global subsequential convergence of our algorithm. Moreover, assuming the Kurdyka--\L{}ojasiewicz property, we also establish that our algorithm globally converges to a stationary point. Numerical experiments on $\ell_p$ regularized least squares problems and nonnegative linear inverse problems demonstrate that our algorithm outperforms existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06615v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiwamu Fujiki, Shota Takahashi, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>On the B-subdifferential of proximal operators of affine-constrained $\ell_1$ regularizer</title>
      <link>https://arxiv.org/abs/2510.06642</link>
      <description>arXiv:2510.06642v1 Announce Type: new 
Abstract: In this work, we study the affine-constrained $\ell_1$ regularizers, which frequently arise in statistical and machine learning problems across a variety of applications, including microbiome compositional data analysis and sparse subspace clustering. With the aim of developing scalable second-order methods for solving optimization problems involving such regularizers, we analyze the associated proximal mapping and characterize its generalized differentiability, with a focus on its B-subdifferential. The revealed structured sparsity in the B-subdifferential enables us to design efficient algorithms within the proximal point framework. Extensive numerical experiments on real applications, including comparisons with state-of-the-art solvers, further demonstrate the superior performance of our approach. Our findings provide new insights into the sensitivity and stability properties of affine-constrained nonsmooth regularizers, and contribute to the development of fast second-order methods for a class of structured, constrained sparse learning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06642v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xudong Li, Meixia Lin, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Trajectory-Optimized Density Control with Flow Matching</title>
      <link>https://arxiv.org/abs/2510.06666</link>
      <description>arXiv:2510.06666v1 Announce Type: new 
Abstract: Optimal transport (OT) and Schr{\"o}dinger bridge (SB) problems have emerged as powerful frameworks for transferring probability distributions with minimal cost. However, existing approaches typically focus on endpoint matching while neglecting critical path-dependent properties -- particularly collision avoidance in multiagent systems -- which limits their practical applicability in robotics, economics, and other domains where inter-agent interactions are essential. Moreover, traditional density control methods often rely on independence assumptions that fail to capture swarm dynamics. We propose a novel framework that addresses these limitations by employing flow matching as the core modeling tool, where the flow model co-evolves with the control policy. Unlike prior methods that treat transport trajectories as mere interpolations between source and target distributions, our approach explicitly optimizes over the entire transport path, enabling the incorporation of trajectory-dependent costs and collision avoidance constraints. Our framework bridges optimal transport theory with mean field control, providing a principled approach to multiagent coordination problems where both endpoint alignment and path properties are critical. Experimental results demonstrate that our method successfully generates collision-free transport plans while maintaining computational efficiency comparable to standard flow matching approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06666v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Duan, Dongmei Chen</dc:creator>
    </item>
    <item>
      <title>Conic optimization for extremal geometry</title>
      <link>https://arxiv.org/abs/2510.06960</link>
      <description>arXiv:2510.06960v1 Announce Type: new 
Abstract: The aim of this paper is to highlight recent progress in using conic optimization methods to study geometric packing problems. We will look at four geometric packing problems of different kinds: two on the unit sphere -- the kissing number problem and measurable $\pi/2$-avoiding sets -- and two in Euclidean space -- the sphere packing problem and measurable one-avoiding sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06960v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frank Vallentin</dc:creator>
    </item>
    <item>
      <title>A combinatorial approach to Ramana's exact dual for semidefinite programming</title>
      <link>https://arxiv.org/abs/2510.07271</link>
      <description>arXiv:2510.07271v1 Announce Type: new 
Abstract: Thirty years ago, in a seminal paper Ramana derived an exact dual for Semidefinite Programming (SDP). Ramana's dual has the following remarkable features: i) it is an explicit, polynomial size semidefinite program ii) it does not assume that the primal is strictly feasible, nor does it make any other regularity assumptions iii) yet, it has strong duality with the primal. The complexity implications of Ramana's dual are fundamental, and to date still the best known. The most important of these is that SDP feasibility in the Turing model is not NP-complete, unless NP = co-NP.
  We give a treatment of Ramana's dual which is both simpler and more complete, than was previously available. First we connect it to a seemingly very different way of inducing strong duality: reformulating the SDP into a rank revealing form using elementary row operations and rotations. Second, while previous works characterized its objective value, we completely characterize its feasible set: in particular, we show it is a higher dimensional representation of an exact dual, which, however is not an explicit SDP. We also prove that -- somewhat surprisingly -- strict feasibility of Ramana's dual implies that the only feasible solution of the primal is the zero matrix.
  As a corollary, we obtain a short and transparent derivation of Ramana's dual, which we believe is accessible to both the optimization and the theoretical computer science communities. Our approach is combinatorial in the following sense: i) we use a minimum amount of continuous optimization theory ii) we show that feasible solutions in Ramana's dual are identified with regular facial reduction sequences, i.e., essentially discrete structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07271v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabor Pataki</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization under Uncertainty for Training a Scale Parameter in Stochastic Models</title>
      <link>https://arxiv.org/abs/2510.06439</link>
      <description>arXiv:2510.06439v1 Announce Type: cross 
Abstract: Hyperparameter tuning is a challenging problem especially when the system itself involves uncertainty. Due to noisy function evaluations, optimization under uncertainty can be computationally expensive. In this paper, we present a novel Bayesian optimization framework tailored for hyperparameter tuning under uncertainty, with a focus on optimizing a scale- or precision-type parameter in stochastic models. The proposed method employs a statistical surrogate for the underlying random variable, enabling analytical evaluation of the expectation operator. Moreover, we derive a closed-form expression for the optimizer of the random acquisition function, which significantly reduces computational cost per iteration. Compared with a conventional one-dimensional Monte Carlo-based optimization scheme, the proposed approach requires 40 times fewer data points, resulting in up to a 40-fold reduction in computational cost. We demonstrate the effectiveness of the proposed method through two numerical examples in computational engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06439v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Yadav, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>A Median Perspective on Unlabeled Data for Out-of-Distribution Detection</title>
      <link>https://arxiv.org/abs/2510.06505</link>
      <description>arXiv:2510.06505v1 Announce Type: cross 
Abstract: Out-of-distribution (OOD) detection plays a crucial role in ensuring the robustness and reliability of machine learning systems deployed in real-world applications. Recent approaches have explored the use of unlabeled data, showing potential for enhancing OOD detection capabilities. However, effectively utilizing unlabeled in-the-wild data remains challenging due to the mixed nature of both in-distribution (InD) and OOD samples. The lack of a distinct set of OOD samples complicates the task of training an optimal OOD classifier. In this work, we introduce Medix, a novel framework designed to identify potential outliers from unlabeled data using the median operation. We use the median because it provides a stable estimate of the central tendency, as an OOD detection mechanism, due to its robustness against noise and outliers. Using these identified outliers, along with labeled InD data, we train a robust OOD classifier. From a theoretical perspective, we derive error bounds that demonstrate Medix achieves a low error rate. Empirical results further substantiate our claims, as Medix outperforms existing methods across the board in open-world settings, confirming the validity of our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06505v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Momin Abbas, Ali Falahati, Hossein Goli, Mohammad Mohammadi Amiri</dc:creator>
    </item>
    <item>
      <title>Conditional McKean-Vlasov control</title>
      <link>https://arxiv.org/abs/2510.06543</link>
      <description>arXiv:2510.06543v1 Announce Type: cross 
Abstract: Conditional McKean-Vlasov control problems involve controlling McKean-Vlasov diffusions where the interaction occurs through the law of the state process conditionally on it staying in a domain. Introduced by Lions in his 2016 lectures at the Coll\`ege de France, these problems have notable applications, particularly in systemic risk. We establish well-posedness and provide a general characterization of optimal controls using a new Pontryagin maximum principle in the probabilistic weak formulation. Unlike the classical approach based on forward-backward systems, our results connect the control problem to a generalized McKean-Vlasov backward stochastic differential equation (BSDE). We illustrate our framework with two applications: a version of the Schr\"odinger problem with killing, and a construction of equilibria in potential mean field games via McKean-Vlasov control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06543v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ren\'e Carmona, Ludovic Tangpi, Kaiwen Zhang</dc:creator>
    </item>
    <item>
      <title>AutoBalance: An Automatic Balancing Framework for Training Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2510.06684</link>
      <description>arXiv:2510.06684v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) provide a powerful and general framework for solving Partial Differential Equations (PDEs) by embedding physical laws into loss functions. However, training PINNs is notoriously difficult due to the need to balance multiple loss terms, such as PDE residuals and boundary conditions, which often have conflicting objectives and vastly different curvatures. Existing methods address this issue by manipulating gradients before optimization (a "pre-combine" strategy). We argue that this approach is fundamentally limited, as forcing a single optimizer to process gradients from spectrally heterogeneous loss landscapes disrupts its internal preconditioning. In this work, we introduce AutoBalance, a novel "post-combine" training paradigm. AutoBalance assigns an independent adaptive optimizer to each loss component and aggregates the resulting preconditioned updates afterwards. Extensive experiments on challenging PDE benchmarks show that AutoBalance consistently outperforms existing frameworks, achieving significant reductions in solution error, as measured by both the MSE and $L^{\infty}$ norms. Moreover, AutoBalance is orthogonal to and complementary with other popular PINN methodologies, amplifying their effectiveness on demanding benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06684v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kang An, Chenhao Si, Ming Yan, Shiqian Ma</dc:creator>
    </item>
    <item>
      <title>Stability Preserving Safe Control of a Bicopter</title>
      <link>https://arxiv.org/abs/2510.07145</link>
      <description>arXiv:2510.07145v1 Announce Type: cross 
Abstract: This paper presents a control law for stabilization and trajectory tracking of a multicopter subject to safety constraints. The proposed approach guarantees forward invariance of a prescribed safety set while ensuring smooth tracking performance. Unlike conventional control barrier function methods, the constrained control problem is transformed into an unconstrained one using state-dependent mappings together with carefully constructed Lyapunov functions. This approach enables explicit synthesis of the control law, instead of requiring a solution of constrained optimization at each step. The transformation also enables the controller to enforce safety without sacrificing stability or performance. Simulation results for a polytopic reference trajectory confined within a designated safe region demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07145v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jhon Manuel Portella Delgado, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>Optimal network pricing with oblivious users: a new model and algorithm</title>
      <link>https://arxiv.org/abs/2510.07157</link>
      <description>arXiv:2510.07157v1 Announce Type: cross 
Abstract: Traffic modeling is important in modern society. In this work we propose a new model on the optimal network pricing (Onp) with the assumption of oblivious users, in which the users remain oblivious to real-time traffic conditions and others' behavior. Inspired by works on transportation research and network pricing for selfish traffic, we mathematically derive and prove a new formulation of Onp with decision-dependent modeling that relax certain existing modeling constraints in the literature. Then, we express the Onp formulation as a constrained nonconvex stochastic quadratic program with uncertainty, and we propose an efficient algorithm to solve the problem, utilizing graph theory, sparse linear algebra and stochastic approximation. Lastly, we showcase the effectiveness of the proposed algorithm and the usefulness of the new Onp formulation. The proposed algorithm achieves a 5x speedup by exploiting the sparsity structure of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07157v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yixuan Li, Andersen Ang, Sebastian Stein</dc:creator>
    </item>
    <item>
      <title>Guided by the Experts: Provable Feature Learning Dynamic of Soft-Routed Mixture-of-Experts</title>
      <link>https://arxiv.org/abs/2510.07205</link>
      <description>arXiv:2510.07205v1 Announce Type: cross 
Abstract: Mixture-of-Experts (MoE) architectures have emerged as a cornerstone of modern AI systems. In particular, MoEs route inputs dynamically to specialized experts whose outputs are aggregated through weighted summation. Despite their widespread application, theoretical understanding of MoE training dynamics remains limited to either separate expert-router optimization or only top-1 routing scenarios with carefully constructed datasets. This paper advances MoE theory by providing convergence guarantees for joint training of soft-routed MoE models with non-linear routers and experts in a student-teacher framework. We prove that, with moderate over-parameterization, the student network undergoes a feature learning phase, where the router's learning process is ``guided'' by the experts, that recovers the teacher's parameters. Moreover, we show that a post-training pruning can effectively eliminate redundant neurons, followed by a provably convergent fine-tuning process that reaches global optimality. To our knowledge, our analysis is the first to bring novel insights in understanding the optimization landscape of the MoE architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07205v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangshuo Liao, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>Regular Pairings for Non-quadratic Lyapunov Functions and Contraction Analysis</title>
      <link>https://arxiv.org/abs/2408.17350</link>
      <description>arXiv:2408.17350v2 Announce Type: replace 
Abstract: Recent studies on stability and contractivity have highlighted the importance of semi-inner products, which we refer to as pairings,
  associated with general norms. A pairing is a binary operation that relates the derivative of a curve's norm to the radius-vector of the
  curve and its tangent. This relationship, known as the curve norm derivative formula, is crucial when using the norm as a Lyapunov
  function. Another important property of the pairing, used in stability and contraction criteria, is the so-called Lumer inequality, which
  relates the pairing to the induced logarithmic norm. We prove that the curve norm derivative formula and Lumer's inequality are, in fact,
  equivalent to each other and to several simpler properties. We then introduce and characterize regular pairings that satisfy all of
  these properties. Our results unify several independent theories of pairings (semi-inner products) developed in previous work on functional
  analysis and control theory. Additionally, we introduce the polyhedral max pairing and develop computational tools for polyhedral norms,
  advancing contraction theory in non-Euclidean spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17350v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.FA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anton V. Proskurnikov, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Efficient gradient-based methods for bilevel learning via recycling Krylov subspaces</title>
      <link>https://arxiv.org/abs/2412.08264</link>
      <description>arXiv:2412.08264v2 Announce Type: replace 
Abstract: Many optimization problems require hyperparameters, i.e., parameters that must be pre-specified in advance, such as regularization parameters and parametric regularizers in variational regularization methods for inverse problems, and dictionaries in compressed sensing. A data-driven approach to determine appropriate hyperparameter values is via a nested optimization framework known as bilevel learning. Even when it is possible to employ a gradient-based solver to the bilevel optimization problem, construction of the gradients, known as hypergradients, is computationally challenging, each one requiring both a solution of a minimization problem and a linear system solve. These systems do not change much during the iterations, which motivates us to apply recycling Krylov subspace methods, wherein information from one linear system solve is re-used to solve the next linear system. Existing recycling strategies often employ eigenvector approximations called Ritz vectors. In this work we propose a novel recycling strategy based on a new concept, Ritz generalized singular vectors, which acknowledge the bilevel setting. Additionally, while existing iterative methods primarily terminate according to the residual norm, this new concept allows us to define a new stopping criterion that directly approximates the error of the associated hypergradient. The proposed approach is validated through extensive numerical testing in the context of inverse problems in imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08264v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Silvia Gazzola, Sebastian J. Scott</dc:creator>
    </item>
    <item>
      <title>On the Instability of Nesterov's ODE under Non-Conservative Vector Fields</title>
      <link>https://arxiv.org/abs/2501.13244</link>
      <description>arXiv:2501.13244v3 Announce Type: replace 
Abstract: We study the instability properties of Nesterov's ODE in non-conservative settings, where the driving term is not necessarily the gradient of a potential function. While convergence properties under Nesterov's ODE are well-characterized for optimization settings with gradient-based driving terms, we show that the presence of arbitrarily small non-conservative terms can lead to instability, a phenomenon previously observed empirically via numerical studies in optimization and game-theoretic problems. Our instability analysis combines multi-time scale techniques, such as averaging via variations-of-constants formula, and Floquet Theory, focusing on systems where the vector field is linear and its Helmholtz decomposition reveals a non-vanishing non-conservative component. To resolve the instability issue, the dynamics under non-vanishing non-conservative components, we study a regularization mechanism based on restarting. The resulting system is a hybrid dynamical system that mirrors Nesterov's ODE during intervals of flow, and implements resets of the momentum state through discrete periodic jumps. For this hybrid system, we establish novel explicit bounds on the resetting period that ensure the decrease of a suitable Lyapunov function, guaranteeing not only stability but also "accelerated" convergence rates under suitable smoothness and strong monotonicity properties on the driving term. Numerical simulations support our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13244v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel E. Ochoa, Mahmoud Abdelgalil, Jorge I. Poveda</dc:creator>
    </item>
    <item>
      <title>Sparse Quadratically Constrained Quadratic Programming via Semismooth Newton Method</title>
      <link>https://arxiv.org/abs/2503.15109</link>
      <description>arXiv:2503.15109v2 Announce Type: replace 
Abstract: Quadratically constrained quadratic programming (QCQP) has long been recognized as a computationally challenging problem, particularly in large-scale or high-dimensional settings where solving it directly becomes intractable. The complexity further escalates when a sparsity constraint is involved, giving rise to the problem of sparse QCQP (SQCQP), which makes conventional solution methods even less effective. Existing approaches for solving SQCQP typically rely on mixed-integer programming formulations, relaxation techniques, or greedy heuristics but often suffer from computational inefficiency and limited accuracy. In this work, we introduce a novel paradigm by designing an efficient algorithm that directly addresses SQCQP. To be more specific, we introduce P-stationarity to establish first- and second-order optimality conditions of the original problem, leading to a system of nonlinear equations whose generalized Jacobian is proven to be nonsingular under mild assumptions. Most importantly, these equations facilitate the development of a semismooth Newton-type method that exhibits significantly low computational complexity due to the sparsity constraint and achieves a locally quadratic convergence rate. Finally, extensive numerical experiments validate the accuracy and computational efficiency of the algorithm compared to several established solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15109v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuai Li, Shenglong Zhou, Ziyan Luo</dc:creator>
    </item>
    <item>
      <title>A three-term Polak-Ribi\`{e}re-Polyak conjugate gradient method for vector optimization</title>
      <link>https://arxiv.org/abs/2505.08408</link>
      <description>arXiv:2505.08408v3 Announce Type: replace 
Abstract: A novel three-term Polak-Ribi\`{e}re-Polyak conjugate gradient method is proposed for solving vector optimization problems. It should be emphasized that this is the first extension of three-term conjugate gradient methods from scalar optimization to vector optimization. The method can consistently generate a sufficient descent direction independent of line search procedures and without modifying the conjugate parameters. This result improves upon the corresponding conclusions in SIAM J. Optim. 28, 2690-2720 (2018), J. Optim. Theory Appl. 204,13 (2025) and Optim. Methods Softw. 28, 725-754 (2025). Based on a new Wolfe-type line search, the global convergence of the proposed scheme is established without imposing restrictions such as self-adjusting strategies, regular restarts and convexity assumptions. Numerical experiments demonstrate the favourable performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08408v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangxuan Lin, Shouqiang Du</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust System Level Synthesis With Output Feedback Affine Control Policy</title>
      <link>https://arxiv.org/abs/2508.05466</link>
      <description>arXiv:2508.05466v2 Announce Type: replace 
Abstract: This paper studies the finite-horizon robust optimal control of constrained linear systems subject to model mismatch and additive stochastic disturbances. Utilizing the system level synthesis (SLS) parameterization, we propose a novel SLS design using an output-feedback affine control policy and extend it to a distributionally robust setting to improve system resilience by minimizing the cost function while ensuring constraint satisfaction against the worst-case uncertainty distribution. The scopes of model mismatch and stochastic disturbances are quantified using the 1-norm and a Wasserstein metric-based ambiguity set, respectively. For the closed-loop dynamics, we analyze the distributional shift between the predicted output-input response -- computed using nominal parameters and empirical disturbance samples -- and the actual closed-loop distribution, highlighting its dependence on model mismatch and SLS parameterization. Assuming convex and Lipschitz continuous cost functions and constraints, we derive a tractable reformulation of the distributionally robust SLS (DR-SLS) problem by leveraging tools from robust control and distributionally robust optimization (DRO). Numerical experiments validate the performance and robustness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05466v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yun Li, Jicheng Shi, Colin N. Jones, Neil Yorke-Smith, Tamas Keviczky</dc:creator>
    </item>
    <item>
      <title>Nagumo-Type Characterization of Forward Invariance for Constrained Systems</title>
      <link>https://arxiv.org/abs/2508.20045</link>
      <description>arXiv:2508.20045v2 Announce Type: replace 
Abstract: This paper proposes a Nagumo-type invariance condition for differential inclusions defined on closed constraint sets. More specifically, given a closed set to render forward invariant, the proposed condition restricts the system's dynamics, assumed to be locally Lipschitz, on the boundary of the set restricted to the interior of the constraint set. In particular, when the boundary of the set is entirely within the interior of the constraint set, the proposed condition reduces to the well-known Nagumo condition, known to be necessary and sufficient for forward invariance in this case. This being said, the proposed condition is only necessary in the general setting. As a result, we provide a set of additional assumptions relating the constrained system to the set to render forward invariant, and restricting to the geometry at the intersection between the two sets, so that the equivalence holds. The importance of the proposed assumptions is illustrated via examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20045v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olayo Reynaud, Mohamed Maghenem, Adnane Saoud, Sadek Belamfedel Alaoui, Ahmad Hably</dc:creator>
    </item>
    <item>
      <title>Optimization via a Control-Centric Framework</title>
      <link>https://arxiv.org/abs/2510.05455</link>
      <description>arXiv:2510.05455v2 Announce Type: replace 
Abstract: Optimization plays a central role in intelligent systems and cyber-physical technologies, where the speed and reliability of convergence directly impact performance. In control theory, optimization-centric methods are standard: controllers are designed by repeatedly solving optimization problems, as in linear quadratic regulation, $H_\infty$ control, and model predictive control. In contrast, this paper develops a control-centric framework for optimization itself, where algorithms are constructed directly from Lyapunov stability principles rather than being proposed first and analyzed afterward. A key element is the stationarity vector, which encodes first-order optimality conditions and enables Lyapunov-based convergence analysis. By pairing a Lyapunov function with a selectable decay law, we obtain continuous-time dynamics with guaranteed exponential, finite-time, fixed-time, or prescribed-time convergence. Within this framework, we introduce three feedback realizations of increasing restrictiveness: the Hessian-gradient, Newton, and gradient dynamics. Each realization shapes the decay of the stationarity vector to achieve the desired rate. These constructions unify unconstrained optimization, extend naturally to constrained problems via Lyapunov-consistent primal-dual dynamics, and broaden the results for minimax and generalized Nash equilibrium seeking problems beyond exponential stability. The framework provides systematic design tools for optimization algorithms in control and game-theoretic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05455v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liraz Mudrik, Isaac Kaminer, Sean Kragelund, Abram H. Clark</dc:creator>
    </item>
    <item>
      <title>Lagrangian Dual Sections: A Topological Perspective on Hidden Convexity</title>
      <link>https://arxiv.org/abs/2510.06112</link>
      <description>arXiv:2510.06112v2 Announce Type: replace 
Abstract: Hidden convexity is a powerful idea in optimization: under the right transformations, nonconvex problems that are seemingly intractable can be solved efficiently using convex optimization. We introduce the notion of a Lagrangian dual section of a nonlinear program defined over a topological space, and we use it to give a sufficient condition for a nonconvex optimization problem to have a natural convex reformulation. We emphasize the topological nature of our framework, using only continuity and connectedness properties of a certain Lagrangian formulation of the problem to prove our results. We demonstrate the practical consequences of our framework in a range of applications and by developing new algorithmic methodology. First, we present families of nonconvex problem instances that can be transformed to convex programs in the context of spectral inverse problems -- which include quadratically constrained quadratic optimization and Stiefel manifold optimization as special cases -- as well as unbalanced Procrustes problems. In each of these applications, we both generalize prior results on hidden convexity and provide unifying proofs. For the case of the spectral inverse problems, we also present a Lie-theoretic approach that illustrates connections with the Kostant convexity theorem. Second, we introduce new algorithmic ideas that can be used to find globally optimal solutions to both Lagrangian forms of an optimization problem as well as constrained optimization problems when the underlying topological space is a Riemannian manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06112v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Venkat Chandrasekaran, Timothy Duff, Jose Israel Rodriguez, Kevin Shu</dc:creator>
    </item>
    <item>
      <title>Hidden monotonicity and canonical transformations for mean field games and master equations</title>
      <link>https://arxiv.org/abs/2403.05426</link>
      <description>arXiv:2403.05426v2 Announce Type: replace-cross 
Abstract: In this paper we unveil novel monotonicity conditions applicable for Mean Field Games through the exploration of finite dimensional $canonical\ transformations$. Our findings contribute to establishing new global well-posedness results for the associated master equations, also in the case of potentially degenerate idiosyncratic noise. Additionally, we show that recent advancements in global well-posedness results, specifically those related to displacement semi-monotone and anti-monotone data, can be easily obtained as a consequence of our main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05426v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohit Bansil, Alp\'ar R. M\'esz\'aros</dc:creator>
    </item>
    <item>
      <title>Default Resilience and Worst-Case Effects in Financial Networks</title>
      <link>https://arxiv.org/abs/2403.10631</link>
      <description>arXiv:2403.10631v2 Announce Type: replace-cross 
Abstract: In this paper we analyze the resilience of a network of banks to joint price fluctuations of the external assets in which they have shared exposures, and evaluate the worst-case effects of the possible default contagion. Indeed, when the prices of certain external assets either decrease or increase, all banks exposed to them experience varying degrees of simultaneous shocks to their balance sheets. These coordinated and structured shocks have the potential to exacerbate the likelihood of defaults. In this context, we introduce first a concept of {default resilience margin}, $\epsilon^*$, i.e., the maximum amplitude of asset prices fluctuations that the network can tolerate without generating defaults. Such threshold value is computed by considering two different measures of price fluctuations, one based on the maximum individual variation of each asset, and the other based on the sum of all the asset's absolute variations. For any price perturbation having amplitude no larger than $\epsilon^*$, the network absorbs the shocks remaining default free. When the perturbation amplitude goes beyond $\epsilon^*$, however, defaults may occur. In this case we find the worst-case systemic loss, that is, the total unpaid debt under the most severe price variation of given magnitude. Computation of both the threshold level $\epsilon^*$ and of the worst-case loss and of a corresponding worst-case asset price scenario, amounts to solving suitable linear programming problems.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10631v2</guid>
      <category>q-fin.RM</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s41109-025-00728-5</arxiv:DOI>
      <arxiv:journal_reference>Applied Network Science 10, 48 (2025)</arxiv:journal_reference>
      <dc:creator>Giuseppe Calafiore, Giulia Fracastoro, Anton Proskurnikov</dc:creator>
    </item>
    <item>
      <title>Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2505.21404</link>
      <description>arXiv:2505.21404v2 Announce Type: replace-cross 
Abstract: Natural-gradient methods markedly accelerate the training of Physics-Informed Neural Networks (PINNs), yet their Gauss--Newton update must be solved in the parameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is the number of network trainable weights. We show that exactly the same step can instead be formulated in a generally smaller residual space of size $m = \sum_{\gamma} N_{\gamma} d_{\gamma}$, where each residual class $\gamma$ (e.g. PDE interior, boundary, initial data) contributes $N_{\gamma}$ collocation points of output dimension $d_{\gamma}$.
  Building on this insight, we introduce \textit{Dual Natural Gradient Descent} (D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it with a geodesic-acceleration correction at negligible extra cost, and provides both a dense direct solver for modest $m$ and a Nystrom-preconditioned conjugate-gradient solver for larger $m$.
  Experimentally, D-NGD scales second-order PINN optimization to networks with up to 12.8 million parameters, delivers one- to three-order-of-magnitude lower final error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton methods, and -- crucially -- enables natural-gradient training of PINNs at this scale on a single GPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21404v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anas Jnini, Flavio Vella</dc:creator>
    </item>
    <item>
      <title>Learning where to learn: Training data distribution optimization for scientific machine learning</title>
      <link>https://arxiv.org/abs/2505.21626</link>
      <description>arXiv:2505.21626v2 Announce Type: replace-cross 
Abstract: In scientific machine learning, models are routinely deployed with parameter values or boundary conditions far from those used in training. This paper studies the learning-where-to-learn problem of designing a training data distribution that minimizes average prediction error across a family of deployment regimes. A theoretical analysis shows how the training distribution shapes deployment accuracy. This motivates two adaptive algorithms based on bilevel or alternating optimization in the space of probability measures. Discretized implementations using parametric distribution classes or nonparametric particle-based gradient flows deliver optimized training distributions that outperform nonadaptive designs. Once trained, the resulting models exhibit improved sample complexity and robustness to distribution shift. This framework unlocks the potential of principled data acquisition for learning functions and solution operators of partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21626v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Guerra, Nicholas H. Nelsen, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>A Minimalist Bayesian Framework for Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2509.07030</link>
      <description>arXiv:2509.07030v2 Announce Type: replace-cross 
Abstract: The Bayesian paradigm offers principled tools for sequential decision-making under uncertainty, but its reliance on a probabilistic model for all parameters can hinder the incorporation of complex structural constraints. We introduce a minimalist Bayesian framework that places a prior only on the component of interest, such as the location of the optimum. Nuisance parameters are eliminated via profile likelihood, which naturally handles constraints. As a direct instantiation, we develop a MINimalist Thompson Sampling (MINTS) algorithm. Our framework accommodates structured problems, including continuum-armed Lipschitz bandits and dynamic pricing. It also provides a probabilistic lens on classical convex optimization algorithms such as the center of gravity and ellipsoid methods. We further analyze MINTS for multi-armed bandits and establish near-optimal regret guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07030v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaizheng Wang</dc:creator>
    </item>
    <item>
      <title>PolyKAN: A Polyhedral Analysis Framework for Provable and Approximately Optimal KAN Compression</title>
      <link>https://arxiv.org/abs/2510.04205</link>
      <description>arXiv:2510.04205v2 Announce Type: replace-cross 
Abstract: Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to traditional Multi-Layer Perceptrons (MLPs), offering enhanced interpretability and a solid mathematical foundation. However, their parameter efficiency remains a significant challenge for practical deployment. This paper introduces PolyKAN, a novel theoretical framework for KAN compression that provides formal guarantees on both model size reduction and approximation error. By leveraging the inherent piecewise polynomial structure of KANs, we formulate the compression problem as a polyhedral region merging task. We establish a rigorous polyhedral characterization of KANs, develop a complete theory of $\epsilon$-equivalent compression, and design a dynamic programming algorithm that achieves approximately optimal compression under specified error bounds. Our theoretical analysis demonstrates that PolyKAN achieves provably near-optimal compression while maintaining strict error control, with guaranteed global optimality for univariate spline functions. This framework provides the first formal foundation for KAN compression with mathematical guarantees, opening new directions for the efficient deployment of interpretable neural architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04205v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang</dc:creator>
    </item>
  </channel>
</rss>
