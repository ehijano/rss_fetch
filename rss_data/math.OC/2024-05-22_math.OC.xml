<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 May 2024 04:47:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stability criteria of nonlinear generalized proportional fractional delayed systems</title>
      <link>https://arxiv.org/abs/2405.12256</link>
      <description>arXiv:2405.12256v1 Announce Type: new 
Abstract: This work deals with the finite time stability of generalized proportional fractional systems with time delay. First, based on the generalized proportional Gr\"onwall inequality, we derive an explicit criterion that enables the system trajectories to stay within a priori given sets during a pre-specified time interval, in terms of the Mittag-Leffler function. Then, we investigate the finite time stability of nonlinear nonhomogeneous delayed systems by means of an approach based on H\"older's and Jensen's inequalities. Numerical applications are presented to illustrate the validity and feasibility of the developed results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12256v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanaa Zitane, Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>Infinite-Dimensional System Signature: System Signature Under the Repairable Principle</title>
      <link>https://arxiv.org/abs/2405.12257</link>
      <description>arXiv:2405.12257v1 Announce Type: new 
Abstract: Investigation of the reliability of technical systems is one of the application areas of stochastic processes. The reliability of a technical system is based on two main elements. The first is the connection type of the system, and the second is the distribution of the working times of the components consisting of the system. In this study, system signatures and their reliability will be calculated under the repairable principle of parallel and serial systems consisting of two components. Although there are a limited number of studies in the literature for repairable systems, there is no study on creating the signature of repairable systems. In technical systems where there is no repair principle, although the system signature has limited components, the technical systems working under the repairable principle, have infinite components of the system signature. While creating the system signature, the probability that the working time of the component that is in the state of the system failure is greater than the repair time was defined as the parameter {\xi}. In the application part of the study, under the principle of repair, the system signature, and the reliability of the system were be successfully calculated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12257v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunus G\"ural, Mehmet G\"urcan</dc:creator>
    </item>
    <item>
      <title>Inexact Newton-type Methods for Optimisation with Nonnegativity Constraints</title>
      <link>https://arxiv.org/abs/2405.12401</link>
      <description>arXiv:2405.12401v1 Announce Type: new 
Abstract: We consider solving large scale nonconvex optimisation problems with nonnegativity constraints. Such problems arise frequently in machine learning, such as nonnegative least-squares, nonnegative matrix factorisation, as well as problems with sparsity-inducing regularisation. In such settings, first-order methods, despite their simplicity, can be prohibitively slow on ill-conditioned problems or become trapped near saddle regions, while most second-order alternatives involve non-trivially challenging subproblems. The two-metric projection framework, initially proposed by Bertsekas (1982), alleviates these issues and achieves the best of both worlds by combining projected gradient steps at the boundary of the feasible region with Newton steps in the interior in such a way that feasibility can be maintained by simple projection onto the nonnegative orthant. We develop extensions of the two-metric projection framework, which by inexactly solving the subproblems as well as employing non-positive curvature directions, are suitable for large scale and nonconvex settings. We obtain state-of-the-art convergence rates for various classes of non-convex problems and demonstrate competitive practical performance on a variety of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12401v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar Smee, Fred Roosta</dc:creator>
    </item>
    <item>
      <title>Distribution Steering for Discrete-Time Uncertain Ensemble Systems</title>
      <link>https://arxiv.org/abs/2405.12415</link>
      <description>arXiv:2405.12415v1 Announce Type: new 
Abstract: Ensemble systems appear frequently in many engineering applications and, as a result, they have become an important research topic in control theory. These systems are best characterized by the evolution of their underlying state distribution. Despite the work to date, few results exist dealing with the problem of directly modifying (i.e., "steering") the distribution of an ensemble system. In addition, in most of the existing results, the distribution of the states of an ensemble of discrete-time systems is assumed to be Gaussian. However, in case the system parameters are uncertain, it is not always realistic to assume that the distribution of the system follows a Gaussian distribution, thus complicating the solution of the overall problem. In this paper, we address the general distribution steering problem for first-order discrete-time ensemble systems, where the distributions of the system parameters and the states are arbitrary with finite first few moments. Both linear and nonlinear system dynamics are considered using the method of power moments to transform the original infinite-dimensional problem into a finite-dimensional one. We also propose a control law for the ensuing moment system, which allows us to obtain the power moments of the desired control inputs. Finally, we solve the inverse problem to obtain the feasible control inputs from their corresponding power moments. We provide numerical results to validate our theoretical developments. These include cases where the parameter distribution is uniform, Gaussian, non-Gaussian, and multi-modal, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12415v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guangyu Wu, Panagiotis Tsiotras, Anders Lindquist</dc:creator>
    </item>
    <item>
      <title>Stochastic Learning of Computational Resource Usage as Graph Structured Multimarginal Schr\"odinger Bridge</title>
      <link>https://arxiv.org/abs/2405.12463</link>
      <description>arXiv:2405.12463v1 Announce Type: new 
Abstract: We propose to learn the time-varying stochastic computational resource usage of software as a graph structured Schr\"odinger bridge problem. In general, learning the computational resource usage from data is challenging because resources such as the number of CPU instructions and the number of last level cache requests are both time-varying and statistically correlated. Our proposed method enables learning the joint time-varying stochasticity in computational resource usage from the measured profile snapshots in a nonparametric manner. The method can be used to predict the most-likely time-varying distribution of computational resource availability at a desired time. We provide detailed algorithms for stochastic learning in both single and multi-core cases, discuss the convergence guarantees, computational complexities, and demonstrate their practical use in two case studies: a single-core nonlinear model predictive controller, and a synthetic multi-core software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12463v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgiy A. Bondar, Robert Gifford, Linh Thi Xuan Phan, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>PhiBE: A PDE-based Bellman Equation for Continuous Time Policy Evaluation</title>
      <link>https://arxiv.org/abs/2405.12535</link>
      <description>arXiv:2405.12535v1 Announce Type: new 
Abstract: In this paper, we address the problem of continuous-time reinforcement learning in scenarios where the dynamics follow a stochastic differential equation. When the underlying dynamics remain unknown and we have access only to discrete-time information, how can we effectively conduct policy evaluation? We first highlight that the commonly used Bellman equation (BE) is not always a reliable approximation to the true value function. We then introduce a new bellman equation, PhiBE, which integrates the discrete-time information into a PDE formulation. The new bellman equation offers a more accurate approximation to the true value function, especially in scenarios where the underlying dynamics change slowly. Moreover, we extend PhiBE to higher orders, providing increasingly accurate approximations. We conduct the error analysis for both BE and PhiBE with explicit dependence on the discounted coefficient, the reward and the dynamics. Additionally, we present a model-free algorithm to solve PhiBE when only discrete-time trajectory data is available. Numerical experiments are provided to validate the theoretical guarantees we propose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12535v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhua Zhu</dc:creator>
    </item>
    <item>
      <title>Ergodic Unobservable MDPs: Decidability of Approximation</title>
      <link>https://arxiv.org/abs/2405.12583</link>
      <description>arXiv:2405.12583v1 Announce Type: new 
Abstract: Unobservable Markov decision processes (UMDPs) serve as a prominent mathematical framework for modeling sequential decision-making problems. A key aspect in computational analysis is the consideration of decidability, which concerns the existence of algorithms. In general, the computation of the exact and approximated values is undecidable for UMDPs with the long-run average objective. Building on matrix product theory and ergodic properties, we introduce a novel subclass of UMDPs, termed ergodic UMDPs. Our main result demonstrates that approximating the value within this subclass is decidable. However, we show that the exact problem remains undecidable. Finally, we discuss the primary challenges of extending these results to partially observable Markov decision processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12583v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnendu Chatterjee, David Lurie, Raimundo Saona, Bruno Ziliotto</dc:creator>
    </item>
    <item>
      <title>Lipschitz minimization and the Goldstein modulus</title>
      <link>https://arxiv.org/abs/2405.12655</link>
      <description>arXiv:2405.12655v1 Announce Type: new 
Abstract: Goldstein's 1977 idealized iteration for minimizing a Lipschitz objective fixes a distance - the step size - and relies on a certain approximate subgradient. That "Goldstein subgradient" is the shortest convex combination of objective gradients at points within that distance of the current iterate. A recent implementable Goldstein-style algorithm allows a remarkable complexity analysis (Zhang et al. 2020), and a more sophisticated variant (Davis and Jiang, 2022) leverages typical objective geometry to force near-linear convergence. To explore such methods, we introduce a new modulus, based on Goldstein subgradients, that robustly measures the slope of a Lipschitz function. We relate near-linear convergence of Goldstein-style methods to linear growth of this modulus at minimizers. We illustrate the idea computationally with a simple heuristic for Lipschitz minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12655v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Kong, Adrian S. Lewis</dc:creator>
    </item>
    <item>
      <title>Clarabel: An interior-point solver for conic programs with quadratic objectives</title>
      <link>https://arxiv.org/abs/2405.12762</link>
      <description>arXiv:2405.12762v1 Announce Type: new 
Abstract: We present a general-purpose interior-point solver for convex optimization problems with conic constraints. Our method is based on a homogeneous embedding method originally developed for general monotone complementarity problems and more recently applied to operator splitting methods, and here specialized to an interior-point method for problems with quadratic objectives. We allow for a variety of standard symmetric and non-symmetric cones, and provide support for chordal decomposition methods in the case of semidefinite cones. We describe the implementation of this method in the open-source solver Clarabel, and provide a detailed numerical evaluation of its performance versus several state-of-the-art solvers on a wide range of standard benchmarks problems. Clarabel is faster and more robust than competing commercial and open-source solvers across a range of test sets, with a particularly large performance advantage for problems with quadratic objectives. Clarabel is currently distributed as a standard solver for the Python CVXPY optimization suite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12762v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul J. Goulart, Yuwen Chen</dc:creator>
    </item>
    <item>
      <title>Chordal-NMF with Riemannian Multiplicative Update</title>
      <link>https://arxiv.org/abs/2405.12823</link>
      <description>arXiv:2405.12823v1 Announce Type: new 
Abstract: Nonnegative Matrix Factorization (NMF) is the problem of approximating a given nonnegative matrix M through the conic combination of two nonnegative low-rank matrices W and H. Traditionally NMF is tackled by optimizing a specific objective function evaluating the quality of the approximation. This assessment is often done based on the Frobenius norm. In this study, we argue that the Frobenius norm as the "point-to-point" distance may not always be appropriate. Due to the nonnegative combination resulting in a polyhedral cone, this conic perspective of NMF may not naturally align with conventional point-to-point distance measures. Hence, a ray-to-ray chordal distance is proposed as an alternative way of measuring the discrepancy between M and WH. This measure is related to the Euclidean distance on the unit sphere, motivating us to employ nonsmooth manifold optimization approaches.
  We apply Riemannian optimization technique to solve chordal-NMF by casting it on a manifold. Unlike existing works on Riemannian optimization that require the manifold to be smooth, the nonnegativity in chordal-NMF is a non-differentiable manifold. We propose a Riemannian Multiplicative Update (RMU) that preserves the convergence properties of Riemannian gradient descent without breaking the smoothness condition on the manifold.
  We showcase the effectiveness of the Chordal-NMF on synthetic datasets as well as real-world multispectral images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12823v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flavia Esposito, Andersen Ang</dc:creator>
    </item>
    <item>
      <title>Aircraft Conflict Resolution: A Benchmark Generator</title>
      <link>https://arxiv.org/abs/2405.12836</link>
      <description>arXiv:2405.12836v1 Announce Type: new 
Abstract: Aircraft conflict resolution is one of the major tasks of computer-aided air traffic management and represents a challenging optimization problem. Many models and methods have been proposed to assist trajectory regulation to avoid conflicts. However, the question of testing the different mathematical optimization approaches against each other is still open. Standard benchmarks include unrealistic scenarios in which all the flights move toward a common point or completely random generated instances. There is a lack of a common set of test instances that allows comparison of the available methods under a variety of heterogeneous and representative scenarios. We present a flight deconfliction benchmark generator that allows the user to choose between (i) different predefined scenario inspired by existing benchmarks in the literature; (ii) pseudo-random traffic meeting certain congestion measurements; (iii) and randomly generated traffic. The proposed setting can account for different levels of difficulty in the deconfliction of the aircraft and allows to explore and compare the real limitations of optimization approaches for aircraft conflict resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12836v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/ijoc.2022.1265</arxiv:DOI>
      <arxiv:journal_reference>INFORMS Journal on Computing, Volume 35, Number 2, Pages 274-285 (2023)</arxiv:journal_reference>
      <dc:creator>Mercedes Pelegrin, Martina Cerulli</dc:creator>
    </item>
    <item>
      <title>Quantum computing and the stable set problem</title>
      <link>https://arxiv.org/abs/2405.12845</link>
      <description>arXiv:2405.12845v1 Announce Type: new 
Abstract: Given an undirected graph, the stable set problem asks to determine the cardinality of the largest subset of pairwise non-adjacent vertices. This value is called the stability number of the graph, and its computation is an NP-hard problem. In this paper, we focus on solving the stable set problem using the D-wave quantum annealer. By formulating the problem as a quadratic unconstrained binary optimization problem with the penalty method, we show that the optimal value of this formulation is equal to the stability number of the graph for certain penalty parameter values. However, D-Wave's quantum annealer is not an exact solver, so the solutions may be far from the optimum and may not even represent stable sets. To address this, we introduce a post-processing procedure that identifies samples that could lead to improved solutions and extracts stable sets from them. Additionally, we propose a so-called simple CH-partitioning method to handle larger instances that cannot be embedded on D-Wave's quantum processing unit. Finally, we investigate how different penalty parameter values affect the solutions' quality. Extensive computational results show that the post-processing procedure significantly improves the solution quality, while the simple CH-partitioning method successfully extends our approach to medium-size instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12845v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alja\v{z} Krpan, Janez Povh, Dunja Pucher</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking is Stable for Scalar Maps that are Strictly but Not Strongly Convex</title>
      <link>https://arxiv.org/abs/2405.12908</link>
      <description>arXiv:2405.12908v1 Announce Type: new 
Abstract: For a map that is strictly but not strongly convex, model-based gradient extremum seeking has an eigenvalue of zero at the extremum, i.e., it fails at exponential convergence. Interestingly, perturbation-based model-free extremum seeking has a negative Jacobian, in the average, meaning that its (practical) convergence is exponential, even though the map's Hessian is zero at the extremum. While these observations for the gradient algorithm are not trivial, we focus in this paper on an even more nontrivial study of the same phenomenon for Newton-based extremum seeking control (NESC).
  NESC is a second-order method which corrects for the unknown Hessian of the unknown map, not only in order to speed up parameter convergence, but also (1) to make the convergence rate user-assignable in spite of the unknown Hessian, and (2) to equalize the convergence rates in different directions for multivariable maps. Previous NESC work established stability only for maps whose Hessians are strictly positive definite everywhere, so the Hessian is invertible everywhere. For a scalar map, we establish the rather unexpected property that, even when the map behind is strictly convex but not strongly convex, i.e., when the Hessian may be zero, NESC guarantees practical asymptotic stability, semiglobally. While a model-based Newton-based algorithm would run into non-invertibility of the Hessian, the perturbation-based NESC, surprisingly, avoids this challenge by leveraging the fact that the average of the perturbation-based Hessian estimate is always positive, even though the actual Hessian may be zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12908v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick McNamee, Miroslav Krsti\'c, Zahra Nili Ahmadabadi</dc:creator>
    </item>
    <item>
      <title>The implications of state aggregation in deteriorating Markov Decision Processes with optimal threshold policies</title>
      <link>https://arxiv.org/abs/2405.12912</link>
      <description>arXiv:2405.12912v1 Announce Type: new 
Abstract: Markov Decision Processes (MDPs) are mathematical models of sequential decision-making under uncertainty that have found applications in healthcare, manufacturing, logistics, and others. In these models, a decision-maker observes the state of a stochastic process and determines which action to take with the goal of maximizing the expected total discounted rewards received. In many applications, the state space of the true system is large and there may be limited observations out of certain states to estimate the transition probability matrix. To overcome this, modelers will aggregate the true states into ``superstates" resulting in a smaller state space. This aggregation process improves computational tractability and increases the number of observations among superstates. Thus, the modeler's choice of state space leads to a trade-off in transition probability estimates. While coarser discretization of the state space gives more observations in each state to estimate the transition probability matrix, this comes at the cost of precision in the state characterization and resulting policy recommendations. In this paper, we consider the implications of this modeling decision on the resulting policies from MDPs for which the true model is expected to have a threshold policy that is optimal. We analyze these MDPs and provide conditions under which the aggregated MDP will also have an optimal threshold policy. Using a simulation study, we explore the trade-offs between more fine and more coarse aggregation. We explore the the show that there is the highest potential for policy improvement on larger state spaces, but that aggregated MDPs are preferable under limited data. We discuss how these findings the implications of our findings for modelers who must select which state space design to use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12912v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madeleine Pollack, Lauren N. Steimle</dc:creator>
    </item>
    <item>
      <title>Adaptive Variant of Frank-Wolfe Method for Relative Smooth Convex Optimization Problems</title>
      <link>https://arxiv.org/abs/2405.12948</link>
      <description>arXiv:2405.12948v1 Announce Type: new 
Abstract: The paper introduces a new adaptive version of the Frank-Wolfe algorithm for relatively smooth convex functions. It is proposed to use the Bregman divergence other than half the square of the Euclidean norm in the formula for step-size. Algorithm convergence estimates for minimization problems of relatively smooth convex functions with the triangle scaling property are proved. Computational experiments are performed, and conditions are shown in which the obvious advantage of the proposed algorithm over its Euclidean norm analogue is shown. We also found examples of problems for which the proposed variation of the Frank-Wolfe method works better than known accelerated gradient-type methods for relatively smooth convex functions with the triangle scaling property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12948v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Vyguzov, Fedor Stonyakin</dc:creator>
    </item>
    <item>
      <title>Orthogonally Initiated Particle Swarm Optimization with Advanced Mutation for Real-Parameter Optimization</title>
      <link>https://arxiv.org/abs/2405.12542</link>
      <description>arXiv:2405.12542v1 Announce Type: cross 
Abstract: This article introduces an enhanced particle swarm optimizer (PSO), termed Orthogonal PSO with Mutation (OPSO-m). Initially, it proposes an orthogonal array-based learning approach to cultivate an improved initial swarm for PSO, significantly boosting the adaptability of swarm-based optimization algorithms. The article further presents archive-based self-adaptive learning strategies, dividing the population into regular and elite subgroups. Each subgroup employs distinct learning mechanisms. The regular group utilizes efficient learning schemes derived from three unique archives, which categorize individuals based on their quality levels. Additionally, a mutation strategy is implemented to update the positions of elite individuals. Comparative studies are conducted to assess the effectiveness of these learning strategies in OPSO-m, evaluating its optimization capacity through exploration-exploitation dynamics and population diversity analysis. The proposed OPSO-m model is tested on real-parameter challenges from the CEC 2017 suite in 10, 30, 50, and 100-dimensional search spaces, with its results compared to contemporary state-of-the-art algorithms using a sensitivity metric. OPSO-m exhibits distinguished performance in the precision of solutions, rapidity of convergence, efficiency in search, and robust stability, thus highlighting its superior aptitude for resolving intricate optimization issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12542v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Indu Bala, Dikshit Chauhan, Lewis Mitchell</dc:creator>
    </item>
    <item>
      <title>Fast Estimation of Relative Transformation Based on Fusion of Odometry and UWB Ranging Data</title>
      <link>https://arxiv.org/abs/2405.12577</link>
      <description>arXiv:2405.12577v1 Announce Type: cross 
Abstract: In this paper, we investigate the problem of estimating the 4-DOF (three-dimensional position and orientation) robot-robot relative frame transformation using odometers and distance measurements between robots. Firstly, we apply a two-step estimation method based on maximum likelihood estimation. Specifically, a good initial value is obtained through unconstrained least squares and projection, followed by a more accurate estimate achieved through one-step Gauss-Newton iteration. Additionally, the optimal installation positions of Ultra-Wideband (UWB) are provided, and the minimum operating time under different quantities of UWB devices is determined. Simulation demonstrates that the two-step approach offers faster computation with guaranteed accuracy while effectively addressing the relative transformation estimation problem within limited space constraints. Furthermore, this method can be applied to real-time relative transformation estimation when a specific number of UWB devices are installed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12577v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Fu, Zheng Zhang, Guangyang Zeng, Chun Liu, Junfeng Wu, Xiaoqiang Ren</dc:creator>
    </item>
    <item>
      <title>Robust portfolio optimization model for electronic coupon allocation</title>
      <link>https://arxiv.org/abs/2405.12865</link>
      <description>arXiv:2405.12865v1 Announce Type: cross 
Abstract: Currently, many e-commerce websites issue online/electronic coupons as an effective tool for promoting sales of various products and services. We focus on the problem of optimally allocating coupons to customers subject to a budget constraint on an e-commerce website. We apply a robust portfolio optimization model based on customer segmentation to the coupon allocation problem. We also validate the efficacy of our method through numerical experiments using actual data from randomly distributed coupons. Main contributions of our research are twofold. First, we handle six types of coupons, thereby making it extremely difficult to accurately estimate the difference in the effects of various coupons. Second, we demonstrate from detailed numerical results that the robust optimization model achieved larger uplifts of sales than did the commonly-used multiple-choice knapsack model and the conventional mean-variance optimization model. Our results open up great potential for robust portfolio optimization as an effective tool for practical coupon allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12865v1</guid>
      <category>cs.IR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuki Uehara, Naoki Nishimura, Yilin Li, Jie Yang, Deddy Jobson, Koya Ohashi, Takeshi Matsumoto, Noriyoshi Sukegawa, Yuichi Takano</dc:creator>
    </item>
    <item>
      <title>Keep the Momentum: Conservation Laws beyond Euclidean Gradient Flows</title>
      <link>https://arxiv.org/abs/2405.12888</link>
      <description>arXiv:2405.12888v1 Announce Type: cross 
Abstract: Conservation laws are well-established in the context of Euclidean gradient flow dynamics, notably for linear or ReLU neural network training. Yet, their existence and principles for non-Euclidean geometries and momentum-based dynamics remain largely unknown. In this paper, we characterize "all" conservation laws in this general setting. In stark contrast to the case of gradient flows, we prove that the conservation laws for momentum-based dynamics exhibit temporal dependence. Additionally, we often observe a "conservation loss" when transitioning from gradient flow to momentum dynamics. Specifically, for linear networks, our framework allows us to identify all momentum conservation laws, which are less numerous than in the gradient flow case except in sufficiently over-parameterized regimes. With ReLU networks, no conservation law remains. This phenomenon also manifests in non-Euclidean metrics, used e.g. for Nonnegative Matrix Factorization (NMF): all conservation laws can be determined in the gradient flow context, yet none persists in the momentum case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12888v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sibylle Marcotte, R\'emi Gribonval, Gabriel Peyr\'e</dc:creator>
    </item>
    <item>
      <title>Quantum optimal control robust to $1/f^\alpha$ noises using fractional calculus: voltage-controlled exchange in semiconductor spin qubits</title>
      <link>https://arxiv.org/abs/2405.12922</link>
      <description>arXiv:2405.12922v1 Announce Type: cross 
Abstract: Low-frequency $1/f^\alpha$ charge noise significantly hinders the performance of voltage-controlled spin qubits in quantum dots. Here, we utilize fractional calculus to design voltage control pulses yielding the highest average fidelities for noisy quantum gate operations. We focus specifically on the exponential voltage control of the exchange interaction generating two-spin $\mathrm{SWAP}^k$ gates. When stationary charge noise is the dominant source of gate infidelity, we derive that the optimal exchange pulse is long and weak, with the broad shape of the symmetric beta distribution function with parameter $1-\alpha/2$. The common practice of making exchange pulses fast and high-amplitude still remains beneficial in the case of strongly nonstationary noise dynamics, modeled as fractional Brownian motion. The proposed methods are applicable to the characterization and optimization of quantum gate operations in various voltage-controlled qubit architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12922v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.mes-hall</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohdan Khromets, Jonathan Baugh</dc:creator>
    </item>
    <item>
      <title>Truncated Variance Reduced Value Iteration</title>
      <link>https://arxiv.org/abs/2405.12952</link>
      <description>arXiv:2405.12952v1 Announce Type: cross 
Abstract: We provide faster randomized algorithms for computing an $\epsilon$-optimal policy in a discounted Markov decision process with $A_{\text{tot}}$-state-action pairs, bounded rewards, and discount factor $\gamma$. We provide an $\tilde{O}(A_{\text{tot}}[(1 - \gamma)^{-3}\epsilon^{-2} + (1 - \gamma)^{-2}])$-time algorithm in the sampling setting, where the probability transition matrix is unknown but accessible through a generative model which can be queried in $\tilde{O}(1)$-time, and an $\tilde{O}(s + (1-\gamma)^{-2})$-time algorithm in the offline setting where the probability transition matrix is known and $s$-sparse. These results improve upon the prior state-of-the-art which either ran in $\tilde{O}(A_{\text{tot}}[(1 - \gamma)^{-3}\epsilon^{-2} + (1 - \gamma)^{-3}])$ time [Sidford, Wang, Wu, Ye 2018] in the sampling setting, $\tilde{O}(s + A_{\text{tot}} (1-\gamma)^{-3})$ time [Sidford, Wang, Wu, Yang, Ye 2018] in the offline setting, or time at least quadratic in the number of states using interior point methods for linear programming. We achieve our results by building upon prior stochastic variance-reduced value iteration methods [Sidford, Wang, Wu, Yang, Ye 2018]. We provide a variant that carefully truncates the progress of its iterates to improve the variance of new variance-reduced sampling procedures that we introduce to implement the steps. Our method is essentially model-free and can be implemented in $\tilde{O}(A_{\text{tot}})$-space when given generative model access. Consequently, our results take a step in closing the sample-complexity gap between model-free and model-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12952v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujia Jin, Ishani Karmarkar, Aaron Sidford, Jiayi Wang</dc:creator>
    </item>
    <item>
      <title>A description based on optimal transport for a class of stochastic McKean-Vlasov control problems</title>
      <link>https://arxiv.org/abs/2405.12960</link>
      <description>arXiv:2405.12960v1 Announce Type: cross 
Abstract: We study the convergence of an $N$-particle Markovian controlled system to the solution of a family of stochastic McKean-Vlasov control problems, either with a finite horizon or Schr\"odinger type cost functional. Specifically, under suitable assumptions, we prove the convergence of the value functions, the fixed-time probability distributions, and the relative entropy of their path-space probability laws. These proofs are based on a Benamou-Brenier type reformulation of the problem and a superposition principle, both of which are tools from the theory of optimal transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12960v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco C. De Vecchi, Chiara Rigoni</dc:creator>
    </item>
    <item>
      <title>Decomposition-Coordination Method for Finite Horizon Bandit Problems</title>
      <link>https://arxiv.org/abs/2106.01165</link>
      <description>arXiv:2106.01165v2 Announce Type: replace 
Abstract: Optimally solving a multi-armed bandit problem suffers the curse of dimensionality. Indeed, resorting to dynamic programming leads to an exponential growth of computing time, as the number of arms and the horizon increase. We introduce a decompositioncoordination heuristic, DeCo, that turns the initial problem into parallelly coordinated one-armed bandit problems. As a consequence, we obtain a computing time which is essentially linear in the number of arms. In addition, the decomposition provides a theoretical lower bound on the regret. For the two-armed bandit case, dynamic programming provides the exact solution, which is almost matched by the DeCo heuristic. Moreover, in numerical simulations with up to 100 rounds and 20 arms, DeCo outperforms classic algorithms (Thompson sampling and Kullback-Leibler upper-confidence bound) and almost matches the theoretical lower bound on the regret for 20 arms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.01165v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michel de Lara (ENPC), Benjamin Heymann (CERMICS, ENPC), Jean-Philippe Chancelier (CERMICS, ENPC)</dc:creator>
    </item>
    <item>
      <title>Convergence of ease-controlled Random Reshuffling gradient Algorithms under Lipschitz smoothness</title>
      <link>https://arxiv.org/abs/2212.01848</link>
      <description>arXiv:2212.01848v3 Announce Type: replace 
Abstract: In this work, we consider minimizing the average of a very large number of smooth and possibly non-convex functions, and we focus on two widely used minibatch frameworks to tackle this optimization problem: Incremental Gradient (IG) and Random Reshuffling (RR). We define ease-controlled modifications of the IG/RR schemes, which require a light additional computational effort {but} can be proved to converge under {weak} and standard assumptions. In particular, we define two algorithmic schemes in which the IG/RR iteration is controlled by using a watchdog rule and a derivative-free linesearch that activates only sporadically to guarantee convergence. The two schemes differ in the watchdog and the linesearch, which are performed using either a monotonic or a non-monotonic rule. The two schemes also allow controlling the updating of the stepsize used in the main IG/RR iteration, avoiding the use of pre-set rules that may drive the stepsize to zero too fast, reducing the effort in designing effective updating rules of the stepsize. We prove convergence under the mild assumption of Lipschitz continuity of the gradients of the component functions and perform extensive computational analysis using different deep neural architectures and a benchmark of varying-size datasets. We compare our implementation with both a full batch gradient method (i.e. L-BFGS) and an implementation of IG/RR methods, proving that our algorithms require a similar computational effort compared to the other online algorithms and that the control on the learning rate may allow a faster decrease of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01848v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruggiero Seccia, Corrado Coppola, Giampaolo Liuzzi, Laura Palagi</dc:creator>
    </item>
    <item>
      <title>Learning-based Rigid Tube Model Predictive Control</title>
      <link>https://arxiv.org/abs/2304.05105</link>
      <description>arXiv:2304.05105v2 Announce Type: replace 
Abstract: This paper is concerned with model predictive control (MPC) of discrete-time linear systems subject to bounded additive disturbance and mixed constraints on the state and input, whereas the true disturbance set is unknown. Unlike most existing work on robust MPC, we propose an algorithm incorporating online learning that builds on prior knowledge of the disturbance, i.e., a known but conservative disturbance set. We approximate the true disturbance set at each time step with a parameterised set, which is referred to as a quantified disturbance set, using disturbance realisations. A key novelty is that the parameterisation of these quantified disturbance sets enjoys desirable properties such that the quantified disturbance set and its corresponding rigid tube bounding disturbance propagation can be efficiently updated online. We provide statistical gaps between the true and quantified disturbance sets, based on which, probabilistic recursive feasibility of MPC optimisation problems is discussed. Numerical simulations are provided to demonstrate the effectiveness of our proposed algorithm and compare with conventional robust MPC algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.05105v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulong Gao, Shuhao Yan, Jian Zhou, Mark Cannon, Alessandro Abate, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>A bilevel approach for compensation and routing decisions in last-mile delivery</title>
      <link>https://arxiv.org/abs/2304.09170</link>
      <description>arXiv:2304.09170v2 Announce Type: replace 
Abstract: In last-mile delivery logistics, peer-to-peer logistic platforms play an important role in connecting senders, customers, and independent carriers to fulfill delivery requests. Since the carriers are not under the platform's control, the platform has to anticipate their reactions, while deciding how to allocate the delivery operations. Indeed, carriers' decisions largely affect the platform's revenue. In this paper, we model this problem using bilevel programming. At the upper level, the platform decides how to assign the orders to the carriers; at the lower level, each carrier solves a profitable tour problem to determine which offered requests to accept, based on her own profit maximization. Possibly, the platform can influence carriers' decisions by determining also the compensation paid for each accepted request. The two considered settings result in two different formulations: the bilevel profitable tour problem with fixed compensation margins and with margin decisions, respectively. For each of them, we propose single-level reformulations and alternative formulations where the lower-level routing variables are projected out. A branch-and-cut algorithm is proposed to solve the bilevel models, with a tailored warm-start heuristic used to speed up the solution process. Extensive computational tests are performed to compare the proposed formulations and analyze solution characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09170v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martina Cerulli, Claudia Archetti, Elena Fernandez, Ivana Ljubic</dc:creator>
    </item>
    <item>
      <title>Weakly coupled systems of eikonal equations for autonomous vehicles</title>
      <link>https://arxiv.org/abs/2310.02966</link>
      <description>arXiv:2310.02966v2 Announce Type: replace 
Abstract: In this paper, we study solutions for a weakly coupled system of eikonal equations arising in an optimal path-planning problem with random breakdown. The model considered takes into account two types of breakdown for the vehicle, partial and total, which happen at a known, spatially inhomogeneous rate. In particular, we analyze the complications due to the delicate degenerate coupling condition by using existing results on weakly coupled systems of Hamilton-Jacobi equations. Then we consider finite element method schemes built for convection-diffusion problems to construct approximate solutions for this system and produce some numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02966v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Teresa Chiri, Kenneth D Czuprynski, Ludmil T Zikatanov</dc:creator>
    </item>
    <item>
      <title>A hybrid deep learning method for finite-horizon mean-field game problems</title>
      <link>https://arxiv.org/abs/2310.18968</link>
      <description>arXiv:2310.18968v2 Announce Type: replace 
Abstract: This paper develops a new deep learning algorithm to solve a class of finite-horizon mean-field games. The proposed hybrid algorithm uses Markov chain approximation method combined with a stochastic approximation-based iterative deep learning algorithm. Under the framework of finite-horizon mean-field games, the induced measure and Monte-Carlo algorithm are adopted to establish the iterative mean-field interaction in Markov chain approximation method and deep learning, respectively. The Markov chain approximation method plays a key role in constructing the iterative algorithm and estimating an initial value of a neural network, whereas stochastic approximation is used to find accurate parameters in a bounded region. The convergence of the hybrid algorithm is proved; two numerical examples are provided to illustrate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18968v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Zhang, Zhuo Jin, Jiaqin Wei, George Yin</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification of Set-Membership Estimation in Control and Perception: Revisiting the Minimum Enclosing Ellipsoid</title>
      <link>https://arxiv.org/abs/2311.15962</link>
      <description>arXiv:2311.15962v3 Announce Type: replace 
Abstract: Set-membership estimation (SME) outputs a set estimator that guarantees to cover the groundtruth. Such sets are, however, defined by (many) abstract (and potentially nonconvex) constraints and therefore difficult to manipulate. We present tractable algorithms to compute simple and tight overapproximations of SME in the form of minimum enclosing ellipsoids (MEE). We first introduce the hierarchy of enclosing ellipsoids proposed by Nie and Demmel (2005), based on sums-of-squares relaxations, that asymptotically converge to the MEE of a basic semialgebraic set. This framework, however, struggles in modern control and perception problems due to computational challenges. We contribute three computational enhancements to make this framework practical, namely constraints pruning, generalized relaxed Chebyshev center, and handling non-Euclidean geometry. We showcase numerical examples on system identification and object pose estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15962v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yukai Tang, Jean-Bernard Lasserre, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Verifying message-passing neural networks via topology-based bounds tightening</title>
      <link>https://arxiv.org/abs/2402.13937</link>
      <description>arXiv:2402.13937v2 Announce Type: replace 
Abstract: Since graph neural networks (GNNs) are often vulnerable to attack, we need to know when we can trust them. We develop a computationally effective approach towards providing robust certificates for message-passing neural networks (MPNNs) using a Rectified Linear Unit (ReLU) activation function. Because our work builds on mixed-integer optimization, it encodes a wide variety of subproblems, for example it admits (i) both adding and removing edges, (ii) both global and local budgets, and (iii) both topological perturbations and feature modifications. Our key technology, topology-based bounds tightening, uses graph structure to tighten bounds. We also experiment with aggressive bounds tightening to dynamically change the optimization constraints by tightening variable bounds. To demonstrate the effectiveness of these strategies, we implement an extension to the open-source branch-and-cut solver SCIP. We test on both node and graph classification problems and consider topological attacks that both add and remove edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13937v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Hojny, Shiqiang Zhang, Juan S. Campos, Ruth Misener</dc:creator>
    </item>
    <item>
      <title>Fast Computation of Superquantile-Constrained Optimization Through Implicit Scenario Reduction</title>
      <link>https://arxiv.org/abs/2405.07965</link>
      <description>arXiv:2405.07965v2 Announce Type: replace 
Abstract: Superquantiles have recently gained significant interest as a risk-aware metric for addressing fairness and distribution shifts in statistical learning and decision making problems. This paper introduces a fast, scalable and robust second-order computational framework to solve large-scale optimization problems with superquantile-based constraints. Unlike empirical risk minimization, superquantile-based optimization requires ranking random functions evaluated across all scenarios to compute the tail conditional expectation. While this tail-based feature might seem computationally unfriendly, it provides an advantageous setting for a semismooth-Newton-based augmented Lagrangian method. The superquantile operator effectively reduces the dimensions of the Newton systems since the tail expectation involves considerably fewer scenarios. Notably, the extra cost of obtaining relevant second-order information and performing matrix inversions is often comparable to, and sometimes even less than, the effort required for gradient computation. Our developed solver is particularly effective when the number of scenarios substantially exceeds the number of decision variables. In synthetic problems with linear and convex diagonal quadratic objectives, numerical experiments demonstrate that our method outperforms existing approaches by a large margin: It achieves speeds more than 750 times faster for linear and quadratic objectives than the alternating direction method of multipliers as implemented by OSQP for computing low-accuracy solutions. Additionally, it is up to 25 times faster for linear objectives and 70 times faster for quadratic objectives than the commercial solver Gurobi, and 20 times faster for linear objectives and 30 times faster for quadratic objectives than the Portfolio Safeguard optimization suite for high-accuracy solution computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07965v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jake Roth, Ying Cui</dc:creator>
    </item>
    <item>
      <title>Decision Machines: An Extension of Decision Trees</title>
      <link>https://arxiv.org/abs/2101.11347</link>
      <description>arXiv:2101.11347v4 Announce Type: replace-cross 
Abstract: Here is a compact representation of binary decision trees. We explicitly formulate the dependence of prediction on binary tests for decision trees and construct a procedure to guide the input sample from the root to its exit node. And we provides a connection between decision trees and error-correcting output codes. Then we borrow the ideas from attention mechanism to approximate and extend this formulation via continuous functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.11347v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic optimal transport and Hamilton-Jacobi-Bellman equations on the set of probability measures</title>
      <link>https://arxiv.org/abs/2306.04283</link>
      <description>arXiv:2306.04283v2 Announce Type: replace-cross 
Abstract: We introduce a stochastic version of the optimal transport problem. We provide an analysis by means of the study of the associated Hamilton-Jacobi-Bellman equation, which is set on the set of probability measures. We introduce a new definition of viscosity solutions of this equation, which yields general comparison principles, in particular for cases involving terms modeling stochasticity in the optimal control problem. We are then able to establish results of existence and uniqueness of viscosity solutions of the Hamilton-Jacobi-Bellman equation. These results rely on controllability results for stochastic optimal transport that we also establish.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04283v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Bertucci (CMAP)</dc:creator>
    </item>
    <item>
      <title>On Learning the Optimal Regularization Parameter in Inverse Problems</title>
      <link>https://arxiv.org/abs/2311.15845</link>
      <description>arXiv:2311.15845v4 Announce Type: replace-cross 
Abstract: Selecting the best regularization parameter in inverse problems is a classical and yet challenging problem. Recently, data-driven approaches have become popular to tackle this challenge. These approaches are appealing since they do require less a priori knowledge, but their theoretical analysis is limited. In this paper, we propose and study a statistical machine learning approach, based on empirical risk minimization. Our main contribution is a theoretical analysis, showing that, provided with enough data, this approach can reach sharp rates while being essentially adaptive to the noise and smoothness of the problem. Numerical simulations corroborate and illustrate the theoretical findings. Our results are a step towards grounding theoretically data-driven approaches to inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15845v4</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Chirinos Rodriguez, Ernesto De Vito, Cesare Molinari, Lorenzo Rosasco, Silvia Villa</dc:creator>
    </item>
    <item>
      <title>Two Choices are Enough for P-LCPs, USOs, and Colorful Tangents</title>
      <link>https://arxiv.org/abs/2402.07683</link>
      <description>arXiv:2402.07683v2 Announce Type: replace-cross 
Abstract: We provide polynomial-time reductions between three search problems from three distinct areas: the P-matrix linear complementarity problem (P-LCP), finding the sink of a unique sink orientation (USO), and a variant of the $\alpha$-Ham Sandwich problem. For all three settings, we show that "two choices are enough", meaning that the general non-binary version of the problem can be reduced in polynomial time to the binary version. This specifically means that generalized P-LCPs are equivalent to P-LCPs, and grid USOs are equivalent to cube USOs. These results are obtained by showing that both the P-LCP and our $\alpha$-Ham Sandwich variant are equivalent to a new problem we introduce, P-Lin-Bellman. This problem can be seen as a new tool for formulating problems as P-LCPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07683v2</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michaela Borzechowski, John Fearnley, Spencer Gordon, Rahul Savani, Patrick Schnider, Simon Weber</dc:creator>
    </item>
    <item>
      <title>Anisotropic power diagrams for polycrystal modelling: efficient generation of curved grains via optimal transport</title>
      <link>https://arxiv.org/abs/2403.03571</link>
      <description>arXiv:2403.03571v2 Announce Type: replace-cross 
Abstract: The microstructure of metals and foams can be effectively modelled with anisotropic power diagrams (APDs), which provide control over the shape of individual grains. One major obstacle to the wider adoption of APDs is the computational cost that is associated with their generation. We propose a novel approach to generate APDs with prescribed statistical properties, including fine control over the size of individual grains. To this end, we rely on fast optimal transport algorithms that stream well on Graphics Processing Units (GPU) and handle non-uniform, anisotropic distance functions. This allows us to find large APDs that best fit experimental data and generate synthetic high-resolution microstructures in (tens of) seconds. This unlocks their use for computational homogenisation, which is especially relevant to machine learning methods that require the generation of large collections of representative microstructures as training data. The paper is accompanied by a Python library, PyAPD, which is freely available at: www.github.com/mbuze/PyAPD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03571v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Buze, Jean Feydy, Steven M. Roper, Karo Sedighiani, David P. Bourne</dc:creator>
    </item>
    <item>
      <title>Optimizing Sensor Network Design for Multiple Coverage</title>
      <link>https://arxiv.org/abs/2405.09096</link>
      <description>arXiv:2405.09096v2 Announce Type: replace-cross 
Abstract: Sensor placement optimization methods have been studied extensively. They can be applied to a wide range of applications, including surveillance of known environments, optimal locations for 5G towers, and placement of missile defense systems. However, few works explore the robustness and efficiency of the resulting sensor network concerning sensor failure or adversarial attacks. This paper addresses this issue by optimizing for the least number of sensors to achieve multiple coverage of non-simply connected domains by a prescribed number of sensors. We introduce a new objective function for the greedy (next-best-view) algorithm to design efficient and robust sensor networks and derive theoretical bounds on the network's optimality. We further introduce a Deep Learning model to accelerate the algorithm for near real-time computations. The Deep Learning model requires the generation of training examples. Correspondingly, we show that understanding the geometric properties of the training data set provides important insights into the performance and training process of deep learning techniques. Finally, we demonstrate that a simple parallel version of the greedy approach using a simpler objective can be highly competitive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09096v2</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Taus, Yen-Hsi Richard Tsai</dc:creator>
    </item>
  </channel>
</rss>
