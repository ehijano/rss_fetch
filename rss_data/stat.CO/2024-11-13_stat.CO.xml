<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Nov 2024 02:43:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On theoretical guarantees and a blessing of dimensionality for nonconvex sampling</title>
      <link>https://arxiv.org/abs/2411.07776</link>
      <description>arXiv:2411.07776v1 Announce Type: new 
Abstract: Existing guarantees for algorithms sampling from nonlogconcave measures on $\mathbb{R}^d$ are generally inexplicit or unscalable. Even for the class of measures with logdensities that have bounded Hessians and are strongly concave outside a Euclidean ball of radius $R$, no available theory is comprehensively satisfactory with respect to both $R$ and $d$. In this paper, it is shown that complete polynomial complexity can in fact be achieved if $R\leq c\sqrt{d}$, whilst an exponential number of point evaluations is generally necessary for any algorithm as soon as $R\geq C\sqrt{d}$ for constants $C&gt;c&gt;0$. A simple importance sampler with tail-matching proposal achieves the former, owing to a blessing of dimensionality. On the other hand, if strong concavity outside a ball is replaced by a distant dissipativity condition, then sampling guarantees must generally scale exponentially with $d$ in all parameter regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07776v1</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Chak</dc:creator>
    </item>
    <item>
      <title>Scaling Up Bayesian Neural Networks with Neural Networks</title>
      <link>https://arxiv.org/abs/2312.11799</link>
      <description>arXiv:2312.11799v2 Announce Type: replace 
Abstract: Bayesian Neural Networks (BNNs) offer a principled and natural framework for proper uncertainty quantification in the context of deep learning. They address the typical challenges associated with conventional deep learning methods, such as data insatiability, ad-hoc nature, and susceptibility to overfitting. However, their implementation typically either relies on Markov chain Monte Carlo (MCMC) methods, which are characterized by their computational intensity and inefficiency in a high-dimensional space, or variational inference methods, which tend to underestimate uncertainty. To address this issue, we propose a novel Calibration-Emulation-Sampling (CES) strategy to significantly enhance the computational efficiency of BNN. In this framework, during the initial calibration stage, we collect a small set of samples from the parameter space. These samples serve as training data for the emulator, which approximates the map between parameters and posterior probability. The trained emulator is then used for sampling from the posterior distribution at substantially higher speed compared to the standard BNN. Using simulated and real data, we demonstrate that our proposed method improves computational efficiency of BNN, while maintaining similar performance in terms of prediction accuracy and uncertainty quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11799v2</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zahra Moslemi, Yang Meng, Shiwei Lan, Babak Shahbaba</dc:creator>
    </item>
    <item>
      <title>Sequential Monte Carlo for Cut-Bayesian Posterior Computation</title>
      <link>https://arxiv.org/abs/2406.07555</link>
      <description>arXiv:2406.07555v2 Announce Type: replace 
Abstract: We propose a sequential Monte Carlo (SMC) method to efficiently and accurately compute cut-Bayesian posterior quantities of interest, variations of standard Bayesian approaches constructed primarily to account for model misspecification. We prove finite sample concentration bounds for estimators derived from the proposed method and apply these results to a realistic setting where a computer model is misspecified. Two theoretically justified variations are presented for making the sequential Monte Carlo estimator more computationally efficient, based on linear tempering and finding suitable permutations of initial parameter draws. We then illustrate the SMC method for inference in a modular chemical reactor example that includes submodels for reaction kinetics, turbulence, mass transfer, and diffusion. The samples obtained are commensurate with a direct-sampling approach that consists of running multiple Markov chains, with computational efficiency gains using the SMC method. Overall, the SMC method presented yields a novel, rigorous approach to computing with cut-Bayesian posterior distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07555v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Mathews, Giri Gopalan, James Gattiker, Sean Smith, Devin Francom</dc:creator>
    </item>
    <item>
      <title>Exact Gradient Evaluation for Adaptive Quadrature Approximate Marginal Likelihood in Mixed Models for Grouped Data</title>
      <link>https://arxiv.org/abs/2310.01589</link>
      <description>arXiv:2310.01589v2 Announce Type: replace-cross 
Abstract: A method is introduced for approximate marginal likelihood inference via adaptive Gaussian quadrature in mixed models with a single grouping factor. The core technical contribution is an algorithm for computing the exact gradient of the approximate log-marginal likelihood. This leads to efficient maximum likelihood via quasi-Newton optimization that is demonstrated to be faster than existing approaches based on finite-differenced gradients or derivative-free optimization. The method is specialized to Bernoulli mixed models with multivariate, correlated Gaussian random effects; here computations are performed using an inverse log-Cholesky parameterization of the Gaussian density that involves no matrix decomposition during model fitting, while Wald confidence intervals are provided for variance parameters on the original scale. Simulations give evidence of these intervals attaining nominal coverage if enough quadrature points are used, for data comprised of a large number of very small groups exhibiting large between-group heterogeneity. The Laplace approximation is well-known to give especially poor coverage and high bias for data comprised of a large number of small groups. Adaptive quadrature mitigates this, and the methods in this paper improve the computational feasibility of this more accurate method. All results may be reproduced using code available at \url{https://github.com/awstringer1/aghmm-paper-code}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01589v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Stringer</dc:creator>
    </item>
  </channel>
</rss>
