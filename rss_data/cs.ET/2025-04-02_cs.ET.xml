<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Apr 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimizing Package Delivery with Quantum Annealers: Addressing Time-Windows and Simultaneous Pickup and Delivery</title>
      <link>https://arxiv.org/abs/2504.01560</link>
      <description>arXiv:2504.01560v1 Announce Type: new 
Abstract: Recent research at the intersection of quantum computing and routing problems has been highly prolific. Much of this work focuses on classical problems such as the Traveling Salesman Problem and the Vehicle Routing Problem. The practical applicability of these problems depends on the specific objectives and constraints considered. However, it is undeniable that translating complex real-world requirements into these classical formulations often proves challenging. In this paper, we resort to our previously published quantum-classical technique for addressing real-world-oriented routing problems, known as Quantum for Real Package Delivery (Q4RPD), and elaborate on solving additional realistic problem instances. Accordingly, this paper emphasizes the following characteristics: i) simultaneous pickup and deliveries, ii) time-windows, and iii) mobility restrictions by vehicle type. To illustrate the application of Q4RPD, we have conducted an experimentation comprising seven instances, serving as a demonstration of the newly developed features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01560v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eneko Osaba, Esther Villar-Rodriguez, Pablo Miranda-Rodriguez, Ant\'on Asla</dc:creator>
    </item>
    <item>
      <title>Over-the-Air Edge Inference via End-to-End Metasurfaces-Integrated Artificial Neural Networks</title>
      <link>https://arxiv.org/abs/2504.00233</link>
      <description>arXiv:2504.00233v1 Announce Type: cross 
Abstract: In the Edge Inference (EI) paradigm, where a Deep Neural Network (DNN) is split across the transceivers to wirelessly communicate goal-defined features in solving a computational task, the wireless medium has been commonly treated as a source of noise. In this paper, motivated by the emerging technologies of Reconfigurable Intelligent Surfaces (RISs) and Stacked Intelligent Metasurfaces (SIM) that offer programmable propagation of wireless signals, either through controllable reflections or diffractions, we optimize the RIS/SIM-enabled smart wireless environment as a means of over-the-air computing, resembling the operations of DNN layers. We propose a framework of Metasurfaces-Integrated Neural Networks (MINNs) for EI, presenting its modeling, training through a backpropagation variation for fading channels, and deployment aspects. The overall end-to-end DNN architecture is general enough to admit RIS and SIM devices, through controllable reconfiguration before each transmission or fixed configurations after training, while both channel-aware and channel-agnostic transceivers are considered. Our numerical evaluation showcases metasurfaces to be instrumental in performing image classification under link budgets that impede conventional communications or metasurface-free systems. It is demonstrated that our MINN framework can significantly simplify EI requirements, achieving near-optimal performance with $50~$dB lower testing signal-to-noise ratio compared to training, even without transceiver channel knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00233v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyriakos Stylianopoulos, Paolo Di Lorenzo, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>Split Federated Learning for UAV-Enabled Integrated Sensing, Computation, and Communication</title>
      <link>https://arxiv.org/abs/2504.01443</link>
      <description>arXiv:2504.01443v1 Announce Type: cross 
Abstract: Unmanned aerial vehicles (UAVs) with integrated sensing, computation, and communication (ISCC) capabilities have become key enablers of next-generation wireless networks. Federated edge learning (FEL) leverages UAVs as mobile learning agents to collect data, perform local model updates, and contribute to global model aggregation. However, existing UAV-assisted FEL systems face critical challenges, including excessive computational demands, privacy risks, and inefficient communication, primarily due to the requirement for full-model training on resource-constrained UAVs. To deal with aforementioned challenges, we propose Split Federated Learning for UAV-Enabled ISCC (SFLSCC), a novel framework that integrates split federated learning (SFL) into UAV-assisted FEL. SFLSCC optimally partitions model training between UAVs and edge servers, significantly reducing UAVs' computational burden while preserving data privacy. We conduct a theoretical analysis of UAV deployment, split point selection, data sensing volume, and client-side aggregation frequency, deriving closed-form upper bounds for the convergence gap. Based on these insights, we conceive a joint optimization problem to minimize the energy consumption required to achieve a target model accuracy. Given the non-convex nature of the problem, we develop a low-complexity algorithm to efficiently determine UAV deployment, split point selection, and communication frequency. Extensive simulations on a target motion recognition task validate the effectiveness of SFLSCC, demonstrating superior convergence performance and energy efficiency compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01443v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangwang Hou, Jingjing Wang, Zekai Zhang, Jiacheng Wang, Lei Liu, Yong Ren</dc:creator>
    </item>
    <item>
      <title>Quantum Computing for Optimizing Aircraft Loading</title>
      <link>https://arxiv.org/abs/2504.01567</link>
      <description>arXiv:2504.01567v1 Announce Type: cross 
Abstract: The aircraft loading optimization problem is a computationally hard problem with the best known classical algorithm scaling exponentially with the number of objects. We propose a quantum approach based on a multi-angle variant of the QAOA algorithm (Multi-Angle Layered Variational Quantum Algorithm (MAL-VQA)) designed to utilize a smaller number of two qubit gates in the quantum circuit as compared to the standard QAOA algorithm so that the quantum optimization algorithm can be run on near-term ion-trap quantum processing units (QPU). We also describe a novel cost function implementation that can handle many different types of inequality constraints without the overhead of introducing slack variables in the quantum circuit so that larger problems with complex constraints may be represented on near-term QPUs which have low qubit counts. We demonstrate the performance of the algorithm on different instances of the aircraft loading problem by execution on IonQ QPUs Aria and Forte. Our experiments obtain the optimal solutions for all the problem instances studied ranging from 12 qubits to 28 qubits. This shows the potential scalability of the method to significantly larger problem sizes with the improvement of quantum hardware in the near future as well as the robustness of the quantum algorithm against varying initial guesses and varying constraints of different problem instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01567v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ananth Kaushik, Sang Hyub Kim, Willie Aboumrad, Martin Roetteler, Albana Topi, Richard Ashworth</dc:creator>
    </item>
    <item>
      <title>Iterative Interpolation Schedules for Quantum Approximate Optimization Algorithm</title>
      <link>https://arxiv.org/abs/2504.01694</link>
      <description>arXiv:2504.01694v1 Announce Type: cross 
Abstract: Quantum Approximate Optimization Algorithm (QAOA) is a promising quantum optimization heuristic with empirical evidence of speedup over classical state-of-the-art for some problems. QAOA solves optimization problems using a parameterized circuit with $p$ layers, with higher $p$ leading to better solutions. Existing methods require optimizing $2p$ independent parameters which is challenging for large $p$. In this work, we present an iterative interpolation method that exploits the smoothness of optimal parameter schedules by expressing them in a basis of orthogonal functions, generalizing Zhou et al. By optimizing a small number of basis coefficients and iteratively increasing both circuit depth and the number of coefficients until convergence, our approach enables construction of high-quality schedules for large $p$. We demonstrate our method achieves better performance with fewer optimization steps than current approaches on three problems: the Sherrington-Kirkpatrick (SK) model, portfolio optimization, and Low Autocorrelation Binary Sequences (LABS). For the largest LABS instance, we achieve near-optimal merit factors with schedules exceeding 1000 layers, an order of magnitude beyond previous methods. As an application of our technique, we observe a mild growth of QAOA depth sufficient to solve SK model exactly, a result of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01694v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anuj Apte, Shree Hari Sureshbabu, Ruslan Shaydulin, Sami Boulebnane, Zichang He, Dylan Herman, James Sud, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>Streamlined optical training of large-scale modern deep learning architectures with direct feedback alignment</title>
      <link>https://arxiv.org/abs/2409.12965</link>
      <description>arXiv:2409.12965v2 Announce Type: replace 
Abstract: Modern deep learning relies nearly exclusively on dedicated electronic hardware accelerators. Photonic approaches, with low consumption and high operation speed, are increasingly considered for inference but, to date, remain mostly limited to relatively basic tasks. Simultaneously, the problem of training deep and complex neural networks, overwhelmingly performed through backpropagation, remains a significant limitation to the size and, consequently, the performance of current architectures and a major compute and energy bottleneck. Here, we experimentally implement a versatile and scalable training algorithm, called direct feedback alignment, on a hybrid electronic-photonic platform. An optical processing unit performs large-scale random matrix multiplications, which is the central operation of this algorithm, at speeds up to 1500 TeraOPS under 30 Watts of power. We perform optical training of modern deep learning architectures, including Transformers, with more than 1B parameters, and obtain good performances on language, vision, and diffusion-based generative tasks. We study the scaling of the training time, and demonstrate a potential advantage of our hybrid opto-electronic approach for ultra-deep and wide neural networks, thus opening a promising route to sustain the exponential growth of modern artificial intelligence beyond traditional von Neumann approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12965v2</guid>
      <category>cs.ET</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>physics.app-ph</category>
      <category>physics.optics</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziao Wang, Kilian M\"uller, Matthew Filipovich, Julien Launay, Ruben Ohana, Gustave Pariente, Safa Mokaadi, Charles Brossollet, Fabien Moreau, Alessandro Cappelli, Iacopo Poli, Igor Carron, Laurent Daudet, Florent Krzakala, Sylvain Gigan</dc:creator>
    </item>
    <item>
      <title>Machine Learning-assisted High-speed Combinatorial Optimization with Ising Machines for Dynamically Changing Problems</title>
      <link>https://arxiv.org/abs/2503.23966</link>
      <description>arXiv:2503.23966v2 Announce Type: replace 
Abstract: Quantum or quantum-inspired Ising machines have recently shown promise in solving combinatorial optimization problems in a short time. Real-world applications, such as time division multiple access (TDMA) scheduling for wireless multi-hop networks and financial trading, require solving those problems sequentially where the size and characteristics change dynamically. However, using Ising machines involves challenges to shorten system-wide latency due to the transfer of large Ising model or the cloud access and to determine the parameters for each problem. Here we show a combinatorial optimization method using embedded Ising machines, which enables solving diverse problems at high speed without runtime parameter tuning. We customize the algorithm and circuit architecture of the simulated bifurcation-based Ising machine to compress the Ising model and accelerate computation and then built a machine learning model to estimate appropriate parameters using extensive training data. In TDMA scheduling for wireless multi-hop networks, our demonstration has shown that the sophisticated system can adapt to changes in the problem and showed that it has a speed advantage over conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23966v2</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yohei Hamakawa, Tomoya Kashimata, Masaya Yamasaki, Kosuke Tatsumura</dc:creator>
    </item>
    <item>
      <title>Hyper-Compression: Model Compression via Hyperfunction</title>
      <link>https://arxiv.org/abs/2409.00592</link>
      <description>arXiv:2409.00592v3 Announce Type: replace-cross 
Abstract: The rapid growth of large models' size has far outpaced that of computing resources. To bridge this gap, encouraged by the parsimonious relationship between genotype and phenotype in the brain's growth and development, we propose the so-called hyper-compression that turns the model compression into the issue of parameter representation via a hyperfunction. Specifically, it is known that the trajectory of some low-dimensional dynamic systems can fill the high-dimensional space eventually. Thus, hyper-compression, using these dynamic systems as the hyperfunctions, represents the parameters of the target network by their corresponding composition number or trajectory length. This suggests a novel mechanism for model compression, substantially different from the existing pruning, quantization, distillation, and decomposition. Along this direction, we methodologically identify a suitable dynamic system with the irrational winding as the hyperfunction and theoretically derive its associated error bound. Next, guided by our theoretical insights, we propose several engineering twists to make the hyper-compression pragmatic and effective. Lastly, systematic and comprehensive experiments confirm that hyper-compression enjoys the following \textbf{PNAS} merits: 1) \textbf{P}referable compression ratio; 2) \textbf{N}o post-hoc retraining; 3) \textbf{A}ffordable inference time; and 4) \textbf{S}hort compression time. It compresses LLaMA2-7B in an hour and achieves close-to-int4-quantization performance, without retraining and with a performance drop of less than 1\%. We have open-sourced our code in https://github.com/Juntongkuki/Hyper-Compression.git for free download and evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00592v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fenglei Fan, Juntong Fan, Dayang Wang, Jingbo Zhang, Zelin Dong, Shijun Zhang, Ge Wang, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>Ownership-based Virtual Memory for Intermittently-Powered Embedded Systems</title>
      <link>https://arxiv.org/abs/2501.17707</link>
      <description>arXiv:2501.17707v2 Announce Type: replace-cross 
Abstract: The Internet of Batteryless Things might revolutionize our understanding of connected devices by harvesting required operational energy from the environment (e.g., using solar cells). These systems come with the major system-software challenge that the intermittently-powered IoT devices have to checkpoint their state in non-volatile memory to later resume operation with this state when sufficient energy is available. The scarce energy resources demand that only modified data is persisted to non-volatile memory before a power failure, which requires precise modification tracking.
  We present vNV-Heap, the first ownership-based virtually Non-Volatile Heap for intermittently-powered systems with guaranteed power-failure resilience. The heap exploits ownership systems, a zero-cost (i.e., compile-time) abstraction for example implemented by Rust, to track modifications and virtualize object persistence. To achieve power-failure resilience, our heap is designed and implemented to guarantee bounded operations by static program code analysis: For example, the heap allows for determining a worst-case energy consumption for the operation of persisting modified and currently volatile objects. Our evaluation with our open-source implementation on an embedded hardware platform (i.e., ESP32-C3) shows that using our heap abstraction is more energy efficient than existing approaches while also providing runtime guarantees by static worst-case bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17707v2</guid>
      <category>cs.OS</category>
      <category>cs.ET</category>
      <category>cs.PL</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Markus Elias Gerber, Luis Gerhorst, Ishwar Mudraje, Kai Vogelgesang, Thorsten Herfet, Peter W\"agemann</dc:creator>
    </item>
    <item>
      <title>Comparative Study of Spike Encoding Methods for Environmental Sound Classification</title>
      <link>https://arxiv.org/abs/2503.11206</link>
      <description>arXiv:2503.11206v2 Announce Type: replace-cross 
Abstract: Spiking Neural Networks (SNNs) offer a promising approach to reduce energy consumption and computational demands, making them particularly beneficial for embedded machine learning in edge applications. However, data from conventional digital sensors must first be converted into spike trains to be processed using neuromorphic computing technologies. The classification of environmental sounds presents unique challenges due to the high variability of frequencies, background noise, and overlapping acoustic events. Despite these challenges, most studies on spike-based audio encoding focus on speech processing, leaving non-speech environmental sounds underexplored. In this work, we conduct a comprehensive comparison of widely used spike encoding techniques, evaluating their effectiveness on the ESC-10 dataset. By understanding the impact of encoding choices on environmental sound processing, researchers and practitioners can select the most suitable approach for real-world applications such as smart surveillance, environmental monitoring, and industrial acoustic analysis. This study serves as a benchmark for spike encoding in environmental sound classification, providing a foundational reference for future research in neuromorphic audio processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11206v2</guid>
      <category>cs.SD</category>
      <category>cs.ET</category>
      <category>eess.AS</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andres Larroza, Javier Naranjo-Alcazar, Vicent Ortiz Castell\'o, Pedro Zuccarello</dc:creator>
    </item>
    <item>
      <title>GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS</title>
      <link>https://arxiv.org/abs/2503.23633</link>
      <description>arXiv:2503.23633v2 Announce Type: replace-cross 
Abstract: The advent of generative AI exemplified by large language models (LLMs) opens new ways to represent and compute geographic information and transcend the process of geographic knowledge production, driving geographic information systems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core, autonomous GIS can independently generate and execute geoprocessing workflows to perform spatial analysis. In this vision paper, we elaborate on the concept of autonomous GIS and present a framework that defines its five autonomous goals, five levels of autonomy, five core functions, and three operational scales. We demonstrate how autonomous GIS could perform geospatial data retrieval, spatial analysis, and map making with four proof-of-concept GIS agents. We conclude by identifying critical challenges and future research directions, including fine-tuning and self-growing decision cores, autonomous modeling, and examining the ethical and practical implications of autonomous GIS. By establishing the groundwork for a paradigm shift in GIScience, this paper envisions a future where GIS moves beyond traditional workflows to autonomously reason, derive, innovate, and advance solutions to pressing global challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23633v2</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenlong Li, Huan Ning, Song Gao, Krzysztof Janowicz, Wenwen Li, Samantha T. Arundel, Chaowei Yang, Budhendra Bhaduri, Shaowen Wang, A-Xing Zhu, Mark Gahegan, Shashi Shekhar, Xinyue Ye, Grant McKenzie, Guido Cervone, Michael E. Hodgson</dc:creator>
    </item>
  </channel>
</rss>
