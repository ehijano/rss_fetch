<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 02:35:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Basic interactive algorithms: Preview</title>
      <link>https://arxiv.org/abs/2508.05798</link>
      <description>arXiv:2508.05798v1 Announce Type: new 
Abstract: This dialog paper offers a preview and provides a foretaste of an upcoming work on the axiomatization of basic interactive algorithms.
  The modern notion of algorithm was elucidated in the 1930s--1950s. It was axiomatized a quarter of a century ago as the notion of ``sequential algorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm" now. The axiomatization was used to show that for every basic algorithm there is a behaviorally equivalent abstract state machine. It was also used to prove the Church-Turing thesis as it has been understood by the logicians.
  Starting from the 1960s, the notion of algorithm has expanded -- probabilistic algorithms, quantum algorithms, etc. -- prompting introduction of a much more ambitious version of the Church-Turing thesis commonly known as the ``physical thesis.'' We emphasize the difference between the two versions of the Church-Turing thesis and illustrate how nondeterministic and probabilistic algorithms can be viewed as basic algorithms with appropriate oracles. The same view applies to quantum circuit algorithms and many other classes of algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05798v1</guid>
      <category>cs.LO</category>
      <category>cs.CL</category>
      <category>math.LO</category>
      <category>quant-ph</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The Bulletin of the EATCS, volume 146, June 2025</arxiv:journal_reference>
      <dc:creator>Yuri Gurevich</dc:creator>
    </item>
    <item>
      <title>Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games</title>
      <link>https://arxiv.org/abs/2508.06088</link>
      <description>arXiv:2508.06088v1 Announce Type: new 
Abstract: For model checking stochastic games (SGs), bounded value iteration (BVI) algorithms have gained attention as efficient approximate methods with rigorous precision guarantees. However, BVI may not terminate or converge when the target SG contains end components. Most existing approaches address this issue by explicitly detecting and processing end components--a process that is often computationally expensive. An exception is the widest path-based BVI approach previously studied by Phalakarn et al., which we refer to as 1WP-BVI. The method performs particularly well in the presence of numerous end components. Nonetheless, its theoretical foundations remain somewhat ad hoc. In this paper, we identify and formalize the core principles underlying the widest path-based BVI approach by (i) presenting 2WP-BVI, a clean BVI algorithm based on (2-player) widest path games, and (ii) proving its correctness using what we call the maximality inheritance principle--a proof principle previously employed in a well-known result in probabilistic model checking. Our experimental results demonstrate the practical relevance and potential of our proposed 2WP-BVI algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06088v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kittiphon Phalakarn, Yun Chen Tsai, Ichiro Hasuo</dc:creator>
    </item>
    <item>
      <title>Hybrid Game Control Envelope Synthesis</title>
      <link>https://arxiv.org/abs/2508.05997</link>
      <description>arXiv:2508.05997v1 Announce Type: cross 
Abstract: Control problems for embedded systems like cars and trains can be modeled by two-player hybrid games. Control envelopes, which are families of safe control solutions, correspond to nondeterministic winning policies of hybrid games, where each deterministic specialization of the policy is a control solution. This paper synthesizes nondeterministic winning policies for hybrid games that are as permissive as possible. It introduces subvalue maps, a compositional representation of such policies that enables verification and synthesis along the structure of the game. An inductive logical characterization in differential game logic (dGL) checks whether a subvalue map induces a sound control envelope which always induces a winning play. A policy is said to win if it always achieves the desirable outcome when the player follows it, no matter what actions the opponent plays. The maximal subvalue map, which allows the most action options while still winning, is shown to exist and satisfy a logical characterization. A family of algorithms for nondeterministic policy synthesis can be obtained from the inductive subvalue map soundness characterization. An implementation of these findings is evaluated on examples that use the expressivity of dGL to model a range of diverse control challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05997v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditi Kabra, Jonathan Laurent, Stefan Mitsch, Andr\'e Platzer</dc:creator>
    </item>
    <item>
      <title>Don't Forget Imagination!</title>
      <link>https://arxiv.org/abs/2508.06062</link>
      <description>arXiv:2508.06062v1 Announce Type: cross 
Abstract: Cognitive imagination is a type of imagination that plays a key role in human thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to mentally visualize coherent and holistic systems of concepts and causal links that serve as semantic contexts for reasoning, decision making and prediction. Our position is that the role of cognitive imagination is still greatly underestimated, and this creates numerous problems and diminishes the current capabilities of AI. For instance, when reasoning, humans rely on imaginary contexts to retrieve background info. They also constantly return to the context for semantic verification that their reasoning is still reasonable. Thus, reasoning without imagination is blind. This paper is a call for greater attention to cognitive imagination as the next promising breakthrough in artificial intelligence. As an instrument for simulating cognitive imagination, we propose semantic models -- a new approach to mathematical models that can learn, like neural networks, and are based on probabilistic causal relationships. Semantic models can simulate cognitive imagination because they ensure the consistency of imaginary contexts and implement a glass-box approach that allows the context to be manipulated as a holistic and coherent system of interrelated facts glued together with causal relations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06062v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evgenii E. Vityaev, Andrei Mantsivoda</dc:creator>
    </item>
    <item>
      <title>Numerical Considerations in Weighted Model Counting</title>
      <link>https://arxiv.org/abs/2508.06264</link>
      <description>arXiv:2508.06264v1 Announce Type: cross 
Abstract: Weighted model counting computes the sum of the rational-valued weights associated with the satisfying assignments for a Boolean formula, where the weight of an assignment is given by the product of the weights assigned to the positive and negated variables comprising the assignment. Weighted model counting finds applications across a variety of domains including probabilistic reasoning and quantitative risk assessment.
  Most weighted model counting programs operate by (explicitly or implicitly) converting the input formula into a form that enables arithmetic evaluation, using multiplication for conjunctions and addition for disjunctions. Performing this evaluation using floating-point arithmetic can yield inaccurate results, and it cannot quantify the level of precision achieved. Computing with rational arithmetic gives exact results, but it is costly in both time and space.
  This paper describes how to combine multiple numeric representations to efficiently compute weighted model counts that are guaranteed to achieve a user-specified precision. When all weights are nonnegative, we prove that the precision loss of arithmetic evaluation using floating-point arithmetic can be tightly bounded. We show that supplementing a standard IEEE double-precision representation with a separate 64-bit exponent, a format we call extended-range double (ERD), avoids the underflow and overflow issues commonly encountered in weighted model counting. For problems with mixed negative and positive weights, we show that a combination of interval floating-point arithmetic and rational arithmetic can achieve the twin goals of efficiency and guaranteed precision. For our evaluations, we have devised especially challenging formulas and weight assignments, demonstrating the robustness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06264v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.NA</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Randal E. Bryant</dc:creator>
    </item>
    <item>
      <title>Tighter Bounds for Query Answering with Guarded TGDs</title>
      <link>https://arxiv.org/abs/2212.11362</link>
      <description>arXiv:2212.11362v4 Announce Type: replace 
Abstract: We consider the complexity of the open-world query answering problem, where we wish to determine certain answers to conjunctive queries over incomplete datasets specified by an initial set of facts and a set of guarded TGDs. This problem has been well-studied in the literature and is decidable but with a high complexity, namely, it is 2EXPTIME complete. Further, the complexity shrinks by one exponential when the arity is fixed.
  We show in this paper how we can obtain better complexity bounds when considering separately the arity of the guard atom and that of the additional atoms, called the side signature. Our results make use of the technique of linearizing guarded TGDs, introduced in Gottlob, Manna, and Pieris. Specifically, we present a variant of the linearization process, making use of a restricted version of the chase that we recently introduced. Our results imply that open-world query answering with guarded TGDs can be solved in EXPTIME with arbitrary-arity guard relations if we simply bound the arity of the side signature; and that the complexity drops to NP if we fix the side signature and bound the width of the dependencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11362v4</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Amarilli, Michael Benedikt</dc:creator>
    </item>
    <item>
      <title>Small Term Reachability and Related Problems for Terminating Term Rewriting Systems</title>
      <link>https://arxiv.org/abs/2412.06047</link>
      <description>arXiv:2412.06047v3 Announce Type: replace 
Abstract: Motivated by an application where we try to make proofs for Description Logic inferences smaller by rewriting, we consider the following decision problem, which we call the small term reachability problem: given a term rewriting system $R$, a term $s$, and a natural number $n$, decide whether there is a term $t$ of size $\leq n$ reachable from $s$ using the rules of $R$. We investigate the complexity of this problem depending on how termination of $R$ can be established. We show that the problem is in general NP-complete for length-reducing term rewriting systems. Its complexity increases to N2ExpTime-complete (NExpTime-complete) if termination is proved using a (linear) polynomial order and to PSpace-complete for systems whose termination can be shown using a restricted class of Knuth-Bendix orders. Confluence reduces the complexity to P for the length-reducing case, but has no effect on the worst-case complexity in the other two cases. Finally, we consider the large term reachability problem, a variant of the problem where we are interested in reachability of a term of size $\geq n$. It turns out that this seemingly innocuous modification in some cases changes the complexity of the problem, which may also become dependent on whether the number $n$ is is represented in unary or binary encoding, whereas this makes no difference for the complexity of the small term reachability problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06047v3</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Franz Baader, J\"urgen Giesl</dc:creator>
    </item>
    <item>
      <title>Reopening of the conjecture about the decidability of Quasi-Dense Modal Logics (Comments on Lyon &amp; Ostropolski-Nalewaja's result)</title>
      <link>https://arxiv.org/abs/2507.11644</link>
      <description>arXiv:2507.11644v3 Announce Type: replace 
Abstract: In \cite{Lyon24} the question of the decidability of quasi-dense modal logics is answered, and an upper bound in $\EXPSPACE$ is given. Unfortunately, authors' intricate proof seems to contain a major flaw that cannot be fixed, leaving the question wide open.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11644v3</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olivier Gasquet</dc:creator>
    </item>
    <item>
      <title>Recursive windows for grammar logics of bounded density</title>
      <link>https://arxiv.org/abs/2507.14956</link>
      <description>arXiv:2507.14956v3 Announce Type: replace 
Abstract: We introduce the family of multi-modal logics of bounded density and with a tableau-like approach using finite \emph{windows} which were introduced in \cite{BalGasq25} and that we generalize to recursive windows. We prove that their satisfiability problem is {\bfseries PSPACE}-complete. As a side effect, the monomodal logic of density is shown to be in para-{\bfseries PSPACE}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14956v3</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olivier Gasquet</dc:creator>
    </item>
    <item>
      <title>A Minimal Substitution Basis for the Kalmar Elementary Functions</title>
      <link>https://arxiv.org/abs/2505.23787</link>
      <description>arXiv:2505.23787v2 Announce Type: replace-cross 
Abstract: We show that the class of Kalmar elementary functions can be inductively generated from the addition, the integer remainder and the base-two exponentiation, hence improving previous results by Marchenkov and Mazzanti. We also prove that the substitution basis defined by these three operations is minimal. Furthermore, we discuss alternative substitution bases under arity constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23787v2</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mihai Prunescu, Lorenzo Sauras-Altuzarra, Joseph M. Shunia</dc:creator>
    </item>
  </channel>
</rss>
