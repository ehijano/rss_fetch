<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jul 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems</title>
      <link>https://arxiv.org/abs/2507.02464</link>
      <description>arXiv:2507.02464v1 Announce Type: new 
Abstract: The CAP theorem asserts a trilemma between consistency, availability, and partition tolerance. This paper introduces a rigorous automata-theoretic and economically grounded framework that reframes the CAP trade-off as a constraint optimization problem. We model distributed systems as partition-aware state machines and embed economic incentive layers to stabilize consensus behavior across adversarially partitioned networks. By incorporating game-theoretic mechanisms into the global transition semantics, we define provable bounds on convergence, liveness, and correctness. Our results demonstrate that availability and consistency can be simultaneously preserved within bounded epsilon margins, effectively extending the classical CAP limits through formal economic control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02464v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <category>cs.FL</category>
      <category>cs.IR</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Craig S Wright</dc:creator>
    </item>
    <item>
      <title>TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games</title>
      <link>https://arxiv.org/abs/2507.02675</link>
      <description>arXiv:2507.02675v1 Announce Type: new 
Abstract: We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO), a new deep reinforcement learning framework. It extends Proximal Policy Optimization (PPO) by integrating team welfare objectives specifically for spatial public goods games. Unlike conventional approaches where cooperation emerges indirectly from individual rewards, TUC-PPO instead optimizes a bi-level objective integrating policy gradients and team utility constraints. Consequently, all policy updates explicitly incorporate collective payoff thresholds. The framework preserves PPO's policy gradient core while incorporating constrained optimization through adaptive Lagrangian multipliers. Therefore, decentralized agents dynamically balance selfish and cooperative incentives. The comparative analysis demonstrates superior performance of this constrained deep reinforcement learning approach compared to unmodified PPO and evolutionary game theory baselines. It achieves faster convergence to cooperative equilibria and greater stability against invasion by defectors. The framework formally integrates team objectives into policy updates. This work advances multi-agent deep reinforcement learning for social dilemmas while providing new computational tools for evolutionary game theory research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02675v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoqilin Yang, Xin Wang, Ruichen Zhang, Chanchan Li, Youliang Tian</dc:creator>
    </item>
    <item>
      <title>Learning to Coordinate Bidders in Non-Truthful Auctions</title>
      <link>https://arxiv.org/abs/2507.02801</link>
      <description>arXiv:2507.02801v1 Announce Type: new 
Abstract: In non-truthful auctions such as first-price and all-pay auctions, the independent strategic behaviors of bidders, with the corresponding equilibrium notion -- Bayes Nash equilibria -- are notoriously difficult to characterize and can cause undesirable outcomes. An alternative approach to designing better auction systems is to coordinate the bidders: let a mediator make incentive-compatible recommendations of correlated bidding strategies to the bidders, namely, implementing a Bayes correlated equilibrium (BCE). The implementation of BCE, however, requires knowledge of the distribution of bidders' private valuations, which is often unavailable. We initiate the study of the sample complexity of learning Bayes correlated equilibria in non-truthful auctions. We prove that the BCEs in a large class of non-truthful auctions, including first-price and all-pay auctions, can be learned with a polynomial number $\tilde O(\frac{n}{\varepsilon^2})$ of samples from the bidders' value distributions. Our technique is a reduction to the problem of estimating bidders' expected utility from samples, combined with an analysis of the pseudo-dimension of the class of all monotone bidding strategies of bidders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02801v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hu Fu, Tao Lin</dc:creator>
    </item>
    <item>
      <title>The algebraic structures of social organizations: the operad of cooperative games</title>
      <link>https://arxiv.org/abs/2507.01969</link>
      <description>arXiv:2507.01969v1 Announce Type: cross 
Abstract: The main goal of this paper is to settle a conceptual framework for cooperative game theory in which the notion of composition/aggregation of games is the defining structure. This is done via the mathematical theory of algebraic operads: we start by endowing the collection of all cooperative games with any number of players with an operad structure, and we show that it generalises all the previous notions of sums, products and compositions of games considered by Owen, Shapley, von Neumann and Morgenstern, and many others. Furthermore, we explicitly compute this operad in terms of generators and relations, showing that the M\"obius transform map induces a canonical isomorphism between the operad of cooperative games and the operad that encodes commutative triassociative algebras. In other words, we prove that any cooperative game is a linear combination of iterated compositions of the 2-player bargaining game and the 2-player dictator games. We show that many interesting classes of games (simple, balanced, capacities a.k.a fuzzy measures and convex functions, totally monotone, etc) are stable under compositions, and thus form suboperads. In the convex case, this gives by the submodularity theorem a new operad structure on the family of all generalized permutahedra. Finally, we focus on how solution concepts in cooperative game theory behave under composition: we study the core of a composite and describe it in terms of the core of its components, and we give explicit formulas for the Shapley value and the Banzhaf index of a compound game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01969v1</guid>
      <category>math.CO</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dylan Laplace Mermoud, Victor Roca i Lucio</dc:creator>
    </item>
    <item>
      <title>Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities</title>
      <link>https://arxiv.org/abs/2507.02125</link>
      <description>arXiv:2507.02125v1 Announce Type: cross 
Abstract: The blockchain oracle problem, which refers to the challenge of injecting reliable external data into decentralized systems, remains a fundamental limitation to the development of trustless applications. While recent years have seen a proliferation of architectural, cryptographic, and economic strategies to mitigate this issue, no one has yet fully resolved the fundamental question of how a blockchain can gain knowledge about the off-chain world. In this position paper, we critically assess the role artificial intelligence (AI) can play in tackling the oracle problem. Drawing from both academic literature and practitioner implementations, we examine how AI techniques such as anomaly detection, language-based fact extraction, dynamic reputation modeling, and adversarial resistance can enhance oracle systems. We observe that while AI introduces powerful tools for improving data quality, source selection, and system resilience, it cannot eliminate the reliance on unverifiable off-chain inputs. Therefore, this study supports the idea that AI should be understood as a complementary layer of inference and filtering within a broader oracle design, not a substitute for trust assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02125v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulio Caldarelli</dc:creator>
    </item>
    <item>
      <title>Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory</title>
      <link>https://arxiv.org/abs/2507.02618</link>
      <description>arXiv:2507.02618v1 Announce Type: cross 
Abstract: Are Large Language Models (LLMs) a new form of strategic intelligence, able to reason about goals in competitive settings? We present compelling supporting evidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for studying decision-making. We conduct the first ever series of evolutionary IPD tournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger) against agents from the leading frontier AI companies OpenAI, Google, and Anthropic. By varying the termination probability in each tournament (the "shadow of the future"), we introduce complexity and chance, confounding memorisation.
  Our results show that LLMs are highly competitive, consistently surviving and sometimes even proliferating in these complex ecosystems. Furthermore, they exhibit distinctive and persistent "strategic fingerprints": Google's Gemini models proved strategically ruthless, exploiting cooperative opponents and retaliating against defectors, while OpenAI's models remained highly cooperative, a trait that proved catastrophic in hostile environments. Anthropic's Claude emerged as the most forgiving reciprocator, showing remarkable willingness to restore cooperation even after being exploited or successfully defecting. Analysis of nearly 32,000 prose rationales provided by the models reveals that they actively reason about both the time horizon and their opponent's likely strategy, and we demonstrate that this reasoning is instrumental to their decisions. This work connects classic game theory with machine psychology, offering a rich and granular view of algorithmic decision-making under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02618v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenneth Payne, Baptiste Alloui-Cros</dc:creator>
    </item>
    <item>
      <title>Horus: A Protocol for Trustless Delegation Under Uncertainty</title>
      <link>https://arxiv.org/abs/2507.00631</link>
      <description>arXiv:2507.00631v3 Announce Type: replace 
Abstract: Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00631v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Shi, Kevin Joo</dc:creator>
    </item>
    <item>
      <title>On the Smoothed Complexity of Combinatorial Local Search</title>
      <link>https://arxiv.org/abs/2211.07547</link>
      <description>arXiv:2211.07547v5 Announce Type: replace-cross 
Abstract: We propose a unifying framework for smoothed analysis of combinatorial local optimization problems, and show how a diverse selection of problems within the complexity class PLS can be cast within this model. This abstraction allows us to identify key structural properties, and corresponding parameters, that determine the smoothed running time of local search dynamics. We formalize this via a black-box tool that provides concrete bounds on the expected maximum number of steps needed until local search reaches an exact local optimum. This bound is particularly strong, in the sense that it holds for any starting feasible solution, any choice of pivoting rule, and does not rely on the choice of specific noise distributions that are applied on the input, but it is parameterized by just a global upper bound $\phi$ on the probability density. The power of this tool can be demonstrated by instantiating it for various PLS-hard problems of interest to derive efficient smoothed running times (as a function of $\phi$ and the input size).
  Most notably, we focus on the important local optimization problem of finding pure Nash equilibria in Congestion Games, that has not been studied before from a smoothed analysis perspective. Specifically, we propose novel smoothed analysis models for general and Network Congestion Games, under various representations, including explicit, step-function, and polynomial resource latencies. We study PLS-hard instances of these problems and show that their standard local search algorithms run in polynomial smoothed time.
  Finally, we present further applications of our framework to a wide range of additional combinatorial problems, including local Max-Cut in weighted graphs, the Travelling Salesman problem (TSP) under the $k$-opt local heuristic, and finding pure equilibria in Network Coordination Games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07547v5</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiannis Giannakopoulos, Alexander Grosz, Themistoklis Melissourgos</dc:creator>
    </item>
  </channel>
</rss>
