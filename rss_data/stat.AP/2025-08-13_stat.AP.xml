<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Aug 2025 04:01:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Bayesian factor analysis model for non-randomised staggered designs</title>
      <link>https://arxiv.org/abs/2508.09554</link>
      <description>arXiv:2508.09554v1 Announce Type: new 
Abstract: The employment of peer supporter workers starting in 2018 was one of the interventions deployed by National Health Service England as part of its Hepatitis C virus (HCV) elimination plan. Peers are individuals with relevant lived experience who educate their communities about the virus and promote testing and treatment. In this paper, we assess the causal effect of the peers intervention on HCV patient case-finding, using data on 22 administrative regions from January 2016 to May 2021. To do this, we develop a Bayesian causal factor analysis model for count outcomes and ordinal interventions. Our method provides uncertainty quantification for all causal estimands of interest, gains efficiency by jointly modelling the intervention assignment process, pre- and post-intervention outcomes, and provides estimates of both conditional average and individual treatment effects (ITEs). For ITEs, we propose a copula-based approach that allows practitioners to perform sensitivity analysis to assumptions made regarding the joint distribution of potential outcomes, that are necessary to estimate these quantities. Our analysis suggests that the introduction of peers led to an increase in HCV patient case-finding. Further, we found that the effect of the intervention increased with intervention intensity, and was stronger during the national COVID-19 lockdown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09554v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Constantin Schmidt, Shaun R. Seaman, Beatrice Emmanouil, Leila Reid, Stuart Smith, Daniela De Angelis, Pantelis Samartsidis</dc:creator>
    </item>
    <item>
      <title>XGBoost meets INLA: a two-stage spatio-temporal forecasting of wildfires in Portugal</title>
      <link>https://arxiv.org/abs/2508.09896</link>
      <description>arXiv:2508.09896v1 Announce Type: new 
Abstract: Wildfires pose a major threat to Portugal, with an average of over 115,000 hectares burned annually in the 45-year period of 1980-2024. Beyond a high number of ignitions, the country has experienced devastating mega-fires, such as those in 2017. Accurate forecasting of wildfire occurrence and burned areas is therefore essential for effective firefighting resource allocation and emergency preparedness. In this study, we present a novel two-stage ensemble approach that extends the widely used latent Gaussian modelling framework with the integrated nested Laplace approximation (INLA) for spatio-temporal wildfire forecasting. The first stage uses XGBoost, a gradient boosting model, to identify wildfire patterns from environmental covariates and historical fire records, producing one-month-ahead point forecasts for fire counts and burned area. These predictions are then incorporated as external covariates in a latent Gaussian model, which includes additional spatiotemporal random effects to produce the final probabilistic forecasts of monthly total fire counts and burned area at the council level. To effectively model both moderate and extreme wildfire events, we implement the extended generalised Pareto (eGP) likelihood (a sub-asymptotic distribution) within the INLA framework. We also develop and discuss penalised complexity priors (PC-priors) for the eGP parameters and provide a comprehensive comparison of the eGP likelihood against other commonly employed distributions in environmental modelling, such as the Gamma and Weibull distributions. The proposed framework addresses the challenge of accessing future environmental covariates, which are typically unavailable at prediction time, and demonstrates strong performance in one-month-ahead wildfire forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09896v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenglei Hu, Regina Baltazar Bispo, H{\aa}vard Rue, Carlos C. DaCamara, Ben Swallow, Daniela Castro-Camilo</dc:creator>
    </item>
    <item>
      <title>Capturing Road-Level Heterogeneity in Crash Severity on Two-Lane Rural Highways: A Multilevel Mixed-Effects Approach</title>
      <link>https://arxiv.org/abs/2508.09941</link>
      <description>arXiv:2508.09941v1 Announce Type: new 
Abstract: Accurately modeling crash severity on rural two-lane roads is essential for effective safety management, yet standard single level approaches often overlook unobserved heterogeneity across road segments. In this study, we analyze 19 956 crash records from 99 rural roads in Iran during recent four years incorporating crash level predictors such as driver age, education, gender, lighting and pavement conditions, along with road level covariates like annual average daily traffic, heavy-vehicle share and terrain slope. We compare three binary logistic frameworks: a single level generalized linear model, a multilevel model with a random intercept capturing latent road level effects (intraclass correlation = 21 %), and a multilevel model with random coefficients that allows key predictor effects to vary by road. The random coefficient model achieves the best fit in terms of deviance, AIC and BIC, and substantially improves predictive performance: classification accuracy rises from 0.62 to 0.71, recall from 0.32 to 0.63, and AUC from 0.570 to 0.775. Results from 200 simulation runs reveal notable variability in slopes for pavement and lighting variables, underscoring how local context influences crash risk. Overall, our findings demonstrate that flexible multilevel modeling not only enhances prediction accuracy but also yields context-specific insights to guide targeted safety interventions on rural road networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09941v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahdi Azhdari, Ali Tavakoli Kashani, Saeideh Amirifar, Amirhossein Taheri, Gerd M\"uller</dc:creator>
    </item>
    <item>
      <title>Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems</title>
      <link>https://arxiv.org/abs/2508.09156</link>
      <description>arXiv:2508.09156v1 Announce Type: cross 
Abstract: We present a framework for fine-tuning flow-matching generative models to enforce physical constraints and solve inverse problems in scientific systems. Starting from a model trained on low-fidelity or observational data, we apply a differentiable post-training procedure that minimizes weak-form residuals of governing partial differential equations (PDEs), promoting physical consistency and adherence to boundary conditions without distorting the underlying learned distribution. To infer unknown physical inputs, such as source terms, material parameters, or boundary data, we augment the generative process with a learnable latent parameter predictor and propose a joint optimization strategy. The resulting model produces physically valid field solutions alongside plausible estimates of hidden parameters, effectively addressing ill-posed inverse problems in a data-driven yet physicsaware manner. We validate our method on canonical PDE benchmarks, demonstrating improved satisfaction of PDE constraints and accurate recovery of latent coefficients. Our approach bridges generative modelling and scientific inference, opening new avenues for simulation-augmented discovery and data-efficient modelling of physical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09156v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Tauberschmidt, Sophie Fellenz, Sebastian J. Vollmer, Andrew B. Duncan</dc:creator>
    </item>
    <item>
      <title>Dynamic Survival Prediction using Longitudinal Images based on Transformer</title>
      <link>https://arxiv.org/abs/2508.09328</link>
      <description>arXiv:2508.09328v1 Announce Type: cross 
Abstract: Survival analysis utilizing multiple longitudinal medical images plays a pivotal role in the early detection and prognosis of diseases by providing insight beyond single-image evaluations. However, current methodologies often inadequately utilize censored data, overlook correlations among longitudinal images measured over multiple time points, and lack interpretability. We introduce SurLonFormer, a novel Transformer-based neural network that integrates longitudinal medical imaging with structured data for survival prediction. Our architecture comprises three key components: a Vision Encoder for extracting spatial features, a Sequence Encoder for aggregating temporal information, and a Survival Encoder based on the Cox proportional hazards model. This framework effectively incorporates censored data, addresses scalability issues, and enhances interpretability through occlusion sensitivity analysis and dynamic survival prediction. Extensive simulations and a real-world application in Alzheimer's disease analysis demonstrate that SurLonFormer achieves superior predictive performance and successfully identifies disease-related imaging biomarkers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09328v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingfan Liu, Haolun Shi, Jiguo Cao</dc:creator>
    </item>
    <item>
      <title>Predictive Significance of CD276/B7-H3 Expression in Baseline Biopsies of Advanced Prostate Carcinoma</title>
      <link>https://arxiv.org/abs/2508.09373</link>
      <description>arXiv:2508.09373v1 Announce Type: cross 
Abstract: At the time of diagnosis, prostate cancer can appear deceptively mild or already display signs of widespread disease. Predicting long-term outcomes is often uncertain. This research focused on measuring CD276/B7-H3, an immune checkpoint protein linked to tumor development, in diagnostic tissue samples from 248 men. Participants included both those with cancer confined to the prostate and those with confirmed metastases. Analysis showed that patients with metastatic disease were more likely to exhibit increased B7-H3 levels. Strong expression of this marker was associated with shorter survival times and was observed alongside higher PSA concentrations and greater tumor aggressiveness based on Gleason grading. These trends remained consistent even when other prognostic factors were taken into account. The results suggest that assessing B7-H3 during the initial biopsy could help clinicians identify high-risk patients earlier. This marker may also represent a new target for treatment strategies in advanced prostate cancer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09373v1</guid>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Yusuf, Paramahansa Pramanik</dc:creator>
    </item>
    <item>
      <title>Consistency assessment and regional sample size calculation for MRCTs under random effects model</title>
      <link>https://arxiv.org/abs/2508.09443</link>
      <description>arXiv:2508.09443v1 Announce Type: cross 
Abstract: Multi-regional clinical trials (MRCTs) have become common practice for drug development and global registration. Once overall significance is established, demonstrating regional consistency is critical for local health authorities. Methods for evaluating such consistency and calculating regional sample sizes have been proposed based on the fixed effects model using various criteria. To better account for the heterogeneity of treatment effects across regions, the random effects model naturally arises as a more effective alternative for both design and inference. In this paper, we present the design of the overall sample size along with regional sample fractions. We also provide the theoretical footage for assessing consistency probability using Method 1 of MHLW (2007), based on the empirical shrinkage estimator. The latter is then used to determine the regional sample size of interest. We elaborate on the applications to common continuous, binary, and survival endpoints in detail. Simulation studies show that the proposed method retains the consistency probability at the desired level. We illustrate the application using a real cardiovascular outcome trial in diabetes. An R package is provided for implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09443v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinru Ren, Jin Xu</dc:creator>
    </item>
    <item>
      <title>Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques</title>
      <link>https://arxiv.org/abs/2508.09810</link>
      <description>arXiv:2508.09810v1 Announce Type: cross 
Abstract: Biomechanical features have become important indicators for evaluating athletes' techniques. Traditionally, experts propose significant features and evaluate them using physics equations. However, the complexity of the human body and its movements makes it challenging to explicitly analyze the relationships between some features and athletes' final performance. With advancements in modern machine learning and statistics, data analytics methods have gained increasing importance in sports analytics. In this study, we leverage machine learning models to analyze expert-proposed biomechanical features from the finals of long jump competitions in the World Championships. The objectives of the analysis include identifying the most important features contributing to top-performing jumps and exploring the combined effects of these key features. Using quantile regression, we model the relationship between the biomechanical feature set and the target variable (effective distance), with a particular focus on elite-level jumps. To interpret the model, we apply SHapley Additive exPlanations (SHAP) alongside Partial Dependence Plots (PDPs) and Individual Conditional Expectation (ICE) plots. The findings reveal that, beyond the well-documented velocity-related features, specific technical aspects also play a pivotal role. For male athletes, the angle of the knee of the supporting leg before take-off is identified as a key factor for achieving top 10% performance in our dataset, with angles greater than 169{\deg}contributing significantly to jump performance. In contrast, for female athletes, the landing pose and approach step technique emerge as the most critical features influencing top 10% performances, alongside velocity. This study establishes a framework for analyzing the impact of various features on athletic performance, with a particular emphasis on top-performing events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09810v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Gan, Stephan Cl\'emen\c{c}on, Moun\^im A. El-Yacoubi, Sao Mai Nguyen, Eric Fenaux, Ons Jelassi</dc:creator>
    </item>
    <item>
      <title>The Causal Effect of the Two-For-One Strategy in the National Basketball Association</title>
      <link>https://arxiv.org/abs/2412.08840</link>
      <description>arXiv:2412.08840v2 Announce Type: replace 
Abstract: This study evaluates the effectiveness of the two-for-one strategy in basketball by applying a causal inference framework to play-by-play data from the 2018-19 and 2021-22 National Basketball Association regular seasons. Incorporating factors such as player lineup, betting odds, and player ratings, we compute the average treatment effect and find that the two-for-one strategy has a positive impact on game outcomes, suggesting it can benefit teams when employed effectively. Additionally, we investigate potential heterogeneity in the strategy's effectiveness using the causal forest framework, with tests indicating no significant variation across different contexts. These findings offer valuable insights into the tactical advantages of the two-for-one strategy in professional basketball.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08840v2</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prateek Sasan, Daryl Swartzentruber</dc:creator>
    </item>
    <item>
      <title>A Diagnostic to Find and Help Combat Stochastic Positivity Issues -- with a Focus on Continuous Treatments</title>
      <link>https://arxiv.org/abs/2502.11820</link>
      <description>arXiv:2502.11820v2 Announce Type: replace 
Abstract: The positivity assumption is central in the identification of a causal effect, and especially the stochastic variant is an issue many applied researchers face, yet is rarely discussed, especially in conjunction with continuous treatments or Modified Treatment Policies. One common recommendation for dealing with a violation is to change the estimand. However, an applied researcher is faced with two problems: First, how can she tell whether there is a stochastic positivity violation given her estimand of interest, preferably without having to estimate a model first? Second, if she finds a problem with stochastic positivity, how should she change her estimand in order to arrive at an estimand which does not face the same issues? We suggest a novel diagnostic which allows the researcher to answer both questions by providing insights into how well an estimation for a certain estimand can be made for each observation using the data at hand. We provide a simulation study on the general behaviour of different Modified Treatment Policies (MTPs) at different levels of stochastic positivity violations and show how the diagnostic helps understand where bias is to be expected. We illustrate the application of our proposed diagnostic in a pharmacoepidemiological study based on data from CHAPAS-3, a trial comparing different treatment regimens for children living with HIV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11820v2</guid>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katharina Ring, Michael Schomaker</dc:creator>
    </item>
    <item>
      <title>A Bayesian approach for fitting semi-Markov mixture models of cancer latency to individual-level data</title>
      <link>https://arxiv.org/abs/2408.14625</link>
      <description>arXiv:2408.14625v2 Announce Type: replace-cross 
Abstract: Multi-state models of cancer natural history are widely used for designing and evaluating cancer early detection strategies. Calibrating such models against longitudinal data from screened cohorts is challenging, especially when fitting non-Markovian mixture models against individual-level data. Here, we consider a family of semi-Markov mixture models of cancer natural history and introduce an efficient data-augmented Markov chain Monte Carlo sampling algorithm for fitting these models to individual-level screening and cancer diagnosis histories. Our fully Bayesian approach supports rigorous uncertainty quantification and model selection through leave-one-out cross-validation, and it enables the estimation of screening-related overdiagnosis rates. We demonstrate the effectiveness of our approach using simulated data, showing that the sampling algorithm efficiently explores the joint posterior distribution of model parameters and latent variables. Finally, we apply our method to data from the US Breast Cancer Surveillance Consortium and estimate the extent of breast cancer overdiagnosis associated with mammography screening. The sampler and model comparison method are available in the R package baclava.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14625v2</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raphael Morsomme, Shannon Holloway, Marc Ryser, Jason Xu</dc:creator>
    </item>
    <item>
      <title>Logarithmic resilience risk metrics that address the huge variations in blackout cost</title>
      <link>https://arxiv.org/abs/2505.12016</link>
      <description>arXiv:2505.12016v2 Announce Type: replace-cross 
Abstract: Resilience risk metrics must address the customer cost of the largest blackouts of greatest impact. However, there are huge variations in blackout cost in observed distribution utility data that make it impractical to properly estimate the mean large blackout cost and the corresponding risk. These problems are caused by the heavy tail observed in the distribution of customer costs. To solve these problems, we propose resilience metrics that describe large blackout risk using the mean of the logarithm of the cost of large-cost blackouts, the slope index of the heavy tail, and the frequency of large-cost blackouts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12016v2</guid>
      <category>q-fin.RM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arslan Ahmad, Ian Dobson</dc:creator>
    </item>
    <item>
      <title>MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements</title>
      <link>https://arxiv.org/abs/2506.02260</link>
      <description>arXiv:2506.02260v2 Announce Type: replace-cross 
Abstract: The growing prevalence of digital health technologies has led to the generation of complex multi-modal data, such as physical activity measurements simultaneously collected from various sensors of mobile and wearable devices. These data hold immense potential for advancing health studies, but current methods predominantly rely on supervised learning, requiring extensive labeled datasets that are often expensive or impractical to obtain, especially in clinical studies. To address this limitation, we propose a self-supervised learning framework called Multi-modal Cross-masked Autoencoder (MoCA) that leverages cross-modality masking and the Transformer autoencoder architecture to utilize both temporal correlations within modalities and cross-modal correlations between data streams. We also provide theoretical guarantees to support the effectiveness of the cross-modality masking scheme in MoCA. Comprehensive experiments and ablation studies demonstrate that our method outperforms existing approaches in both reconstruction and downstream tasks. We release open-source code for data processing, pre-training, and downstream tasks in the supplementary materials. This work highlights the transformative potential of self-supervised learning in digital health and multi-modal data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02260v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Howon Ryu, Yuliang Chen, Yacun Wang, Andrea Z. LaCroix, Chongzhi Di, Loki Natarajan, Yu Wang, Jingjing Zou</dc:creator>
    </item>
    <item>
      <title>How Much is Too Much? Learning Personalised Risk Thresholds in Real-World Driving</title>
      <link>https://arxiv.org/abs/2508.00888</link>
      <description>arXiv:2508.00888v2 Announce Type: replace-cross 
Abstract: While naturalistic driving studies have become foundational for providing real-world driver behaviour data, the existing frameworks for identifying risk based on such data have two fundamental limitations: (i) they rely on predefined time windows and fixed thresholds to disentangle risky and normal episodes of driving behaviour, and (ii) they assume stationary behavioural distribution across drivers and trips. These limitations have hindered the ability of the existing frameworks to capture behavioural nuances, adapt to individual variability, or respond to stochastic fluctuations in driving contexts. Thus, there is a need for a unified framework that jointly adapts risk labels and model learning to per-driver behavioural dynamics, a gap this study aims to bridge. We present an adaptive and personalised risk detection framework, built on Belgian naturalistic driving data, integrating a rolling time window with bi-level optimisation and dynamically calibrating both model hyperparameters and driver-specific risk thresholds at the same time. The framework was tested using two safety indicators, speed-weighted time headway and harsh driving events, and three models: Random Forest, XGBoost, and Deep Neural Network (DNN). Speed-weighted time headway yielded more stable and context-sensitive classifications than harsh-event counts. XGBoost maintained consistent performance under changing thresholds, while the DNN excelled in early-risk detection at lower thresholds but exhibited higher variability. The ensemble calibration integrates model-specific thresholds and confidence scores into a unified risk decision, balancing sensitivity and stability. Overall, the framework demonstrates the potential of adaptive and personalised risk detection to enhance real-time safety feedback and support driver-specific interventions within intelligent transport systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00888v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Hossein Kalantari, Eleonora Papadimitriou, Amir Pooyan Afghari</dc:creator>
    </item>
    <item>
      <title>Nonparametric Bayesian Multi-Treatment Mixture Cure Survival Model with Application in Pediatric Oncology</title>
      <link>https://arxiv.org/abs/2508.08975</link>
      <description>arXiv:2508.08975v2 Announce Type: replace-cross 
Abstract: Heterogeneous treatment effect estimation is critical in oncology, particularly in multi-arm trials with overlapping therapeutic components and long-term survivors. These shared mechanisms pose a central challenge to identifying causal effects in precision medicine. We propose a novel covariate-dependent nonparametric Bayesian multi-treatment cure survival model that jointly accounts for common structures among treatments and cure fractions. Through latent link functions, our model leverages sharing among treatments through a flexible modeling approach, enabling individualized survival inference. We adopt a Bayesian route for inference and implement an efficient MCMC algorithm for approximating the posterior. Simulation studies demonstrate the method's robustness and superiority in various specification scenarios. Finally, application to the AALL0434 trial reveals clinically meaningful differences in survival across methotrexate-based regimens and their associations with different covariates, underscoring its practical utility for learning treatment effects in real-world pediatric oncology data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08975v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Chang, John Kairalla, Arkaprava Roy</dc:creator>
    </item>
  </channel>
</rss>
