<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Jun 2024 01:51:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Canceled: A New Reliability Incentive for Energy-Only Electricity Markets</title>
      <link>https://arxiv.org/abs/2406.15687</link>
      <description>arXiv:2406.15687v1 Announce Type: new 
Abstract: This paper considers the reliability problem in energy-only markets. Following widespread blackouts in 2011, Texas introduced a reliability price incentive to attract two GW of net additional natural gas-generating capacity. The incentive is unusual because energy buyers pay the incentive directly to producers in a real-time spot market. The program has created $13 billion in direct payments to generators annually since 2015 and is now being implemented or considered in several major energy markets in the US and abroad. We assess the incentive's impact on the Texas market from three perspectives: First, we derive the incentive's equilibrium effect on the electricity price in a monopolistic market from first principles using a standard partial equilibrium economic model. We then empirically test whether the incentive encouraged net entry into the market or the generating applicant pool, controlling for market and climatic conditions using monthly capacity data. Finally, we look for direct evidence of an incentive response among active traders using real-time market trading data. The three approaches suggest buyers and producers cancel out the incentive, and the price-only program does not encourage new generation capacity to enter the market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15687v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devin Mounts, Robin M. Cross</dc:creator>
    </item>
    <item>
      <title>Revealing risk preferences Evidence from Turkeys 2023 Earthquake</title>
      <link>https://arxiv.org/abs/2406.15905</link>
      <description>arXiv:2406.15905v1 Announce Type: new 
Abstract: The study on risk preferences and its potential changes amid natural catastrophes has been subject of recent study, producing contradictory findings. An often proposed explanation specifically distinguishes between the opposite effect of realized and unrealized losses on risk preferences. Moreover, higher-order risk preferences and its relation to post-disaster behaviors remain unexplored, despite potential theoretical implications. We address these gaps in the literature by conducting experiments with 600 individuals post Turkeys 2023 catastrophic earthquake, specifically heavily affected individuals who are displaced, those who are not and a control group. Results indicate higher risk-taking in heavily affected individuals when compared to unaffected individuals. Our results are specifically driven by affected females. We find no pre existing differences in risk preferences between earthquake and control areas using 2012 data. Within the heavily affected group of individuals, higher house damage, our proxy for realized losses, increases risk aversion. Regarding higher-order risk preferences for individuals heavily affected by the earthquake, we find that prudence is positively associated with selfprotective behaviors after the earthquake, specifically internal migration and/or displacement. While precautionary savings shows initially no correlation to prudence, a positive association emerges when considering that prudence is also related to occupational choices, with individuals with stable incomes and who save being more prudent. Our results contribute insights into how disasters influence risk preferences, specifically aiming to address contradictory findings in the literature, while presenting novel evidence on the relationship between prudence and post-natural disaster behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15905v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emily Quiroga, Michael Tanner</dc:creator>
    </item>
    <item>
      <title>Reinterpreting Economic Complexity: A co-clustering approach</title>
      <link>https://arxiv.org/abs/2406.16199</link>
      <description>arXiv:2406.16199v1 Announce Type: new 
Abstract: Economic growth results from countries' accumulation of organizational and technological capabilities. The Economic and Product Complexity Indices, introduced as an attempt to measure these capabilities from a country's basket of exported products, have become popular to study economic development, the geography of innovation, and industrial policies. Despite this reception, the interpretation of these indicators proved difficult. Although the original Method of Reflections suggested a direct interconnection between country and product metrics, it has been proved that the Economic and Product Complexity Indices result from a spectral clustering algorithm that separately groups similar countries or similar products, respectively. This recent approach to economic and product complexity conflicts with the original one and treats separately countries and products. However, building on previous interpretations of the indices and the recent evolution in spectral clustering, we show that these indices simultaneously identify two co-clusters of similar countries and products. This viewpoint reconciles the spectral clustering interpretation of the indices with the original Method of Reflections interpretation. By proving the often neglected intimate relationship between country and product complexity, this approach emphasizes the role of a selected set of products in determining economic development while extending the range of applications of these indicators in economics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16199v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Bottai, Jacopo Di Iorio, Martina Iori</dc:creator>
    </item>
    <item>
      <title>Large Language Models in Student Assessment: Comparing ChatGPT and Human Graders</title>
      <link>https://arxiv.org/abs/2406.16510</link>
      <description>arXiv:2406.16510v1 Announce Type: new 
Abstract: This study investigates the efficacy of large language models (LLMs) as tools for grading master-level student essays. Utilizing a sample of 60 essays in political science, the study compares the accuracy of grades suggested by the GPT-4 model with those awarded by university teachers. Results indicate that while GPT-4 aligns with human grading standards on mean scores, it exhibits a risk-averse grading pattern and its interrater reliability with human raters is low. Furthermore, modifications in the grading instructions (prompt engineering) do not significantly alter AI performance, suggesting that GPT-4 primarily assesses generic essay characteristics such as language quality rather than adapting to nuanced grading criteria. These findings contribute to the understanding of AI's potential and limitations in higher education, highlighting the need for further development to enhance its adaptability and sensitivity to specific educational assessment requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16510v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Magnus Lundgren</dc:creator>
    </item>
    <item>
      <title>Velocity, Holding Time and Lifespan of Cryptocurrency in Transactions</title>
      <link>https://arxiv.org/abs/2406.16587</link>
      <description>arXiv:2406.16587v1 Announce Type: new 
Abstract: The measurement of the velocity of money is still a significant topic. In this paper, we proposed a method to calculate the velocity of money by combining the holding-time distribution and lifespan distribution. By derivation, the velocity of money equals the holding-time distribution's value at zero. When we have much holding-time data, this problem can be converted to a regression problem. After a numeric simulation, we find that the calculating accuracy is high even if we used only a small part of the holding time data, which implies a potential application in measuring the velocity of money in reality, such as digital money. We also tested the methods on Cardano and found that the method can also provide a reasonable estimation of velocity in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16587v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yu Zhang, Mostafa Chegeni, Claudio Tessone</dc:creator>
    </item>
    <item>
      <title>Occupation Life Cycle</title>
      <link>https://arxiv.org/abs/2406.15373</link>
      <description>arXiv:2406.15373v1 Announce Type: cross 
Abstract: This paper explores the evolution of occupations within the context of industry and technology life cycles, highlighting the critical yet underexplored intersection between occupational trends and broader economic dynamics. Introducing the Occupation Life Cycle (OLC) model, we delineate five stages (i.e., growth, peak, fluctuation, maturity, and decline) to systematically explore the trajectory of occupations. Utilizing job posting data from one of China's largest recruitment platforms as a novel proxy, our study meticulously tracks the fluctuations and emerging trends in the labor market from 2018 to 2023. Through a detailed examination of representative roles, such as short video operators and data analysts, alongside emerging occupations within the artificial intelligence (AI) sector, our findings allocate occupations to specific life cycle stages, revealing insightful patterns of occupational development and decline. Our findings offer a unique perspective on the interplay between occupational evolution and economic factors, with a particular focus on the rapidly changing Chinese labor market. This study not only contributes to the theoretical understanding of OLC but also provides practical insights for policymakers, educators, and industry leaders facing the challenges of workforce planning and development in the face of technological advancement and market shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15373v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lan Chen, Yufei Ji, Xichen Yao, Hengshu Zhu</dc:creator>
    </item>
    <item>
      <title>Contrastive Entity Coreference and Disambiguation for Historical Texts</title>
      <link>https://arxiv.org/abs/2406.15576</link>
      <description>arXiv:2406.15576v1 Announce Type: cross 
Abstract: Massive-scale historical document collections are crucial for social science research. Despite increasing digitization, these documents typically lack unique cross-document identifiers for individuals mentioned within the texts, as well as individual identifiers from external knowledgebases like Wikipedia/Wikidata. Existing entity disambiguation methods often fall short in accuracy for historical documents, which are replete with individuals not remembered in contemporary knowledgebases. This study makes three key contributions to improve cross-document coreference resolution and disambiguation in historical texts: a massive-scale training dataset replete with hard negatives - that sources over 190 million entity pairs from Wikipedia contexts and disambiguation pages - high-quality evaluation data from hand-labeled historical newswire articles, and trained models evaluated on this historical benchmark. We contrastively train bi-encoder models for coreferencing and disambiguating individuals in historical texts, achieving accurate, scalable performance that identifies out-of-knowledgebase individuals. Our approach significantly surpasses other entity disambiguation models on our historical newswire benchmark. Our models also demonstrate competitive performance on modern entity disambiguation benchmarks, particularly certain news disambiguation datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15576v1</guid>
      <category>cs.CL</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Arora, Emily Silcock, Leander Heldring, Melissa Dell</dc:creator>
    </item>
    <item>
      <title>News Deja Vu: Connecting Past and Present with Semantic Search</title>
      <link>https://arxiv.org/abs/2406.15593</link>
      <description>arXiv:2406.15593v1 Announce Type: cross 
Abstract: Social scientists and the general public often analyze contemporary events by drawing parallels with the past, a process complicated by the vast, noisy, and unstructured nature of historical texts. For example, hundreds of millions of page scans from historical newspapers have been noisily transcribed. Traditional sparse methods for searching for relevant material in these vast corpora, e.g., with keywords, can be brittle given complex vocabularies and OCR noise. This study introduces News Deja Vu, a novel semantic search tool that leverages transformer large language models and a bi-encoder approach to identify historical news articles that are most similar to modern news queries. News Deja Vu first recognizes and masks entities, in order to focus on broader parallels rather than the specific named entities being discussed. Then, a contrastively trained, lightweight bi-encoder retrieves historical articles that are most similar semantically to a modern query, illustrating how phenomena that might seem unique to the present have varied historical precedents. Aimed at social scientists, the user-friendly News Deja Vu package is designed to be accessible for those who lack extensive familiarity with deep learning. It works with large text datasets, and we show how it can be deployed to a massive scale corpus of historical, open-source news articles. While human expertise remains important for drawing deeper insights, News Deja Vu provides a powerful tool for exploring parallels in how people have perceived past and present.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15593v1</guid>
      <category>cs.CL</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brevin Franklin, Emily Silcock, Abhishek Arora, Tom Bryan, Melissa Dell</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Study for Multi-Criteria Comparison of EV, ICEV, and HEV</title>
      <link>https://arxiv.org/abs/2404.11705</link>
      <description>arXiv:2404.11705v4 Announce Type: replace 
Abstract: Electric vehicles (EVs) are increasingly becoming popular as a viable means of transportation for the future. The use of EVs may help to provide better climatic conditions in urban areas with a pocket friendly cost for transportation to the consumers throughout its life. EVs enact as a boon to the society by providing zero tailpipe emissions, better comfort, low lifecycle cost and higher connectivity. The article aims to provide scientific information through the literature across various aspects of EVs in their lifetime and thus, assist the scholarly community and various organisations to understand the impact of EVs. In this study we have gathered information from the articles published in SCOPUS database and through grey literature with the focus of information post 2009. After identification of various factors while purchasing the vehicle, the total cost of ownership (TCO) for vehicles is calculated and their average TCO for each segment is considered for the study. Following that, we investigate the ranking of EVs, vehicles powered by internal combustion engines (ICEVs), and hybrid electric vehicles (HEVs) in a variety of price segments by employing a combination of two different multi-criteria decision making (MCDM) techniques. Initially, best-worst method (BWM) is used to determine the weights of each of the identified criterion, which is thereafter, used in conjunction with the technique for order preference by similarity to ideal solution (TOPSIS) to compute the rank of the available alternatives using BWM. The ranking obtained clearly indicates that EVs should be first purchase choice of the consumers, followed by HEVs and ICEVs respectively. Thus, the results help us conclude that EVs enact as a sustainable means of transport for the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11705v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tushar Gahlaut, Gourav Dwivedi</dc:creator>
    </item>
    <item>
      <title>Linking Representations with Multimodal Contrastive Learning</title>
      <link>https://arxiv.org/abs/2304.03464</link>
      <description>arXiv:2304.03464v3 Announce Type: replace-cross 
Abstract: Many applications require linking individuals, firms, or locations across datasets. Most widely used methods, especially in social science, do not employ deep learning, with record linkage commonly approached using string matching techniques. Moreover, existing methods do not exploit the inherently multimodal nature of documents. In historical record linkage applications, documents are typically noisily transcribed by optical character recognition (OCR). Linkage with just OCR'ed texts may fail due to noise, whereas linkage with just image crops may also fail because vision models lack language understanding (e.g., of abbreviations or other different ways of writing firm names). To leverage multimodal learning, this study develops CLIPPINGS (Contrastively LInking Pooled Pre-trained Embeddings). CLIPPINGS aligns symmetric vision and language bi-encoders, through contrastive language-image pre-training on document images and their corresponding OCR'ed texts. It then contrastively learns a metric space where the pooled image-text embedding for a given instance is close to embeddings in the same class (e.g., the same firm or location) and distant from embeddings of a different class. Data are linked by treating linkage as a nearest neighbor retrieval problem with the multimodal embeddings. CLIPPINGS outperforms widely used string matching methods by a wide margin in linking mid-20th century Japanese firms across financial documents. A purely self-supervised model - trained only by aligning the embeddings for the image crop of a firm name and its corresponding OCR'ed text - also outperforms popular string matching methods. Fascinatingly, a multimodally pre-trained vision-only encoder outperforms a unimodally pre-trained vision-only encoder, illustrating the power of multimodal pre-training even if only one modality is available for linking at inference time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03464v3</guid>
      <category>cs.CV</category>
      <category>cs.CL</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Arora, Xinmei Yang, Shao-Yu Jheng, Melissa Dell</dc:creator>
    </item>
  </channel>
</rss>
