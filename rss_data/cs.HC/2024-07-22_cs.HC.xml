<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Jul 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Lessons in Cooperation: A Qualitative Analysis of Driver Sentiments towards Real-Time Advisory Systems from a Driving Simulator User Study</title>
      <link>https://arxiv.org/abs/2407.13775</link>
      <description>arXiv:2407.13775v1 Announce Type: new 
Abstract: Real-time Advisory (RTA) systems, such as navigational and eco-driving assistants, are becoming increasingly ubiquitous in vehicles due to their benefits for users and society. Until autonomous vehicles mature, such advisory systems will continue to expand their ability to cooperate with drivers, enabling safer and more eco-friendly driving practices while improving user experience. However, the interactions between these systems and drivers have not been studied extensively. To this end, we conduct a driving simulator study (N=16) to capture driver reactions to a Cooperative RTA system. Through a case study with a congestion mitigation assistant, we qualitatively analyze the sentiments of drivers towards advisory systems and discuss driver preferences for various aspects of the interaction. We comment on how the advice should be communicated, the effects of the advice on driver trust, and how drivers adapt to the system. We present recommendations to inform the future design of Cooperative RTA systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13775v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aamir Hasan, Neeloy Chakraborty, Haonan Chen, Cathy Wu, Katherine Driggs-Campbell</dc:creator>
    </item>
    <item>
      <title>Understanding Physiological Responses of Students Over Different Courses</title>
      <link>https://arxiv.org/abs/2407.14015</link>
      <description>arXiv:2407.14015v1 Announce Type: new 
Abstract: Student engagement plays a vital role in academic success with high engagement often linked to positive educational outcomes. Traditionally, student engagement is measured through self-reports, which are both labour-intensive and not real-time. An emerging alternative is monitoring physiological signals such as Electrodermal Activity (EDA) and Inter-Beat Interval (IBI), which reflect students' emotional and cognitive states. In this research, we analyzed these signals from 23 students wearing Empatica E4 devices in real-world scenarios. Diverging from previous studies focused on lab settings or specific subjects, we examined physiological synchrony at the intra-student level across various courses. We also assessed how different courses influence physiological responses and identified consistent temporal patterns. Our findings show unique physiological response patterns among students, enhancing our understanding of student engagement dynamics. This opens up possibilities for tailoring educational strategies based on unobtrusive sensing data to optimize learning outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14015v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3675095.3676620</arxiv:DOI>
      <dc:creator>Soundariya Ananthan, Nan Gao, Flora D. Salim</dc:creator>
    </item>
    <item>
      <title>Data Guards: Challenges and Solutions for Fostering Trust in Data</title>
      <link>https://arxiv.org/abs/2407.14042</link>
      <description>arXiv:2407.14042v1 Announce Type: new 
Abstract: From dirty data to intentional deception, there are many threats to the validity of data-driven decisions. Making use of data, especially new or unfamiliar data, therefore requires a degree of trust or verification. How is this trust established? In this paper, we present the results of a series of interviews with both producers and consumers of data artifacts (outputs of data ecosystems like spreadsheets, charts, and dashboards) aimed at understanding strategies and obstacles to building trust in data. We find a recurring need, but lack of existing standards, for data validation and verification, especially among data consumers. We therefore propose a set of data guards: methods and tools for fostering trust in data artifacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14042v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole Sultanum, Dennis Bromley, Michael Correll</dc:creator>
    </item>
    <item>
      <title>FAVis: Visual Analytics of Factor Analysis for Psychological Research</title>
      <link>https://arxiv.org/abs/2407.14072</link>
      <description>arXiv:2407.14072v1 Announce Type: new 
Abstract: Psychological research often involves understanding psychological constructs through conducting factor analysis on data collected by a questionnaire, which can comprise hundreds of questions. Without interactive systems for interpreting factor models, researchers are frequently exposed to subjectivity, potentially leading to misinterpretations or overlooked crucial information. This paper introduces FAVis, a novel interactive visualization tool designed to aid researchers in interpreting and evaluating factor analysis results. FAVis enhances the understanding of relationships between variables and factors by supporting multiple views for visualizing factor loadings and correlations, allowing users to analyze information from various perspectives. The primary feature of FAVis is to enable users to set optimal thresholds for factor loadings to balance clarity and information retention. FAVis also allows users to assign tags to variables, enhancing the understanding of factors by linking them to their associated psychological constructs. Our user study demonstrates the utility of FAVis in various tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14072v1</guid>
      <category>cs.HC</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yikai Lu, Chaoli Wang</dc:creator>
    </item>
    <item>
      <title>Experiences of Censorship on TikTok Across Marginalised Identities</title>
      <link>https://arxiv.org/abs/2407.14164</link>
      <description>arXiv:2407.14164v1 Announce Type: new 
Abstract: TikTok has seen exponential growth as a platform, fuelled by the success of its proprietary recommender algorithm which serves tailored content to every user - though not without controversy. Users complain of their content being unfairly suppressed by ''the algorithm'', particularly users with marginalised identities such as LGBTQ+ users. Together with content removal, this suppression acts to censor what is shared on the platform. Journalists have revealed biases in automatic censorship, as well as human moderation. We investigate experiences of censorship on TikTok, across users marginalised by their gender, LGBTQ+ identity, disability or ethnicity. We survey 627 UK-based TikTok users and find that marginalised users often feel they are subject to censorship for content that does not violate community guidelines. We highlight many avenues for future research into censorship on TikTok, with a focus on users' folk theories, which greatly shape their experiences of the platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14164v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eddie L. Ungless, Nina Markl, Bj\"orn Ross</dc:creator>
    </item>
    <item>
      <title>Urban Visual Appeal According to ChatGPT: Contrasting AI and Human Insights</title>
      <link>https://arxiv.org/abs/2407.14268</link>
      <description>arXiv:2407.14268v1 Announce Type: new 
Abstract: The visual appeal of urban environments significantly impacts residents' satisfaction with their living spaces and their overall mood, which in turn, affects their health and well-being. Given the resource-intensive nature of gathering evaluations on urban visual appeal through surveys or inquiries from residents, there is a constant quest for automated solutions to streamline this process and support spatial planning. In this study, we applied an off-the-shelf AI model to automate the analysis of urban visual appeal, using over 1,800 Google Street View images of Helsinki, Finland. By incorporating the GPT-4 model with specified criteria, we assessed these images. Simultaneously, 24 participants were asked to rate the images. Our results demonstrated a strong alignment between GPT-4 and participant ratings, although geographic disparities were noted. Specifically, GPT-4 showed a preference for suburban areas with significant greenery, contrasting with participants who found these areas less appealing. Conversely, in the city centre and densely populated urban regions of Helsinki, GPT-4 assigned lower visual appeal scores than participant ratings. While there was general agreement between AI and human assessments across various locations, GPT-4 struggled to incorporate contextual nuances into its ratings, unlike participants, who considered both context and features of the urban environment. The study suggests that leveraging AI models like GPT-4 allows spatial planners to gather insights into the visual appeal of different areas efficiently, aiding decisions that enhance residents' and travellers' satisfaction and mental health. Although AI models provide valuable insights, human perspectives are essential for a comprehensive understanding of urban visual appeal. This will ensure that planning and design decisions promote healthy living environments effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14268v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Milad Malekzadeh, Elias Willberg, Jussi Torkko, Tuuli Toivonen</dc:creator>
    </item>
    <item>
      <title>As Generative Models Improve, People Adapt Their Prompts</title>
      <link>https://arxiv.org/abs/2407.14333</link>
      <description>arXiv:2407.14333v1 Announce Type: new 
Abstract: In an online experiment with N = 1891 participants, we collected and analyzed over 18,000 prompts to explore how the importance of prompting will change as the capabilities of generative AI models continue to improve. Each participant in our experiment was randomly and blindly assigned to use one of three text-to-image diffusion models: DALL-E 2, its more advanced successor DALL-E 3, or a version of DALL-E 3 with automatic prompt revision. Participants were then asked to write prompts to reproduce a target image as closely as possible in 10 consecutive tries. We find that task performance was higher for participants using DALL-E 3 than for those using DALL-E 2. This performance gap corresponds to a noticeable difference in the similarity of participants' images to their target images, and was caused in equal measure by: (1) the increased technical capabilities of DALL-E 3, and (2) endogenous changes in participants' prompting in response to these increased capabilities. More specifically, despite being blind to the model they were assigned, participants assigned to DALL-E 3 wrote longer prompts that were more semantically similar to each other and contained a greater number of descriptive words. Furthermore, while participants assigned to DALL-E 3 with prompt revision still outperformed those assigned to DALL-E 2, automatic prompt revision reduced the benefits of using DALL-E 3 by 58%. Taken together, our results suggest that as models continue to progress, people will continue to adapt their prompts to take advantage of new models' capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14333v1</guid>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eaman Jahani, Benjamin S. Manning, Joe Zhang, Hong-Yi TuYe, Mohammed Alsobay, Christos Nicolaides, Siddharth Suri, David Holtz</dc:creator>
    </item>
    <item>
      <title>Exploring Indoor Air Quality Dynamics in Developing Nations: A Perspective from India</title>
      <link>https://arxiv.org/abs/2407.14393</link>
      <description>arXiv:2407.14393v1 Announce Type: new 
Abstract: Indoor air pollution is a major issue in developing countries such as India and Bangladesh, exacerbated by factors like traditional cooking methods, insufficient ventilation, and cramped living conditions, all of which elevate the risk of health issues like lung infections and cardiovascular diseases. With the World Health Organization associating around 3.2 million annual deaths globally to household air pollution, the gravity of the problem is clear. Yet, extensive empirical studies exploring these unique patterns and indoor pollutions extent are missing. To fill this gap, we carried out a six months long field study involving over 30 households, uncovering the complexity of indoor air pollution in developing countries, such as the longer lingering time of VOCs in the air or the significant influence of air circulation on the spatiotemporal distribution of pollutants. We introduced an innovative IoT air quality sensing platform, the Distributed Air QuaLiTy MONitor (DALTON ), explicitly designed to meet the needs of these nations, considering factors like cost, sensor type, accuracy, network connectivity, power, and usability. As a result of a multi-device deployment, the platform identifies pollution hot-spots in low and middle-income households in developing nations. It identifies best practices to minimize daily indoor pollution exposure. Our extensive qualitative survey estimates an overall system usability score of 2.04, indicating an efficient system for air quality monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14393v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prasenjit Karmakar, Swadhin Pradhan, Sandip Chakraborty</dc:creator>
    </item>
    <item>
      <title>From Instruction to Insight: Exploring the Functional and Semantic Roles of Text in Interactive Dashboards</title>
      <link>https://arxiv.org/abs/2407.14451</link>
      <description>arXiv:2407.14451v1 Announce Type: new 
Abstract: There is increased interest in the interplay between text and visuals in the field of data visualization. However, this attention has predominantly been on the use of text in standalone visualizations or augmenting text stories supported by a series of independent views. In this paper, we shift from the traditional focus on single-chart annotations to characterize the nuanced but crucial communication role of text in the complex environment of interactive dashboards. Through a survey and analysis of 190 dashboards in the wild, plus 13 expert interview sessions with experienced dashboard authors, we highlight the distinctive nature of text as an integral component of the dashboard experience, while delving into the categories, semantic levels, and functional roles of text, and exploring how these text elements are coalesced by dashboard authors to guide and inform dashboard users.
  Our contributions are: 1) we distill qualitative and quantitative findings from our studies to characterize current practices of text use in dashboards, including a categorization of text-based components and design patterns; 2) we leverage current practices and existing literature to propose, discuss, and validate recommended practices for text in dashboards, embodied as 12 heuristics that underscore the semantic and functional role of text in offering navigational cues, contextualizing data insights, supporting reading order, etc; 3) we reflect on our findings to identify gaps and propose opportunities for data visualization researchers to push the boundaries on text usage for dashboards, from authoring support and interactivity to text generation and content personalization.
  Our research underscores the significance of elevating text as a first-class citizen in data visualization, and the need to support the inclusion of textual components and their interactive affordances in dashboard design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14451v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole Sultanum, Vidya Setlur</dc:creator>
    </item>
    <item>
      <title>AudioInsight: Detecting Social Contexts Relevant to Social Anxiety from Speech</title>
      <link>https://arxiv.org/abs/2407.14458</link>
      <description>arXiv:2407.14458v1 Announce Type: new 
Abstract: During social interactions, understanding the intricacies of the context can be vital, particularly for socially anxious individuals. While previous research has found that the presence of a social interaction can be detected from ambient audio, the nuances within social contexts, which influence how anxiety provoking interactions are, remain largely unexplored. As an alternative to traditional, burdensome methods like self-report, this study presents a novel approach that harnesses ambient audio segments to detect social threat contexts. We focus on two key dimensions: number of interaction partners (dyadic vs. group) and degree of evaluative threat (explicitly evaluative vs. not explicitly evaluative). Building on data from a Zoom-based social interaction study (N=52 college students, of whom the majority N=45 are socially anxious), we employ deep learning methods to achieve strong detection performance. Under sample-wide 5-fold Cross Validation (CV), our model distinguished dyadic from group interactions with 90\% accuracy and detected evaluative threat at 83\%. Using a leave-one-group-out CV, accuracies were 82\% and 77\%, respectively. While our data are based on virtual interactions due to pandemic constraints, our method has the potential to extend to diverse real-world settings. This research underscores the potential of passive sensing and AI to differentiate intricate social contexts, and may ultimately advance the ability of context-aware digital interventions to offer personalized mental health support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14458v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Varun Reddy, Zhiyuan Wang, Emma Toner, Max Larrazabal, Mehdi Boukhechba, Bethany A. Teachman, Laura E. Barnes</dc:creator>
    </item>
    <item>
      <title>Reporting Risks in AI-based Assistive Technology Research: A Systematic Review</title>
      <link>https://arxiv.org/abs/2407.12035</link>
      <description>arXiv:2407.12035v2 Announce Type: replace 
Abstract: Artificial Intelligence (AI) is increasingly employed to enhance assistive technologies, yet it can fail in various ways. We conducted a systematic literature review of research into AI-based assistive technology for persons with visual impairments. Our study shows that most proposed technologies with a testable prototype have not been evaluated in a human study with members of the sight-loss community. Furthermore, many studies did not consider or report failure cases or possible risks. These findings highlight the importance of inclusive system evaluations and the necessity of standardizing methods for presenting and analyzing failure cases and threats when developing AI-based assistive technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12035v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zahra Ahmadi, Peter R. Lewis, Mahadeo A. Sukhai</dc:creator>
    </item>
    <item>
      <title>The need of a self for self-driving cars a theoretical model applying homeostasis to self driving</title>
      <link>https://arxiv.org/abs/2407.12795</link>
      <description>arXiv:2407.12795v2 Announce Type: replace 
Abstract: This paper explores the concept of creating a "self" for self-driving cars through a homeostatic architecture designed to enhance their autonomy, safety, and efficiency. The proposed system integrates inward focused sensors to monitor the car's internal state, such as the condition of its metal bodywork, wheels, engine, and battery, establishing a baseline homeostatic state representing optimal functionality. Outward facing sensors, like cameras and LIDAR, are then interpreted via their impact on the car's homeostatic state by quantifying deviations from homeostasis. This contrasts with the approach of trying to make cars "see" reality in a similar way to humans and identify elements in their reality in the same way humans. Virtual environments would be leveraged to accelerate training. Additionally, cars are programmed to communicate and share experiences via blockchain technology, learning from each other's mistakes while maintaining individualized training models. A dedicated language for self-driving cars is proposed to enable nuanced interpretation and response to environmental data. This architecture allows self-driving cars to dynamically adjust their behavior based on internal and external feedback, promoting cooperation and continuous improvement. The study concludes by discussing the broader implications for AI development, potential real-world applications, and future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12795v2</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Schmalzried</dc:creator>
    </item>
    <item>
      <title>Mapping the Empirical Evidence of the GDPR (In-)Effectiveness: A Systematic Review</title>
      <link>https://arxiv.org/abs/2310.16735</link>
      <description>arXiv:2310.16735v2 Announce Type: replace-cross 
Abstract: In the realm of data protection, a striking disconnect prevails between traditional domains of doctrinal, legal, theoretical, and policy-based inquiries and a burgeoning body of empirical evidence. Much of the scholarly and regulatory discourse remains entrenched in abstract legal principles or normative frameworks, leaving the empirical landscape uncharted or minimally engaged. Since the birth of EU data protection law, a modest body of empirical evidence has been generated but remains widely scattered and unexamined. Such evidence offers vital insights into the perception, impact, clarity, and effects of data protection measures but languishes on the periphery, inadequately integrated into the broader conversation. To make a meaningful connection, we conduct a comprehensive review and synthesis of empirical research spanning nearly three decades (1995- March 2022), advocating for a more robust integration of empirical evidence into the evaluation and review of the GDPR, while laying a methodological foundation for future empirical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16735v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenlong Li, Zihao Li, Wenkai Li, Yueming Zhang, Aolan Li</dc:creator>
    </item>
    <item>
      <title>Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers</title>
      <link>https://arxiv.org/abs/2405.10276</link>
      <description>arXiv:2405.10276v2 Announce Type: replace-cross 
Abstract: Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that maximize the task accuracy. In this paper, we revisit OPRO for automated prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral 7B. Our investigation reveals that OPRO shows limited effectiveness in small-scale LLMs, with limited inference capabilities constraining optimization ability. We suggest future automatic prompting engineering to consider both model capabilities and computational costs. Additionally, for small-scale LLMs, we recommend direct instructions that clearly outline objectives and methodologies as robust prompt baselines, ensuring efficient and effective prompt engineering in ongoing research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10276v2</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ACL Findings 2024</arxiv:journal_reference>
      <dc:creator>Tuo Zhang, Jinyue Yuan, Salman Avestimehr</dc:creator>
    </item>
    <item>
      <title>Noninvasive Extraction of Maternal and Fetal ECG using Periodic Progressive FastICA Peel-off</title>
      <link>https://arxiv.org/abs/2406.01281</link>
      <description>arXiv:2406.01281v2 Announce Type: replace-cross 
Abstract: The abdominal electrocardiogram (AECG) gives a safe and non-invasive way to monitor fetal well-being during pregnancy. However, due to the overlap with maternal ECG (MECG) as well as significant external noise, it is challenging to extract weak fetal ECG (FECG) using surface electrodes. In this study, we introduce a novel periodic progressive FastICA peel-off (PPFP) method for noninvasive extraction of weak surface FECG signals, leveraging the two-step FastICA method and a peel-off strategy from the progressive FastICA peel-off (PFP) approach. Specifically, for ECG signals, the periodic constrained FastICA that integrates ECG signal characteristics enables precise extraction of MECG and FECG spike trains. Additionally, a peel-off strategy incorporating SVD waveform reconstruction ensures comprehensive identification of subtle source signals. The performance of the proposed method was examined on public datasets with reference, synthetic data and clinical data, with an F1-scores for FECG extraction on public dataset of 99.59%, on synthetic data with the highest noise level of 99.50%, which are all superior to other comparative methods. Furthermore, clearly periodic and physiologically consistent FECG signals were extracted from clinically collected data. The results indicates that our proposed method has potential and effectiveness to separate MECG and weak FECG from multichannel AECG with high precision in high noise condition, which is of vital importance for ensuring the safety of both the fetus and the mother, as well as the advancement of artificial intelligent clinical monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01281v2</guid>
      <category>physics.med-ph</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Li, Xuanyu Luo, Haowen Zhao, Jiawen Cui, Yangfan She, Dongfang Li, Lai Jiang, Xu Zhang</dc:creator>
    </item>
    <item>
      <title>Proceedings of The second international workshop on eXplainable AI for the Arts (XAIxArts)</title>
      <link>https://arxiv.org/abs/2406.14485</link>
      <description>arXiv:2406.14485v5 Announce Type: replace-cross 
Abstract: This second international workshop on explainable AI for the Arts (XAIxArts) brought together a community of researchers in HCI, Interaction Design, AI, explainable AI (XAI), and digital arts to explore the role of XAI for the Arts. Workshop held at the 16th ACM Conference on Creativity and Cognition (C&amp;C 2024), Chicago, USA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14485v5</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Bryan-Kinns, Corey Ford, Shuoyang Zheng, Helen Kennedy, Alan Chamberlain, Makayla Lewis, Drew Hemment, Zijin Li, Qiong Wu, Lanxi Xiao, Gus Xia, Jeba Rezwana, Michael Clemens, Gabriel Vigliensoni</dc:creator>
    </item>
  </channel>
</rss>
