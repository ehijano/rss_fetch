<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Oct 2024 02:03:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Large-scale Multi-objective Feature Selection: A Multi-phase Search Space Shrinking Approach</title>
      <link>https://arxiv.org/abs/2410.21293</link>
      <description>arXiv:2410.21293v1 Announce Type: new 
Abstract: Feature selection is a crucial step in machine learning, especially for high-dimensional datasets, where irrelevant and redundant features can degrade model performance and increase computational costs. This paper proposes a novel large-scale multi-objective evolutionary algorithm based on the search space shrinking, termed LMSSS, to tackle the challenges of feature selection particularly as a sparse optimization problem. The method includes a shrinking scheme to reduce dimensionality of the search space by eliminating irrelevant features before the main evolutionary process. This is achieved through a ranking-based filtering method that evaluates features based on their correlation with class labels and frequency in an initial, cost-effective evolutionary process. Additionally, a smart crossover scheme based on voting between parent solutions is introduced, giving higher weight to the parent with better classification accuracy. An intelligent mutation process is also designed to target features prematurely excluded from the population, ensuring they are evaluated in combination with other features. These integrated techniques allow the evolutionary process to explore the search space more efficiently and effectively, addressing the sparse and high-dimensional nature of large-scale feature selection problems. The effectiveness of the proposed algorithm is demonstrated through comprehensive experiments on 15 large-scale datasets, showcasing its potential to identify more accurate feature subsets compared to state-of-the-art large-scale feature selection algorithms. These results highlight LMSSS's capability to improve model performance and computational efficiency, setting a new benchmark in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21293v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Azam Asilian Bidgoli, Shahryar Rahnamayan</dc:creator>
    </item>
    <item>
      <title>Optimization of Complex Process, Based on Design Of Experiments, a Generic Methodology</title>
      <link>https://arxiv.org/abs/2410.21294</link>
      <description>arXiv:2410.21294v1 Announce Type: new 
Abstract: MicroLED displays are the result of a complex manufacturing chain. Each stage of this process, if optimized, contributes to achieving the highest levels of final efficiencies. Common works carried out by Pollen Metrology, Aledia, and Universit{\'e} Clermont-Auvergne led to a generic process optimization workflow. This software solution offers a holistic approach where stages are chained together for gaining a complete optimal solution. This paper highlights key corners of the methodology, validated by the experiments and process experts: data cleaning and multi-objective optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21294v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Baderot (UCA), Yann Cauchepin (UCA), Alexandre Seiller (UCA), Richard Fontanges (UCA), Sergio Martinez (UCA), Johann Foucher (UCA), Emmanuel Fuchs (UCA), Mehdi Daanoune (UCA), Vincent Grenier (UCA), Vincent Barra (UCA), Arnaud Guillin (UCA)</dc:creator>
    </item>
    <item>
      <title>The Trap of Presumed Equivalence: Artificial General Intelligence Should Not Be Assessed on the Scale of Human Intelligence</title>
      <link>https://arxiv.org/abs/2410.21296</link>
      <description>arXiv:2410.21296v1 Announce Type: new 
Abstract: A traditional approach to assessing emerging intelligence in the theory of intelligent systems is based on the similarity, 'imitation' of human-like actions and behaviors, benchmarking the performance of intelligent systems on the scale of human cognitive skills. In this work we attempt to outline the shortcomings of this line of thought, which is based on the implicit presumption of equivalence and compatibility of the originating and emergent intelligences. We provide arguments to the point that under some natural assumptions, developing intelligent systems will be able to form their own in-tents and objectives. Then, the difference in the rate of progress of natural and artificial systems that was noted on multiple occasions in the discourse on artificial intelligence can lead to the scenario of a progressive divergence of the intelligences, in their cognitive abilities, functions and resources, values, ethical frameworks, worldviews, intents and existential objectives, the scenario of the AGI evolutionary gap. We discuss evolutionary processes that can guide the development of emergent intelligent systems and attempt to identify the starting point of the progressive divergence scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21296v1</guid>
      <category>cs.NE</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Dolgikh</dc:creator>
    </item>
    <item>
      <title>Designing an adaptive room for captivating the collective consciousness from internal states</title>
      <link>https://arxiv.org/abs/2410.21571</link>
      <description>arXiv:2410.21571v1 Announce Type: new 
Abstract: Beyond conventional productivity metrics, human interaction and collaboration dynamics merit careful consideration in our increasingly digital workspace. This research proposes a conjectural neuro-adaptive room that enhances group interactions by adjusting the physical environment to desired internal states. Drawing inspiration from previous work on collective consciousness, the system leverages computer vision and machine learning models to analyze physiological and behavioral cues, such as facial expressions and speech analysis, to infer the overall internal state of occupants. Environmental conditions of the room, such as visual projections, lighting and sound, are actively adjusted to create an optimal setting for inducing the desired state, including focus or collaboration. Our goal is to create a dynamic and responsive environment to support group needs, fostering a sense of collective consciousness and improving workplace well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21571v1</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ad\'an Flores-Ram\'irez, \'Angel Mario Alarc\'on-L\'opez, Sof\'ia Vaca-Narvaja, Daniela Leo-Orozco</dc:creator>
    </item>
    <item>
      <title>S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2306.15220</link>
      <description>arXiv:2306.15220v4 Announce Type: replace 
Abstract: Spiking Neural Networks (SNNs) are biologically plausible models that have been identified as potentially apt for deploying energy-efficient intelligence at the edge, particularly for sequential learning tasks. However, training of SNNs poses significant challenges due to the necessity for precise temporal and spatial credit assignment. Back-propagation through time (BPTT) algorithm, whilst the most widely used method for addressing these issues, incurs high computational cost due to its temporal dependency. In this work, we propose S-TLLR, a novel three-factor temporal local learning rule inspired by the Spike-Timing Dependent Plasticity (STDP) mechanism, aimed at training deep SNNs on event-based learning tasks. Furthermore, S-TLLR is designed to have low memory and time complexities, which are independent of the number of time steps, rendering it suitable for online learning on low-power edge devices. To demonstrate the scalability of our proposed method, we have conducted extensive evaluations on event-based datasets spanning a wide range of applications, such as image and gesture recognition, audio classification, and optical flow estimation. In all the experiments, S-TLLR achieved high accuracy, comparable to BPTT, with a reduction in memory between $5-50\times$ and multiply-accumulate (MAC) operations between $1.3-6.6\times$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15220v4</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Paul E. Apolinario, Kaushik Roy</dc:creator>
    </item>
    <item>
      <title>LLS: Local Learning Rule for Deep Neural Networks Inspired by Neural Activity Synchronization</title>
      <link>https://arxiv.org/abs/2405.15868</link>
      <description>arXiv:2405.15868v2 Announce Type: replace 
Abstract: Training deep neural networks (DNNs) using traditional backpropagation (BP) presents challenges in terms of computational complexity and energy consumption, particularly for on-device learning where computational resources are limited. Various alternatives to BP, including random feedback alignment, forward-forward, and local classifiers, have been explored to address these challenges. These methods have their advantages, but they can encounter difficulties when dealing with intricate visual tasks or demand considerable computational resources. In this paper, we propose a novel Local Learning rule inspired by neural activity Synchronization phenomena (LLS) observed in the brain. LLS utilizes fixed periodic basis vectors to synchronize neuron activity within each layer, enabling efficient training without the need for additional trainable parameters. We demonstrate the effectiveness of LLS and its variations, LLS-M and LLS-MxM, on multiple image classification datasets, achieving accuracy comparable to BP with reduced computational complexity and minimal additional parameters. Specifically, LLS achieves comparable performance with up to $300 \times$ fewer multiply-accumulate (MAC) operations and half the memory requirements of BP. Furthermore, the performance of LLS on the Visual Wake Word (VWW) dataset highlights its suitability for on-device learning tasks, making it a promising candidate for edge hardware implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15868v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Paul E. Apolinario, Arani Roy, Kaushik Roy</dc:creator>
    </item>
    <item>
      <title>Noise-Aware Training of Neuromorphic Dynamic Device Networks</title>
      <link>https://arxiv.org/abs/2401.07387</link>
      <description>arXiv:2401.07387v2 Announce Type: replace-cross 
Abstract: Physical computing has the potential to enable widespread embodied intelligence by leveraging the intrinsic dynamics of complex systems for efficient sensing, processing, and interaction. While individual devices provide basic data processing capabilities, networks of interconnected devices can perform more complex and varied tasks. However, designing networks to perform dynamic tasks is challenging without physical models and accurate quantification of device noise. We propose a novel, noise-aware methodology for training device networks using Neural Stochastic Differential Equations (Neural-SDEs) as differentiable digital twins, accurately capturing the dynamics and associated stochasticity of devices with intrinsic memory. Our approach employs backpropagation through time and cascade learning, allowing networks to effectively exploit the temporal properties of physical devices. We validate our method on diverse networks of spintronic devices across temporal classification and regression benchmarks. By decoupling the training of individual device models from network training, our method reduces the required training data and provides a robust framework for programming dynamical devices without relying on analytical descriptions of their dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07387v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Manneschi, Ian T. Vidamour, Kilian D. Stenning, Charles Swindells, Guru Venkat, David Griffin, Lai Gui, Daanish Sonawala, Denis Donskikh, Dana Hariga, Susan Stepney, Will R. Branford, Jack C. Gartside, Thomas Hayward, Matthew O. A. Ellis, Eleni Vasilaki</dc:creator>
    </item>
    <item>
      <title>UDC: A Unified Neural Divide-and-Conquer Framework for Large-Scale Combinatorial Optimization Problems</title>
      <link>https://arxiv.org/abs/2407.00312</link>
      <description>arXiv:2407.00312v3 Announce Type: replace-cross 
Abstract: Single-stage neural combinatorial optimization solvers have achieved near-optimal results on various small-scale combinatorial optimization (CO) problems without requiring expert knowledge. However, these solvers exhibit significant performance degradation when applied to large-scale CO problems. Recently, two-stage neural methods motivated by divide-and-conquer strategies have shown efficiency in addressing large-scale CO problems. Nevertheless, the performance of these methods highly relies on problem-specific heuristics in either the dividing or the conquering procedure, which limits their applicability to general CO problems. Moreover, these methods employ separate training schemes and ignore the interdependencies between the dividing and conquering strategies, often leading to sub-optimal solutions. To tackle these drawbacks, this article develops a unified neural divide-and-conquer framework (i.e., UDC) for solving general large-scale CO problems. UDC offers a Divide-Conquer-Reunion (DCR) training method to eliminate the negative impact of a sub-optimal dividing policy. Employing a high-efficiency Graph Neural Network (GNN) for global instance dividing and a fixed-length sub-path solver for conquering divided sub-problems, the proposed UDC framework demonstrates extensive applicability, achieving superior performance in 10 representative large-scale CO problems. The code is available at https://github.com/CIAM-Group/NCO_code/tree/main/single_objective/UDC-Large-scale-CO-master.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00312v3</guid>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhi Zheng, Changliang Zhou, Tong Xialiang, Mingxuan Yuan, Zhenkun Wang</dc:creator>
    </item>
  </channel>
</rss>
