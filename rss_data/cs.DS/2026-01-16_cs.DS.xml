<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improved Algorithms for Fair Matroid Submodular Maximization</title>
      <link>https://arxiv.org/abs/2601.09860</link>
      <description>arXiv:2601.09860v1 Announce Type: new 
Abstract: Submodular maximization subject to matroid constraints is a central problem with many applications in machine learning. As algorithms are increasingly used in decision-making over datapoints with sensitive attributes such as gender or race, it is becoming crucial to enforce fairness to avoid bias and discrimination. Recent work has addressed the challenge of developing efficient approximation algorithms for fair matroid submodular maximization. However, the best algorithms known so far are only guaranteed to satisfy a relaxed version of the fairness constraints that loses a factor 2, i.e., the problem may ask for $\ell$ elements with a given attribute, but the algorithm is only guaranteed to find $\lfloor \ell/2 \rfloor$. In particular, there is no provable guarantee when $\ell=1$, which corresponds to a key special case of perfect matching constraints.
  In this work, we achieve a new trade-off via an algorithm that gets arbitrarily close to full fairness. Namely, for any constant $\varepsilon&gt;0$, we give a constant-factor approximation to fair monotone matroid submodular maximization that in expectation loses only a factor $(1-\varepsilon)$ in the lower-bound fairness constraint. Our empirical evaluation on a standard suite of real-world datasets -- including clustering, recommendation, and coverage tasks -- demonstrates the practical effectiveness of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09860v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sepideh Mahabadi, Sherry Sarkar, Jakub Tarnawski</dc:creator>
    </item>
    <item>
      <title>Scalable Algorithms for Approximate DNF Model Counting</title>
      <link>https://arxiv.org/abs/2601.10511</link>
      <description>arXiv:2601.10511v1 Announce Type: new 
Abstract: Model counting of Disjunctive Normal Form (DNF) formulas is a critical problem in applications such as probabilistic inference and network reliability. For example, it is often used for query evaluation in probabilistic databases. Due to the computational intractability of exact DNF counting, there has been a line of research into a variety of approximation algorithms. These include Monte Carlo approaches such as the classical algorithms of Karp, Luby, and Madras (1989), as well as methods based on hashing (Soos et al. 2023), and heuristic approximations based on Neural Nets (Abboud, Ceylan, and Lukasiewicz 2020).
  We develop a new Monte Carlo approach with an adaptive stopping rule and short-circuit formula evaluation. We prove it achieves Probably Approximately Correct (PAC) learning bounds and is asymptotically more efficient than the previous methods. We also show experimentally that it out-performs prior algorithms by orders of magnitude, and can scale to much larger problems with millions of variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10511v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Burkhardt, David G. Harris, Kevin T Schmitt</dc:creator>
    </item>
    <item>
      <title>UFO Trees: Practical and Provably-Efficient Parallel Batch-Dynamic Trees</title>
      <link>https://arxiv.org/abs/2601.10706</link>
      <description>arXiv:2601.10706v1 Announce Type: new 
Abstract: The dynamic trees problem is to maintain a tree under edge updates while supporting queries like connectivity queries or path queries. Despite the first data structure for this fundamental problem -- the link-cut tree -- being invented 40 years ago, our experiments reveal that they are still the fastest sequential data structure for the problem. However, link-cut trees cannot support parallel batch-dynamic updates and have limitations on the kinds of queries they support.
  In this paper, we design a new parallel batch-dynamic trees data structure called UFO trees that simultaneously supports a wide range of query functionality, supports work-efficient parallel batch-dynamic updates, and is competitive with link-cut trees when run sequentially. We prove that a key reason for the strong practical performance of both link-cut trees and UFO trees is that they can perform updates and queries in sub-logarithmic time for low-diameter trees. We perform an experimental study of our optimized C++ implementations of UFO trees with ten other dynamic tree implementations, several of which are new, in a broad benchmark of both synthetic and real-world trees of varying diameter and size. Our results show that, in both sequential and parallel settings, UFO trees are the fastest dynamic tree data structure that supports a wide range of queries. Our new implementation of UFO trees has low space usage and easily scales to billion-size inputs, making it a promising building block for implementing more complex dynamic graph algorithms in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10706v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quinten De Man, Atharva Sharma, Kishen N Gowda, Laxman Dhulipala</dc:creator>
    </item>
    <item>
      <title>Pushing the frontiers of subexponential FPT time for Feedback Vertex Set</title>
      <link>https://arxiv.org/abs/2504.17708</link>
      <description>arXiv:2504.17708v2 Announce Type: replace 
Abstract: The paper deals with the Feedback Vertex Set problem parameterized by the solution size. Given a graph $G$ and a parameter $k$, one has to decide if there is a set $S$ of at most $k$ vertices such that $G-S$ is acyclic. Assuming the Exponential Time Hypothesis, it is known that FVS cannot be solved in time $2^{o(k)}n^{\mathcal{O}(1)}$ in general graphs. To overcome this, many recent results considered FVS restricted to particular intersection graph classes and provided such $2^{o(k)}n^{\mathcal{O}(1)}$ algorithms.
  In this paper we provide generic conditions on a graph class for the existence of an algorithm solving FVS in subexponential FPT time, i.e. time $2^{k^\varepsilon} \mathop{\rm poly}(n)$, for some $\varepsilon&lt;1$, where $n$ denotes the number of vertices of the instance and $k$ the parameter. On the one hand this result unifies algorithms that have been proposed over the years for several graph classes such as planar graphs, map graphs, unit-disk graphs, pseudo-disk graphs, and string graphs of bounded edge-degree. On the other hand it extends the tractability horizon of FVS to new classes that are not amenable to previously used techniques, in particular intersection graphs of ``thin'' objects like segment graphs or more generally $s$-string graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17708v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ga\'etan Berthe, Marin Bougeret, Daniel Gon\c{c}alves, Jean-Florent Raymond</dc:creator>
    </item>
    <item>
      <title>Approximations for Fault-Tolerant Total and Partial Positive Influence Domination</title>
      <link>https://arxiv.org/abs/2506.12828</link>
      <description>arXiv:2506.12828v3 Announce Type: replace 
Abstract: In $\textit{total domination}$, given a graph $G=(V,E)$, we seek a minimum-size set of nodes $S\subseteq V$, such that every node in $V$ has at least one neighbor in $S$. We define a $\textit{fault-tolerant}$ version of total domination, where we require any node in $V \setminus S$ to have at least $m$ neighbors in $S$. Let $\Delta$ denote the maximum degree in $G$. We prove a first $1 + \ln(\Delta + m - 1)$ approximation for fault-tolerant total domination. We also consider fault-tolerant variants of the weighted $\textit{partial positive influence dominating set}$ problem, where we seek a minimum-size set of nodes $S\subseteq V$, such that every node in $V$ is either a member of $S$ or the sum of weights of its incident edges leading to nodes in $S$ is at least half of the sum of weights over all its incident edges. We prove the first logarithmic approximations for the simple, total, and connected variants of this problem. To prove the result for the connected case, we extend the general approximation framework for non-submodular functions from integer-valued to fractional-valued functions, which we believe is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12828v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Lamprou, Ioannis Sigalas, Ioannis Vaxevanakis, Vassilis Zissimopoulos</dc:creator>
    </item>
    <item>
      <title>Approximation algorithms for scheduling with rejection in green manufacturing</title>
      <link>https://arxiv.org/abs/2507.12635</link>
      <description>arXiv:2507.12635v3 Announce Type: replace 
Abstract: Motivated by green manufacturing, this paper investigates a scheduling with rejection problem subject to an energy consumption constraint. Machines are associated with non-uniform energy consumption rates, defined as the energy consumed per unit time. Each job is either rejected with a rejection penalty or accepted and scheduled on some machine for processing, which incurs energy consumption. The problem aims to minimize the makespan of the accepted jobs plus the total penalty of the rejected jobs while the total energy consumption is bounded by a given threshold. In this paper, when the number of machines is part of the input, we develop the first $(2+\epsilon)$-approximation algorithm for any fixed constant $\epsilon$ and a simple QPTAS as well as a PTAS for uniform energy consumption rates. Moreover, we present an FPTAS when the number of machines is a fixed constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12635v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingyang Gong, Brendan Mumey</dc:creator>
    </item>
    <item>
      <title>Query-Efficient Locally Private Hypothesis Selection via the Scheffe Graph</title>
      <link>https://arxiv.org/abs/2509.16180</link>
      <description>arXiv:2509.16180v2 Announce Type: replace 
Abstract: We propose an algorithm with improved query-complexity for the problem of hypothesis selection under local differential privacy constraints. Given a set of $k$ probability distributions $Q$, we describe an algorithm that satisfies local differential privacy, performs $\tilde{O}(k^{3/2})$ non-adaptive queries to individuals who each have samples from a probability distribution $p$, and outputs a probability distribution from the set $Q$ which is nearly the closest to $p$. Previous algorithms required either $\Omega(k^2)$ queries or many rounds of interactive queries.
  Technically, we introduce a new object we dub the Scheff\'e graph, which captures structure of the differences between distributions in $Q$, and may be of more broad interest for hypothesis selection tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16180v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gautam Kamath, Alireza F. Pour, Matthew Regehr, David P. Woodruff</dc:creator>
    </item>
    <item>
      <title>Cost-Free Neutrality for the River Method</title>
      <link>https://arxiv.org/abs/2512.14409</link>
      <description>arXiv:2512.14409v2 Announce Type: replace 
Abstract: Recently, the River Method was introduced as novel refinement of the Split Cycle voting rule.
  The decision-making process of River is closely related to the well established Ranked Pairs Method.
  Both methods consider a margin graph computed from the voters' preferences and eliminate majority cycles in that graph to choose a winner.
  As ties can occur in the margin graph, a tiebreaker is required along with the preferences.
  While such a tiebreaker makes the computation efficient, it compromises the fundamental property of neutrality: the voting rule should not favor alternatives in advance.
  One way to reintroduce neutrality is to use Parallel-Universe Tiebreaking (PUT), where each alternative is a winner if it wins according to any possible tiebreaker.
  Unfortunately, computing the winners selected by Ranked Pairs with PUT is NP-complete.
  Given the similarity of River to Ranked Pairs, one might expect River to suffer from the same complexity.
  Surprisingly, we show the opposite:
  We present a polynomial-time algorithm for computing River winners with PUT, highlighting significant structural advantages of River over Ranked Pairs.
  Our Fused-Universe (FUN) algorithm simulates River for every possible tiebreaking in one pass.
  From the resulting FUN diagram one can then directly read off both the set of winners and, for each winner, a certificate that explains how this alternative dominates the others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14409v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michelle D\"oring, Jannes Malanowski, Stefan Neubert</dc:creator>
    </item>
    <item>
      <title>Convex optimization with $p$-norm oracles</title>
      <link>https://arxiv.org/abs/2410.24158</link>
      <description>arXiv:2410.24158v2 Announce Type: replace-cross 
Abstract: In recent years, there have been significant advances in efficiently solving $\ell_s$-regression using linear system solvers and $\ell_2$-regression [Adil-Kyng-Peng-Sachdeva, J. ACM'24]. Would efficient smoothed $\ell_p$-norm solvers lead to even faster rates for solving $\ell_s$-regression when $2 \leq p &lt; s$? In this paper, we give an affirmative answer to this question and show how to solve $\ell_s$-regression using $\tilde{O}(n^{\frac{\nu}{1+\nu}})$ iterations of solving smoothed $\ell_p$ regression problems, where $\nu := \frac{1}{p} - \frac{1}{s}$. To obtain this result, we provide improved accelerated rates for convex optimization problems when given access to an $\ell_p^s(\lambda)$-proximal oracle, which, for a point $c$, returns the solution of the regularized problem $\min_{x} f(x) + \lambda ||x-c||_p^s$. Additionally, we show that these rates for the $\ell_p^s(\lambda)$-proximal oracle are optimal for algorithms that query in the span of the outputs of the oracle, and we further apply our techniques to settings of high-order and quasi-self-concordant optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24158v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deeksha Adil, Brian Bullins, Arun Jambulapati, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Assessing fault-tolerant quantum advantage for $k$-SAT with structure</title>
      <link>https://arxiv.org/abs/2412.13274</link>
      <description>arXiv:2412.13274v3 Announce Type: replace-cross 
Abstract: For many problems, quantum algorithms promise speedups over their classical counterparts. However, these results predominantly rely on asymptotic worst-case analysis, which overlooks significant overheads due to error correction and the fact that real-world instances often contain exploitable structure. In this work, we employ the hybrid benchmarking method to evaluate the potential of quantum Backtracking and Grover's algorithm against the 2023 SAT competition main track winner in solving random $k$-SAT instances with tunable structure, designed to represent industry-like scenarios, using both $T$-depth and $T$-count as cost metrics to estimate quantum run times. Our findings reproduce the results of Campbell, Khurana, and Montanaro (Quantum '19) in the unstructured case using hybrid benchmarking. However, we offer a more sobering perspective in practically relevant regimes: almost all quantum speedups vanish, even asymptotically, when minimal structure is introduced or when $T$-count is considered instead of $T$-depth. Moreover, when the requirement is for the algorithm to find a solution within a single day, we find that only Grover's algorithm has the potential to outperform classical algorithms, but only in a very limited regime and only when using $T$-depth. We also discuss how more sophisticated heuristics could restore the asymptotic scaling advantage for quantum backtracking, but our findings suggest that the potential for practical quantum speedups in more structured $k$-SAT solving will remain limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13274v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martijn Brehm, Jordi Weggemans</dc:creator>
    </item>
    <item>
      <title>Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2510.21414</link>
      <description>arXiv:2510.21414v2 Announce Type: replace-cross 
Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains fundamentally hard, with worst-case time complexity-measured by the total number of multiplications-being no better than straightforward exhaustive search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper introduces a simple, code-agnostic framework that reduces the worst-case complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable reduction in practice. The result holds for both linear and nonlinear block codes over general memoryless channels and under both hard-decision and soft-decision decoding. It naturally extends to intersymbol-interference (ISI) channels and ML list decoding with only a negligible increase in complexity. Our core insight is that, upon receipt of each sequence at the receiver, the conditional probability of that sequence for each codeword in the codebook (i.e., the \emph{likelihood}) can be expressed as the inner product of two carefully constructed vectors -- the first depending on the received sequence, and the second on that codeword itself. As a result, evaluating the likelihoods for all codewords in the codebook reduces to a single vector-matrix multiplication, and ML decoding (MLD) becomes the simple task of picking the maximum entry in the resulting vector. The only non-trivial cost lies in the vector-matrix product. However, our matrix construction allows the use of the Mailman algorithm to reduce this cost. This time reduction is achieved at the cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to store the pre-computed codebook matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21414v2</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin, Michael Schleppy</dc:creator>
    </item>
    <item>
      <title>Pinwheel Scheduling with Real Periods</title>
      <link>https://arxiv.org/abs/2510.24068</link>
      <description>arXiv:2510.24068v3 Announce Type: replace-cross 
Abstract: For a sequence of tasks, each with a positive integer period, the pinwheel scheduling problem involves finding a valid schedule in the sense that the schedule performs one task per day and each task is performed at least once every consecutive days of its period. It had been conjectured by Chan and Chin in 1993 that there exists a valid schedule for any sequence of tasks with density, the sum of the reciprocals of each period, at most $\frac{5}{6}$. Recently, Kawamura settled this conjecture affirmatively. In this paper we consider an extended version with real periods proposed by Kawamura, in which a valid schedule must perform each task $i$ having a real period~$a_{i}$ at least $l$ times in any consecutive $\lceil l a_{i} \rceil$ days for all positive integer $l$. We show that any sequence of tasks such that the periods take three distinct real values and the density is at most $\frac{5}{6}$ admits a valid schedule. We hereby conjecture that the conjecture of Chan and Chin is true also for real periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24068v3</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroshi Fujiwara, Kota Miyagi, Katsuhisa Ouchi</dc:creator>
    </item>
    <item>
      <title>ProbeWalk: Fast Estimation of Biharmonic Distance on Graphs via Probe-Driven Random Walks</title>
      <link>https://arxiv.org/abs/2512.05460</link>
      <description>arXiv:2512.05460v3 Announce Type: replace-cross 
Abstract: The biharmonic distance is a fundamental metric on graphs that measures the dissimilarity between two nodes, capturing both local and global structures. It has found applications across various fields, including network centrality, graph clustering, and machine learning. These applications typically require efficient evaluation of pairwise biharmonic distances. However, existing algorithms remain computationally expensive. The state-of-the-art method attains an absolute-error guarantee epsilon_abs with time complexity O(L^5 / epsilon_abs^2), where L denotes the truncation length. In this work, we improve the complexity to O(L^3 / epsilon^2) under a relative-error guarantee epsilon via probe-driven random walks. We provide a relative-error guarantee rather than an absolute-error guarantee because biharmonic distances vary by orders of magnitude across node pairs. Since L is often very large in real-world networks (for example, L &gt;= 10^3), reducing the L-dependence from the fifth to the third power yields substantial gains. Extensive experiments on real-world networks show that our method delivers 10x-1000x per-query speedups at matched relative error over strong baselines and scales to graphs with tens of millions of nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05460v3</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dehong Zheng, Zhongzhi Zhang</dc:creator>
    </item>
  </channel>
</rss>
