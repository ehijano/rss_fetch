<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2025 02:42:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Parareal in time numerical method for the collisional Vlasov equation in the hyperbolic scaling</title>
      <link>https://arxiv.org/abs/2502.02704</link>
      <description>arXiv:2502.02704v1 Announce Type: new 
Abstract: We present the design of a multiscale parareal method for kinetic equations in the fluid dynamic regime. The goal is to reduce the cost of a fully kinetic simulation using a parallel in time procedure. Using the multiscale property of kinetic models, the cheap, coarse propagator consists in a fluid solver and the fine (expensive) propagation is achieved through a kinetic solver for a collisional Vlasov equation. To validate our approach, we present simulations in the 1D in space, 3D in velocity settings over a wide range of initial data and kinetic regimes, showcasing the accuracy, efficiency, and the speedup capabilities of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02704v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tino Laidin, Thomas Rey</dc:creator>
    </item>
    <item>
      <title>Parametric Reduced Order Models for the Generalized Kuramoto--Sivashinsky Equations</title>
      <link>https://arxiv.org/abs/2502.02718</link>
      <description>arXiv:2502.02718v1 Announce Type: new 
Abstract: The paper studies parametric Reduced Order Models (ROMs) for the Kuramoto--Sivashinsky (KS) and generalized Kuramoto--Sivashinsky (gKS) equations. We consider several POD and POD-DEIM projection ROMs with various strategies for parameter sampling and snapshot collection. The aim is to identify an approach for constructing a ROM that is efficient across a range of parameters, encompassing several regimes exhibited by the KS and gKS solutions: weakly chaotic, transitional, and quasi-periodic dynamics. We describe such an approach and demonstrate that it is essential to develop ROMs that adequately represent the short-time transient behavior of the gKS model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02718v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Rezwan Bin Mizan, Maxim Olshanskii, Ilya Timofeyev</dc:creator>
    </item>
    <item>
      <title>Randomized and Inner-product Free Krylov Methods for Large-scale Inverse Problems</title>
      <link>https://arxiv.org/abs/2502.02721</link>
      <description>arXiv:2502.02721v1 Announce Type: new 
Abstract: Iterative Krylov projection methods have become widely used for solving large-scale linear inverse problems. However, methods based on orthogonality include the computation of inner-products, which become costly when the number of iterations is high; are a bottleneck for parallelization; and can cause the algorithms to break down in low precision due to information loss in the projections. Recent works on inner-product free Krylov iterative algorithms alleviate these concerns, but they are quasi-minimal residual rather than minimal residual methods. This is a potential concern for inverse problems where the residual norm provides critical information from the observations via the likelihood function, and we do not have any way of controlling how close the quasi-norm is from the norm we want to minimize. In this work, we introduce a new Krylov method that is both inner-product-free and minimizes a functional that is theoretically closer to the residual norm. The proposed scheme combines an inner-product free Hessenberg projection approach for generating a solution subspace with a randomized sketch-and-solve approach for solving the resulting strongly overdetermined projected least-squares problem. Numerical results show that the proposed algorithm can solve large-scale inverse problems efficiently and without requiring inner-products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02721v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Malena Sabat\'e Landman, Ariana N. Brown, Julianne Chung, James G. Nagy</dc:creator>
    </item>
    <item>
      <title>On Trimming Tensor-structured Measurements and Efficient Low-rank Tensor Recovery</title>
      <link>https://arxiv.org/abs/2502.02843</link>
      <description>arXiv:2502.02843v1 Announce Type: new 
Abstract: In this paper, we take a step towards developing efficient hard thresholding methods for low-rank tensor recovery from memory-efficient linear measurements with tensorial structure. Theoretical guarantees for many standard iterative low-rank recovery methods, such as iterative hard thresholding (IHT), are based on model assumptions on the measurement operator, like the restricted isometry property (RIP). However, tensor-structured random linear maps -- while memory-efficient and convenient to apply -- lack good restricted isometry properties; that is, they do not preserve the norms of low-rank tensors sufficiently well.
  To address this, we propose local trimming techniques that provably restore point-wise geometry-preservation properties of tensor-structured maps, making them comparable to those of unstructured sub-Gaussian measurements. Then, we propose two novel versions of tensor IHT algorithms: an adaptive gradient trimming algorithm and a randomized Kaczmarz-based IHT algorithm, that efficiently recover low-rank tensors from linear measurements. We provide initial theoretical guarantees for the proposed methods and present numerical experiments on real and synthetic data, highlighting their efficiency over the original TensorIHT for low HOSVD and CP-rank tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02843v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shambhavi Suryanarayanan, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>An Augmented Backward-Corrected Projector Splitting Integrator for Dynamical Low-Rank Training</title>
      <link>https://arxiv.org/abs/2502.03006</link>
      <description>arXiv:2502.03006v1 Announce Type: new 
Abstract: Layer factorization has emerged as a widely used technique for training memory-efficient neural networks. However, layer factorization methods face several challenges, particularly a lack of robustness during the training process. To overcome this limitation, dynamical low-rank training methods have been developed, utilizing robust time integration techniques for low-rank matrix differential equations. Although these approaches facilitate efficient training, they still depend on computationally intensive QR and singular value decompositions of matrices with small rank. In this work, we introduce a novel low-rank training method that reduces the number of required QR decompositions. Our approach integrates an augmentation step into a projector-splitting scheme, ensuring convergence to a locally optimal solution. We provide a rigorous theoretical analysis of the proposed method and demonstrate its effectiveness across multiple benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03006v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Kusch, Steffen Schotth\"ofer, Alexandra Walter</dc:creator>
    </item>
    <item>
      <title>An energy stable and conservative multiplicative dynamical low-rank discretization for the Su-Olson problem</title>
      <link>https://arxiv.org/abs/2502.03008</link>
      <description>arXiv:2502.03008v1 Announce Type: new 
Abstract: Computing numerical solutions of the thermal radiative transfer equations on a finely resolved grid can be costly due to high computational and memory requirements. A numerical reduced order method that has recently been applied to a wide variety of kinetic partial differential equations is the concept of dynamical low-rank approximation (DLRA). In this paper, we consider the thermal radiative transfer equations with Su-Olson closure, leading to a linearized kinetic model. For the conducted theoretical and practical considerations we use a multiplicative splitting of the distribution function that poses additional challenges in finding an energy stable discretization and deriving a hyperbolic Courant-Friedrichs-Lewy (CFL) condition. We propose such an energy stable DLRA scheme that makes use of the augmented basis update &amp; Galerkin integrator. This integrator allows for additional basis augmentations, enabling us to give a mathematically rigorous proof of energy stability and local mass conservation. Numerical examples confirm the derived properties and show the computational advantages of the DLRA scheme compared to a numerical solution of the full system of equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03008v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lena Baumann, Lukas Einkemmer, Christian Klingenberg, Jonas Kusch</dc:creator>
    </item>
    <item>
      <title>Determine the point source of the heat equation with sparse boundary measurements</title>
      <link>https://arxiv.org/abs/2502.03018</link>
      <description>arXiv:2502.03018v1 Announce Type: new 
Abstract: In this work the authors consider the recovery of the point source in the heat equation. The used data is the sparse boundary measurements. The uniqueness theorem of the inverse problem is given. After that, the numerical reconstruction is considered. We propose a numerical method to reconstruct the location of a Dirac point source by reformulating the inverse problem as a least-squares optimization problem, which is efficiently solved using a gradient descent algorithm. Numerical experiments confirm the accuracy of the proposed method and demonstrate its robustness to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03018v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiling Gu, Wenlong Zhang, Zhidong Zhang</dc:creator>
    </item>
    <item>
      <title>Internal layer solutions and coefficient recovery in time-periodic reaction-diffusion-advection equations</title>
      <link>https://arxiv.org/abs/2502.03068</link>
      <description>arXiv:2502.03068v1 Announce Type: new 
Abstract: This article investigates the non-stationary reaction-diffusion-advection equation, emphasizing solutions with internal layers and the associated inverse problems. We examine a nonlinear singularly perturbed partial differential equation (PDE) within a bounded spatial domain and an infinite temporal domain, subject to periodic temporal boundary conditions. A periodic asymptotic solution featuring an inner transition layer is proposed, advancing the mathematical modeling of reaction-diffusion-advection dynamics. Building on this asymptotic analysis, we develop a simple yet effective numerical algorithm to address ill-posed nonlinear inverse problems aimed at reconstructing coefficient functions that depend solely on spatial or temporal variables. Conditions ensuring the existence and uniqueness of solutions for both forward and inverse problems are established. The proposed method's effectiveness is validated through numerical experiments, demonstrating high accuracy in reconstructing coefficient functions under varying noise conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03068v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitrii Chaikovskii, Ye Zhang, Aleksei Liubavin</dc:creator>
    </item>
    <item>
      <title>Comparison of 2D Regular Lattices for the CPWL Approximation of Functions</title>
      <link>https://arxiv.org/abs/2502.03115</link>
      <description>arXiv:2502.03115v1 Announce Type: new 
Abstract: We investigate the approximation error of functions with continuous and piecewise-linear (CPWL) representations. We focus on the CPWL search spaces generated by translates of box splines on two-dimensional regular lattices. We compute the approximation error in terms of the stepsize and angles that define the lattice. Our results show that hexagonal lattices are optimal, in the sense that they minimize the asymptotic approximation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03115v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehrsa Pourya, Ma\"ika Nogarotto, Michael Unser</dc:creator>
    </item>
    <item>
      <title>A boundary-corrected weak Galerkin mixed finite method for elliptic interface problems with curved interfaces</title>
      <link>https://arxiv.org/abs/2502.03157</link>
      <description>arXiv:2502.03157v1 Announce Type: new 
Abstract: We propose a boundary-corrected weak Galerkin mixed finite element method for solving elliptic interface problems in 2D domains with curved interfaces. The method is formulated on body-fitted polygonal meshes, where interface edges are straight and may not align exactly with the curved physical interface. To address this discrepancy, a boundary value correction technique is employed to transfer the interface conditions from the physical interface to the approximate interface using a Taylor expansion approach. The Neumann interface condition is then weakly imposed in the variational formulation. This approach eliminates the need for numerical integration on curved elements, thereby reducing implementation complexity. We establish optimal-order convergence in the energy norm for arbitrary-order discretizations. Numerical results are provided to support the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03157v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongli Hou, Yi Liu, Yanqiu Wang</dc:creator>
    </item>
    <item>
      <title>Multivariate Rational Approximation via Low-Rank Tensors and the p-AAA Algorithm</title>
      <link>https://arxiv.org/abs/2502.03204</link>
      <description>arXiv:2502.03204v1 Announce Type: new 
Abstract: Approximations based on rational functions are widely used in various applications across computational science and engineering. For univariate functions, the adaptive Antoulas-Anderson algorithm (AAA), which uses the barycentric form of a rational approximant, has established itself as a powerful tool for efficiently computing such approximations. The p-AAA algorithm, an extension of the AAA algorithm specifically designed to address multivariate approximation problems, has been recently introduced. A common challenge in multivariate approximation methods is that multivariate problems with a large number of variables often pose significant memory and computational demands. To tackle this hurdle in the setting of p-AAA, we first introduce barycentric forms that are represented in the terms of separable functions. This then leads to the low-rank p-AAA algorithm which leverages low-rank tensor decompositions in the setting of barycentric rational approximations. We discuss various theoretical and practical aspects of the proposed computational framework and showcase its effectiveness on four numerical examples. We focus specifically on applications in parametric reduced-order modeling for which higher-dimensional data sets can be tackled effectively with our novel procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03204v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linus Balicki, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Multilevel Picard approximations for McKean-Vlasov stochastic differential equations with nonconstant diffusion</title>
      <link>https://arxiv.org/abs/2502.03205</link>
      <description>arXiv:2502.03205v1 Announce Type: new 
Abstract: We introduce multilevel Picard (MLP) approximations for McKean-Vlasov stochastic differential equations (SDEs) with nonconstant diffusion coefficient. Under standard Lipschitz assumptions on the coefficients, we show that the MLP algorithm approximates the solution of the SDE in the $L^2$-sense without the curse of dimensionality. The latter means that its computational cost grows at most polynomially in both the dimension and the reciprocal of the prescribed error tolerance. In two numerical experiments, we demonstrate its applicability by approximating McKean-Vlasov SDEs in dimensions up to 10000.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03205v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Tuan Anh Nguyen, Philipp Schmocker</dc:creator>
    </item>
    <item>
      <title>Practical Introduction to FEM with GMSH: A MATLAB/Octave Perspective</title>
      <link>https://arxiv.org/abs/2502.03248</link>
      <description>arXiv:2502.03248v1 Announce Type: new 
Abstract: The Finite Element Method (FEM) is a powerful computational tool for solving partial differential equations (PDEs). Although commercial and open-source FEM software packages are widely available, an independent implementation of FEM provides significant educational value, provides a deeper understanding of the method, and enables the development of custom solutions tailored to specialized applications or integration with other solvers. This work introduces a 3D $\mathbb{P}_m$-element FEM implementation in MATLAB/Octave that is designed to balance educational clarity with computational efficiency. A key feature is its integration with GMSH, an open-source 3D mesh generator with CAD capabilities that streamlines mesh generation for complex geometries. By leveraging GMSH data structures, we provide a seamless connection between geometric modeling and numerical simulation. The implementation focuses on solving the general convection-diffusion-advection equation and serves as a flexible foundation for addressing advanced problems, including elasticity, mixed formulations, and integration with other numerical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03248v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Dominguez, Alejandro Duque</dc:creator>
    </item>
    <item>
      <title>A time adaptive multirate Quasi-Newton waveform iteration for coupled problems</title>
      <link>https://arxiv.org/abs/2502.03265</link>
      <description>arXiv:2502.03265v1 Announce Type: new 
Abstract: We consider waveform iterations for dynamical coupled problems, or more specifically, PDEs that interact through a lower dimensional interface. We want to allow for the reuse of existing codes for the subproblems, called a partitioned approach. To improve computational efficiency, different and adaptive time steps in the subsolvers are advisable. Using so called waveform iterations in combination with relaxation, this has been achieved for heat transfer problems earlier. Alternatively, one can use a black box method like Quasi-Newton to improve the convergence behaviour. These methods have recently been combined with waveform iterations for fixed time steps. Here, we suggest an extension of the Quasi-Newton method to the time adaptive setting and analyze its properties.
  We compare the proposed Quasi-Newton method with state of the art solvers on a heat transfer test case, and a complex mechanical Fluid-Structure interaction case, demonstrating the methods efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03265v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niklas Kotarsky, Philipp Birken</dc:creator>
    </item>
    <item>
      <title>Efficient sampling approaches based on generalized Golub-Kahan methods for large-scale hierarchical Bayesian inverse problems</title>
      <link>https://arxiv.org/abs/2502.03281</link>
      <description>arXiv:2502.03281v1 Announce Type: new 
Abstract: Uncertainty quantification for large-scale inverse problems remains a challenging task. For linear inverse problems with additive Gaussian noise and Gaussian priors, the posterior is Gaussian but sampling can be challenging, especially for problems with a very large number of unknown parameters (e.g., dynamic inverse problems) and for problems where computation of the square root and inverse of the prior covariance matrix are not feasible. Moreover, for hierarchical problems where several hyperparameters that define the prior and the noise model must be estimated from the data, the posterior distribution may no longer be Gaussian, even if the forward operator is linear. Performing large-scale uncertainty quantification for these hierarchical settings requires new computational techniques. In this work, we consider a hierarchical Bayesian framework where both the noise and prior variance are modeled as hyperparameters. Our approach uses Metropolis-Hastings independence sampling within Gibbs where the proposal distribution is based on generalized Golub-Kahan based methods. We consider two proposal samplers, one that uses a low rank approximation to the conditional covariance matrix and another that uses a preconditioned Lanczos method. Numerical examples from seismic imaging, dynamic photoacoustic tomography, and atmospheric inverse modeling demonstrate the effectiveness of the described approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03281v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elle Buser, Julianne Chung</dc:creator>
    </item>
    <item>
      <title>An efficient end-to-end computational framework for the generation of ECG calibrated volumetric models of human atrial electrophysiology</title>
      <link>https://arxiv.org/abs/2502.03322</link>
      <description>arXiv:2502.03322v1 Announce Type: new 
Abstract: Computational models of atrial electrophysiology (EP) are increasingly utilized for applications such as the development of advanced mapping systems, personalized clinical therapy planning, and the generation of virtual cohorts and digital twins. These models have the potential to establish robust causal links between simulated in silico behaviors and observed human atrial EP, enabling safer, cost-effective, and comprehensive exploration of atrial dynamics. However, current state-of-the-art approaches lack the fidelity and scalability required for regulatory-grade applications, particularly in creating high-quality virtual cohorts or patient-specific digital twins. Challenges include anatomically accurate model generation, calibration to sparse and uncertain clinical data, and computational efficiency within a streamlined workflow. This study addresses these limitations by introducing novel methodologies integrated into an automated end-to-end workflow for generating high-fidelity digital twin snapshots and virtual cohorts of atrial EP. These innovations include: (i) automated multi-scale generation of volumetric biatrial models with detailed anatomical structures and fiber architecture; (ii) a robust method for defining space-varying atrial parameter fields; (iii) a parametric approach for modeling inter-atrial conduction pathways; and (iv) an efficient forward EP model for high-fidelity electrocardiogram computation. We evaluated this workflow on a cohort of 50 atrial fibrillation patients, producing high-quality meshes suitable for reaction-eikonal and reaction-diffusion models and demonstrating the ability to simulate atrial ECGs under parametrically controlled conditions. These advancements represent a critical step toward scalable, precise, and clinically applicable digital twin models and virtual cohorts, enabling enhanced patient-specific predictions and therapeutic planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03322v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>q-bio.TO</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Zappon, Luca Azzolin, Matthias A. F. Gsell, Franz Thaler, Anton J. Prassl, Robert Arnold, Karli Gillette, Mohammadreza Kariman, Martin Manninger-W\"unscher, Daniel Scherr, Aurel Neic, Martin Urschler, Christoph M. Augustin, Edward J. Vigmond, Gernot Plank</dc:creator>
    </item>
    <item>
      <title>Cheap and stable quadrature on polyhedral elements</title>
      <link>https://arxiv.org/abs/2502.03446</link>
      <description>arXiv:2502.03446v1 Announce Type: new 
Abstract: We discuss a cheap tetrahedra-free approach to the numerical integration of polynomials on polyhedral elements, based on hyperinterpolation in a bounding box and Chebyshev moment computation via the divergence theorem. No conditioning issues arise, since no matrix factorization or inversion is needed. The resulting quadrature formula is theoretically stable even in the presence of some negative weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03446v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alvise Sommariva, Marco Vianello</dc:creator>
    </item>
    <item>
      <title>The bilinear Hessian for large scale optimization</title>
      <link>https://arxiv.org/abs/2502.03070</link>
      <description>arXiv:2502.03070v1 Announce Type: cross 
Abstract: Second order information is useful in many ways in smooth optimization problems, including for the design of step size rules and descent directions, or the analysis of the local properties of the objective functional. However, the computation and storage of the Hessian matrix using second order partial derivatives is prohibitive in many contexts, and in particular in large scale problems. In this work, we propose a new framework for computing and presenting second order information in analytic form. The key novel insight is that the Hessian for a problem can be worked with efficiently by computing its bilinear form or operator form using Taylor expansions, instead of introducing a basis and then computing the Hessian matrix. Our new framework is suited for high-dimensional problems stemming e.g. from imaging applications, where computation of the Hessian matrix is unfeasible. We also show how this can be used to implement Newton's step rule, Daniel's Conjugate Gradient rule, or Quasi-Newton schemes, without explicit knowledge of the Hessian matrix, and illustrate our findings with a simple numerical experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03070v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcus Carlsson, Viktor Nikitin, Erik Troedsson, Herwig Wendt</dc:creator>
    </item>
    <item>
      <title>Gaussian Processes Regression for Uncertainty Quantification: An Introductory Tutorial</title>
      <link>https://arxiv.org/abs/2502.03090</link>
      <description>arXiv:2502.03090v1 Announce Type: cross 
Abstract: Gaussian Process Regression (GPR) is a powerful method widely used in Uncertainty Quantification (UQ). This tutorial serves as an introductory guide for beginners, aiming to offer a structured and accessible overview of GPR's applications in UQ. We begin with an introduction to UQ and outline its key tasks, including uncertainty propagation, risk estimation, optimization under uncertainty, parameter estimation, and sensitivity analysis. We then introduce Gaussian Processes (GPs) as a surrogate modeling technique, detailing their formulation, choice of covariance kernels, hyperparameter estimation, and active learning strategies for efficient data acquisition. The tutorial further explores how GPR can be applied to different UQ tasks, including Bayesian quadrature for uncertainty propagation, active learning-based risk estimation, Bayesian optimization for optimization under uncertainty, and surrogate-based sensitivity analysis. Throughout, we emphasize how to leverage the unique formulation of GP for these UQ tasks, rather than simply using it as a standard surrogate model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03090v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinglai Li, Hongqiao Wang</dc:creator>
    </item>
    <item>
      <title>Chiral rank-$k$ truncations for the multigrid preconditioner of Wilson fermions in lattice QCD</title>
      <link>https://arxiv.org/abs/2502.03091</link>
      <description>arXiv:2502.03091v1 Announce Type: cross 
Abstract: We present a modification to the setup algorithm for the multigrid preconditioner of Wilson fermions in lattice QCD. A larger number of test vectors than that used in conventional multigrid is generated by the smoother. This set of test vectors is then truncated by a singular value decomposition on the chiral components of the test vectors, which are subsequently used to form the prolongation and restriction matrices of the multigrid hierarchy. This modification is demonstrated to improve the convergence of linear equations on an anisotropic lattice with $m_{\pi} \approx 239$ MeV from the Hadron Spectrum Collaboration and an isotropic lattice with $m_{\pi} \approx 220$ MeV from the MILC Collaboration. The lattice volume dependence of the method is also examined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03091v1</guid>
      <category>hep-lat</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Travis Whyte, Andreas Stathopoulos, Eloy Romero</dc:creator>
    </item>
    <item>
      <title>Is In-Context Universality Enough? MLPs are Also Universal In-Context</title>
      <link>https://arxiv.org/abs/2502.03327</link>
      <description>arXiv:2502.03327v1 Announce Type: cross 
Abstract: The success of transformers is often linked to their ability to perform in-context learning. Recent work shows that transformers are universal in context, capable of approximating any real-valued continuous function of a context (a probability measure over $\mathcal{X}\subseteq \mathbb{R}^d$) and a query $x\in \mathcal{X}$. This raises the question: Does in-context universality explain their advantage over classical models? We answer this in the negative by proving that MLPs with trainable activation functions are also universal in-context. This suggests the transformer's success is likely due to other factors like inductive bias or training stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03327v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasis Kratsios, Takashi Furuya</dc:creator>
    </item>
    <item>
      <title>Multilevel Picard approximation algorithm for semilinear partial integro-differential equations and its complexity analysis</title>
      <link>https://arxiv.org/abs/2205.09639</link>
      <description>arXiv:2205.09639v4 Announce Type: replace 
Abstract: In this paper we introduce a multilevel Picard approximation algorithm for semilinear parabolic partial integro-differential equations (PIDEs). We prove that the numerical approximation scheme converges to the unique viscosity solution of the PIDE under consideration. To that end, we derive a Feynman-Kac representation for the unique viscosity solution of the semilinear PIDE, extending the classical Feynman-Kac representation for linear PIDEs. Furthermore, we show that the algorithm does not suffer from the curse of dimensionality, i.e. the computational complexity of the algorithm is bounded polynomially in the dimension $d$ and the reciprocal of the prescribed accuracy $\varepsilon$. We also provide a numerical example in up to 10'000 dimensions to demonstrate its applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.09639v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Sizhou Wu</dc:creator>
    </item>
    <item>
      <title>Distributional Finite Element curl div Complexes and Application to Quad Curl Problems</title>
      <link>https://arxiv.org/abs/2311.09051</link>
      <description>arXiv:2311.09051v5 Announce Type: replace 
Abstract: The paper addresses the challenge of constructing finite element curl div complexes in three dimensions. Tangential-normal continuity is introduced in order to develop distributional finite element curl div complexes. The spaces constructed are applied to discretize the quad curl problem, demonstrating optimal order of convergence. Furthermore, a hybridization technique is proposed, demonstrating its equivalence to nonconforming finite elements and weak Galerkin methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09051v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Long Chen, Xuehai Huang, Chao Zhang</dc:creator>
    </item>
    <item>
      <title>Bayesian learning with Gaussian processes for low-dimensional representations of time-dependent nonlinear systems</title>
      <link>https://arxiv.org/abs/2408.03455</link>
      <description>arXiv:2408.03455v2 Announce Type: replace 
Abstract: This work presents a data-driven method for learning low-dimensional time-dependent physics-based surrogate models whose predictions are endowed with uncertainty estimates. We use the operator inference approach to model reduction that poses the problem of learning low-dimensional model terms as a regression of state space data and corresponding time derivatives by minimizing the residual of reduced system equations. Standard operator inference models perform well with accurate training data that are dense in time, but producing stable and accurate models when the state data are noisy and/or sparse in time remains a challenge. Another challenge is the lack of uncertainty estimation for the predictions from the operator inference models. Our approach addresses these challenges by incorporating Gaussian process surrogates into the operator inference framework to (1) probabilistically describe uncertainties in the state predictions and (2) procure analytical time derivative estimates with quantified uncertainties. The formulation leads to a generalized least-squares regression and, ultimately, reduced-order models that are described probabilistically with a closed-form expression for the posterior distribution of the operators. The resulting probabilistic surrogate model propagates uncertainties from the observed state data to reduced-order predictions. We demonstrate the method is effective for constructing low-dimensional models of two nonlinear partial differential equations representing a compressible flow and a nonlinear diffusion-reaction process, as well as for estimating the parameters of a low-dimensional system of nonlinear ordinary differential equations representing compartmental models in epidemiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03455v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shane A. McQuarrie, Anirban Chaudhuri, Karen E. Willcox, Mengwu Guo</dc:creator>
    </item>
    <item>
      <title>Deep Ritz-Finite Element methods: Neural Network Methods trained with Finite Elements</title>
      <link>https://arxiv.org/abs/2409.08362</link>
      <description>arXiv:2409.08362v4 Announce Type: replace 
Abstract: While much attention of neural network methods is devoted to high-dimensional PDE problems, in this work we consider methods designed to work for elliptic problems on domains $\Omega \subset \mathbb{R} ^d, $ $d=1,2,3$ in association with more standard finite elements. We suggest to connect finite elements and neural network approximations through training, i.e., using finite element spaces to compute the integrals appearing in the loss functionals. This approach, retains the simplicity of classical neural network methods for PDEs, uses well established finite element tools (and software) to compute the integrals involved and it gains in efficiency and accuracy. We demonstrate that the proposed methods are stable and furthermore, we establish that the resulting approximations converge to the solutions of the PDE. Numerical results indicating the efficiency and robustness of the proposed algorithms are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08362v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2025.117798</arxiv:DOI>
      <dc:creator>Georgios Grekas, Charalambos G. Makridakis</dc:creator>
    </item>
    <item>
      <title>AttNS: Attention-Inspired Numerical Solving For Limited Data Scenarios</title>
      <link>https://arxiv.org/abs/2302.10184</link>
      <description>arXiv:2302.10184v2 Announce Type: replace-cross 
Abstract: We propose the attention-inspired numerical solver (AttNS), a concise method that helps the generalization and robustness issues faced by the AI-Hybrid numerical solver in solving differential equations due to limited data. AttNS is inspired by the effectiveness of attention modules in Residual Neural Networks (ResNet) in enhancing model generalization and robustness for conventional deep learning tasks. Drawing from the dynamical system perspective of ResNet, we seamlessly incorporate attention mechanisms into the design of numerical methods tailored for the characteristics of solving differential equations. Our results on benchmarks, ranging from high-dimensional problems to chaotic systems, showcases AttNS consistently enhancing various numerical solvers without any intricate model crafting. Finally, we analyze AttNS experimentally and theoretically, demonstrating its ability to achieve strong generalization and robustness while ensuring the convergence of the solver. This includes requiring less data compared to other advanced methods to achieve comparable generalization errors and better prevention of numerical explosion issues when solving differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.10184v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongzhan Huang, Mingfu Liang, Shanshan Zhong, Liang Lin</dc:creator>
    </item>
    <item>
      <title>Reconstructing the Magnetic Field in an Arbitrary Domain via Data-driven Bayesian Methods and Numerical Simulations</title>
      <link>https://arxiv.org/abs/2404.15745</link>
      <description>arXiv:2404.15745v3 Announce Type: replace-cross 
Abstract: Inverse problems are prevalent in numerous scientific and engineering disciplines, where the objective is to determine unknown parameters within a physical system using indirect measurements or observations. The inherent challenge lies in deducing the most probable parameter values that align with the collected data. This study introduces an algorithm for reconstructing parameters by addressing an inverse problem formulated through differential equations underpinned by uncertain boundary conditions or variant parameters. We adopt a Bayesian approach for parameter inference, delineating the establishment of prior, likelihood, and posterior distributions, and the subsequent resolution of the maximum a posteriori problem via numerical optimization techniques. The proposed algorithm is applied to the task of magnetic field reconstruction within a conical domain, demonstrating precise recovery of the true parameter values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15745v3</guid>
      <category>physics.comp-ph</category>
      <category>astro-ph.HE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/computation13020037</arxiv:DOI>
      <dc:creator>Georgios E. Pavlou, Vasiliki Pavlidou, Vagelis Harmandaris</dc:creator>
    </item>
    <item>
      <title>An accelerated gradient method with adaptive restart for convex multiobjective optimization problems</title>
      <link>https://arxiv.org/abs/2501.07863</link>
      <description>arXiv:2501.07863v5 Announce Type: replace-cross 
Abstract: In this work, based on the continuous time approach, we propose an accelerated gradient method with adaptive residual restart for convex multiobjective optimization problems. For the first, we derive rigorously the continuous limit of the multiobjective accelerated proximal gradient method by Tanabe et al. [Comput. Optim. Appl., 2023]. It is a second-order ordinary differential equation (ODE) that involves a special projection operator and can be viewed as an extension of the ODE by Su et al. [J. Mach. Learn. Res., 2016] for Nesterov acceleration. Then, we introduce a novel accelerated multiobjective gradient (AMG) flow with tailored time scaling that adapts automatically to the convex case and the strongly convex case, and the exponential decay rate of a merit function along with the solution trajectory of AMG flow is established via the Lyapunov analysis. After that, we consider an implicit-explicit time discretization and obtain an accelerated multiobjective gradient method with a convex quadratic programming subproblem. The fast sublinear rate and linear rate are proved respectively for convex and strongly convex problems. In addition, we present an efficient residual based adaptive restart technique to overcome the oscillation issue and improve the convergence significantly. Numerical results are provided to validate the practical performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07863v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Luo, Liping Tang, Xinmin Yang</dc:creator>
    </item>
  </channel>
</rss>
