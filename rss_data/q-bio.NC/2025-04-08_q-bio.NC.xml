<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 01:55:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Modeling the Dynamics of Attentional Gamma Oscillations During the Encoding Process of Noise-Mixed Speech Signals</title>
      <link>https://arxiv.org/abs/2504.04329</link>
      <description>arXiv:2504.04329v1 Announce Type: new 
Abstract: The brain's bottom-up loop for processing speech influx involves both the selective attention and the encoding of specific speech information. Previous human studies have found that such attention can be represented by the cortical gamma-rhythm oscillations. However, the underlying mechanisms remain unclear. To address this issue, this paper proposes a neural network model that incorporates speech signal input, the cochlea, the thalamus, and a balanced excitatory-inhibitory cortical neural network, with the aim of connecting real speech signals to brain cortical responses. Using this model, we explored neural oscillation patterns in response to mixed speech stimuli and background noise. The findings revealed that the peak of gamma oscillation decreased as the frequency of the pure-tone stimuli diminished. This suggests a strong correlation and coding role of gamma oscillation peaks in auditory attention. Similar results were confirmed by analyzing the rhythmic oscillations of EEG data in response to pure-tone signals. Further results indicated that dynamic gamma oscillations are involved in the encoding capacity of continuous speech input. The coding entropy of the dynamic series was found to be proportional to the complexity of the content. This suggests that gamma oscillations play multiple roles, not only in sustaining the bottom-up attentional state but also in potentially conveying specific information from external speech inputs. Finally, we found that enhancing the excitatory-inhibitory balance level properly could improve auditory attention. This finding provides a potential endogenous explanation for the dynamic switching process of brain attention in processing auditory signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04329v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duoyu Feng, Jiajia Li, Ying Wu</dc:creator>
    </item>
    <item>
      <title>End-to-End Deep Learning for Real-Time Neuroimaging-Based Assessment of Bimanual Motor Skills</title>
      <link>https://arxiv.org/abs/2504.03681</link>
      <description>arXiv:2504.03681v1 Announce Type: cross 
Abstract: The real-time assessment of complex motor skills presents a challenge in fields such as surgical training and rehabilitation. Recent advancements in neuroimaging, particularly functional near-infrared spectroscopy (fNIRS), have enabled objective assessment of such skills with high accuracy. However, these techniques are hindered by extensive preprocessing requirements to extract neural biomarkers. This study presents a novel end-to-end deep learning framework that processes raw fNIRS signals directly, eliminating the need for intermediate preprocessing steps. The model was evaluated on datasets from three distinct bimanual motor tasks--suturing, pattern cutting, and endotracheal intubation (ETI)--using performance metrics derived from both training and retention datasets. It achieved a mean classification accuracy of 93.9% (SD 4.4) and a generalization accuracy of 92.6% (SD 1.9) on unseen skill retention datasets, with a leave-one-subject-out cross-validation yielding an accuracy of 94.1% (SD 3.6). Contralateral prefrontal cortex activations exhibited task-specific discriminative power, while motor cortex activations consistently contributed to accurate classification. The model also demonstrated resilience to neurovascular coupling saturation caused by extended task sessions, maintaining robust performance across trials. Comparative analysis confirms that the end-to-end model performs on par with or surpasses baseline models optimized for fully processed fNIRS data, with statistically similar (p&lt;0.05) or improved prediction accuracies. By eliminating the need for extensive signal preprocessing, this work provides a foundation for real-time, non-invasive assessment of bimanual motor skills in medical training environments, with potential applications in robotics, rehabilitation, and sports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03681v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aseem Subedi,  Rahul, Lora Cavuoto, Steven Schwaitzberg, Matthew Hackett, Jack Norfleet, Suvranu De</dc:creator>
    </item>
    <item>
      <title>Beyond catastrophic forgetting in associative networks with self-interactions</title>
      <link>https://arxiv.org/abs/2504.04560</link>
      <description>arXiv:2504.04560v1 Announce Type: cross 
Abstract: Spin-glass models of associative memories are a cornerstone between statistical physics and theoretical neuroscience. In these networks, stochastic spin-like units interact through a synaptic matrix shaped by local Hebbian learning. In absence of self-interactions (i.e., autapses), the free energy reveals catastrophic forgetting of all stored patterns when their number exceeds a critical memory load. Here, we bridge the gap with biology by considering networks of deterministic, graded units coupled via the same Amari-Hopfield synaptic matrix, while retaining autapses. Contrary to the assumption that self-couplings play a negligible role, we demonstrate that they qualitatively reshape the energy landscape, confining the recurrent dynamics to the subspace hosting the stored patterns. This allows for the derivation of an exact overlap-dependent Lyapunov function, valid even for networks with finite size. Moreover, self-interactions generate an auxiliary internal field aligned with the target memory pattern, widening the repertoire of accessible attractor states. Consequently, pure recall states act as robust associative memories for any memory load, beyond the critical threshold for catastrophic forgetting observed in spin-glass models -- all without requiring nonlocal learning prescriptions or significant reshaping of the Hebbian synaptic matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04560v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gianni V. Vinci, Andrea Galluzzi, Maurizio Mattia</dc:creator>
    </item>
    <item>
      <title>Retinotopic Mechanics derived using classical physics</title>
      <link>https://arxiv.org/abs/2109.11632</link>
      <description>arXiv:2109.11632v4 Announce Type: replace 
Abstract: The concept of a cell$'$s receptive field is a bedrock in systems neuroscience, and the classical static description of the receptive field has had enormous success in explaining the fundamental mechanisms underlying visual processing. Borne out by the spatio-temporal dynamics of visual sensitivity to probe stimuli in primates, I build on top of this static account with the introduction of a new computational field of research, retinotopic mechanics. At its core, retinotopic mechanics assumes that during active sensing receptive fields are not static but can shift beyond their classical extent. Specifically, the canonical computations and the neural architecture that supports these computations are inherently mediated by a neurobiologically inspired force field (e.g.,$R_s\propto \sim 1 /\Delta M$). For example, when the retina is displaced because of a saccadic eye movement from one point in space to another, cells across retinotopic brain areas are tasked with discounting the retinal disruptions such active surveillance inherently introduces. This neural phenomenon is known as spatial constancy. Using retinotopic mechanics, I propose that to achieve spatial constancy or any active visually mediated task, retinotopic cells, namely their receptive fields, are constrained by eccentricity dependent elastic fields. I propose that elastic fields are self-generated by the visual system and allow receptive fields the ability to predictively shift beyond their classical extent to future post-saccadic location such that neural sensitivity which would otherwise support intermediate eccentric locations likely to contain retinal disruptions is transiently blunted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.11632v4</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ifedayo-EmmanuEL Adeyefa-Olasupo</dc:creator>
    </item>
    <item>
      <title>Oja's plasticity rule overcomes several challenges of training neural networks under biological constraints</title>
      <link>https://arxiv.org/abs/2408.08408</link>
      <description>arXiv:2408.08408v3 Announce Type: replace 
Abstract: Deep neural networks have achieved impressive performance through carefully engineered training strategies. Nonetheless, such methods lack parallels in biological neural circuits, relying heavily on non-local credit assignment, precise initialization, normalization layers, batch processing, and large datasets. Biologically plausible plasticity rules, such as random feedback alignment, often suffer from instability and unbounded weight growth without these engineered methods, while Hebbian-type schemes fail to provide goal-oriented credit. In this study, we demonstrate that incorporating Oja's plasticity rule into error-driven training yields stable, efficient learning in feedforward and recurrent architectures, obviating the need for carefully engineered tricks. Our results show that Oja's rule preserves richer activation subspaces, mitigates exploding or vanishing signals, and improves short-term memory in recurrent networks. Notably, meta-learned local plasticity rules incorporating Oja's principle not only match but surpass standard backpropagation in data-scarce regimes. These findings reveal a biologically grounded pathway bridging engineered deep networks and plausible synaptic mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08408v3</guid>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Navid Shervani-Tabar, Marzieh Alireza Mirhoseini, Robert Rosenbaum</dc:creator>
    </item>
    <item>
      <title>Dual mechanism of Anti-Seizure Medications in controlling seizure activity</title>
      <link>https://arxiv.org/abs/2504.01887</link>
      <description>arXiv:2504.01887v2 Announce Type: replace 
Abstract: Background: Anti-seizure medications (ASMs) can reduce seizure duration, but their precise modes of action are unclear. Specifically, it is unknown whether ASMs shorten seizures by simply compressing existing seizure activity into a shorter time frame or by selectively suppressing certain seizure activity patterns.
  Methods: We analysed intracranial EEG (iEEG) recordings of 457 seizures from 28 people with epilepsy undergoing ASM tapering. Beyond measuring seizure occurrence and duration, we categorized distinct seizure activity patterns (states) based on spatial and frequency power characteristics and related these to different ASM levels.
  Results: We found that reducing ASM levels led to increased seizure frequency (r = 0.87, p &lt; 0.001) and longer seizure duration ($\beta$ = -0.033, p &lt; 0.001), consistent with prior research. Further analysis revealed two distinct mechanisms in which seizures became prolonged:
  Emergence of new seizure patterns - In approx. 40% of patients, ASM tapering unmasked additional seizure activity states, and seizures containing these 'taper-emergent states' were substantially longer (r = 0.49, p &lt; 0.001).
  Prolongation of existing seizure patterns - Even in seizures without taper-emergent states, lower ASM levels still resulted in approx. 12-224% longer durations depending on the ASM dosage and tapering ($\beta$ = -0.049, p &lt; 0.001).
  Conclusion: ASMs influence seizures through two mechanisms: they (i) suppress specific seizure activity patterns (states) in an all-or-nothing fashion and (ii) curtail the duration of other seizure patterns. These findings highlight the complex role of ASMs in seizure modulation and could inform personalized dosing strategies for epilepsy management. These findings may also have implications in understanding the effects of ASMs on cognition and mood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01887v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillermo M. Besne, Emmanuel Molefi, Sarah J. Gascoigne, Nathan Evans, Billy Smith, Chris Thornton, Fahmida A. Chowdhury, Beate Diehl, John S. Duncan, Andrew W. McEvoy, Anna Miserocchi, Jane de Tisi, Matthew Walker, Peter N. Taylor, Yujiang Wang</dc:creator>
    </item>
    <item>
      <title>Interpreting the structure of multi-object representations in vision encoders</title>
      <link>https://arxiv.org/abs/2406.09067</link>
      <description>arXiv:2406.09067v3 Announce Type: replace-cross 
Abstract: In this work, we interpret the representations of multi-object scenes in vision encoders through the lens of structured representations. Structured representations allow modeling of individual objects distinctly and their flexible use based on the task context for both scene-level and object-specific tasks. These capabilities play a central role in human reasoning and generalization, allowing us to abstract away irrelevant details and focus on relevant information in a compact and usable form. We define structured representations as those that adhere to two specific properties: binding specific object information into discrete representation units and segregating object representations into separate sets of tokens to minimize cross-object entanglement. Based on these properties, we evaluated and compared image encoders pre-trained on classification (ViT), large vision-language models (CLIP, BLIP, FLAVA), and self-supervised methods (DINO, DINOv2). We examine the token representations by creating object-decoding tasks that measure the ability of specific tokens to capture individual objects in multi-object scenes from the COCO dataset. This analysis provides insights into how object-wise representations are distributed across tokens and layers within these vision encoders. Our findings highlight significant differences in the representation of objects depending on their relevance to the pre-training objective, with this effect particularly pronounced in the CLS token (often used for downstream tasks). Meanwhile, networks and layers that exhibit more structured representations retain better information about individual objects. To guide practical applications, we propose formal measures to quantify the two properties of structured representations, aiding in selecting and adapting vision encoders for downstream tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09067v3</guid>
      <category>cs.CV</category>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarun Khajuria, Braian Olmiro Dias, Marharyta Domnich, Jaan Aru</dc:creator>
    </item>
    <item>
      <title>Dense networks of integrate-and-fire neurons: Spatially-extended mean-field limit of the empirical measure</title>
      <link>https://arxiv.org/abs/2409.06325</link>
      <description>arXiv:2409.06325v3 Announce Type: replace-cross 
Abstract: The dynamics of spatially-structured networks of $N$ interacting stochastic neurons can be described by deterministic population equations in the mean-field limit. While this is known, a general question has remained unanswered: does synaptic weight scaling suffice, by itself, to guarantee the convergence of network dynamics to a deterministic population equation, even when networks are not assumed to be homogeneous or spatially structured? In this work, we consider networks of stochastic integrate-and-fire neurons with arbitrary synaptic weights satisfying a $O(1/N)$ scaling condition. Borrowing results from the theory of dense graph limits, or graphons, we prove that, as $N\to\infty$, and up to the extraction of a subsequence, the empirical measure of the neurons' membrane potentials converges to the solution of a spatially-extended mean-field partial differential equation (PDE). Our proof requires analytical techniques that go beyond standard propagation of chaos methods. In particular, we introduce a weak metric that depends on the dense graph limit kernel and we show how the weak convergence of the initial data can be obtained by propagating the regularity of the limit kernel along the dual-backward equation associated with the spatially-extended mean-field PDE. Overall, this result invites us to reinterpret spatially-extended population equations as universal mean-field limits of networks of neurons with $O(1/N)$ synaptic weight scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06325v3</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pierre-Emmanuel Jabin, Valentin Schmutz, Datong Zhou</dc:creator>
    </item>
  </channel>
</rss>
