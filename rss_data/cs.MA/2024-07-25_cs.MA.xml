<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 04:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 26 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Strategic Pseudo-Goal Perturbation for Deadlock-Free Multi-Agent Navigation in Social Mini-Games</title>
      <link>https://arxiv.org/abs/2407.17766</link>
      <description>arXiv:2407.17766v1 Announce Type: new 
Abstract: This work introduces a Strategic Pseudo-Goal Perturbation (SPGP) technique, a novel approach to resolve deadlock situations in multi-agent navigation scenarios. Leveraging the robust framework of Safety Barrier Certificates, our method integrates a strategic perturbation mechanism that guides agents through social mini-games where deadlock and collision occur frequently. The method adopts a strategic calculation process where agents, upon encountering a deadlock select a pseudo goal within a predefined radius around the current position to resolve the deadlock among agents. The calculation is based on controlled strategic algorithm, ensuring that deviation towards pseudo-goal is both purposeful and effective in resolution of deadlock. Once the agent reaches the pseudo goal, it resumes the path towards the original goal, thereby enhancing navigational efficiency and safety. Experimental results demonstrates SPGP's efficacy in reducing deadlock instances and improving overall system throughput in variety of multi-agent navigation scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17766v1</guid>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Jha, Tanishq Gupta, Sumit Singh Rawat, Girish Kumar</dc:creator>
    </item>
    <item>
      <title>Very Large-Scale Multi-Agent Simulation in AgentScope</title>
      <link>https://arxiv.org/abs/2407.17789</link>
      <description>arXiv:2407.17789v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have opened new avenues for applying multi-agent systems in very large-scale simulations. However, there remain several challenges when conducting multi-agent simulations with existing platforms, such as limited scalability and low efficiency, unsatisfied agent diversity, and effort-intensive management processes. To address these challenges, we develop several new features and components for AgentScope, a user-friendly multi-agent platform, enhancing its convenience and flexibility for supporting very large-scale multi-agent simulations. Specifically, we propose an actor-based distributed mechanism as the underlying technological infrastructure towards great scalability and high efficiency, and provide flexible environment support for simulating various real-world scenarios, which enables parallel execution of multiple agents, centralized workflow orchestration, and both inter-agent and agent-environment interactions among agents. Moreover, we integrate an easy-to-use configurable tool and an automatic background generation pipeline in AgentScope, simplifying the process of creating agents with diverse yet detailed background settings. Last but not least, we provide a web-based interface for conveniently monitoring and managing a large number of agents that might deploy across multiple devices. We conduct a comprehensive simulation to demonstrate the effectiveness of the proposed enhancements in AgentScope, and provide detailed observations and discussions to highlight the great potential of applying multi-agent systems in large-scale simulations. The source code is released on GitHub at https://github.com/modelscope/agentscope to inspire further research and development in large-scale multi-agent simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17789v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuchen Pan, Dawei Gao, Yuexiang Xie, Zhewei Wei, Yaliang Li, Bolin Ding, Ji-Rong Wen, Jingren Zhou</dc:creator>
    </item>
    <item>
      <title>Stochastic Games with Minimally Bounded Action Costs</title>
      <link>https://arxiv.org/abs/2407.18010</link>
      <description>arXiv:2407.18010v1 Announce Type: new 
Abstract: In many multi-player interactions, players incur strictly positive costs each time they execute actions e.g. 'menu costs' or transaction costs in financial systems. Since acting at each available opportunity would accumulate prohibitively large costs, the resulting decision problem is one in which players must make strategic decisions about when to execute actions in addition to their choice of action. This paper analyses a discrete-time stochastic game (SG) in which players face minimally bounded positive costs for each action and influence the system using impulse controls. We prove SGs of two-sided impulse control have a unique value and characterise the saddle point equilibrium in which the players execute actions at strategically chosen times in accordance with Markovian strategies. We prove the game respects a dynamic programming principle and that the Markov perfect equilibrium can be computed as a limit point of a sequence of Bellman operations. We then introduce a new Q-learning variant which we show converges almost surely to the value of the game enabling solutions to be extracted in unknown settings. Lastly, we extend our results to settings with budgetory constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18010v1</guid>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Mguni</dc:creator>
    </item>
    <item>
      <title>Limited Voting for Better Representation?</title>
      <link>https://arxiv.org/abs/2407.17973</link>
      <description>arXiv:2407.17973v1 Announce Type: cross 
Abstract: Limited Voting (LV) is an approval-based method for multi-winner elections where all ballots are required to have a same fixed size. While it appears to be used as voting method in corporate governance and has some political applications, to the best of our knowledge, no formal analysis of the rule exists to date. We provide such an analysis here, prompted by a request for advice about this voting rule by a health insurance company in the Netherlands, which uses it to elect its work council. We study conditions under which LV would improve representation over standard approval voting and when it would not. We establish the extent of such an improvement, or lack thereof, both in terms of diversity and proportionality notions. These results help us understand if, and how, LV may be used as a low-effort fix of approval voting in order to enhance representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17973v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maaike Venema-Los, Zo\'e Christoff, Davide Grossi</dc:creator>
    </item>
    <item>
      <title>Principal-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2407.18074</link>
      <description>arXiv:2407.18074v1 Announce Type: cross 
Abstract: Contracts are the economic framework which allows a principal to delegate a task to an agent -- despite misaligned interests, and even without directly observing the agent's actions. In many modern reinforcement learning settings, self-interested agents learn to perform a multi-stage task delegated to them by a principal. We explore the significant potential of utilizing contracts to incentivize the agents. We model the delegated task as an MDP, and study a stochastic game between the principal and agent where the principal learns what contracts to use, and the agent learns an MDP policy in response. We present a learning-based algorithm for optimizing the principal's contracts, which provably converges to the subgame-perfect equilibrium of the principal-agent game. A deep RL implementation allows us to apply our method to very large MDPs with unknown transition dynamics. We extend our approach to multiple agents, and demonstrate its relevance to resolving a canonical sequential social dilemma with minimal intervention to agent rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18074v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dima Ivanov, Paul D\"utting, Inbal Talgam-Cohen, Tonghan Wang, David C. Parkes</dc:creator>
    </item>
    <item>
      <title>Strategic Cost Selection in Participatory Budgeting</title>
      <link>https://arxiv.org/abs/2407.18092</link>
      <description>arXiv:2407.18092v1 Announce Type: cross 
Abstract: We study strategic behavior of project proposers in the context of approval-based participatory budgeting (PB). In our model we assume that the votes are fixed and known and the proposers want to set as high project prices as possible, provided that their projects get selected and the prices are not below the minimum costs of their delivery. We study the existence of pure Nash equilibria (NE) in such games, focusing on the AV/Cost, Phragm\'en, and Method of Equal Shares rules. Furthermore, we report an experimental study of strategic cost selection on real-life PB election data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18092v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Faliszewski, {\L}ukasz Janeczko, Andrzej Kaczmarczyk, Grzegorz Lisowski, Piotr Skowron, Stanis{\l}aw Szufa</dc:creator>
    </item>
  </channel>
</rss>
