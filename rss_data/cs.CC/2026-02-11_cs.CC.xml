<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 02:49:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improved Parallel Repetition for GHZ-Supported Games via Spreadness</title>
      <link>https://arxiv.org/abs/2602.09290</link>
      <description>arXiv:2602.09290v1 Announce Type: new 
Abstract: We prove that for any 3-player game $\mathcal G$, whose query distribution has the same support as the GHZ game (i.e., all $x,y,z\in \{0,1\}$ satisfying $x+y+z=0\pmod{2}$), the value of the $n$-fold parallel repetition of $\mathcal G$ decays exponentially fast: \[ \text{val}(\mathcal G^{\otimes n}) \leq \exp(-n^c)\] for all sufficiently large $n$, where $c&gt;0$ is an absolute constant.
  We also prove a concentration bound for the parallel repetition of the GHZ game: For any constant $\epsilon&gt;0$, the probability that the players win at least a $\left(\frac{3}{4}+\epsilon\right)$ fraction of the $n$ coordinates is at most $\exp(-n^c)$, where $c=c(\epsilon)&gt;0$ is a constant.
  In both settings, our work exponentially improves upon the previous best known bounds which were only polynomially small, i.e., of the order $n^{-\Omega(1)}$. Our key technical tool is the notion of \emph{algebraic spreadness} adapted from the breakthrough work of Kelley and Meka (FOCS '23) on sets free of 3-term progressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09290v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang P. Liu, Shachar Lovett, Kunal Mittal</dc:creator>
    </item>
    <item>
      <title>A Theory for Probabilistic Polynomial-Time Reasoning</title>
      <link>https://arxiv.org/abs/2602.09302</link>
      <description>arXiv:2602.09302v1 Announce Type: new 
Abstract: In this work, we propose a new bounded arithmetic theory, denoted $APX_1$, designed to formalize a broad class of probabilistic arguments commonly used in theoretical computer science. Under plausible assumptions, $APX_1$ is strictly weaker than previously proposed frameworks, such as the theory $APC_1$ introduced in the seminal work of Jerabek (2007). From a computational standpoint, $APX_1$ is closely tied to approximate counting and to the central question in derandomization, the prBPP versus prP problem, whereas $APC_1$ is linked to the dual weak pigeonhole principle and to the existence of Boolean functions with exponential circuit complexity.
  A key motivation for introducing $APX_1$ is that its weaker axioms expose finer proof-theoretic structure, making it a natural setting for several lines of research, including unprovability of complexity conjectures and reverse mathematics of randomized lower bounds. In particular, the framework we develop for $APX_1$ enables the formulation of precise questions concerning the provability of prBPP=prP in deterministic feasible mathematics. Since the (un)provability of P versus NP in bounded arithmetic has long served as a central theme in the field, we expect this line of investigation to be of particular interest.
  Our technical contributions include developing a comprehensive foundation for probabilistic reasoning from weaker axioms, formalizing non-trivial results from theoretical computer science in $APX_1$, and establishing a tailored witnessing theorem for its provably total TFNP problems. As a byproduct of our analysis of the minimal proof-theoretic strength required to formalize statements arising in theoretical computer science, we resolve an open problem regarding the provability of $AC^0$ lower bounds in $PV_1$, which was considered in earlier works by Razborov (1995), Krajicek (1995), and Muller and Pich (2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09302v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lijie Chen, Jiatu Li, Igor C. Oliveira, Ryan Williams</dc:creator>
    </item>
    <item>
      <title>Higher Hardness Results for the Reconfiguration of Odd Matchings</title>
      <link>https://arxiv.org/abs/2602.09573</link>
      <description>arXiv:2602.09573v1 Announce Type: new 
Abstract: We study the reconfiguration of odd matchings of combinatorial graphs. Odd matchings are matchings that cover all but one vertex of a graph. A reconfiguration step, or flip, is an operation that matches the isolated vertex and, consequently, isolates another vertex. The flip graph of odd matchings is a graph that has all odd matchings of a graph as vertices and an edge between two vertices if their corresponding matchings can be transformed into one another via a single flip. We show that computing the diameter of the flip graph of odd matchings is $\Pi_2^p$-hard. This complements a recent result by Wulf [FOCS25] that it is~$\Pi_2^p$-hard to compute the diameter of the flip graph of perfect matchings where a flip swaps matching edges along a single cycle of unbounded size. Further, we show that computing the radius of the flip graph of odd matchings is $\Sigma_3^p$-hard. The respective decision problems for the diameter and the radius are also complete in the respective level of the polynomial hierarchy. This shows that computing the radius of the flip graph of odd matchings is provably harder than computing its diameter, unless the polynomial hierarchy collapses. Finally, we reduce set cover to the problem of finding shortest flip sequences. As a consequence, we show $\log$-\APX-hardness and that the problem cannot be approximated by a sublogarithmic factor. By doing so, we answer a question asked by Aichholzer, Brenner, Dorfer, Hoang, Perz, Rieck, and Verciani [GD25].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09573v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Dorfer</dc:creator>
    </item>
    <item>
      <title>On the complexity of Sandwich Problems for $M$-partitions</title>
      <link>https://arxiv.org/abs/2602.09576</link>
      <description>arXiv:2602.09576v1 Announce Type: new 
Abstract: We present a structural classification of constraint satisfaction problems (CSP) described by reflexive complete $2$-edge-coloured graphs. In particular, this classification extends the structural dichotomy for graph homomorphism problems known as the Hell--Ne\v{s}et\v{r}il theorem (1990). Our classification is also efficient: we can check in polynomial time whether the CSP of a reflexive complete $2$-edge-coloured graph is in P or NP-complete, whereas for arbitrary $2$-edge-coloured graphs, this task is NP-complete. We then apply our main result in the context of matrix partition problems and sandwich problems. Firstly, we obtain one of the few algorithmic solutions to general classes of matrix partition problems. And secondly, we present a P vs. NP-complete classification of sandwich problems for matrix partitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09576v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexey Barsukov, Santiago Guzm\'an-Pro</dc:creator>
    </item>
    <item>
      <title>The Parameterized Complexity of Geometric 1-Planarity</title>
      <link>https://arxiv.org/abs/2602.09978</link>
      <description>arXiv:2602.09978v1 Announce Type: new 
Abstract: A graph is geometric 1-planar if it admits a straight-line drawing where each edge is crossed at most once. We provide the first systematic study of the parameterized complexity of recognizing geometric 1-planar graphs. By substantially extending a technique of Bannister, Cabello, and Eppstein, combined with Thomassen's characterization of 1-planar embeddings that can be straightened, we show that the problem is fixed-parameter tractable when parameterized by treedepth. Furthermore, we obtain a kernel for Geometric 1-Planarity parameterized by the feedback edge number $\ell$. As a by-product, we improve the best known kernel size of $O((3\ell)!)$ for 1-Planarity and $k$-Planarity under the same parameterization to $O(\ell \cdot 8^{\ell})$. Our approach naturally extends to Geometric $k$-Planarity, yielding a kernelization under the same parameterization, albeit with a larger kernel. Complementing these results, we provide matching lower bounds: Geometric 1-Planarity remains \NP-complete even for graphs of bounded pathwidth, bounded feedback vertex number, and bounded bandwidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09978v1</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Firbas</dc:creator>
    </item>
    <item>
      <title>Optimal PRGs for Low-Degree Polynomials over Polynomial-Size Fields</title>
      <link>https://arxiv.org/abs/2602.10030</link>
      <description>arXiv:2602.10030v1 Announce Type: new 
Abstract: Pseudorandom generators (PRGs) for low-degree polynomials are a central object in pseudorandomness, with applications to circuit lower bounds and derandomization. Viola's celebrated construction gives a PRG over the binary field, but with seed length exponential in the degree $d$. This exponential dependence can be avoided over sufficiently large fields. In particular, Dwivedi, Guo, and Volk constructed PRGs with optimal seed length over fields of size exponential in $d$. The latter builds on the framework of Derksen and Viola, who obtained optimal-seed constructions over fields of size polynomial in $d$, although growing with the number of variables $n$.
  In this work, we construct the first PRG with optimal seed length for degree-$d$ polynomials over fields of polynomial size, specifically $q \approx d^4$, assuming sufficiently large characteristic. Our construction follows the framework of prior work and reduces the required field size by replacing the hitting-set generator used in previous constructions with a new pseudorandom object.
  We also observe a threshold phenomenon in the field-size dependence. Specifically, we prove that constructing PRGs over fields of sublinear size, for example $q = d^{0.99}$ where $q$ is a power of two, would already yield PRGs for the binary field with comparable seed length via our reduction, provided that the construction imposes no restriction on the characteristic. While a breakdown of existing techniques has been noted before, we prove that this phenomenon is inherent to the problem itself, irrespective of the technique used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10030v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gil Cohen, Dean Doron, Noam Goldgraber</dc:creator>
    </item>
    <item>
      <title>Some conditions implying if P=NP then P=PSPACE</title>
      <link>https://arxiv.org/abs/2602.10073</link>
      <description>arXiv:2602.10073v1 Announce Type: new 
Abstract: We identify a few conditions $X$ such that $(P=NP \wedge X) \;\Rightarrow\; P=PSPACE$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10073v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ismael Rodriguez</dc:creator>
    </item>
    <item>
      <title>Separating Quantum and Classical Advice with Good Codes</title>
      <link>https://arxiv.org/abs/2602.09385</link>
      <description>arXiv:2602.09385v1 Announce Type: cross 
Abstract: We show an unconditional classical oracle separation between the class of languages that can be verified using a quantum proof ($\mathsf{QMA}$) and the class of languages that can be verified with a classical proof ($\mathsf{QCMA}$). Compared to the recent work of Bostanci, Haferkamp, Nirkhe, and Zhandry (STOC 2026), our proof is conceptually and technically simpler, and readily extends to other oracle separations. In particular, our techniques yield the first unconditional classical oracle separation between the class of languages that can be decided with quantum advice ($\mathsf{BQP}/\mathsf{qpoly}$) and the class of languages that can be decided with classical advice ($\mathsf{BQP}/\mathsf{poly}$), improving on the quantum oracle separation of Aaronson and Kuperberg (CCC 2007) and the classically-accessible classical oracle separation of Li, Liu, Pelecanos and Yamakawa (ITCS 2024).
  Our oracles are based on the code intersection problem introduced by Yamakawa and Zhandry (FOCS 2022), combined with codes that have extremely good list-recovery properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09385v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Bostanci, Andrew Huang, Vinod Vaikuntanathan</dc:creator>
    </item>
    <item>
      <title>A Minimal Substitution Basis for the Kalm\'ar Elementary Functions</title>
      <link>https://arxiv.org/abs/2505.23787</link>
      <description>arXiv:2505.23787v5 Announce Type: replace-cross 
Abstract: We show that the class of Kalm\'ar elementary functions can be inductively generated from the addition, the integer remainder, and the base-two exponentiation, hence improving previous results by Marchenkov and Mazzanti. We also prove that the substitution basis defined by these three operations is minimal. Furthermore, we discuss alternative substitution bases under arity constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23787v5</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mihai Prunescu, Lorenzo Sauras-Altuzarra, Joseph M. Shunia</dc:creator>
    </item>
    <item>
      <title>On the undecidability of quantum channel capacities</title>
      <link>https://arxiv.org/abs/2601.22471</link>
      <description>arXiv:2601.22471v2 Announce Type: replace-cross 
Abstract: An important distinction in our understanding of capacities of classical versus quantum channels is marked by the following question: is there an algorithm which can compute (or even efficiently compute) the capacity? While there is overwhelming evidence suggesting that quantum channel capacities may be uncomputable, a formal proof of any such statement is elusive. We initiate the study of the hardness of computing quantum channel capacities. We show that, for a general quantum channel, it is QMA-hard to compute its quantum capacity, and that the maximal-entanglement-assisted zero-error one-shot classical capacity is uncomputable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22471v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Archishna Bhattacharyya, Arthur Mehta, Yuming Zhao</dc:creator>
    </item>
  </channel>
</rss>
