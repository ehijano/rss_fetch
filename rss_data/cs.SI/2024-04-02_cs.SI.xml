<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Apr 2024 04:00:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Information Cascade Prediction under Public Emergencies: A Survey</title>
      <link>https://arxiv.org/abs/2404.01319</link>
      <description>arXiv:2404.01319v1 Announce Type: new 
Abstract: With the advent of the era of big data, massive information, expert experience, and high-accuracy models bring great opportunities to the information cascade prediction of public emergencies. However, the involvement of specialist knowledge from various disciplines has resulted in a primarily application-specific focus (e.g., earthquakes, floods, infectious diseases) for information cascade prediction of public emergencies. The lack of a unified prediction framework poses a challenge for classifying intersectional prediction methods across different application fields. This survey paper offers a systematic classification and summary of information cascade modeling, prediction, and application. We aim to help researchers identify cutting-edge research and comprehend models and methods of information cascade prediction under public emergencies. By summarizing open issues and outlining future directions in this field, this paper has the potential to be a valuable resource for researchers conducting further studies on predicting information cascades.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01319v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Zhang, Guang Wang, Li Lin, Kaiwen Xia, Shuai Wang</dc:creator>
    </item>
    <item>
      <title>Graph-Based Optimisation of Network Expansion in a Dockless Bike Sharing System</title>
      <link>https://arxiv.org/abs/2404.01320</link>
      <description>arXiv:2404.01320v1 Announce Type: new 
Abstract: Bike-sharing systems (BSSs) are deployed in over a thousand cities worldwide and play an important role in many urban transportation systems. BSSs alleviate congestion, reduce pollution and promote physical exercise. It is essential to explore the spatiotemporal patterns of bike-sharing demand, as well as the factors that influence these patterns, in order to optimise system operational efficiency. In this study, an optimised geo-temporal graph is constructed using trip data from Moby Bikes, a dockless BSS operator. The process of optimising the graph unveiled prime locations for erecting new stations during future expansions of the BSS. The Louvain algorithm, a community detection technique, is employed to uncover usage patterns at different levels of temporal granularity. The community detection results reveal largely self-contained sub-networks that exhibit similar usage patterns at their respective levels of temporal granularity. Overall, this study reinforces that BSSs are intrinsically spatiotemporal systems, with community presence driven by spatiotemporal dynamics. These findings may aid operators in improving redistribution efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01320v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mark Roantree, Niamh Murphi, Dinh Viet Cuong, Vuong Minh Ngo</dc:creator>
    </item>
    <item>
      <title>WhatsApp Explorer: A Data Donation Tool To Facilitate Research on WhatsApp</title>
      <link>https://arxiv.org/abs/2404.01328</link>
      <description>arXiv:2404.01328v1 Announce Type: new 
Abstract: In recent years, reports and anecdotal evidence pointing at the role of WhatsApp in a variety of events, ranging from elections to collective violence, have emerged. While academic research should examine the validity of these claims, obtaining WhatsApp data for research is notably challenging, contrasting with the relative abundance of data from platforms like Facebook and Twitter, where user "information diets" have been extensively studied. This lack of data is particularly problematic since misinformation and hate speech are major concerns in the set of Global South countries in which WhatsApp dominates the market for messaging. To help make research on these questions, and more generally research on WhatsApp, possible, this paper introduces WhatsApp Explorer, a tool designed to enable WhatsApp data collection on a large scale. We discuss protocols for data collection, including potential sampling approaches, and explain why our tool (and adjoining protocol) arguably allow researchers to collect WhatsApp data in an ethical and legal manner, at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01328v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiran Garimella, Simon Chauchard</dc:creator>
    </item>
    <item>
      <title>Unraveling the Dynamics of Television Debates and Social Media Engagement: Insights from an Indian News Show</title>
      <link>https://arxiv.org/abs/2404.01329</link>
      <description>arXiv:2404.01329v1 Announce Type: new 
Abstract: The relationship between television shows and social media has become increasingly intertwined in recent years. Social media platforms, particularly Twitter, have emerged as significant sources of public opinion and discourse on topics discussed in television shows. In India, news debates leverage the popularity of social media to promote hashtags and engage users in discussions and debates on a daily basis.
  This paper focuses on the analysis of one of India's most prominent and widely-watched TV news debate shows: "Arnab Goswami-The Debate". The study examines the content of the show by analyzing the hashtags used to promote it and the social media data corresponding to these hashtags. The findings reveal that the show exhibits a strong bias towards the ruling Bharatiya Janata Party (BJP), with over 60% of the debates featuring either pro-BJP or anti-opposition content. Social media support for the show primarily comes from BJP supporters. Notably, BJP leaders and influencers play a significant role in promoting the show on social media, leveraging their existing networks and resources to artificially trend specific hashtags. Furthermore, the study uncovers a reciprocal flow of information between the TV show and social media. We find evidence that the show's choice of topics is linked to social media posts made by party workers, suggesting a dynamic interplay between traditional media and online platforms.
  By exploring the complex interaction between television debates and social media support, this study contributes to a deeper understanding of the evolving relationship between these two domains in the digital age. The findings hold implications for media researchers and practitioners, offering insights into the ways in which social media can influence traditional media and vice versa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01329v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiran Garimella, Abhilash Datta</dc:creator>
    </item>
    <item>
      <title>Transnational Network Dynamics of Problematic Information Diffusion</title>
      <link>https://arxiv.org/abs/2404.01467</link>
      <description>arXiv:2404.01467v1 Announce Type: new 
Abstract: This study maps the spread of two cases of COVID-19 conspiracy theories and misinformation in Spanish and French in Latin American and French-speaking communities on Facebook, and thus contributes to understanding the dynamics, reach and consequences of emerging transnational misinformation networks. The findings show that co-sharing behavior of public Facebook groups created transnational networks by sharing videos of Medicos por la Verdad (MPV) conspiracy theories in Spanish and hydroxychloroquine-related misinformation sparked by microbiologist Didier Raoult (DR) in French, usually igniting the surge of locally led interest groups across the Global South. Using inferential methods, the study shows how these networks are enabled primarily by shared cultural and thematic attributes among Facebook groups, effectively creating very large, networked audiences. The study contributes to the understanding of how potentially harmful conspiracy theories and misinformation transcend national borders through non-English speaking online communities, further highlighting the overlooked role of transnationalism in global misinformation diffusion and the potentially disproportionate harm that it causes in vulnerable communities across the globe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01467v1</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esteban Villa-Turek, Rod Abhari, Erik C. Nisbet, Yu Xu, Ayse Deniz Lokmanoglu</dc:creator>
    </item>
    <item>
      <title>Fear over Friends: Examining the Perceived Influence of Others on Vaccination Decisions</title>
      <link>https://arxiv.org/abs/2404.01489</link>
      <description>arXiv:2404.01489v1 Announce Type: new 
Abstract: In this study, we examine the perceived influence of others, across both strong and weak social ties, on vaccination decisions in the United States. In particular, we focus on the case study of COVID-19 vaccinations. We add context to social influence by measuring related concepts, such as perceived agreement of others and perceived danger of COVID-19 to others. We find that vaccinated populations perceived more influence from their social circles than unvaccinated populations. This finding holds true across various social groups, including family, close friends, co-workers, and neighbors. Indirect measures of social influence also followed this trend. Vaccinated participants perceived COVID-19 as more dangerous to their social circles than unvaccinated participants and perceived that others agreed with their decision to get vaccinated more than unvaccinated participants perceived others to agree with their decision to not get vaccinated. Despite the clear differences in perceived social influence across the groups, we find through open-ended responses that both vaccinated and unvaccinated participants frequently cited fear as a motivating factor in their decision, rather than social influence: vaccinated participants feared COVID-19, while unvaccinated participants feared the vaccine itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01489v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denise Yewell, R. Alexander Bentley, Benjamin D. Horne</dc:creator>
    </item>
    <item>
      <title>How COVID-19 has Impacted the Anti-Vaccine Discourse: A Large-Scale Twitter Study Spanning Pre-COVID and Post-COVID Era</title>
      <link>https://arxiv.org/abs/2404.01669</link>
      <description>arXiv:2404.01669v1 Announce Type: new 
Abstract: The debate around vaccines has been going on for decades, but the COVID-19 pandemic showed how crucial it is to understand and mitigate anti-vaccine sentiments. While the pandemic may be over, it is still important to understand how the pandemic affected the anti-vaccine discourse, and whether the arguments against non-COVID vaccines (e.g., Flu, MMR, IPV, HPV vaccines) have also changed due to the pandemic. This study attempts to answer these questions through a large-scale study of anti-vaccine posts on Twitter. Almost all prior works that utilized social media to understand anti-vaccine opinions considered only the three broad stances of Anti-Vax, Pro-Vax, and Neutral. There has not been any effort to identify the specific reasons/concerns behind the anti-vax sentiments (e.g., side-effects, conspiracy theories, political reasons) on social media at scale. In this work, we propose two novel methods for classifying tweets into 11 different anti-vax concerns -- a discriminative approach (entailment-based) and a generative approach (based on instruction tuning of LLMs) -- which outperform several strong baselines. We then apply this classifier on anti-vaccine tweets posted over a 5-year period (Jan 2018 - Jan 2023) to understand how the COVID-19 pandemic has impacted the anti-vaccine concerns among the masses. We find that the pandemic has made the anti-vaccine discourse far more complex than in the pre-COVID times, and increased the variety of concerns being voiced. Alarmingly, we find that concerns about COVID vaccines are now being projected onto the non-COVID vaccines, thus making more people hesitant in taking vaccines in the post-COVID era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01669v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soham Poddar, Rajdeep Mukherjee, Subhendu Khatuya, Niloy Ganguly, Saptarshi Ghosh</dc:creator>
    </item>
    <item>
      <title>The Effects of Group Sanctions on Participation and Toxicity: Quasi-experimental Evidence from the Fediverse</title>
      <link>https://arxiv.org/abs/2404.02109</link>
      <description>arXiv:2404.02109v1 Announce Type: new 
Abstract: Online communities often overlap and coexist, despite incongruent norms and approaches to content moderation. When communities diverge, decentralized and federated communities may pursue group-level sanctions, including defederation (disconnection) to block communication between members of specific communities. We investigate the effects of defederation in the context of the Fediverse, a set of decentralized, interconnected social networks with independent governance. Mastodon and Pleroma, the most popular software powering the Fediverse, allow administrators on one server to defederate from another. We use a difference-in-differences approach and matched controls to estimate the effects of defederation events on participation and message toxicity among affected members of the blocked and blocking servers. We find that defederation causes a drop in activity for accounts on the blocked servers, but not on the blocking servers. Also, we find no evidence of an effect of defederation on message toxicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02109v1</guid>
      <category>cs.SI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carl Colglazier, Nathan TeBlunthuis, Aaron Shaw</dc:creator>
    </item>
    <item>
      <title>Utilizing AI and Social Media Analytics to Discover Adverse Side Effects of GLP-1 Receptor Agonists</title>
      <link>https://arxiv.org/abs/2404.01358</link>
      <description>arXiv:2404.01358v1 Announce Type: cross 
Abstract: Adverse side effects (ASEs) of drugs, revealed after FDA approval, pose a threat to patient safety. To promptly detect overlooked ASEs, we developed a digital health methodology capable of analyzing massive public data from social media, published clinical research, manufacturers' reports, and ChatGPT. We uncovered ASEs associated with the glucagon-like peptide 1 receptor agonists (GLP-1 RA), a market expected to grow exponentially to $133.5 billion USD by 2030. Using a Named Entity Recognition (NER) model, our method successfully detected 21 potential ASEs overlooked upon FDA approval, including irritability and numbness. Our data-analytic approach revolutionizes the detection of unreported ASEs associated with newly deployed drugs, leveraging cutting-edge AI-driven social media analytics. It can increase the safety of new drugs in the marketplace by unlocking the power of social media to support regulators and manufacturers in the rapid discovery of hidden ASE risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01358v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alon Bartal, Kathleen M. Jagodnik, Nava Pliskin, Abraham Seidmann</dc:creator>
    </item>
    <item>
      <title>GLEMOS: Benchmark for Instantaneous Graph Learning Model Selection</title>
      <link>https://arxiv.org/abs/2404.01578</link>
      <description>arXiv:2404.01578v1 Announce Type: cross 
Abstract: The choice of a graph learning (GL) model (i.e., a GL algorithm and its hyperparameter settings) has a significant impact on the performance of downstream tasks. However, selecting the right GL model becomes increasingly difficult and time consuming as more and more GL models are developed. Accordingly, it is of great significance and practical value to equip users of GL with the ability to perform a near-instantaneous selection of an effective GL model without manual intervention. Despite the recent attempts to tackle this important problem, there has been no comprehensive benchmark environment to evaluate the performance of GL model selection methods. To bridge this gap, we present GLEMOS in this work, a comprehensive benchmark for instantaneous GL model selection that makes the following contributions. (i) GLEMOS provides extensive benchmark data for fundamental GL tasks, i.e., link prediction and node classification, including the performances of 366 models on 457 graphs on these tasks. (ii) GLEMOS designs multiple evaluation settings, and assesses how effectively representative model selection techniques perform in these different settings. (iii) GLEMOS is designed to be easily extended with new models, new graphs, and new performance records. (iv) Based on the experimental results, we discuss the limitations of existing approaches and highlight future research directions. To promote research on this significant problem, we make the benchmark data and code publicly available at https://github.com/facebookresearch/glemos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01578v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Namyong Park, Ryan Rossi, Xing Wang, Antoine Simoulin, Nesreen Ahmed, Christos Faloutsos</dc:creator>
    </item>
    <item>
      <title>NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but Teaching the Distinction Helps</title>
      <link>https://arxiv.org/abs/2404.01651</link>
      <description>arXiv:2404.01651v1 Announce Type: cross 
Abstract: The use of words to convey speaker's intent is traditionally distinguished from the `mention' of words for quoting what someone said, or pointing out properties of a word. Here we show that computationally modeling this use-mention distinction is crucial for dealing with counterspeech online. Counterspeech that refutes problematic content often mentions harmful language but is not harmful itself (e.g., calling a vaccine dangerous is not the same as expressing disapproval of someone for calling vaccines dangerous). We show that even recent language models fail at distinguishing use from mention, and that this failure propagates to two key downstream tasks: misinformation and hate speech detection, resulting in censorship of counterspeech. We introduce prompting mitigations that teach the use-mention distinction, and show they reduce these errors. Our work highlights the importance of the use-mention distinction for NLP and CSS and offers ways to address it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01651v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristina Gligoric, Myra Cheng, Lucia Zheng, Esin Durmus, Dan Jurafsky</dc:creator>
    </item>
    <item>
      <title>Event Detection from Social Media for Epidemic Prediction</title>
      <link>https://arxiv.org/abs/2404.01679</link>
      <description>arXiv:2404.01679v1 Announce Type: cross 
Abstract: Social media is an easy-to-access platform providing timely updates about societal trends and events. Discussions regarding epidemic-related events such as infections, symptoms, and social interactions can be crucial for informing policymaking during epidemic outbreaks. In our work, we pioneer exploiting Event Detection (ED) for better preparedness and early warnings of any upcoming epidemic by developing a framework to extract and analyze epidemic-related events from social media posts. To this end, we curate an epidemic event ontology comprising seven disease-agnostic event types and construct a Twitter dataset SPEED with human-annotated events focused on the COVID-19 pandemic. Experimentation reveals how ED models trained on COVID-based SPEED can effectively detect epidemic events for three unseen epidemics of Monkeypox, Zika, and Dengue; while models trained on existing ED datasets fail miserably. Furthermore, we show that reporting sharp increases in the extracted events by our framework can provide warnings 4-9 weeks earlier than the WHO epidemic declaration for Monkeypox. This utility of our framework lays the foundations for better preparedness against emerging epidemics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01679v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanmay Parekh, Anh Mac, Jiarui Yu, Yuxuan Dong, Syed Shahriar, Bonnie Liu, Eric Yang, Kuan-Hao Huang, Wei Wang, Nanyun Peng, Kai-Wei Chang</dc:creator>
    </item>
    <item>
      <title>A (More) Realistic Evaluation Setup for Generalisation of Community Models on Malicious Content Detection</title>
      <link>https://arxiv.org/abs/2404.01822</link>
      <description>arXiv:2404.01822v1 Announce Type: cross 
Abstract: Community models for malicious content detection, which take into account the context from a social graph alongside the content itself, have shown remarkable performance on benchmark datasets. Yet, misinformation and hate speech continue to propagate on social media networks. This mismatch can be partially attributed to the limitations of current evaluation setups that neglect the rapid evolution of online content and the underlying social graph. In this paper, we propose a novel evaluation setup for model generalisation based on our few-shot subgraph sampling approach. This setup tests for generalisation through few labelled examples in local explorations of a larger graph, emulating more realistic application settings. We show this to be a challenging inductive setup, wherein strong performance on the training graph is not indicative of performance on unseen tasks, domains, or graph structures. Lastly, we show that graph meta-learners trained with our proposed few-shot subgraph sampling outperform standard community models in the inductive setup. We make our code publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01822v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivo Verhoeven, Pushkar Mishra, Rahel Beloch, Helen Yannakoudakis, Ekaterina Shutova</dc:creator>
    </item>
    <item>
      <title>Calibrate-Extrapolate: Rethinking Prevalence Estimation with Black Box Classifiers</title>
      <link>https://arxiv.org/abs/2401.09329</link>
      <description>arXiv:2401.09329v2 Announce Type: replace 
Abstract: In computational social science, researchers often use a pre-trained, black box classifier to estimate the frequency of each class in unlabeled datasets. A variety of prevalence estimation techniques have been developed in the literature, each yielding an unbiased estimate if certain stability assumption holds. This work introduces a framework to rethink the prevalence estimation process as calibrating the classifier outputs against ground truth labels to obtain the joint distribution of a base dataset and then extrapolating to the joint distribution of a target dataset. We call this framework "Calibrate-Extrapolate". It clarifies what stability assumptions must hold for a prevalence estimation technique to yield accurate estimates. In the calibration phase, the techniques assume only a stable calibration curve between a calibration dataset and the full base dataset. This allows for the classifier outputs to be used for disproportionate random sampling, thus improving the efficiency of calibration. In the extrapolation phase, some techniques assume a stable calibration curve while some assume stable class-conditional densities. We discuss the stability assumptions from a causal perspective. By specifying base and target joint distributions, we can generate simulated datasets, as a way to build intuitions about the impacts of assumption violations. This also leads to a better understanding of how the classifier's predictive power affects the accuracy of prevalence estimates: the greater the predictive power, the lower the sensitivity to violations of stability assumptions in the extrapolation phase. We illustrate the framework with an application that estimates the prevalence of toxic comments on news topics over time on Reddit, Twitter/X, and YouTube, using Jigsaw's Perspective API as a black box classifier. Finally, we summarize several practical advice for prevalence estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09329v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siqi Wu, Paul Resnick</dc:creator>
    </item>
    <item>
      <title>Assembling a Multi-Platform Ensemble Social Bot Detector with Applications to US 2020 Elections</title>
      <link>https://arxiv.org/abs/2401.14607</link>
      <description>arXiv:2401.14607v2 Announce Type: replace 
Abstract: Bots have been in the spotlight for many social media studies, for they have been observed to be participating in the manipulation of information and opinions on social media. These studies analyzed the activity and influence of bots in a variety of contexts: elections, protests, health communication and so forth. Prior to this analyses is the identification of bot accounts to segregate the class of social media users. In this work, we propose an ensemble method for bot detection, designing a multi-platform bot detection architecture to handle several problems along the bot detection pipeline: incomplete data input, minimal feature engineering, optimized classifiers for each data field, and also eliminate the need for a threshold value for classification determination. With these design decisions, we generalize our bot detection framework across Twitter, Reddit and Instagram. We also perform feature importance analysis, observing that the entropy of names and number of interactions (retweets/shares) are important factors in bot determination. Finally, we apply our multi-platform bot detector to the US 2020 presidential elections to identify and analyze bot activity across multiple social media platforms, showcasing the difference in online discourse of bots from different platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14607v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lynnette Hui Xian Ng, Kathleen M. Carley</dc:creator>
    </item>
    <item>
      <title>Nonparametric inference of higher order interaction patterns in networks</title>
      <link>https://arxiv.org/abs/2403.15635</link>
      <description>arXiv:2403.15635v2 Announce Type: replace 
Abstract: We propose a method for obtaining parsimonious decompositions of networks into higher order interactions which can take the form of arbitrary motifs.The method is based on a class of analytically solvable generative models, where vertices are connected via explicit copies of motifs, which in combination with non-parametric priors allow us to infer higher order interactions from dyadic graph data without any prior knowledge on the types or frequencies of such interactions. Crucially, we also consider 'degree--corrected' models that correctly reflect the degree distribution of the network and consequently prove to be a better fit for many real world--networks compared to non-degree corrected models. We test the presented approach on simulated data for which we recover the set of underlying higher order interactions to a high degree of accuracy. For empirical networks the method identifies concise sets of atomic subgraphs from within thousands of candidates that cover a large fraction of edges and include higher order interactions of known structural and functional significance. The method not only produces an explicit higher order representation of the network but also a fit of the network to analytically tractable models opening new avenues for the systematic study of higher order network structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15635v2</guid>
      <category>cs.SI</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.soc-ph</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anatol E. Wegner, Sofia C. Olhede</dc:creator>
    </item>
    <item>
      <title>Modularity and partially observed graphs</title>
      <link>https://arxiv.org/abs/2112.13190</link>
      <description>arXiv:2112.13190v2 Announce Type: replace-cross 
Abstract: Suppose that there is an unknown underlying graph $G$ on a large vertex set, and we can test only a proportion of the possible edges to check whether they are present in $G$. If $G$ has high modularity, is the observed graph $G'$ likely to have high modularity? We see that this is indeed the case under a mild condition, in a natural model where we test edges at random. We find that $q^*(G') \geq q^*(G)-\varepsilon$ with probability at least $1-\varepsilon$, as long as the expected number edges in $G'$ is large enough. Similarly, $q^*(G') \leq q^*(G)+\varepsilon$ with probability at least $1-\varepsilon$, under the stronger condition that the expected average degree in $G'$ is large enough. Further, under this stronger condition, finding a good partition for $G'$ helps us to find a good partition for $G$.
  We also consider the vertex sampling model for partially observing the underlying graph: we find that for dense underlying graphs we may estimate the modularity by sampling constantly many vertices and observing the corresponding induced subgraph, but this does not hold for underlying graphs with a subquadratic number of edges. Finally we deduce some related results, for example showing that under-sampling tends to lead to overestimation of modularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.13190v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colin McDiarmid, Fiona Skerman</dc:creator>
    </item>
    <item>
      <title>GIDN: A Lightweight Graph Inception Diffusion Network for High-efficient Link Prediction</title>
      <link>https://arxiv.org/abs/2210.01301</link>
      <description>arXiv:2210.01301v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a Graph Inception Diffusion Networks(GIDN) model. This model generalizes graph diffusion in different feature spaces, and uses the inception module to avoid the large amount of computations caused by complex network structures. We evaluate GIDN model on Open Graph Benchmark(OGB) datasets, reached an 11% higher performance than AGDN on ogbl-collab dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.01301v3</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixiao Wang, Yuluo Guo, Jin Zhao, Yu Zhang, Hui Yu, Xiaofei Liao, Biao Wang, Ting Yu</dc:creator>
    </item>
    <item>
      <title>The temporal dynamics of group interactions in higher-order social networks</title>
      <link>https://arxiv.org/abs/2306.09967</link>
      <description>arXiv:2306.09967v2 Announce Type: replace-cross 
Abstract: Representing social systems as networks, starting from the interactions between individuals, sheds light on the mechanisms governing their dynamics. However, networks encode only pairwise interactions, while most social interactions occur among groups of individuals, requiring higher-order network representations. Despite the recent interest in higher-order networks, little is known about the mechanisms that govern the formation and evolution of groups, and how people move between groups. Here, we leverage empirical data on social interactions among children and university students to study their temporal dynamics at both individual and group levels, characterising how individuals navigate groups and how groups form and disaggregate. We find robust patterns across contexts and propose a dynamical model that closely reproduces empirical observations. These results represent a further step in understanding social systems, and open up research directions to study the impact of group dynamics on dynamical processes that evolve on top of them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09967v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iacopo Iacopini, M\'arton Karsai, Alain Barrat</dc:creator>
    </item>
    <item>
      <title>How to Train Your YouTube Recommender to Avoid Unwanted Videos</title>
      <link>https://arxiv.org/abs/2307.14551</link>
      <description>arXiv:2307.14551v3 Announce Type: replace-cross 
Abstract: YouTube provides features for users to indicate disinterest when presented with unwanted recommendations, such as the "Not interested" and "Don't recommend channel" buttons. These buttons purportedly allow the user to correct "mistakes" made by the recommendation system. Yet, relatively little is known about the empirical efficacy of these buttons. Neither is much known about users' awareness of and confidence in them. To address these gaps, we simulated YouTube users with sock puppet agents. Each agent first executed a "stain phase", where it watched many videos of an assigned topic; it then executed a "scrub phase", where it tried to remove recommendations from the assigned topic. Each agent repeatedly applied a single scrubbing strategy, either indicating disinterest in one of the videos visited in the stain phase (disliking it or deleting it from the watch history), or indicating disinterest in a video recommended on the homepage (clicking the "not interested" or "don't recommend channel" button or opening the video and clicking the dislike button). We found that the stain phase significantly increased the fraction of the recommended videos dedicated to the assigned topic on the user's homepage. For the scrub phase, using the "Not interested" button worked best, significantly reducing such recommendations in all topics tested, on average removing 88% of them. Neither the stain phase nor the scrub phase, however, had much effect on videopage recommendations. We also ran a survey (N = 300) asking adult YouTube users in the US whether they were aware of and used these buttons before, as well as how effective they found these buttons to be. We found that 44% of participants were not aware that the "Not interested" button existed. Those who were aware of it often used it to remove unwanted recommendations (82.8%) and found it to be modestly effective (3.42 out of 5).</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14551v3</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Liu, Siqi Wu, Paul Resnick</dc:creator>
    </item>
    <item>
      <title>Navigating the Post-API Dilemma | Search Engine Results Pages Present a Biased View of Social Media Data</title>
      <link>https://arxiv.org/abs/2401.15479</link>
      <description>arXiv:2401.15479v3 Announce Type: replace-cross 
Abstract: Recent decisions to discontinue access to social media APIs are having detrimental effects on Internet research and the field of computational social science as a whole. This lack of access to data has been dubbed the Post-API era of Internet research. Fortunately, popular search engines have the means to crawl, capture, and surface social media data on their Search Engine Results Pages (SERP) if provided the proper search query, and may provide a solution to this dilemma. In the present work we ask: does SERP provide a complete and unbiased sample of social media data? Is SERP a viable alternative to direct API-access? To answer these questions, we perform a comparative analysis between (Google) SERP results and nonsampled data from Reddit and Twitter/X. We find that SERP results are highly biased in favor of popular posts; against political, pornographic, and vulgar posts; are more positive in their sentiment; and have large topical gaps. Overall, we conclude that SERP is not a viable alternative to social media API access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15479v3</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amrit Poudel, Tim Weninger</dc:creator>
    </item>
  </channel>
</rss>
