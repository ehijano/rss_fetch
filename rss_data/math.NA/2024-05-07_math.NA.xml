<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 May 2024 04:00:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Active flux methods for hyperbolic conservation laws -- flux vector splitting and bound-preservation: One-dimensional case</title>
      <link>https://arxiv.org/abs/2405.02447</link>
      <description>arXiv:2405.02447v1 Announce Type: new 
Abstract: The active flux (AF) method is a compact high-order finite volume method that evolves cell averages and point values at cell interfaces independently. Within the method of lines framework, the point value can be updated based on Jacobian splitting (JS), incorporating the upwind idea. However, such JS-based AF methods encounter transonic issues for nonlinear problems due to inaccurate upwind direction estimation. This paper proposes to use flux vector splitting for the point value update, offering a natural and uniform remedy to the transonic issue. To improve robustness, this paper also develops bound-preserving (BP) AF methods for one-dimensional hyperbolic conservation laws. Two cases are considered: preservation of the maximum principle for the scalar case, and preservation of positive density and pressure for the compressible Euler equations. The update of the cell average in high-order AF methods is rewritten as a convex combination of using the original high-order fluxes and robust low-order (local Lax-Friedrichs or Rusanov) fluxes, and the desired bounds are enforced by choosing the right amount of low-order fluxes. A similar blending strategy is used for the point value update. Several challenging benchmark tests are conducted to verify the accuracy, BP properties, and shock-capturing ability of the methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02447v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junming Duan, Wasilij Barsukow, Christian Klingenberg</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of a second order numerical scheme for the Flory-Huggins-Cahn-Hilliard-Navier-Stokes system</title>
      <link>https://arxiv.org/abs/2405.02616</link>
      <description>arXiv:2405.02616v1 Announce Type: new 
Abstract: We present an optimal rate convergence analysis for a second order accurate in time, fully discrete finite difference scheme for the Cahn-Hilliard-Navier-Stokes (CHNS) system, combined with logarithmic Flory-Huggins energy potential. The numerical scheme has been recently proposed, and the positivity-preserving property of the logarithmic arguments, as well as the total energy stability, have been theoretically justified. In this paper, we rigorously prove second order convergence of the proposed numerical scheme, in both time and space. Since the CHNS is a coupled system, the standard $\ell^\infty (0, T; \ell^2) \cap \ell^2 (0, T; H_h^2)$ error estimate could not be easily derived, due to the lack of regularity to control the numerical error associated with the coupled terms. Instead, the $\ell^\infty (0, T; H_h^1) \cap \ell^2 (0, T; H_h^3)$ error analysis for the phase variable and the $\ell^\infty (0, T; \ell^2)$ analysis for the velocity vector, which shares the same regularity as the energy estimate, is more suitable to pass through the nonlinear analysis for the error terms associated with the coupled physical process. Furthermore, the highly nonlinear and singular nature of the logarithmic error terms makes the convergence analysis even more challenging, since a uniform distance between the numerical solution and the singular limit values of is needed for the associated error estimate. Many highly non-standard estimates, such as a higher order asymptotic expansion of the numerical solution (up to the third order accuracy in time and fourth order in space), combined with a rough error estimate (to establish the maximum norm bound for the phase variable), as well as a refined error estimate, have to be carried out to conclude the desired convergence result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02616v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbin Chen, Jianyu Jing, Qianqian Liu, Cheng Wang, Xiaoming Wang</dc:creator>
    </item>
    <item>
      <title>Adaptive deep density approximation for stochastic dynamical systems</title>
      <link>https://arxiv.org/abs/2405.02810</link>
      <description>arXiv:2405.02810v1 Announce Type: new 
Abstract: In this paper we consider adaptive deep neural network approximation for stochastic dynamical systems. Based on the Liouville equation associated with the stochastic dynamical systems, a new temporal KRnet (tKRnet) is proposed to approximate the probability density functions (PDFs) of the state variables. The tKRnet gives an explicit density model for the solution of the Liouville equation, which alleviates the curse of dimensionality issue that limits the application of traditional grid based numerical methods. To efficiently train the tKRnet, an adaptive procedure is developed to generate collocation points for the corresponding residual loss function, where samples are generated iteratively using the approximate density function at each iteration. A temporal decomposition technique is also employed to improve the long-time integration. Theoretical analysis of our proposed method is provided, and numerical examples are presented to demonstrate its performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02810v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Junjie He, Qifeng Liao, Xiaoliang Wan</dc:creator>
    </item>
    <item>
      <title>The weighted and shifted seven-step BDF method for parabolic equations</title>
      <link>https://arxiv.org/abs/2405.02872</link>
      <description>arXiv:2405.02872v1 Announce Type: new 
Abstract: Stability of the BDF methods of order up to five for parabolic equations can be established by the energy technique via Nevanlinna--Odeh multipliers. The nonexistence of Nevanlinna--Odeh multipliers makes the six-step BDF method special; however, the energy technique was recently extended by the authors in [Akrivis et al., SIAM J. Numer. Anal. \textbf{59} (2021) 2449--2472] and covers all six stable BDF methods. The seven-step BDF method is unstable for parabolic equations, since it is not even zero-stable. In this work, we construct and analyze a stable linear combination of two non zero-stable schemes, the seven-step BDF method and its shifted counterpart, referred to as WSBDF7 method. The stability regions of the WSBDF$q, q\leqslant 7$, with a weight $\vartheta\geqslant1$, increase as $\vartheta$ increases, are larger than the stability regions of the classical BDF$q,$ corresponding to $\vartheta=1$. We determine novel and suitable multipliers for the WSBDF7 method and establish stability for parabolic equations by the energy technique. The proposed approach is applicable for mean curvature flow, gradient flows, fractional equations and nonlinear equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02872v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgios Akrivis, Minghua Chen, Fan Yu</dc:creator>
    </item>
    <item>
      <title>Analysis about Theoretical Foundations for Method to Enhancing ASR Performance using OCR Word Frequency Differences</title>
      <link>https://arxiv.org/abs/2405.02995</link>
      <description>arXiv:2405.02995v1 Announce Type: new 
Abstract: As interest in large language models (LLMs) grows, the importance of accuracy in automatic speech recognition (ASR) has become more pronounced. This is particularly true for lectures that include specialized terminology, where the success rate of traditional ASR models tends to be low, posing a challenging problem. A method to improve ASR performance for specialized terminology using the word frequency difference approach has been proposed. Through experiments and data analysis, we investigate whether this proposal effectively addresses the issue. Additionally, we introduce the power law as the theoretical foundation for the relative frequency</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02995v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyudan Jung, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee</dc:creator>
    </item>
    <item>
      <title>Pathwise uniform convergence of a full discretization for a three-dimensional stochastic Allen-Cahn equation with multiplicative noise</title>
      <link>https://arxiv.org/abs/2405.03016</link>
      <description>arXiv:2405.03016v1 Announce Type: new 
Abstract: This paper analyzes a full discretization of a three-dimensional stochastic Allen-Cahn equation with multiplicative noise. The discretization uses the Euler scheme for temporal discretization and the finite element method for spatial discretization. By deriving a stability estimate of a discrete stochastic convolution and utilizing this stability estimate along with the discrete stochastic maximal $L^p$-regularity estimate, a pathwise uniform convergence rate with the general spatial $ L^q $-norms is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03016v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binjie Li, Qin Zhou</dc:creator>
    </item>
    <item>
      <title>Design optimization in unilateral contact using pressure constraints and Bayesian optimization</title>
      <link>https://arxiv.org/abs/2405.03081</link>
      <description>arXiv:2405.03081v1 Announce Type: new 
Abstract: Design optimization problems, e.g., shape optimization, that involve deformable bodies in unilateral contact are challenging as they require robust contact solvers, complex optimization methods that are typically gradient-based, and sensitivity derivations. Notably, the problems are nonsmooth, adding significant difficulty to the optimization process. We study design optimization problems in frictionless unilateral contact subject to pressure constraints, using both gradient-based and gradient-free optimization methods, namely Bayesian optimization. The contact simulation problem is solved via the mortar contact and finite element methods. For the gradient-based method, we use the direct differentiation method to compute the sensitivities of the cost and constraint function with respect to the design variables. Then, we use Ipopt to solve the optimization problems. For the gradient-free approach, we use a constrained Bayesian optimization algorithm based on the standard Gaussian Process surrogate model. We present numerical examples that control the contact pressure, inspired by real-life engineering applications, to demonstrate the effectiveness, strengths and shortcomings of both methods. Our results suggest that both optimization methods perform reasonably well for these nonsmooth problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03081v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyi Wang, Jerome Solberg, Mike A. Puso, Eric B. Chin, Cosmin G. Petra</dc:creator>
    </item>
    <item>
      <title>A continuum and computational framework for viscoelastodynamics: III. A nonlinear theory</title>
      <link>https://arxiv.org/abs/2405.03090</link>
      <description>arXiv:2405.03090v1 Announce Type: new 
Abstract: We continue our investigation of viscoelasticity by extending the Holzapfel-Simo approach discussed in Part I to the fully nonlinear regime. By scrutinizing the relaxation property for the non-equilibrium stresses, it is revealed that a kinematic assumption akin to the Green-Naghdi type is necessary in the design of the potential. This insight underscores a link between the so-called additive plasticity and the viscoelasticity model under consideration, further inspiring our development of a nonlinear viscoelasticity theory. Our strategy is based on Hill's hyperelasticity framework and leverages the concept of generalized strains. Notably, the adopted kinematic assumption makes the proposed theory fundamentally different from the existing models rooted in the notion of the intermediate configuration. The computation aspects, including the consistent linearization, constitutive integration, and modular implementation, are addressed in detail. A suite of numerical examples is provided to demonstrate the capability of the proposed model in characterizing viscoelastic material behaviors at large strains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03090v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ju Liu, Jiashen Guan, Chongran Zhao, Jiawei Luo</dc:creator>
    </item>
    <item>
      <title>A novel fourth-order scheme for two-dimensional Riesz space fractional nonlinear reaction-diffusion equations and its optimal preconditioned solver</title>
      <link>https://arxiv.org/abs/2405.03143</link>
      <description>arXiv:2405.03143v1 Announce Type: new 
Abstract: A novel fourth-order finite difference formula coupling the Crank-Nicolson explicit linearized method is proposed to solve Riesz space fractional nonlinear reaction-diffusion equations in two dimensions. Theoretically, under the Lipschitz assumption on the nonlinear term, the proposed high-order scheme is proved to be unconditionally stable and convergent in the discrete $L_2$-norm. Moreover, a $\tau$-matrix based preconditioner is developed to speed up the convergence of the conjugate gradient method with an optimal convergence rate (a convergence rate independent of mesh sizes) for solving the symmetric discrete linear system. Theoretical analysis shows that the spectra of the preconditioned matrices are uniformly bounded in the open interval $(3/8,2)$. To the best of our knowledge, this is the first attempt to develop a preconditioned iterative solver with a mesh-independent convergence rate for the linearized high-order scheme. Numerical examples are given to validate the accuracy of the scheme and the effectiveness of the proposed preconditioned solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03143v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Qu, Yuan-Yuan Huang, Sean Hon, Siu-Long Lei</dc:creator>
    </item>
    <item>
      <title>Projection-Free Method for the Full Frank-Oseen Model of Liquid Crystals</title>
      <link>https://arxiv.org/abs/2405.03145</link>
      <description>arXiv:2405.03145v1 Announce Type: new 
Abstract: Liquid crystals are materials that experience an intermediate phase where the material can flow like a liquid, but the molecules maintain an orientation order. The Frank-Oseen model is a continuum model of a liquid crystal. The model represents the liquid crystal orientation as a vector field and posits that the vector field minimizes some elastic energy subject to a pointwise unit length constraint, which is a nonconvex constraint. Previous numerical methods in the literature assumed restrictions on the physical constants or had regularity assumptions that ruled out point defects, which are important physical phenomena to model. We present a finite element discretization of the full Frank-Oseen model and a projection free gradient flow algorithm for the discrete problem in the spirit of Bartels (2016). We prove Gamma-convergence of the discrete to the continuous problem: weak convergence of subsequences of discrete minimizers and convergence of energies. We also prove that the gradient flow algorithm has a desirable energy decrease property. Our analysis only requires that the physical constants are positive, which presents challenges due to the additional nonlinearities from the elastic energy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03145v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Bouck, Ricardo H. Nochetto</dc:creator>
    </item>
    <item>
      <title>SOC-MartNet: A Martingale Neural Network for the Hamilton-Jacobi-Bellman Equation without Explicit inf H in Stochastic Optimal Controls</title>
      <link>https://arxiv.org/abs/2405.03169</link>
      <description>arXiv:2405.03169v1 Announce Type: new 
Abstract: In this work, we propose a martingale based neural network, SOC-MartNet, for solving high-dimensional Hamilton-Jacobi-Bellman (HJB) equations where no explicit expression is needed for the Hamiltonian $\inf_{u \in U} H(t,x,u, z,p)$, and stochastic optimal control problems with controls on both drift and volatility. We reformulate the HJB equations into a stochastic neural network learning process, i.e., training a control network and a value network such that the associated Hamiltonian process is minimized and the cost process becomes a martingale.To enforce the martingale property for the cost process, we employ an adversarial network and construct a loss function based on the projection property of conditional expectations. Then, the control/value networks and the adversarial network are trained adversarially, such that the cost process is driven towards a martingale and the minimum principle is satisfied for the control.Numerical results show that the proposed SOC-MartNet is effective and efficient for solving HJB-type equations and SOCP with a dimension up to $500$ in a small number of training epochs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03169v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Cai, Shuixin Fang, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>A Two-Step Method Coupling Eddy Currents and Magneto-Statics</title>
      <link>https://arxiv.org/abs/2405.03224</link>
      <description>arXiv:2405.03224v1 Announce Type: new 
Abstract: We present the mathematical theory and its numerical validation of a method tailored to include eddy-current effects only in a part of the domain. This results in a heterogeneous problem combining an eddy-current model in a subset of the computational domain with a magneto-static model in the remainder of the domain. We adopt a two-domain two-step approach in which the primary variables of the problem are the electric scalar potential and the magnetic vector potential. We show numerical results that validate the formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03224v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martina Busetto, Christoph Winkelmann</dc:creator>
    </item>
    <item>
      <title>V-line tensor tomography: numerical results</title>
      <link>https://arxiv.org/abs/2405.03249</link>
      <description>arXiv:2405.03249v1 Announce Type: new 
Abstract: This article presents the numerical verification and validation of several inversion algorithms for V-line transforms (VLTs) acting on symmetric 2-tensor fields in the plane. The analysis of these transforms and the theoretical foundation of their inversion methods were studied in a recent work [G. Ambartsoumian, R. K. Mishra, and I. Zamindar, Inverse Problems, 40 (2024), 035003]. We demonstrate the efficient recovery of an unknown symmetric 2-tensor field from various combinations of the longitudinal, transverse, and mixed VLTs, their corresponding first moments, and the star VLT. The paper examines the performance of the proposed algorithms in different settings and illustrates the results with numerical simulations on smooth and non-smooth phantoms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03249v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gaik Ambartsoumian, Rohit Kumar Mishra, Indrani Zamindar</dc:creator>
    </item>
    <item>
      <title>A continuous approach for computing the pseudospectra of linear operators</title>
      <link>https://arxiv.org/abs/2405.03285</link>
      <description>arXiv:2405.03285v1 Announce Type: new 
Abstract: We propose a continuous approach for computing the pseudospectra of linear operators following a 'solve-then-discretize' strategy. Instead of taking a finite section approach or using a finite-dimensional matrix to approximate the operator of interest, the new method employs an operator analogue of the Lanczos process to work directly with operators and functions. The method is shown to be free of spectral pollution and spectral invisibility, fully adaptive, nearly optimal in accuracy, and well-conditioned. The advantages of the method are demonstrated by extensive numerical examples and comparison with the traditional method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03285v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kuan Deng, Xiaolin Liu, Kuan Xu</dc:creator>
    </item>
    <item>
      <title>An efficient hierarchical Bayesian method for the Kuopio tomography challenge 2023</title>
      <link>https://arxiv.org/abs/2405.03343</link>
      <description>arXiv:2405.03343v1 Announce Type: new 
Abstract: The aim of Electrical Impedance Tomography (EIT) is to determine the electrical conductivity distribution inside a domain by applying currents and measuring voltages on its boundary. Mathematically, the EIT reconstruction task can be formulated as a non-linear inverse problem. The Bayesian inverse problems framework has been applied expensively to solutions of the EIT inverse problem, in particular in the cases when the unknown conductivity is believed to be blocky. Recently, the Sparsity Promoting Iterative Alternating Sequential (PS-IAS) algorithm, originally proposed for the solution of linear inverse problems, has been adapted for the non linear case of EIT reconstruction in a computationally efficient manner. Here we introduce a hybrid version of the SP-IAS algorithms for the nonlinear EIT inverse problem, providing a detailed description of the implementation details, with a specific focus on parameters selection. The method is applied to the 2023 Kuopio Tomography Challenge dataset, with a comprehensive report of the running times for the different cases and parameter selections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03343v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Monica Pragliola, Daniela Calvetti, Erkki Somersalo</dc:creator>
    </item>
    <item>
      <title>Improved scalar auxiliary variable schemes for original energy stability of gradient flows</title>
      <link>https://arxiv.org/abs/2405.03403</link>
      <description>arXiv:2405.03403v1 Announce Type: new 
Abstract: Scalar auxiliary variable (SAV) methods are a class of linear schemes for solving gradient flows that are known for the stability of a `modified' energy. In this paper, we propose an improved SAV (iSAV) scheme that not only retains the complete linearity but also ensures rigorously the stability of the original energy. The convergence and optimal error bound are rigorously established for the iSAV scheme and discussions are made for its high-order extension. Extensive numerical experiments are done to validate the convergence, robustness and energy stability of iSAV, and some comparisons are made.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03403v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>RUi Chen, Tingfeng Wang, Xiaofei Zhao</dc:creator>
    </item>
    <item>
      <title>Unique solvability and error analysis of the Lagrange multiplier approach for gradient flows</title>
      <link>https://arxiv.org/abs/2405.03415</link>
      <description>arXiv:2405.03415v1 Announce Type: new 
Abstract: The unique solvability and error analysis of the original Lagrange multiplier approach proposed in [8] for gradient flows is studied in this paper. We identify a necessary and sufficient condition that must be satisfied for the nonlinear algebraic equation arising from the original Lagrange multiplier approach to admit a unique solution in the neighborhood of its exact solution, and propose a modified Lagrange multiplier approach so that the computation can continue even if the aforementioned condition is not satisfied. Using Cahn-Hilliard equation as an example, we prove rigorously the unique solvability and establish optimal error estimates of a second-order Lagrange multiplier scheme assuming this condition and that the time step is sufficient small. We also present numerical results to demonstrate that the modified Lagrange multiplier approach is much more robust and can use much larger time step than the original Lagrange multiplier approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03415v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Qing Cheng, Jie Shen, Cheng Wang</dc:creator>
    </item>
    <item>
      <title>Homotopy methods for higher order shape optimization: A globalized shape-Newton method and Pareto-front tracing</title>
      <link>https://arxiv.org/abs/2405.03421</link>
      <description>arXiv:2405.03421v1 Announce Type: new 
Abstract: First order shape optimization methods, in general, require a large number of iterations until they reach a locally optimal design. While higher order methods can significantly reduce the number of iterations, they exhibit only local convergence properties, necessitating a sufficiently close initial guess. In this work, we present an unregularized shape-Newton method and combine shape optimization with homotopy (or continuation) methods in order to allow for the use of higher order methods even if the initial design is far from a solution. The idea of homotopy methods is to continuously connect the problem of interest with a simpler problem and to follow the corresponding solution path by a predictor-corrector scheme. We use a shape-Newton method as a corrector and arbitrary order shape derivatives for the predictor. Moreover, we apply homotopy methods also to the case of multi-objective shape optimization to efficiently obtain well-distributed points on a Pareto front. Finally, our results are substantiated with a set of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03421v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Cesarano, B. Endtmayer, P. Gangl</dc:creator>
    </item>
    <item>
      <title>Annealed adaptive importance sampling method in PINNs for solving high dimensional partial differential equations</title>
      <link>https://arxiv.org/abs/2405.03433</link>
      <description>arXiv:2405.03433v1 Announce Type: new 
Abstract: Physics-informed neural networks (PINNs) have emerged as powerful tools for solving a wide range of partial differential equations (PDEs). However, despite their user-friendly interface and broad applicability, PINNs encounter challenges in accurately resolving PDEs, especially when dealing with singular cases that may lead to unsatisfactory local minima. To address these challenges and improve solution accuracy, we propose an innovative approach called Annealed Adaptive Importance Sampling (AAIS) for computing the discretized PDE residuals of the cost functions, inspired by the Expectation Maximization algorithm used in finite mixtures to mimic target density. Our objective is to approximate discretized PDE residuals by strategically sampling additional points in regions with elevated residuals, thus enhancing the effectiveness and accuracy of PINNs. Implemented together with a straightforward resampling strategy within PINNs, our AAIS algorithm demonstrates significant improvements in efficiency across a range of tested PDEs, even with limited training datasets. Moreover, our proposed AAIS-PINN method shows promising capabilities in solving high-dimensional singular PDEs. The adaptive sampling framework introduced here can be integrated into various PINN frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03433v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengqi Zhang, Jing Li, Bin Liu</dc:creator>
    </item>
    <item>
      <title>On certain matrix algebras related to quasi-Toeplitz matrices</title>
      <link>https://arxiv.org/abs/2405.03483</link>
      <description>arXiv:2405.03483v1 Announce Type: new 
Abstract: Let $A_\alpha$ be the semi-infinite tridiagonal matrix having subdiagonal and superdiagonal unit entries, $(A_\alpha)_{11}=\alpha$, where $\alpha\in\mathbb C$, and zero elsewhere. A basis $\{P_0,P_1,P_2,\ldots\}$ of the linear space $\mathcal P_\alpha$ spanned by the powers of $A_\alpha$ is determined, where $P_0=I$, $P_n=T_n+H_n$, $T_n$ is the symmetric Toeplitz matrix having ones in the $n$th super- and sub-diagonal, zeros elsewhere, and $H_n$ is the Hankel matrix with first row $[\theta\alpha^{n-2}, \theta\alpha^{n-3}, \ldots, \theta, \alpha, 0, \ldots]$, where $\theta=\alpha^2-1$. The set $\mathcal P_\alpha$ is an algebra, and for $\alpha\in\{-1,0,1\}$, $H_n$ has only one nonzero anti-diagonal. This fact is exploited to provide a better representation of symmetric quasi-Toeplitz matrices $\mathcal {QT}_S$, where, instead of representing a generic matrix $A\in\mathcal{QT}_S$ as $A=T+K$, where $T$ is Toeplitz and $K$ is compact, it is represented as $A=P+H$, where $P\in\mathcal P_\alpha$ and $H$ is compact. It is shown experimentally that the matrix arithmetic obtained this way is much more effective than that implemented in the CQT-Toolbox of Numer.~Algo. 81(2):741--769, 2019.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03483v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dario Bini, Beatrice Meini</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo for Bayesian design of experiment problems governed by parametric PDEs</title>
      <link>https://arxiv.org/abs/2405.03529</link>
      <description>arXiv:2405.03529v1 Announce Type: new 
Abstract: This paper contributes to the study of optimal experimental design for Bayesian inverse problems governed by partial differential equations (PDEs). We derive estimates for the parametric regularity of multivariate double integration problems over high-dimensional parameter and data domains arising in Bayesian optimal design problems. We provide a detailed analysis for these double integration problems using two approaches: a full tensor product and a sparse tensor product combination of quasi-Monte Carlo (QMC) cubature rules over the parameter and data domains. Specifically, we show that the latter approach significantly improves the convergence rate, exhibiting performance comparable to that of QMC integration of a single high-dimensional integral. Furthermore, we numerically verify the predicted convergence rates for an elliptic PDE problem with an unknown diffusion coefficient in two spatial dimensions, offering empirical evidence supporting the theoretical results and highlighting practical applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03529v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vesa Kaarnioja, Claudia Schillings</dc:creator>
    </item>
    <item>
      <title>Asymptotic-preserving hybridizable discontinuous Galerkin method for the Westervelt quasilinear wave equation</title>
      <link>https://arxiv.org/abs/2405.03535</link>
      <description>arXiv:2405.03535v1 Announce Type: new 
Abstract: We discuss the asymptotic-preserving properties of a hybridizable discontinuous Galerkin method for the Westervelt model of ultrasound waves. More precisely, we show that the proposed method is robust with respect to small values of the sound diffusivity damping parameter~$\delta$ by deriving low- and high-order energy stability estimates, and \emph{a priori} error bounds that are independent of~$\delta$. Such bounds are then used to show that, when~$\delta \rightarrow 0^+$, the method remains stable and the discrete acoustic velocity potential~$\psi_h^{(\delta)}$ converges to~$\psi_h^{(0)}$, where the latter is the singular vanishing dissipation limit. Moreover, we prove optimal convergence for the approximation of the acoustic particle velocity variable~$\bv = \nabla \psi$. The established theoretical results are illustrated with some numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03535v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio G\'omez, Mostafa Meliani</dc:creator>
    </item>
    <item>
      <title>Effective Quadratic Error Bounds for Floating-Point Algorithms Computing the Hypotenuse Function</title>
      <link>https://arxiv.org/abs/2405.03588</link>
      <description>arXiv:2405.03588v1 Announce Type: new 
Abstract: We provide tools to help automate the error analysis of algorithms that evaluate simple functions over the floating-point numbers. The aim is to obtain tight relative error bounds for these algorithms, expressed as a function of the unit round-off. Due to the discrete nature of the set of floating-point numbers, the largest errors are often intrinsically "arithmetic" in the sense that their appearance may depend on specific bit patterns in the binary representations of intermediate variables, which may be present only for some precisions. We focus on generic (i.e., parameterized by the precision) and analytic over-estimations that still capture the correlations between the errors made at each step of the algorithms. Using methods from computer algebra, which we adapt to the particular structure of the polynomial systems that encode the errors, we obtain bounds with a linear term in the unit round-off that is sharp in manycases. An explicit quadratic bound is given, rather than the $O()$-estimate that is more common in this area. This is particularly important when using low precision formats, which are increasingly common in modern processors. Using this approach, we compare five algorithms for computing the hypotenuse function, ranging from elementary to quite challenging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03588v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jean-Michel Muller, Bruno Salvy</dc:creator>
    </item>
    <item>
      <title>Multilevel Monte Carlo with Numerical Smoothing for Robust and Efficient Computation of Probabilities and Densities</title>
      <link>https://arxiv.org/abs/2003.05708</link>
      <description>arXiv:2003.05708v4 Announce Type: cross 
Abstract: The multilevel Monte Carlo (MLMC) method is highly efficient for estimating expectations of a functional of a solution to a stochastic differential equation (SDE). However, MLMC estimators may be unstable and have a poor (noncanonical) complexity in the case of low regularity of the functional. To overcome this issue, we extend our previously introduced idea of numerical smoothing in (Quantitative Finance, 23(2), 209-227, 2023), in the context of deterministic quadrature methods to the MLMC setting. The numerical smoothing technique is based on root-finding methods combined with one-dimensional numerical integration with respect to a single well-chosen variable. This study is motivated by the computation of probabilities of events, pricing options with a discontinuous payoff, and density estimation problems for dynamics where the discretization of the underlying stochastic processes is necessary. The analysis and numerical experiments reveal that the numerical smoothing significantly improves the strong convergence, and consequently, the complexity and robustness (by making the kurtosis at deep levels bounded) of the MLMC method. In particular, we show that numerical smoothing enables recovering the MLMC complexities obtained for Lipschitz functionals due to the optimal variance decay rate when using the Euler--Maruyama scheme. For the Milstein scheme, numerical smoothing recovers the canonical MLMC complexity even for the nonsmooth integrand mentioned above. Finally, our approach efficiently estimates univariate and multivariate density functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2003.05708v4</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bayer, Chiheb Ben Hammouda, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Simulating the aftermath of Northern European Enclosure Dam (NEED) break and flooding of European coast</title>
      <link>https://arxiv.org/abs/2405.02310</link>
      <description>arXiv:2405.02310v1 Announce Type: cross 
Abstract: The Northern European Enclosure Dam (NEED) is a hypothetical project to prevent flooding in European countries following the rising ocean level due to melting arctic glaciers. This project involves the construction of two large dams between Scotland and Norway, as well as England and France. The anticipated cost of this project is 250 to 500 billion euros. In this paper, we present the simulation of the aftermath of flooding on the European coastline caused by a catastrophic break of this hypothetical dam. From our simulation results, we can observe that there is a traveling wave after the accident, with a velocity of around 10 kilometers per hour, raising the sea level permanently inside the dammed region. This observation implies a need to construct additional dams or barriers protecting the northern coastline of the Netherlands and the interior of the Baltic Sea. Our simulations have been obtained using the following building blocks. First, a graph transformation model was applied to generate an adaptive mesh approximating the topography of the Earth. We employ the composition graph grammar model for breaking triangular elements in the mesh without the generation of hanging nodes. Second, the wave equation is formulated in a spherical latitude-longitude system of coordinates and solved by a high-order time integration scheme using the generalized $\alpha$ method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02310v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.ao-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pawe{\l} Maczuga, Marcin {\L}o\'s, Eirik Valseth, Albert Oliver Serra, Leszek Siwik, Elisabede Alberdi Celaya, Anna Paszy\'nska, Maciej Paszy\'nski</dc:creator>
    </item>
    <item>
      <title>Finite Sample Analysis and Bounds of Generalization Error of Gradient Descent in In-Context Linear Regression</title>
      <link>https://arxiv.org/abs/2405.02462</link>
      <description>arXiv:2405.02462v1 Announce Type: cross 
Abstract: Recent studies show that transformer-based architectures emulate gradient descent during a forward pass, contributing to in-context learning capabilities - an ability where the model adapts to new tasks based on a sequence of prompt examples without being explicitly trained or fine tuned to do so. This work investigates the generalization properties of a single step of gradient descent in the context of linear regression with well-specified models. A random design setting is considered and analytical expressions are derived for the statistical properties of generalization error in a non-asymptotic (finite sample) setting. These expressions are notable for avoiding arbitrary constants, and thus offer robust quantitative information and scaling relationships. These results are contrasted with those from classical least squares regression (for which analogous finite sample bounds are also derived), shedding light on systematic and noise components, as well as optimal step sizes. Additionally, identities involving high-order products of Gaussian random matrices are presented as a byproduct of the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02462v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Duraisamy</dc:creator>
    </item>
    <item>
      <title>Understanding the Difficulty of Solving Cauchy Problems with PINNs</title>
      <link>https://arxiv.org/abs/2405.02561</link>
      <description>arXiv:2405.02561v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) have gained popularity in scientific computing in recent years. However, they often fail to achieve the same level of accuracy as classical methods in solving differential equations. In this paper, we identify two sources of this issue in the case of Cauchy problems: the use of $L^2$ residuals as objective functions and the approximation gap of neural networks. We show that minimizing the sum of $L^2$ residual and initial condition error is not sufficient to guarantee the true solution, as this loss function does not capture the underlying dynamics. Additionally, neural networks are not capable of capturing singularities in the solutions due to the non-compactness of their image sets. This, in turn, influences the existence of global minima and the regularity of the network. We demonstrate that when the global minimum does not exist, machine precision becomes the predominant source of achievable error in practice. We also present numerical experiments in support of our theoretical claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02561v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Wang, Bo Zhao, Sicun Gao, Rose Yu</dc:creator>
    </item>
    <item>
      <title>Gradient-enhanced sparse Hermite polynomial expansions for pricing and hedging high-dimensional American options</title>
      <link>https://arxiv.org/abs/2405.02570</link>
      <description>arXiv:2405.02570v1 Announce Type: cross 
Abstract: We propose an efficient and easy-to-implement gradient-enhanced least squares Monte Carlo method for computing price and Greeks (i.e., derivatives of the price function) of high-dimensional American options. It employs the sparse Hermite polynomial expansion as a surrogate model for the continuation value function, and essentially exploits the fast evaluation of gradients. The expansion coefficients are computed by solving a linear least squares problem that is enhanced by gradient information of simulated paths. We analyze the convergence of the proposed method, and establish an error estimate in terms of the best approximation error in the weighted $H^1$ space, the statistical error of solving discrete least squares problems, and the time step size. We present comprehensive numerical experiments to illustrate the performance of the proposed method. The results show that it outperforms the state-of-the-art least squares Monte Carlo method with more accurate price, Greeks, and optimal exercise strategies in high dimensions but with nearly identical computational cost, and it can deliver comparable results with recent neural network-based methods up to dimension 100.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02570v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiefei Yang, Guanglian Li</dc:creator>
    </item>
    <item>
      <title>Inexact Adaptive Cubic Regularization Algorithms on Riemannian Manifolds and Application</title>
      <link>https://arxiv.org/abs/2405.02588</link>
      <description>arXiv:2405.02588v1 Announce Type: cross 
Abstract: The adaptive cubic regularization algorithm employing the inexact gradient and Hessian is proposed on general Riemannian manifolds, together with the iteration complexity to get an approximate second-order optimality under certain assumptions on accuracies about the inexact gradient and Hessian. The algorithm extends the inexact adaptive cubic regularization algorithm under true gradient in [Math. Program., 184(1-2): 35-70, 2020] to more general cases even in Euclidean settings. As an application, the algorithm is applied to solve the joint diagonalization problem on the Stiefel manifold. Numerical experiments illustrate that the algorithm performs better than the inexact trust-region algorithm in [Advances of the neural information processing systems, 31, 2018].</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02588v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Z. Y. Li, X. M. Wang</dc:creator>
    </item>
    <item>
      <title>Predicting Open-Hole Laminates Failure Using Support Vector Machines With Classical and Quantum Kernels</title>
      <link>https://arxiv.org/abs/2405.02903</link>
      <description>arXiv:2405.02903v1 Announce Type: cross 
Abstract: Modeling open hole failure of composites is a complex task, consisting in a highly nonlinear response with interacting failure modes. Numerical modeling of this phenomenon has traditionally been based on the finite element method, but requires to tradeoff between high fidelity and computational cost. To mitigate this shortcoming, recent work has leveraged machine learning to predict the strength of open hole composite specimens. Here, we also propose using data-based models but to tackle open hole composite failure from a classification point of view. More specifically, we show how to train surrogate models to learn the ultimate failure envelope of an open hole composite plate under in-plane loading. To achieve this, we solve the classification problem via support vector machine (SVM) and test different classifiers by changing the SVM kernel function. The flexibility of kernel-based SVM also allows us to integrate the recently developed quantum kernels in our algorithm and compare them with the standard radial basis function (RBF) kernel. Finally, thanks to kernel-target alignment optimization, we tune the free parameters of all kernels to best separate safe and failure-inducing loading states. The results show classification accuracies higher than 90% for RBF, especially after alignment, followed closely by the quantum kernel classifiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02903v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giorgio Tosti Balducci, Boyang Chen, Matthias M\"oller, Marc Gerritsma, Roeland De Breuker</dc:creator>
    </item>
    <item>
      <title>Accelerating Legacy Numerical Solvers by Non-intrusive Gradient-based Meta-solving</title>
      <link>https://arxiv.org/abs/2405.02952</link>
      <description>arXiv:2405.02952v1 Announce Type: cross 
Abstract: Scientific computing is an essential tool for scientific discovery and engineering design, and its computational cost is always a main concern in practice. To accelerate scientific computing, it is a promising approach to use machine learning (especially meta-learning) techniques for selecting hyperparameters of traditional numerical methods. There have been numerous proposals to this direction, but many of them require automatic-differentiable numerical methods. However, in reality, many practical applications still depend on well-established but non-automatic-differentiable legacy codes, which prevents practitioners from applying the state-of-the-art research to their own problems. To resolve this problem, we propose a non-intrusive methodology with a novel gradient estimation technique to combine machine learning and legacy numerical codes without any modification. We theoretically and numerically show the advantage of the proposed method over other baselines and present applications of accelerating established non-automatic-differentiable numerical solvers implemented in PETSc, a widely used open-source numerical software library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02952v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sohei Arisaka, Qianxiao Li</dc:creator>
    </item>
    <item>
      <title>Braced Fourier Continuation and Regression for Anomaly Detection</title>
      <link>https://arxiv.org/abs/2405.03180</link>
      <description>arXiv:2405.03180v1 Announce Type: cross 
Abstract: In this work, the concept of Braced Fourier Continuation and Regression (BFCR) is introduced. BFCR is a novel and computationally efficient means of finding nonlinear regressions or trend lines in arbitrary one-dimensional data sets. The Braced Fourier Continuation (BFC) and BFCR algorithms are first outlined, followed by a discussion of the properties of BFCR as well as demonstrations of how BFCR trend lines may be used effectively for anomaly detection both within and at the edges of arbitrary one-dimensional data sets. Finally, potential issues which may arise while using BFCR for anomaly detection as well as possible mitigation techniques are outlined and discussed. All source code and example data sets are either referenced or available via GitHub, and all associated code is written entirely in Python.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03180v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josef Sabuda</dc:creator>
    </item>
    <item>
      <title>Impact of EIP-4844 on Ethereum: Consensus Security, Ethereum Usage, Rollup Transaction Dynamics, and Blob Gas Fee Markets</title>
      <link>https://arxiv.org/abs/2405.03183</link>
      <description>arXiv:2405.03183v1 Announce Type: cross 
Abstract: On March 13, 2024, Ethereum implemented EIP-4844, designed to enhance its role as a data availability layer. While this upgrade reduces data posting costs for rollups, it also raises concerns about its impact on the consensus layer due to increased propagation sizes. Moreover, the broader effects on the overall Ethereum ecosystem remain largely unexplored. In this paper, we conduct an empirical analysis of the impact of EIP-4844 on consensus security, Ethereum usage, rollup transaction dynamics, and the blob gas fee mechanism. We explore changes in synchronization times, provide quantitative assessments of rollup and user behaviors, and deepen the understanding of the blob gas fee mechanism, highlighting both enhancements and areas of concern post-upgrade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03183v1</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seongwan Park, Bosul Mun, Seungyun Lee, Woojin Jeong, Jaewook Lee, Hyeonsang Eom, Huisu Jang</dc:creator>
    </item>
    <item>
      <title>pyCFS-data: Data Processing Framework in Python for openCFS</title>
      <link>https://arxiv.org/abs/2405.03437</link>
      <description>arXiv:2405.03437v1 Announce Type: cross 
Abstract: Many numerical simulation tools have been developed and are on the market, but there is still a strong need for appropriate tools capable of simulating multi-field problems, especially in aeroacoustics. Therefore, openCFS provides an open-source framework for implementing partial differential equations using the finite element method. Since 2000, the software has been developed continuously. The result is openCFS (before 2020, known as CFS++ Coupled Field Simulations written in C++). In this paper, we present pyCFS-data, a data processing framework written in Python to provide a flexible and easy-to-use toolbox to access and manipulate, pre- and postprocess data generated by or for usage with openCFS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03437v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Wurzinger, Stefan Schoder</dc:creator>
    </item>
    <item>
      <title>A Symplectic Analysis of Alternating Mirror Descent</title>
      <link>https://arxiv.org/abs/2405.03472</link>
      <description>arXiv:2405.03472v1 Announce Type: cross 
Abstract: Motivated by understanding the behavior of the Alternating Mirror Descent (AMD) algorithm for bilinear zero-sum games, we study the discretization of continuous-time Hamiltonian flow via the symplectic Euler method. We provide a framework for analysis using results from Hamiltonian dynamics, Lie algebra, and symplectic numerical integrators, with an emphasis on the existence and properties of a conserved quantity, the modified Hamiltonian (MH), for the symplectic Euler method. We compute the MH in closed-form when the original Hamiltonian is a quadratic function, and show that it generally differs from the other conserved quantity known previously in that case. We derive new error bounds on the MH when truncated at orders in the stepsize in terms of the number of iterations, $K$, and utilize this bound to show an improved $\mathcal{O}(K^{1/5})$ total regret bound and an $\mathcal{O}(K^{-4/5})$ duality gap of the average iterates for AMD. Finally, we propose a conjecture which, if true, would imply that the total regret for AMD goes as $\mathcal{O}\left(K^{\varepsilon}\right)$ and the duality gap of the average iterates as $\mathcal{O}\left(K^{-1+\varepsilon}\right)$ for any $\varepsilon&gt;0$, and we can take $\varepsilon=0$ upon certain convergence conditions for the MH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03472v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Katona, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Fast Approximate Determinants Using Rational Functions</title>
      <link>https://arxiv.org/abs/2405.03474</link>
      <description>arXiv:2405.03474v1 Announce Type: cross 
Abstract: We show how rational function approximations to the logarithm, such as $\log z \approx (z^2 - 1)/(z^2 + 6z + 1)$, can be turned into fast algorithms for approximating the determinant of a very large matrix. We empirically demonstrate that when combined with a good preconditioner, the third order rational function approximation offers a very good trade-off between speed and accuracy when measured on matrices coming from Mat\'ern-$5/2$ and radial basis function Gaussian process kernels. In particular, it is significantly more accurate on those matrices than the state-of-the-art stochastic Lanczos quadrature method for approximating determinants while running at about the same speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03474v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Colthurst, Srinivas Vasudevan, James Lottes, Brian Patton</dc:creator>
    </item>
    <item>
      <title>Piecewise Pad\'e-Chebyshev Reconstruction of Bivariate Piecewise Smooth Functions</title>
      <link>https://arxiv.org/abs/2109.11436</link>
      <description>arXiv:2109.11436v3 Announce Type: replace 
Abstract: We extend the idea of approximating piecewise smooth univariate functions using rational approximation introduced in \cite{aka_bas-19a} to two-dimensional space. This article aims to implement the novel piecewise Maehly based Pad\'e-Chebyshev approximation \cite{mae_60a}. We first develop a method referred to as PiPC to approximate univariate piecewise smooth functions and then extend the same to a two-dimensional space, leading to a bivariate piecewise Pad\'e-Chebyshev approximation (Pi2DPC) for approximating piecewise smooth functions in two-dimension. We study the utility of the proposed techniques in minimizing the Gibbs phenomenon while approximating piecewise smooth functions. The chief advantage of these methods lies in their non-dependence on any apriori knowledge of the locations and types of singularities (if any) present in the original function. Finally, we supplement our methods with numerical results to validate their effectiveness in diminishing the Gibbs phenomenon to negligible levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.11436v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akansha Singh</dc:creator>
    </item>
    <item>
      <title>UltimateKalman: Flexible Kalman Filtering and Smoothing Using Orthogonal Transformations</title>
      <link>https://arxiv.org/abs/2207.13526</link>
      <description>arXiv:2207.13526v2 Announce Type: replace 
Abstract: UltimateKalman is a flexible linear Kalman filter and smoother implemented in three popular programming languages: MATLAB, C, and Java. UltimateKalman is a slight simplification and slight generalization of an elegant Kalman filter and smoother that was proposed in 1977 by Paige and Saunders. Their algorithm appears to be numerically superior and more flexible than other Kalman filters and smoothers, but curiously has never been implemented or used before. UltimateKalman is flexible: it can easily handle time-dependent problems, problems with state vectors whose dimensions vary from step to step, problems with varying number of observations in different steps (or no observations at all in some steps), and problems in which the expectation of the initial state is unknown. The programming interface of UltimateKalman is broken into simple building blocks that can be used to construct filters, single or multi-step predictors, multi-step or whole-track smoothers, and combinations. The paper describes the algorithm and its implementation as well as with a test suite of examples and tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.13526v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sivan Toledo</dc:creator>
    </item>
    <item>
      <title>Data-based Adaptive Refinement of Finite Element Thin Plate Spline</title>
      <link>https://arxiv.org/abs/2302.10442</link>
      <description>arXiv:2302.10442v3 Announce Type: replace 
Abstract: The thin plate spline, as introduced by Duchon, interpolates a smooth surface through scattered data. It is computationally expensive when there are many data points. The finite element thin plate spline (TPSFEM) possesses similar smoothing properties and is efficient for large data sets. Its efficiency is further improved by adaptive refinement that adapts the precision of the finite element grid. Adaptive refinement processes and error indicators developed for partial differential equations may not apply to the TPSFEM as it incorporates information about the scattered data. This additional information results in features not evident in partial differential equations. An iterative adaptive refinement process and five error indicators were adapted for the TPSFEM. We give comprehensive depictions of the process in this article and evaluate the error indicators through a numerical experiment with a model problem and two bathymetric surveys in square and L-shaped domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.10442v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. Fang, L. Stals</dc:creator>
    </item>
    <item>
      <title>Absorbing boundary conditions for the Helmholtz equation using Gauss-Legendre quadrature reduced integrations</title>
      <link>https://arxiv.org/abs/2308.12255</link>
      <description>arXiv:2308.12255v2 Announce Type: replace 
Abstract: We introduce a new class of absorbing boundary conditions (ABCs) for the Helmholtz equation. The proposed ABCs are obtained by using $L$ discrete layers and the $Q_N$ Lagrange finite element in conjunction with the $N$-point Gauss-Legendre quadrature reduced integration rule in a specific formulation of perfectly matched layers. The proposed ABCs are classified by a tuple $(L,N)$, and achieve reflection error of order $O(R^{2LN})$ for some $R&lt;1$. The new ABCs generalise the perfectly matched discrete layers proposed by Guddati and Lim [Int. J. Numer. Meth. Engng 66 (6) (2006) 949-977], including them as type $(L,1)$. An analysis of the proposed ABCs is performed motivated by the work of Ainsworth [J. Comput. Phys. 198 (1) (2004) 106-130]. The new ABCs facilitate numerical implementations of the Helmholtz problem with ABCs if $Q_N$ finite elements are used in the physical domain as well as give more insight into this field for the further advancement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12255v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koki Sagiyama</dc:creator>
    </item>
    <item>
      <title>Modeling and Simulation of Chemo-Elasto-Plastically Coupled Battery Active Particles</title>
      <link>https://arxiv.org/abs/2310.05440</link>
      <description>arXiv:2310.05440v3 Announce Type: replace 
Abstract: As an anode material for lithium-ion batteries, amorphous silicon offers a significantly higher energy density than the graphite anodes currently used. Alloying reactions of lithium and silicon, however, induce large deformation and lead to volume changes up to 300%. We formulate a thermodynamically consistent continuum model for the chemo-elasto-plastic diffusion-deformation behavior of amorphous silicon and it's alloy with lithium based on finite deformations. In this paper, two plasticity theories, i.e. a rate-independent theory with linear isotropic hardening and a rate-dependent one, are formulated to allow the evolution of plastic deformations and reduce occurring stresses. Using modern numerical techniques, such as higher order finite element methods as well as efficient space and time adaptive solution algorithms, the diffusion-deformation behavior resulting from both theories is compared. In order to further increase the computational efficiency, an automatic differentiation scheme is used, allowing for a significant speed up in assembling time as compared to an algorithmic linearization for the global finite element Newton scheme. Both plastic approaches lead to a more heterogeneous concentration distribution and to a change to tensile tangential Cauchy stresses at the particle surface at the end of one charging cycle. Different parameter studies show how an amplification of the plastic deformation is affected. Interestingly, an elliptical particle shows only plastic deformation at the smaller half axis. With the demonstrated efficiency of the applied methods, results after five charging cycles are also discussed and can provide indications for the performance of lithium-ion batteries in long term use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05440v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Raphael Schoof, Johannes Niermann, Alexander Dyck, Thomas B\"ohlke, Willy D\"orfler</dc:creator>
    </item>
    <item>
      <title>Discontinuous Galerkin approximations of the heterodimer model for protein-protein interaction</title>
      <link>https://arxiv.org/abs/2310.08342</link>
      <description>arXiv:2310.08342v3 Announce Type: replace 
Abstract: Mathematical models of protein-protein dynamics, such as the heterodimer model, play a crucial role in understanding many physical phenomena. This model is a system of two semilinear parabolic partial differential equations describing the evolution and mutual interaction of biological species. An example is the neurodegenerative disease progression in some significant pathologies, such as Alzheimer's and Parkinson's diseases, characterized by the accumulation and propagation of toxic prionic proteins. This article presents and analyzes a flexible high-order discretization method for the numerical approximation of the heterodimer model. We propose a space discretization based on a Discontinuous Galerkin method on polygonal/polyhedral grids, which provides flexibility in handling complex geometries. Concerning the semi-discrete formulation, we prove stability and a-priori error estimates for the first time. Next, we adopt a $\theta$-method scheme as a time integration scheme. Convergence tests are carried out to demonstrate the theoretical bounds and the ability of the method to approximate traveling wave solutions, considering also complex geometries such as brain sections reconstructed from medical images. Finally, the proposed scheme is tested in a practical test case stemming from neuroscience applications, namely the simulation of the spread of $\alpha$-synuclein in a realistic test case of Parkinson's disease in a two-dimensional sagittal brain section geometry reconstructed from medical images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08342v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paola F. Antonietti, Francesca Bonizzoni, Mattia Corti, Agnese Dall'Olio</dc:creator>
    </item>
    <item>
      <title>Solving High Dimensional Partial Differential Equations Using Tensor Neural Network and A Posteriori Error Estimators</title>
      <link>https://arxiv.org/abs/2311.02732</link>
      <description>arXiv:2311.02732v2 Announce Type: replace 
Abstract: In this paper, based on the combination of tensor neural network and a posteriori error estimator, a novel type of machine learning method is proposed to solve high-dimensional boundary value problems with homogeneous and non-homogeneous Dirichlet or Neumann type of boundary conditions and eigenvalue problems of the second-order elliptic operator. The most important advantage of the tensor neural network is that the high dimensional integrations of tensor neural networks can be computed with high accuracy and high efficiency. Based on this advantage and the theory of a posteriori error estimation, the a posteriori error estimator is adopted to design the loss function to optimize the network parameters adaptively. The applications of tensor neural network and the a posteriori error estimator improve the accuracy of the corresponding machine learning method. The theoretical analysis and numerical examples are provided to validate the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02732v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wang, Zhongshuo Lin, Yangfei Liao, Haochen Liu, Hehu Xie</dc:creator>
    </item>
    <item>
      <title>Tractability of linear ill-posed problems in Hilbert space</title>
      <link>https://arxiv.org/abs/2401.09919</link>
      <description>arXiv:2401.09919v4 Announce Type: replace 
Abstract: We introduce a notion of tractability for ill-posed operator equations in Hilbert space. For such operator equations the asymptotics of the best possible rate of reconstruction in terms of the underlying noise level is known in many cases. However, the relevant question is, which level of discretization, again driven by the noise level, is required in order to achieve this best possible accuracy. The proposed concept adapts the one from Information-based Complexity.
  Several examples indicate the relevance of this concept in the light of the curse of dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09919v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Math\'e, Bernd Hofmann</dc:creator>
    </item>
    <item>
      <title>Efficient solution of ill-posed integral equations through averaging</title>
      <link>https://arxiv.org/abs/2401.16250</link>
      <description>arXiv:2401.16250v3 Announce Type: replace 
Abstract: This paper discusses the error and cost aspects of ill-posed integral equations when given discrete noisy point evaluations on a fine grid. Standard solution methods usually employ discretization schemes that are directly induced by the measurement points. Thus, they may scale unfavorably with the number of evaluation points, which can result in computational inefficiency. To address this issue, we propose an algorithm that achieves the same level of accuracy while significantly reducing computational costs. Our approach involves an initial averaging procedure to sparsify the underlying grid. To keep the exposition simple, we focus only on one-dimensional ill-posed integral equations that have sufficient smoothness. However, the approach can be generalized to more complicated two- and three-dimensional problems with appropriate modifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16250v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Griebel, Tim Jahn</dc:creator>
    </item>
    <item>
      <title>On metrics robust to noise and deformations</title>
      <link>https://arxiv.org/abs/2101.10867</link>
      <description>arXiv:2101.10867v3 Announce Type: replace-cross 
Abstract: We study the properties of a family of distances between functions of a single variable. These distances are examples of integral probability metrics, and have been used previously for comparing probability measures on the line; special cases include the Earth Mover's Distance and the Kolmogorov Metric. We examine their properties for general signals, proving that they are robust to a broad class of deformations. We also establish corresponding robustness results for the induced sliced distances between multivariate functions. Finally, we establish error bounds for approximating the univariate metrics from finite samples, and prove that these approximations are robust to additive Gaussian noise. The results are illustrated in numerical experiments, which include comparisons with Wasserstein distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.10867v3</guid>
      <category>math.FA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Leeb</dc:creator>
    </item>
    <item>
      <title>Physics-informed neural networks for operator equations with stochastic data</title>
      <link>https://arxiv.org/abs/2211.10344</link>
      <description>arXiv:2211.10344v2 Announce Type: replace-cross 
Abstract: We consider the computation of statistical moments to operator equations with stochastic data. We remark that application of PINNs -- referred to as TPINNs -- allows to solve the induced tensor operator equations under minimal changes of existing PINNs code, and enabling handling of non-linear and time-dependent operators. We propose two types of architectures, referred to as vanilla and multi-output TPINNs, and investigate their benefits and limitations. Exhaustive numerical experiments are performed; demonstrating applicability and performance; raising a variety of new promising research avenues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.10344v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Escapil-Inchausp\'e, Gonzalo A. Ruz</dc:creator>
    </item>
    <item>
      <title>Koopman neural operator as a mesh-free solver of non-linear partial differential equations</title>
      <link>https://arxiv.org/abs/2301.10022</link>
      <description>arXiv:2301.10022v2 Announce Type: replace-cross 
Abstract: The lacking of analytic solutions of diverse partial differential equations (PDEs) gives birth to a series of computational techniques for numerical solutions. Although numerous latest advances are accomplished in developing neural operators, a kind of neural-network-based PDE solver, these solvers become less accurate and explainable while learning long-term behaviors of non-linear PDE families. In this paper, we propose the Koopman neural operator (KNO), a new neural operator, to overcome these challenges. With the same objective of learning an infinite-dimensional mapping between Banach spaces that serves as the solution operator of the target PDE family, our approach differs from existing models by formulating a non-linear dynamic system of equation solution. By approximating the Koopman operator, an infinite-dimensional operator governing all possible observations of the dynamic system, to act on the flow mapping of the dynamic system, we can equivalently learn the solution of a non-linear PDE family by solving simple linear prediction problems. We validate the KNO in mesh-independent, long-term, and5zero-shot predictions on five representative PDEs (e.g., the Navier-Stokes equation and the Rayleigh-B{\'e}nard convection) and three real dynamic systems (e.g., global water vapor patterns and western boundary currents). In these experiments, the KNO exhibits notable advantages compared with previous state-of-the-art models, suggesting the potential of the KNO in supporting diverse science and engineering applications (e.g., PDE solving, turbulence modelling, and precipitation forecasting).</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10022v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Xiong, Xiaomeng Huang, Ziyang Zhang, Ruixuan Deng, Pei Sun, Yang Tian</dc:creator>
    </item>
    <item>
      <title>Guaranteed Approximation Bounds for Mixed-Precision Neural Operators</title>
      <link>https://arxiv.org/abs/2307.15034</link>
      <description>arXiv:2307.15034v3 Announce Type: replace-cross 
Abstract: Neural operators, such as Fourier Neural Operators (FNO), form a principled approach for learning solution operators for PDEs and other mappings between function spaces. However, many real-world problems require high-resolution training data, and the training time and limited GPU memory pose big barriers. One solution is to train neural operators in mixed precision to reduce the memory requirement and increase training speed. However, existing mixed-precision training techniques are designed for standard neural networks, and we find that their direct application to FNO leads to numerical overflow and poor memory efficiency. Further, at first glance, it may appear that mixed precision in FNO will lead to drastic accuracy degradation since reducing the precision of the Fourier transform yields poor results in classical numerical solvers. We show that this is not the case; in fact, we prove that reducing the precision in FNO still guarantees a good approximation bound, when done in a targeted manner. Specifically, we build on the intuition that neural operator learning inherently induces an approximation error, arising from discretizing the infinite-dimensional ground-truth input function, implying that training in full precision is not needed. We formalize this intuition by rigorously characterizing the approximation and precision errors of FNO and bounding these errors for general input functions. We prove that the precision error is asymptotically comparable to the approximation error. Based on this, we design a simple method to optimize the memory-intensive half-precision tensor contractions by greedily finding the optimal contraction order. Through extensive experiments on different state-of-the-art neural operators, datasets, and GPUs, we demonstrate that our approach reduces GPU memory usage by up to 50% and improves throughput by 58% with little or no reduction in accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15034v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renbo Tu, Colin White, Jean Kossaifi, Boris Bonev, Nikola Kovachki, Gennady Pekhimenko, Kamyar Azizzadenesheli, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>GPLaSDI: Gaussian Process-based Interpretable Latent Space Dynamics Identification through Deep Autoencoder</title>
      <link>https://arxiv.org/abs/2308.05882</link>
      <description>arXiv:2308.05882v2 Announce Type: replace-cross 
Abstract: Numerically solving partial differential equations (PDEs) can be challenging and computationally expensive. This has led to the development of reduced-order models (ROMs) that are accurate but faster than full order models (FOMs). Recently, machine learning advances have enabled the creation of non-linear projection methods, such as Latent Space Dynamics Identification (LaSDI). LaSDI maps full-order PDE solutions to a latent space using autoencoders and learns the system of ODEs governing the latent space dynamics. By interpolating and solving the ODE system in the reduced latent space, fast and accurate ROM predictions can be made by feeding the predicted latent space dynamics into the decoder. In this paper, we introduce GPLaSDI, a novel LaSDI-based framework that relies on Gaussian process (GP) for latent space ODE interpolations. Using GPs offers two significant advantages. First, it enables the quantification of uncertainty over the ROM predictions. Second, leveraging this prediction uncertainty allows for efficient adaptive training through a greedy selection of additional training data points. This approach does not require prior knowledge of the underlying PDEs. Consequently, GPLaSDI is inherently non-intrusive and can be applied to problems without a known PDE or its residual. We demonstrate the effectiveness of our approach on the Burgers equation, Vlasov equation for plasma physics, and a rising thermal bubble problem. Our proposed method achieves between 200 and 100,000 times speed-up, with up to 7% relative error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05882v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2023.116535</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering, 418A, 116535, 2024</arxiv:journal_reference>
      <dc:creator>Christophe Bonneville, Youngsoo Choi, Debojyoti Ghosh, Jonathan L. Belof</dc:creator>
    </item>
  </channel>
</rss>
