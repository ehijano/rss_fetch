<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 01:56:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Two and three dimensional $H^2$-conforming finite element approximations without $C^1$-elements</title>
      <link>https://arxiv.org/abs/2406.00338</link>
      <description>arXiv:2406.00338v1 Announce Type: new 
Abstract: We develop a method to compute $H^2$-conforming finite element approximations in both two and three space dimensions using readily available finite element spaces. This is accomplished by deriving a novel, equivalent mixed variational formulation involving spaces with at most $H^1$-smoothness, so that conforming discretizations require at most $C^0$-continuity. The method is demonstrated on arbitrary order $C^1$-splines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00338v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Ainsworth, Charles Parker</dc:creator>
    </item>
    <item>
      <title>A brief review of Reduced Order Models using intrusive and non-intrusive techniques</title>
      <link>https://arxiv.org/abs/2406.00559</link>
      <description>arXiv:2406.00559v2 Announce Type: new 
Abstract: Reduced Order Models (ROMs) have gained a great attention by the scientific community in the last years thanks to their capabilities of significantly reducing the computational cost of the numerical simulations, which is a crucial objective in applications like real time control and shape optimization. This contribution aims to provide a brief overview about such a topic. We discuss both an intrusive framework based on a Galerkin projection technique and non-intrusive approaches, including Physics Informed Neural Networks (PINN), purely Data-Driven Neural Networks (DDNN), Radial Basis Functions (RBF), Dynamic Mode Decomposition (DMD) and Gaussian Process Regression (GPR). We also briefly mention geometrical parametrization and dimensionality reduction methods like Active Subspaces (AS). Then we present some results related to academic test cases as well as a preliminary investigation related to an industrial application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00559v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guglielmo Padula, Michele Girfoglio, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>On a perturbation analysis of Higham squared maximum Gaussian elimination growth matrices</title>
      <link>https://arxiv.org/abs/2406.00737</link>
      <description>arXiv:2406.00737v1 Announce Type: new 
Abstract: Gaussian elimination is the most popular technique for solving a dense linear system. Large errors in this procedure can occur in floating point arithmetic when the matrix's growth factor is large. We study this potential issue and how perturbations can improve the robustness of the Gaussian elimination algorithm. In their 1989 paper, Higham and Higham characterized the complete set of real n by n matrices that achieves the maximum growth factor under partial pivoting. This set of matrices serves as the critical focus of this work. Through theoretical insights and empirical results, we illustrate the high sensitivity of the growth factor of these matrices to perturbations and show how subtle changes can be strategically applied to matrix entries to significantly reduce the growth, thus enhancing computational stability and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00737v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Edelman, John Urschel, Bowen Zhu</dc:creator>
    </item>
    <item>
      <title>Graph Neural Preconditioners for Iterative Solutions of Sparse Linear Systems</title>
      <link>https://arxiv.org/abs/2406.00809</link>
      <description>arXiv:2406.00809v1 Announce Type: new 
Abstract: Preconditioning is at the heart of iterative solutions of large, sparse linear systems of equations in scientific disciplines. Several algebraic approaches, which access no information beyond the matrix itself, are widely studied and used, but ill-conditioned matrices remain very challenging. We take a machine learning approach and propose using graph neural networks as a general-purpose preconditioner. They show attractive performance for ill-conditioned problems, in part because they better approximate the matrix inverse from appropriately generated training data. Empirical evaluation on over 800 matrices suggests that the construction time of these graph neural preconditioners (GNPs) is more predictable than other widely used ones, such as ILU and AMG, while the execution time is faster than using a Krylov method as the preconditioner, such as in inner-outer GMRES. GNPs have a strong potential for solving large-scale, challenging algebraic problems arising from not only partial differential equations, but also economics, statistics, graph, and optimization, to name a few.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00809v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Chen</dc:creator>
    </item>
    <item>
      <title>A New Parallel-in-time Direct Inverse Method for Nonlinear Differential Equations</title>
      <link>https://arxiv.org/abs/2406.00878</link>
      <description>arXiv:2406.00878v1 Announce Type: new 
Abstract: We present a new approach to parallelization of the first-order backward difference discretization (BDF1) of the time derivative in partial differential equations, such as the nonlinear heat and viscous Burgers equations. The time derivative term is discretized by using the method of lines based on the implicit BDF1 scheme, while the inviscid and viscous terms are approximated by conventional 2nd-order 3-point central discretizations of the 1st- and 2nd-order derivatives in each spatial direction. The global system of nonlinear discrete equations in the space-time domain is solved by the Newton method for all time levels simultaneously. For the BDF1 discretization, this all-at-once system at each Newton iteration is block bidiagonal, which can be inverted directly in a blockwise manner, thus leading to a set of fully decoupled equations associated with each time level. This allows for an efficient parallel-in-time implementation of the implicit BDF1 discretization for nonlinear differential equations. The proposed parallel-in-time method preserves a quadratic rate of convergence of the Newton method of the sequential BDF1 scheme, so that the computational cost of solving each block matrix in parallel is nearly identical to that of the sequential counterpart at each time step. Numerical results show that the new parallel-in-time BDF1 scheme provides the speedup of up to 28 on 32 computing cores for the 2-D nonlinear partial differential equations with both smooth and discontinuous solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00878v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nail K. Yamaleev, Subhash Paudel</dc:creator>
    </item>
    <item>
      <title>Block $\omega$-circulant preconditioners for parabolic optimal control problems</title>
      <link>https://arxiv.org/abs/2406.00952</link>
      <description>arXiv:2406.00952v1 Announce Type: new 
Abstract: In this work, we propose a class of novel preconditioned Krylov subspace methods for solving an optimal control problem of parabolic equations. Namely, we develop a family of block $\omega$-circulant based preconditioners for the all-at-once linear system arising from the concerned optimal control problem, where both first order and second order time discretization methods are considered. The proposed preconditioners can be efficiently diagonalized by fast Fourier transforms in a parallel-in-time fashion, and their effectiveness is theoretically shown in the sense that the eigenvalues of the preconditioned matrix are clustered around $\pm 1$, which leads to rapid convergence when the minimal residual method is used. When the generalized minimal residual method is deployed, the efficacy of the proposed preconditioners are justified in the way that the singular values of the preconditioned matrices are proven clustered around unity. Numerical results are provided to demonstrate the effectiveness of our proposed solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00952v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Po Yin Fung, Sean Hon</dc:creator>
    </item>
    <item>
      <title>A High-Order Hybrid-Spectral Incompressible Navier-Stokes Model For Nonlinear Water Waves</title>
      <link>https://arxiv.org/abs/2406.00991</link>
      <description>arXiv:2406.00991v1 Announce Type: new 
Abstract: We present a new high-order accurate computational fluid dynamics model based on the incompressible Navier-Stokes equations with a free surface for the accurate simulation of nonlinear and dispersive water waves in the time domain. The spatial discretization is based on Chebyshev polynomials in the vertical direction and a Fourier basis in the horizontal direction, allowing for the use of the fast Chebyshev and Fourier transforms for the efficient computation of spatial derivatives. The temporal discretization is done through a generalized low-storage explicit 4th order Runge-Kutta, and for the scheme to conserve mass and achieve high-order accuracy, a velocity-pressure coupling needs to be satisfied at all Runge-Kutta stages. This result in the emergence of a Poisson pressure problem that constitute a geometric conservation law for mass conservation. The occurring Poisson problem is proposed to be solved efficiently via an accelerated iterative solver based on a geometric $p$-multigrid scheme, which takes advantage of the high-order polynomial basis in the spatial discretization and hence distinguishes itself from conventional low-order numerical schemes. We present numerical experiments for validation of the scheme in the context of numerical wave tanks demonstrating that the $p$-multigrid accelerated numerical scheme can effectively solve the Poisson problem that constitute the computational bottleneck, that the model can achieve the desired spectral convergence, and is capable of simulating wave-propagation over non-flat bottoms with excellent agreement in comparison to experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00991v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anders Melander, Max E. Bitsch, Dong Chen, Allan P. Engsig-Karup</dc:creator>
    </item>
    <item>
      <title>Explicit inverse of symmetric, tridiagonal near Toeplitz matrices with strictly diagonally dominant Toeplitz part</title>
      <link>https://arxiv.org/abs/2406.01035</link>
      <description>arXiv:2406.01035v1 Announce Type: new 
Abstract: This study investigates tridiagonal near-Toeplitz matrices in which the Toeplitz part is strictly diagonally dominant. The focus is on determining the exact inverse of these matrices and establishing upper bounds for the infinite norms of the inverse matrices. For cases with $b &gt; 2$ and $b &lt; -2$, we derive the compact form of the entries of the exact inverse. These results remain valid even when the matrices' corners are not diagonally dominant, specifically when $|\widetilde{b}| &lt; 1$.
  Furthermore, we calculate the traces and row sums of the inverse matrices. Afterwards, we present upper bound theorems for the infinite norms of the inverse matrices. To demonstrate the effectiveness of the bounds and their application, we provide numerical results for solving Fisher's problem.
  Our findings reveal that the converging rates of fixed-point iterations closely align with the expected rates, and there is minimal disparity between the upper bounds and infinite norm of the inverse matrix. Specifically, this observation holds true when $b &gt; 2$ with $\widetilde{b} \leq 1$ and $b &lt; -2$ with $\widetilde{b} \geq -1$. For other cases, there is potential for further improvement in the obtained upper bounds.
  This study contributes to the field of numerical analysis of fixed-point iterations by improving the convergence rate of iterations and reducing the computing time of the inverse matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01035v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bakytzhan Kurmanbek, Yogi Erlangga, Yerlan Amanbek</dc:creator>
    </item>
    <item>
      <title>Conforming Spline-Based Parameterisation Techniques for Plane Graphs</title>
      <link>https://arxiv.org/abs/2406.01347</link>
      <description>arXiv:2406.01347v1 Announce Type: new 
Abstract: This paper presents a spline-based parameterisation framework for plane graphs. The plane graph is characterised by a collection of curves forming closed loops that fence-off planar faces which have to be parameterised individually. Hereby, we focus on parameterisations that are conforming across the interfaces between the faces. Parameterising each face individually allows for the imposition of locally differing material parameters which has many applications in engineering applications, such as elasticity and heat transfer. For the parameterisation of the individual faces, we employ the concept of harmonic maps. The plane graph's spline-based parameterisation is suitable for numerical simulation based on isogeometric analysis or can be utilised to extract arbitrarily dense classical meshes. Application-specific features can be built into the geometry's mathematical description either on the spline level or in the mesh extraction step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01347v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jochen Hinz</dc:creator>
    </item>
    <item>
      <title>Computing the Action of the Generating Function of Bernoulli Polynomials on a Matrix with An Application to Non-local Boundary Value Problems</title>
      <link>https://arxiv.org/abs/2406.01437</link>
      <description>arXiv:2406.01437v1 Announce Type: new 
Abstract: This paper deals with efficient numerical methods for computing the action of the generating function of Bernoulli polynomials, say $q(\tau,w)$, on a typically large sparse matrix. This problem occurs when solving some non-local boundary value problems. Methods based on the Fourier expansion of $q(\tau,w)$ have already been addressed in the scientific literature. The contribution of this paper is twofold. First, we place these methods in the classical framework of Krylov-Lanczos (polynomial-rational) techniques for accelerating Fourier series. This allows us to apply the convergence results developed in this context to our function. Second, we design a new acceleration scheme. Some numerical results are presented to show the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01437v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Lidia Aceto, Luca Gemignani</dc:creator>
    </item>
    <item>
      <title>Non-splitting Eulerian-Lagrangian WENO schemes for two-dimensional nonlinear convection-diffusion equations</title>
      <link>https://arxiv.org/abs/2406.01479</link>
      <description>arXiv:2406.01479v1 Announce Type: new 
Abstract: In this paper, we develop high-order, conservative, non-splitting Eulerian-Lagrangian (EL) Runge-Kutta (RK) finite volume (FV) weighted essentially non-oscillatory (WENO) schemes for convection-diffusion equations. The proposed EL-RK-FV-WENO scheme defines modified characteristic lines and evolves the solution along them, significantly relaxing the time-step constraint for the convection term. The main algorithm design challenge arises from the complexity of constructing accurate and robust reconstructions on dynamically varying Lagrangian meshes. This reconstruction process is needed for flux evaluations on time-dependent upstream quadrilaterals and time integrations along moving characteristics. To address this, we propose a strategy that utilizes a WENO reconstruction on a fixed Eulerian mesh for spatial reconstruction, and updates intermediate solutions on the Eulerian background mesh for implicit-explicit RK temporal integration. This strategy leverages efficient reconstruction and remapping algorithms to manage the complexities of polynomial reconstructions on time-dependent quadrilaterals, while ensuring local mass conservation. The proposed scheme ensures mass conservation due to the flux-form semi-discretization and the mass-conservative reconstruction on both background and upstream cells. Extensive numerical tests have been performed to verify the effectiveness of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01479v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nanyi Zheng, Xiaofeng Cai, Jing-Mei Qiu, Jianxian Qiu</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal evolution of PM2.5 diffusion in Cheng-Yu urban agglomeration in response to COVID-19 lockdown using complex network</title>
      <link>https://arxiv.org/abs/2406.01502</link>
      <description>arXiv:2406.01502v1 Announce Type: new 
Abstract: As the decrease in human activities resulting from the COVID-19 control measures had a significant impact on air quality, the epidemic provided an opportunity to investigate the extent to which air pollution is influenced by human activities and review existing measures. However, the corresponding diffusion pattern on a city scale is seldom mentioned at present stage, therefore, we chose the Cheng-Yu urban agglomeration, which is the largest city cluster in Southwest China, as our study area during the COVID-19 period, and attempted to investigate the process of PM2.5 diffusion using a complex network method. The results displayed that there was an evident external spillover effect of PM2.5 across all regions, and the PM2.5 spillovers were concentrated in several cities in the Cheng-Yu urban agglomeration during the lockdown period, whereas they are more dispersed during the recovery period. The overall decline in the impact of PM2.5 pollution source areas on receptor areas from a normal year to the pandemic year, and the intensity of PM2.5 spillover decreases gradually as the distance from the center increases. The implementation of the lockdown measures had an impact on both the input and output patterns of PM2.5 pollution in the region, the input pattern of PM2.5 pollution exhibited higher vulnerability, while the output pattern showed higher resilience. Additionally, the spillover relationship of PM2.5 pollution varies between different blocks, with relatively simple spillover relationships observed during the lockdown period and more complex dynamics during the recovery period. These findings have highlighted the importance of joint controls in combating regional air pollution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01502v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxian Huang, Yi Huang, Yong Zhang, Jiao Zhang</dc:creator>
    </item>
    <item>
      <title>Feedback Stabilization and Finite Element Error Analysis of Viscous Burgers Equation around Non-Constant Steady State</title>
      <link>https://arxiv.org/abs/2406.01553</link>
      <description>arXiv:2406.01553v1 Announce Type: new 
Abstract: In this article, we explore the feedback stabilization of a viscous Burgers equation around a non-constant steady state using localized interior controls and then develop error estimates for the stabilized system using finite element method. The system is not only feedback stabilizable but exhibits an exponential decay $-\omega&lt;0$ for any $\omega&gt;0$. The derivation of a stabilizing control in feedback form is achieved by solving a suitable algebraic Riccati equation posed for the linearized system. In the second part of the article, we utilize a conforming finite element method to discretize the continuous system, resulting in a finite-dimensional discrete system. This approximated system is also proven to be feedback stabilizable (uniformly) with exponential decay $-\omega+\epsilon$ for any $\epsilon&gt;0$. The feedback control for this discrete system is obtained by solving a discrete algebraic Riccati equation. To validate the effectiveness of our approach, we provide error estimates for both the stabilized solutions and the stabilizing feedback controls. Numerical implementations are carried out to support and validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01553v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wasim Akram</dc:creator>
    </item>
    <item>
      <title>Learning Preconditioners for Inverse Problems</title>
      <link>https://arxiv.org/abs/2406.00260</link>
      <description>arXiv:2406.00260v1 Announce Type: cross 
Abstract: We explore the application of preconditioning in optimisation algorithms, specifically those appearing in Inverse Problems in imaging. Such problems often contain an ill-posed forward operator and are large-scale. Therefore, computationally efficient algorithms which converge quickly are desirable. To remedy these issues, learning-to-optimise leverages training data to accelerate solving particular optimisation problems. Many traditional optimisation methods use scalar hyperparameters, significantly limiting their convergence speed when applied to ill-conditioned problems. In contrast, we propose a novel approach that replaces these scalar quantities with matrices learned using data. Often, preconditioning considers only symmetric positive-definite preconditioners. However, we consider multiple parametrisations of the preconditioner, which do not require symmetry or positive-definiteness. These parametrisations include using full matrices, diagonal matrices, and convolutions. We analyse the convergence properties of these methods and compare their performance against classical optimisation algorithms. Generalisation performance of these methods is also considered, both for in-distribution and out-of-distribution data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00260v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Patrick Fahy, Mohammad Golbabaee</dc:creator>
    </item>
    <item>
      <title>Incompressible Navier-Stokes solve on noisy quantum hardware via a hybrid quantum-classical scheme</title>
      <link>https://arxiv.org/abs/2406.00280</link>
      <description>arXiv:2406.00280v1 Announce Type: cross 
Abstract: Partial differential equation solvers are required to solve the Navier-Stokes equations for fluid flow. Recently, algorithms have been proposed to simulate fluid dynamics on quantum computers. Fault-tolerant quantum devices might enable exponential speedups over algorithms on classical computers. However, current and upcoming quantum hardware presents noise in the computations, requiring algorithms that make modest use of quantum resources: shallower circuit depths and fewer qubits. Variational algorithms are more appropriate and robust under resource restrictions. This work presents a hybrid quantum-classical algorithm for the incompressible Navier-Stokes equations. Classical devices perform nonlinear computations, and quantum ones use variational algorithms to solve the pressure Poisson equation. A lid-driven cavity problem benchmarks the method. We verify the algorithm via noise-free simulation and test it on noisy IBM superconducting quantum hardware. Results show that high-fidelity results can be achieved via this approach, even on current quantum devices. A multigrid preconditioning approach helps avoid local minima. HTree, a tomography technique with linear complexity in qubit count, reduces the quantum state readout time. We compare the quantum resources required for near-term and fault-tolerant solvers to determine quantum hardware requirements for fluid simulations with complexity improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00280v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhixin Song, Robert Deaton, Bryan Gard, Spencer H. Bryngelson</dc:creator>
    </item>
    <item>
      <title>An Image Segmentation Model with Transformed Total Variation</title>
      <link>https://arxiv.org/abs/2406.00571</link>
      <description>arXiv:2406.00571v2 Announce Type: cross 
Abstract: Based on transformed $\ell_1$ regularization, transformed total variation (TTV) has robust image recovery that is competitive with other nonconvex total variation (TV) regularizers, such as TV$^p$, $0&lt;p&lt;1$. Inspired by its performance, we propose a TTV-regularized Mumford--Shah model with fuzzy membership function for image segmentation. To solve it, we design an alternating direction method of multipliers (ADMM) algorithm that utilizes the transformed $\ell_1$ proximal operator. Numerical experiments demonstrate that using TTV is more effective than classical TV and other nonconvex TV variants in image segmentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00571v2</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisha Dayag, Kevin Bui, Fredrick Park, Jack Xin</dc:creator>
    </item>
    <item>
      <title>The Biot-Allard poro-elasticity system: equivalent forms and well-posedness</title>
      <link>https://arxiv.org/abs/2406.01184</link>
      <description>arXiv:2406.01184v1 Announce Type: cross 
Abstract: We consider the fully dynamic Biot-Allard model, which includes memory effects. Convolution integrals in time model the history of the porous medium. We use a series representation of the dynamic permeability in the frequency domain to rewrite the equations in a coupled system without convolution integrals, suitable for the design of efficient numerical approximation schemes. The main result is the well-posedness of the system, proved by the abstract theory of R. Picard for evolutionary problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01184v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob S. Stokke, Markus Bause, Nils Margenberg, Florin A. Radu</dc:creator>
    </item>
    <item>
      <title>Aging modeling and lifetime prediction of a proton exchange membrane fuel cell using an extended Kalman filter</title>
      <link>https://arxiv.org/abs/2406.01259</link>
      <description>arXiv:2406.01259v1 Announce Type: cross 
Abstract: This article presents a methodology that aims to model and to provide predictive capabilities for the lifetime of Proton Exchange Membrane Fuel Cell (PEMFC). The approach integrates parametric identification, dynamic modeling, and Extended Kalman Filtering (EKF). The foundation is laid with the creation of a representative aging database, emphasizing specific operating conditions. Electrochemical behavior is characterized through the identification of critical parameters. The methodology extends to capture the temporal evolution of the identified parameters. We also address challenges posed by the limiting current density through a differential analysis-based modeling technique and the detection of breakpoints. This approach, involving Monte Carlo simulations, is coupled with an EKF for predicting voltage degradation. The Remaining Useful Life (RUL) is also estimated. The results show that our approach accurately predicts future voltage and RUL with very low relative errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01259v1</guid>
      <category>stat.AP</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serigne Daouda Pene, Antoine Picot, Fabrice Gamboa, Nicolas Savy, Christophe Turpin, Amine Jaafar</dc:creator>
    </item>
    <item>
      <title>Physics-informed deep learning and compressive collocation for high-dimensional diffusion-reaction equations: practical existence theory and numerics</title>
      <link>https://arxiv.org/abs/2406.01539</link>
      <description>arXiv:2406.01539v1 Announce Type: cross 
Abstract: On the forefront of scientific computing, Deep Learning (DL), i.e., machine learning with Deep Neural Networks (DNNs), has emerged a powerful new tool for solving Partial Differential Equations (PDEs). It has been observed that DNNs are particularly well suited to weakening the effect of the curse of dimensionality, a term coined by Richard E. Bellman in the late `50s to describe challenges such as the exponential dependence of the sample complexity, i.e., the number of samples required to solve an approximation problem, on the dimension of the ambient space. However, although DNNs have been used to solve PDEs since the `90s, the literature underpinning their mathematical efficiency in terms of numerical analysis (i.e., stability, accuracy, and sample complexity), is only recently beginning to emerge. In this paper, we leverage recent advancements in function approximation using sparsity-based techniques and random sampling to develop and analyze an efficient high-dimensional PDE solver based on DL. We show, both theoretically and numerically, that it can compete with a novel stable and accurate compressive spectral collocation method. In particular, we demonstrate a new practical existence theorem, which establishes the existence of a class of trainable DNNs with suitable bounds on the network architecture and a sufficient condition on the sample complexity, with logarithmic or, at worst, linear scaling in dimension, such that the resulting networks stably and accurately approximate a diffusion-reaction PDE with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01539v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Brugiapaglia, Nick Dexter, Samir Karam, Weiqi Wang</dc:creator>
    </item>
    <item>
      <title>Variational inequalities of multilayer elastic systems with interlayer friction: existence and uniqueness of solution and convergence of numerical solution</title>
      <link>https://arxiv.org/abs/2207.13260</link>
      <description>arXiv:2207.13260v2 Announce Type: replace 
Abstract: Based on the mathematical-physical model of pavement mechanics, a multilayer elastic system with interlayer friction conditions is constructed. Given the complex boundary conditions, the corresponding variational inequalities of the partial differential equations are derived, so that the problem can be analyzed under the variational framework. First, the existence and uniqueness of the solution of the variational inequality is proved; then the approximation error of the numerical solution based on the finite element method is analyzed, and when the finite element space satisfies certain approximation conditions, the convergence of the numerical solution is proved; finally, in the trivial finite element space, the convergence order of the numerical solution is derived. The above conclusions provide basic theoretical support for solving the displacement-strain problem of multilayer elastic systems under the framework of variational inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.13260v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhizhuo Zhang, Xiaobing Nie, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>A data-driven method for parametric PDE Eigenvalue Problems using Gaussian Process with different covariance functions</title>
      <link>https://arxiv.org/abs/2303.18064</link>
      <description>arXiv:2303.18064v4 Announce Type: replace 
Abstract: We use a Gaussian Process Regression (GPR) strategy that was recently developed [3,16,17] to analyze different types of curves that are commonly encountered in parametric eigenvalue problems. We employ an offline-online decomposition method. In the offline phase, we generate the basis of the reduced space by applying the proper orthogonal decomposition (POD) method on a collection of pre-computed, full-order snapshots at a chosen set of parameters. Then, we generate our GPR model using four different Mat\'{e}rn covariance functions. In the online phase, we use this model to predict both eigenvalues and eigenvectors at new parameters. We then illustrate how the choice of each covariance function influences the performance of GPR. Furthermore, we discuss the connection between Gaussian Process Regression and spline methods and compare the performance of the GPR method against linear and cubic spline methods. We show that GPR outperforms other methods for functions with a certain regularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.18064v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moataz Alghamdi, Fleurianne Bertrand, Daniele Boffi, Abdul Halim</dc:creator>
    </item>
    <item>
      <title>Discrete stochastic maximal $ L^p $-regularity and convergence of a spatial semidiscretization for a stochastic parabolic equation</title>
      <link>https://arxiv.org/abs/2311.04615</link>
      <description>arXiv:2311.04615v3 Announce Type: replace 
Abstract: This study demonstrates that the boundedness of the \( H^\infty \)-calculus for the negative discrete Laplace operator is independent of the spatial mesh size. Using this result, we deduce the discrete stochastic maximal \( L^p \)-regularity estimate for a spatial semidiscretization. Furthermore, we derive (nearly) sharp error estimates for the semidiscretization under the general spatial \( L^q \)-norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04615v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Binjie Li, Qin Zhou</dc:creator>
    </item>
    <item>
      <title>A Framework for Solving Parabolic Partial Differential Equations on Discrete Domains</title>
      <link>https://arxiv.org/abs/2312.00327</link>
      <description>arXiv:2312.00327v2 Announce Type: replace 
Abstract: We introduce a framework for solving a class of parabolic partial differential equations on triangle mesh surfaces, including the Hamilton-Jacobi equation and the Fokker-Planck equation. PDE in this class often have nonlinear or stiff terms that cannot be resolved with standard methods on curved triangle meshes. To address this challenge, we leverage a splitting integrator combined with a convex optimization step to solve these PDE. Our machinery can be used to compute entropic approximation of optimal transport distances on geometric domains, overcoming the numerical limitations of the state-of-the-art method. In addition, we demonstrate the versatility of our method on a number of linear and nonlinear PDE that appear in diffusion and front propagation tasks in geometry processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00327v2</guid>
      <category>math.NA</category>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3666087</arxiv:DOI>
      <dc:creator>Leticia Mattos Da Silva, Oded Stein, Justin Solomon</dc:creator>
    </item>
    <item>
      <title>High Resolution Optimized High-Order Schemes for Discretization of Non-Linear Straight and Mixed Second Derivative Terms</title>
      <link>https://arxiv.org/abs/2312.12069</link>
      <description>arXiv:2312.12069v2 Announce Type: replace 
Abstract: In this paper, we propose a new set of midpoint-based high-order discretization schemes for computing straight and mixed nonlinear second derivative terms that appear in the compressible Navier-Stokes equations. Firstly, we detail a set of conventional fourth and sixth-order baseline schemes that utilize central midpoint derivatives for the calculation of second derivatives terms. To enhance the spectral properties of the baseline schemes, an optimization procedure is proposed that adjusts the order and truncation error of the midpoint derivative approximation while still constraining the same overall stencil width and scheme order. A new filter penalty term is introduced into the midpoint derivative calculation to help achieve high wavenumber accuracy and high-frequency damping in the mixed derivative discretization. Fourier analysis performed on the both straight and mixed second derivative terms show high spectral efficiency and minimal numerical viscosity with no odd-even decoupling effect. Numerical validation of the resulting optimized schemes is performed through various benchmark test cases assessing their theoretical order of accuracy and solution resolution. The results highlight that the present optimized schemes efficiently utilize the inherent viscosity of the governing equations to achieve improved simulation stability - a feature attributed to their superior spectral resolution in the high wavenumber range. The method is also tested and applied to non-uniform structured meshes in curvilinear coordinates, employing a supersonic impinging jet test case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12069v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hemanth Chandravamsi, Steven H. Frankel</dc:creator>
    </item>
    <item>
      <title>Reduced Order Model Enhanced Source Iteration with Synthetic Acceleration for Parametric Radiative Transfer Equation</title>
      <link>https://arxiv.org/abs/2402.10488</link>
      <description>arXiv:2402.10488v3 Announce Type: replace 
Abstract: Applications such as uncertainty quantification and optical tomography, require solving the radiative transfer equation (RTE) many times for various parameters. Efficient solvers for RTE are highly desired.
  Source Iteration with Synthetic Acceleration (SISA) is a popular and successful iterative solver for RTE. Synthetic Acceleration (SA) acts as a preconditioning step to accelerate the convergence of Source Iteration (SI). After each source iteration, classical SA strategies introduce a correction to the macroscopic particle density by solving a low order approximation to a kinetic correction equation. For example, Diffusion Synthetic Acceleration (DSA) uses the diffusion limit. However, these strategies may become less effective when the underlying low order approximations are not accurate enough. Furthermore, they do not exploit low rank structures concerning the parameters of parametric problems.
  To address these issues, we propose enhancing SISA with data-driven ROMs for the parametric problem and the corresponding kinetic correction equation. First, the ROM for the parametric problem can be utilized to obtain an improved initial guess. Second, the ROM for the kinetic correction equation can be utilized to design a novel SA strategy called ROMSAD. In the early stage, ROMSAD adopts a ROM based approximation, which builds on the kinetic description of the correction equation and leverages low rank structures concerning the parameters. This ROM-based approximation has greater efficiency than DSA in the early stage of SI. In the later stage, ROMSAD automatically switches to DSA to leverage its robustness. Additionally, we propose an approach to construct the ROM for the kinetic correction equation without directly solving it.
  In a series of of numerical tests, we compare the performance of the proposed methods with SI-DSA and DSA preconditioned GMRES solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10488v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhichao Peng</dc:creator>
    </item>
    <item>
      <title>Hyper-differential sensitivity analysis with respect to model discrepancy: Posterior Optimal Solution Sampling</title>
      <link>https://arxiv.org/abs/2402.10957</link>
      <description>arXiv:2402.10957v2 Announce Type: replace 
Abstract: Optimization constrained by high-fidelity computational models has potential for transformative impact. However, such optimization is frequently unattainable in practice due to the complexity and computational intensity of the model. An alternative is to optimize a low-fidelity model and use limited evaluations of the high-fidelity model to assess the quality of the solution. This article develops a framework to use limited high-fidelity simulations to update the optimization solution computed using the low-fidelity model. Building off a previous article [22], which introduced hyper-differential sensitivity analysis with respect to model discrepancy, this article provides novel extensions of the algorithm to enable uncertainty quantification of the optimal solution update via a Bayesian framework. Specifically, we formulate a Bayesian inverse problem to estimate the model discrepancy and propagate the posterior model discrepancy distribution through the post-optimality sensitivity operator for the low-fidelity optimization problem. We provide a rigorous treatment of the Bayesian formulation, a computationally efficient algorithm to compute posterior samples, a guide to specify and interpret the algorithm hyper-parameters, and a demonstration of the approach on three examples which highlight various types of discrepancy between low and high-fidelity models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10957v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Hart, Bart van Bloemen Waanders</dc:creator>
    </item>
    <item>
      <title>Computing large deviation rate functions of entropy production for diffusion processes by an interacting particle method</title>
      <link>https://arxiv.org/abs/2403.19223</link>
      <description>arXiv:2403.19223v2 Announce Type: replace 
Abstract: We study an interacting particle method (IPM) for computing the large deviation rate function of entropy production for diffusion processes, with emphasis on the vanishing-noise limit and high dimensions. The crucial ingredient to obtain the rate function is the computation of the principal eigenvalue $\lambda$ of elliptic, non-self-adjoint operators. We show that this principal eigenvalue can be approximated in terms of the spectral radius of a discretized evolution operator obtained from an operator splitting scheme and an Euler--Maruyama scheme with a small time step size, and we show that this spectral radius can be accessed through a large number of iterations of this discretized semigroup, suitable for the IPM. The IPM applies naturally to problems in unbounded domains, scales easily to high dimensions, and adapts to singular behaviors in the vanishing-noise limit. We show numerical examples in dimensions up to 16. The numerical results show that our numerical approximation of $\lambda$ converges to the analytical vanishing-noise limit within visual tolerance with a fixed number of particles and a fixed time step size. Our paper appears to be the first one to obtain numerical results of principal eigenvalue problems for non-self-adjoint operators in such high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19223v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhizhang Wu, Renaud Raqu\'epas, Jack Xin, Zhiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Structure-preserving neural networks for the regularized entropy-based closure of the Boltzmann moment system</title>
      <link>https://arxiv.org/abs/2404.14312</link>
      <description>arXiv:2404.14312v3 Announce Type: replace 
Abstract: The main challenge of large-scale numerical simulation of radiation transport is the high memory and computation time requirements of discretization methods for kinetic equations. In this work, we derive and investigate a neural network-based approximation to the entropy closure method to accurately compute the solution of the multi-dimensional moment system with a low memory footprint and competitive computational time. We extend methods developed for the standard entropy-based closure to the context of regularized entropy-based closures. The main idea is to interpret structure-preserving neural network approximations of the regularized entropy closure as a two-stage approximation to the original entropy closure. We conduct a numerical analysis of this approximation and investigate optimal parameter choices. Our numerical experiments demonstrate that the method has a much lower memory footprint than traditional methods with competitive computation times and simulation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14312v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steffen Schotth\"ofer, M. Paul Laiu, Martin Frank, Cory D. Hauck</dc:creator>
    </item>
    <item>
      <title>How to reveal the rank of a matrix?</title>
      <link>https://arxiv.org/abs/2405.04330</link>
      <description>arXiv:2405.04330v2 Announce Type: replace 
Abstract: We study algorithms called rank-revealers that reveal a matrix's rank structure. Such algorithms form a fundamental component in matrix compression, singular value estimation, and column subset selection problems. While column-pivoted QR has been widely adopted due to its practicality, it is not always a rank-revealer. Conversely, Gaussian elimination (GE) with a pivoting strategy known as global maximum volume pivoting is guaranteed to estimate a matrix's singular values but its exponential complexity limits its interest to theory. We show that the concept of local maximum volume pivoting is a crucial and practical pivoting strategy for rank-revealers based on GE and QR. In particular, we prove that it is both necessary and sufficient; highlighting that all local solutions are nearly as good as the global one. This insight elevates Gu and Eisenstat's rank-revealing QR as an archetypal rank-revealer, and we implement a version that is observed to be at most $2\times$ more computationally expensive than CPQR. We unify the landscape of rank-revealers by considering GE and QR together and prove that the success of any pivoting strategy can be assessed by benchmarking it against a local maximum volume pivot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04330v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anil Damle, Silke Glas, Alex Townsend, Annan Yu</dc:creator>
    </item>
    <item>
      <title>Randomized quasi-Monte Carlo and Owen's boundary growth condition: A spectral analysis</title>
      <link>https://arxiv.org/abs/2405.05181</link>
      <description>arXiv:2405.05181v2 Announce Type: replace 
Abstract: In this work, we analyze the convergence rate of randomized quasi-Monte Carlo (RQMC) methods under Owen's boundary growth condition [Owen, 2006] via spectral analysis. Specifically, we examine the RQMC estimator variance for the two commonly studied sequences: the lattice rule and the Sobol' sequence, applying the Fourier transform and Walsh--Fourier transform, respectively, for this analysis. Assuming certain regularity conditions, our findings reveal that the asymptotic convergence rate of the RQMC estimator's variance closely aligns with the exponent specified in Owen's boundary growth condition for both sequence types. We also provide analysis for certain discontinuous integrands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05181v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Liu</dc:creator>
    </item>
    <item>
      <title>Space-time deep neural network approximations for high-dimensional partial differential equations</title>
      <link>https://arxiv.org/abs/2006.02199</link>
      <description>arXiv:2006.02199v2 Announce Type: replace-cross 
Abstract: It is one of the most challenging issues in applied mathematics to approximately solve high-dimensional partial differential equations (PDEs) and most of the numerical approximation methods for PDEs in the scientific literature suffer from the so-called curse of dimensionality in the sense that the number of computational operations employed in the corresponding approximation scheme to obtain an approximation precision $\varepsilon&gt;0$ grows exponentially in the PDE dimension and/or the reciprocal of $\varepsilon$. Recently, certain deep learning based approximation methods for PDEs have been proposed and various numerical simulations for such methods suggest that deep neural network (DNN) approximations might have the capacity to indeed overcome the curse of dimensionality in the sense that the number of real parameters used to describe the approximating DNNs grows at most polynomially in both the PDE dimension $d\in\mathbb{N}$ and the reciprocal of the prescribed accuracy $\varepsilon&gt;0$. There are now also a few rigorous results in the scientific literature which substantiate this conjecture by proving that DNNs overcome the curse of dimensionality in approximating solutions of PDEs. Each of these results establishes that DNNs overcome the curse of dimensionality in approximating suitable PDE solutions at a fixed time point $T&gt;0$ and on a compact cube $[a,b]^d$ in space but none of these results provides an answer to the question whether the entire PDE solution on $[0,T]\times [a,b]^d$ can be approximated by DNNs without the curse of dimensionality. It is precisely the subject of this article to overcome this issue. More specifically, the main result of this work in particular proves for every $a\in\mathbb{R}$, $ b\in (a,\infty)$ that solutions of certain Kolmogorov PDEs can be approximated by DNNs on the space-time region $[0,T]\times [a,b]^d$ without the curse of dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.02199v2</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Hornung, Arnulf Jentzen, Diyora Salimova</dc:creator>
    </item>
    <item>
      <title>Smooth Surfaces via Nets of Geodesics</title>
      <link>https://arxiv.org/abs/2109.01429</link>
      <description>arXiv:2109.01429v3 Announce Type: replace-cross 
Abstract: The goal of this study is to provide a method for computing the following: Given a network of curves in 3d (satisfying a condition at the intersection points), compute efficiently a smooth surface such that the curves are geodesics on it. This work can serve as a base for engineers who wish to implement computations of such surfaces in Computer Aided Design (CAD) software or other applications. The motivation for this study was the following hypothesis and observation together with the desire to improve CAD interfaces. The hypothesis and observation is that artists draw projections of geodesics to illustrate 3d objects: for example projections of nets of curves can be seen in drawings of Rembrandt. In addition, this observation is supported by research in cognitive sciences: in a seminal work by the late David Knill he suggested that the human visual system incorporates a geodesic constraint in the processing of reflected contours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.01429v3</guid>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Gilat</dc:creator>
    </item>
    <item>
      <title>Consistency of semi-supervised learning, stochastic tug-of-war games, and the p-Laplacian</title>
      <link>https://arxiv.org/abs/2401.07463</link>
      <description>arXiv:2401.07463v2 Announce Type: replace-cross 
Abstract: In this paper we give a broad overview of the intersection of partial differential equations (PDEs) and graph-based semi-supervised learning. The overview is focused on a large body of recent work on PDE continuum limits of graph-based learning, which have been used to prove well-posedness of semi-supervised learning algorithms in the large data limit. We highlight some interesting research directions revolving around consistency of graph-based semi-supervised learning, and present some new results on the consistency of $p$-Laplacian semi-supervised learning using the stochastic tug-of-war game interpretation of the $p$-Laplacian. We also present the results of some numerical experiments that illustrate our results and suggest directions for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07463v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeff Calder, Nadejda Drenska</dc:creator>
    </item>
    <item>
      <title>Equivariant Graph Neural Operator for Modeling 3D Dynamics</title>
      <link>https://arxiv.org/abs/2401.11037</link>
      <description>arXiv:2401.11037v2 Announce Type: replace-cross 
Abstract: Modeling the complex three-dimensional (3D) dynamics of relational systems is an important problem in the natural sciences, with applications ranging from molecular simulations to particle mechanics. Machine learning methods have achieved good success by learning graph neural networks to model spatial interactions. However, these approaches do not faithfully capture temporal correlations since they only model next-step predictions. In this work, we propose Equivariant Graph Neural Operator (EGNO), a novel and principled method that directly models dynamics as trajectories instead of just next-step prediction. Different from existing methods, EGNO explicitly learns the temporal evolution of 3D dynamics where we formulate the dynamics as a function over time and learn neural operators to approximate it. To capture the temporal correlations while keeping the intrinsic SE(3)-equivariance, we develop equivariant temporal convolutions parameterized in the Fourier space and build EGNO by stacking the Fourier layers over equivariant networks. EGNO is the first operator learning framework that is capable of modeling solution dynamics functions over time while retaining 3D equivariance. Comprehensive experiments in multiple domains, including particle simulations, human motion capture, and molecular dynamics, demonstrate the significantly superior performance of EGNO against existing methods, thanks to the equivariant temporal modeling. Our code is available at https://github.com/MinkaiXu/egno.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11037v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minkai Xu, Jiaqi Han, Aaron Lou, Jean Kossaifi, Arvind Ramanathan, Kamyar Azizzadenesheli, Jure Leskovec, Stefano Ermon, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>Transolver: A Fast Transformer Solver for PDEs on General Geometries</title>
      <link>https://arxiv.org/abs/2402.02366</link>
      <description>arXiv:2402.02366v2 Announce Type: replace-cross 
Abstract: Transformers have empowered many milestones across various fields and have recently been applied to solve partial differential equations (PDEs). However, since PDEs are typically discretized into large-scale meshes with complex geometries, it is challenging for Transformers to capture intricate physical correlations directly from massive individual points. Going beyond superficial and unwieldy meshes, we present Transolver based on a more foundational idea, which is learning intrinsic physical states hidden behind discretized geometries. Specifically, we propose a new Physics-Attention to adaptively split the discretized domain into a series of learnable slices of flexible shapes, where mesh points under similar physical states will be ascribed to the same slice. By calculating attention to physics-aware tokens encoded from slices, Transovler can effectively capture intricate physical correlations under complex geometrics, which also empowers the solver with endogenetic geometry-general modeling capacity and can be efficiently computed in linear complexity. Transolver achieves consistent state-of-the-art with 22% relative gain across six standard benchmarks and also excels in large-scale industrial simulations, including car and airfoil designs. Code is available at https://github.com/thuml/Transolver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02366v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haixu Wu, Huakun Luo, Haowen Wang, Jianmin Wang, Mingsheng Long</dc:creator>
    </item>
    <item>
      <title>The sequence of pseudo-equilibria describes the long-time behaviour of the NNLIF model with large delay</title>
      <link>https://arxiv.org/abs/2403.00971</link>
      <description>arXiv:2403.00971v2 Announce Type: replace-cross 
Abstract: There is a wide range of mathematical models that describe populations of large numbers of neurons. In this article, we focus on nonlinear noisy leaky integrate and fire (NNLIF) models that describe neuronal activity at the level of the membrane potential of neurons. We introduce a set of novel states, which we call "pseudo-equilibria", and give evidence of their defining role in the behaviour of the NNLIF system when a significant synaptic delay is considered. The advantage is that these states are determined solely by the system's parameters and are derived from a sequence of firing rates that result from solving a recurrence equation. We propose a new strategy to show convergence to an equilibrium for a weakly connected system with large transmission delay, based on following the sequence of pseudo-equilibria. Unlike with the direct entropy dissipation method, this technique allows us to see how a large delay favours convergence. We also present a detailed numerical study to support our results. This study explores the overall behaviour of the NNLIF system and helps us understand, among other phenomena, periodic solutions in strongly inhibitory networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00971v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mar\'ia J. C\'aceres, Jos\'e A. Ca\~nizo, Alejandro Ramos-Lora</dc:creator>
    </item>
    <item>
      <title>Shadow Hamiltonians of structure-preserving integrators for Nambu mechanics</title>
      <link>https://arxiv.org/abs/2403.11612</link>
      <description>arXiv:2403.11612v2 Announce Type: replace-cross 
Abstract: Symplectic integrators are widely implemented numerical integrators for Hamiltonian mechanics, which preserve the Hamiltonian structure (symplecticity) of the system. Although the symplectic integrator does not conserve the energy of the system, it is well known that there exists a conserving modified Hamiltonian, called the shadow Hamiltonian. For the Nambu mechanics, which is a kind of generalized Hamiltonian mechanics, we can also construct structure-preserving integrators by the same procedure used to construct the symplectic integrators. In the structure-preserving integrator, however, the existence of shadow Hamiltonians is nontrivial. This is because the Nambu mechanics is driven by multiple Hamiltonians and it is nontrivial whether the time evolution by the integrator can be cast into the Nambu mechanical time evolution driven by multiple shadow Hamiltonians. In this paper we present a general procedure to calculate the shadow Hamiltonians of structure-preserving integrators for Nambu mechanics, and give an example where the shadow Hamiltonians exist. This is the first attempt to determine the concrete forms of the shadow Hamiltonians for a Nambu mechanical system. We show that the fundamental identity, which corresponds to the Jacobi identity in Hamiltonian mechanics, plays an important role in calculating the shadow Hamiltonians using the Baker-Campbell-Hausdorff formula. It turns out that the resulting shadow Hamiltonians have indefinite forms depending on how the fundamental identities are used. This is not a technical artifact, because the exact shadow Hamiltonians obtained independently have the same indefiniteness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11612v2</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/ptep/ptae067</arxiv:DOI>
      <arxiv:journal_reference>Prog. Theor. Exp. Phys. 2024, 053A05 (2024)</arxiv:journal_reference>
      <dc:creator>Atsushi Horikoshi</dc:creator>
    </item>
    <item>
      <title>A finite operator learning technique for mapping the elastic properties of microstructures to their mechanical deformations</title>
      <link>https://arxiv.org/abs/2404.00074</link>
      <description>arXiv:2404.00074v2 Announce Type: replace-cross 
Abstract: To obtain fast solutions for governing physical equations in solid mechanics, we introduce a method that integrates the core ideas of the finite element method with physics-informed neural networks and concept of neural operators. This approach generalizes and enhances each method, learning the parametric solution for mechanical problems without relying on data from other resources (e.g. other numerical solvers). We propose directly utilizing the available discretized weak form in finite element packages to construct the loss functions algebraically, thereby demonstrating the ability to find solutions even in the presence of sharp discontinuities. Our focus is on micromechanics as an example, where knowledge of deformation and stress fields for a given heterogeneous microstructure is crucial for further design applications. The primary parameter under investigation is the Young's modulus distribution within the heterogeneous solid system. Our investigations reveal that physics-based training yields higher accuracy compared to purely data-driven approaches for unseen microstructures. Additionally, we offer two methods to directly improve the process of obtaining high-resolution solutions, avoiding the need to use basic interpolation techniques. First is based on an autoencoder approach to enhance the efficiency for calculation on high resolution grid point. Next, Fourier-based parametrization is utilized to address complex 2D and 3D problems in micromechanics. The latter idea aims to represent complex microstructures efficiently using Fourier coefficients. Comparisons with other well-known operator learning algorithms, further emphasize the advantages of the newly proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00074v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shahed Rezaei, Reza Najian Asl, Shirko Faroughi, Mahdi Asgharzadeh, Ali Harandi, Rasoul Najafi Koopas, Gottfried Laschet, Stefanie Reese, Markus Apel</dc:creator>
    </item>
    <item>
      <title>Skew-symmetric schemes for stochastic differential equations with non-Lipschitz drift: an unadjusted Barker algorithm</title>
      <link>https://arxiv.org/abs/2405.14373</link>
      <description>arXiv:2405.14373v2 Announce Type: replace-cross 
Abstract: We propose a new simple and explicit numerical scheme for time-homogeneous stochastic differential equations. The scheme is based on sampling increments at each time step from a skew-symmetric probability distribution, with the level of skewness determined by the drift and volatility of the underlying process. We show that as the step-size decreases the scheme converges weakly to the diffusion of interest. We then consider the problem of simulating from the limiting distribution of an ergodic diffusion process using the numerical scheme with a fixed step-size. We establish conditions under which the numerical scheme converges to equilibrium at a geometric rate, and quantify the bias between the equilibrium distributions of the scheme and of the true diffusion process. Notably, our results do not require a global Lipschitz assumption on the drift, in contrast to those required for the Euler--Maruyama scheme for long-time simulation at fixed step-sizes. Our weak convergence result relies on an extension of the theory of Milstein \&amp; Tretyakov to stochastic differential equations with non-Lipschitz drift, which could also be of independent interest. We support our theoretical results with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14373v2</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Livingstone, Nikolas N\"usken, Giorgos Vasdekis, Rui-Yang Zhang</dc:creator>
    </item>
    <item>
      <title>Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers</title>
      <link>https://arxiv.org/abs/2405.17527</link>
      <description>arXiv:2405.17527v2 Announce Type: replace-cross 
Abstract: Deep models have recently emerged as a promising tool to solve partial differential equations (PDEs), known as neural PDE solvers. While neural solvers trained from either simulation data or physics-informed loss can solve the PDEs reasonably well, they are mainly restricted to a specific set of PDEs, e.g. a certain equation or a finite set of coefficients. This bottleneck limits the generalizability of neural solvers, which is widely recognized as its major advantage over numerical solvers. In this paper, we present the Universal PDE solver (Unisolver) capable of solving a wide scope of PDEs by leveraging a Transformer pre-trained on diverse data and conditioned on diverse PDEs. Instead of simply scaling up data and parameters, Unisolver stems from the theoretical analysis of the PDE-solving process. Our key finding is that a PDE solution is fundamentally under the control of a series of PDE components, e.g. equation symbols, coefficients, and initial and boundary conditions. Inspired by the mathematical structure of PDEs, we define a complete set of PDE components and correspondingly embed them as domain-wise (e.g. equation symbols) and point-wise (e.g. boundaries) conditions for Transformer PDE solvers. Integrating physical insights with recent Transformer advances, Unisolver achieves consistent state-of-the-art results on three challenging large-scale benchmarks, showing impressive gains and endowing favorable generalizability and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17527v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hang Zhou, Yuezhou Ma, Haixu Wu, Haowen Wang, Mingsheng Long</dc:creator>
    </item>
  </channel>
</rss>
