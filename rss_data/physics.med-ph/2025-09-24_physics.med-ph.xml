<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Sep 2025 01:47:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Comparison of Adaptive plan doses using Velocity generated synthetic CT with KV CBCT and re-planning CT</title>
      <link>https://arxiv.org/abs/2509.18307</link>
      <description>arXiv:2509.18307v1 Announce Type: new 
Abstract: Introduction: This study uses KV CBCT based Synthetic CT (sCT) generated through Velocity workstation and compare the target and normal tissue doses with Adaptive plan CT doses.
  Methods: Thirty head and neck cancer patients undergoing Adaptive Radiation Therapy (ART) were included in this retrospective study. Initially, patient underwent treatment with the primary plan. After subsequent indications of major changes in patients' physicality and anatomy adaptive CT scans were acquired as per institutional protocol. Both the primary planning CT and the indicative cone-beam CT (CBCT) last acquired before the commencement of the adaptive treatment were imported into Velocity workstation. Rigid and deformable image registration techniques were used for the generation of a Synthetic CT (sCT). Simultaneously replanning was done on re-planning CT (rCT) for adaptive plan execution. The primary plan dose was subsequently mapped and deformed onto the Synthetic CT in Velocity workstation, allowing for a comparative dosimetric analysis between the sCT and rCT plan doses. This comparison was conducted in both Velocity and Eclipse, focusing on dose variations across different organs at risk (OARs) and the planning target volume (PTV). Additionally, dosimetric indices were evaluated to assess and validate the accuracy and quality of the synthetic CT-based dose mapping relative to adaptive planning.
  Results: The dosimetric comparison between sCT and rCT stated that Mean dose for OARs and PTVs were found to be similar in the two planning and the level of confidence by using T-statistics. Collaborative research has the potential to eliminate the need of rCT as a standard requirement.
  Conclusion: The sCT shows comparable CT numbers and doses to the replanning CT, suggesting it's potential as a replacement pending clinical correlation and contour adjustments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18307v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sudam Masanta, Gurvinder Singh, Shefali Pahwa, Shekhar Dwivedi, Devaraju Sampathirao, Ramandeep Singh</dc:creator>
    </item>
    <item>
      <title>Neural Network-Driven Direct CBCT-Based Dose Calculation for Head-and-Neck Proton Treatment Planning</title>
      <link>https://arxiv.org/abs/2509.18378</link>
      <description>arXiv:2509.18378v1 Announce Type: new 
Abstract: Accurate dose calculation on cone beam computed tomography (CBCT) images is essential for modern proton treatment planning workflows, particularly when accounting for inter-fractional anatomical changes in adaptive treatment scenarios. Traditional CBCT-based dose calculation suffers from image quality limitations, requiring complex correction workflows. This study develops and validates a deep learning approach for direct proton dose calculation from CBCT images using extended Long Short-Term Memory (xLSTM) neural networks. A retrospective dataset of 40 head-and-neck cancer patients with paired planning CT and treatment CBCT images was used to train an xLSTM-based neural network (CBCT-NN). The architecture incorporates energy token encoding and beam's-eye-view sequence modelling to capture spatial dependencies in proton dose deposition patterns. Training utilized 82,500 paired beam configurations with Monte Carlo-generated ground truth doses. Validation was performed on 5 independent patients using gamma analysis, mean percentage dose error assessment, and dose-volume histogram comparison. The CBCT-NN achieved gamma pass rates of 95.1 $\pm$ 2.7% using 2mm/2% criteria. Mean percentage dose errors were 2.6 $\pm$ 1.4% in high-dose regions ($&gt;$90% of max dose) and 5.9 $\pm$ 1.9% globally. Dose-volume histogram analysis showed excellent preservation of target coverage metrics (Clinical Target Volume V95% difference: -0.6 $\pm$ 1.1%) and organ-at-risk constraints (parotid mean dose difference: -0.5 $\pm$ 1.5%). Computation time is under 3 minutes without sacrificing Monte Carlo-level accuracy. This study demonstrates the proof-of-principle of direct CBCT-based proton dose calculation using xLSTM neural networks. The approach eliminates traditional correction workflows while achieving comparable accuracy and computational efficiency suitable for adaptive protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18378v1</guid>
      <category>physics.med-ph</category>
      <category>cs.CV</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muheng Li, Evangelia Choulilitsa, Lisa Fankhauser, Francesca Albertini, Antony Lomax, Ye Zhang</dc:creator>
    </item>
    <item>
      <title>Digital Twins of Mechanically Ventilated Preterm Neonates with Respiratory Distress Syndrome</title>
      <link>https://arxiv.org/abs/2509.18999</link>
      <description>arXiv:2509.18999v1 Announce Type: new 
Abstract: Background: Mechanical ventilation is life-saving for preterm infants with respiratory distress syndrome but can also contribute to lung injury and long-term morbidity. Protective ventilation strategies are recommended, yet implementation in neonatal intensive care units remains inconsistent, and infants continue to be exposed to injurious ventilator settings. Objective: To develop and validate a cohort of neonatal digital twins, based on mechanistic models of cardiopulmonary physiology calibrated to individual patient data, as a tool for simulating and optimising protective ventilation strategies. Methods: A high-fidelity computational simulator of human cardiopulmonary physiology was adapted to neonatal-specific parameters, including lung compliance, dead space, pulmonary vascular resistance, oxygen consumption, and fetal haemoglobin oxygen affinity. Digital twins were generated using data at 65 time points from 11 preterm neonates receiving volume-controlled ventilation. Model parameters were calibrated to minimise the error between simulated and observed PaO2, PaCO2, and peak inspiratory pressure (PIP). Results: Digital twins reproduced measured data with mean absolute percentage errors of 3.9% (PaO2), 3.0% (PaCO2), and 5.8% (PIP) across the cohort. Predictions for uncalibrated variables (pHa, SaO2, mean and minimum airway pressure) also showed high accuracy, with errors &lt;5%. Strong correlations and narrow limits of agreement were observed across all patients and time points. Conclusions: This study demonstrates, for the first time, the feasibility of creating fully mechanistic digital twins of mechanically ventilated neonates with RDS. The twins accurately captured patient-specific gas exchange and respiratory mechanics, supporting their potential as a platform for conducting virtual clinical trials and for the design of individualized, lung-protective ventilation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18999v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sina Saffaran, Tng Chang Kwok, Don Sharkey, Declan G. Bates</dc:creator>
    </item>
    <item>
      <title>A Low-cost Quasi-planar Array Probe for Photoacoustic Imaging</title>
      <link>https://arxiv.org/abs/2509.19268</link>
      <description>arXiv:2509.19268v1 Announce Type: new 
Abstract: Photoacoustic imaging (PAI) is a novel hybrid imaging technique that combines the benefits of both optical and acoustic imaging modalities, which provides functional and molecular optical contrasts of deep tissue. Commonly used ultrasound transducers for PAI include linear and planar arrays, which can provide two-dimensional (2D) and three-dimensional (3D) image reconstruction, respectively. However, linear arrays cannot provide reconstruction of 3D images, which makes it impossible to locate chromophores in 3D space. Although planar array can provide fast 3D imaging in real time, it usually requires thousands of analog-to-digital conversion channels for data acquisition, which is costly. To fill the gap between 2D and 3D PAI, we propose a quasi-planar array that uses double 16-elements-linear arrays arranged in parallel to achieve real-time 3D imaging. We first conducted simulation studies to prove that the quasi-planar probe can perform 3D imaging to localize simple chromophores. Then, the agarose phantom experiment demonstrated that the probe can reconstruct 3D imaging of multiple absorbers in different depths. A potential application of this device is to provide a low-cost 3D PAI solution for fast tracking of needle tip during needle biopsy, which will be further explored in our future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19268v1</guid>
      <category>physics.med-ph</category>
      <category>eess.SP</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiyu Chen, Junxiang Cai, Rui Zheng, Tao Wu, Fei Gao</dc:creator>
    </item>
    <item>
      <title>CPT-4DMR: Continuous sPatial-Temporal Representation for 4D-MRI Reconstruction</title>
      <link>https://arxiv.org/abs/2509.18427</link>
      <description>arXiv:2509.18427v1 Announce Type: cross 
Abstract: Four-dimensional MRI (4D-MRI) is an promising technique for capturing respiratory-induced motion in radiation therapy planning and delivery. Conventional 4D reconstruction methods, which typically rely on phase binning or separate template scans, struggle to capture temporal variability, complicate workflows, and impose heavy computational loads. We introduce a neural representation framework that considers respiratory motion as a smooth, continuous deformation steered by a 1D surrogate signal, completely replacing the conventional discrete sorting approach. The new method fuses motion modeling with image reconstruction through two synergistic networks: the Spatial Anatomy Network (SAN) encodes a continuous 3D anatomical representation, while a Temporal Motion Network (TMN), guided by Transformer-derived respiratory signals, produces temporally consistent deformation fields. Evaluation using a free-breathing dataset of 19 volunteers demonstrates that our template- and phase-free method accurately captures both regular and irregular respiratory patterns, while preserving vessel and bronchial continuity with high anatomical fidelity. The proposed method significantly improves efficiency, reducing the total processing time from approximately five hours required by conventional discrete sorting methods to just 15 minutes of training. Furthermore, it enables inference of each 3D volume in under one second. The framework accurately reconstructs 3D images at any respiratory state, achieves superior performance compared to conventional methods, and demonstrates strong potential for application in 4D radiation therapy planning and real-time adaptive treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18427v1</guid>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyang Wu, Muheng Li, Xia Li, Orso Pusterla, Sairos Safai, Philippe C. Cattin, Antony J. Lomax, Ye Zhang</dc:creator>
    </item>
  </channel>
</rss>
