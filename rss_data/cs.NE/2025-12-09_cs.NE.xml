<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Dec 2025 02:42:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Multi-objective Optimization Approach for Feature Selection in Gentelligent Systems</title>
      <link>https://arxiv.org/abs/2512.05971</link>
      <description>arXiv:2512.05971v1 Announce Type: new 
Abstract: The integration of advanced technologies, such as Artificial Intelligence (AI), into manufacturing processes is attracting significant attention, paving the way for the development of intelligent systems that enhance efficiency and automation. This paper uses the term "Gentelligent system" to refer to systems that incorporate inherent component information (akin to genes in bioinformatics-where manufacturing operations are likened to chromosomes in this study) and automated mechanisms. By implementing reliable fault detection methods, manufacturers can achieve several benefits, including improved product quality, increased yield, and reduced production costs. To support these objectives, we propose a hybrid framework with a dominance-based multi-objective evolutionary algorithm. This mechanism enables simultaneous optimization of feature selection and classification performance by exploring Pareto-optimal solutions in a single run. This solution helps monitor various manufacturing operations, addressing a range of conflicting objectives that need to be minimized together. Manufacturers can leverage such predictive methods and better adapt to emerging trends. To strengthen the validation of our model, we incorporate two real-world datasets from different industrial domains. The results on both datasets demonstrate the generalizability and effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05971v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2025.3629076</arxiv:DOI>
      <dc:creator>Mohammadhossein Ghahramani, Yan Qiao, NaiQi Wu, Mengchu Zhou</dc:creator>
    </item>
    <item>
      <title>SEB-ChOA: An Improved Chimp Optimization Algorithm Using Spiral Exploitation Behavior</title>
      <link>https://arxiv.org/abs/2512.05981</link>
      <description>arXiv:2512.05981v1 Announce Type: new 
Abstract: The chimp optimization algorithm (ChOA) is a nature-inspired algorithm that imitates chimpanzees' individual intelligence and hunting behaviors. In this algorithm, the hunting process consists of four steps: driving, blocking, chasing, and attacking. Because of the novelty of ChOA, the steps of the hunting process have been modeled in a simple way, leading to slow and premature convergence similar to other iterative algorithms. This paper proposes six spiral functions and introduces two novel hybrid spiral functions (SEB-ChOA) to address these deficiencies. The performance of SEB-ChOA is evaluated on 23 standard benchmarks, 20 benchmarks of the IEEE CEC-2005 test suite, 10 cases from the IEEE CEC06-2019 test suite, and 12 constrained real-world engineering problems from IEEE CEC-2020. The SEB-ChOA variants are compared with three groups of optimization algorithms, including Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) as well-known optimizers; Slime Mould Algorithm (SMA), Marine Predators Algorithm (MPA), Ant Lion Optimization (ALO), and Henry Gas Solubility Optimization (HGSO) as recently developed optimizers; and jDE100 and DISHchain1e+12, the winners of the IEEE CEC06-2019 competition. Additional comparisons are made with EBOwithCMAR and CIPDE as strong secondary baselines. The SEB-ChOA methods achieve top-ranked results on nearly all benchmarks and show competitive performance compared to jDE100 and DISHchain1e+12. Statistical results indicate that SEB-ChOA outperforms PSO, GA, SMA, MPA, ALO, and HGSO while producing results comparable to those of jDE100 and DISHchain1e+12.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05981v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00521-023-09236-y</arxiv:DOI>
      <arxiv:journal_reference>Neural Computing and Applications (2024)</arxiv:journal_reference>
      <dc:creator>Leren Qian, Mohammad Khishe, Yiqian Huang, Seyedali Mirjalili</dc:creator>
    </item>
    <item>
      <title>Entropic Regularization in the Deep Linear Network</title>
      <link>https://arxiv.org/abs/2512.06137</link>
      <description>arXiv:2512.06137v1 Announce Type: new 
Abstract: We study regularization for the deep linear network (DLN) using the entropy formula introduced in arXiv:2509.09088. The equilibria and gradient flow of the free energy on the Riemannian manifold of end-to-end maps of the DLN are characterized for energies that depend symmetrically on the singular values of the end-to-end matrix.
  The only equilibria are minimizers and the set of minimizers is an orbit of the orthogonal group. In contrast with random matrix theory there is no singular value repulsion. The corresponding gradient flow reduces to a one-dimensional ordinary differential equation whose solution gives explicit relaxation rates toward the minimizers. We also study the concavity of the entropy in the chamber of singular values. The entropy is shown to be strictly concave in the Euclidean geometry on the chamber but not in the Riemannian geometry defined by the DLN metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06137v1</guid>
      <category>cs.NE</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Chen, Tejas Kotwal, Govind Menon</dc:creator>
    </item>
    <item>
      <title>Neuro-Vesicles: Neuromodulation Should Be a Dynamical System, Not a Tensor Decoration</title>
      <link>https://arxiv.org/abs/2512.06966</link>
      <description>arXiv:2512.06966v1 Announce Type: new 
Abstract: We introduce Neuro-Vesicles, a framework that augments conventional neural networks with a missing computational layer: a dynamical population of mobile, discrete vesicles that live alongside the network rather than inside its tensors. Each vesicle is a self contained object v = (c, kappa, l, tau, s) carrying a vector payload, type label, location on the graph G = (V, E), remaining lifetime, and optional internal state. Vesicles are emitted in response to activity, errors, or meta signals; migrate along learned transition kernels; probabilistically dock at nodes; locally modify activations, parameters, learning rules, or external memory through content dependent release operators; and finally decay or are absorbed.
  This event based interaction layer reshapes neuromodulation. Instead of applying the same conditioning tensors on every forward pass, modulation emerges from the stochastic evolution of a vesicle population that can accumulate, disperse, trigger cascades, carve transient pathways, and write structured traces into topological memory. Dense, short lived vesicles approximate familiar tensor mechanisms such as FiLM, hypernetworks, or attention. Sparse, long lived vesicles resemble a small set of mobile agents that intervene only at rare but decisive moments.
  We give a complete mathematical specification of the framework, including emission, migration, docking, release, decay, and their coupling to learning; a continuous density relaxation that yields differentiable reaction diffusion dynamics on the graph; and a reinforcement learning view where vesicle control is treated as a policy optimized for downstream performance. We also outline how the same formalism extends to spiking networks and neuromorphic hardware such as the Darwin3 chip, enabling programmable neuromodulation on large scale brain inspired computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06966v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zilin Li, Weiwei Xu, Vicki Kane</dc:creator>
    </item>
    <item>
      <title>Synchrony-Gated Plasticity with Dopamine Modulation for Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2512.07194</link>
      <description>arXiv:2512.07194v1 Announce Type: new 
Abstract: While surrogate backpropagation proves useful for training deep spiking neural networks (SNNs), incorporating biologically inspired local signals on a large scale remains challenging. This difficulty stems primarily from the high memory demands of maintaining accurate spike-timing logs and the potential for purely local plasticity adjustments to clash with the supervised learning goal. To effectively leverage local signals derived from spiking neuron dynamics, we introduce Dopamine-Modulated Spike-Synchrony-Dependent Plasticity (DA-SSDP), a synchrony-based rule that is sensitive to loss and brings a synchrony-based local learning signal to the model. DA-SSDP condenses spike patterns into a synchrony metric at the batch level. An initial brief warm-up phase assesses its relationship to the task loss and sets a fixed gate that subsequently adjusts the local update's magnitude. In cases where synchrony proves unrelated to the task, the gate settles at one, simplifying DA-SSDP to a basic two-factor synchrony mechanism that delivers minor weight adjustments driven by concurrent spike firing and a Gaussian latency function. These small weight updates are only added to the network`s deeper layers following the backpropagation phase, and our tests showed this simplified version did not degrade performance and sometimes gave a small accuracy boost, serving as a regularizer during training. The rule stores only binary spike indicators and first-spike latencies with a Gaussian kernel. Without altering the model structure or optimization routine, evaluations on benchmarks like CIFAR-10 (+0.42\%), CIFAR-100 (+0.99\%), CIFAR10-DVS (+0.1\%), and ImageNet-1K (+0.73\%) demonstrated consistent accuracy gains, accompanied by a minor increase in computational overhead. Our code is available at https://github.com/NeuroSyd/DA-SSDP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07194v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Tian, Samuel Tensingh, Jason Eshraghian, Nhan Duy Truong, Omid Kavehei</dc:creator>
    </item>
    <item>
      <title>Algorithm-hardware co-design of neuromorphic networks with dual memory pathways</title>
      <link>https://arxiv.org/abs/2512.07602</link>
      <description>arXiv:2512.07602v1 Announce Type: new 
Abstract: Spiking neural networks excel at event-driven sensing yet maintaining task-relevant context over long timescales. However building these networks in hardware respecting both tight energy and memory budgets, remains a core challenge in the field. We address this challenge through novel algorithm-hardware co-design effort. At the algorithm level, inspired by the cortical fast-slow organization in the brain, we introduce a neural network with an explicit slow memory pathway that, combined with fast spiking activity, enables a dual memory pathway (DMP) architecture in which each layer maintains a compact low-dimensional state that summarizes recent activity and modulates spiking dynamics. This explicit memory stabilizes learning while preserving event-driven sparsity, achieving competitive accuracy on long-sequence benchmarks with 40-60% fewer parameters than equivalent state-of-the-art spiking neural networks. At the hardware level, we introduce a near-memory-compute architecture that fully leverages the advantages of the DMP architecture by retaining its compact shared state while optimizing dataflow, across heterogeneous sparse-spike and dense-memory pathways. We show experimental results that demonstrate more than a 4x increase in throughput and over a 5x improvement in energy efficiency compared with state-of-the-art implementations. Together, these contributions demonstrate that biological principles can guide functional abstractions that are both algorithmically effective and hardware-efficient, establishing a scalable co-design paradigm for real-time neuromorphic computation and learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07602v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengfei Sun, Zhe Su, Jascha Achterberg, Giacomo Indiveri, Dan F. M. Goodman, Danyal Akarca</dc:creator>
    </item>
    <item>
      <title>PRIMRose: Insights into the Per-Residue Energy Metrics of Proteins with Double InDel Mutations using Deep Learning</title>
      <link>https://arxiv.org/abs/2512.06496</link>
      <description>arXiv:2512.06496v1 Announce Type: cross 
Abstract: Understanding how protein mutations affect protein structure is essential for advancements in computational biology and bioinformatics. We introduce PRIMRose, a novel approach that predicts energy values for each residue given a mutated protein sequence. Unlike previous models that assess global energy shifts, our method analyzes the localized energetic impact of double amino acid insertions or deletions (InDels) at the individual residue level, enabling residue-specific insights into structural and functional disruption. We implement a Convolutional Neural Network architecture to predict the energy changes of each residue in a protein mutation. We train our model on datasets constructed from nine proteins, grouped into three categories: one set with exhaustive double InDel mutations, another with approximately 145k randomly sampled double InDel mutations, and a third with approximately 80k randomly sampled double InDel mutations. Our model achieves high predictive accuracy across a range of energy metrics as calculated by the Rosetta molecular modeling suite and reveals localized patterns that influence model performance, such as solvent accessibility and secondary structure context. This per-residue analysis offers new insights into the mutational tolerance of specific regions within proteins and provides higher interpretable and biologically meaningful predictions of InDels' effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06496v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3768322.3769032</arxiv:DOI>
      <arxiv:journal_reference>BCB Companion 2025: Companion Proceedings of the 16th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics</arxiv:journal_reference>
      <dc:creator>Stella Brown, Nicolas Preisig, Autumn Davis, Brian Hutchinson, Filip Jagodzinski</dc:creator>
    </item>
    <item>
      <title>QL-LSTM: A Parameter-Efficient LSTM for Stable Long-Sequence Modeling</title>
      <link>https://arxiv.org/abs/2512.06582</link>
      <description>arXiv:2512.06582v1 Announce Type: cross 
Abstract: Recurrent neural architectures such as LSTM and GRU remain widely used in sequence modeling, but they continue to face two core limitations: redundant gate-specific parameters and reduced ability to retain information across long temporal distances. This paper introduces the Quantum-Leap LSTM (QL-LSTM), a recurrent architecture designed to address both challenges through two independent components. The Parameter-Shared Unified Gating mechanism replaces all gate-specific transformations with a single shared weight matrix, reducing parameters by approximately 48 percent while preserving full gating behavior. The Hierarchical Gated Recurrence with Additive Skip Connections component adds a multiplication-free pathway that improves long-range information flow and reduces forget-gate degradation. We evaluate QL-LSTM on sentiment classification using the IMDB dataset with extended document lengths, comparing it to LSTM, GRU, and BiLSTM reference models. QL-LSTM achieves competitive accuracy while using substantially fewer parameters. Although the PSUG and HGR-ASC components are more efficient per time step, the current prototype remains limited by the inherent sequential nature of recurrent models and therefore does not yet yield wall-clock speed improvements without further kernel-level optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06582v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isaac Kofi Nti</dc:creator>
    </item>
    <item>
      <title>Phase-multiplexed optical computing: Reconfiguring a multi-task diffractive optical processor using illumination phase diversity</title>
      <link>https://arxiv.org/abs/2512.06658</link>
      <description>arXiv:2512.06658v1 Announce Type: cross 
Abstract: We report a monochrome multi-task diffractive network architecture that leverages illumination phase multiplexing to dynamically reconfigure its output function and accurately implement a large group of complex-valued linear transformations between an input and output aperture. Each member of the desired group of T unique transformations is encoded and addressed with a distinct 2D illumination phase profile, termed "phase key", which illuminates the input aperture, activating the corresponding transformation at the output field-of-view. A common diffractive optical network, optimized with T phase keys, demultiplexes these encoded inputs and accurately executes any of the T distinct linear transformations at its output. We demonstrate that a diffractive network composed of N = 2 x T x Ni x No optimized diffractive features can realize T distinct complex-valued linear transformations, accurately executed for any complex field at the input aperture, where Ni and No refer to the input/output pixels, respectively. In our proof-of-concept numerical analysis, T = 512 complex-valued transformations are implemented by the same monochrome diffractive network with negligible error using illumination phase diversity. Compared with wavelength-multiplexed diffractive systems, phase-multiplexing architecture significantly lowers the transformation errors, potentially enabling larger-scale optical transformations to be implemented through a monochrome processor. Phase-multiplexed multi-task diffractive networks would enhance the capabilities of optical computing and machine-vision systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06658v1</guid>
      <category>physics.optics</category>
      <category>cs.NE</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Wang, Aydogan Ozcan</dc:creator>
    </item>
    <item>
      <title>Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics</title>
      <link>https://arxiv.org/abs/2512.06737</link>
      <description>arXiv:2512.06737v1 Announce Type: cross 
Abstract: The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06737v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikhil Verma, Joonas Linnosmaa, Espinosa-Leal Leonardo, Napat Vajragupta</dc:creator>
    </item>
    <item>
      <title>Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search</title>
      <link>https://arxiv.org/abs/2512.07142</link>
      <description>arXiv:2512.07142v1 Announce Type: cross 
Abstract: The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks ('winning tickets') within dense, randomly initialized neural networks. However, state-of-the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI's reliance on first-order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTS-KL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, it reaches 99.3% sparsity with 74.0% accuracy in 7.9 minutes, while LTR attains the same sparsity with 68.3% accuracy in 95.2 minutes. CTS's subnetworks outperform saliency-based methods across all sparsities, but its advantage over LTR is most pronounced in the highly sparse regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07142v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanay Arora, Christof Teuscher</dc:creator>
    </item>
    <item>
      <title>An Asynchronous Mixed-Signal Resonate-and-Fire Neuron</title>
      <link>https://arxiv.org/abs/2512.07361</link>
      <description>arXiv:2512.07361v1 Announce Type: cross 
Abstract: Analog computing at the edge is an emerging strategy to limit data storage and transmission requirements, as well as energy consumption, and its practical implementation is in its initial stages of development. Translating properties of biological neurons into hardware offers a pathway towards low-power, real-time edge processing. Specifically, resonator neurons offer selectivity to specific frequencies as a potential solution for temporal signal processing. Here, we show a fabricated Complementary Metal-Oxide-Semiconductor (CMOS) mixed-signal Resonate-and-Fire (R&amp;F) neuron circuit implementation that emulates the behavior of these neural cells responsible for controlling oscillations within the central nervous system. We integrate the design with asynchronous handshake capabilities, perform comprehensive variability analyses, and characterize its frequency detection functionality. Our results demonstrate the feasibility of large-scale integration within neuromorphic systems, thereby advancing the exploitation of bio-inspired circuits for efficient edge temporal signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07361v1</guid>
      <category>eess.SP</category>
      <category>cs.NE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Giuseppe Leo, Paolo Gibertini, Irem Ilter, Erika Covi, Ole Richter, Elisabetta Chicca</dc:creator>
    </item>
    <item>
      <title>From sparse recovery to plug-and-play priors, understanding trade-offs for stable recovery with generalized projected gradient descent</title>
      <link>https://arxiv.org/abs/2512.07397</link>
      <description>arXiv:2512.07397v1 Announce Type: cross 
Abstract: We consider the problem of recovering an unknown low-dimensional vector from noisy, underdetermined observations. We focus on the Generalized Projected Gradient Descent (GPGD) framework, which unifies traditional sparse recovery methods and modern approaches using learned deep projective priors. We extend previous convergence results to robustness to model and projection errors. We use these theoretical results to explore ways to better control stability and robustness constants. To reduce recovery errors due to measurement noise, we consider generalized back-projection strategies to adapt GPGD to structured noise, such as sparse outliers. To improve the stability of GPGD, we propose a normalized idempotent regularization for the learning of deep projective priors. We provide numerical experiments in the context of sparse recovery and image inverse problems, highlighting the trade-offs between identifiability and stability that can be achieved with such methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07397v1</guid>
      <category>eess.IV</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Joundi (IMB), Yann Traonmilin (IMB), Jean-Fran\c{c}ois Aujol (UB, IMB)</dc:creator>
    </item>
    <item>
      <title>KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models</title>
      <link>https://arxiv.org/abs/2512.07437</link>
      <description>arXiv:2512.07437v1 Announce Type: cross 
Abstract: DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07437v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenwei Shi, Xueyu Luan</dc:creator>
    </item>
    <item>
      <title>Asynchronous Bioplausible Neuron for SNN for Event Vision</title>
      <link>https://arxiv.org/abs/2311.11853</link>
      <description>arXiv:2311.11853v3 Announce Type: replace 
Abstract: Spiking Neural Networks (SNNs) offer a biologically inspired approach to computer vision that can lead to more efficient processing of visual data with reduced energy consumption. However, maintaining homeostasis within these networks is challenging, as it requires continuous adjustment of neural responses to preserve equilibrium and optimal processing efficiency amidst diverse and often unpredictable input signals. In response to these challenges, we propose the Asynchronous Bioplausible Neuron (ABN), a dynamic spike firing mechanism to auto-adjust the variations in the input signal. Comprehensive evaluation across various datasets demonstrates ABN's enhanced performance in image classification and segmentation, maintenance of neural equilibrium, and energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11853v3</guid>
      <category>cs.NE</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanket Kachole, Hussain Sajwani, Fariborz Baghaei Naeini, Dimitrios Makris, Yahya Zweiri</dc:creator>
    </item>
    <item>
      <title>Stochastic Orthogonal Regularization for deep projective priors</title>
      <link>https://arxiv.org/abs/2505.13078</link>
      <description>arXiv:2505.13078v3 Announce Type: replace-cross 
Abstract: Many crucial tasks of image processing and computer vision are formulated as inverse problems. Thus, it is of great importance to design fast and robust algorithms to solve these problems. In this paper, we focus on generalized projected gradient descent (GPGD) algorithms where generalized projections are realized with learned neural networks and provide state-of-the-art results for imaging inverse problems. Indeed, neural networks allow for projections onto unknown low-dimensional sets that model complex data, such as images. We call these projections deep projective priors. In generic settings, when the orthogonal projection onto a lowdimensional model set is used, it has been shown, under a restricted isometry assumption, that the corresponding orthogonal PGD converges with a linear rate, yielding near-optimal convergence (within the class of GPGD methods) in the classical case of sparse recovery. However, for deep projective priors trained with classical mean squared error losses, there is little guarantee that the hypotheses for linear convergence are satisfied. In this paper, we propose a stochastic orthogonal regularization of the training loss for deep projective priors. This regularization is motivated by our theoretical results: a sufficiently good approximation of the orthogonal projection guarantees linear stable recovery with performance close to orthogonal PGD. We show experimentally, using two different deep projective priors (based on autoencoders and on denoising networks), that our stochastic orthogonal regularization yields projections that improve convergence speed and robustness of GPGD in challenging inverse problem settings, in accordance with our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13078v3</guid>
      <category>eess.IV</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Joundi (UB), Yann Traonmilin (UB), Alasdair Newson (ISIR)</dc:creator>
    </item>
  </channel>
</rss>
