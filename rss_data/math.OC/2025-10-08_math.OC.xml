<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Oct 2025 01:44:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A System Level Approach to LQR Control of the Diffusion Equation</title>
      <link>https://arxiv.org/abs/2510.05345</link>
      <description>arXiv:2510.05345v1 Announce Type: new 
Abstract: The continuous-time, infinite horizon LQR problem for the diffusion equation over the unit circle with fully distributed actuation is considered. It is well-known that the solution to this problem can be obtained from the solution to an operator-valued algebraic Riccati equation. Here, it is demonstrated that this solution can be equivalently obtained by solving an $H_2$ control problem through a closed-loop design procedure that is analogous to the "System Level Synthesis" methodology previously developed for systems over a discrete spatial domain and/or over a finite time horizon. The presented extension to the continuous spatial domain and continuous and infinite-horizon time setting admits analytical solutions that may complement computational approaches for discrete or finite-horizon settings. It is further illustrated that spatio-temporal constraints on the closed-loop responses can be incorporated into this new formulation in a convex manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05345v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Addie McCurdy, Andrew Gusty, Emily Jensen</dc:creator>
    </item>
    <item>
      <title>Learning-based model predictive control with moving horizon state estimation for autonomous racing</title>
      <link>https://arxiv.org/abs/2510.05366</link>
      <description>arXiv:2510.05366v1 Announce Type: new 
Abstract: This paper addresses autonomous racing by introducing a real-time nonlinear model predictive controller (NMPC) coupled with a moving horizon estimator (MHE). The racing problem is solved by an NMPC-based off-line trajectory planner that computes the best trajectory while considering the physical limits of the vehicle and circuit constraints. The developed controller is further enhanced with a learning extension based on Gaussian process regression that improves model predictions. The proposed control, estimation, and planning schemes are evaluated on two different race tracks. Code can be found here: https://github.com/yassinekebbati/GP_Learning-based_MPC_with_MHE</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05366v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/00207179.2024.2409305</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Control 2024</arxiv:journal_reference>
      <dc:creator>Yassine Kebbati, Andreas Rauh, Naima Ait-Oufroukh, Dalil Ichalal, Vincent Vigneron</dc:creator>
    </item>
    <item>
      <title>Optimization via a Control-Centric Framework</title>
      <link>https://arxiv.org/abs/2510.05455</link>
      <description>arXiv:2510.05455v2 Announce Type: new 
Abstract: Optimization plays a central role in intelligent systems and cyber-physical technologies, where the speed and reliability of convergence directly impact performance. In control theory, optimization-centric methods are standard: controllers are designed by repeatedly solving optimization problems, as in linear quadratic regulation, $H_\infty$ control, and model predictive control. In contrast, this paper develops a control-centric framework for optimization itself, where algorithms are constructed directly from Lyapunov stability principles rather than being proposed first and analyzed afterward. A key element is the stationarity vector, which encodes first-order optimality conditions and enables Lyapunov-based convergence analysis. By pairing a Lyapunov function with a selectable decay law, we obtain continuous-time dynamics with guaranteed exponential, finite-time, fixed-time, or prescribed-time convergence. Within this framework, we introduce three feedback realizations of increasing restrictiveness: the Hessian-gradient, Newton, and gradient dynamics. Each realization shapes the decay of the stationarity vector to achieve the desired rate. These constructions unify unconstrained optimization, extend naturally to constrained problems via Lyapunov-consistent primal-dual dynamics, and broaden the results for minimax and generalized Nash equilibrium seeking problems beyond exponential stability. The framework provides systematic design tools for optimization algorithms in control and game-theoretic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05455v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liraz Mudrik, Isaac Kaminer, Sean Kragelund, Abram H. Clark</dc:creator>
    </item>
    <item>
      <title>Revisiting Invex Functions: Explicit Kernel Constructions and Applications</title>
      <link>https://arxiv.org/abs/2510.05523</link>
      <description>arXiv:2510.05523v1 Announce Type: new 
Abstract: An invex function generalizes a convex function in the sense that every stationary point is a global minimizer. Recently, invex functions and related concepts have attracted attention in signal processing and machine learning. However, proving that a function is invex is not straightforward, because the definition involves an unknown function called a kernel function. This paper develops several methods for constructing explicit kernel functions, which have been missing from the literature. These methods support proving invexity of new functions, and they would also be useful in the development of optimization algorithms for invex problems. We also clarify connections to pseudoconvex functions and present examples of nonsmooth, non-pseudoconvex invex functions that arise in signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05523v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akatsuki Nishioka</dc:creator>
    </item>
    <item>
      <title>On the equivalence of $c$-potentiability and $c$-path boundedness in the sense of Artstein-Avidan, Sadovsky, and Wyczesany</title>
      <link>https://arxiv.org/abs/2510.05550</link>
      <description>arXiv:2510.05550v1 Announce Type: new 
Abstract: A cornerstone of convex analysis, established by Rockafellar in 1966, asserts that a set has a potential if and only if it is cyclically monotone. This characterization was generalized to hold for any real-valued cost function $c$ and lies at the core structure of optimal transport plans. However, this equivalence fails to hold for costs that attain infinite values. In this paper, we explore potentiability for an infinite-valued cost $c$ under the assumption of $c$-path boundedness, a condition that was first introduced by Artstein-Avidan, Sadovsky and Wyczesany. This condition is necessary for potentiability and is more restrictive than $c$-cyclic monotonicity. We provide general settings and other conditions under which $c$-path boundedness is sufficient for potentability, and therefore equivalent. We provide a general theorem for potentiability, requiring no topological assumptions on the spaces or the cost. We then provide sufficiency in separable metric spaces and costs that are continuous in their domain. Finally, we introduce the notion of a $c$-path bounded extension and use it to prove the existence of potentials for a special class of costs on $\mathbb{R}^2$. We illustrate our discussion and results with several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05550v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sedi Bartz, Heinz H. Bauschke, Yuan Gao</dc:creator>
    </item>
    <item>
      <title>Unbiased Extremum Seeking for MPPT in Photovoltaic Systems</title>
      <link>https://arxiv.org/abs/2510.05563</link>
      <description>arXiv:2510.05563v1 Announce Type: new 
Abstract: This paper presents novel extremum seeking (ES) strategies for maximum power point tracking (MPPT) in photovoltaic (PV) systems that ensure unbiased convergence and prescribed-time performance. Conventional ES methods suffer from steady-state bias due to persistent dither signal. We introduce two novel ES algorithms: the exponential unbiased ES (uES), which guarantees exponential convergence to the maximum power point (MPP) without steady-state oscillation bias, and the unbiased prescribed-time ES (uPT-ES), which ensures convergence within a user-defined time horizon. Both methods leverage time-varying perturbation amplitudes and demodulation gains, with uPT-ES additionally utilizing chirp signals to enhance excitation over finite-time intervals. Experimental results on a hardware-in-the-loop testbed validate the proposed algorithms, demonstrating improved convergence speed and tracking accuracy compared to classical ES, under both static and time-varying environmental conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05563v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cemal Tugrul Yilmaz, Eric Foss, Mamadou Diagne, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Nonlinear constrained optimization of Schur test functions</title>
      <link>https://arxiv.org/abs/2510.05585</link>
      <description>arXiv:2510.05585v1 Announce Type: new 
Abstract: We apply the iterative nonlinear programming method, previously proposed in our earlier work, to optimize Schur test functions and thereby provide refined upper bounds for the norms of integral operators. As an illustration, we derive such bounds for transfer operators associated with twofold additive compound operators that arise in the study of delay equations. This is related to the verification of frequency inequalities that guarantee the global stability of nonlinear delay equations through the generalized Bendixson criterion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05585v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikhail Anikushin, Andrey Romanov</dc:creator>
    </item>
    <item>
      <title>Strategic Inference in Stackelberg Games: Optimal Control for Revealing Adversary Intent</title>
      <link>https://arxiv.org/abs/2510.05641</link>
      <description>arXiv:2510.05641v1 Announce Type: new 
Abstract: We study a continuous-time stochastic Stackelberg game in which a leader seeks to accomplish a primary objective while inferring a hidden parameter of a rational follower. The follower solves an entropy-regularized tracking problem and responds to the leader's trajectory with a randomized policy. Anticipating this response, the leader designs informative controls to maximize the estimation efficiency for the follower's latent intent, through maximum likelihood estimation. Unlike prior work on discrete-time or finite-candidate inverse learning, our framework enables continuous parameter inference without prior assumptions and endogenizes the information source through the follower's strategic feedback. We derive semi-explicit solutions, prove well-posedness, and develop recurrent neural network algorithms to approximate the leader's path-dependent control. Numerical experiments demonstrate how the leader balances task performance and information gain, highlighting the practical value of our approach for adversarial strategic inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05641v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruimeng Hu, Daniel Ralston, Xu Yang, Haosheng Zhou</dc:creator>
    </item>
    <item>
      <title>On Implicit Concave Structures in Half-Quadratic Methods for Signal Reconstruction</title>
      <link>https://arxiv.org/abs/2510.05690</link>
      <description>arXiv:2510.05690v1 Announce Type: new 
Abstract: In this work, we introduce a new class of non-convex functions, called implicit concave functions, which are compositions of a concave function with a continuously differentiable mapping. We analyze the properties of their minimization by leveraging Fenchel conjugate theory to construct an augmented optimization problem. This reformulation yields a one-to-one correspondence between the stationary points and local minima of the original and augmented problems. Crucially, the augmented problem admits a natural variable splitting that reveals convexity with respect to at least one block, and, in some cases, leading to a biconvex structure that is more amenable to optimization. This enables the use of efficient block coordinate descent algorithms for solving otherwise non-convex problems. As a representative application, we show how this framework applies to half-quadratic regularization in signal reconstruction and image processing. We demonstrate that common edge-preserving regularizers fall within the proposed class, and that their corresponding augmented problems are biconvex and bounded from below. Our results offer both a theoretical foundation and a practical pathway for solving a broad class of structured non-convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05690v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vittorio Latorre</dc:creator>
    </item>
    <item>
      <title>Duality for Non Convex Composite Functions via the Fenchel Rockafellar Perturbation Framework</title>
      <link>https://arxiv.org/abs/2510.05741</link>
      <description>arXiv:2510.05741v1 Announce Type: new 
Abstract: We examine the duality theory for a class of non-convex functions obtained by composing a convex function with a continuous one. Using Fenchel duality, we derive a dual problem that satisfies weak duality under general assumptions. To better understand this duality, we compare it with classical Lagrange duality by analyzing a related, yet more complex, constrained problem. We demonstrate that the newly derived stationarity conditions are equivalent to the classical Lagrange stationarity conditions for the constrained problem, as expected by the close relationship between Fenchel and Lagrange dualities. We introduce two non-convex optimization problems and prove strong duality results with their respective duals. The second problem is a constrained optimization problem whose dual is obtained through the concurrent use of the duality theory introduced in this paper and classical Lagrange duality for constrained optimization. We also report numerical tests where we solve randomly generated instances of the presented problems using an ad-hoc primal-dual potential reduction interior point method that directly exploits the global optimality conditions established in this paper. The results include a comparison with a well-known conic programming solver applied to the convex duals of the analyzed problems. The interior point method successfully reduces the duality gap close to zero, validating the proposed duality framework. The theory presented in this paper can be applied to various non-convex problems and serves as a valuable tool in the field of hidden convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05741v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vittorio Latorre</dc:creator>
    </item>
    <item>
      <title>The Golden Ratio Proximal ADMM with Norm Independent Step-Sizes for Separable Convex Optimization</title>
      <link>https://arxiv.org/abs/2510.05779</link>
      <description>arXiv:2510.05779v1 Announce Type: new 
Abstract: In this work, we propose two step-size strategies for the Golden-ratio proximal ADMM (GrpADMM) to solve linearly constrained separable convex optimization problems. Both strategies eliminate explicit operator-norm estimates by relying solely on inexpensive local information computed at the current iterate without involving backtracking. However, the key difference is that the second step-size rule allows for recovery from poor initial steps and can increase from iteration to iteration. Under standard assumptions, we prove global iterate convergence and derive sublinear rates for both the objective gap and feasibility residuals. Several numerical experiments confirm the adaptability of the approaches, where accurately computing such parameters can be costly or even infeasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05779v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Santanu Soe, V. Vetrivel</dc:creator>
    </item>
    <item>
      <title>MadNCL: A GPU Implementation of Algorithm NCL for Large-Scale, Degenerate Nonlinear Programs</title>
      <link>https://arxiv.org/abs/2510.05885</link>
      <description>arXiv:2510.05885v1 Announce Type: new 
Abstract: We present a GPU implementation of Algorithm NCL, an augmented Lagrangian method for solving large-scale and degenerate nonlinear programs. Although interior-point methods and sequential quadratic programming are widely used for solving nonlinear programs, the augmented Lagrangian method is known to offer superior robustness against constraint degeneracies and can rapidly detect infeasibility. We introduce several enhancements to Algorithm NCL, including fusion of the inner and outer loops and use of extrapolation steps, which improve both efficiency and convergence stability. Further, NCL has the key advantage of being well-suited for GPU architectures because of the regularity of the KKT systems provided by quadratic penalty terms. In particular, the NCL subproblem formulation allows the KKT systems to be naturally expressed as either stabilized or condensed KKT systems, whereas the interior-point approach requires aggressive reformulations or relaxations to make it suitable for GPUs. Both systems can be efficiently solved on GPUs using sparse \ldlt factorization with static pivoting, as implemented in NVIDIA cuDSS. Building on these advantages, we examine the KKT systems arising from NCL subproblems. We present an optimized GPU implementation of Algorithm NCL by leveraging MadNLP as an interior-point subproblem solver and utilizing the stabilized and condensed formulations of the KKT systems for computing Newton steps. Numerical experiments on various large-scale and degenerate NLPs, including optimal power flow, COPS benchmarks, and security-constrained optimal power flow, demonstrate that MadNCL operates efficiently on GPUs while effectively managing problem degeneracy, including MPCC constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05885v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexis Montoison, Fran\c{c}ois Pacaud, Michael Saunders, Sungho Shin, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>A Simple Adaptive Proximal Gradient Method for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2510.06079</link>
      <description>arXiv:2510.06079v1 Announce Type: new 
Abstract: Consider composite nonconvex optimization problems where the objective function consists of a smooth nonconvex term (with Lipschitz-continuous gradient) and a convex (possibly nonsmooth) term. Existing parameter-free methods for such problems often rely on complex multi-loop structures, require line searches, or depend on restrictive assumptions (e.g., bounded iterates). To address these limitations, we introduce a novel adaptive proximal gradient method (referred to as AdaPGNC) that features a simple single-loop structure, eliminates the need for line searches, and only requires the gradient's Lipschitz continuity to ensure convergence. Furthermore, AdaPGNC achieves the theoretically optimal iteration/gradient evaluation complexity of $\mathcal{O}(\varepsilon^{-2})$ for finding an $\varepsilon$-stationary point. Our core innovation lies in designing an adaptive step size strategy that leverages upper and lower curvature estimates. A key technical contribution is the development of a novel Lyapunov function that effectively balances the function value gap and the norm-squared of consecutive iterate differences, serving as a central component in our convergence analysis. Preliminary experimental results indicate that AdaPGNC demonstrates competitive performance on several benchmark nonconvex (and convex) problems against state-of-the-art parameter-free methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06079v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zilong Ye, Shiqian Ma, Junfeng Yang, Danqing Zhou</dc:creator>
    </item>
    <item>
      <title>Lagrangian Dual Sections: A Topological Perspective on Hidden Convexity</title>
      <link>https://arxiv.org/abs/2510.06112</link>
      <description>arXiv:2510.06112v2 Announce Type: new 
Abstract: Hidden convexity is a powerful idea in optimization: under the right transformations, nonconvex problems that are seemingly intractable can be solved efficiently using convex optimization. We introduce the notion of a Lagrangian dual section of a nonlinear program defined over a topological space, and we use it to give a sufficient condition for a nonconvex optimization problem to have a natural convex reformulation. We emphasize the topological nature of our framework, using only continuity and connectedness properties of a certain Lagrangian formulation of the problem to prove our results. We demonstrate the practical consequences of our framework in a range of applications and by developing new algorithmic methodology. First, we present families of nonconvex problem instances that can be transformed to convex programs in the context of spectral inverse problems -- which include quadratically constrained quadratic optimization and Stiefel manifold optimization as special cases -- as well as unbalanced Procrustes problems. In each of these applications, we both generalize prior results on hidden convexity and provide unifying proofs. For the case of the spectral inverse problems, we also present a Lie-theoretic approach that illustrates connections with the Kostant convexity theorem. Second, we introduce new algorithmic ideas that can be used to find globally optimal solutions to both Lagrangian forms of an optimization problem as well as constrained optimization problems when the underlying topological space is a Riemannian manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06112v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Venkat Chandrasekaran, Timothy Duff, Jose Israel Rodriguez, Kevin Shu</dc:creator>
    </item>
    <item>
      <title>Robust Data-Driven Receding-Horizon Control for LQR with Input Constraints</title>
      <link>https://arxiv.org/abs/2510.06117</link>
      <description>arXiv:2510.06117v1 Announce Type: new 
Abstract: This letter presents a robust data-driven receding-horizon control framework for the discrete time linear quadratic regulator (LQR) with input constraints. Unlike existing data-driven approaches that design a controller from initial data and apply it unchanged throughout the trajectory, our method exploits all available execution data in a receding-horizon manner, thereby capturing additional information about the unknown system and enabling less conservative performance. Prior data-driven LQR and model predictive control methods largely rely on Willem's fundamental lemma, which requires noise-free data, or use regularization to address disturbances, offering only practical stability guarantees. In contrast, the proposed approach extends semidefinite program formulations for the data-driven LQR to incorporate input constraints and leverages duality to provide formal robust stability guarantees. Simulation results demonstrate the effectiveness of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06117v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Zheng, Mario Sznaier</dc:creator>
    </item>
    <item>
      <title>Robust Data-Driven Receding Horizon Control</title>
      <link>https://arxiv.org/abs/2510.06153</link>
      <description>arXiv:2510.06153v1 Announce Type: new 
Abstract: This paper presents a data-driven receding horizon control framework for discrete-time linear systems that guarantees robust performance in the presence of bounded disturbances. Unlike the majority of existing data-driven predictive control methods, which rely on Willem's fundamental lemma, the proposed method enforces set-membership constraints for data-driven control and utilizes execution data to iteratively refine a set of compatible systems online. Numerical results demonstrate that the proposed receding horizon framework achieves better contractivity for the unknown system compared with regular data-driven control approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06153v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jian Zheng, Sahand Kiani, Mario Sznaier, Constantino Lagoa</dc:creator>
    </item>
    <item>
      <title>Differentiable Model Predictive Control on the GPU</title>
      <link>https://arxiv.org/abs/2510.06179</link>
      <description>arXiv:2510.06179v1 Announce Type: new 
Abstract: Differentiable model predictive control (MPC) offers a powerful framework for combining learning and control. However, its adoption has been limited by the inherently sequential nature of traditional optimization algorithms, which are challenging to parallelize on modern computing hardware like GPUs. In this work, we tackle this bottleneck by introducing a GPU-accelerated differentiable optimization tool for MPC. This solver leverages sequential quadratic programming and a custom preconditioned conjugate gradient (PCG) routine with tridiagonal preconditioning to exploit the problem's structure and enable efficient parallelization. We demonstrate substantial speedups over CPU- and GPU-based baselines, significantly improving upon state-of-the-art training times on benchmark reinforcement learning and imitation learning tasks. Finally, we showcase the method on the challenging task of reinforcement learning for driving at the limits of handling, where it enables robust drifting of a Toyota Supra through water puddles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06179v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emre Adabag, Marcus Greiff, John Subosits, Thomas Lew</dc:creator>
    </item>
    <item>
      <title>Procrustes Problems on Random Matrices</title>
      <link>https://arxiv.org/abs/2510.05182</link>
      <description>arXiv:2510.05182v1 Announce Type: cross 
Abstract: Meaningful comparison between sets of observations often necessitates alignment or registration between them, and the resulting optimization problems range in complexity from those admitting simple closed-form solutions to those requiring advanced and novel techniques. We compare different Procrustes problems in which we align two sets of points after various perturbations by minimizing the norm of the difference between one matrix and an orthogonal transformation of the other. The minimization problem depends significantly on the choice of matrix norm; we highlight recent developments in nonsmooth Riemannian optimization and characterize which choices of norm work best for each perturbation. We show that in several applications, from low-dimensional alignments to hypothesis testing for random networks, when Procrustes alignment with the spectral or robust norm is the appropriate choice, it is often feasible to replace the computationally more expensive spectral and robust minimizers with their closed-form Frobenius-norm counterpart. Our work reinforces the synergy between optimization, geometry, and statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05182v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hajg Jasa, Ronny Bergmann, Christian K\"ummerle, Avanti Athreya, Zachary Lubberts</dc:creator>
    </item>
    <item>
      <title>OptPipe: Memory- and Scheduling-Optimized Pipeline Parallelism for LLM Training</title>
      <link>https://arxiv.org/abs/2510.05186</link>
      <description>arXiv:2510.05186v1 Announce Type: cross 
Abstract: Pipeline parallelism (PP) has become a standard technique for scaling large language model (LLM) training across multiple devices. However, despite recent progress in reducing memory consumption through activation offloading, existing approaches remain largely heuristic and coarse-grained, often overlooking the fine-grained trade-offs between memory, computation, and scheduling latency. In this work, we revisit the pipeline scheduling problem from a principled optimization perspective. We observe that prevailing strategies either rely on static rules or aggressively offload activations without fully leveraging the interaction between memory constraints and scheduling efficiency. To address this, we formulate scheduling as a constrained optimization problem that jointly accounts for memory capacity, activation reuse, and pipeline bubble minimization. Solving this model yields fine-grained schedules that reduce pipeline bubbles while adhering to strict memory budgets. Our approach complements existing offloading techniques: whereas prior approaches trade memory for time in a fixed pattern, we dynamically optimize the tradeoff with respect to model structure and hardware configuration. Experimental results demonstrate that our method consistently improves both throughput and memory utilization. In particular, we reduce idle pipeline time by up to 50% under the same per-device memory limit, and in some cases, enable the training of larger models within limited memory budgets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05186v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongpei Li, Han Zhang, Huikang Liu, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Simultaneous Learning and Optimization via Misspecified Saddle Point Problems</title>
      <link>https://arxiv.org/abs/2510.05241</link>
      <description>arXiv:2510.05241v1 Announce Type: cross 
Abstract: We study a class of misspecified saddle point (SP) problems, where the optimization objective depends on an unknown parameter that must be learned concurrently from data. Unlike existing studies that assume parameters are fully known or pre-estimated, our framework integrates optimization and learning into a unified formulation, enabling a more flexible problem class. To address this setting, we propose two algorithms based on the accelerated primal-dual (APD) by Hamedani &amp; Aybat 2021. In particular, we first analyze the naive extension of the APD method by directly substituting the evolving parameter estimates into the primal-dual updates; then, we design a new learning-aware variant of the APD method that explicitly accounts for parameter dynamics by adjusting the momentum updates. Both methods achieve a provable convergence rate of $\mathcal{O}(\log K / K)$, while the learning-aware approach attains a tighter $\mathcal{O}(1)$ constant and further benefits from an adaptive step-size selection enabled by a backtracking strategy. Furthermore, we extend the framework to problems where the learning problem admits multiple optimal solutions, showing that our modified algorithm for a structured setting achieves an $\mathcal{O}(1/\sqrt{K})$ rate. To demonstrate practical impact, we evaluate our methods on a misspecified portfolio optimization problem and show superior empirical performance compared to state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05241v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Mahdi Ahmadi, Erfan Yazdandoost Hamedani</dc:creator>
    </item>
    <item>
      <title>A Neural Network Algorithm for KL Divergence Estimation with Quantitative Error Bounds</title>
      <link>https://arxiv.org/abs/2510.05386</link>
      <description>arXiv:2510.05386v1 Announce Type: cross 
Abstract: Estimating the Kullback-Leibler (KL) divergence between random variables is a fundamental problem in statistical analysis. For continuous random variables, traditional information-theoretic estimators scale poorly with dimension and/or sample size. To mitigate this challenge, a variety of methods have been proposed to estimate KL divergences and related quantities, such as mutual information, using neural networks. The existing theoretical analyses show that neural network parameters achieving low error exist. However, since they rely on non-constructive neural network approximation theorems, they do not guarantee that the existing algorithms actually achieve low error. In this paper, we propose a KL divergence estimation algorithm using a shallow neural network with randomized hidden weights and biases (i.e. a random feature method). We show that with high probability, the algorithm achieves a KL divergence estimation error of $O(m^{-1/2}+T^{-1/3})$, where $m$ is the number of neurons and $T$ is both the number of steps of the algorithm and the number of samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05386v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikil Foss, Andrew Lamperski</dc:creator>
    </item>
    <item>
      <title>The Method of Infinite Descent</title>
      <link>https://arxiv.org/abs/2510.05489</link>
      <description>arXiv:2510.05489v1 Announce Type: cross 
Abstract: Training - the optimisation of complex models - is traditionally performed through small, local, iterative updates [D. E. Rumelhart, G. E. Hinton, R. J. Williams, Nature 323, 533-536 (1986)]. Approximating solutions through truncated gradients is a paradigm dating back to Cauchy [A.-L. Cauchy, Comptes Rendus Math\'ematique 25, 536-538 (1847)] and Newton [I. Newton, The Method of Fluxions and Infinite Series (Henry Woodfall, London, 1736)]. This work introduces the Method of Infinite Descent, a semi-analytic optimisation paradigm that reformulates training as the direct solution to the first-order optimality condition. By analytical resummation of its Taylor expansion, this method yields an exact, algebraic equation for the update step. Realisation of the infinite Taylor tower's cascading resummation is formally derived, and an exploitative algorithm for the direct solve step is proposed.
  This principle is demonstrated with the herein-introduced AION (Analytic, Infinitely-Optimisable Network) architecture. AION is a model designed expressly to satisfy the algebraic closure required by Infinite Descent. In a simple test problem, AION reaches the optimum in a single descent step. Together, this optimiser-model pair exemplify how analytic structure enables exact, non-iterative convergence. Infinite Descent extends beyond this example, applying to any appropriately closed architecture. This suggests a new class of semi-analytically optimisable models: the \emph{Infinity Class}; sufficient conditions for class membership are discussed. This offers a pathway toward non-iterative learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05489v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reza T. Batley, Sourav Saha</dc:creator>
    </item>
    <item>
      <title>NeST-BO: Fast Local Bayesian Optimization via Newton-Step Targeting of Gradient and Hessian Information</title>
      <link>https://arxiv.org/abs/2510.05516</link>
      <description>arXiv:2510.05516v1 Announce Type: cross 
Abstract: Bayesian optimization (BO) is effective for expensive black-box problems but remains challenging in high dimensions. We propose NeST-BO, a local BO method that targets the Newton step by jointly learning gradient and Hessian information with Gaussian process surrogates, and selecting evaluations via a one-step lookahead bound on Newton-step error. We show that this bound (and hence the step error) contracts with batch size, so NeST-BO directly inherits inexact-Newton convergence: global progress under mild stability assumptions and quadratic local rates once steps are sufficiently accurate. To scale, we optimize the acquisition in low-dimensional subspaces (e.g., random embeddings or learned sparse subspaces), reducing the dominant cost of learning curvature from $O(d^2)$ to $O(m^2)$ with $m \ll d$ while preserving step targeting. Across high-dimensional synthetic and real-world problems, including cases with thousands of variables and unknown active subspaces, NeST-BO consistently yields faster convergence and lower regret than state-of-the-art local and high-dimensional BO baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05516v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei-Ting Tang, Akshay Kudva, Joel A. Paulson</dc:creator>
    </item>
    <item>
      <title>Stable Robot Motions on Manifolds: Learning Lyapunov-Constrained Neural Manifold ODEs</title>
      <link>https://arxiv.org/abs/2510.05707</link>
      <description>arXiv:2510.05707v1 Announce Type: cross 
Abstract: Learning stable dynamical systems from data is crucial for safe and reliable robot motion planning and control. However, extending stability guarantees to trajectories defined on Riemannian manifolds poses significant challenges due to the manifold's geometric constraints. To address this, we propose a general framework for learning stable dynamical systems on Riemannian manifolds using neural ordinary differential equations. Our method guarantees stability by projecting the neural vector field evolving on the manifold so that it strictly satisfies the Lyapunov stability criterion, ensuring stability at every system state. By leveraging a flexible neural parameterisation for both the base vector field and the Lyapunov function, our framework can accurately represent complex trajectories while respecting manifold constraints by evolving solutions directly on the manifold. We provide an efficient training strategy for applying our framework and demonstrate its utility by solving Riemannian LASA datasets on the unit quaternion (S^3) and symmetric positive-definite matrix manifolds, as well as robotic motions evolving on \mathbb{R}^3 \times S^3. We demonstrate the performance, scalability, and practical applicability of our approach through extensive simulations and by learning robot motions in a real-world experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05707v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Boetius, Abdelrahman Abdelnaby, Ashok Kumar, Stefan Leue, Abdalla Swikir, Fares J. Abu-Dakka</dc:creator>
    </item>
    <item>
      <title>Safe Landing on Small Celestial Bodies with Gravitational Uncertainty Using Disturbance Estimation and Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2510.05895</link>
      <description>arXiv:2510.05895v1 Announce Type: cross 
Abstract: Soft landing on small celestial bodies (SCBs) poses unique challenges, as uncertainties in gravitational models and poorly characterized, dynamic environments require a high level of autonomy. Existing control approaches lack formal guarantees for safety constraint satisfaction, necessary to ensure the safe execution of the maneuvers. This paper introduces a control that addresses this limitation by integrating trajectory tracking, disturbance estimation, and safety enforcement. An extended high-gain observer is employed to estimate disturbances resulting from gravitational model uncertainties. We then apply a feedback-linearizing and disturbance-canceling controller that achieves exponential tracking of reference trajectories. Finally, we use a control barrier function based minimum-intervention controller to enforce state and input constraints through out the maneuver execution. This control combines trajectory tracking of offline generated reference trajectories with formal guarantees of safety, which follows common guidance and control architectures for spacecraft and allows aggressive maneuvers to be executed without compromising safety. Numerical simulations using fuel-optimal trajectories demonstrate the effectiveness of the controller in achieving precise and safe soft-landing, highlighting its potential for autonomous SCB missions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05895v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Arenas-Uribe, T. Michael Seigler, Jesse B. Hoagg</dc:creator>
    </item>
    <item>
      <title>Self-concordant Schr\"odinger operators: spectral gaps and optimization without condition numbers</title>
      <link>https://arxiv.org/abs/2510.06115</link>
      <description>arXiv:2510.06115v1 Announce Type: cross 
Abstract: Spectral gaps play a fundamental role in many areas of mathematics, computer science, and physics. In quantum mechanics, the spectral gap of Schr\"odinger operators has a long history of study due to its physical relevance, while in quantum computing spectral gaps are an important proxy for efficiency, such as in the quantum adiabatic algorithm. Motivated by convex optimization, we study Schr\"odinger operators associated with self-concordant barriers over convex domains and prove non-asymptotic lower bounds on the spectral gap for this class of operators. Significantly, we find that the spectral gap does not display any condition-number dependence when the usual Laplacian is replaced by the Laplace--Beltrami operator, which uses second-order information of the barrier and hence can take the curvature of the barrier into account. As an algorithmic application, we construct a novel quantum interior point method that applies to arbitrary self-concordant barriers and shows no condition-number dependence. To achieve this we combine techniques from semiclassical analysis, convex optimization, and quantum annealing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06115v1</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sander Gribling, Simon Apers, Harold Nieuwboer, Michael Walter</dc:creator>
    </item>
    <item>
      <title>Improved High-probability Convergence Guarantees of Decentralized SGD</title>
      <link>https://arxiv.org/abs/2510.06141</link>
      <description>arXiv:2510.06141v1 Announce Type: cross 
Abstract: Convergence in high-probability (HP) has been receiving increasing interest, due to its attractive properties, such as exponentially decaying tail bounds and strong guarantees for each individual run of an algorithm. While HP guarantees are extensively studied in centralized settings, much less is understood in the decentralized, networked setup. Existing HP studies in decentralized settings impose strong assumptions, like uniformly bounded gradients, or asymptotically vanishing noise, resulting in a significant gap between assumptions used to establish convergence in the HP and the mean-squared error (MSE) sense, even for vanilla Decentralized Stochastic Gradient Descent ($\mathtt{DSGD}$) algorithm. This is contrary to centralized settings, where it is known that $\mathtt{SGD}$ converges in HP under the same conditions on the cost function as needed to guarantee MSE convergence. Motivated by this observation, we revisit HP guarantees for $\mathtt{DSGD}$ in the presence of light-tailed noise. We show that $\mathtt{DSGD}$ converges in HP under the same conditions on the cost as in the MSE sense, removing uniformly bounded gradients and other restrictive assumptions, while simultaneously achieving order-optimal rates for both non-convex and strongly convex costs. Moreover, our improved analysis yields linear speed-up in the number of users, demonstrating that $\mathtt{DSGD}$ maintains strong performance in the HP sense and matches existing MSE guarantees. Our improved results stem from a careful analysis of the MGF of quantities of interest (norm-squared of gradient or optimality gap) and the MGF of the consensus gap between users' models. To achieve linear speed-up, we provide a novel result on the variance-reduction effect of decentralized methods in the HP sense and more fine-grained bounds on the MGF for strongly convex costs, which are both of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06141v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>From Halpern's Fixed-Point Iterations to Nesterov's Accelerated Interpretations for Root-Finding Problems</title>
      <link>https://arxiv.org/abs/2203.04869</link>
      <description>arXiv:2203.04869v2 Announce Type: replace 
Abstract: We derive an equivalent form of Halpern's fixed-point iteration scheme for solving a co-coercive equation (also called a root-finding problem), which can be viewed as a Nesterov's accelerated interpretation. We show that one method is equivalent to another via a simple transformation, leading to a straightforward convergence proof for Nesterov's accelerated scheme. Alternatively, we directly establish convergence rates of Nesterov's accelerated variant, and as a consequence, we obtain a new convergence rate of Halpern's fixed-point iteration. Next, we apply our results to different methods to solve monotone inclusions, where our convergence guarantees are applied. Since the gradient/forward scheme requires the co-coerciveness of the underlying operator, we derive new Nesterov's accelerated variants for both recent extra-anchored gradient and past-extra anchored gradient methods in the literature. These variants alleviate the co-coerciveness condition by only assuming the monotonicity and Lipschitz continuity of the underlying operator. Interestingly, our new Nesterov's accelerated interpretation of the past-extra anchored gradient method involves two past-iterate correction terms. This formulation is expected to guide us developing new Nesterov's accelerated methods for minimax problems and their continuous views without co-coericiveness. We test our theoretical results on two numerical examples, where the actual convergence rates match well the theoretical ones up to a constant factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.04869v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quoc Tran-Dinh</dc:creator>
    </item>
    <item>
      <title>An inexact LPA for DC composite optimization and application to matrix completions with outliers</title>
      <link>https://arxiv.org/abs/2303.16822</link>
      <description>arXiv:2303.16822v5 Announce Type: replace 
Abstract: This paper concerns a class of DC composite optimization problems which, as an extension of convex composite optimization problems and DC programs with nonsmooth components, often arises in robust factorization models of low-rank matrix recovery. For this class of nonconvex and nonsmooth problems, we propose an inexact linearized proximal algorithm (iLPA) by computing at each step an inexact minimizer of a strongly convex majorization constructed with a partial linearization of their objective functions at the current iterate. We establish the full convergence of the generated iterate sequence under the Kurdyka-\L\"ojasiewicz (KL) property of a potential function, and employ the composite structure to provide a verifiable condition for the potential function to satisfy the KL property of exponent $1/2$ at the limit point, so for the iterate sequence to have a local R-linear convergence rate. This condition is weaker than the one provided in \cite[Theorem 3.2]{LiPong18} for identifying the KL property of exponent $p\in[0,1)$ for a general composite function. The proposed iLPA is applied to a robust factorization model for matrix completion with outliers and non-uniform sampling, and numerical comparisons with the Polyak subgradient method and a proximal alternating minimization (PAM) method validate its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.16822v5</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Tao, Ruyu Liu, Shaohua Pan</dc:creator>
    </item>
    <item>
      <title>Oblivious Stochastic Composite Optimization</title>
      <link>https://arxiv.org/abs/2306.17470</link>
      <description>arXiv:2306.17470v2 Announce Type: replace 
Abstract: In stochastic convex optimization problems, most existing adaptive methods rely on prior knowledge about the diameter bound $D$ when the smoothness or the Lipschitz constant is unknown. This often significantly affects performance as only a rough approximation of $D$ is usually known in practice. Here, we bypass this limitation by combining mirror descent with dual averaging techniques and we show that, under oblivious step-sizes regime, our algorithms converge without any prior knowledge on the parameters of the problem. We introduce three oblivious stochastic algorithms to address different settings. The first algorithm is designed for objectives in relative scale, the second one is an accelerated version tailored for smooth objectives, whereas the last one is for relatively-smooth objectives. All three algorithms work without prior knowledge of the diameter of the feasible set, the Lipschitz constant or smoothness of the objective function. We use these results to revisit the problem of solving large-scale semidefinite programs using randomized first-order methods and stochastic smoothing. We extend our framework to relative scale and demonstrate the efficiency and robustness of our methods on large-scale semidefinite programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17470v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Lezane, Alexandre d'Aspremont</dc:creator>
    </item>
    <item>
      <title>Fast Policy Learning for Linear Quadratic Control with Entropy Regularization</title>
      <link>https://arxiv.org/abs/2311.14168</link>
      <description>arXiv:2311.14168v4 Announce Type: replace 
Abstract: This paper proposes and analyzes two new policy learning methods: regularized policy gradient (RPG) and iterative policy optimization (IPO), for a class of discounted linear-quadratic control (LQC) problems over an infinite time horizon with entropy regularization. Assuming access to the exact policy evaluation, both proposed approaches are proven to converge linearly in finding optimal policies of the regularized LQC. Moreover, the IPO method can achieve a super-linear convergence rate once it enters a local region around the optimal policy. Finally, when the optimal policy for an RL problem with a known environment is appropriately transferred as the initial policy to an RL problem with an unknown environment, the IPO method is shown to enable a super-linear convergence rate if the two environments are sufficiently close. Performances of these proposed algorithms are supported by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14168v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xin Guo, Xinyu Li, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Error Bounds for Rank-one Double Nonnegative Reformulations of QAP and Exact Penalties</title>
      <link>https://arxiv.org/abs/2403.11210</link>
      <description>arXiv:2403.11210v2 Announce Type: replace 
Abstract: This paper focuses on the error bounds for several equivalent rank-one doubly nonnegative (DNN) conic reformulations of the quadratic assignment problem (QAP), a class of challenging combinatorial optimization problems. We provide three equivalent rank-one DNN reformulations of the QAP, including the one proposed in \cite{Jiang21}, and establish the locally and globally Lipschitzian error bounds for their feasible sets. Then, these error bounds are employed to prove that the penalty problems induced by the difference-of-convexity (DC) reformulation of the rank-one constraint are global exact penalties, and so are the penalty problems for their Burer-Monteiro (BM) factorizations. As a byproduct, the penalty problem for the rank-one DNN reformulation in \cite{Jiang21} is shown to be a global exact penalty without the calmness assumption. Finally, we illustrate the application of these exact penalties by proposing a relaxation approach with one of them to seek a rank-one approximate feasible solution. This relaxation approach is validated to be superior to the commercial solver Gurobi for \textbf{132} benchmark instances in terms of the relative gap between the generated objective value and the known best one and the number of instances with better objective values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11210v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yitian Qian, Shaohua Pan, Shujun Bi, Houduo Qi</dc:creator>
    </item>
    <item>
      <title>Convergence of the majorized PAM method with subspace correction for low-rank composite factorization model</title>
      <link>https://arxiv.org/abs/2406.04588</link>
      <description>arXiv:2406.04588v3 Announce Type: replace 
Abstract: This paper focuses on the convergence certificates of the majorized proximal alternating minimization (PAM) method with subspace correction, proposed in \cite{TaoQianPan22} for the column $\ell_{2,0}$-norm regularized factorization model and now extended to a class of low-rank composite factorization models from matrix completion. The convergence analysis of this PAM method becomes extremely challenging because a subspace correction step is introduced to every proximal subproblem to ensure a closed-form solution. We establish the full convergence of the iterate sequence and column subspace sequences of factor pairs generated by the PAM, under the KL property of the objective function and a condition that holds automatically for the column $\ell_{2,0}$-norm function. Numerical comparison with the popular proximal alternating linearized minimization (PALM) method is conducted on one-bit matrix completion problems, which indicates that the PAM with subspace correction has an advantage in seeking lower relative error within less time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04588v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Tao, Yitian Qian, Shaohua Pan</dc:creator>
    </item>
    <item>
      <title>Strong bounds for large-scale Minimum Sum-of-Squares Clustering</title>
      <link>https://arxiv.org/abs/2502.08397</link>
      <description>arXiv:2502.08397v2 Announce Type: replace 
Abstract: Clustering is a fundamental technique in data analysis and machine learning, used to group similar data points together. Among various clustering methods, the Minimum Sum-of-Squares Clustering (MSSC) is one of the most widely used. MSSC aims to minimize the total squared Euclidean distance between data points and their corresponding cluster centroids. Due to the unsupervised nature of clustering, achieving global optimality is crucial, yet computationally challenging. The complexity of finding the global solution increases exponentially with the number of data points, making exact methods impractical for large-scale datasets. Even obtaining strong lower bounds on the optimal MSSC objective value is computationally prohibitive, making it difficult to assess the quality of heuristic solutions. We address this challenge by introducing a novel method to validate heuristic MSSC solutions through optimality gaps. Our approach employs a divide-and-conquer strategy, decomposing the problem into smaller instances that can be handled by an exact solver. The decomposition is guided by an auxiliary optimization problem, the "anticlustering problem", for which we design an efficient heuristic. Computational experiments demonstrate the effectiveness of the method for large-scale instances, achieving optimality gaps below 3% in most cases while maintaining reasonable computational times. These results highlight the practicality of our approach in assessing feasible clustering solutions for large datasets, bridging a critical gap in MSSC evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08397v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Livia Croella, Veronica Piccialli, Antonio M. Sudoso</dc:creator>
    </item>
    <item>
      <title>Stochastic exit-time control on the half-line over a finite horizon</title>
      <link>https://arxiv.org/abs/2503.19648</link>
      <description>arXiv:2503.19648v2 Announce Type: replace 
Abstract: We consider a finite-time stochastic drift control problem with the assumption that the control is bounded and the system is controlled until the state process leaves the half-line. Assuming general conditions, it is proved that the resulting parabolic Hamilton-Jacobi-Bellman equation has a classical solution. In fact, we consider an even more general family of semilinear equations, which might be helpful in solving other control or game problems. Not only is the existence result proved, but also a recursive procedure for finding a solution resulting from a fixed-point argument is provided. An application to the dividend optimization problem is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19648v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dariusz Zawisza</dc:creator>
    </item>
    <item>
      <title>BC-ADMM: An Efficient Non-convex Constrained Optimizer with Robotic Applications</title>
      <link>https://arxiv.org/abs/2504.05465</link>
      <description>arXiv:2504.05465v2 Announce Type: replace 
Abstract: Non-convex constrained optimizations are ubiquitous in robotic applications such as multi-agent navigation, UAV trajectory optimization, and soft robot simulation. For this problem class, conventional optimizers suffer from small step sizes and slow convergence. We propose BC-ADMM, a variant of Alternating Direction Method of Multiplier (ADMM), that can solve a class of non-convex constrained optimizations with biconvex constraint relaxation. Our algorithm allows larger step sizes by breaking the problem into small-scale sub-problems that can be easily solved in parallel. We show that our method has both theoretical convergence speed guarantees and practical convergence guarantees in the asymptotic sense. Through numerical experiments in a row of four robotic applications, we show that BC-ADMM has faster convergence than conventional gradient descent and Newton's method in terms of wall clock time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05465v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.RO</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherong Pan, Kui Wu</dc:creator>
    </item>
    <item>
      <title>An alternative definition for c-convex functions and another synthetic statement of MTW condition</title>
      <link>https://arxiv.org/abs/2505.12063</link>
      <description>arXiv:2505.12063v2 Announce Type: replace 
Abstract: The main theorem of this paper states that the c-convexity and the alternative c-convexity are equivalent if and only if the cost function c satisfies MTW condition. The alternative c-convex function is an analogy of the definition of the convex function that is using the inequality phi(t x1 + (1 - t) x0) &lt;= t phi(x1) + (1 - t) phi(x0). We study properties of the alternative c-convex functions and MTW condition, then prove the main theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12063v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonghyeon Jeong</dc:creator>
    </item>
    <item>
      <title>Gradient Methods with Online Scaling Part II. Practical Aspects</title>
      <link>https://arxiv.org/abs/2509.11007</link>
      <description>arXiv:2509.11007v2 Announce Type: replace 
Abstract: Part I of this work [Gao25] establishes online scaled gradient methods (OSGM), a framework that utilizes online convex optimization to adapt stepsizes in gradient methods. This paper focuses on the practical aspects of OSGM. We leverage the OSGM framework to design new adaptive first-order methods and provide insights into their empirical behavior. The resulting method, OSGM-Best, matches the performance of quasi-Newton variants while requiring less memory and cheaper iterations. We also extend OSGM to nonconvex optimization and outline directions that connect OSGM to existing branches of optimization theory and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11007v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ya-Chi Chu, Wenzhi Gao, Yinyu Ye, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>End-to-End Training of High-Dimensional Optimal Control with Implicit Hamiltonians via Jacobian-Free Backpropagation</title>
      <link>https://arxiv.org/abs/2510.00359</link>
      <description>arXiv:2510.00359v2 Announce Type: replace 
Abstract: Neural network approaches that parameterize value functions have succeeded in approximating high-dimensional optimal feedback controllers when the Hamiltonian admits explicit formulas. However, many practical problems, such as the space shuttle reentry problem and bicycle dynamics, among others, may involve implicit Hamiltonians that do not admit explicit formulas, limiting the applicability of existing methods. Rather than directly parameterizing controls, which does not leverage the Hamiltonian's underlying structure, we propose an end-to-end implicit deep learning approach that directly parameterizes the value function to learn optimal control laws. Our method enforces physical principles by ensuring trained networks adhere to the control laws by exploiting the fundamental relationship between the optimal control and the value function's gradient; this is a direct consequence of the connection between Pontryagin's Maximum Principle and dynamic programming. Using Jacobian-Free Backpropagation (JFB), we achieve efficient training despite temporal coupling in trajectory optimization. We show that JFB produces descent directions for the optimal control objective and experimentally demonstrate that our approach effectively learns high-dimensional feedback controllers across multiple scenarios involving implicit Hamiltonians, which existing methods cannot address.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00359v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Gelphman, Deepanshu Verma, Nicole Tianjiao Yang, Stanley Osher, Samy Wu Fung</dc:creator>
    </item>
    <item>
      <title>Modeling and Optimization of Control Problems on GPUs</title>
      <link>https://arxiv.org/abs/2510.03932</link>
      <description>arXiv:2510.03932v2 Announce Type: replace 
Abstract: We present a fully Julia-based, GPU-accelerated workflow for solving large-scale sparse nonlinear optimal control problems. Continuous-time dynamics are modeled and then discretized via direct transcription with \texttt{OptimalControl.jl} into structured sparse nonlinear programs. These programs are compiled into GPU kernels using \texttt{ExaModels.jl}, leveraging SIMD parallelism for fast evaluation of objectives, constraints, gradients, Jacobians and Hessians. The resulting sparse problems are solved entirely on GPU using the interior-point solver \texttt{MadNLP.jl} and the GPU sparse linear solver cuDSS, yielding significant speed-ups over CPU-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03932v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexis Montoison, Jean-Baptiste Caillau</dc:creator>
    </item>
    <item>
      <title>Measurement of Trustworthiness of the Online Reviews</title>
      <link>https://arxiv.org/abs/2210.00815</link>
      <description>arXiv:2210.00815v3 Announce Type: replace-cross 
Abstract: In electronic commerce (e-commerce)markets, a decision-maker faces a sequential choice problem. Third-party intervention is essential in making purchase decisions in this choice process. For instance, while purchasing products/services online, a buyer's choice or behavior is often affected by the overall reviewers' ratings, feedback, etc. Moreover, the reviewer is also a decision-maker. The question that arises is how trustworthy these review reports and ratings are. The trustworthiness of these review reports and ratings is based on whether the reviewer is rational or irrational. Indexing the reviewer's rationality could be a way to quantify a reviewer's rationality, but it needs to communicate the history of their behavior. In this article, the researcher aims to derive a rationality pattern function formally and, thereby, the degree of rationality of the decision-maker or the reviewer in the sequential choice problem in the e-commerce markets. Applying such a rationality pattern function could make quantifying the rational behavior of an agent participating in the digital markets easier. This, in turn, is expected to minimize the information asymmetry within the decision-making process and identify the paid reviewers or manipulative reviews.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00815v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipankar Das</dc:creator>
    </item>
    <item>
      <title>Nonlinear Filtering with Brenier Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2310.13886</link>
      <description>arXiv:2310.13886v3 Announce Type: replace-cross 
Abstract: This paper is concerned with the problem of nonlinear filtering, i.e., computing the conditional distribution of the state of a stochastic dynamical system given a history of noisy partial observations. Conventional sequential importance resampling (SIR) particle filters suffer from fundamental limitations, in scenarios involving degenerate likelihoods or high-dimensional states, due to the weight degeneracy issue. In this paper, we explore an alternative method, which is based on estimating the Brenier optimal transport (OT) map from the current prior distribution of the state to the posterior distribution at the next time step. Unlike SIR particle filters, the OT formulation does not require the analytical form of the likelihood. Moreover, it allows us to harness the approximation power of neural networks to model complex and multi-modal distributions and employ stochastic optimization algorithms to enhance scalability. Extensive numerical experiments are presented that compare the OT method to the SIR particle filter and the ensemble Kalman filter, evaluating the performance in terms of sample efficiency, high-dimensional scalability, and the ability to capture complex and multi-modal distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13886v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Al-Jarrah, Niyizhen Jin, Bamdad Hosseini, Amirhossein Taghvaei</dc:creator>
    </item>
    <item>
      <title>SAMCIRT: A Simultaneous Reconstruction and Affine Motion Compensation Technique for Four Dimensional Computed Tomography (4DCT)</title>
      <link>https://arxiv.org/abs/2402.04480</link>
      <description>arXiv:2402.04480v2 Announce Type: replace-cross 
Abstract: The majority of the recent iterative approaches in 4DCT not only rely on nested iterations, thereby increasing computational complexity and constraining potential acceleration, but also fail to provide a theoretical proof of convergence for their proposed iterative schemes. On the other hand, the latest MATLAB and Python image processing toolboxes lack the implementation of analytic adjoints of affine motion operators for 3D object volumes, which does not allow gradient methods using exact derivatives towards affine motion parameters. In this work, we propose the Simultaneous Affine Motion-Compensated Image Reconstruction Technique (SAMCIRT)- an efficient iterative reconstruction scheme that combines image reconstruction and affine motion estimation in a single update step, based on the analytic adjoints of the motion operators then exact partial derivatives with respect to both the reconstruction and the affine motion parameters. Moreover, we prove the separated Lipschitz continuity of the objective function and its associated functions, including the gradient, which supports the convergence of our proposed iterative scheme, despite the non-convexity of the objective function with respect to the affine motion parameters. Results from simulation and real experiments show that our method outperforms the state-of-the-art CT reconstruction with affine motion correction methods in computational feasibility and projection distance. In particular, this allows accurate reconstruction for a real, nonstationary diamond, showing a novel application of 4DCT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04480v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anh-Tuan Nguyen, Jens Renders, Khoi-Nguyen Nguyen, Tat-Dat To, Domenico Iuso, Yves Maris</dc:creator>
    </item>
    <item>
      <title>Constrained free energy minimization for the design of thermal states and stabilizer thermodynamic systems</title>
      <link>https://arxiv.org/abs/2508.09103</link>
      <description>arXiv:2508.09103v2 Announce Type: replace-cross 
Abstract: A quantum thermodynamic system is described by a Hamiltonian and a list of conserved, non-commuting charges, and a fundamental goal is to determine the minimum energy of the system subject to constraints on the charges. Recently, [Liu et al., arXiv:2505.04514] proposed first- and second-order classical and hybrid quantum-classical algorithms for solving a dual chemical potential maximization problem, and they proved that these algorithms converge to global optima by means of gradient-ascent approaches. In this paper, we benchmark these algorithms on several problems of interest in thermodynamics, including one- and two-dimensional quantum Heisenberg models with nearest and next-to-nearest neighbor interactions and with the charges set to the total x, y, and z magnetizations. We also offer an alternative compelling interpretation of these algorithms as methods for designing ground and thermal states of controllable Hamiltonians, with potential applications in molecular and material design. Furthermore, we introduce stabilizer thermodynamic systems as thermodynamic systems based on stabilizer codes, with the Hamiltonian constructed from a given code's stabilizer operators and the charges constructed from the code's logical operators. We benchmark the aforementioned algorithms on several examples of stabilizer thermodynamic systems, including those constructed from the one-to-three-qubit repetition code, the perfect one-to-five-qubit code, and the two-to-four-qubit error-detecting code. Finally, we observe that the aforementioned hybrid quantum-classical algorithms, when applied to stabilizer thermodynamic systems, can serve as alternative methods for encoding qubits into stabilizer codes at a fixed temperature, and we provide an effective method for warm-starting these encoding algorithms whenever a single qubit is encoded into multiple physical qubits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09103v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Minervini, Madison Chin, Jacob Kupperman, Nana Liu, Ivy Luo, Meghan Ly, Soorya Rethinasamy, Kathie Wang, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Minimizing the Weighted Number of Tardy Jobs: Data-Driven Heuristic for Single-Machine Scheduling</title>
      <link>https://arxiv.org/abs/2508.13703</link>
      <description>arXiv:2508.13703v2 Announce Type: replace-cross 
Abstract: Existing research on single-machine scheduling is largely focused on exact algorithms, which perform well on typical instances but can significantly deteriorate on certain regions of the problem space. In contrast, data-driven approaches provide strong and scalable performance when tailored to the structure of specific datasets. Leveraging this idea, we focus on a single-machine scheduling problem where each job is defined by its weight, duration, due date, and deadline, aiming to minimize the total weight of tardy jobs. We introduce a novel data-driven scheduling heuristic that combines machine learning with problem-specific characteristics, ensuring feasible solutions, which is a common challenge for ML-based algorithms. Experimental results demonstrate that our approach significantly outperforms the state-of-the-art in terms of optimality gap, number of optimal solutions, and adaptability across varied data scenarios, highlighting its flexibility for practical applications. In addition, we conduct a systematic exploration of ML models, addressing a common gap in similar studies by offering a detailed model selection process and providing insights into why the chosen model is the best fit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13703v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cor.2025.107281</arxiv:DOI>
      <dc:creator>Nikolai Antonov, Pr\v{e}mysl \v{S}\r{u}cha, Mikol\'a\v{s} Janota, Jan H\r{u}la</dc:creator>
    </item>
    <item>
      <title>Strong Lyapunov functions for rough systems</title>
      <link>https://arxiv.org/abs/2508.14559</link>
      <description>arXiv:2508.14559v3 Announce Type: replace-cross 
Abstract: We introduce the concept of {\it strong Lyapunov functions} to investigate the long term behavior of autonomous ordinary differential equations under a multiplicative noise of H\"older continuity, using rough path calculus and the framework of random dynamical systems. We conclude that if such a function exists for the drift then the perturbed system admits the global random pullback attractor which is upper semi-continuous w.r.t. the noise intensity coefficient and the dyadic approximation of the noise. Moreover, in case the drift is globally Lipschitz continuous, then there exists also a numerical attractor for the discritization which is also upper semi-continuous w.r.t. the noise intensity and also converges to the continuous attractor as the step size tends to zero. Several applications are studied, including dissipative systems, the pendulum, Fitzhugh-Nagumo neuro-system and Lorenz system. We also prove that strong Lyapunov functions could be approximated in practice by Lyapunov neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14559v3</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luu Hoang Duc, J\"urgen Jost</dc:creator>
    </item>
    <item>
      <title>Learning to Price Bundles: A GCN Approach for Mixed Bundling</title>
      <link>https://arxiv.org/abs/2509.22557</link>
      <description>arXiv:2509.22557v2 Announce Type: replace-cross 
Abstract: Bundle pricing refers to designing several product combinations (i.e., bundles) and determining their prices in order to maximize the expected profit. It is a classic problem in revenue management and arises in many industries, such as e-commerce, tourism, and video games. However, the problem is typically intractable due to the exponential number of candidate bundles. In this paper, we explore the usage of graph convolutional networks (GCNs) in solving the bundle pricing problem. Specifically, we first develop a graph representation of the mixed bundling model (where every possible bundle is assigned with a specific price) and then train a GCN to learn the latent patterns of optimal bundles. Based on the trained GCN, we propose two inference strategies to derive high-quality feasible solutions. A local-search technique is further proposed to improve the solution quality. Numerical experiments validate the effectiveness and efficiency of our proposed GCN-based framework. Using a GCN trained on instances with 5 products, our methods consistently achieve near-optimal solutions (better than 97%) with only a fraction of computational time for problems of small to medium size. It also achieves superior solutions for larger size of problems compared with other heuristic methods such as bundle size pricing (BSP). The method can also provide high quality solutions for instances with more than 30 products even for the challenging cases where product utilities are non-additive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22557v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangyu Ding, Chenghan Wu, Guokai Li, Zizhuo Wang</dc:creator>
    </item>
    <item>
      <title>Constrained Dikin-Langevin diffusion for polyhedra</title>
      <link>https://arxiv.org/abs/2510.04582</link>
      <description>arXiv:2510.04582v2 Announce Type: replace-cross 
Abstract: Interior-point geometry offers a straightforward approach to constrained sampling and optimization on polyhedra, eliminating reflections and ad hoc projections. We exploit the Dikin log-barrier to define a Dikin--Langevin diffusion whose drift and noise are modulated by the inverse barrier Hessian. In continuous time, we establish a boundary no-flux property; trajectories started in the interior remain in $U$ almost surely, so feasibility is maintained by construction. For computation, we adopt a discretize-then-correct design: an Euler--Maruyama proposal with state-dependent covariance, followed by a Metropolis--Hastings correction that targets the exact constrained law and reduces to a Dikin random walk when $f$ is constant.
  Numerically, the unadjusted diffusion exhibits the expected first-order step size bias, while the MH-adjusted variant delivers strong convergence diagnostics on anisotropic, box-constrained Gaussians (rank-normalized split-$\hat{R}$ concentrated near $1$) and higher inter-well transition counts on a bimodal target, indicating superior cross-well mobility. Taken together, these results demonstrate that coupling calibrated stochasticity with interior-point preconditioning provides a practical, reflection-free approach to sampling and optimization over polyhedral domains, offering clear advantages near faces, corners, and in nonconvex landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04582v2</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Chok, Domenic Petzinna</dc:creator>
    </item>
  </channel>
</rss>
