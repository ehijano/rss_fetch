<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:00:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Lung Cancer Survival Prediction Using Machine Learning and Statistical Methods</title>
      <link>https://arxiv.org/abs/2510.01267</link>
      <description>arXiv:2510.01267v1 Announce Type: new 
Abstract: Lung cancer remains one of the leading causes of cancer-related mortality, yet most survival models rely only on baseline factors and overlook posttreatment variables that reflect disease progression. To address this gap, we applied Cox Proportional Hazards and Random Survival Forests, integrating baseline features with post-treatment predictors such as progression-free interval (PFI.time) and residual tumor status. The Cox model achieved a concordance index (C-index) of 0.90, while the RSF model reached 0.86, both outperforming previous studies. Beyond statistical gains, the integration of post-treatment variables provides oncologists with more clinically meaningful and reliable survival estimates. This enables improved treatment planning, more personalized patient counseling, and better-informed follow-up strategies. From a practical standpoint, these results demonstrate how routinely collected clinical variables can be transformed into actionable survival predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01267v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Varun Vishwanathan Nair, Victor Miranda Soberanis</dc:creator>
    </item>
    <item>
      <title>Neural Tangent Kernels for Complex Genetic Risk Prediction: Bridging Deep Learning and Kernel Methods in Genomics</title>
      <link>https://arxiv.org/abs/2510.01426</link>
      <description>arXiv:2510.01426v1 Announce Type: new 
Abstract: Given the complexity of genetic risk prediction, there is a critical need for the development of novel methodologies that can effectively capture intricate genotype--phenotype relationships (e.g., nonlinear) while remaining statistically interpretable and computationally tractable. We develop a Neural Tangent Kernel (NTK) framework to integrate kernel methods into deep neural networks for genetic risk prediction analysis. We consider two approaches: NTK-LMM, which embeds the empirical NTK in a linear mixed model with variance components estimated via minimum quadratic unbiased estimator (MINQUE), and NTK-KRR, which performs kernel ridge regression with cross-validated regularization. Through simulation studies, we show that NTK-based models outperform the traditional neural network models and linear mixed models. By applying NTK to endophenotypes (e.g., hippocampal volume) and AD-related genes (e.g., APOE) from Alzheimer's Disease Neuroimaging Initiative (ADNI), we found that NTK achieved higher accuracy than existing methods for hippocampal volume and entorhinal cortex thickness. In addition to its accuracy performance, NTK has favorable optimization properties (i.e., having a closed-form or convex training) and generates interpretable results due to its connection to variance components and heritability. Overall, our results indicate that by integrating the strengths of both deep neural networks and kernel methods, NTK offers competitive performance for genetic risk prediction analysis while having the advantages of interpretability and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01426v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heng Ge, Qing Lu</dc:creator>
    </item>
    <item>
      <title>The Perceived Influences of Environment on Health in Italy: a Penalized Ordinal Regression Approach</title>
      <link>https://arxiv.org/abs/2510.01803</link>
      <description>arXiv:2510.01803v1 Announce Type: new 
Abstract: Understanding how individuals perceive their living environment is a complex task, as it reflects both personal and contextual determinants. In this paper, we address this task by analyzing the environmental module of the Italian nationwide health surveillance system PASSI (Progressi delle Aziende Sanitarie per la Salute in Italia), integrating it with contextual information at the municipal level, including socio-economic indicators, pollution exposure, and other geographical characteristics. Methodologically, we adopt a penalized semi-parallel cumulative ordinal regression model to analyze how subjective perceptions are shaped by both personal and territorial determinants. The approach balances flexibility and interpretability by allowing both parallel and non-parallel effects while regularizing estimates to address multicollinearity and separation issues. We use the model as an analytical tool to uncover the determinants of positivity and neutrality in environmental perceptions, defined as factors that contribute the most to improving perception or increasing the sense of neutrality. The results are diverse. First, results reveal significant heterogeneity across Italian territories, indicating that local characteristics strongly shape environmental perception. Second, various individual factors interact with contextual influences to shape perceptions. Third, hazardous environmental factors, such as higher PM2.5 levels, appear to be associated with poorer environmental perception, suggesting a tendency among respondents to recognize specific environmental issues. Overall, the approach demonstrates strong potential for application and provides useful insights for environmental policy planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01803v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mattia Stival, Angela Andreella, Gaia Bertarelli, Catarina Mid\~oes, Stefano Federico Tonellato, Enrica De Cian, Stefano Campostrini</dc:creator>
    </item>
    <item>
      <title>Dependent stochastic block models for age-indexed sequences of directed causes-of-death networks</title>
      <link>https://arxiv.org/abs/2510.01806</link>
      <description>arXiv:2510.01806v1 Announce Type: new 
Abstract: Death events commonly arise from complex interactions among interrelated causes, formally classified in reporting practices as underlying and contributing. Leveraging information from death certificates, these interactions can be naturally represented through a sequence of directed networks encoding co-occurrence strengths between pairs of underlying and contributing causes across ages. Although this perspective opens the avenues to learn informative age-specific block interactions among endogenous groups of underlying and contributing causes displaying similar co-occurrence patterns, there has been limited research along this direction in mortality modeling. This is mainly due to the lack of suitable stochastic block models for age-indexed sequences of directed networks. We cover this gap through a novel Bayesian formulation which crucially learns two separate group structures for underlying and contributing causes, while allowing both structures to change smoothly across ages via dependent random partition priors. As illustrated in simulations, this formulation outperforms state-of-the-art solutions that could be adapted to our motivating application. Moreover, when applied to USA mortality data, it unveils structures in the composition, evolution, and modular interactions among causes-of-death groups that were hidden to previous studies. Such findings could have relevant policy implications and contribute to an improved understanding of the recent "death of despair" phenomena in USA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01806v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Roman\`o, Cristian Castiglione, Daniele Durante</dc:creator>
    </item>
    <item>
      <title>Multidata Causal Discovery for Statistical Hurricane Intensity Forecasting</title>
      <link>https://arxiv.org/abs/2510.02050</link>
      <description>arXiv:2510.02050v1 Announce Type: new 
Abstract: Improving statistical forecasts of Atlantic hurricane intensity is limited by complex nonlinear interactions and difficulty in identifying relevant predictors. Conventional methods prioritize correlation or fit, often overlooking confounding variables and limiting generalizability to unseen tropical storms. To address this, we leverage a multidata causal discovery framework with a replicated dataset based on Statistical Hurricane Intensity Prediction Scheme (SHIPS) using ERA5 meteorological reanalysis. We conduct multiple experiments to identify and select predictors causally linked to hurricane intensity changes. We train multiple linear regression models to compare causal feature selection with no selection, correlation, and random forest feature importance across five forecast lead times from 1 to 5 days (24 to 120 hours). Causal feature selection consistently outperforms on unseen test cases, especially for lead times shorter than 3 days. The causal features primarily include vertical shear, mid-tropospheric potential vorticity and surface moisture conditions, which are physically significant yet often underutilized in hurricane intensity predictions. Further, we build an extended predictor set (SHIPS+) by adding selected features to the standard SHIPS predictors. SHIPS+ yields increased short-term predictive skill at lead times of 24, 48, and 72 hours. Adding nonlinearity using multilayer perceptron further extends skill to longer lead times, despite our framework being purely regional and not requiring global forecast data. Operational SHIPS tests confirm that three of the six added causally discovered predictors improve forecasts, with the largest gains at longer lead times. Our results demonstrate that causal discovery improves hurricane intensity prediction and pave the way toward more empirical forecasts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02050v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saranya Ganesh S., Frederick Iat-Hin Tam, Milton S. Gomez, Marie McGraw, Mark DeMaria, Kate Musgrave, Jakob Runge, Tom Beucler</dc:creator>
    </item>
    <item>
      <title>How to Find Fantastic Papers: Self-Rankings as a Powerful Predictor of Scientific Impact Beyond Peer Review</title>
      <link>https://arxiv.org/abs/2510.02143</link>
      <description>arXiv:2510.02143v1 Announce Type: new 
Abstract: Peer review in academic research aims not only to ensure factual correctness but also to identify work of high scientific potential that can shape future research directions. This task is especially critical in fast-moving fields such as artificial intelligence (AI), yet it has become increasingly difficult given the rapid growth of submissions. In this paper, we investigate an underexplored measure for identifying high-impact research: authors' own rankings of their multiple submissions to the same AI conference. Grounded in game-theoretic reasoning, we hypothesize that self-rankings are informative because authors possess unique understanding of their work's conceptual depth and long-term promise. To test this hypothesis, we conducted a large-scale experiment at a leading AI conference, where 1,342 researchers self-ranked their 2,592 submissions by perceived quality. Tracking outcomes over more than a year, we found that papers ranked highest by their authors received twice as many citations as their lowest-ranked counterparts; self-rankings were especially effective at identifying highly cited papers (those with over 150 citations). Moreover, we showed that self-rankings outperformed peer review scores in predicting future citation counts. Our results remained robust after accounting for confounders such as preprint posting time and self-citations. Together, these findings demonstrate that authors' self-rankings provide a reliable and valuable complement to peer review for identifying and elevating high-impact research in AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02143v1</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Buxin Su, Natalie Collina, Garrett Wen, Didong Li, Kyunghyun Cho, Jianqing Fan, Bingxin Zhao, Weijie Su</dc:creator>
    </item>
    <item>
      <title>Privacy-Aware Sequential Learning</title>
      <link>https://arxiv.org/abs/2502.19525</link>
      <description>arXiv:2502.19525v5 Announce Type: cross 
Abstract: In settings like vaccination registries, individuals act after observing others, and the resulting public records can expose private information. We study privacy-preserving sequential learning, where agents add endogenous noise to their reported actions to conceal private signals. Efficient social learning relies on information flow, seemingly in conflict with privacy. Surprisingly, with continuous signals and a fixed privacy budget $(\epsilon)$, the optimal randomization strategy balances privacy and accuracy, accelerating learning to $\Theta_{\epsilon}(\log n)$, faster than the nonprivate $\Theta(\sqrt{\log n})$ rate. In the nonprivate baseline, the expected time to the first correct action and the number of incorrect actions diverge; under privacy with sufficiently small $\epsilon$, both are finite. Privacy helps because, under the false state, agents more often receive signals contradicting the majority; randomization then asymmetrically amplifies the log-likelihood ratio, enhancing aggregation. In heterogeneous populations, an order-optimal $\Theta(\sqrt{n})$ rate is achievable when a subset of agents have low privacy budgets. With binary signals, however, privacy reduces informativeness and impairs learning relative to the nonprivate baseline, though the dependence on $\epsilon$ is nonmonotone. Our results show how privacy reshapes information dynamics and inform the design of platforms and policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19525v5</guid>
      <category>econ.TH</category>
      <category>cs.CR</category>
      <category>cs.SI</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxin Liu, M. Amin Rahimian</dc:creator>
    </item>
    <item>
      <title>DiffKnock: Diffusion-based Knockoff Statistics for Neural Networks Inference</title>
      <link>https://arxiv.org/abs/2510.01418</link>
      <description>arXiv:2510.01418v1 Announce Type: cross 
Abstract: We introduce DiffKnock, a diffusion-based knockoff framework for high-dimensional feature selection with finite-sample false discovery rate (FDR) control. DiffKnock addresses two key limitations of existing knockoff methods: preserving complex feature dependencies and detecting non-linear associations. Our approach trains diffusion models to generate valid knockoffs and uses neural network--based gradient and filter statistics to construct antisymmetric feature importance measures. Through simulations, we showed that DiffKnock achieved higher power than autoencoder-based knockoffs while maintaining target FDR, indicating its superior performance in scenarios involving complex non-linear architectures. Applied to murine single-cell RNA-seq data of LPS-stimulated macrophages, DiffKnock identifies canonical NF-$\kappa$B target genes (Ccl3, Hmox1) and regulators (Fosb, Pdgfb). These results highlight that, by combining the flexibility of deep generative models with rigorous statistical guarantees, DiffKnock is a powerful and reliable tool for analyzing single-cell RNA-seq data, as well as high-dimensional and structured data in other domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01418v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heng Ge, Qing Lu</dc:creator>
    </item>
    <item>
      <title>Increasing accessibility by public transport benefits local economy: the effect of a new metro line in Rome</title>
      <link>https://arxiv.org/abs/2510.01449</link>
      <description>arXiv:2510.01449v1 Announce Type: cross 
Abstract: This study investigates the economic impact of Metro C, a major expansion of Rome's metro system. Using a difference-in-differences (DID) approach within a multiplicative framework, the research quantifies the impact of increased accessibility on local economic activities. The results show a statistically significant rise in the number of economic activities in areas affected by the new line. A mild decline in economic diversity suggests the emergence of spatial clustering of similar activities. A dedicated analysis of microenterprises, which represent the majority of the dataset, examines changes in employment and GDP associated with the new infrastructure. The observed zone-level correlation between accessibility gains and growth in economic activities also offers a basis for generalising the findings beyond the specific case of Metro C. Overall, the case study shows that public transport investments aimed at boosting sustainable mobility can also generate positive spillover effects on the local economic fabric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01449v1</guid>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Marzolla, Bruno Campanelli, Hygor Piaget Monteiro Melo, Matteo Bruno, Vittorio Loreto</dc:creator>
    </item>
    <item>
      <title>Z-scores-based methods and their application to biological monitoring: An extended analysis of professional soccer players and cyclists athletes</title>
      <link>https://arxiv.org/abs/2510.01810</link>
      <description>arXiv:2510.01810v1 Announce Type: cross 
Abstract: The increase in the collection of biological data allows for the individual and longitudinal monitoring of hematological or urine biomarkers. However, identifying abnormal behavior in these biological sequences is not trivial. Moreover, the complexity of the biological data (correlation between biomarkers, seasonal effects, etc.) is also an issue. Z-score methods can help assess the abnormality in these longitudinal sequences while capturing some features of the biological complexity. This work details a statistical framework for handling biological sequences using three custom Z-score methods in the intra-individual variability scope. These methods can detect abnormal samples in the longitudinal sequences with respect to the seasonality, chronological time or correlation between biomarkers. One of these methods is an extension of one custom Z-score method to the Gaussian linear model, which allows for including additional variables in the model design. We illustrate the use of the framework on the longitudinal data of 3,936 professional soccer players (5 biomarkers) and 1,683 amateur or professional cyclists (10 biomarkers). The results show that a particular Z-score method, designed to detect a change in a series of consecutive observations, measured a high proportion of abnormal values (more than three times the false positive rate) in the ferritin and IGF1 biomarkers for both data sets. The proposed framework and methods could be applied in other contexts, such as the clinical patient follow-up in monitoring abnormal values of biological markers. The methods are flexible enough to include more complicated biological features, which can be directly incorporated into the model design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01810v1</guid>
      <category>cs.MS</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geoffroy C. B. Berthelot (IRMES - URP\_7329, RELAIS), Brigitte Gelein (ENSAI, IRMAR), Eric Meinadier (FFC), Emmanuel Orhant (FFF), J\'er\^ome Dedecker (MAP5 - UMR 8145)</dc:creator>
    </item>
    <item>
      <title>Multivariate distributional modeling of low, moderate, and large intensities without threshold selection steps</title>
      <link>https://arxiv.org/abs/2510.02152</link>
      <description>arXiv:2510.02152v1 Announce Type: cross 
Abstract: In fields such as hydrology and climatology, modelling the entire distribution of positive data is essential, as stakeholders require insights into the full range of values, from low to extreme. Traditional approaches often segment the distribution into separate regions, which introduces subjectivity and limits coherence. This is especially true when dealing with multivariate data.
  In line with multivariate extreme value theory, this paper presents a unified, threshold-free framework for modelling marginal behaviours and dependence structures based on an extended generalized Pareto distribution (EGPD). We propose decomposing multivariate data into radial and angular components. The radial component is modelled using a semi-parametric EGPD and the angular distribution is permitted to vary conditionally. This approach allows for sufficiently flexible dependence modelling.
  The hierarchical structure of the model facilitates the inference process. First, we combine classical maximum likelihood estimation (MLE) methods with semi-parametric approaches based on Bernstein polynomials to estimate the distribution of the radial component. Then, we use multivariate regression techniques to estimate the angular component's parameters.
  The model is evaluated through synthetic simulations and applied to hydrological datasets to exemplify its capacity to capture heavy-tailed marginals and complex multivariate dependencies without threshold specification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02152v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Carlo Gaetan, Philippe Naveau</dc:creator>
    </item>
    <item>
      <title>Partial Identification of Structural Vector Autoregressions with Non-Centred Stochastic Volatility</title>
      <link>https://arxiv.org/abs/2404.11057</link>
      <description>arXiv:2404.11057v2 Announce Type: replace-cross 
Abstract: We consider structural vector autoregressions that are identified through stochastic volatility under Bayesian estimation. Three contributions emerge from our exercise. First, we show that a non-centred parameterization of stochastic volatility yields a marginal prior for the conditional variances of structural shocks that is centred on homoskedasticity, with strong shrinkage and heavy tails -- unlike the common centred parameterization. This feature makes it well suited for assessing partial identification of any shock of interest. Second, Monte Carlo experiments on small and large systems indicate that the non-centred setup estimates structural parameters more precisely and normalizes conditional variances efficiently. Third, revisiting prominent fiscal structural vector autoregressions, we show how the non-centred approach identifies tax shocks that are consistent with estimates reported in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11057v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Helmut L\"utkepohl (Freie Universit\"at Berlin and DIW Berlin), Fei Shang (South China University of Technology and Yuexiu Capital Holdings Group), Luis Uzeda (Bank of Canada), Tomasz Wo\'zniak (University of Melbourne)</dc:creator>
    </item>
    <item>
      <title>Development and Validation of a Dynamic Kidney Failure Prediction Model based on Deep Learning: A Real-World Study with External Validation</title>
      <link>https://arxiv.org/abs/2501.16388</link>
      <description>arXiv:2501.16388v2 Announce Type: replace-cross 
Abstract: Background: Chronic kidney disease (CKD), a progressive disease with high morbidity and mortality, has become a significant global public health problem. Most existing models are static and fail to capture temporal trends in disease progression, limiting their ability to inform timely interventions. We address this gap by developing a dynamic model that leverages common longitudinal clinical indicators from real-world Electronic Health Records (EHRs) for real-time kidney failure prediction.
  Findings: A retrospective cohort of 4,587 patients from Yinzhou, China, was used for model development (2,752 patients for training, 917 patients for validation) and internal validation (918 patients), while external validation was conducted on a prospective PKUFH cohort (934 patients). The model demonstrated competitive performance across datasets, with an AUROC of 0.9311 (95%CI, 0.8873-0.9749) in the internal validation cohort and 0.8141 (95%CI, 0.7728-0.8554) in the external validation cohort, alongside progressively improving dynamic predictions, good calibration, and clinically consistent interpretability. KFDeep has been deployed on an open-access website and in primary care settings.
  Interpretation: The KFDeep model enables dynamic prediction of kidney failure without increasing clinical examination costs. It has been integrated into existing hospital systems, providing physicians with a continuously updated decision-support tool in routine care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16388v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingying Ma, Jinwei Wang, Lanlan Lu, Yexiang Sun, Mengling Feng, Feifei Zhang, Peng Shen, Zhiqin Jiang, Shenda Hong, Luxia Zhang</dc:creator>
    </item>
    <item>
      <title>Online Multivariate Regularized Distributional Regression for High-dimensional Probabilistic Electricity Price Forecasting</title>
      <link>https://arxiv.org/abs/2504.02518</link>
      <description>arXiv:2504.02518v2 Announce Type: replace-cross 
Abstract: Probabilistic electricity price forecasting (PEPF) is vital for short-term electricity markets, yet the multivariate nature of day-ahead prices - spanning 24 consecutive hours - remains underexplored. At the same time, real-time decision-making requires methods that are both accurate and fast. We introduce an online algorithm for multivariate distributional regression models, allowing an efficient modelling of the conditional means, variances, and dependence structures of electricity prices. The approach combines multivariate distributional regression with online coordinate descent and LASSO-type regularization, enabling scalable estimation in high-dimensional covariate spaces. Additionally, we propose a regularized estimation path over increasingly complex dependence structures, allowing for early stopping and avoiding overfitting. In a case study of the German day-ahead market, our method outperforms a wide range of benchmarks, showing that modeling dependence improves both calibration and predictive accuracy. Furthermore, we analyse the trade-off between predictive accuracy and computational costs for batch and online estimation and provide an high-performing open-source Python implementation in the ondil package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02518v2</guid>
      <category>stat.ML</category>
      <category>econ.EM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Hirsch</dc:creator>
    </item>
    <item>
      <title>How to optimise tournament draws: The case of the FIFA World Cup</title>
      <link>https://arxiv.org/abs/2505.13106</link>
      <description>arXiv:2505.13106v2 Announce Type: replace-cross 
Abstract: The organisers of major sports competitions use different policies with respect to constraints in the group draw. Our paper aims to rationalise these choices by analysing the trade-off between attractiveness (the number of games played by teams from the same geographic zone) and fairness (the departure of the draw mechanism from a uniform distribution). A parametric optimisation model is formulated and applied to the 2018 and 2022 FIFA World Cup draws. A flaw of the draw procedure is identified: the pre-assignment of the host to a group unnecessarily increases the distortions. All Pareto efficient sets of draw constraints are determined via simulations. The proposed framework can be used to find the optimal draw rules and justify the non-uniformity of the draw procedure for the stakeholders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13106v2</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>GARG-AML against Smurfing: A Scalable and Interpretable Graph-Based Framework for Anti-Money Laundering</title>
      <link>https://arxiv.org/abs/2506.04292</link>
      <description>arXiv:2506.04292v2 Announce Type: replace-cross 
Abstract: Purpose: This paper introduces a novel graph-based method, GARG-AML, for efficient and effective anti-money laundering (AML). It quantifies smurfing risk, a popular money laundering method, by providing each node in the network with a single interpretable score. The proposed method strikes a balance among computational efficiency, detection power and transparency. Different versions of GARG-AML are introduced for undirected and directed networks.
  Methodology: GARG-AML constructs the adjacency matrix of a node's second-order neighbourhood in a specific way. This allows us to use the density of different blocks in the adjacency matrix to express the neighbourhood's resemblance to a pure smurfing pattern. GARG-AML is extended using a decision tree and gradient-boosting classifier to increase its performance even more. The methods are tested on synthetic and on open-source data against the current state-of-the-art in AML.
  Findings: We find that GARG-AML obtains state-of-the-art performance on all datasets. We illustrate that GARG-AML scales well to massive transactions graphs encountered at financial institutions. By leveraging only the adjacency matrix of the second-order neighbourhood and basic network features, this work highlights the potential of fundamental network properties towards advancing fraud detection.
  Originality: This paper uses only basic network features and expert knowledge on smurfing to construct a performant AML system. The originality lies in the translation of smurfing detection to these features and network representation. Our proposed method is built around the real business needs of scalability and interpretability. It therefore provides a solution that can be easily implemented at financial institutions or incorporated in existing AML solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04292v2</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruno Deprez, Bart Baesens, Tim Verdonck, Wouter Verbeke</dc:creator>
    </item>
    <item>
      <title>How Much Is Too Much? Adaptive, Context-Aware Risk Detection in Naturalistic Driving</title>
      <link>https://arxiv.org/abs/2508.00888</link>
      <description>arXiv:2508.00888v3 Announce Type: replace-cross 
Abstract: Reliable risk identification based on driver behavior data underpins real-time safety feedback, fleet risk management, and evaluation of driver-assist systems. While naturalistic driving studies have become foundational for providing real-world driver behavior data, the existing frameworks for identifying risk based on such data have two fundamental limitations: (i) they rely on predefined time windows and fixed thresholds to disentangle risky and normal driving behavior, and (ii) they assume behavior is stationary across drivers and time, ignoring heterogeneity and temporal drift. In practice, these limitations can lead to timing errors and miscalibration in alerts, weak generalization to new drivers/routes/conditions, and higher false-alarm and miss rates, undermining driver trust and reducing safety intervention effectiveness. To address this gap, we propose a unified, context-aware framework that adapts labels and models over time and across drivers via rolling windows, joint optimization, dynamic calibration, and model fusion, tailored for time-stamped kinematic data. The framework is tested using two safety indicators, speed-weighted headway and harsh driving events, and three models: Random Forest, XGBoost, and Deep Neural Network (DNN). Speed-weighted headway yielded more stable and context-sensitive classifications than harsh-event counts. XGBoost maintained consistent performance under changing thresholds, whereas DNN achieved higher recall at lower thresholds but with greater variability across trials. The ensemble aggregated signals from multiple models into a single risk decision, balancing responsiveness to risky behavior with control of false alerts. Overall, the framework shows promise for adaptive, context-aware risk detection that can enhance real-time safety feedback and support driver-focused interventions in intelligent transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00888v3</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Hossein Kalantari, Eleonora Papadimitriou, Arkady Zgonnikov, Amir Pooyan Afghari</dc:creator>
    </item>
    <item>
      <title>Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji</title>
      <link>https://arxiv.org/abs/2509.13388</link>
      <description>arXiv:2509.13388v2 Announce Type: replace-cross 
Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible in the massive development projects that include housing, roads, and civil works. In this study, we present machine learning and remote sensing frameworks to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The ultimate goal of this study is to provide technical support in land cover/land use modelling and change detection. We used Landsat-8 satellite image for the study region and created our training dataset with labels for supervised machine learning. We used Google Earth Engine and unsupervised machine learning via k-means clustering to generate the land cover map. We used convolutional neural networks to classify the selected regions' land cover types. We present a visualisation of change detection, highlighting urban area changes over time to monitor changes in the map.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13388v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yadvendra Gurjar, Ruoni Wan, Ehsan Farahbakhsh, Rohitash Chandra</dc:creator>
    </item>
  </channel>
</rss>
