<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Oct 2025 02:08:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Ringleader ASGD: The First Asynchronous SGD with Optimal Time Complexity under Data Heterogeneity</title>
      <link>https://arxiv.org/abs/2509.22860</link>
      <description>arXiv:2509.22860v2 Announce Type: new 
Abstract: Asynchronous stochastic gradient methods are central to scalable distributed optimization, particularly when devices differ in computational capabilities. Such settings arise naturally in federated learning, where training takes place on smartphones and other heterogeneous edge devices. In addition to varying computation speeds, these devices often hold data from different distributions. However, existing asynchronous SGD methods struggle in such heterogeneous settings and face two key limitations. First, many rely on unrealistic assumptions of similarity across workers' data distributions. Second, methods that relax this assumption still fail to achieve theoretically optimal performance under heterogeneous computation times. We introduce Ringleader ASGD, the first asynchronous SGD algorithm that attains the theoretical lower bounds for parallel first-order stochastic methods in the smooth nonconvex regime, thereby achieving optimal time complexity under data heterogeneity and without restrictive similarity assumptions. Our analysis further establishes that Ringleader ASGD remains optimal under arbitrary and even time-varying worker computation speeds, closing a fundamental gap in the theory of asynchronous optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22860v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Mixtures Closest to a Given Measure: A Semidefinite Programming Approach</title>
      <link>https://arxiv.org/abs/2509.22879</link>
      <description>arXiv:2509.22879v1 Announce Type: new 
Abstract: Mixture models, such as Gaussian mixture models, are widely used in machine learning to represent complex data distributions. A key challenge, especially in high-dimensional settings, is to determine the mixture order and estimate the mixture parameters. We study the problem of approximating a target measure, available only through finitely many of its moments, by a mixture of distributions from a parametric family (e.g., Gaussian, exponential, Poisson), with approximation quality measured by the 2-Wasserstein or the total variation distance. Unlike many existing approaches, the parameter set is not assumed to be finite; it is modeled as a compact basic semi-algebraic set. We introduce a hierarchy of semidefinite relaxations with asymptotic convergence to the desired optimal value. In addition, when a certain rank condition is satisfied, the convergence is even finite and recovery of an optimal mixing measure is obtained. We also present an application to clustering, where our framework serves either as a stand-alone method or as a preprocessing step that yields both the number of clusters and strong initial parameter estimates, thereby accelerating convergence of standard (local) clustering algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22879v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sre\'cko {\DJ}ura\v{s}inovi\'c, Jean-Bernard Lasserre, Victor Magron</dc:creator>
    </item>
    <item>
      <title>Data-Driven Long-Term Asset Allocation with Tsallis Entropy Regularization</title>
      <link>https://arxiv.org/abs/2509.23062</link>
      <description>arXiv:2509.23062v1 Announce Type: new 
Abstract: This paper addresses the problem of dynamic asset allocation under uncertainty, which can be formulated as a linear quadratic (LQ) control problem with multiplicative noise. To handle exploration exploitation trade offs and induce sparse control actions, we introduce Tsallis entropy as a regularization term. We develop an entropy regularized policy iteration scheme and provide theoretical guarantees for its convergence. For cases where system dynamics are unknown, we further propose a fully data driven algorithm that estimates Q functions using an instrumental variable least squares approach, allowing efficient and stable policy updates. Our framework connects entropy-regularized stochastic control with model free reinforcement learning, offering new tools for intelligent decision making in finance and automation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23062v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Zhang, Wenhao Zhang, Xianping Wu</dc:creator>
    </item>
    <item>
      <title>Cyber Risk Management and Mitigation Under Controlled Stochastic SIS Model</title>
      <link>https://arxiv.org/abs/2509.23116</link>
      <description>arXiv:2509.23116v1 Announce Type: new 
Abstract: In this paper, we formulate cyber risk management and mitigation as a stochastic optimal control problem under a stochastic Susceptible-Infected-Susceptible (SIS) epidemic model. To capture the dynamics and interplay of management and mitigation strategies, we introduce two stochastic controls: (i) a proactive risk management control to reduce external cyber attacks and internal contagion effects, and (ii) a reactive mitigation control to accelerate system recovery from cyber infection. The interplay between these controls is modeled by minimizing the expected discounted running costs, which balance proactive management expenses against reactive mitigation expenditures. We derive the associated Hamilton-Jacobi-Bellman (HJB) equation and characterize the value function as its unique viscosity solution. For numerical implementation, we propose a Policy Improvement Algorithm (PIA) and prove its convergence via Backward Stochastic Differential Equations (BSDEs). Finally, we present numerical results through a benchmark example, suboptimal control analysis, sensitivity analysis, and comparative statics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23116v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shize Na, Zhuo Jin, Ran Xu, Hailiang Yang</dc:creator>
    </item>
    <item>
      <title>Local SGD and Federated Averaging Through the Lens of Time Complexity</title>
      <link>https://arxiv.org/abs/2509.23207</link>
      <description>arXiv:2509.23207v1 Announce Type: new 
Abstract: We revisit the classical Local SGD and Federated Averaging (FedAvg) methods for distributed optimization and federated learning. While prior work has primarily focused on iteration complexity, we analyze these methods through the lens of time complexity, taking into account both computation and communication costs. Our analysis reveals that, despite its favorable iteration complexity, the time complexity of canonical Local SGD is provably worse than that of Minibatch SGD and Hero SGD (locally executed SGD). We introduce a corrected variant, Dual Local SGD, and further improve it by increasing the local step sizes, leading to a new method called Decaying Local SGD. Our analysis shows that these modifications, together with Hero SGD, are optimal in the nonconvex setting (up to logarithmic factors), closing the time complexity gap. Finally, we use these insights to improve the theory of a number of other asynchronous and local methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23207v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrien Fradin, Peter Richt\'arik, Alexander Tyurin</dc:creator>
    </item>
    <item>
      <title>Efficient Norm-Based Reachable Sets via Iterative Dynamic Programming</title>
      <link>https://arxiv.org/abs/2509.23367</link>
      <description>arXiv:2509.23367v1 Announce Type: new 
Abstract: In this work, we present a numerical optimal control framework for reachable set computation using \emph{normotopes}, a new set representation as a norm ball with a shaping matrix. In reachable set computations, we expect to continuously vary the shape matrix as a function of time. Incorporating the shape dynamics as an input, we build a \emph{controlled embedding system} using a linear differential inclusion overapproximating the dynamics of the system, where a single forward simulation of this embedding system always provides an overapproximating reachable set of the system, no matter the choice of \emph{hypercontrol}. By iteratively solving a linear quadratic approximation of the nonlinear optimal hypercontrol problem, we synthesize less conservative final reachable sets, providing a natural tradeoff between runtime and accuracy. Terminating our algorithm at any point always returns a valid reachable set overapproximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23367v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Harapanahalli, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>New Insights and Algorithms for Optimal Diagonal Preconditioning</title>
      <link>https://arxiv.org/abs/2509.23439</link>
      <description>arXiv:2509.23439v1 Announce Type: new 
Abstract: Preconditioning (scaling) is essential in many areas of mathematics, and in particular in optimization. In this work, we study the problem of finding an optimal diagonal preconditioner. We focus on minimizing two different notions of condition number: the classical, worst-case type, $\kappa$-condition number, and the more averaging motivated $\omega$-condition number. We provide affine based pseudoconvex reformulations of both optimization problems. The advantage of our formulations is that the gradient of the objective is inexpensive to compute and the optimization variable is just an $n\times 1$ vector. We also provide elegant characterizations of the optimality conditions of both problems.
  We develop a competitive subgradient method, with convergence guarantees, for $\kappa$-optimal diagonal preconditioning that scales much better and is more efficient than existing SDP-based approaches. We also show that the preconditioners found by our subgradient method leads to better PCG performance for solving linear systems than other approaches. Finally, we show the interesting phenomenon that we can apply the $\omega$-optimal preconditioner to the exact $\kappa$-optimally diagonally preconditioned matrix $A$ and get consistent, significantly improved convergence results for PCG methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23439v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Ghadimi, Woosuk L. Jung, Arnesh Sujanani, David Torregrosa-Bel\'en, Henry Wolkowicz</dc:creator>
    </item>
    <item>
      <title>Distributionally robust LMI synthesis for LTI systems</title>
      <link>https://arxiv.org/abs/2509.23493</link>
      <description>arXiv:2509.23493v1 Announce Type: new 
Abstract: This article shows that distributionally robust controller synthesis as investigated in \cite{taskesen2024distributionally} can be formulated as a convex linear matrix inequality (LMI) synthesis problem. To this end, we rely on well-established convexification techniques from robust control. The LMI synthesis problem we propose has the advantage that it can be solved efficiently using off-the-shelf semi-definite programming (SDP) solvers. In addition, our formulation exposes the studied distributionally robust controller synthesis problem as an instance of robust $H_2$ synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23493v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dennis Gramlich, Shuhao Yan, Carsten W. Scherer, Christian Ebenbauer%</dc:creator>
    </item>
    <item>
      <title>Bounds for the Permutation Flowshop Scheduling Problem: New Framework and Theoretical Insights</title>
      <link>https://arxiv.org/abs/2509.23512</link>
      <description>arXiv:2509.23512v1 Announce Type: new 
Abstract: In this work, we use the matrix formulation of the Permutation Flowshop Scheduling Problem with makespan minimization to derive an upper bound and a general framework for obtaining lower bounds. The proposed framework involves solving a min-max or max-min expression over a set of paths. We introduce a family of such path sets for which the min-max expression can be solved in polynomial time under certain bounded parameters. To validate the proposed approach, we test it on the Taillard and VRF benchmark instances, the two most widely used datasets in PFSP research. Our method improves the bounds in $112$ out of the $120$ Taillard instances and $430$ out of the $480$ VRF instances. These improvements include both small and large instances, highlighting the scalability of the proposed methodology. Additionally, the upper bound is used to give a more accurate estimate of the number of possible makespan values for a given instance and to present asymptotic results which provide advances in a conjecture given by Taillard related to the quality of one of the most popular lower bounds, as well as the asymptotic approximation ratio of any algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23512v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. A. Alejandro-Soto, Carlos Segura, Joel Antonio Trejo-Sanchez</dc:creator>
    </item>
    <item>
      <title>Hybrid Powertrain Optimization for Regional Aircraft Integrating Hydrogen Fuel Cells and Aluminum Air Batteries</title>
      <link>https://arxiv.org/abs/2509.23682</link>
      <description>arXiv:2509.23682v1 Announce Type: new 
Abstract: With the increasing demand for air travel and the urgency to reduce emissions, transitioning from fossil fuel-based propulsion systems is a critical step toward sustainable aviation. While batteries are widely used in urban air mobility, their long charging durations limit their feasibility for consecutive flights. Hybrid propulsion systems, which integrate fuel cells and batteries, offer a promising alternative due to their higher energy density and improved efficiency. This paper presents a novel hybrid powertrain architecture for regional aircraft, incorporating a hydrogen fuel cell, a lithium-ion battery, and an auxiliary aluminum-air battery. The proposed system is evaluated using real-world power demand data from a Cessna 208 aircraft. The hydrogen fuel cell acts as the primary power source, ensuring continuous operation, while the lithium-ion battery manages transient power fluctuations to enhance system stability. The aluminum-air battery is introduced as a high-energy emergency backup, providing extended endurance during critical situations. A mixed-integer optimization model is formulated for system sizing and power scheduling, ensuring optimal energy distribution among the power sources. Multiple operational scenarios are analyzed to evaluate system performance, particularly under emergency conditions, where power reliability is crucial. The results highlight the feasibility and effectiveness of the proposed hybrid architecture in improving energy efficiency and flight safety for regional aircraft applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23682v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harshal Kaushik, Ali Mahboub Rad, Korebami Adebajo, Sobhan Badakhshan, Nathaniel Cooper, Austin Downey, Jie Zhang</dc:creator>
    </item>
    <item>
      <title>Weak and strong convergence of a relaxed inertial proximal splitting algorithm for solving hierarchical equilibrium problems</title>
      <link>https://arxiv.org/abs/2509.23817</link>
      <description>arXiv:2509.23817v1 Announce Type: new 
Abstract: In this chapter, we introduce the relaxed inertial proximal splitting algorithm (RIPSA) for hierarchical equilibrium problems. Using Opial-Passty's lemma, we first establish weak ergodic and weak convergence of the sequence generated by the algorithm to a solution of the problem, in the absence of the Browder-Halpern contraction factor. We then derive a strong convergence result under an additional strong monotonicity assumption. Subsequently, we relax this requirement by removing strong monotonicity and instead incorporating a Browder-Halpern contraction factor into (RIPSA), which guarantees strong convergence to a solution determined by the contraction factor. Finally, we discuss two related settings: convex minimization problems and monotone variational inequalities formulated as fixed-point problems for nonexpansive operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23817v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zakaria Mazgouri, Hassan Riahi, Michel Th\'era</dc:creator>
    </item>
    <item>
      <title>Stochastic Origin Frank-Wolfe for traffic assignment</title>
      <link>https://arxiv.org/abs/2509.23840</link>
      <description>arXiv:2509.23840v1 Announce Type: new 
Abstract: In this paper, we present the Stochastic Origin Frank-Wolfe (SOFW) method, which is a special case of the block-coordinate Frank-Wolfe algorithm, applied to the problem of finding equilibrium flow distributions. By significantly reducing the computational complexity of the minimization oracle, the method improves overall efficiency at the cost of increased memory consumption. Its key advantage lies in minimizing the number of shortest path computations.
  We refer to existing theoretical convergence guarantees for generalized coordinate Frank-Wolfe methods and, in addition, extend the analysis by providing a convergence proof for a batched version of the Block-Coordinate Frank-Wolfe algorithm, which was not covered in the original work. We also demonstrate the practical effectiveness of our approach through experimental results. In particular, our findings show that the proposed method significantly outperforms the classical Frank-Wolfe algorithm and its variants on large-scale datasets. On smaller datasets, SOFW also remains effective, though the performance gap relative to classical methods becomes less pronounced. In such cases, there is a trade-off between solution quality, iteration time complexity, and memory usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23840v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Ignashin, Demyan Yarmoshik</dc:creator>
    </item>
    <item>
      <title>On the Relationships among GPU-Accelerated First-Order Methods for Solving Linear Programming</title>
      <link>https://arxiv.org/abs/2509.23903</link>
      <description>arXiv:2509.23903v1 Announce Type: new 
Abstract: This paper aims to understand the relationships among recently developed GPU-accelerated first-order methods (FOMs) for linear programming (LP), with particular emphasis on HPR-LP -- a Halpern Peaceman--Rachford (HPR) method for LP. Our findings can be summarized as follows: (i) the base algorithm of cuPDLPx, a recently released GPU solver, is a special case of the base algorithm of HPR-LP, thereby showing that cuPDLPx is another concrete implementation instance of HPR-LP; (ii) once the active sets have been identified, HPR-LP and EPR-LP -- an ergodic PR method for LP -- become equivalent under the same initialization; and (iii) extensive numerical experiments on benchmark datasets demonstrate that HPR-LP achieves the best overall performance among current GPU-accelerated LP solvers. These findings provide a strong motivation for using the HPR method as a baseline to further develop GPU-accelerated LP solvers and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23903v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaihuang Chen, Defeng Sun, Yancheng Yuan, Guojun Zhang, Xinyuan Zhao</dc:creator>
    </item>
    <item>
      <title>Efficient Douglas-Rachford Methods on Hadamard Manifolds with Applications to the Heron Problems</title>
      <link>https://arxiv.org/abs/2509.23939</link>
      <description>arXiv:2509.23939v1 Announce Type: new 
Abstract: Our interest lies in developing some efficient methods for minimizing the sum of two geodesically convex functions on Hadamard manifolds, with the aim to enhance the convergence of the Douglas-Rachford algorithm in Hadamard manifolds. Specifically, we propose two types of algorithms: inertial and non-inertial algorithms. The convergence analysis of both algorithms is provided under suitable assumptions on algorithmic parameters and the geodesic convexity of the objective functions. This convergence analysis is based on fixed-point theory for nonexpansive operators. We also study the convergence rates of these two methods. Additionally, we introduce parallel Douglas-Rachford type algorithms for minimizing functionals containing multiple summands with applications to the generalized Heron problem on Hadamard manifolds. To demonstrate the effectiveness of the proposed algorithms, we present some numerical experiments for the generalized Heron problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23939v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D. R. Sahu, Shikher Sharma, Pankaj Gautam</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Constrained Optimization from a Control Perspective via Feedback Linearization</title>
      <link>https://arxiv.org/abs/2509.24056</link>
      <description>arXiv:2509.24056v1 Announce Type: new 
Abstract: Designing safe derivative-free optimization algorithms under unknown constraints is a fundamental challenge in modern learning and control. Most existing zeroth-order (ZO) approaches typically assume white-box constraints or focus on convex settings, leaving the general case of nonconvex optimization with black-box constraints largely open. We propose a control-theoretic framework for ZO constrained optimization that enforces feasibility without relying on solving costly convex subproblems. Leveraging feedback linearization, we introduce a family of ZO feedback linearization (ZOFL) algorithms applicable to both equality and inequality constraints. Our method requires only noisy, sample-based gradient estimates yet provably guarantees constraint satisfaction under mild regularity conditions. We establish finite-time bounds on constraint violation and further present a midpoint discretization variant that further improves feasibility without sacrificing optimality. Empirical results demonstrate that ZOFL consistently outperforms standard ZO baselines, achieving competitive objective values while maintaining feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24056v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Gioele Zardini, Asuman Ozdaglar, Jeff Shamma, Na Li</dc:creator>
    </item>
    <item>
      <title>Computing Invariant Zeros of a MIMO Linear System Using State-Space Realization</title>
      <link>https://arxiv.org/abs/2509.24105</link>
      <description>arXiv:2509.24105v1 Announce Type: new 
Abstract: Poles of a multi-input multi-output (MIMO) linear system can be computed by solving an eigenvalue problem; however, the problem of computing its invariant zeros is equivalent to a generalized eigenvalue problem. This paper revisits the problem of computing the invariant zeros by solving an eigenvalue problem. We introduce a realization called the invariant zero form in which the system's invariant zeros are isolated in a partition of the transformed dynamics matrix. It is shown that the invariant zeros are then the eigenvalues of a partition of the transformed dynamics matrix. Although the paper's main result is proved only for square MIMO systems, the technique can be heuristically extended to nonsquare MIMO systems, as shown in the numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24105v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jhon Manuel Portella Delgado, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>Learning Hybrid Dynamics via Convex Optimizations</title>
      <link>https://arxiv.org/abs/2509.24157</link>
      <description>arXiv:2509.24157v1 Announce Type: new 
Abstract: This paper investigates the problem of identifying state-dependent switching systems, a class of hybrid dynamical systems that combine multiple linear or nonlinear modes. We propose two broad classes of switching systems: switching linear systems (SLSs) and switching polynomial systems (SPSs). We first formulate the joint estimation of the mode dynamics and switching rules as a mixed integer program. To solve its inherent scalability issue, we develop a hierarchy of convex relaxations and establish a bound and conditions under which these relaxations are tight. Building on these results, we propose a bilevel convex optimization framework that alternates between mode assignment and dynamics estimation, and we recover switching boundaries using margin-based polynomial classifiers. Numerical experiments on both linear and nonlinear oscillators demonstrate that the method accurately identifies mode dynamics and reconstructs switching surfaces from trajectory data. Our results provide a tractable optimization-based framework for switching system identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24157v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaito Iwasaki, Sangli Teng, Anthony Bloch, Maani Ghaffari</dc:creator>
    </item>
    <item>
      <title>An Augmented Lagrangian Value Function Method for Lower-level Constrained Stochastic Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2509.24249</link>
      <description>arXiv:2509.24249v1 Announce Type: new 
Abstract: Recently, lower-level constrained bilevel optimization has attracted increasing attention. However, existing methods mostly focus on either deterministic cases or problems with linear constraints. The main challenge in stochastic cases with general constraints is the bias and variance of the hyper-gradient, arising from the inexact solution of the lower-level problem. In this paper, we propose a novel stochastic augmented Lagrangian value function method for solving stochastic bilevel optimization problems with nonlinear lower-level constraints. Our approach reformulates the original bilevel problem using an augmented Lagrangian-based value function and then applies a penalized stochastic gradient method that carefully manages the noise from stochastic oracles. We establish an equivalence between the stochastic single-level reformulation and the original constrained bilevel problem and provide a non-asymptotic rate of convergence for the proposed method. The rate is further enhanced by employing variance reduction techniques. Extensive experiments on synthetic problems and real-world applications demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24249v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hantao Nie, Jiaxiang Li, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Simplex Frank-Wolfe: Linear Convergence and Its Numerical Efficiency for Convex Optimization over Polytopes</title>
      <link>https://arxiv.org/abs/2509.24279</link>
      <description>arXiv:2509.24279v1 Announce Type: new 
Abstract: We investigate variants of the Frank-Wolfe (FW) algorithm for smoothing and strongly convex optimization over polyhedral sets, with the goal of designing algorithms that achieve linear convergence while minimizing per-iteration complexity as much as possible. Starting from the simple yet fundamental unit simplex, and based on geometrically intuitive motivations, we introduce a novel oracle called Simplex Linear Minimization Oracle (SLMO), which can be implemented with the same complexity as the standard FW oracle. We then present two FW variants based on SLMO: Simplex Frank-Wolfe and the refined Simplex Frank-Wolfe (rSFW). Both variants achieve a linear convergence rate for all three common step-size rules. Finally, we generalize the entire framework from the unit simplex to arbitrary polytopes. Furthermore, the refinement step in rSFW can accommodate any existing FW strategies such as the well-known away-step and pairwise-step, leading to outstanding numerical performance. We emphasize that the oracle used in our rSFW method requires only one more vector addition compared to the standard LMO, resulting in the lowest per-iteration computational overhead among all known Frank-Wolfe variants with linear convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24279v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoning Wang, Houduo Qi, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>Asymptotic Weighted Approximation of Convex Functions</title>
      <link>https://arxiv.org/abs/2509.24434</link>
      <description>arXiv:2509.24434v2 Announce Type: new 
Abstract: Extending classical results on polytopal approximation of convex bodies, we derive asymptotic formulas for the weighted approximation of smooth convex functions by piecewise affine convex functions as the number of their facets tends to infinity. These asymptotic expressions are formulated in terms of a functional that extends the notion of affine surface area to the functional setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24434v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernanda M. Ba\^eta</dc:creator>
    </item>
    <item>
      <title>Markov Decision Processing Networks</title>
      <link>https://arxiv.org/abs/2509.24541</link>
      <description>arXiv:2509.24541v1 Announce Type: new 
Abstract: We introduce Markov Decision Processing Networks (MDPNs) as a multiclass queueing network model where service is a controlled, finite-state Markov process. The model exhibits a decision-dependent service process where actions taken influence future service availability. Viewed as a two-sided queueing model, this captures settings such as assemble-to-order systems, ride-hailing platforms, cross-skilled call centers, and quantum switches.
  We first characterize the capacity region of MDPNs. Unlike classical switched networks, the MDPN capacity region depends on the long-run mix of service states induced by the control of the underlying service process. We show, via a counterexample, that MaxWeight is not throughput-optimal in this class, demonstrating the distinction between MDPNs and classical queueing models.
  To bridge this gap, we design a weighted average reward policy, a multiobjective MDP that leverages a two-timescale separation at the fluid scale. We prove throughput-optimality of the resulting policy. The techniques yield a clear capacity region description and apply to a broad family of two-sided matching systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24541v1</guid>
      <category>math.OC</category>
      <category>cs.NI</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanidhay Bhambay, Thirupathaiah Vasantam, Neil Walton</dc:creator>
    </item>
    <item>
      <title>Tree-based formulation for the multi-commodity flow problem</title>
      <link>https://arxiv.org/abs/2509.24656</link>
      <description>arXiv:2509.24656v1 Announce Type: new 
Abstract: We introduce a tree-based formulation for the minimum-cost multi-commodity flow problem that addresses large-scale instances. The method decomposes the source-based model by representing flows as convex combinations of trees rooted at source nodes, and solves the resulting formulation with column generation. The number of demand constraints now depends on the number of sources $|S|$, not commodities $|K|$, yielding a compact master problem when $|S| \ll |K|$. We conduct a computational study comparing tree-based decomposition against path-based column generation and direct LP solving. The results show speed-ups of up to one order of magnitude over direct LP solving, and improved scalability compared to path-based formulations. Tree-based decomposition enables solving instances with millions of commodities and hundreds of thousands of nodes. This makes it well-suited for applications in transportation and logistics networks where multiple demands often share common origins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24656v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Spoorendonk, Bj{\o}rn Petersen</dc:creator>
    </item>
    <item>
      <title>Continuation strategies to mitigate convergence to low-performing local optima in dynamic topology optimization</title>
      <link>https://arxiv.org/abs/2509.24667</link>
      <description>arXiv:2509.24667v1 Announce Type: new 
Abstract: Solving dynamic topology optimization problems often yields low-performing local optima. Instead of converging towards a design that exploits dynamic mechanisms, a less interesting, mass-driven solution is often generated. This necessitates repeated and computationally expensive optimization reruns before a suitable optimum is found. In this work, an overview of three strategy classes that reduce the need for such reruns is presented: exclusion strategies, frequency shift methods and relaxation strategies. Novel variants for each strategy class are developed, implemented and compared via Monte Carlo sampling on a benchmark problem, namely the sound transmission loss optimization of a sandwich panel. Probabilities of achieving high-performing optima are estimated and all investigated strategies demonstrate quantifiable improvements and trade-offs. The study offers furthermore a quantitative comparison of the presented strategies, supporting researchers in making an informed choice when addressing convergence to poor local optima in dynamic topology optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24667v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom De Weer, Vanessa Cool, Elke Deckers</dc:creator>
    </item>
    <item>
      <title>Proximal gradient methods in Banach spaces</title>
      <link>https://arxiv.org/abs/2509.24685</link>
      <description>arXiv:2509.24685v1 Announce Type: new 
Abstract: Proximal gradient methods are a popular tool for the solution of structured, nonsmooth minimization problems. In this work, we investigate an extension of the former to general Banach spaces and provide worst-case convergence rates for, both, convex and nonconvex, problem instances. Moreover, assuming additional regularity properties of stationary points, linear rates of convergence are derived. The theoretical results are illustrated for bang-bang type optimal control problems with partial differential equations which we study in the space of Radon measures. An efficient implementation of the resulting $L^1$-proximal gradient method is given and its performance is compared to standard $L^2$-proximal gradient as well as Frank-Wolfe methods. The paper is complemented by discussing the relationship among different regularity properties as well as by providing a novel characterization of the Polyak--{\L}ojasiewicz--Kurdyka property via second-order conditions involving weak* second subderivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24685v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gerd Wachsmuth, Daniel Walter</dc:creator>
    </item>
    <item>
      <title>$\mathcal{KL}$ and Lyapunov Approaches for Discrete-time Peak Computation Problems</title>
      <link>https://arxiv.org/abs/2509.24689</link>
      <description>arXiv:2509.24689v1 Announce Type: new 
Abstract: In this paper, we propose a method to solve discrete-time peak computation problems (DPCPs for short). DPCPs are optimization problems that consist of maximizing a function over the reachable values set of a discrete-time dynamical system. The optimal value of a DPCP can be rewritten as the supremum of the sequence of optimal values. Previous results provide general techniques for computing the supremum of a real sequence from a well-chosen pair of a strictly increasing continuous function on [0,1] and a positive scalar in (0,1). In this paper, we exploit the specific structure of the optimal value of the DPCP to construct such a pair from classical tools from stability theory: $\mathcal{KL}$ certificate and Lyapunov functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24689v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Assal\'e Adj\'e</dc:creator>
    </item>
    <item>
      <title>Quasi-Ergodic Control of Multi-Periodic Autoregressive Processes: Formulation and Examples</title>
      <link>https://arxiv.org/abs/2509.24729</link>
      <description>arXiv:2509.24729v1 Announce Type: new 
Abstract: This work considers state dynamics driven by Periodic Autoregressive Moving Average noise, and control of the system over time. Such processes appear frequently in applications involving the environment, such as energy and agriculture. Managing these systems applying forecasts to make decisions that exhibit foresight and risk aversion while maximizing profits is a challenging control problem that can be computationally difficult for standard scenario-based methods. This paper presents a formulation that explicitly enforces time-periodicity of distribution of the state, facilitating the use of periodic stochastic process basis elements as a discretization. By enforcing periodicity explicitly, an ansatz for the solution can be formed that does not require exponential scaling with time. We provide a few examples that can be modeled with this new control formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24729v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vyacheslav Kungurtsev</dc:creator>
    </item>
    <item>
      <title>Bundle Network: a Machine Learning-Based Bundle Method</title>
      <link>https://arxiv.org/abs/2509.24736</link>
      <description>arXiv:2509.24736v1 Announce Type: new 
Abstract: This paper presents Bundle Network, a learning-based algorithm inspired by the Bundle Method for convex non-smooth minimization problems. Unlike classical approaches that rely on heuristic tuning of a regularization parameter, our method automatically learns to adjust it from data. Furthermore, we replace the iterative resolution of the optimization problem that provides the search direction-traditionally computed as a convex combination of gradients at visited points-with a recurrent neural model equipped with an attention mechanism. By leveraging the unrolled graph of computation, our Bundle Network can be trained end-to-end via automatic differentiation. Experiments on Lagrangian dual relaxations of the Multi-Commodity Network Design and Generalized Assignment problems demonstrate that our approach consistently outperforms traditional methods relying on grid search for parameter tuning, while generalizing effectively across datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24736v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Demelas, Joseph Le Roux, Antonio Frangioni, Mathieu Lacroix, Emiliano Traversi, Roberto Wolfler Calvo</dc:creator>
    </item>
    <item>
      <title>Continuous differentiability of the signum function and Newton's method for bang-bang control</title>
      <link>https://arxiv.org/abs/2509.24829</link>
      <description>arXiv:2509.24829v1 Announce Type: new 
Abstract: We investigate bang-bang control problems and the possibility to apply Newton's method to solve such kind of problems numerically. To this end, we show that the signum function is Fr\'echet differentiable between appropriate function spaces. Numerical experiments show the applicability of the resulting method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24829v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Wachsmuth, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Improved Stochastic Optimization of LogSumExp</title>
      <link>https://arxiv.org/abs/2509.24894</link>
      <description>arXiv:2509.24894v1 Announce Type: new 
Abstract: The LogSumExp function, also known as the free energy, plays a central role in many important optimization problems, including entropy-regularized optimal transport and distributionally robust optimization (DRO). It is also the dual to the Kullback-Leibler (KL) divergence, which is widely used in machine learning. In practice, when the number of exponential terms inside the logarithm is large or infinite, optimization becomes challenging since computing the gradient requires differentiating every term. Previous approaches that replace the full sum with a small batch introduce significant bias. We propose a novel approximation to LogSumExp that can be efficiently optimized using stochastic gradient methods. This approximation is rooted in a sound modification of the KL divergence in the dual, resulting in a new $f$-divergence called the safe KL divergence. The accuracy of the approximation is controlled by a tunable parameter and can be made arbitrarily small. Like the LogSumExp, our approximation preserves convexity. Moreover, when applied to an $L$-smooth function bounded from below, the smoothness constant of the resulting objective scales linearly with $L$. Experiments in DRO and continuous optimal transport demonstrate the advantages of our approach over state-of-the-art baselines and the effective treatment of numerical issues associated with the standard LogSumExp and KL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24894v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egor Gladin, Alexey Kroshnin, Jia-Jie Zhu, Pavel Dvurechensky</dc:creator>
    </item>
    <item>
      <title>Addressing Methodological Uncertainty in MCDM with a Systematic Pipeline Approach to Data Transformation Sensitivity Analysis</title>
      <link>https://arxiv.org/abs/2509.24996</link>
      <description>arXiv:2509.24996v1 Announce Type: new 
Abstract: Multicriteria decision-making methods exhibit critical dependence on the choice of normalization techniques, where different selections can alter 20-40% of the final rankings. Current practice is characterized by the ad-hoc selection of methods without systematic robustness evaluation. We present a framework that addresses this methodological uncertainty through automated exploration of the scaling transformation space. The implementation leverages the existing Scikit-Criteria infrastructure to automatically generate all possible methodological combinations and provide robust comparative analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24996v1</guid>
      <category>math.OC</category>
      <category>cs.SE</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan B. Cabral, Alvaro Roy Schachner</dc:creator>
    </item>
    <item>
      <title>Managing ride-sourcing drivers at transportation terminals: a lottery-based queueing approach</title>
      <link>https://arxiv.org/abs/2509.25071</link>
      <description>arXiv:2509.25071v1 Announce Type: new 
Abstract: Problem definition: Transportation terminals such as airports often experience persistent oversupply of idle ride-sourcing drivers, resulting in long driver waiting times and inducing externalities such as curbside congestion. While platforms now employ virtual queues with control levers like dynamic pricing, information provision, and direct admission control to manage this issue, all existing levers involve significant trade-offs and side effects. This limitation highlights the need for an alternative management approach. Methodology/results: We develop a queueing-theoretic framework to model ride-sourcing operations at terminals and propose a novel lottery-based control mechanism for the virtual queue. This non-monetary strategy works by probabilistically assigning a driver's entry position. By directly influencing their expected waiting time, the mechanism in turn shapes their decision to join the queue. We reformulate the resulting infinite-dimensional, non-smooth optimization into a tractable bi-level program by leveraging the threshold structure of the equilibrium. Theoretically, we prove that the lottery mechanism can achieve higher or equal social welfare than FIFO-queue-based dynamic pricing. Numerical experiments in unconstrained markets show that in profit maximization, our approach only narrowly trails dynamic pricing and significantly outperforms static pricing. Furthermore, it is shown that under commission fee caps, the lottery mechanism can surpass dynamic pricing in profitability. Implications: This study introduces a new, non-monetary lever for managing idle ride-sourcing drivers at transportation terminals. By aligning operational practices with queue-based dynamics, the proposed lottery mechanism offers a robust and implementable alternative to pricing-based approaches, with advantages in both unconstrained and regulated markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25071v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianming Liu, Yafeng Yin, Vijay Subramanian</dc:creator>
    </item>
    <item>
      <title>Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots</title>
      <link>https://arxiv.org/abs/2509.22815</link>
      <description>arXiv:2509.22815v1 Announce Type: cross 
Abstract: Ensuring safe and effective collaboration between humans and autonomous legged robots is a fundamental challenge in shared autonomy, particularly for teleoperated systems navigating cluttered environments. Conventional shared-control approaches often rely on fixed blending strategies that fail to capture the dynamics of legged locomotion and may compromise safety. This paper presents a teleoperator-aware, safety-critical, adaptive nonlinear model predictive control (ANMPC) framework for shared autonomy of quadrupedal robots in obstacle-avoidance tasks. The framework employs a fixed arbitration weight between human and robot actions but enhances this scheme by modeling the human input with a noisily rational Boltzmann model, whose parameters are adapted online using a projected gradient descent (PGD) law from observed joystick commands. Safety is enforced through control barrier function (CBF) constraints integrated into a computationally efficient NMPC, ensuring forward invariance of safe sets despite uncertainty in human behavior. The control architecture is hierarchical: a high-level CBF-based ANMPC (10 Hz) generates blended human-robot velocity references, a mid-level dynamics-aware NMPC (60 Hz) enforces reduced-order single rigid body (SRB) dynamics to track these references, and a low-level nonlinear whole-body controller (500 Hz) imposes the full-order dynamics via quadratic programming to track the mid-level trajectories. Extensive numerical and hardware experiments, together with a user study, on a Unitree Go2 quadrupedal robot validate the framework, demonstrating real-time obstacle avoidance, online learning of human intent parameters, and safe teleoperator collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22815v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruturaj Sambhus, Muneeb Ahmad, Basit Muhammad Imran, Sujith Vijayan, Dylan P. Losey, Kaveh Akbari Hamed</dc:creator>
    </item>
    <item>
      <title>Multihead Finite-State Dimension</title>
      <link>https://arxiv.org/abs/2509.22912</link>
      <description>arXiv:2509.22912v1 Announce Type: cross 
Abstract: We introduce multihead finite-state dimension, a generalization of finite-state dimension in which a group of finite-state agents (the heads) with oblivious, one-way movement rules, each reporting only one symbol at a time, enable their leader to bet on subsequent symbols in an infinite data stream. In aggregate, such a scheme constitutes an $h$-head finite state gambler whose maximum achievable growth rate of capital in this task, quantified using betting strategies called gales, determines the multihead finite-state dimension of the sequence. The 1-head case is equivalent to finite-state dimension as defined by Dai, Lathrop, Lutz and Mayordomo (2004). In our main theorem, we prove a strict hierarchy as the number of heads increases, giving an explicit sequence family that separates, for each positive integer $h$, the earning power of $h$-head finite-state gamblers from that of $(h+1)$-head finite-state gamblers. We prove that multihead finite-state dimension is stable under finite unions but that the corresponding quantity for any fixed number $h&gt;1$ of heads--the $h$-head finite-state predimension--lacks this stability property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22912v1</guid>
      <category>cs.IT</category>
      <category>cs.FL</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Huang, Xiaoyuan Li, Jack H. Lutz, Neil Lutz</dc:creator>
    </item>
    <item>
      <title>MDP modeling for multi-stage stochastic programs</title>
      <link>https://arxiv.org/abs/2509.22981</link>
      <description>arXiv:2509.22981v1 Announce Type: cross 
Abstract: We study a class of multi-stage stochastic programs, which incorporate modeling features from Markov decision processes (MDPs). This class includes structured MDPs with continuous state and action spaces. We extend policy graphs to include decision-dependent uncertainty for one-step transition probabilities as well as a limited form of statistical learning. We focus on the expressiveness of our modeling approach, illustrating ideas with a series of examples of increasing complexity. As a solution method, we develop new variants of stochastic dual dynamic programming, including approximations to handle non-convexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22981v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David P. Morton, Oscar Dowson, Bernardo K. Pagnoncelli</dc:creator>
    </item>
    <item>
      <title>A Constrained Optimization Approach for Constructing Rigid Bar Frameworks with Higher-order Rigidity</title>
      <link>https://arxiv.org/abs/2509.23072</link>
      <description>arXiv:2509.23072v1 Announce Type: cross 
Abstract: We present a systematic approach for constructing bar frameworks that are rigid but not first-order rigid, using constrained optimization. We show that prestress stable (but not first-order rigid) frameworks arise as the solution to a simple optimization problem, which asks to maximize or minimize the length of one edge while keep the other edge lengths fixed. By starting with a random first-order rigid framework, we can thus design a wide variety of prestress stable frameworks, which, unlike many examples known in the literature, have no special symmetries. We then show how to incorporate a bifurcation method to design frameworks that are third-order rigid. Our results highlight connections between concepts in rigidity theory and constrained optimization, offering new insights into the construction and analysis of bar frameworks with higher-order rigidity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23072v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xuenan Li, Christian D. Santangelo, Miranda Holmes-Cerfon</dc:creator>
    </item>
    <item>
      <title>On Optimal Markovian Couplings of Levy Processes</title>
      <link>https://arxiv.org/abs/2509.23086</link>
      <description>arXiv:2509.23086v1 Announce Type: cross 
Abstract: We study the optimal Markovian coupling problem for two Pi-valued Feller processes {X_t} and {Y_t}, which seeks a coupling process {(X_t, Y_t)} that minimizes the right derivative at t = 0 of the expected cost E^{(x,y)}[c(X_t, Y_t)], for all initial states (x,y) in Pi^2 and a given cost function c on Pi. This problem was first formulated and solved by Chen (1994) for drift-diffusion processes and later extended by Zhang (2000) to Markov processes with bounded jumps. In this work, we resolve the case of Levy processes under the quadratic cost c(x,y) = 1/2 |x - y|^2 by introducing a new formulation of the "Levy optimal transport problem" between Levy measures. We show that the resulting optimal coupling process {(X_t*, Y_t*)}_{t &gt;= 0} satisfies a minimal growth property: for each t &gt;= 0 and x,y in R^d, the expectation E^{(x,y)}|X_t* - Y_t*|^2 is minimized among all Feller couplings. A key feature of our approach is the development of a dual problem, expressed as a variational principle over test functions of the generators. We prove strong duality for this formulation, thereby closing the optimality gap. As a byproduct, we obtain a Wasserstein-type metric on the space of Levy generators and Levy measures with finite second moment, and establish several of its fundamental properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23086v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Yang Kang, Tau Shean Lim</dc:creator>
    </item>
    <item>
      <title>Conditional Risk Minimization with Side Information: A Tractable, Universal Optimal Transport Framework</title>
      <link>https://arxiv.org/abs/2509.23128</link>
      <description>arXiv:2509.23128v1 Announce Type: cross 
Abstract: Conditional risk minimization arises in high-stakes decisions where risk must be assessed in light of side information, such as stressed economic conditions, specific customer profiles, or other contextual covariates. Constructing reliable conditional distributions from limited data is notoriously difficult, motivating a series of optimal-transport-based proposals that address this uncertainty in a distributionally robust manner. Yet these approaches remain fragmented, each constrained by its own limitations: some rely on point estimates or restrictive structural assumptions, others apply only to narrow classes of risk measures, and their structural connections are unclear. We introduce a universal framework for distributionally robust conditional risk minimization, built on a novel union-ball formulation in optimal transport. This framework offers three key advantages: interpretability, by subsuming existing methods as special cases and revealing their deep structural links; tractability, by yielding convex reformulations for virtually all major risk functionals studied in the literature; and scalability, by supporting cutting-plane algorithms for large-scale conditional risk problems. Applications to portfolio optimization with rank-dependent expected utility highlight the practical effectiveness of the framework, with conditional models converging to optimal solutions where unconditional ones clearly do not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23128v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinqiao Xie, Jonathan Yu-Meng Li</dc:creator>
    </item>
    <item>
      <title>Continuous-Time Reinforcement Learning for Asset-Liability Management</title>
      <link>https://arxiv.org/abs/2509.23280</link>
      <description>arXiv:2509.23280v1 Announce Type: cross 
Abstract: This paper proposes a novel approach for Asset-Liability Management (ALM) by employing continuous-time Reinforcement Learning (RL) with a linear-quadratic (LQ) formulation that incorporates both interim and terminal objectives. We develop a model-free, policy gradient-based soft actor-critic algorithm tailored to ALM for dynamically synchronizing assets and liabilities. To ensure an effective balance between exploration and exploitation with minimal tuning, we introduce adaptive exploration for the actor and scheduled exploration for the critic. Our empirical study evaluates this approach against two enhanced traditional financial strategies, a model-based continuous-time RL method, and three state-of-the-art RL algorithms. Evaluated across 200 randomized market scenarios, our method achieves higher average rewards than all alternative strategies, with rapid initial gains and sustained superior performance. The outperformance stems not from complex neural networks or improved parameter estimation, but from directly learning the optimal ALM strategy without learning the environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23280v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilie Huang</dc:creator>
    </item>
    <item>
      <title>Landing with the Score: Riemannian Optimization through Denoising</title>
      <link>https://arxiv.org/abs/2509.23357</link>
      <description>arXiv:2509.23357v1 Announce Type: cross 
Abstract: Under the data manifold hypothesis, high-dimensional data are concentrated near a low-dimensional manifold. We study the problem of Riemannian optimization over such manifolds when they are given only implicitly through the data distribution, and the standard manifold operations required by classical algorithms are unavailable. This formulation captures a broad class of data-driven design problems that are central to modern generative AI. Our key idea is to introduce a link function that connects the data distribution to the geometric operations needed for optimization. We show that this function enables the recovery of essential manifold operations, such as retraction and Riemannian gradient computation. Moreover, we establish a direct connection between our construction and the score function in diffusion models of the data distribution. This connection allows us to leverage well-studied parameterizations, efficient training procedures, and even pretrained score networks from the diffusion model literature to perform optimization. Building on this foundation, we propose two efficient inference-time algorithms -- Denoising Landing Flow (DLF) and Denoising Riemannian Gradient Descent (DRGD) -- and provide theoretical guarantees for both feasibility (approximate manifold adherence) and optimality (small Riemannian gradient norm). Finally, we demonstrate the effectiveness of our approach on finite-horizon reference tracking tasks in data-driven control, highlighting its potential for practical generative and design applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23357v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrey Kharitenko, Zebang Shen, Riccardo de Santi, Niao He, Florian Doerfler</dc:creator>
    </item>
    <item>
      <title>Penalized Weighted Trace Minimization for Optimal Control Device Design and Placement</title>
      <link>https://arxiv.org/abs/2509.23477</link>
      <description>arXiv:2509.23477v1 Announce Type: cross 
Abstract: In this paper, we present a new analytical framework for determining the well-posedness of constrained optimization problems that arise in the study of optimal control device design and placement within the context of infinite dimensional linear quadratic control systems. We first prove the well-posedness of the newly minted "strong form" of the time-independent operator-valued Riccati equation. This form of the equation then enables the use of trace-class operator analysis and the Lagrange multiplier formalism to analyze operator-valued Riccati equation-constrained optimization problems. Using this fundamental result, we then determine the conditions under which there exists unique solutions to two important classes of penalized trace minimization problems for optimal control device placement and design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23477v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Cheung</dc:creator>
    </item>
    <item>
      <title>Network-Optimised Spiking Neural Network for Event-Driven Networking</title>
      <link>https://arxiv.org/abs/2509.23516</link>
      <description>arXiv:2509.23516v1 Announce Type: cross 
Abstract: Spiking neural networks offer event-driven computation suited to time-critical networking tasks such as anomaly detection, local routing control, and congestion management at the edge. Classical units, including Hodgkin-Huxley, Izhikevich, and the Random Neural Network, map poorly to these needs. We introduce Network-Optimised Spiking (NOS), a compact two-variable unit whose state encodes normalised queue occupancy and a recovery resource. The model uses a saturating nonlinearity to enforce finite buffers, a service-rate leak, and graph-local inputs with delays and optional per link gates. It supports two differentiable reset schemes for training and deployment. We give conditions for equilibrium existence and uniqueness, local stability tests from the Jacobian trace and determinant, and a network threshold that scales with the Perron eigenvalue of the coupling matrix. The analysis yields an operational rule g* ~ k* rho(W) linking damping and offered load, shows how saturation enlarges the stable region, and explains finite-size smoothing of synchrony onsets. Stochastic arrivals follow a Poisson shot-noise model aligned with telemetry smoothing. Against queueing baselines, NOS matches M/M/1 mean by calibration while truncating deep tails under bursty input. In closed loop it gives, low-jitte with short settling. In zero-shot, label-free forecasting NOS is calibrated per node from arrival statistics. Its NOS dynamics yield high AUROC/AUPRC, enabling timely detection of congestion onsets with few false positives. Under a train-calibrated residual protocol across chain, star, and scale-free topologies, NOS improves early-warning F1 and detection latency over MLP, RNN, GRU, and tGNN. We provide guidance for data-driven initialisation, surrogate-gradient training with a homotopy on reset sharpness, and explicit stability checks with topology-aware bounds for resource constrained deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23516v1</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Bilal</dc:creator>
    </item>
    <item>
      <title>On Computing the Copositive Minimum and its Representatives</title>
      <link>https://arxiv.org/abs/2509.23696</link>
      <description>arXiv:2509.23696v1 Announce Type: cross 
Abstract: Computing the copositive minimum of a strictly copositive quadratic form is a natural generalization of computing the arithmetical minimum of a positive definite one. In this paper we show that this generalized problem is NP-complete. Moreover, we describe a practical method to calculate all shortest vectors using the LDLT-decomposition in a big class of special cases. Our numerical tests show that our method performs significantly better than previous approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23696v1</guid>
      <category>math.NT</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Oertel, Achill Sch\"urmann</dc:creator>
    </item>
    <item>
      <title>Bridging Discrete and Continuous RL: Stable Deterministic Policy Gradient with Martingale Characterization</title>
      <link>https://arxiv.org/abs/2509.23711</link>
      <description>arXiv:2509.23711v1 Announce Type: cross 
Abstract: The theory of discrete-time reinforcement learning (RL) has advanced rapidly over the past decades. Although primarily designed for discrete environments, many real-world RL applications are inherently continuous and complex. A major challenge in extending discrete-time algorithms to continuous-time settings is their sensitivity to time discretization, often leading to poor stability and slow convergence. In this paper, we investigate deterministic policy gradient methods for continuous-time RL. We derive a continuous-time policy gradient formula based on an analogue of the advantage function and establish its martingale characterization. This theoretical foundation leads to our proposed algorithm, CT-DDPG, which enables stable learning with deterministic policies in continuous-time environments. Numerical experiments show that the proposed CT-DDPG algorithm offers improved stability and faster convergence compared to existing discrete-time and continuous-time methods, across a wide range of control tasks with varying time discretizations and noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23711v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziheng Cheng, Xin Guo, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Best weighted approximation of some kernels on the real axis</title>
      <link>https://arxiv.org/abs/2509.23890</link>
      <description>arXiv:2509.23890v1 Announce Type: cross 
Abstract: We calculate the exact value and find the polynomial of the best weighted polynomial approximation of kernels of the form $\frac {A+Bt}{(t^2+\lambda^2)^{s+1}}$, where $A$ and $B$ are fixed complex numbers, $\lambda&gt;0$, $s\in {\mathbb N}$, in the mean square metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23890v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stanislav Chaichenko, Viktor Savchuk, Andrii Shidlich</dc:creator>
    </item>
    <item>
      <title>Dynamic Orthogonal Continual Fine-tuning for Mitigating Catastrophic Forgettings</title>
      <link>https://arxiv.org/abs/2509.23893</link>
      <description>arXiv:2509.23893v1 Announce Type: cross 
Abstract: Catastrophic forgetting remains a critical challenge in continual learning for large language models (LLMs), where models struggle to retain performance on historical tasks when fine-tuning on new sequential data without access to past datasets. In this paper, we first reveal that the drift of functional directions during the fine-tuning process is a key reason why existing regularization-based methods fail in long-term LLM continual learning. To address this, we propose Dynamic Orthogonal Continual (DOC) fine-tuning, a novel approach that tracks the drift of these functional directions and dynamically updates them during the fine-tuning process. Furthermore, by adjusting the gradients of new task parameters to be orthogonal to the tracked historical function directions, our method mitigates interference between new and old tasks. Extensive experiments on various LLM continual learning benchmarks demonstrate that this approach outperforms prior methods, effectively reducing catastrophic forgetting and providing a robust tool for continuous LLM fine-tuning. Our code is available at https://github.com/meloxxxxxx/DOC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23893v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhixin Zhang, Zeming Wei, Meng Sun</dc:creator>
    </item>
    <item>
      <title>Observability of Schr\"odinger propagators on tori in rough settings</title>
      <link>https://arxiv.org/abs/2509.23965</link>
      <description>arXiv:2509.23965v1 Announce Type: cross 
Abstract: On a torus of arbitrary dimension, it is conjectured that Schr\"odinger propagators with bounded potentials are observable from any space-time set of positive Lebesgue measure. We establish a criterion that proves the conjecture on the one-dimensional torus, yields new examples of measurable observation sets, and, more significantly, reduces the general conjecture to verifying certain integrability bounds for free Schr\"odinger waves. These bounds are far weaker than Bourgain's conjectured periodic Strichartz estimates, yet remain highly nontrivial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23965v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.FA</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Burq, Hui Zhu</dc:creator>
    </item>
    <item>
      <title>Equation-Free Coarse Control of Distributed Parameter Systems via Local Neural Operators</title>
      <link>https://arxiv.org/abs/2509.23975</link>
      <description>arXiv:2509.23975v1 Announce Type: cross 
Abstract: The control of high-dimensional distributed parameter systems (DPS) remains a challenge when explicit coarse-grained equations are unavailable. Classical equation-free (EF) approaches rely on fine-scale simulators treated as black-box timesteppers. However, repeated simulations for steady-state computation, linearization, and control design are often computationally prohibitive, or the microscopic timestepper may not even be available, leaving us with data as the only resource. We propose a data-driven alternative that uses local neural operators, trained on spatiotemporal microscopic/mesoscopic data, to obtain efficient short-time solution operators. These surrogates are employed within Krylov subspace methods to compute coarse steady and unsteady-states, while also providing Jacobian information in a matrix-free manner. Krylov-Arnoldi iterations then approximate the dominant eigenspectrum, yielding reduced models that capture the open-loop slow dynamics without explicit Jacobian assembly. Both discrete-time Linear Quadratic Regulator (dLQR) and pole-placement (PP) controllers are based on this reduced system and lifted back to the full nonlinear dynamics, thereby closing the feedback loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23975v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gianluca Fabiani, Constantinos Siettos, Ioannis G. Kevrekidis</dc:creator>
    </item>
    <item>
      <title>Mixed-Derivative Total Variation</title>
      <link>https://arxiv.org/abs/2509.23995</link>
      <description>arXiv:2509.23995v1 Announce Type: cross 
Abstract: The formulation of norms on continuous-domain Banach spaces with exact pixel-based discretization is advantageous for solving inverse problems (IPs). In this paper, we investigate a new regularization that is a convex combination of a TV term and the $\M(\R^2)$ norm of mixed derivatives. We show that the extreme points of the corresponding unit ball are indicator functions of polygons whose edges are aligned with either the $x_1$- or $x_2$-axis. We then apply this result to construct a new regularization for IPs, which can be discretized exactly by tensor products of first-order B-splines, or equivalently, pixels. Furthermore, we exactly discretize the loss of the denoising problem on its canonical pixel basis and prove that it admits a unique solution, which is also a solution to the underlying continuous-domain IP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23995v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Vincent Guillemet, Michael Unser</dc:creator>
    </item>
    <item>
      <title>Optimism as Risk-Seeking in Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2509.24047</link>
      <description>arXiv:2509.24047v1 Announce Type: cross 
Abstract: Risk sensitivity has become a central theme in reinforcement learning (RL), where convex risk measures and robust formulations provide principled ways to model preferences beyond expected return. Recent extensions to multi-agent RL (MARL) have largely emphasized the risk-averse setting, prioritizing robustness to uncertainty. In cooperative MARL, however, such conservatism often leads to suboptimal equilibria, and a parallel line of work has shown that optimism can promote cooperation. Existing optimistic methods, though effective in practice, are typically heuristic and lack theoretical grounding. Building on the dual representation for convex risk measures, we propose a principled framework that interprets risk-seeking objectives as optimism. We introduce optimistic value functions, which formalize optimism as divergence-penalized risk-seeking evaluations. Building on this foundation, we derive a policy-gradient theorem for optimistic value functions, including explicit formulas for the entropic risk/KL-penalty setting, and develop decentralized optimistic actor-critic algorithms that implement these updates. Empirical results on cooperative benchmarks demonstrate that risk-seeking optimism consistently improves coordination over both risk-neutral baselines and heuristic optimistic methods. Our framework thus unifies risk-sensitive learning and optimism, offering a theoretically grounded and practically effective approach to cooperation in MARL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24047v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Na Li, Asuman Ozdaglar, Jeff Shamma, Gioele Zardini</dc:creator>
    </item>
    <item>
      <title>ADAPT: Lightweight, Long-Range Machine Learning Force Fields Without Graphs</title>
      <link>https://arxiv.org/abs/2509.24115</link>
      <description>arXiv:2509.24115v1 Announce Type: cross 
Abstract: Point defects play a central role in driving the properties of materials. First-principles methods are widely used to compute defect energetics and structures, including at scale for high-throughput defect databases. However, these methods are computationally expensive, making machine-learning force fields (MLFFs) an attractive alternative for accelerating structural relaxations. Most existing MLFFs are based on graph neural networks (GNNs), which can suffer from oversmoothing and poor representation of long-range interactions. Both of these issues are especially of concern when modeling point defects. To address these challenges, we introduce the Accelerated Deep Atomic Potential Transformer (ADAPT), an MLFF that replaces graph representations with a direct coordinates-in-space formulation and explicitly considers all pairwise atomic interactions. Atoms are treated as tokens, with a Transformer encoder modeling their interactions. Applied to a dataset of silicon point defects, ADAPT achieves a roughly 33 percent reduction in both force and energy prediction errors relative to a state-of-the-art GNN-based model, while requiring only a fraction of the computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24115v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan Dramko, Yihuang Xiong, Yizhi Zhu, Geoffroy Hautier, Thomas Reps, Christopher Jermaine, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>A Novel Model for 3D Motion Planning for a Generalized Dubins Vehicle with Pitch and Yaw Rate Constraints</title>
      <link>https://arxiv.org/abs/2509.24143</link>
      <description>arXiv:2509.24143v1 Announce Type: cross 
Abstract: In this paper, we propose a new modeling approach and a fast algorithm for 3D motion planning, applicable for fixed-wing unmanned aerial vehicles. The goal is to construct the shortest path connecting given initial and final configurations subject to motion constraints. Our work differs from existing literature in two ways. First, we consider full vehicle orientation using a body-attached frame, which includes roll, pitch, and yaw angles. However, existing work uses only pitch and/or heading angle, which is insufficient to uniquely determine orientation. Second, we use two control inputs to represent bounded pitch and yaw rates, reflecting control by two separate actuators. In contrast, most previous methods rely on a single input, such as path curvature, which is insufficient for accurately modeling the vehicle's kinematics in 3D. We use a rotation minimizing frame to describe the vehicle's configuration and its evolution, and construct paths by concatenating optimal Dubins paths on spherical, cylindrical, or planar surfaces. Numerical simulations show our approach generates feasible paths within 10 seconds on average and yields shorter paths than existing methods in most cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24143v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deepak Prakash Kumar, Swaroop Darbha, Satyanarayana Gupta Manyam, David Casbeer</dc:creator>
    </item>
    <item>
      <title>SDC-Based Model Predictive Control: Enhancing Computational Feasibility for Safety-Critical Quadrotor Control</title>
      <link>https://arxiv.org/abs/2509.24208</link>
      <description>arXiv:2509.24208v1 Announce Type: cross 
Abstract: Nonlinear Model Predictive Control (NMPC) is widely used for controlling high-speed robotic systems such as quadrotors. However, its significant computational demands often hinder real-time feasibility and reliability, particularly in environments requiring robust obstacle avoidance. This paper proposes a novel SDC-Based Model Predictive Control (MPC) framework, which preserves the high-precision performance of NMPC while substantially reducing computational complexity by over 30%. By reformulating the nonlinear quadrotor dynamics through the State-Dependent Coefficient (SDC) method, the original nonlinear program problem is transformed into a sequential quadratic optimization problem. The controller integrates an integral action to eliminate steady-state tracking errors and imposes constraints for safety-critical obstacle avoidance. Additionally, a disturbance estimator is incorporated to enhance robustness against external perturbations. Simulation results demonstrate that the SDC-Based MPC achieves comparable tracking accuracy to NMPC, with greater efficiency in terms of computation times, thereby improving its suitability for real-time applications. Theoretical analysis further establishes the stability and recursive feasibility of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24208v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saber Omidi</dc:creator>
    </item>
    <item>
      <title>Asynchronous Policy Gradient Aggregation for Efficient Distributed Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2509.24305</link>
      <description>arXiv:2509.24305v1 Announce Type: cross 
Abstract: We study distributed reinforcement learning (RL) with policy gradient methods under asynchronous and parallel computations and communications. While non-distributed methods are well understood theoretically and have achieved remarkable empirical success, their distributed counterparts remain less explored, particularly in the presence of heterogeneous asynchronous computations and communication bottlenecks. We introduce two new algorithms, Rennala NIGT and Malenia NIGT, which implement asynchronous policy gradient aggregation and achieve state-of-the-art efficiency. In the homogeneous setting, Rennala NIGT provably improves the total computational and communication complexity while supporting the AllReduce operation. In the heterogeneous setting, Malenia NIGT simultaneously handles asynchronous computations and heterogeneous environments with strictly better theoretical guarantees. Our results are further corroborated by experiments, showing that our methods significantly outperform prior approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24305v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Andrei Spiridonov, Varvara Rudenko</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Federated Learning with Outlier Resilience</title>
      <link>https://arxiv.org/abs/2509.24462</link>
      <description>arXiv:2509.24462v1 Announce Type: cross 
Abstract: Federated learning (FL) enables collaborative model training without direct data sharing, but its performance can degrade significantly in the presence of data distribution perturbations. Distributionally robust optimization (DRO) provides a principled framework for handling this by optimizing performance against the worst-case distributions within a prescribed ambiguity set. However, existing DRO-based FL methods often overlook the detrimental impact of outliers in local datasets, which can disproportionately bias the learned models. In this work, we study distributionally robust federated learning with explicit outlier resilience. We introduce a novel ambiguity set based on the unbalanced Wasserstein distance, which jointly captures geometric distributional shifts and incorporates a non-geometric Kullback--Leibler penalization to mitigate the influence of outliers. This formulation naturally leads to a challenging min--max--max optimization problem. To enable decentralized training, we reformulate the problem as a tractable Lagrangian penalty optimization, which admits robustness certificates. Building on this reformulation, we propose the distributionally outlier-robust federated learning algorithm and establish its convergence guarantees. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24462v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifan Wang, Xinlei Yi, Xenia Konti, Michael M. Zavlanos, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Learning to Solve Optimization Problems Constrained with Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2509.24573</link>
      <description>arXiv:2509.24573v1 Announce Type: cross 
Abstract: Partial differential equation (PDE)-constrained optimization arises in many scientific and engineering domains, such as energy systems, fluid dynamics and material design. In these problems, the decision variables (e.g., control inputs or design parameters) are tightly coupled with the PDE state variables, and the feasible set is implicitly defined by the governing PDE constraints. This coupling makes the problems computationally demanding, as it requires handling high dimensional discretization and dynamic constraints. To address these challenges, this paper introduces a learning-based framework that integrates a dynamic predictor with an optimization surrogate. The dynamic predictor, a novel time-discrete Neural Operator (Lu et al.), efficiently approximate system trajectories governed by PDE dynamics, while the optimization surrogate leverages proxy optimizer techniques (Kotary et al.) to approximate the associated optimal decisions. This dual-network design enables real-time approximation of optimal strategies while explicitly capturing the coupling between decisions and PDE dynamics. We validate the proposed approach on benchmark PDE-constrained optimization tasks inlacing Burgers' equation, heat equation and voltage regulation, and demonstrate that it achieves solution quality comparable to classical control-based algorithms, such as the Direct Method and Model Predictive Control (MPC), while providing up to four orders of magnitude improvement in computational speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24573v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yusuf Guven, Vincenzo Di Vito, Ferdinando Fioretto</dc:creator>
    </item>
    <item>
      <title>Observability estimates for the Schr\"odinger equation on the equilateral triangle</title>
      <link>https://arxiv.org/abs/2509.24642</link>
      <description>arXiv:2509.24642v1 Announce Type: cross 
Abstract: We prove observability estimates for the Schr\"odinger equation posed on the equilateral triangle in the plane, under both Neumann and Dirichlet boundary conditions. No geometric control condition is required on the rough localization functions that we consider. This is the first result of this kind on a non-toric domain in the compact setting. Our strategy is to exploit Pinsky's tiling argument to deduce this result from observability estimates on rational twisted tori. These are obtained via propagation of singularities, adapting arguments from Burq and Zworski. The later require Strichartz estimates on such twisted rational tori, that we derive from Zygmund inequalities in the same geometric setting, also providing the sharp constant. Strichartz estimates on the equilateral triangle are also derived from this analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24642v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Alphonse, David Lafontaine</dc:creator>
    </item>
    <item>
      <title>Hierarchical Analysis and Control of Epidemic Spreading over Networks using Dissipativity and Mesh Stability</title>
      <link>https://arxiv.org/abs/2509.24665</link>
      <description>arXiv:2509.24665v2 Announce Type: cross 
Abstract: Analyzing and controlling spreading processes are challenging problems due to the involved non-linear node (subsystem) dynamics, unknown disturbances, complex interconnections, and the large-scale and multi-level nature of the problems. The dissipativity concept provides a practical framework for addressing such concerns, thanks to the energy-based representation it offers for subsystems and the compositional properties it provides for the analysis and control of interconnected (networked) systems comprised of such subsystems. Therefore, in this paper, we utilize the dissipativity concept to analyze and control a spreading process that occurs over a hierarchy of nodes, groups, and a network (i.e., a spreading network). We start by generalizing several existing results on dissipativity-based topology design for networked systems. Next, we model the considered spreading network as a networked system and establish the dissipativity properties of its nodes. The generalized topology design method is then applied at multiple levels of the considered spreading network to formulate its analysis and control problems as Linear Matrix Inequality (LMI) problems. We identify and enforce localized necessary conditions to support the feasibility of the LMI problem solved at each subsequent hierarchical level of the spreading network. Consequently, the proposed method does not involve iterative multi-level optimization stages that are computationally inefficient. The proposed control solution ensures that the spreading network is not only stable but also dissipative and mesh-stable. Compared to conventional methods, such as threshold pruning and high-degree edge removal, our approach offers superior performance in terms of infection containment, control efficiency, and disturbance robustness. Extensive numerical results demonstrate the effectiveness of the proposed technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24665v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shirantha Welikala, Hai Lin, Panos J. Antsaklis</dc:creator>
    </item>
    <item>
      <title>Orbits and attainable Hamiltonian diffeomorphisms of mechanical Liouville equations</title>
      <link>https://arxiv.org/abs/2509.24960</link>
      <description>arXiv:2509.24960v2 Announce Type: cross 
Abstract: We study the approximate controllability problem for Liouville transport equations along a mechanical Hamiltonian vector field. Such PDEs evolve inside the orbit $$\mathcal{O}(\rho_0):=\left\{\rho_0\circ \Phi\mid \Phi\in {\rm DHam}(T^*M)\right\},\quad \rho_0\in L^r(T^*M,\mathbb{R}), \quad r\in[1,\infty),$$ where $\rho_0$ is the initial density and ${\rm DHam}(T^*M)$ is the group of Hamiltonian diffeomorphisms of the cotangent bundle manifold $T^*M$. The approximately reachable densities from $\rho_0$ are thus contained in $\overline{\mathcal{O}(\rho_0)}$, where the closure is taken with respect to the $L^r$-topology. Our first result is a characterization of $\overline{\mathcal{O}(\rho_0)}$ when the manifold $M$ is the Euclidean space $\mathbb{R}^d$ or the torus $\mathbb{T}^d$ of arbitrary dimension: $\overline{\mathcal{O}(\rho_0)}$ is the set of all the densities whose sub- and super-level sets have the same measure as those of $\rho_0$. This result is an approximate version, in the case of ${\rm DHam}(T^*M)$, of a theorem by J. Moser (Trans. Am. Math. Soc. 120: 286-294, 1965) on the group of diffeomorphisms.
  We then present two examples of systems, respectively on $M=\mathbb{R}^d$ and $\mathbb{T}^d$, where the small-time approximately attainable diffeomorphisms coincide with ${\rm DHam}(T^*M)$, respectively at the level of the group and at the level of the densities.
  The proofs are based on the construction of Hamiltonian diffeomorphisms that approximate suitable permutations of finite grids, and Poisson bracket techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24960v2</guid>
      <category>math.SG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bettina Kazandjian, Eugenio Pozzoli, Mario Sigalotti</dc:creator>
    </item>
    <item>
      <title>Last-Iterate Convergence: Zero-Sum Games and Constrained Min-Max Optimization</title>
      <link>https://arxiv.org/abs/1807.04252</link>
      <description>arXiv:1807.04252v5 Announce Type: replace 
Abstract: Motivated by applications in Game Theory, Optimization, and Generative Adversarial Networks, recent work of Daskalakis et al \cite{DISZ17} and follow-up work of Liang and Stokes \cite{LiangS18} have established that a variant of the widely used Gradient Descent/Ascent procedure, called "Optimistic Gradient Descent/Ascent (OGDA)", exhibits last-iterate convergence to saddle points in {\em unconstrained} convex-concave min-max optimization problems. We show that the same holds true in the more general problem of {\em constrained} min-max optimization under a variant of the no-regret Multiplicative-Weights-Update method called "Optimistic Multiplicative-Weights Update (OMWU)". This answers an open question of Syrgkanis et al \cite{SALS15}.
  The proof of our result requires fundamentally different techniques from those that exist in no-regret learning literature and the aforementioned papers. We show that OMWU monotonically improves the Kullback-Leibler divergence of the current iterate to the (appropriately normalized) min-max solution until it enters a neighborhood of the solution. Inside that neighborhood we show that OMWU is locally (asymptotically) stable converging to the exact solution. We believe that our techniques will be useful in the analysis of the last iterate of other learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:1807.04252v5</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantinos Daskalakis, Ioannis Panageas</dc:creator>
    </item>
    <item>
      <title>First-order methods almost always avoid saddle points: the case of vanishing step-sizes</title>
      <link>https://arxiv.org/abs/1906.07772</link>
      <description>arXiv:1906.07772v3 Announce Type: replace 
Abstract: In a series of papers \cite{LSJR16, PP17, LPP}, it was established that some of the most commonly used first order methods almost surely (under random initializations) and with step-size being small enough, avoid strict saddle points, as long as the objective function $f$ is $C^2$ and has Lipschitz gradient. The key observation was that first order methods can be studied from a dynamical systems perspective, in which instantiations of Center-Stable manifold theorem allow for a global analysis. The results of the aforementioned papers were limited to the case where the step-size $\alpha$ is constant, i.e., does not depend on time (and bounded from the inverse of the Lipschitz constant of the gradient of $f$). It remains an open question whether or not the results still hold when the step-size is time dependent and vanishes with time.
  In this paper, we resolve this question on the affirmative for gradient descent, mirror descent, manifold descent and proximal point. The main technical challenge is that the induced (from each first order method) dynamical system is time non-homogeneous and the stable manifold theorem is not applicable in its classic form. By exploiting the dynamical systems structure of the aforementioned first order methods, we are able to prove a stable manifold theorem that is applicable to time non-homogeneous dynamical systems and generalize the results in \cite{LPP} for vanishing step-sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:1906.07772v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Panageas, Georgios Piliouras, Xiao Wang</dc:creator>
    </item>
    <item>
      <title>A Cutting-plane and Benders' Decomposition Algorithm for Two-Stage Distributionally Robust Convex programs</title>
      <link>https://arxiv.org/abs/2112.04160</link>
      <description>arXiv:2112.04160v3 Announce Type: replace 
Abstract: We present a finitely convergent cutting-plane algorithm for solving a general mixed-integer convex program given an oracle for solving a general convex program. This method is extended to solve a family of two-stage mixed-integer convex programs using cutting planes, with applications to solving distributionally-robust two-stage stochastic mixed-integer convex programs. Analysis is also given for the case where convex programming oracle provides an $epsilon$-optimal solution. We combine the cut generation with a branch-and-union scheme to develop a more practical algorithm. Computational results on generated test problems show the practicality of our algorithm. Specifically, results show that in the tested problems our algorithm achieves &lt; 5% optimality gap in 12 hours. This gap is &gt;17% with a commercial solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.04160v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fengqiao Luo, Shibshankar Dey, Sanjay Mehrotra</dc:creator>
    </item>
    <item>
      <title>Explicit Second-Order Min-Max Optimization: Practical Algorithms and Complexity Analysis</title>
      <link>https://arxiv.org/abs/2210.12860</link>
      <description>arXiv:2210.12860v5 Announce Type: replace 
Abstract: We propose and analyze several inexact regularized Newton-type methods for finding a global saddle point of \emph{convex-concave} unconstrained min-max optimization problems. Compared to first-order methods, our understanding of second-order methods for min-max optimization is relatively limited, as obtaining global rates of convergence with second-order information can be much more involved. In this paper, we examine how second-order information is used to speed up extra-gradient methods, even under inexactness. In particular, we show that the proposed methods generate iterates that remain within a bounded set and that the averaged iterates converge to an $\epsilon$-saddle point within $O(\epsilon^{-2/3})$ iterations in terms of a restricted gap function. We also provide a simple routine for solving the subproblem at each iteration, requiring a single Schur decomposition and $O(\log\log(1/\epsilon))$ calls to a linear system solver in a quasi-upper-triangular system. Thus, our method improves the existing line-search-based second-order min-max optimization methods by shaving off an $O(\log\log(1/\epsilon))$ factor in the required number of Schur decompositions. Finally, we conduct experiments on synthetic and real data to demonstrate the efficiency of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12860v5</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyi Lin, Panayotis Mertikopoulos, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Algorithms for Robust MDPs with Non-Rectangular Uncertainty Sets</title>
      <link>https://arxiv.org/abs/2305.19004</link>
      <description>arXiv:2305.19004v4 Announce Type: replace 
Abstract: We propose policy gradient algorithms for robust infinite-horizon Markov decision processes (MDPs) with non-rectangular uncertainty sets, thereby addressing an open challenge in the robust MDP literature. Indeed, uncertainty sets that display statistical optimality properties and make optimal use of limited data often fail to be rectangular. Unfortunately, the corresponding robust MDPs cannot be solved with dynamic programming techniques and are in fact provably intractable. We first present a randomized projected Langevin dynamics algorithm that solves the robust policy evaluation problem to global optimality but is inefficient. We also propose a deterministic policy gradient method that is efficient but solves the robust policy evaluation problem only approximately, and we prove that the approximation error scales with a new measure of non-rectangularity of the uncertainty set. Finally, we describe an actor-critic algorithm that finds an $\epsilon$-optimal solution for the robust policy improvement problem in $\mathcal{O}(1/\epsilon^4)$ iterations. We thus present the first complete solution scheme for robust MDPs with non-rectangular uncertainty sets offering global optimality guarantees. Numerical experiments show that our algorithms compare favorably against state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19004v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmeng Li, Daniel Kuhn, Tobias Sutter</dc:creator>
    </item>
    <item>
      <title>Vibrational Stabilization of Complex Network Systems</title>
      <link>https://arxiv.org/abs/2308.05823</link>
      <description>arXiv:2308.05823v2 Announce Type: replace 
Abstract: Many natural and man-made network systems need to maintain certain patterns, such as working at equilibria or limit cycles, to function properly. Thus, the ability to stabilize such patterns is crucial. Most of the existing studies on stabilization assume that network systems states can be measured online so that feedback control strategies can be used. However, in many real-world scenarios, systems states, e.g., neuronal activity in the brain, are often difficult to measure. In this paper, we take this situation into account and study the stabilization problem of linear network systems with an open-loop control strategy (vibrational control). We derive a graph-theoretic sufficient condition for structural vibrational stabilizability, under which network systems can always be stabilized. We further provide an approach to select the locations in the network for control placement and design corresponding vibrational inputs to stabilize systems that satisfy this condition. Finally, we provide some numerical results that demonstrate the validity of our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05823v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/ACC55779.2023.10156032</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2022 American Control Conference, San Diego, May, 2022</arxiv:journal_reference>
      <dc:creator>Alberto Maria Nobili, Yuzhen Qin, Carlo Alberto Avizzano, Danielle S. Bassett, Fabio Pasqualetti</dc:creator>
    </item>
    <item>
      <title>A Proximal Gradient Method With Probabilistic Multi-Gossip Communications for Decentralized Composite Optimization</title>
      <link>https://arxiv.org/abs/2312.11861</link>
      <description>arXiv:2312.11861v3 Announce Type: replace 
Abstract: Decentralized optimization methods with local updates have recently gained attention for their provable ability to communication acceleration. In these methods, nodes perform several iterations of local computations between the communication rounds. Nevertheless, this capability is effective only when the network is sufficiently well-connected and the loss function is smooth. In this paper, we propose a communication-efficient method MG-Skip with probabilistic local updates and multi-gossip communications for decentralized composite (smooth + nonsmooth) optimization, whose stepsize is independent of the number of local updates and the network topology. For any undirected and connected networks, MG-Skip allows for the multi-gossip communications to be skipped in most iterations in the strongly convex setting, while its computation complexity is $\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$ and communication complexity is only $\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log \frac{1}{\epsilon}\right)$, where $\kappa$ is the condition number of the loss function, $\rho$ reflects the connectivity of the network topology, and $\epsilon$ is the target accuracy. The theoretical results indicate that MG-Skip achieves provable communication acceleration, thereby validating the advantages of local updates in the nonsmooth setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11861v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyao Guo, Luqing Wang, Xinli Shi, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>A Globally Convergent Gradient Method with Momentum</title>
      <link>https://arxiv.org/abs/2403.17613</link>
      <description>arXiv:2403.17613v4 Announce Type: replace 
Abstract: In this work, we consider smooth unconstrained optimization problems and we deal with the class of gradient methods with momentum, i.e., descent algorithms where the search direction is defined as a linear combination of the current gradient and the preceding search direction. This family of algorithms includes nonlinear conjugate gradient methods and Polyak's heavy-ball approach, and is thus of high practical and theoretical interest in large-scale nonlinear optimization. We propose a general framework where the scalars of the linear combination defining the search direction are computed simultaneously by minimizing the approximate quadratic model in the 2 dimensional subspace. This strategy allows us to define a class of gradient methods with momentum enjoying global convergence guarantees and an optimal worst-case complexity bound in the nonconvex setting. Differently than all related works in the literature, the convergence conditions are stated in terms of the Hessian matrix of the bi-dimensional quadratic model. To the best of our knowledge, these results are novel to the literature. Moreover, extensive computational experiments show that the gradient method with momentum here presented is a solid choice to tackle some classes of nonconvex unconstrained problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17613v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Giampaolo Liuzzi, Stefano Lucidi, Davide Pucci, Marco Sciandrone</dc:creator>
    </item>
    <item>
      <title>Rapid stabilization and finite time stabilization of the bilinear Schr\"odinger equation</title>
      <link>https://arxiv.org/abs/2405.10002</link>
      <description>arXiv:2405.10002v2 Announce Type: replace 
Abstract: We propose a method to establish the rapid stabilization of the bilinear Schr\"odinger control system and its linearized system, and the finite time stabilization of the linearized system using the Grammian operators. The analysis of the rapid stabilization involves a new quantity (variable) which is inspired by the adjoint state in the optimal control theory and is proposed in our recent work on control systems associated with strongly continuous group. The analysis of the finite time stabilization follows the strategy introduced by Coron and Nguyen in the study of the finite time stabilization of the heat equation and incorporate a new ingredient involving the estimate of the cost of controls of the linearized system in small time derived in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10002v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoai-Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>BIBO stability of 1-D hyperbolic boundary control systems</title>
      <link>https://arxiv.org/abs/2410.12697</link>
      <description>arXiv:2410.12697v2 Announce Type: replace 
Abstract: We study the question of bounded-input bounded-output (BIBO) stability of a class of 1-D hyperbolic boundary control systems, which, in particular, contains distributed port-Hamiltonian systems. Exploiting the particular structure of the transfer function of these systems, we derive several sufficient conditions for BIBO stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12697v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix L. Schwenninger, Alexander A. Wierzba</dc:creator>
    </item>
    <item>
      <title>A quantitative Robbins-Siegmund theorem</title>
      <link>https://arxiv.org/abs/2410.15986</link>
      <description>arXiv:2410.15986v2 Announce Type: replace 
Abstract: The Robbins-Siegmund theorem is one of the most important results in stochastic optimization, where it is widely used to prove the convergence of stochastic algorithms. We provide a quantitative version of the theorem, establishing a bound on how far one needs to look in order to locate a region of \emph{metastability} in the sense of Tao. Our proof involves a metastable analogue of Doob's theorem for $L_1$-supermartingales along with a series of technical lemmas that make precise how quantitative information propagates through sums and products of stochastic processes. In this way, our paper establishes a general methodology for finding metastable bounds for stochastic processes that can be reduced to supermartingales, and therefore for obtaining quantitative convergence information across a broad class of stochastic algorithms whose convergence proof relies on some variation of the Robbins-Siegmund theorem. We conclude by discussing how our general quantitative result might be used in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15986v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.LO</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morenikeji Neri, Thomas Powell</dc:creator>
    </item>
    <item>
      <title>Predict-and-Optimize Robust Unit Commitment with Statistical Guarantees via Weight Combination</title>
      <link>https://arxiv.org/abs/2411.03138</link>
      <description>arXiv:2411.03138v3 Announce Type: replace 
Abstract: The growing uncertainty from renewable power and electricity demand brings significant challenges to unit commitment (UC). While various advanced forecasting and optimization methods have been developed to predict better and address this uncertainty, most previous studies treat forecasting and optimization as separate tasks. This separation can lead to suboptimal results due to misalignment between the objectives of the two tasks. To overcome this challenge, we propose a robust UC framework that integrates forecasting and optimization processes while ensuring statistical guarantees. In the forecasting stage, we combine multiple predictions derived from diverse data sources and methodologies for an improved prediction, aiming to optimize the UC performance. In the optimization stage, the combined prediction is used to construct an uncertainty set with statistical guarantees, based on which the robust UC model is formulated. The optimal robust UC solution provides feedback to refine the weight used for combining multiple predictions. To solve the proposed integrated forecasting-optimization framework efficiently and effectively, we develop a neural network-based surrogate model for acceleration and introduce a reshaping method for the uncertainty set based on the optimization result to reduce conservativeness. Case studies on modified IEEE 30-bus and 118-bus systems demonstrate the advantages of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03138v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui Xie, Yue Chen, Pierre Pinson</dc:creator>
    </item>
    <item>
      <title>Fast Krasnoselskii-Mann Method with Overrelaxation and Preconditioners</title>
      <link>https://arxiv.org/abs/2411.18574</link>
      <description>arXiv:2411.18574v2 Announce Type: replace 
Abstract: We study accelerated Krasnoselskii-Mann-type methods with preconditioners in both continuous and discrete time. From a continuous-time model, we derive a generalized fast Krasnoselskii-Mann method, providing a new yet simple proof of convergence that leads to unprecedented flexibility in parameter tuning, allowing up to twice larger relaxation parameters. Our analysis unifies inertial and anchoring acceleration mechanisms and offers a broad range of parameter choices, which prove beneficial in practice. Additionally, we extend our analysis to the case where preconditioners are allowed to be degenerate, unifying the treatment of various splitting methods and establishing the weak convergence of shadow sequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18574v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu I. Bo\c{t}, Enis Chenchene, Jalal M. Fadili</dc:creator>
    </item>
    <item>
      <title>Moment-sos and spectral hierarchies for polynomial optimization on the sphere and quantum de Finetti theorems</title>
      <link>https://arxiv.org/abs/2412.13191</link>
      <description>arXiv:2412.13191v3 Announce Type: replace 
Abstract: We revisit the convergence analysis of two approximation hierarchies for polynomial optimization on the unit sphere. The first one is based on the moment-sos approach and gives semidefinite bounds for which Fang and Fawzi (2021) showed an analysis in $O(1/r^2)$ for the r-th level bound, using the polynomial kernel method. The second hierarchy was recently proposed by Lovitz and Johnston (2023) and gives spectral bounds for which they show a convergence rate in $O(1/r)$, using a quantum de Finetti theorem of Christandl et al. (2007) that applies to complex Hermitian matrices with a "double" symmetry. We investigate links between these approaches, in particular, via duality of moments and sums of squares.
  Our main results include showing that the spectral bounds cannot have a convergence rate better than $O(1/r^2)$ and that they do not enjoy generic finite convergence. In addition, we propose alternative performance analyses that involve explicit constants depending on intrinsic parameters of the optimization problem. For this we develop a novel "banded" real de Finetti theorem that applies to real matrices with "double" symmetry. We also show how to use the polynomial kernel method to obtain a de Finetti type result in $O(1/r^2)$ for real maximally symmetric matrices, improving an earlier result in $O(1/r)$ of Doherty and Wehner (2012).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13191v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Taveira Blomenhofer, Monique Laurent</dc:creator>
    </item>
    <item>
      <title>A learning-based approach to stochastic optimal control under reach-avoid constraint</title>
      <link>https://arxiv.org/abs/2412.16561</link>
      <description>arXiv:2412.16561v3 Announce Type: replace 
Abstract: We develop a model-free approach to optimally control stochastic, Markovian systems subject to a reach-avoid constraint. Specifically, the state trajectory must remain within a safe set while reaching a target set within a finite time horizon. Due to the time-dependent nature of these constraints, we show that, in general, the optimal policy for this constrained stochastic control problem is non-Markovian, which increases the computational complexity. To address this challenge, we apply the state-augmentation technique from arXiv:2402.19360, reformulating the problem as a constrained Markov decision process (CMDP) on an extended state space. This transformation allows us to search for a Markovian policy, avoiding the complexity of non-Markovian policies. To learn the optimal policy without a system model, and using only trajectory data, we develop a log-barrier policy gradient approach. We prove that under suitable assumptions, the policy parameters converge to the optimal parameters, while ensuring that the system trajectories satisfy the stochastic reach-avoid constraint with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16561v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3716863.3718055</arxiv:DOI>
      <arxiv:journal_reference>28th ACM International Conference on Hybrid Systems: Computation and Control (HSCC '25), May 6-9, 2025</arxiv:journal_reference>
      <dc:creator>Tingting Ni, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Non-Expansive Mappings in Two-Time-Scale Stochastic Approximation: Finite-Time Analysis</title>
      <link>https://arxiv.org/abs/2501.10806</link>
      <description>arXiv:2501.10806v2 Announce Type: replace 
Abstract: Two-time-scale stochastic approximation algorithms are iterative methods used in applications such as optimization, reinforcement learning, and control. Finite-time analysis of these algorithms has primarily focused on fixed point iterations where both time-scales have contractive mappings. In this work, we broaden the scope of such analyses by considering settings where the slower time-scale has a non-expansive mapping. For such algorithms, the slower time-scale can be viewed as a stochastic inexact Krasnoselskii-Mann iteration. We also study a variant where the faster time-scale has a projection step which leads to non-expansiveness in the slower time-scale. We show that the last-iterate mean square residual error for such algorithms decays at a rate $O(1/k^{1/4-\epsilon})$, where $\epsilon&gt;0$ is arbitrarily small. We further establish almost sure convergence of iterates to the set of fixed points. We demonstrate the applicability of our framework by applying our results to minimax optimization, linear stochastic approximation, and Lagrangian optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10806v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth Chandak</dc:creator>
    </item>
    <item>
      <title>Min-Max Optimisation for Nonconvex-Nonconcave Functions Using a Random Zeroth-Order Extragradient Algorithm</title>
      <link>https://arxiv.org/abs/2504.07388</link>
      <description>arXiv:2504.07388v2 Announce Type: replace 
Abstract: This study explores the performance of the random Gaussian smoothing Zeroth-Order ExtraGradient (ZO-EG) scheme considering \Af{deterministic} min-max optimisation problems with possibly NonConvex-NonConcave (NC-NC) objective functions. We consider both unconstrained and constrained, differentiable and non-differentiable settings. We discuss the min-max problem from the point of view of variational inequalities. For the unconstrained problem, we establish the convergence of the ZO-EG algorithm to the neighbourhood of an $\epsilon$-stationary point of the NC-NC objective function, whose radius can be controlled under a variance reduction scheme, along with its complexity. For the constrained problem, we introduce the new notion of proximal variational inequalities and give examples of functions satisfying this property. Moreover, we prove analogous results to the unconstrained case for the constrained problem. For the non-differentiable case, we prove the convergence of the ZO-EG algorithm to a neighbourhood of an $\epsilon$-stationary point of the smoothed version of the objective function, where the radius of the neighbourhood can be controlled, which can be related to the ($\delta,\epsilon$)-Goldstein stationary point of the original objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07388v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amir Ali Farzin, Yuen Man Pun, Philipp Braun, Antoine Lesage-landry, Youssef Diouane, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Convergence of Clipped-SGD for Convex $(L_0,L_1)$-Smooth Optimization with Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2505.20817</link>
      <description>arXiv:2505.20817v2 Announce Type: replace 
Abstract: Gradient clipping is a widely used technique in Machine Learning and Deep Learning (DL), known for its effectiveness in mitigating the impact of heavy-tailed noise, which frequently arises in the training of large language models. Additionally, first-order methods with clipping, such as Clip-SGD, exhibit stronger convergence guarantees than SGD under the $(L_0,L_1)$-smoothness assumption, a property observed in many DL tasks. However, the high-probability convergence of Clip-SGD under both assumptions -- heavy-tailed noise and $(L_0,L_1)$-smoothness -- has not been fully addressed in the literature. In this paper, we bridge this critical gap by establishing the first high-probability convergence bounds for Clip-SGD applied to convex $(L_0,L_1)$-smooth optimization with heavy-tailed noise. Our analysis extends prior results by recovering known bounds for the deterministic case and the stochastic setting with $L_1 = 0$ as special cases. Notably, our rates avoid exponentially large factors and do not rely on restrictive sub-Gaussian noise assumptions, significantly broadening the applicability of gradient clipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20817v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Savelii Chezhegov, Aleksandr Beznosikov, Samuel Horv\'ath, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence for the Last Iterate of Stochastic Gradient Descent Schemes</title>
      <link>https://arxiv.org/abs/2507.07281</link>
      <description>arXiv:2507.07281v2 Announce Type: replace 
Abstract: We study the almost sure convergence rate for the last iterate of stochastic gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric setting when the objective function $F$ is globally convex or non-convex whose gradient is $\gamma$-H\"{o}lder. Using only discrete Gronwall's inequality without Robbins-Siegmund theorem, we recover results for both SGD and SHB: $\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$ for non-convex objectives and $F(w_t) - F_* = o(t^{2\gamma/(1+\gamma) \cdot \max(p-1,-2p+1)-\epsilon})$ for $\beta \in (0, 1)$ and $\min_{s \leq t} F(w_s) - F_* = o(t^{p-1})$ almost surely for convex objectives. In addition, we proved that SHB with constant momentum parameter $\beta \in (0, 1)$ attains a convergence rate of $F(w_t) - F_* = O(t^{\max(p-1,-2p+1)} \log^2 \frac{t}{\delta})$ with probability at least $1-\delta$ when $F$ is convex and $\gamma = 1$ and step size $\alpha_t = \Theta(t^{-p})$ with $p \in (\frac{1}{2}, 1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07281v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcel Hudiani</dc:creator>
    </item>
    <item>
      <title>Augmentation approaches for Mixed Integer Programming</title>
      <link>https://arxiv.org/abs/2507.08525</link>
      <description>arXiv:2507.08525v2 Announce Type: replace 
Abstract: This paper analyses the feasible sets structure of general mixed integer linear programs (MIPs) and its relationship with the existence of a finite cardinality test set which can be applied in augmentation algorithms. We derive and characterize a computable, finite test set for MIPs which can be embedded in a finite augmentation algorithm. Several examples illustrate the structure of this set and its relationship with previous approaches in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08525v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justo Puerto, Jose A. Ruiz-Alba</dc:creator>
    </item>
    <item>
      <title>FMIP: Joint Continuous-Integer Flow For Mixed-Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2507.23390</link>
      <description>arXiv:2507.23390v2 Announce Type: replace 
Abstract: Mixed-Integer Linear Programming (MILP) is a foundational tool for complex decision-making problems. However, the NP-hard nature of MILP presents a significant computational challenge, motivating the development of machine learning-based heuristic solutions to accelerate downstream solvers. While recent generative models have shown promise in learning powerful heuristics, they suffer from a critical limitation. That is, they model the distribution of only the integer variables and fail to capture the intricate coupling between integer and continuous variables, creating an information bottleneck and ultimately leading to suboptimal solutions. To this end, we propose Joint Continuous-Integer Flow for Mixed-Integer Linear Programming (FMIP), which is the first generative framework that models the joint distribution of both integer and continuous variables for MILP solutions. Built upon the joint modeling paradigm, a holistic guidance mechanism is designed to steer the generative trajectory, actively refining solutions toward optimality and feasibility during the inference process. Extensive experiments on eight standard MILP benchmarks demonstrate the superior performance of FMIP against existing baselines, reducing the primal gap by 41.34% on average. Moreover, we show that FMIP is fully compatible with arbitrary backbone networks and various downstream solvers, making it well-suited for a broad range of real-world MILP applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23390v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongpei Li, Hui Yuan, Han Zhang, Jianghao Lin, Dongdong Ge, Mengdi Wang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>The Second-Order T\^atonnement: Decentralized Interior-Point Methods for Market Equilibrium</title>
      <link>https://arxiv.org/abs/2508.04822</link>
      <description>arXiv:2508.04822v3 Announce Type: replace 
Abstract: The t\^atonnement process and Smale's process are two classical approaches to compute market equilibrium in exchange economies. While the t\^atonnement process can be seen as a first-order method, Smale's process, being second-order, is less popular due to its reliance on additional information from the players and expensive Newton steps. In this paper, we study Fisher exchange market for a broad class of utility functions, where we show that all high-order information required by Smale's process is readily available from players' best responses. Motivated by this observation, we develop two second-order t\^atonnement processes, constructed as decentralized interior-point methods, which are traditionally known to work in a centralized manner. The methods here bear the name "t\^atonnement", since, in spirit, they demand no more information than the classical t\^atonnement process. To address the Newton systems involved, we introduce an explicitly invertible approximation with high-probability guarantees and a scaling matrix that optimally minimizes the condition number, both of which rely solely on best responses as the methods themselves. Using these tools, the first second-order t\^atonnement process has O(log(1/$\epsilon$))complexity rate. Under mild conditions, the other method achieves a non-asymptotic superlinear convergence rate. Preliminary experiments are presented to justify the capability of the proposed methods for large-scale problems. Extensions of our approach are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04822v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chuwen Zhang, Chang He, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Optimality of Linear Policies in Distributionally Robust Linear Quadratic Control</title>
      <link>https://arxiv.org/abs/2508.11858</link>
      <description>arXiv:2508.11858v2 Announce Type: replace 
Abstract: We study a generalization of the classical discrete-time, Linear-Quadratic-Gaussian (LQG) control problem where the noise distributions affecting the states and observations are unknown and chosen adversarially from divergence-based ambiguity sets centered around a known nominal distribution. For a finite horizon model with Gaussian nominal noise and a structural assumption on the divergence that is satisfied by many examples -- including 2-Wasserstein distance, Kullback-Leibler divergence, moment-based divergences, entropy-regularized optimal transport, or Fisher (score-matching) divergence -- we prove that a control policy that is affine in the observations is optimal and the adversary's corresponding worst-case optimal distribution is Gaussian.
  When the nominal means are zero (as in the classical LQG model), we show that the adversary should optimally set the distribution's mean to zero and the optimal control policy becomes linear. Moreover, the adversary should optimally ``inflate" the noise by choosing covariance matrices that dominate the nominal covariance in Loewner order. Exploiting these structural properties, we develop a Frank-Wolfe algorithm whose inner step solves standard LQG subproblems via Kalman filtering and dynamic programming and show that the implementation consistently outperforms semidefinite-programming reformulations of the problem. All structural and algorithmic results extend to an infinite-horizon, average-cost formulation, yielding stationary linear policies and a time-invariant Gaussian distribution for the adversary. Lastly, we show that when the divergence is 2-Wasserstein, the entire framework remains valid when the nominal distributions are elliptical rather than Gaussian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11858v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bahar Ta\c{s}kesen, Dan A. Iancu, \c{C}a\u{g}{\i}l Ko\c{c}yi\u{g}it, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Shuffling Heuristic in Variational Inequalities: Establishing New Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2509.04133</link>
      <description>arXiv:2509.04133v2 Announce Type: replace 
Abstract: Variational inequalities have gained significant attention in machine learning and optimization research. While stochastic methods for solving these problems typically assume independent data sampling, we investigate an alternative approach -- the shuffling heuristic. This strategy involves permuting the dataset before sequential processing, ensuring equal consideration of all data points. Despite its practical utility, theoretical guarantees for shuffling in variational inequalities remain unexplored. We address this gap by providing the first theoretical convergence estimates for shuffling methods in this context. Our analysis establishes rigorous bounds and convergence rates, extending the theoretical framework for this important class of algorithms. We validate our findings through extensive experiments on diverse benchmark variational inequality problems, demonstrating faster convergence of shuffling methods compared to independent sampling approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04133v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Medyakov, Gleb Molodtsov, Grigoriy Evseev, Egor Petrov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>What is the Best Way to Do Something? A Discreet Tour of Discrete Optimization</title>
      <link>https://arxiv.org/abs/2509.05932</link>
      <description>arXiv:2509.05932v2 Announce Type: replace 
Abstract: In mathematical optimization, we want to find the best possible solution for a decision-making problem. Curiously, these problems are harder to solve if they have discrete decisions. Imagine that you would like to buy chocolate: you can buy no chocolate or one chocolate bar, but typically you cannot buy just half of a bar. Now imagine that you could also buy many other items, and that you need to meet nutritional needs while minimizing the grocery bill. With more options and more demands, finding the best solution becomes trickier. But since many real-world settings benefit from mathematical optimization, such as scheduling trains and flights, planning truck deliveries, and making better investment decisions, these problems are widely studied in a branch of mathematics called Operations Research (OR). Sometimes we can simply write the mathematical model and find an optimal solution with OR software, but for larger problems we may need to develop new mathematical models and even write our own algorithms. We explore both cases with a simple and well-known problem (the traveling salesperson problem), some computer programming (in Python), and software that is free for academic use (Gurobi).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05932v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Serra</dc:creator>
    </item>
    <item>
      <title>On Tackling High-Dimensional Nonconvex Stochastic Optimization via Stochastic First-Order Methods with Non-smooth Proximal Terms and Variance Reduction</title>
      <link>https://arxiv.org/abs/2509.13992</link>
      <description>arXiv:2509.13992v2 Announce Type: replace 
Abstract: When the nonconvex problem is complicated by stochasticity, the sample complexity of stochastic first-order methods may depend linearly on the problem dimension, which is undesirable for large-scale problems. To alleviate this linear dependence, we adopt non-Euclidean settings and propose two choices of non-smooth proximal terms when taking the stochastic gradient steps. This approach leads to stronger convergence metric, incremental computational overhead, and potentially dimension-insensitive sample complexity. We also consider further acceleration through variance reduction which achieves near optimal sample complexity and, to our best knowledge, is the first such result in the $\ell_1/\ell_\infty$ setting. Since the use of non-smooth proximal terms is unconventional, the convergence analysis deviates much from algorithms in Euclidean settings or employing Bregman divergence, providing tools for analyzing other non-Euclidean choices of distance functions. Efficient resolution of the subproblems in various scenarios is also discussed and simulated. We illustrate the dimension-insensitive property of the proposed methods via preliminary numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13992v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Xie, Jiawen Bi, Hongcheng Liu</dc:creator>
    </item>
    <item>
      <title>The Aubin Property for Generalized Equations over $C^2$-cone Reducible Sets</title>
      <link>https://arxiv.org/abs/2509.14194</link>
      <description>arXiv:2509.14194v3 Announce Type: replace 
Abstract: This paper establishes the equivalence of the Aubin property and the strong regularity for generalized equations over $C^2$-cone reducible sets. This result resolves a long-standing question in variational analysis and extends the well-known equivalence theorem for polyhedral sets to a significantly broader class of non-polyhedral cases. Our proof strategy departs from traditional variational techniques, integrating insights from convex geometry with powerful tools from algebraic topology. A cornerstone of our analysis is a new fundamental lemma concerning the local structure of the normal cone map for arbitrary closed convex sets, which reveals how the dimension of normal cones varies in the neighborhood of a boundary point. This geometric insight is the key to applying degree theory, allowing us to prove that a crucial function associated with the problem has a topological index of $\pm1$. This, via a homological version of the inverse mapping theorem, implies that the function is a local homeomorphism, which in turn yields the strong regularity of the original solution map. This result unifies and extends several existing stability results for problems such as conventional nonlinear programming, nonlinear second-order cone programming, and nonlinear semidefinite programming under a single general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14194v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaming Ma, Defeng Sun</dc:creator>
    </item>
    <item>
      <title>Bayesian distributionally robust variational inequalities: regularization and quantification</title>
      <link>https://arxiv.org/abs/2509.16537</link>
      <description>arXiv:2509.16537v2 Announce Type: replace 
Abstract: We propose a Bayesian distributionally robust variational inequality (DRVI) framework that models the data-generating distribution through a finite mixture family, which allows us to study the DRVI on a tractable finite-dimensional parametric ambiguity set. To address distributional uncertainty, we construct a data-driven ambiguity set with posterior coverage guarantees via Bayesian inference. We also employ a regularization approach to ensure numerical stability. We prove the existence of solutions to the Bayesian DRVI and the asymptotic convergence to a solution as sample size grows to infinity and the regularization parameter goes to zero. Moreover, we derive quantitative stability bounds and finite-sample guarantees under data scarcity and contamination. Numerical experiments on a distributionally robust multi-portfolio Nash equilibrium problem validate our theoretical results and demonstrate the robustness and reliability of Bayesian DRVI solutions in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16537v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wentao Ma, Zhiping Chen, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>Eco-Conscious Customers Behavior in Capacitated Two-Echelon Location-Routing Models for Sustainable Last-Mile Delivery</title>
      <link>https://arxiv.org/abs/2509.22357</link>
      <description>arXiv:2509.22357v2 Announce Type: replace 
Abstract: This paper introduces a novel capacitated Two-Echelon Location-Routing Problem with Eco-conscious Customer Behavior (2E-LRP-ECB) aimed at enhancing the environmental sustainability of last-mile delivery (LMD) operations. The model jointly optimizes dynamic satellites location, vehicle routing, and customer delivery modes, explicitly accounting for (i) heterogeneous customer travel behaviors, (ii) heterogeneous fleet composition, and (iii) diverse emission profiles across both echelons. A piecewise linear formulation captures the additional emissions from first-echelon vehicle stops, while customer travel emissions are computed based on individual willingness and capacity to use zero-emission transport. The problem is solved exactly for a wide set of real-world-based instances under four operational strategies, differing in optimization objectives and second-echelon fleet composition. Computational experiments, including a case study with a major Portuguese LMD provider, highlight the environmental and operational tradeoffs inherent to strategic and operational choices such as fleet composition, satellite activation, and customer pick-up policies. Results reveal that minimizing distance can lead to substantial increases in emissions, while emissions-oriented strategies leverage customer travel to achieve significant sustainability gains without compromising service efficiency. A multi-objective analysis using the epsilon-constraint method produces Pareto frontiers and knee-point solutions, offering actionable insights for balancing operational efficiency and environmental impact in sustainable LMD design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22357v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentina Bonomi, Diana Jorge, T\^ania Ramos, Ana Barbosa-P\'ovoa</dc:creator>
    </item>
    <item>
      <title>Duality of causal distributionally robust optimization</title>
      <link>https://arxiv.org/abs/2401.16556</link>
      <description>arXiv:2401.16556v2 Announce Type: replace-cross 
Abstract: We study the distributionally robust optimization (DRO) in a dynamic context where the model uncertainty is captured by penalizing potential models in function of their adapted Wasserstein distance to a given reference model. We consider both discrete- and continuous-time settings and derive dynamic duality formulas that reformulate the worst-case expectation as a tractable minimax problem. The inner maximum can be computed recursively in discrete time, or solved by a path-dependent Hamilton--Jacobi--Bellman equation in continuous time. We further extend these duality results from the worst-case expectation to the worst-case expected shortfall, a non-linear expectation. Finally, we apply the DRO framework to optimal stopping problems in discrete time. We recast the original problem as a classical Wasserstein DRO on a nested space by introducing a novel relaxation that considers stopping times with respect to general flitrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16556v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Jiang</dc:creator>
    </item>
    <item>
      <title>Gromov's Approximating Tree and the All-Pairs Bottleneck Paths Problem</title>
      <link>https://arxiv.org/abs/2408.05338</link>
      <description>arXiv:2408.05338v2 Announce Type: replace-cross 
Abstract: Given a pointed metric space $(X,\mathsf{dist}, w)$ on $n$ points, its Gromov's approximating tree is a 0-hyperbolic pseudo-metric space $(X,\mathsf{dist}_T)$ such that $\mathsf{dist}(x,w)=\mathsf{dist}_T(x,w)$ and $\mathsf{dist}(x, y)-2 \delta \log_2n \leq \mathsf{dist}_T (x, y) \leq \mathsf{dist}(x, y)$ for all $x, y \in X$ where $\delta$ is the Gromov hyperbolicity of $X$. On the other hand, the all pairs bottleneck paths (APBP) problem asks, given an undirected graph with some capacities on its edges, to find the maximal path capacity between each pair of vertices. In this note, we prove:
  $\bullet$ Computing Gromov's approximating tree for a metric space with $n+1$ points from its matrix of distances reduces to solving the APBP problem on an connected graph with $n$ vertices.
  $\bullet$ There is an explicit algorithm that computes Gromov's approximating tree for a graph from its adjacency matrix in quadratic time.
  $\bullet$ Solving the APBP problem on a weighted graph with $n$ vertices reduces to finding Gromov's approximating tree for a metric space with $n+1$ points from its distance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05338v2</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anders Cornect, Eduardo Mart\'inez-Pedroza</dc:creator>
    </item>
    <item>
      <title>Cost-Aware Opinion Dynamics in Multi-Agents Systems under Malicious Agent Influence</title>
      <link>https://arxiv.org/abs/2412.01524</link>
      <description>arXiv:2412.01524v3 Announce Type: replace-cross 
Abstract: In many MASs, links to malicious agents cannot be severed immediately. Under these conditions, averaging-only consensus mechanisms typically lack sufficient resistance, leaving the system vulnerable to harmful deviations. To address this challenge, this brief leverages the Boomerang Effect from sociology, which drives normal agents to firmly reject malicious inputs, although this strategy may appear overly cautious. Thus, this brief emphasizes the necessity of acknowledging the resulting trade-off between cost and convergence speed in practice. To address this, the additional costs induced by Boomerang-style fusion is analyzed and a cost aware evolution rate adjustment mechanism is proposed. Multi-robot simulations demonstrate that this mechanism suppresses excess costs while maintaining resilience to extremist disruptions and ensuring stable convergence, enabling MAS to efficiently develop in a ethical order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01524v3</guid>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhan Suo, Kaiyuan Chen, Yuanqing Xia, Xudong Zhao, Shuo Wang, Runqi Chai</dc:creator>
    </item>
    <item>
      <title>Faster Convergence of Riemannian Stochastic Gradient Descent with Increasing Batch Size</title>
      <link>https://arxiv.org/abs/2501.18164</link>
      <description>arXiv:2501.18164v5 Announce Type: replace-cross 
Abstract: We theoretically analyzed the convergence behavior of Riemannian stochastic gradient descent (RSGD) and found that using an increasing batch size leads to faster convergence than using a constant batch size, not only with a constant learning rate but also with a decaying learning rate, such as cosine annealing decay and polynomial decay. The convergence rate improves from $O(T^{-1}+C)$ with a constant batch size to $O(T^{-1})$ with an increasing batch size, where $T$ denotes the total number of iterations and $C$ is a constant. Using principal component analysis and low-rank matrix completion, we investigated, both theoretically and numerically, how an increasing batch size affects computational time as quantified by stochastic first-order oracle (SFO) complexity. An increasing batch size was found to reduce the SFO complexity of RSGD. Furthermore, an increasing batch size was found to offer the advantages of both small and large constant batch sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18164v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanata Oowada, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Finite-Time Bounds for Two-Time-Scale Stochastic Approximation with Arbitrary Norm Contractions and Markovian Noise</title>
      <link>https://arxiv.org/abs/2503.18391</link>
      <description>arXiv:2503.18391v2 Announce Type: replace-cross 
Abstract: Two-time-scale Stochastic Approximation (SA) is an iterative algorithm with applications in reinforcement learning and optimization. Prior finite time analysis of such algorithms has focused on fixed point iterations with mappings contractive under Euclidean norm. Motivated by applications in reinforcement learning, we give the first mean square bound on non linear two-time-scale SA where the iterations have arbitrary norm contractive mappings and Markovian noise. We show that the mean square error decays at a rate of $O(1/n^{2/3})$ in the general case, and at a rate of $O(1/n)$ in a special case where the slower timescale is noiseless. Our analysis uses the generalized Moreau envelope to handle the arbitrary norm contractions and solutions of Poisson equation to deal with the Markovian noise. By analyzing the SSP Q-Learning algorithm, we give the first $O(1/n)$ bound for an algorithm for asynchronous control of MDPs under the average reward criterion. We also obtain a rate of $O(1/n)$ for Q-Learning with Polyak-averaging and provide an algorithm for learning Generalized Nash Equilibrium (GNE) for strongly monotone games which converges at a rate of $O(1/n^{2/3})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18391v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth Chandak, Shaan Ul Haque, Nicholas Bambos</dc:creator>
    </item>
    <item>
      <title>Safety-Critical Control with Guaranteed Lipschitz Continuity via Filtered Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2503.23267</link>
      <description>arXiv:2503.23267v3 Announce Type: replace-cross 
Abstract: In safety-critical control systems, ensuring both system safety and smooth control input is essential for practical deployment. Existing Control Barrier Function (CBF) frameworks, especially High-Order CBFs (HOCBFs), effectively enforce safety constraints, but also raise concerns about the smoothness of the resulting control inputs. While smoothness typically refers to continuity and differentiability, it does not by itself ensure bounded input variation. In contrast, Lipschitz continuity is a stronger form of continuity that not only is necessary for the theoretical guarantee of safety, but also bounds the rate of variation and eliminates abrupt changes in the control input. Such abrupt changes can degrade system performance or even violate actuator limitations, yet current CBF-based methods do not provide Lipschitz continuity guarantees. This paper introduces Filtered Control Barrier Functions (FCBFs), which extend HOCBFs by incorporating an auxiliary dynamic system-referred to as an input regularization filter-to produce Lipschitz continuous control inputs. The proposed framework ensures safety, control bounds, and Lipschitz continuity of the control inputs simultaneously by integrating FCBFs and HOCBFs within a unified quadratic program (QP). Theoretical guarantees are provided and simulations on a unicycle model demonstrate the effectiveness of the proposed method compared to standard and smoothness-penalized HOCBF approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23267v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Wei Xiao, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>VAMO: Efficient Zeroth-Order Variance Reduction for SGD with Faster Convergence</title>
      <link>https://arxiv.org/abs/2505.13954</link>
      <description>arXiv:2505.13954v2 Announce Type: replace-cross 
Abstract: Optimizing large-scale nonconvex problems, common in deep learning, demands balancing rapid convergence with computational efficiency. First-order (FO) optimizers, which serve as today's baselines, provide fast convergence and good generalization but often incur high computation and memory costs due to the large size of modern models. Conversely, zeroth-order (ZO) algorithms reduce this burden using estimated gradients, yet their slow convergence in high-dimensional settings limits practicality. We introduce VAMO (VAriance-reduced Mixed-gradient Optimizer), a stochastic variance-reduced method that extends mini-batch SGD with full-batch ZO gradients under an SVRG-style framework. VAMO's hybrid design utilizes a two-point ZO estimator to achieve a dimension-agnostic convergence rate of $\mathcal{O}(1/T + 1/b)$, where $T$ is the number of iterations and $b$ is the batch-size, surpassing the dimension-dependent slowdown of purely ZO methods and significantly improving over SGD's $\mathcal{O}(1/\sqrt{T})$ rate. Additionally, we propose a multi-point variant that mitigates the $O(1/b)$ error by adjusting the number of estimation points to balance convergence and cost. Importantly, VAMO achieves these gains with smaller dynamic memory requirements than many FO baselines, making it particularly attractive for edge deployment. Experiments including traditional neural network training and LLM finetuning confirm that VAMO not only outperforms established FO and ZO methods, but also does so with a light memory footprint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13954v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiahe Chen, Ziye Ma</dc:creator>
    </item>
    <item>
      <title>Leveraging Coordinate Momentum in SignSGD and Muon: Memory-Optimized Zero-Order</title>
      <link>https://arxiv.org/abs/2506.04430</link>
      <description>arXiv:2506.04430v3 Announce Type: replace-cross 
Abstract: Fine-tuning Large Language Models (LLMs) is essential for adapting pre-trained models to downstream tasks. Yet traditional first-order optimizers such as Stochastic Gradient Descent (SGD) and Adam incur prohibitive memory and computational costs that scale poorly with model size. In this paper, we investigate zero-order (ZO) optimization methods as a memory- and compute-efficient alternative, particularly in the context of parameter-efficient fine-tuning techniques like LoRA. We propose $\texttt{JAGUAR SignSGD}$, a ZO momentum-based algorithm that extends ZO SignSGD, requiring the same number of parameters as the standard ZO SGD and only $\mathcal{O}(1)$ function evaluations per iteration. To the best of our knowledge, this is the first study to establish rigorous convergence guarantees for SignSGD in the stochastic ZO case. We further propose $\texttt{JAGUAR Muon}$, a novel ZO extension of the Muon optimizer that leverages the matrix structure of model parameters, and we provide its convergence rate under arbitrary stochastic noise. Through extensive experiments on challenging LLM fine-tuning benchmarks, we demonstrate that the proposed algorithms meet or exceed the convergence quality of standard first-order methods, achieving significant memory reduction. Our theoretical and empirical results establish new ZO optimization methods as a practical and theoretically grounded approach for resource-constrained LLM adaptation. Our code is available at https://github.com/brain-mmo-lab/ZO_LLM</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04430v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Egor Petrov, Grigoriy Evseev, Aleksey Antonov, Andrey Veprikov, Nikolay Bushkov, Stanislav Moiseev, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Muon Optimizes Under Spectral Norm Constraints</title>
      <link>https://arxiv.org/abs/2506.15054</link>
      <description>arXiv:2506.15054v2 Announce Type: replace-cross 
Abstract: The pursuit of faster optimization algorithms remains an active and important research direction in deep learning. Recently, the Muon optimizer [JJB+24] has demonstrated promising empirical performance, but its theoretical foundation remains less understood. In this paper, we bridge this gap and provide a theoretical analysis of Muon by placing it within the Lion-$\mathcal{K}$ family of optimizers [CLLL24]. Specifically, we show that Muon corresponds to Lion-$\mathcal{K}$ when equipped with the nuclear norm, and we leverage the theoretical results of Lion-$\mathcal{K}$ to establish that Muon (with decoupled weight decay) implicitly solves an optimization problem that enforces a constraint on the spectral norm of weight matrices. This perspective not only demystifies the implicit regularization effects of Muon but also leads to natural generalizations through varying the choice of convex map $\mathcal{K}$, allowing for the exploration of a broader class of implicitly regularized and constrained optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15054v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lizhang Chen, Jonathan Li, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime</title>
      <link>https://arxiv.org/abs/2506.24120</link>
      <description>arXiv:2506.24120v2 Announce Type: replace-cross 
Abstract: Data selection plays a crucial role in data-driven decision-making, including in large language models (LLMs), and is typically task-dependent. Properties such as data quality and diversity have been extensively studied and are known to enhance model performance. However, it remains unclear whether there exist other quantitative and general principles of data selection that can consistently improve performance, especially for complicated tasks. In this paper, we demonstrate that selecting more uniformly distributed data can improve training efficiency while enhancing performance. Specifically, we establish that more uniform (less biased) distribution leads to a larger minimum pairwise distance between data points, denoted by $h_{\min}$, and prove that a smaller $h_{\min}$ can slow down the training dynamics of gradient descent (GD). Moreover, we theoretically show that the approximation error of neural networks decreases as $h_{\min}$ increases. Our analysis introduces a convergence framework for GD beyond the Neural Tangent Kernel (NTK) regime, applicable to a broad class of architectures, including transformers, without requiring Lipschitz smoothness. This framework further provides theoretical justification for the use of residual connection and function composition in deep neural architectures. In the end, we conduct comprehensive experiments for supervised fine-tuning across various settings, including different optimization strategies, model sizes, and training datasets. The results consistently demonstrate that selecting data by maximizing pairwise distance significantly accelerates training and achieves comparable or better performance in LLMs across diverse datasets. Code and Datasets are available at the link: https://github.com/SafeRL-Lab/data-uniformity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24120v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Wang, Shangding Gu</dc:creator>
    </item>
    <item>
      <title>From group stage to league format: The impact of the draw in European football's Champions League</title>
      <link>https://arxiv.org/abs/2507.15320</link>
      <description>arXiv:2507.15320v3 Announce Type: replace-cross 
Abstract: A fundamental reform has been introduced in the 2024/25 season of club competitions organised by the Union of European Football Associations (UEFA): the well-established group stage has been replaced by an incomplete round-robin format. In this format, the 36 teams are ranked in a single league table, but play against only a subset of the competitors. While this innovative change has highlighted that the incomplete round-robin tournament is a reasonable alternative to the standard design of allocating the teams into round-robin groups, the characteristics of the new format remain unexplored. Our paper contributes to this topic by using simulations to compare the uncertainty generated by the draw in the old format with that in the new format of the UEFA Champions League. We develop a method to break down the impact of the 2024/25 reform into various components for each team. The new format is found to decrease the overall effect of the draw. However, this reduction can mainly be attributed to the inaccurate seeding system used by UEFA. If the teams are seeded based on their actual strengths, the impact of the draw is about the same in a tournament with an incomplete round-robin league or a group stage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15320v3</guid>
      <category>stat.AP</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o, Andr\'as Gyimesi, Dries Goossens, Karel Devriesere, Roel Lambers, Frits Spieksma</dc:creator>
    </item>
    <item>
      <title>Enhancing Stability of Physics-Informed Neural Network Training Through Saddle-Point Reformulation</title>
      <link>https://arxiv.org/abs/2507.16008</link>
      <description>arXiv:2507.16008v2 Announce Type: replace-cross 
Abstract: Physics-informed neural networks (PINNs) have gained prominence in recent years and are now effectively used in a number of applications. However, their performance remains unstable due to the complex landscape of the loss function. To address this issue, we reformulate PINN training as a nonconvex-strongly concave saddle-point problem. After establishing the theoretical foundation for this approach, we conduct an extensive experimental study, evaluating its effectiveness across various tasks and architectures. Our results demonstrate that the proposed method outperforms the current state-of-the-art techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16008v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Bylinkin, Mikhail Aleksandrov, Savelii Chezhegov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level</title>
      <link>https://arxiv.org/abs/2507.23512</link>
      <description>arXiv:2507.23512v2 Announce Type: replace-cross 
Abstract: Gradient clipping is a fundamental tool in Deep Learning, improving the high-probability convergence of stochastic first-order methods like SGD, AdaGrad, and Adam under heavy-tailed noise, which is common in training large language models. It is also a crucial component of Differential Privacy (DP) mechanisms. However, existing high-probability convergence analyses typically require the clipping threshold to increase with the number of optimization steps, which is incompatible with standard DP mechanisms like the Gaussian mechanism. In this work, we close this gap by providing the first high-probability convergence analysis for DP-Clipped-SGD with a fixed clipping level, applicable to both convex and non-convex smooth optimization under heavy-tailed noise, characterized by a bounded central $\alpha$-th moment assumption, $\alpha \in (1,2]$. Our results show that, with a fixed clipping level, the method converges to a neighborhood of the optimal solution with a faster rate than the existing ones. The neighborhood can be balanced against the noise introduced by DP, providing a refined trade-off between convergence speed and privacy guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23512v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saleh Vatan Khah, Savelii Chezhegov, Shahrokh Farahmand, Samuel Horv\'ath, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Flow Matching for Efficient and Scalable Data Assimilation</title>
      <link>https://arxiv.org/abs/2508.13313</link>
      <description>arXiv:2508.13313v3 Announce Type: replace-cross 
Abstract: Data assimilation (DA) estimates a dynamical system's state from noisy observations. Recent generative models like the ensemble score filter (EnSF) improve DA in high-dimensional nonlinear settings but are computationally expensive. We introduce the ensemble flow filter (EnFF), a training-free, flow matching (FM)-based framework that accelerates sampling and offers flexibility in flow design. EnFF uses Monte Carlo estimators for the marginal flow field, localized guidance for observation assimilation, and utilizes a novel flow that exploits the Bayesian DA formulation. It generalizes classical filters such as the bootstrap particle filter and ensemble Kalman filter. Experiments on high-dimensional benchmarks demonstrate EnFF's improved cost-accuracy tradeoffs and scalability, highlighting FM's potential for efficient, scalable DA. Code is available at https://github.com/Utah-Math-Data-Science/Data-Assimilation-Flow-Matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13313v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taos Transue, Bohan Chen, So Takao, Bao Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Savings with Preference for Wealth</title>
      <link>https://arxiv.org/abs/2509.12195</link>
      <description>arXiv:2509.12195v2 Announce Type: replace-cross 
Abstract: The consumption function maps current wealth and the exogenous state to current consumption. We prove the existence and uniqueness of a consumption function when the agent has a preference for wealth. When the period utility functions are restricted to power functions, we prove that the consumption function is asymptotically linear as wealth tends to infinity and provide a complete characterization of the asymptotic slopes. When the risk aversion with respect to wealth is less than that for consumption, the asymptotic slope is zero regardless of other model parameters, implying wealthy households save a large fraction of their income, consistent with empirical evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12195v2</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyin Ma, Alexis Akira Toda</dc:creator>
    </item>
  </channel>
</rss>
