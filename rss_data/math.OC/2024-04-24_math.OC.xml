<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Apr 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 24 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convex Ternary Quartics Are SOS-Convex</title>
      <link>https://arxiv.org/abs/2404.14440</link>
      <description>arXiv:2404.14440v1 Announce Type: new 
Abstract: We prove that convex ternary quartic forms are sum-of-squares-convex (sos-convex). This result is in a meaningful sense the ``convex analogue'' a celebrated theorem of Hilbert from 1888, where he proves that nonnegative ternary quartic forms are sums of squares. We show by an appropriate construction that exploiting the structure of the Hessian matrix is crucial in any possible proof of our result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14440v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Ali Ahmadi, Grigoriy Blekherman, Pablo A. Parrilo</dc:creator>
    </item>
    <item>
      <title>The Duality Theory of Fractional Calculus and a New Fractional Calculus of Variations Involving Left Operators Only</title>
      <link>https://arxiv.org/abs/2404.14458</link>
      <description>arXiv:2404.14458v1 Announce Type: new 
Abstract: Through duality it is possible to transform left fractional operators into right fractional operators and vice versa. In contrast to existing literature, we establish integration by parts formulas that exclusively involve either left or right operators. The emergence of these novel fractional integration by parts formulas inspires the introduction of a new calculus of variations, where only one type of fractional derivative (left or right) is present. This applies to both the problem formulation and the corresponding necessary optimality conditions. As a practical application, we present a new Lagrangian that relies solely on left-hand side fractional derivatives. The fractional variational principle derived from this Lagrangian leads us to the equation of motion for a dissipative/damped system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14458v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>Randomized Nystr\"om Preconditioned Interior Point-Proximal Method of Multipliers</title>
      <link>https://arxiv.org/abs/2404.14524</link>
      <description>arXiv:2404.14524v1 Announce Type: new 
Abstract: We present a new algorithm for convex separable quadratic programming (QP) called Nys-IP-PMM, a regularized interior-point solver that uses low-rank structure to accelerate solution of the Newton system. The algorithm combines the interior point proximal method of multipliers (IP-PMM) with the randomized Nystr\"om preconditioned conjugate gradient method as the inner linear system solver. Our algorithm is matrix-free: it accesses the input matrices solely through matrix-vector products, as opposed to methods involving matrix factorization. It works particularly well for separable QP instances with dense constraint matrices. We establish convergence of Nys-IP-PMM. Numerical experiments demonstrate its superior performance in terms of wallclock time compared to previous matrix-free IPM-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14524v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ya-Chi Chu, Luiz-Rafael Santos, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Constrained multi-cluster game: Distributed Nash equilibrium seeking over directed graphs</title>
      <link>https://arxiv.org/abs/2404.14554</link>
      <description>arXiv:2404.14554v1 Announce Type: new 
Abstract: Motivated by the complex dynamics of cooperative and competitive interactions within networked agent systems, multi-cluster games provide a framework for modeling the interconnected goals of self-interested clusters of agents. For this setup, the existing literature lacks comprehensive gradient-based solutions that simultaneously consider constraint sets and directed communication networks, both of which are crucial for many practical applications. To address this gap, this paper proposes a distributed Nash equilibrium seeking algorithm that integrates consensus-based methods and gradient-tracking techniques, where inter-cluster and intra-cluster communications only use row- and column-stochastic weight matrices, respectively. To handle constraints, we introduce an averaging procedure, which can effectively address the complications associated with projections. In turn, we can show linear convergence of our algorithm, focusing on the contraction property of the optimality gap. We demonstrate the efficacy of the proposed algorithm through a microgrid energy management application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14554v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Duong Thuy Anh Nguyen, Mattia Bianchi, Florian D\"orfler, Duong Tung Nguyen, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>Geometric Optimization of Restricted-Open and Complete Active Space Self-Consistent Field Wavefunctions</title>
      <link>https://arxiv.org/abs/2404.14655</link>
      <description>arXiv:2404.14655v1 Announce Type: new 
Abstract: We explore Riemannian optimization methods for Restricted-Open-shell Hartree-Fock (ROHF) and Complete Active Space Self-Consistent Field (CASSCF) methods. After showing that ROHF and CASSCF can be reformulated as optimization problems on so-called flag manifolds, we review Riemannian optimization basics and their application to these specific problems. We compare these methods to traditional ones and find robust convergence properties without fine-tuning of numerical parameters. Our study suggests Riemannian optimization as a valuable addition to orbital optimization for ROHF and CASSCF, warranting further investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14655v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Vidal, Tommaso Nottoli, Filippo Lipparini, Eric Canc\`es</dc:creator>
    </item>
    <item>
      <title>Some Remarks on Controllability of the Liouville Equation</title>
      <link>https://arxiv.org/abs/2404.14683</link>
      <description>arXiv:2404.14683v1 Announce Type: new 
Abstract: We revisit the work of Roger Brockett on controllability of the Liouville equation, with a particular focus on the following problem: Given a smooth controlled dynamical system of the form $\dot{x} = f(x,u)$ and a state-space diffeomorphism $\psi$, design a feedback control $u(t,x)$ to steer an arbitrary initial state $x_0$ to $\psi(x_0)$ in finite time. This formulation of the problem makes contact with the theory of optimal transportation and with nonlinear controllability. For controllable linear systems, Brockett showed that this is possible under a fairly restrictive condition on $\psi$. We prove that controllability suffices for a much larger class of diffeomorphisms. For nonlinear systems defined on smooth manifolds, we review a recent result of Agrachev and Caponigro regarding controllability on the group of diffeomorphisms. A corollary of this result states that, for control-affine systems satisfying a bracket generating condition, any $\psi$ in a neighborhood of the identity can be implemented using a time-varying feedback control law that switches between finitely many time-invariant flows. We prove a quantitative version which allows us to describe the implementation complexity of the Agrachev-Caponigro construction in terms of a lower bound on the number of switchings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14683v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxim Raginsky</dc:creator>
    </item>
    <item>
      <title>Second-order Information Promotes Mini-Batch Robustness in Variance-Reduced Gradients</title>
      <link>https://arxiv.org/abs/2404.14758</link>
      <description>arXiv:2404.14758v1 Announce Type: new 
Abstract: We show that, for finite-sum minimization problems, incorporating partial second-order information of the objective function can dramatically improve the robustness to mini-batch size of variance-reduced stochastic gradient methods, making them more scalable while retaining their benefits over traditional Newton-type approaches. We demonstrate this phenomenon on a prototypical stochastic second-order algorithm, called Mini-Batch Stochastic Variance-Reduced Newton ($\texttt{Mb-SVRN}$), which combines variance-reduced gradient estimates with access to an approximate Hessian oracle. In particular, we show that when the data size $n$ is sufficiently large, i.e., $n\gg \alpha^2\kappa$, where $\kappa$ is the condition number and $\alpha$ is the Hessian approximation factor, then $\texttt{Mb-SVRN}$ achieves a fast linear convergence rate that is independent of the gradient mini-batch size $b$, as long $b$ is in the range between $1$ and $b_{\max}=O(n/(\alpha \log n))$. Only after increasing the mini-batch size past this critical point $b_{\max}$, the method begins to transition into a standard Newton-type algorithm which is much more sensitive to the Hessian approximation quality. We demonstrate this phenomenon empirically on benchmark optimization tasks showing that, after tuning the step size, the convergence rate of $\texttt{Mb-SVRN}$ remains fast for a wide range of mini-batch sizes, and the dependence of the phase transition point $b_{\max}$ on the Hessian approximation factor $\alpha$ aligns with our theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14758v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sachin Garg, Albert S. Berahas, Micha{\l} Derezi\'nski</dc:creator>
    </item>
    <item>
      <title>New Douglas-Rashford Splitting Algorithms for Generalized DC Programming with Applications in Machine Learning</title>
      <link>https://arxiv.org/abs/2404.14800</link>
      <description>arXiv:2404.14800v1 Announce Type: new 
Abstract: In this work, we propose some new Douglas-Rashford splitting algorithms for solving a class of generalized DC (difference of convex functions) in real Hilbert spaces. The proposed methods leverage the proximal properties of the nonsmooth component and a fasten control parameter which improves the convergence rate of the algorithms. We prove the convergence of these methods to the critical points of nonconvex optimization under reasonable conditions. We evaluate the performance and effectiveness of our methods through experimentation with three practical examples in machine learning. Our findings demonstrated that our methods offer efficiency in problem-solving and outperform state-of-the-art techniques like the DCA (DC Algorithm) and ADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14800v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonghong Yao, Lateef O. Jolaoso, Yekini Shehu, Jen-Chih Yao</dc:creator>
    </item>
    <item>
      <title>Variational Dynamic Programming for Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2404.14806</link>
      <description>arXiv:2404.14806v1 Announce Type: new 
Abstract: We consider the problem of stochastic optimal control where the state-feedback control policies take the form of a probability distribution, and where a penalty on the entropy is added. By viewing the cost function as a Kullback-Leibler (KL) divergence between two Markov chains, we bring the tools from variational inference to bear on our optimal control problem. This allows for deriving a dynamic programming principle, where the value function is defined as a KL divergence again. We then resort to Gaussian distributions to approximate the control policies, and apply the theory to control affine nonlinear systems with quadratic costs. This results in closed-form recursive updates, which generalize LQR control and the backward Riccati equation. We illustrate this novel method on the simple problem of stabilizing an inverted pendulum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14806v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Lambert (SIERRA), Silv\`ere Bonnabel (CAOR), Francis Bach (SIERRA)</dc:creator>
    </item>
    <item>
      <title>Variants of the slacks-based measure with assurance region and zeros in input-output data</title>
      <link>https://arxiv.org/abs/2404.14820</link>
      <description>arXiv:2404.14820v1 Announce Type: new 
Abstract: Incorporating an assurance region (AR) into the slacks-based measure (SBM) improves practicality; however, its efficiency measure may not have desirable properties, such as monotonicity. We incorporate a closer target setting approach into the SBM with AR and a variant of the SBM with AR. We demonstrate that the efficiency measure with the hybrid approach has the same desirable properties as that without AR, and we also show that the efficiency scores can be computed by solving linear programming problems. Our proposed approach can handle zeros in the observed input-output data without any data transformation or additional model modification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14820v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atsushi Hori, Kazuyuki Sekitani</dc:creator>
    </item>
    <item>
      <title>Closed-Loop Identification and Tracking Control of a Ballbot</title>
      <link>https://arxiv.org/abs/2404.14845</link>
      <description>arXiv:2404.14845v1 Announce Type: new 
Abstract: Identifying and controlling an unstable, underactuated robot to enable reference tracking is a challenging control problem. In this paper, a ballbot (robot balancing on a ball) is used as an experimental setup to demonstrate and test proposed strategies to tackle this control problem. A double-loop control system, including a state-feedback gain in the outer-loop and a Proportional-Integral-Derivative (PID) controller in the inner-loop, is presented to balance the system in its unstable equilibrium. Once stability is reached, the plant's response to a designed excitation signal is measured and interpreted to identify the system's dynamics. Hereby, the parameters of a linearized model of the ballbot are identified with prior knowledge about the structure of the nonlinear dynamics of the system. Based on an identified linear time-invariant (LTI) state-space model, a double-loop control strategy is considered to balance the real system and to allow reference tracking. A linear quadratic regulator (LQR) is designed offline and implemented in the inner-loop to ensure balance. In the outer-loop, the estimated dynamics forecast the system's behavior online using a model-predictive-control (MPC) design to find the optimal control input for reference tracking. The experimental results demonstrate the applicability of the proposed strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14845v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Fischer, Dimitrios S. Karachalios, Ievgen Zhavzharov, Hossam S. Abbas</dc:creator>
    </item>
    <item>
      <title>Fast convergence rates and trajectory convergence of a Tikhonov regularized inertial primal\mbox{-}dual dynamical system with time scaling and vanishing damping</title>
      <link>https://arxiv.org/abs/2404.14853</link>
      <description>arXiv:2404.14853v1 Announce Type: new 
Abstract: A Tikhonov regularized inertial primal\mbox{-}dual dynamical system with time scaling and vanishing damping is proposed for solving a linearly constrained convex optimization problem in Hilbert spaces. The system under consideration consists of two coupled second order differential equations and its convergence properties depend upon the decaying speed of the product of the time scaling parameter and the Tikhonov regularization parameter (named the rescaled regularization parameter) to zero. When the rescaled regularization parameter converges rapidly to zero, the system enjoys fast convergence rates of the primal-dual gap, the feasibility violation, the objective residual, and the gradient norm of the objective function along the trajectory, and the weak convergence of the trajectory to a primal-dual solution of the linearly constrained convex optimization problem. When the rescaled regularization parameter converges slowly to zero, the generated primal trajectory converges strongly to the minimal norm solution of the problem under suitable conditions. Finally, numerical experiments are performed to illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14853v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting-Ting Zhu, Rong Hu, Ya-Ping Fang</dc:creator>
    </item>
    <item>
      <title>Global Complexity Analysis of BFGS</title>
      <link>https://arxiv.org/abs/2404.15051</link>
      <description>arXiv:2404.15051v1 Announce Type: new 
Abstract: In this paper, we present a global complexity analysis of the classical BFGS method with inexact line search, as applied to minimizing a strongly convex function with Lipschitz continuous gradient and Hessian. We consider a variety of standard line search strategies including the backtracking line search based on the Armijo condition, Armijo-Goldstein and Wolfe-Powell line searches. Our analysis suggests that the convergence of the algorithm proceeds in several different stages before the fast superlinear convergence actually begins. Furthermore, once the initial point is far away from the minimizer, the starting moment of superlinear convergence may be quite large. We show, however, that this drawback can be easily rectified by using a simple restarting procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15051v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Rodomanov</dc:creator>
    </item>
    <item>
      <title>Cooperation, Correlation and Competition in Ergodic $N$-player Games and Mean-field Games of Singular Controls: A Case Study</title>
      <link>https://arxiv.org/abs/2404.15079</link>
      <description>arXiv:2404.15079v1 Announce Type: new 
Abstract: We consider ergodic symmetric $N$-player and mean-field games of singular control in both cooperative and competitive settings. The state process dynamics of a representative player follow geometric Brownian motion, controlled additively through a nondecreasing process. Agents aim to maximize a long-time average reward functional with instantaneous profit of power type. The game shows strategic complementarities, in that the marginal profit function is increasing with respect to the dynamic average of the states of the other players, when $N&lt;\infty$, or with respect to the stationary mean of the players' distribution, in the mean-field case. In the mean-field formulation, we explicitly construct the solution to the mean-field control problem associated with central planner optimization, as well as Nash and coarse correlated equilibria (with singular and regular recommendations). Among our findings, we show that coarse correlated equilibria may exist even when Nash equilibria do not. Additionally, we show that a coarse correlated equilibrium with a regular (absolutely continuous) recommendation can outperform a Nash equilibrium where the equilibrium policy is of reflecting type (thus singularly continuous). Furthermore, we prove that the constructed mean-field control and mean-field equilibria can approximate the cooperative and competitive equilibria, respectively, in the corresponding game with $N$ players when $N$ is sufficiently large. To the best of our knowledge, this paper is the first to characterize coarse correlated equilibria, construct the explicit solution to an ergodic mean-field control problem, and provide approximation results for the related $N$-player game in the context of singular control games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15079v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Cannerozzi, Giorgio Ferrari</dc:creator>
    </item>
    <item>
      <title>All You Need is Resistance: On the Equivalence of Effective Resistance and Certain Optimal Transport Problems on Graphs</title>
      <link>https://arxiv.org/abs/2404.15261</link>
      <description>arXiv:2404.15261v1 Announce Type: new 
Abstract: The fields of effective resistance and optimal transport on graphs are filled with rich connections to combinatorics, geometry, machine learning, and beyond. In this article we put forth a bold claim: that the two fields should be understood as one and the same, up to a choice of $p$. We make this claim precise by introducing the parameterized family of $p$-Beckmann distances for probability measures on graphs and relate them sharply to certain Wasserstein distances. Then, we break open a suite of results including explicit connections to optimal stopping times and random walks on graphs, graph Sobolev spaces, and a Benamou-Brenier type formula for $2$-Beckmann distance. We further explore empirical implications in the world of unsupervised learning for graph data and propose further study of the usage of these metrics where Wasserstein distance may produce computational bottlenecks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15261v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sawyer Robertson, Zhengchao Wan, Alexander Cloninger</dc:creator>
    </item>
    <item>
      <title>Estimation Network Design framework for efficient distributed optimization</title>
      <link>https://arxiv.org/abs/2404.15273</link>
      <description>arXiv:2404.15273v1 Announce Type: new 
Abstract: Distributed decision problems features a group of agents that can only communicate over a peer-to-peer network, without a central memory. In applications such as network control and data ranking, each agent is only affected by a small portion of the decision vector: this sparsity is typically ignored in distributed algorithms, while it could be leveraged to improve efficiency and scalability. To address this issue, our recent paper introduces Estimation Network Design (END), a graph theoretical language for the analysis and design of distributed iterations. END algorithms can be tuned to exploit the sparsity of specific problem instances, reducing communication overhead and minimizing redundancy, yet without requiring case-by-case convergence analysis. In this paper, we showcase the flexility of END in the context of distributed optimization. In particular, we study the sparsity-aware version of many established methods, including ADMM, AugDGM and Push-Sum DGD. Simulations on an estimation problem in sensor networks demonstrate that END algorithms can boost convergence speed and greatly reduce the communication and memory cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15273v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mattia Bianchi, Sergio Grammatico</dc:creator>
    </item>
    <item>
      <title>Regularized Gauss-Newton for Optimizing Overparameterized Neural Networks</title>
      <link>https://arxiv.org/abs/2404.14875</link>
      <description>arXiv:2404.14875v1 Announce Type: cross 
Abstract: The generalized Gauss-Newton (GGN) optimization method incorporates curvature estimates into its solution steps, and provides a good approximation to the Newton method for large-scale optimization problems. GGN has been found particularly interesting for practical training of deep neural networks, not only for its impressive convergence speed, but also for its close relation with neural tangent kernel regression, which is central to recent studies that aim to understand the optimization and generalization properties of neural networks. This work studies a GGN method for optimizing a two-layer neural network with explicit regularization. In particular, we consider a class of generalized self-concordant (GSC) functions that provide smooth approximations to commonly-used penalty terms in the objective function of the optimization problem. This approach provides an adaptive learning rate selection technique that requires little to no tuning for optimal performance. We study the convergence of the two-layer neural network, considered to be overparameterized, in the optimization loop of the resulting GGN method for a given scaling of the network parameters. Our numerical experiments highlight specific aspects of GSC regularization that help to improve generalization of the optimized neural network. The code to reproduce the experimental results is available at https://github.com/adeyemiadeoye/ggn-score-nn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14875v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adeyemi D. Adeoye, Philipp Christian Petersen, Alberto Bemporad</dc:creator>
    </item>
    <item>
      <title>Dynamic Population Games: A Tractable Intersection of Mean-Field Games and Population Games</title>
      <link>https://arxiv.org/abs/2104.14662</link>
      <description>arXiv:2104.14662v2 Announce Type: replace 
Abstract: In many real-world large-scale decision problems, self-interested agents have individual dynamics and optimize their own long-term payoffs. Important examples include the competitive access to shared resources (e.g., roads, energy, or bandwidth) but also non-engineering domains like epidemic propagation and control. These problems are natural to model as mean-field games. However, existing mathematical formulations of mean field games have had limited applicability in practice, since they require solving non-standard initial-terminal-value problems that are tractable only in limited special cases. In this letter, we propose a novel formulation, along with computational tools, for a practically relevant class of Dynamic Population Games (DPGs), which correspond to discrete-time, finite-state-and-action, stationary mean-field games. Our main contribution is a mathematical reduction of Stationary Nash Equilibria (SNE) in DPGs to standard Nash Equilibria (NE) in static population games. This reduction is leveraged to guarantee the existence of a SNE, develop an evolutionary dynamics-based SNE computation algorithm, and derive simple conditions that guarantee stability and uniqueness of the SNE. Additionally, DPGs enable us to tractably incorporate multiple agent types, which is of particular importance to assess fairness concerns in resource allocation problems. We demonstrate our results by computing the SNE in two complex application examples: fair resource allocation with heterogeneous agents and control of epidemic propagation.
  Open source software for SNE computation: https://gitlab.ethz.ch/elokdae/dynamic-population-games</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.14662v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ezzat Elokda, Saverio Bolognani, Andrea Censi, Florian D\"orfler, Emilio Frazzoli</dc:creator>
    </item>
    <item>
      <title>Risk-Averse Markov Decision Processes through a Distributional Lens</title>
      <link>https://arxiv.org/abs/2203.09612</link>
      <description>arXiv:2203.09612v4 Announce Type: replace 
Abstract: By adopting a distributional viewpoint on law-invariant convex risk measures, we construct dynamics risk measures (DRMs) at the distributional level. We then apply these DRMs to investigate Markov decision processes, incorporating latent costs, random actions, and weakly continuous transition kernels. Furthermore, the proposed DRMs allow risk aversion to change dynamically. Under mild assumptions, we derive a dynamic programming principle and show the existence of an optimal policy in both finite and infinite time horizons. Moreover, we provide a sufficient condition for the optimality of deterministic actions. For illustration, we conclude the paper with examples from optimal liquidation with limit order books and autonomous driving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.09612v4</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziteng Cheng, Sebastian Jaimungal</dc:creator>
    </item>
    <item>
      <title>A fast continuous time approach for non-smooth convex optimization with time scaling and Tikhonov regularization</title>
      <link>https://arxiv.org/abs/2207.12023</link>
      <description>arXiv:2207.12023v3 Announce Type: replace 
Abstract: In a Hilbert setting we aim to study a second order in time differential equation, combining viscous and Hessian-driven damping, containing a time scaling parameter function and a Tikhonov regularization term. The dynamical system is related to the problem of minimization of a nonsmooth convex function. In the formulation of the problem as well as in our analysis we use the Moreau envelope of the objective function and its gradient and heavily rely on their properties. We show that there is a setting where the newly introduced system preserves and even improves the well-known fast convergence properties of the function and Moreau envelope along the trajectories and also of the gradient of Moreau envelope due to the presence of time scaling. Moreover, in a different setting we prove strong convergence of the trajectories to the element of the minimal norm from the set of all minimizers of the objective. The manuscript concludes with various numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.12023v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Ern\"o Csetnek, Mikhail A. Karapetyants</dc:creator>
    </item>
    <item>
      <title>Explicit Second-Order Min-Max Optimization Methods with Optimal Convergence Guarantee</title>
      <link>https://arxiv.org/abs/2210.12860</link>
      <description>arXiv:2210.12860v4 Announce Type: replace 
Abstract: We propose and analyze several inexact regularized Newton-type methods for finding a global saddle point of \emph{convex-concave} unconstrained min-max optimization problems. Compared to first-order methods, our understanding of second-order methods for min-max optimization is relatively limited, as obtaining global rates of convergence with second-order information is much more involved. In this paper, we examine how second-order information can be used to speed up extra-gradient methods, even under inexactness. Specifically, we show that the proposed methods generate iterates that remain within a bounded set and that the averaged iterates converge to an $\epsilon$-saddle point within $O(\epsilon^{-2/3})$ iterations in terms of a restricted gap function. This matched the theoretically established lower bound in this context. We also provide a simple routine for solving the subproblem at each iteration, requiring a single Schur decomposition and $O(\log\log(1/\epsilon))$ calls to a linear system solver in a quasi-upper-triangular system. Thus, our method improves the existing line-search-based second-order min-max optimization methods by shaving off an $O(\log\log(1/\epsilon))$ factor in the required number of Schur decompositions. Finally, we present numerical experiments on synthetic and real data that demonstrate the efficiency of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12860v4</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyi Lin, Panayotis Mertikopoulos, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Calculus rules for proximal {\epsilon}-subdifferentials and inexact proximity operators for weakly convex functions</title>
      <link>https://arxiv.org/abs/2211.14525</link>
      <description>arXiv:2211.14525v2 Announce Type: replace 
Abstract: We investigate inexact proximity operators for weakly convex functions. To this aim, we derive sum rules for proximal {\epsilon}-subdifferentials, by incorporating the moduli of weak convexity of the functions into the respective formulas. This allows us to investigate inexact proximity operators for weakly convex functions in terms of proximal {\epsilon}-subdifferentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.14525v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ewa Bednarczuk, Giovanni Bruccola, Gabriele Scrivanti, The Hung Tran</dc:creator>
    </item>
    <item>
      <title>Inverse demand tracking in transportation networks</title>
      <link>https://arxiv.org/abs/2212.11560</link>
      <description>arXiv:2212.11560v3 Announce Type: replace 
Abstract: This paper deals with the reconstruction of the desired demand in an optimal control problem, stated over a tree-shaped transportation network which is governed by a linear hyperbolic conservation law. As desired demands typically undergo fluctuations due to seasonality or unexpected events making short-term adjustments necessary, such an approach can exemplary be used for forecasting from past data. We suggest to model this problem as a so-called inverse optimal control problem, i.e., a hierarchical optimization problem whose inner problem is the optimal control problem and whose outer problem is the reconstruction problem. In order to guarantee the existence of solutions in the function space framework, the hyperbolic conservation law is interpreted in weak sense allowing for control functions in Lebesgue spaces. For the computational treatment of the model, we transfer the hierarchical problem into a nonsmooth single-level one by plugging the uniquely determined solution of the inner optimal control problem into the outer reconstruction problem before applying techniques from nonsmooth optimization. Some numerical experiments are presented to visualize various features of the model including different types of noise in the demand and strategies of how to observe the network in order to obtain good reconstructions of the desired demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11560v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Patrick Mehlitz, Thomas Schillinger</dc:creator>
    </item>
    <item>
      <title>A Machine Learning Method for Stackelberg Mean Field Games</title>
      <link>https://arxiv.org/abs/2302.10440</link>
      <description>arXiv:2302.10440v2 Announce Type: replace 
Abstract: We propose a single-level numerical approach to solve Stackelberg mean field game (MFG) problems. In Stackelberg MFG, an infinite population of agents play a non-cooperative game and choose their controls to optimize their individual objectives while interacting with the principal and other agents through the population distribution. The principal can influence the mean field Nash equilibrium at the population level through policies, and she optimizes her own objective, which depends on the population distribution. This leads to a bi-level problem between the principal and mean field of agents that cannot be solved using traditional methods for MFGs. We propose a reformulation of this problem as a single-level mean field optimal control problem through a penalization approach. We prove convergence of the reformulated problem to the original problem. We propose a machine learning method based on (feed-forward and recurrent) neural networks and illustrate it on several examples from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.10440v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gokce Dayanikli, Mathieu Lauriere</dc:creator>
    </item>
    <item>
      <title>On Dynamic Programming Decompositions of Static Risk Measures in Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2304.12477</link>
      <description>arXiv:2304.12477v4 Announce Type: replace 
Abstract: Optimizing static risk-averse objectives in Markov decision processes is difficult because they do not admit standard dynamic programming equations common in Reinforcement Learning (RL) algorithms. Dynamic programming decompositions that augment the state space with discrete risk levels have recently gained popularity in the RL community. Prior work has shown that these decompositions are optimal when the risk level is discretized sufficiently. However, we show that these popular decompositions for Conditional-Value-at-Risk (CVaR) and Entropic-Value-at-Risk (EVaR) are inherently suboptimal regardless of the discretization level. In particular, we show that a saddle point property assumed to hold in prior literature may be violated. However, a decomposition does hold for Value-at-Risk and our proof demonstrates how this risk measure differs from CVaR and EVaR. Our findings are significant because risk-averse algorithms are used in high-stake environments, making their correctness much more critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12477v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems (Neurips), 2023</arxiv:journal_reference>
      <dc:creator>Jia Lin Hau, Erick Delage, Mohammad Ghavamzadeh, Marek Petrik</dc:creator>
    </item>
    <item>
      <title>Convex quartic problems: homogenized gradient method and preconditioning</title>
      <link>https://arxiv.org/abs/2306.17683</link>
      <description>arXiv:2306.17683v2 Announce Type: replace 
Abstract: We consider a convex minimization problem for which the objective is the sum of a homogeneous polynomial of degree four and a linear term. Such task arises as a subproblem in algorithms for quadratic inverse problems with a difference-of-convex structure. We design a first-order method called Homogenized Gradient, along with an accelerated version, which enjoy fast convergence rates of respectively $\mathcal{O}(\kappa^2/K^2)$ and $\mathcal{O}(\kappa^2/K^4)$ in relative accuracy, where $K$ is the iteration counter. The constant $\kappa$ is the quartic condition number of the problem.
  Then, we show that for a certain class of problems, it is possible to compute a preconditioner for which this condition number is $\sqrt{n}$, where $n$ is the problem dimension. To establish this, we study the more general problem of finding the best quadratic approximation of an $\ell_p$ norm composed with a quadratic map. Our construction involves a generalization of the so-called Lewis weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17683v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Radu-Alexandru Dragomir, Yurii Nesterov</dc:creator>
    </item>
    <item>
      <title>Adaptive Online Non-stochastic Control</title>
      <link>https://arxiv.org/abs/2310.02261</link>
      <description>arXiv:2310.02261v3 Announce Type: replace 
Abstract: We tackle the problem of Non-stochastic Control (NSC) with the aim of obtaining algorithms whose policy regret is proportional to the difficulty of the controlled environment. Namely, we tailor the Follow The Regularized Leader (FTRL) framework to dynamical systems by using regularizers that are proportional to the actual witnessed costs. The main challenge arises from using the proposed adaptive regularizers in the presence of a state, or equivalently, a memory, which couples the effect of the online decisions and requires new tools for bounding the regret. Via new analysis techniques for NSC and FTRL integration, we obtain novel disturbance action controllers (DAC) with sub-linear data adaptive policy regret bounds that shrink when the trajectory of costs has small gradients, while staying sub-linear even in the worst case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02261v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naram Mhaisen, George Iosifidis</dc:creator>
    </item>
    <item>
      <title>Approximating the set of Nash equilibria for convex games</title>
      <link>https://arxiv.org/abs/2310.04176</link>
      <description>arXiv:2310.04176v4 Announce Type: replace 
Abstract: In Feinstein and Rudloff (2023), it was shown that the set of Nash equilibria for any non-cooperative $N$ player game coincides with the set of Pareto optimal points of a certain vector optimization problem with non-convex ordering cone. To avoid dealing with a non-convex ordering cone, an equivalent characterization of the set of Nash equilibria as the intersection of the Pareto optimal points of $N$ multi-objective problems (i.e.\ with the natural ordering cone) is proven. So far, algorithms to compute the exact set of Pareto optimal points of a multi-objective problem exist only for the class of linear problems, which reduces the possibility of finding the true set of Nash equilibria by those algorithms to linear games only.
  In this paper, we will consider the larger class of convex games. As, typically, only approximate solutions can be computed for convex vector optimization problems, we first show, in total analogy to the result above, that the set of $\epsilon$-approximate Nash equilibria can be characterized by the intersection of $\epsilon$-approximate Pareto optimal points for $N$ convex multi-objective problems. Then, we propose an algorithm based on results from vector optimization and convex projections that allows for the computation of a set that, on one hand, contains the set of all true Nash equilibria, and is, on the other hand, contained in the set of $\epsilon$-approximate Nash equilibria. In addition to the joint convexity of the cost function for each player, this algorithm works provided the players are restricted by either shared polyhedral constraints or independent convex constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04176v4</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Feinstein, Niklas Hey, Birgit Rudloff</dc:creator>
    </item>
    <item>
      <title>Risk-Adaptive Local Decision Rules</title>
      <link>https://arxiv.org/abs/2310.09844</link>
      <description>arXiv:2310.09844v2 Announce Type: replace 
Abstract: For parameterized mixed-binary optimization problems, we construct local decision rules that prescribe near-optimal courses of action across a set of parameter values. The decision rules stem from solving risk-adaptive training problems over classes of continuous, possibly nonlinear mappings. In asymptotic and nonasymptotic analysis, we establish that the decision rules prescribe near-optimal decisions locally for the actual problems, without relying on linearity, convexity, or smoothness. The development also accounts for practically important aspects such as inexact function evaluations, solution tolerances in training problems, regularization, and reformulations to solver-friendly models. The decision rules also furnish a means to carry out sensitivity and stability analysis for broad classes of parameterized optimization problems. We develop a decomposition algorithm for solving the resulting training problems and demonstrate its ability to generate quality decision rules on a nonlinear binary optimization model from search theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09844v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes O. Royset, Miguel A. Lejeune</dc:creator>
    </item>
    <item>
      <title>Conditions when the problems of linear programming are algorithmically unsolvable</title>
      <link>https://arxiv.org/abs/2311.06687</link>
      <description>arXiv:2311.06687v2 Announce Type: replace 
Abstract: We study the properties of the constructive linear programing problems. The parameters of linear functions in such problems are constructive real numbers. To solve such a problem is to find the optimal plan with the constructive real number components. We show that it is impossible to have an algorithm that solves an arbitrary constructive real programming problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06687v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Chernov, Vladimir Chernov</dc:creator>
    </item>
    <item>
      <title>A Single-Loop Algorithm for Decentralized Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2311.08945</link>
      <description>arXiv:2311.08945v3 Announce Type: replace 
Abstract: Bilevel optimization has gained significant attention in recent years due to its broad applications in machine learning. This paper focuses on bilevel optimization in decentralized networks and proposes a novel single-loop algorithm for solving decentralized bilevel optimization with a strongly convex lower-level problem. Our approach is a fully single-loop method that approximates the hypergradient using only two matrix-vector multiplications per iteration. Importantly, our algorithm does not require any gradient heterogeneity assumption, distinguishing it from existing methods for decentralized bilevel optimization and federated bilevel optimization. Our analysis demonstrates that the proposed algorithm achieves the best-known convergence rate for bilevel optimization algorithms. We also present experimental results on hyperparameter optimization problems using both synthetic and MNIST datasets, which demonstrate the efficiency of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08945v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youran Dong, Shiqian Ma, Junfeng Yang, Chao Yin</dc:creator>
    </item>
    <item>
      <title>Direct approach of linear-quadratic Stackelberg mean field games of backward-forward stochastic systems</title>
      <link>https://arxiv.org/abs/2401.15835</link>
      <description>arXiv:2401.15835v2 Announce Type: replace 
Abstract: This paper is concerned with a linear-quadratic (LQ) Stackelberg mean field games of backward-forward stochastic systems, involving a backward leader and a substantial number of forward followers. The leader initiates by providing its strategy, and subsequently, each follower optimizes its individual cost. A direct approach is applied to solve this game. Initially, we address a mean field game problem, determining the optimal response of followers to the leader's strategy. Following the implementation of followers' strategies, the leader faces an optimal control problem driven by high-dimensional forward-backward stochastic differential equations (FBSDEs). Through the decoupling of the high-dimensional Hamiltonian system using mean field approximations, we formulate a set of decentralized strategies for all players, demonstrated to be an $(\epsilon_1, \epsilon_2)$-Stackelberg equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15835v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wenyu Cong, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Two-sided Assortment Optimization: Adaptivity Gaps and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2403.08929</link>
      <description>arXiv:2403.08929v3 Announce Type: replace 
Abstract: To address the challenge of choice congestion in matching markets, in this work, we introduce a two-sided assortment optimization framework under general choice preferences. The goal in this problem is to maximize the expected number of matches by deciding which assortments are displayed to the agents and the order in which they are shown. In this context, we identify several classes of policies that platforms can use in their design. Our goals are: (1) to measure the value that one class of policies has over another one, and (2) to approximately solve the optimization problem itself for a given class. For (1), we define the adaptivity gap as the worst-case ratio between the optimal values of two different policy classes. First, we show that the gap between the class of policies that statically show assortments to one-side first and the class of policies that adaptively show assortments to one-side first is exactly $1-1/e$. Second, we show that the gap between the latter class of policies and the fully adaptive class of policies that show assortments to agents one by one is exactly $1/2$. We also note that the worst policies are those who simultaneously show assortments to all the agents, in fact, we show that their adaptivity gap even with respect to one-sided static policies can be arbitrarily small. For (2), we first show that there exists a polynomial time policy that achieves a $1/4$ approximation factor within the class of policies that adaptively show assortments to agents one by one. Finally, when agents' preferences are governed by multinomial-logit models, we show that a 0.082 approximation factor can be obtained within the class of policies that show assortments to all agents at once.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08929v3</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar El Housni, Alfredo Torrico, Ulysse Hennebelle</dc:creator>
    </item>
    <item>
      <title>Mathematical Program Networks</title>
      <link>https://arxiv.org/abs/2404.03767</link>
      <description>arXiv:2404.03767v2 Announce Type: replace 
Abstract: Mathematical Program Networks (MPNs) are introduced in this work. An MPN is a collection of interdependent Mathematical Programs (MPs) which are to be solved simultaneously, while respecting the connectivity pattern of the network defining their relationships. The network structure of an MPN impacts which decision variables each constituent mathematical program can influence, either directly or indirectly via solution graph constraints representing optimal decisions for their decedents. Many existing problem formulations can be formulated as MPNs, including Nash Equilibrium problems, multilevel optimization problems, and Equilibrium Programs with Equilibrium Constraints (EPECs), among others. The equilibrium points of an MPN correspond with the equilibrium points or solutions of these other problems. By thinking of a collection of decision problems as an MPN, a common definition of equilibrium can be used regardless of relationship between problems, and the same algorithms can be used to compute solutions. The presented framework facilitates modeling flexibility and analysis of various equilibrium points in problems involving multiple mathematical programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03767v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Forrest Laine</dc:creator>
    </item>
    <item>
      <title>Optimality of Decentralized Symmetric Policies for Stochastic Teams with Mean-Field Information Sharing</title>
      <link>https://arxiv.org/abs/2404.04957</link>
      <description>arXiv:2404.04957v2 Announce Type: replace 
Abstract: We study a class of stochastic exchangeable teams comprising a finite number of decision makers (DMs) as well as their mean-field limits involving infinite numbers of DMs. In the finite population regime, we study exchangeable teams under the centralized information structure. For the infinite population setting, we study exchangeable teams under the decentralized mean-field information sharing. The paper makes the following main contributions: i) For finite population exchangeable teams, we establish the existence of a randomized optimal policy that is exchangeable (permutation invariant) and Markovian; ii) As our main result in the paper, we show that a sequence of exchangeable optimal policies for finite population settings converges to a conditionally symmetric (identical), independent, and decentralized randomized policy for the infinite population problem, which is globally optimal for the infinite population problem. This result establishes the existence of a symmetric, independent, decentralized optimal randomized policy for the infinite population problem. Additionally, this proves the optimality of the limiting measure-valued MDP for the representative DM; iii) Finally, we show that symmetric, independent, decentralized optimal randomized policies are approximately optimal for the corresponding finite-population team with a large number of DMs under the centralized information structure. Our paper thus establishes the relation between the controlled McKean-Vlasov dynamics and the optimal infinite population decentralized stochastic control problem (without an apriori restriction of symmetry in policies of individual agents), for the first time, to our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04957v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Sanjari, Naci Saldi, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>Linear Optimal Partial Transport Embedding</title>
      <link>https://arxiv.org/abs/2302.03232</link>
      <description>arXiv:2302.03232v5 Announce Type: replace-cross 
Abstract: Optimal transport (OT) has gained popularity due to its various applications in fields such as machine learning, statistics, and signal processing. However, the balanced mass requirement limits its performance in practical problems. To address these limitations, variants of the OT problem, including unbalanced OT, Optimal partial transport (OPT), and Hellinger Kantorovich (HK), have been proposed. In this paper, we propose the Linear optimal partial transport (LOPT) embedding, which extends the (local) linearization technique on OT and HK to the OPT problem. The proposed embedding allows for faster computation of OPT distance between pairs of positive measures. Besides our theoretical contributions, we demonstrate the LOPT embedding technique in point-cloud interpolation and PCA analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03232v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yikun Bai, Ivan Medri, Rocio Diaz Martin, Rana Muhammad Shahroz Khan, Soheil Kolouri</dc:creator>
    </item>
    <item>
      <title>Non-Parametric Learning of Stochastic Differential Equations with Non-asymptotic Fast Rates of Convergence</title>
      <link>https://arxiv.org/abs/2305.15557</link>
      <description>arXiv:2305.15557v2 Announce Type: replace-cross 
Abstract: We propose a novel non-parametric learning paradigm for the identification of drift and diffusion coefficients of multi-dimensional non-linear stochastic differential equations, which relies upon discrete-time observations of the state. The key idea essentially consists of fitting a RKHS-based approximation of the corresponding Fokker-Planck equation to such observations, yielding theoretical estimates of non-asymptotic learning rates which, unlike previous works, become increasingly tighter when the regularity of the unknown drift and diffusion coefficients becomes higher. Our method being kernel-based, offline pre-processing may be profitably leveraged to enable efficient numerical implementation, offering excellent balance between precision and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15557v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Bonalli, Alessandro Rudi</dc:creator>
    </item>
    <item>
      <title>Reflections on BSDEs</title>
      <link>https://arxiv.org/abs/2306.14615</link>
      <description>arXiv:2306.14615v3 Announce Type: replace-cross 
Abstract: We prove well-posedness results for backward stochastic differential equations (BSDEs) and reflected BSDEs with an optional obstacle process in the case of appropriately weighted $\mathbb{L}^2$-data when the generator is integrated with respect to a possibly purely discontinuous process. This leads to a unified treatment of discrete-time and continuous-time (reflected) BSDEs. We compare our well-posedness results with the current literature and highlight that our results are sharp and cannot be improved within the framework presented here. Finally, we provide sufficient conditions for a comparison principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14615v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dylan Possama\"i, Marco Rodrigues</dc:creator>
    </item>
    <item>
      <title>Estimation Sample Complexity of a Class of Nonlinear Continuous-time Systems</title>
      <link>https://arxiv.org/abs/2312.05382</link>
      <description>arXiv:2312.05382v2 Announce Type: replace-cross 
Abstract: We present a method of parameter estimation for large class of nonlinear systems, namely those in which the state consists of output derivatives and the flow is linear in the parameter. The method, which solves for the unknown parameter by directly inverting the dynamics using regularized linear regression, is based on new design and analysis ideas for differentiation filtering and regularized least squares. Combined in series, they yield a novel finite-sample bound on mean absolute error of estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05382v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Kuang, Xinfan Lin</dc:creator>
    </item>
    <item>
      <title>Change of regularity in controllability and observability of systems of wave equations</title>
      <link>https://arxiv.org/abs/2312.06311</link>
      <description>arXiv:2312.06311v2 Announce Type: replace-cross 
Abstract: Solutions of a system of wave equations are constructed for both homogeneous and inhomogeneous Dirichlet boundary conditions at every regularity level. We prove that boundary observability, and thus boundary exact controllability, at some regularity level is equivalent to boundary observability at all levels. The main ingredient is the ellipticity of a time-derivative on the Neumann trace of the solution, which is proved by microlocal techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06311v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Perrin</dc:creator>
    </item>
    <item>
      <title>Decoupled Weight Decay for Any $p$ Norm</title>
      <link>https://arxiv.org/abs/2404.10824</link>
      <description>arXiv:2404.10824v2 Announce Type: replace-cross 
Abstract: With the success of deep neural networks (NNs) in a variety of domains, the computational and storage requirements for training and deploying large NNs have become a bottleneck for further improvements. Sparsification has consequently emerged as a leading approach to tackle these issues. In this work, we consider a simple yet effective approach to sparsification, based on the Bridge, or $L_p$ regularization during training. We introduce a novel weight decay scheme, which generalizes the standard $L_2$ weight decay to any $p$ norm. We show that this scheme is compatible with adaptive optimizers, and avoids the gradient divergence associated with $0&lt;p&lt;1$ norms. We empirically demonstrate that it leads to highly sparse networks, while maintaining generalization performance comparable to standard $L_2$ regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10824v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadav Joseph Outmezguine, Noam Levi</dc:creator>
    </item>
  </channel>
</rss>
