<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.CD updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.CD</link>
    <description>nlin.CD updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.CD" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Apr 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Rosenzweig Porter model revisited for the three Wigner Dyson symmetry classes</title>
      <link>https://arxiv.org/abs/2404.05755</link>
      <description>arXiv:2404.05755v1 Announce Type: cross 
Abstract: We present numerical results for the Rosenzweig Porter model for all symmetry classes of the Dyson threefold way. We analyzed the fluctuation properties in the eigenvalue spectra, and compared them with existing and new analytical results. Based on these results we propose characteristics of the spectral properties as measures to explore the transition from Poisson to Wigner Dyson WD statistics. Furthermore, we performed thorough studies of the properties of the eigenvectors in terms of the fractal dimensions, the Kullback Leibler KL divergences and the fidelity susceptibility. The ergodic and Anderson transitions take place at the same parameter values and a finite size scaling analysis of the KL divergences at the transitions yields the same critical exponents for all three WD classes, thus indicating superuniversality of these transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05755v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tilen Cadez, Dillip Nandy, Dario Rosa, Alexei Andreanov, Barbara Dietz</dc:creator>
    </item>
    <item>
      <title>Dynamical stability and chaos in artificial neural network trajectories along training</title>
      <link>https://arxiv.org/abs/2404.05782</link>
      <description>arXiv:2404.05782v1 Announce Type: cross 
Abstract: The process of training an artificial neural network involves iteratively adapting its parameters so as to minimize the error of the network's prediction, when confronted with a learning task. This iterative change can be naturally interpreted as a trajectory in network space -- a time series of networks -- and thus the training algorithm (e.g. gradient descent optimization of a suitable loss function) can be interpreted as a dynamical system in graph space. In order to illustrate this interpretation, here we study the dynamical properties of this process by analyzing through this lens the network trajectories of a shallow neural network, and its evolution through learning a simple classification task. We systematically consider different ranges of the learning rate and explore both the dynamical and orbital stability of the resulting network trajectories, finding hints of regular and chaotic behavior depending on the learning rate regime. Our findings are put in contrast to common wisdom on convergence properties of neural networks and dynamical systems theory. This work also contributes to the cross-fertilization of ideas between dynamical systems theory, network theory and machine learning</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05782v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaloyan Danovski, Miguel C. Soriano, Lucas Lacasa</dc:creator>
    </item>
    <item>
      <title>Turbulent cascade arrests and the formation of intermediate-scale condensates</title>
      <link>https://arxiv.org/abs/2404.06169</link>
      <description>arXiv:2404.06169v1 Announce Type: cross 
Abstract: Energy cascades lie at the heart of the dynamics of turbulent flows. In a recent study of turbulence in fluids with odd-viscosity [de Wit \textit{et al.}, Nature \textbf{627}, 515 (2024)], the two-dimensionalization of the flow at small scales leads to the arrest of the energy cascade and selection of an intermediate scale, between the forcing and the viscous scales. To investigate the generality of this phenomenon, we study a shell model that is carefully constructed to have three-dimensional turbulent dynamics at small wavenumbers and two-dimensional turbulent dynamics at large wavenumbers. The large scale separation that we can achieve in our shell model allows us to examine clearly the interplay between these dynamics, which leads to an arrest of the energy cascade at a transitional wavenumber and an associated accumulation of energy at the same scale. Such pile-up of energy around the transitional wavenumber is reminiscent of the formation of condensates in two-dimensional turbulence, \textit{but, in contrast, it occurs at intermediate wavenumbers instead of the smallest wavenumber</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06169v1</guid>
      <category>physics.flu-dyn</category>
      <category>cond-mat.soft</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kolluru Venkata Kiran, Dario Vincenzi, Rahul Pandit</dc:creator>
    </item>
    <item>
      <title>Simplicity bias, algorithmic probability, and the random logistic map</title>
      <link>https://arxiv.org/abs/2401.00593</link>
      <description>arXiv:2401.00593v2 Announce Type: replace-cross 
Abstract: Simplicity bias is an intriguing phenomenon prevalent in various input-output maps, characterized by a preference for simpler, more regular, or symmetric outputs. Notably, these maps typically feature high-probability outputs with simple patterns, whereas complex patterns are exponentially less probable. This bias has been extensively examined and attributed to principles derived from algorithmic information theory and algorithmic probability. In a significant advancement, it has been demonstrated that the renowned logistic map and other one-dimensional maps exhibit simplicity bias when conceptualized as input-output systems. Building upon this work, our research delves into the manifestations of simplicity bias within the random logistic map, specifically focusing on scenarios involving additive noise.
  We discover that simplicity bias is observable in the random logistic map for specific ranges of $\mu$ and noise magnitudes. Additionally, we find that this bias persists even with the introduction of small measurement noise, though it diminishes as noise levels increase. Our studies also revisit the phenomenon of noise-induced chaos, particularly when $\mu=3.83$, revealing its characteristics through complexity-probability plots. Intriguingly, we employ the logistic map to illustrate a paradoxical aspect of data analysis: more data adhering to a consistent trend can occasionally lead to \emph{reduced} confidence in extrapolation predictions, challenging conventional wisdom.
  We propose that adopting a probability-complexity perspective in analyzing dynamical systems could significantly enrich statistical learning theories related to series prediction and analysis. This approach not only facilitates a deeper understanding of simplicity bias and its implications but also paves the way for novel methodologies in forecasting complex systems behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00593v2</guid>
      <category>cs.IT</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <category>nlin.CD</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.29746.79048</arxiv:DOI>
      <dc:creator>Boumediene Hamzi, Kamaludin Dingle</dc:creator>
    </item>
  </channel>
</rss>
