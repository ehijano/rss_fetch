<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 04:03:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multi-Source Approximate Message Passing: Random Semi-Unitary Dictionaries</title>
      <link>https://arxiv.org/abs/2410.13021</link>
      <description>arXiv:2410.13021v1 Announce Type: new 
Abstract: Recently, several problems in communication theory have been tackled using approximate message passing (AMP) for matrix-valued noisy linear observations involving \emph{multiple statistically asymmetric signal sources}. These problems assume that the ``dictionaries'' for each signal source are drawn from an i.i.d. (Gaussian) random matrix ensemble. In this work, we address the case with random semi-unitary dictionaries. We introduce an AMP algorithm devised for the new setting and provide a rigorous high-dimensional (but finite-sample) analysis. As a proof of concept, we show the efficacy of our results in addressing the problem of message detection and channel estimation for unsourced random access in wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13021v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Burak \c{C}akmak, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Physics-Compliant Modeling and Scaling Laws of Multi-RIS Aided Systems</title>
      <link>https://arxiv.org/abs/2410.13089</link>
      <description>arXiv:2410.13089v1 Announce Type: new 
Abstract: Reconfigurable intelligent surface (RIS) is a revolutionary technology enabling the control of wireless channels and improving coverage in wireless networks. To further extend coverage, multi-RIS aided systems have been explored, where multiple RISs steer the signal toward the receiver via a multi-hop path. However, deriving a physics-compliant channel model for multi-RIS aided systems is still an open problem. In this study, we fill this gap by modeling multi-RIS aided systems through multiport network theory, and deriving the scaling law of the physics-compliant channel gain. The derived physics-compliant channel model differs from the widely used model, where the structural scattering of the RISs is neglected. Theoretical insights, validated by numerical results, show a significant discrepancy between the physics-compliant and the widely used models. This discrepancy increases with the number of RISs and decreases with the number of RIS elements, reaching 200% in a system with eight RISs with 128 elements each.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13089v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Gabriele Gradoni, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Study of Weighted Residual Layered Belief Propagation for Decoding of LDPC Codes</title>
      <link>https://arxiv.org/abs/2410.13131</link>
      <description>arXiv:2410.13131v1 Announce Type: new 
Abstract: In this work, we investigate the decoding of Low-Density Parity-Check (LDPC) codes using informed dynamic scheduling algorithms that require a reduced number of iterations. In particular, we devise the weighted residual layered belief propagation (WR-LBP) decoding algorithm, which exploits the residual within a structured layer framework to speed the number of required decoding iterations. The proposed WR-LBP algorithm is assessed against important LDPC decoding algorithms, in terms of the number of iterations required for convergence and the bit error rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13131v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Touati, R. C. de Lamare</dc:creator>
    </item>
    <item>
      <title>Secrecy Sum-Rate Maximization for Active IRS-Assisted MIMO-OFDM SWIPT System</title>
      <link>https://arxiv.org/abs/2410.13180</link>
      <description>arXiv:2410.13180v1 Announce Type: new 
Abstract: The propagation loss of RF signals is a significant issue in simultaneous wireless information and power transfer (SWIPT) systems. Additionally, ensuring information security is crucial due to the broadcasting nature of wireless channels. To address these challenges, we exploit the potential of active intelligent reflecting surface (IRS) in a multiple-input and multiple-output (MIMO) orthogonal frequency division multiplexing (OFDM) SWIPT system. The active IRS provides better beamforming gain than the passive IRS, reducing the "double-fading" effect. Moreover, the noise introduced at the active IRS can be used as artificial noise (AN) to jam eavesdroppers. This paper formulates a secrecy sum-rate maximization problem related to precoding matrices, power splitting (PS) ratios, and the IRS matrix. Since the problem is highly non-convex, we propose a block coordinate descent (BCD)-based algorithm to find a sub-optimal solution. Moreover, we develop a heuristic algorithm based on the zero-forcing precoding scheme to reduce computational complexity. Simulation results show that the active IRS achieves a higher secrecy sum rate than the passive and non-IRS systems, especially when the transmit power is low or the direct link is blocked. Moreover, increasing the power budget at the active IRS can significantly improve the secrecy sum rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13180v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3478252</arxiv:DOI>
      <dc:creator>Xingxiang Peng, Peiran Wu, Junhui Zhao, Minghua Xia</dc:creator>
    </item>
    <item>
      <title>Windowed Compressed Spectrum Sensing with Block sparsity</title>
      <link>https://arxiv.org/abs/2410.13312</link>
      <description>arXiv:2410.13312v1 Announce Type: new 
Abstract: Compressed Spectrum Sensing (CSS) is widely employed in spectral analysis due to its sampling efficiency. However, conventional CSS assumes a standard sparse spectrum, which is affected by Spectral Leakage (SL). Despite the widespread use of CSS, the impact of SL on its performance has not been systematically and thoroughly investigated. This study addresses this research gap by analyzing the Restricted Isometry Property (RIP) of windowed Gaussian measurement matrices and proposing a novel block-sparse CSS model.
  We introduce the Edge Zeroing Coefficient (EZC) to evaluate SL suppression and RIP impact, and the Window Scaling Coefficient (WSC) to quantify the effect on RIP. Our research investigates the influence of Window Function (WF) on signal sparsity and measurement matrices, and presents a block-sparse CSS model that considers component frequency distribution, signal length, windowing, and noise floor. Based on subspace counting theory, we derive sample bound for our model. The findings demonstrate that while WFs reduce SL, excessively small EZC and WSC values can negatively affect RIP quality and cause numerical instability during signal reconstruction. This highlights the delicate balance required when applying WFs in CSS. Our block-sparse approach enables precise compression and reconstruction, particularly for high noise floor and super-sparse signals. This study provides a framework for optimizing CSS performance when dealing with SL and sparse signals, offering insights for improving signal reconstruction quality in various applications</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13312v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huiguang Zhang, Baoguo Liu</dc:creator>
    </item>
    <item>
      <title>High Rate Multivariate Polynomial Evaluation Codes</title>
      <link>https://arxiv.org/abs/2410.13470</link>
      <description>arXiv:2410.13470v1 Announce Type: new 
Abstract: The classical Reed-Muller codes over a finite field $\mathbb{F}_q$ are based on evaluations of $m$-variate polynomials of degree at most $d$ over a product set $U^m$, for some $d$ less than $|U|$. Because of their good distance properties, as well as the ubiquity and expressive power of polynomials, these codes have played an influential role in coding theory and complexity theory. This is especially so in the setting of $U$ being ${\mathbb{F}}_q$ where they possess deep locality properties. However, these Reed-Muller codes have a significant limitation in terms of the rate achievable -- the rate cannot be more than $\frac{1}{m{!}} = \exp(-m \log m)$.
  In this work, we give the first constructions of multivariate polynomial evaluation codes which overcome the rate limitation -- concretely, we give explicit evaluation domains $S \subseteq \mathbb{F}_q^m$ on which evaluating $m$-variate polynomials of degree at most $d$ gives a good code. For $m= O(1)$, these new codes have relative distance $\Omega(1)$ and rate $1 - \epsilon$ for any $\epsilon &gt; 0$. In fact, we give two quite different constructions, and for both we develop efficient decoding algorithms for these codes that can decode from half the minimum distance.
  The first of these codes is based on evaluating multivariate polynomials on simplex-like sets whereas the second construction is more algebraic, and surprisingly (to us), has some strong locality properties, specifically, we show that they are locally testable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13470v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Swastik Kopparty, Mrinal Kumar, Harry Sha</dc:creator>
    </item>
    <item>
      <title>A further study on the mass formula for linear codes with prescribed hull dimension</title>
      <link>https://arxiv.org/abs/2410.13578</link>
      <description>arXiv:2410.13578v1 Announce Type: new 
Abstract: Finding a mass formula for a given class of linear codes is a fundamental problem in combinatorics and coding theory. In this paper, we consider the action of the unitary (resp. symplectic) group on the set of all Hermitian (resp. symplectic) linear complementary dual (LCD) codes, prove that all Hermitian (resp. symplectic) LCD codes are on a unique orbit under this action, and determine the formula for the size of the orbit. Based on this, we develop a general technique to obtain a closed mass formula for linear codes with prescribed Hermitian (resp. symplectic) hull dimension, and further obtain some asymptotic results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13578v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shitao Li, Minjia Shi, Yang Li, San Ling</dc:creator>
    </item>
    <item>
      <title>Beamforming Optimization for Continuous Aperture Array (CAPA)-based Communications</title>
      <link>https://arxiv.org/abs/2410.13677</link>
      <description>arXiv:2410.13677v1 Announce Type: new 
Abstract: The beamforming optimization in continuous aperture array (CAPA)-based multi-user communications is studied. In contrast to conventional spatially discrete antenna arrays, CAPAs can exploit the full spatial degrees of freedoms (DoFs) by emitting information-bearing electromagnetic (EM) wave through continuous source current distributed across the aperture. Nevertheless, such operation renders the beamforming optimization problem as a non-convex integral-based functional programming problem, which is challenging for conventional discrete optimization methods. A couple of low-complexity approaches are proposed to solve the functional programming problem. 1) Calculus of variations (CoV)-based approach: Closed-form structure of the optimal continuous source patterns are derived based on CoV, inspiring a low-complexity integral-free iterative algorithm for solving the functional programming problem. 2) Correlation-based zero-forcing (Corr-ZF) approach: Closed-form ZF source current patterns that completely eliminate the interuser interference are derived based on the channel correlations. By using these patterns, the original functional programming problem is transformed to a simple power allocation problem, which can be solved using the classical water-filling approach with reduced complexity. Our numerical results validate the effectiveness of the proposed designs and reveal that: i) compared to the state-of-the-art Fourier-based discretization approach, the proposed CoV-based approach not only improves communication performance but also reduces computational complexity by up to hundreds of times for large CAPA apertures and high frequencies, and ii) the proposed Corr-ZF approach achieves asymptotically optimal performance compared to the CoV-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13677v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Wang, Chongjun Ouyang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Optimal Quantization for Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2410.13780</link>
      <description>arXiv:2410.13780v1 Announce Type: new 
Abstract: Recent work in machine learning community proposed multiple methods for performing lossy compression (quantization) of large matrices. This quantization is important for accelerating matrix multiplication (main component of large language models), which is often bottlenecked by the speed of loading these matrices from memory. Unlike classical vector quantization and rate-distortion theory, the goal of these new compression algorithms is to be able to approximate not the matrices themselves, but their matrix product. Specifically, given a pair of real matrices $A,B$ an encoder (compressor) is applied to each of them independently producing descriptions with $R$ bits per entry. These representations subsequently are used by the decoder to estimate matrix product $A^\top B$. In this work, we provide a non-asymptotic lower bound on the mean squared error of this approximation (as a function of rate $R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically, we construct a universal quantizer based on nested lattices with an explicit guarantee of approximation error for any (non-random) pair of matrices $A$, $B$ in terms of only Frobenius norms $\|A\|_F, \|B\|_F$ and $\|A^\top B\|_F$. For iid Gaussian matrices our quantizer achieves the lower bound and is, thus, asymptotically optimal. A practical low-complexity version of our quantizer achieves performance quite close to optimal. In information-theoretic terms we derive rate-distortion function for matrix multiplication of iid Gaussian matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13780v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Or Ordentlich, Yury Polyanskiy</dc:creator>
    </item>
    <item>
      <title>Private Counterfactual Retrieval</title>
      <link>https://arxiv.org/abs/2410.13812</link>
      <description>arXiv:2410.13812v1 Announce Type: new 
Abstract: Transparency and explainability are two extremely important aspects to be considered when employing black-box machine learning models in high-stake applications. Providing counterfactual explanations is one way of catering this requirement. However, this also poses a threat to the privacy of both the institution that is providing the explanation as well as the user who is requesting it. In this work, we propose multiple schemes inspired by private information retrieval (PIR) techniques which ensure the \emph{user's privacy} when retrieving counterfactual explanations. We present a scheme which retrieves the \emph{exact} nearest neighbor counterfactual explanation from a database of accepted points while achieving perfect (information-theoretic) privacy for the user. While the scheme achieves perfect privacy for the user, some leakage on the database is inevitable which we quantify using a mutual information based metric. Furthermore, we propose strategies to reduce this leakage to achieve an advanced degree of database privacy. We extend these schemes to incorporate user's preference on transforming their attributes, so that a more actionable explanation can be received. Since our schemes rely on finite field arithmetic, we empirically validate our schemes on real datasets to understand the trade-off between the accuracy and the finite field sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13812v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Nomeir, Pasan Dissanayake, Shreya Meel, Sanghamitra Dutta, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Private Information Retrieval within 1-bit/sec/Hz of the full Gaussian MAC Capacity</title>
      <link>https://arxiv.org/abs/2401.15912</link>
      <description>arXiv:2401.15912v4 Announce Type: replace 
Abstract: In this paper, we revisit the problem of Private Information Retrieval (PIR), where there are $N$ replicated non-communicating databases containing the same $M$ messages and a user who wishes to retrieve one of the messages without revealing the message's index to the databases. However, we assume a block-fading Additive White Gaussian Noise Multiple Access Channel (AWGN MAC) linking the user and the databases. Previous work \cite{shmuel2021private} presented a joint channel-PIR scheme, utilizing the Compute and Forward (C\&amp;F) protocol, demonstrating the potential of a joint channel-PIR scheme over a separated one, yet still lagging behind the channel capacity.
  We propose an improved scheme that offers reduced computational complexity while improving the achievable rate, both for finite parameters and its scaling laws. Specifically, the achievable rate outperforms the C\&amp;F-based approach, and scales with the number of databases $N$ and the power $P$ similarly to the channel capacity \textit{without the privacy constraint}. Furthermore, the analysis demonstrates that the improved rate exhibits only a finite gap from this unconstrained channel capacity -- $1$ $bit/sec/Hz$ as $N$ increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15912v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Or Elimelech, Asaf Cohen</dc:creator>
    </item>
    <item>
      <title>Game of Coding: Sybil Resistant Decentralized Machine Learning with Minimal Trust Assumption</title>
      <link>https://arxiv.org/abs/2410.05540</link>
      <description>arXiv:2410.05540v2 Announce Type: replace 
Abstract: Coding theory plays a crucial role in ensuring data integrity and reliability across various domains, from communication to computation and storage systems. However, its reliance on trust assumptions for data recovery poses significant challenges, particularly in emerging decentralized systems where trust is scarce. To address this, the game of coding framework was introduced, offering insights into strategies for data recovery within incentive-oriented environments. The focus of the earliest version of the game of coding was limited to scenarios involving only two nodes. This paper investigates the implications of increasing the number of nodes in the game of coding framework, particularly focusing on scenarios with one honest node and multiple adversarial nodes. We demonstrate that despite the increased flexibility for the adversary with an increasing number of adversarial nodes, having more power is not beneficial for the adversary and is not detrimental to the data collector, making this scheme sybil-resistant. Furthermore, we outline optimal strategies for the data collector in terms of accepting or rejecting the inputs, and characterize the optimal noise distribution for the adversary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05540v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanzaleh Akbari Nodehi, Viveck R. Cadambe, Mohammad Ali Maddah-Ali</dc:creator>
    </item>
    <item>
      <title>Exact computation of Transfer Entropy with Path Weight Sampling</title>
      <link>https://arxiv.org/abs/2409.01650</link>
      <description>arXiv:2409.01650v2 Announce Type: replace-cross 
Abstract: The ability to quantify the directional flow of information is vital to understanding natural systems and designing engineered information-processing systems. A widely used measure to quantify this information flow is the transfer entropy. However, until now, this quantity could only be obtained in dynamical models using approximations that are typically uncontrolled. Here we introduce a computational algorithm called Transfer Entropy-Path Weight Sampling (TE-PWS), which makes it possible, for the first time, to quantify the transfer entropy and its variants exactly for any stochastic model, including those with multiple hidden variables, nonlinearity, transient conditions, and feedback. By leveraging techniques from polymer and path sampling, TE-PWS efficiently computes the transfer entropy as a Monte-Carlo average over signal trajectory space. We apply TE-PWS to linear and nonlinear systems to reveal how transfer entropy can overcome naive applications of the data processing inequality in the presence of feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01650v2</guid>
      <category>q-bio.MN</category>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.bio-ph</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avishek Das, Pieter Rein ten Wolde</dc:creator>
    </item>
    <item>
      <title>Generalization Error of the Tilted Empirical Risk</title>
      <link>https://arxiv.org/abs/2409.19431</link>
      <description>arXiv:2409.19431v2 Announce Type: replace-cross 
Abstract: The generalization error (risk) of a supervised statistical learning algorithm quantifies its prediction ability on previously unseen data. Inspired by exponential tilting, Li et al. (2021) proposed the tilted empirical risk as a non-linear risk metric for machine learning applications such as classification and regression problems. In this work, we examine the generalization error of the tilted empirical risk. In particular, we provide uniform and information-theoretic bounds on the tilted generalization error, defined as the difference between the population risk and the tilted empirical risk, with a convergence rate of $O(1/\sqrt{n})$ where $n$ is the number of training samples. Furthermore, we study the solution to the KL-regularized expected tilted empirical risk minimization problem and derive an upper bound on the expected tilted generalization error with a convergence rate of $O(1/n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19431v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gholamali Aminian, Amir R. Asadi, Tian Li, Ahmad Beirami, Gesine Reinert, Samuel N. Cohen</dc:creator>
    </item>
    <item>
      <title>Variational Source-Channel Coding for Semantic Communication</title>
      <link>https://arxiv.org/abs/2410.08222</link>
      <description>arXiv:2410.08222v2 Announce Type: replace-cross 
Abstract: Semantic communication technology emerges as a pivotal bridge connecting AI with classical communication. The current semantic communication systems are generally modeled as an Auto-Encoder (AE). AE lacks a deep integration of AI principles with communication strategies due to its inability to effectively capture channel dynamics. This gap makes it difficult to justify the need for joint source-channel coding (JSCC) and to explain why performance improves. This paper begins by exploring lossless and lossy communication, highlighting that the inclusion of data distortion distinguishes semantic communication from classical communication. It breaks the conditions for the separation theorem to hold and explains why the amount of data transferred by semantic communication is less. Therefore, employing JSCC becomes imperative for achieving optimal semantic communication. Moreover, a Variational Source-Channel Coding (VSCC) method is proposed for constructing semantic communication systems based on data distortion theory, integrating variational inference and channel characteristics. Using a deep learning network, we develop a semantic communication system employing the VSCC method and demonstrate its capability for semantic transmission. We also establish semantic communication systems of equivalent complexity employing the AE method and the VAE method. Experimental results reveal that the VSCC model offers superior interpretability compared to AE model, as it clearly captures the semantic features of the transmitted data, represented as the variance of latent variables in our experiments. In addition, VSCC model exhibits superior semantic transmission capabilities compared to VAE model. At the same level of data distortion evaluated by PSNR, VSCC model exhibits stronger human interpretability, which can be partially assessed by SSIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08222v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulong Feng, Jing Xu, Liujun Hu, Guanghui Yu, Xiangyang Duan</dc:creator>
    </item>
  </channel>
</rss>
