<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Oct 2024 02:04:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Meta-Learning for Hybrid Precoding in Millimeter Wave MIMO System</title>
      <link>https://arxiv.org/abs/2410.09427</link>
      <description>arXiv:2410.09427v1 Announce Type: new 
Abstract: The hybrid analog/digital architecture that connects a limited number of RF chains to multiple antennas through phase shifters could effectively address the energy consumption issues in massive multiple-input multiple-output (MIMO) systems. However, the main challenges in hybrid precoding lie in the coupling between analog and digital precoders and the constant modulus constraint. Generally, traditional optimization algorithms for this problem typically suffer from high computational complexity or suboptimal performance, while deep learning based solutions exhibit poor scalability and robustness. This paper proposes a plug and play, free of pre-training solution that leverages gradient guided meta learning (GGML) framework to maximize the spectral efficiency of MIMO systems through hybrid precoding. Specifically, GGML utilizes gradient information as network input to facilitate the sharing of gradient information flow. We retain the iterative process of traditional algorithms and leverage meta learning to alternately optimize the precoder. Simulation results show that this method outperforms existing methods, demonstrates robustness to variations in system parameters, and can even exceed the performance of fully digital weighted minimum mean square error (WMMSE) precoding with the same number of antennas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09427v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Guo</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Based Decoder for Concatenated Coding over Deletion Channels</title>
      <link>https://arxiv.org/abs/2410.09460</link>
      <description>arXiv:2410.09460v1 Announce Type: new 
Abstract: In this paper, we introduce a deep learning-based decoder designed for concatenated coding schemes over a deletion/substitution channel. Specifically, we focus on serially concatenated codes, where the outer code is either a convolutional or a low-density parity-check (LDPC) code, and the inner code is a marker code. We utilize Bidirectional Gated Recurrent Units (BI-GRUs) as log-likelihood ratio (LLR) estimators and outer code decoders for estimating the message bits. Our results indicate that decoders powered by BI-GRUs perform comparably in terms of error rates with the MAP detection of the marker code. We also find that a single network can work well for a wide range of channel parameters. In addition, it is possible to use a single BI-GRU based network to estimate the message bits via one-shot decoding when the outer code is a convolutional code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09460v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICC51166.2024.10622561</arxiv:DOI>
      <arxiv:journal_reference>ICC 2024 - IEEE International Conference on Communications, Denver, CO, USA, 2024, pp. 2797-2802</arxiv:journal_reference>
      <dc:creator>E. Uras Karg{\i}, Tolga M. Duman</dc:creator>
    </item>
    <item>
      <title>Air-to-Ground Communications Beyond 5G: CoMP Handoff Management in UAV Network</title>
      <link>https://arxiv.org/abs/2410.09548</link>
      <description>arXiv:2410.09548v1 Announce Type: new 
Abstract: Air-to-ground (A2G) networks, using unmanned aerial vehicles (UAVs) as base stations to serve terrestrial user equipments (UEs), are promising for extending the spatial coverage capability in future communication systems. Coordinated transmission among multiple UAVs significantly improves network coverage and throughput compared to a single UAV transmission. However, implementing coordinated multi-point (CoMP) transmission for UAV mobility requires complex cooperation procedures, regardless of the handoff mechanism involved. This paper designs a novel CoMP transmission strategy that enables terrestrial UEs to achieve reliable and seamless connections with mobile UAVs. Specifically, a computationally efficient CoMP transmission method based on the theory of Poisson-Delaunay triangulation is developed, where an efficient subdivision search strategy for a CoMP UAV set is designed to minimize search overhead by a divide-and-conquer approach. For concrete performance evaluation, the cooperative handoff probability of the typical UE is analyzed, and the coverage probability with handoffs is derived. Simulation results demonstrate that the proposed scheme outperforms the conventional Voronoi scheme with the nearest serving UAV regarding coverage probabilities with handoffs. Moreover, each UE has a fixed and unique serving UAV set to avoid real-time dynamic UAV searching and achieve effective load balancing, significantly reducing system resource costs and enhancing network coverage performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09548v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3476943</arxiv:DOI>
      <dc:creator>Yan Li, Deke Guo, Lailong Luo, Minghua Xia</dc:creator>
    </item>
    <item>
      <title>A Game-Theoretic Perspective for Efficient Modern Random Access</title>
      <link>https://arxiv.org/abs/2410.09588</link>
      <description>arXiv:2410.09588v1 Announce Type: new 
Abstract: Modern random access mechanisms combine packet repetitions with multi-user detection mechanisms at the receiver to maximize the throughput and reliability in massive Internet of Things (IoT) scenarios. However, optimizing the access policy, which selects the number of repetitions, is a complicated problem, and failing to do so can lead to an inefficient use of resources and, potentially, to an increased congestion. In this paper, we follow a game-theoretic approach for optimizing the access policies of selfish users in modern random access mechanisms. Our goal is to find adequate values for the rewards given after a success to achieve a Nash equilibrium (NE) that optimizes the throughput of the system while considering the cost of transmission. Our results show that a mixed strategy, where repetitions are selected according to the irregular repetition slotted ALOHA (IRSA) protocol, attains a NE that maximizes the throughput in the special case with two users. In this scenario, our method increases the throughput by 30% when compared to framed ALOHA. Furthermore, we present three methods to attain a NE with near-optimal throughput for general modern random access scenarios, which exceed the throughput of framed ALOHA by up to 34%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09588v1</guid>
      <category>cs.IT</category>
      <category>cs.GT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Peter Juhl Hansen, Jeppe Roden M\"unster, Rasmus Erik Villadsen, Simon Bock Segaard, S{\o}ren Pilegaard Rasmussen, Christophe Biscio, Israel Leyva-Mayorga</dc:creator>
    </item>
    <item>
      <title>Intelligent Reflecting Surface-Assisted Symbiotic Radio Systems: A Double-Reflection Covert Communication Design</title>
      <link>https://arxiv.org/abs/2410.10276</link>
      <description>arXiv:2410.10276v1 Announce Type: new 
Abstract: We investigate covert communication in an intelligent reflecting surface (IRS)-assisted symbiotic radio (SR) system under the parasitic SR (PSR) and the commensal SR (CSR) cases, where an IRS is exploited to create a double reflection link for legitimate users and degrade the detection performance of the warden (W). Specifically, we derive an analytical expression for the average detection error probability of W and design an optimal strategy to determine the transmit power and backscatter reflection coefficient. To further enhance the covert performance, the joint optimization of the source transmit power, backscatter device (BD) reflection coefficient, and IRS phase-shifter is formulated as an expectation-based quadratic-fractional (EQF) problem. By reformulating the original problem into a fraction-eliminated backscatter power leakage minimization problem, we further develop the phase alignment pursuit and the power leakage minimization algorithms for the PSR and the CSR cases, respectively. Numerical results confirm the accuracy of the derived results and the superiority of our proposed strategy in terms of covertness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10276v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunpeng Feng, Jian Chen, Lu Lv, Yuchen Zhou, Long Yang, Naofal Al-Dhahir, Fumiyuki Adachi</dc:creator>
    </item>
    <item>
      <title>Achievable Second-Order Asymptotics for MAC and RAC with Additive Non-Gaussian Noise</title>
      <link>https://arxiv.org/abs/2410.10312</link>
      <description>arXiv:2410.10312v1 Announce Type: new 
Abstract: We first study the two-user additive noise multiple access channel (MAC) where the noise distribution is arbitrary. For such a MAC, we use spherical codebooks and either joint nearest neighbor (JNN) or successive interference cancellation (SIC) decoding. Under both decoding methods, we derive second-order achievable rate regions and compare the finite blocklength performance between JNN and SIC decoding. Our results indicate that although the first-order rate regions of JNN and SIC decoding are identical, JNN decoding has better second-order asymptotic performance. When specialized to the Gaussian noise, we provide an alternative achievability proof to the result by MolavianJazi and Laneman (T-IT, 2015). Furthermore, we generalize our results to the random access channel (RAC) where neither the transmitters nor the receiver knows the user activity pattern. We use spherical-type codebooks and a rateless transmission scheme combining JNN/SIC decoding, and derive second-order achievability bounds. Comparing second-order achievability results of JNN and SIC decoding in a RAC, we show that JNN decoding achieves strictly larger first-order asymptotic rate. When specialized to Gaussian noise, our second-order asymptotic results recover the corresponding results of Yavas, Kostina, and Effros (T-IT, 2021) up to second-order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10312v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Wang, Lin Bai, Zhuangfei Wu, Lin Zhou</dc:creator>
    </item>
    <item>
      <title>Performance of a Threshold-based WDM and ACM for FSO Communication between Mobile Platforms in Maritime Environments</title>
      <link>https://arxiv.org/abs/2410.10335</link>
      <description>arXiv:2410.10335v1 Announce Type: new 
Abstract: In this study, we statistically analyze the performance of a threshold-based multiple optical signal selection scheme (TMOS) for wavelength division multiplexing (WDM) and adaptive coded modulation (ACM) using free space optical (FSO) communication between mobile platforms in maritime environments with fog and 3D pointing errors. Specifically, we derive a new closed-form expression for a composite probability density function (PDF) that is more appropriate for applying various algorithms to FSO systems under the combined effects of fog and pointing errors. We then analyze the outage probability, average spectral efficiency (ASE), and bit error rate (BER) performance of the conventional detection techniques (i.e., heterodyne and intensity modulation/direct detection). The derived analytical results were cross-verified using Monte Carlo simulations. The results show that we can obtain a higher ASE performance by applying TMOS-based WDM and ACM and that the probability of the beam being detected in the photodetector increased at a low signal-to-noise ratio, contrary to conventional performance. Furthermore, it has been confirmed that applying WDM and ACM is suitable, particularly in maritime environments where channel conditions frequently change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10335v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jae-Eun Han, Sung Sik Nam, Duck Dong Hwang, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Near-Pilotless MIMO Single Carrier Communications using Matrix Decomposition</title>
      <link>https://arxiv.org/abs/2410.10403</link>
      <description>arXiv:2410.10403v1 Announce Type: new 
Abstract: Multiple Input-Multiple Output (MIMO) is a key enabler of higher data rates in the next generation wireless communications. However in MIMO systems, channel estimation and equalization are challenging particularly in the presence of rapidly changing channels. The high pilot overhead required for channel estimation can reduce the system throughput for large antenna configuration. In this paper, we provide an iterative matrix decomposition algorithm for near-pilotless or blind decoding of MIMO signals, in a single carrier system with frequency domain equalization. This novel approach replaces the standard equalization and estimates both the transmitted data and the channel without the knowledge of any prior distributions, by making use of only one pilot. Our simulations demonstrate improved performance, in terms of error rates, compared to the more widely used pilot-based Maximal Ratio Combining (MRC) method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10403v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Praneeth K, P Aswathylakshmi, Radhakrishna Ganti</dc:creator>
    </item>
    <item>
      <title>Characterising high-order interdependence via entropic conjugation</title>
      <link>https://arxiv.org/abs/2410.10485</link>
      <description>arXiv:2410.10485v1 Announce Type: new 
Abstract: High-order phenomena play crucial roles in many systems of interest, but their analysis is often highly nontrivial. There is a rich literature providing a number of alternative information-theoretic quantities capturing high-order phenomena, but their interpretation and relationship with each other is not well understood. The lack of principles unifying these quantities obscures the choice of tools for enabling specific type of analyses. Here we show how an entropic conjugation provides a theoretically grounded principle to investigate the space of possible high-order quantities, clarifying the nature of the existent metrics while revealing gaps in the literature. This leads to identify novel notions of symmetry and skew-symmetry as key properties for guaranteeing a balanced account of high-order interdependencies and enabling broadly applicable analyses across physical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10485v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando E. Rosas, Aaron Gutknecht, Pedro A. M. Mediano, Michael Gastpar</dc:creator>
    </item>
    <item>
      <title>Optimizing Quantitative Photoacoustic Imaging Systems: The Bayesian Cram\'er-Rao Bound Approach</title>
      <link>https://arxiv.org/abs/2410.09557</link>
      <description>arXiv:2410.09557v1 Announce Type: cross 
Abstract: Quantitative photoacoustic computed tomography (qPACT) is an emerging medical imaging modality that carries the promise of high-contrast, fine-resolution imaging of clinically relevant quantities like hemoglobin concentration and blood-oxygen saturation. However, qPACT image reconstruction is governed by a multiphysics, partial differential equation (PDE) based inverse problem that is highly non-linear and severely ill-posed. Compounding the difficulty of the problem is the lack of established design standards for qPACT imaging systems, as there is currently a proliferation of qPACT system designs for various applications and it is unknown which ones are optimal or how to best modify the systems under various design constraints. This work introduces a novel computational approach for the optimal experimental design (OED) of qPACT imaging systems based on the Bayesian Cram\'er-Rao bound (CRB). Our approach incorporates several techniques to address challenges associated with forming the bound in the infinite-dimensional function space setting of qPACT, including priors with trace-class covariance operators and the use of the variational adjoint method to compute derivatives of the log-likelihood function needed in the bound computation. The resulting Bayesian CRB based design metric is computationally efficient and independent of the choice of estimator used to solve the inverse problem. The efficacy of the bound in guiding experimental design was demonstrated in a numerical study of qPACT design schemes under a stylized two-dimensional imaging geometry. To the best of our knowledge, this is the first work to propose Bayesian CRB based design for systems governed by PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09557v1</guid>
      <category>physics.med-ph</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan Scope Crafts, Mark A. Anastasio, Umberto Villa</dc:creator>
    </item>
    <item>
      <title>Transformers as Game Players: Provable In-context Game-playing Capabilities of Pre-trained Models</title>
      <link>https://arxiv.org/abs/2410.09701</link>
      <description>arXiv:2410.09701v1 Announce Type: cross 
Abstract: The in-context learning (ICL) capability of pre-trained models based on the transformer architecture has received growing interest in recent years. While theoretical understanding has been obtained for ICL in reinforcement learning (RL), the previous results are largely confined to the single-agent setting. This work proposes to further explore the in-context learning capabilities of pre-trained transformer models in competitive multi-agent games, i.e., in-context game-playing (ICGP). Focusing on the classical two-player zero-sum games, theoretical guarantees are provided to demonstrate that pre-trained transformers can provably learn to approximate Nash equilibrium in an in-context manner for both decentralized and centralized learning settings. As a key part of the proof, constructional results are established to demonstrate that the transformer architecture is sufficiently rich to realize celebrated multi-agent game-playing algorithms, in particular, decentralized V-learning and centralized VI-ULCB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09701v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengshuai Shi, Kun Yang, Jing Yang, Cong Shen</dc:creator>
    </item>
    <item>
      <title>Universal scaling laws in quantum-probabilistic machine learning by tensor network towards interpreting representation and generalization powers</title>
      <link>https://arxiv.org/abs/2410.09703</link>
      <description>arXiv:2410.09703v1 Announce Type: cross 
Abstract: Interpreting the representation and generalization powers has been a long-standing issue in the field of machine learning (ML) and artificial intelligence. This work contributes to uncovering the emergence of universal scaling laws in quantum-probabilistic ML. We take the generative tensor network (GTN) in the form of a matrix product state as an example and show that with an untrained GTN (such as a random TN state), the negative logarithmic likelihood (NLL) $L$ generally increases linearly with the number of features $M$, i.e., $L \simeq k M + const$. This is a consequence of the so-called ``catastrophe of orthogonality,'' which states that quantum many-body states tend to become exponentially orthogonal to each other as $M$ increases. We reveal that while gaining information through training, the linear scaling law is suppressed by a negative quadratic correction, leading to $L \simeq \beta M - \alpha M^2 + const$. The scaling coefficients exhibit logarithmic relationships with the number of training samples and the number of quantum channels $\chi$. The emergence of the quadratic correction term in NLL for the testing (training) set can be regarded as evidence of the generalization (representation) power of GTN. Over-parameterization can be identified by the deviation in the values of $\alpha$ between training and testing sets while increasing $\chi$. We further investigate how orthogonality in the quantum feature map relates to the satisfaction of quantum probabilistic interpretation, as well as to the representation and generalization powers of GTN. The unveiling of universal scaling laws in quantum-probabilistic ML would be a valuable step toward establishing a white-box ML scheme interpreted within the quantum probabilistic framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09703v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng-Chen Bai, Shi-Ju Ran</dc:creator>
    </item>
    <item>
      <title>Sharper Guarantees for Learning Neural Network Classifiers with Gradient Methods</title>
      <link>https://arxiv.org/abs/2410.10024</link>
      <description>arXiv:2410.10024v1 Announce Type: cross 
Abstract: In this paper, we study the data-dependent convergence and generalization behavior of gradient methods for neural networks with smooth activation. Our first result is a novel bound on the excess risk of deep networks trained by the logistic loss, via an alogirthmic stability analysis. Compared to previous works, our results improve upon the shortcomings of the well-established Rademacher complexity-based bounds. Importantly, the bounds we derive in this paper are tighter, hold even for neural networks of small width, do not scale unfavorably with width, are algorithm-dependent, and consequently capture the role of initialization on the sample complexity of gradient descent for deep nets. Specialized to noiseless data separable with margin $\gamma$ by neural tangent kernel (NTK) features of a network of width $\Omega(\poly(\log(n)))$, we show the test-error rate to be $e^{O(L)}/{\gamma^2 n}$, where $n$ is the training set size and $L$ denotes the number of hidden layers. This is an improvement in the test loss bound compared to previous works while maintaining the poly-logarithmic width conditions. We further investigate excess risk bounds for deep nets trained with noisy data, establishing that under a polynomial condition on the network width, gradient descent can achieve the optimal excess risk. Finally, we show that a large step-size significantly improves upon the NTK regime's results in classifying the XOR distribution. In particular, we show for a one-hidden-layer neural network of constant width $m$ with quadratic activation and standard Gaussian initialization that mini-batch SGD with linear sample complexity and with a large step-size $\eta=m$ reaches the perfect test accuracy after only $\ceil{\log(d)}$ iterations, where $d$ is the data dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10024v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossein Taheri, Christos Thrampoulidis, Arya Mazumdar</dc:creator>
    </item>
    <item>
      <title>Local Optimality of Dictator Functions with Applications to Courtade--Kumar Conjecture</title>
      <link>https://arxiv.org/abs/2410.10147</link>
      <description>arXiv:2410.10147v1 Announce Type: cross 
Abstract: Given a convex function $\Phi:[0,1]\to\mathbb{R}$, the $\Phi$-stability of a Boolean function $f$ is $\mathbb{E}[\Phi(T_{\rho}f(\mathbf{X}))]$, where $\mathbf{X}$ is a random vector uniformly distributed on the discrete cube $\{\pm1\}^{n}$ and $T_{\rho}$ is the Bonami-Beckner operator. In this paper, we prove that dictator functions are locally optimal in maximizing the $\Phi$-stability of $f$ over all balanced Boolean functions. Combining this result with our previous bound in \cite{yu2023phi}, we provide a new bound for the Courtade--Kumar conjecture which is expressed in the form of finite-dimensional program. By evaluating this new bound, we numerically verify that the Courtade--Kumar conjecture is true for all $\rho\in[0,0.92]$. Our proofs are based on the majorization of noise operators and hypercontractivity inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10147v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yu</dc:creator>
    </item>
    <item>
      <title>On Sum-Free Functions</title>
      <link>https://arxiv.org/abs/2410.10426</link>
      <description>arXiv:2410.10426v1 Announce Type: cross 
Abstract: A function from $\Bbb F_{2^n}$ to $\Bbb F_{2^n}$ is said to be {\em $k$th order sum-free} if the sum of its values over each $k$-dimensional $\Bbb F_2$-affine subspace of $\Bbb F_{2^n}$ is nonzero. This notion was recently introduced by C. Carlet as, among other things, a generalization of APN functions. At the center of this new topic is a conjecture about the sum-freedom of the multiplicative inverse function $f_{\text{\rm inv}}(x)=x^{-1}$ (with $0^{-1}$ defined to be $0$). It is known that $f_{\text{\rm inv}}$ is 2nd order (equivalently, $(n-2)$th order) sum-free if and only if $n$ is odd, and it is conjectured that for $3\le k\le n-3$, $f_{\text{\rm inv}}$ is never $k$th order sum-free. The conjecture has been confirmed for even $n$ but remains open for odd $n$. In the present paper, we show that the conjecture holds under each of the following conditions: (1) $n=13$; (2) $3\mid n$; (3) $5\mid n$; (4) the smallest prime divisor $l$ of $n$ satisfies $(l-1)(l+2)\le (n+1)/2$. We also determine the ``right'' $q$-ary generalization of the binary multiplicative inverse function $f_{\text{\rm inv}}$ in the context of sum-freedom. This $q$-ary generalization not only maintains most results for its binary version, but also exhibits some extraordinary phenomena that are not observed in the binary case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10426v1</guid>
      <category>math.NT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alyssa Ebeling, Xiang-dong Hou, Ashley Rydell, Shujun Zhao</dc:creator>
    </item>
    <item>
      <title>Combinatorial Multi-armed Bandits: Arm Selection via Group Testing</title>
      <link>https://arxiv.org/abs/2410.10679</link>
      <description>arXiv:2410.10679v1 Announce Type: cross 
Abstract: This paper considers the problem of combinatorial multi-armed bandits with semi-bandit feedback and a cardinality constraint on the super-arm size. Existing algorithms for solving this problem typically involve two key sub-routines: (1) a parameter estimation routine that sequentially estimates a set of base-arm parameters, and (2) a super-arm selection policy for selecting a subset of base arms deemed optimal based on these parameters. State-of-the-art algorithms assume access to an exact oracle for super-arm selection with unbounded computational power. At each instance, this oracle evaluates a list of score functions, the number of which grows as low as linearly and as high as exponentially with the number of arms. This can be prohibitive in the regime of a large number of arms. This paper introduces a novel realistic alternative to the perfect oracle. This algorithm uses a combination of group-testing for selecting the super arms and quantized Thompson sampling for parameter estimation. Under a general separability assumption on the reward function, the proposed algorithm reduces the complexity of the super-arm-selection oracle to be logarithmic in the number of base arms while achieving the same regret order as the state-of-the-art algorithms that use exact oracles. This translates to at least an exponential reduction in complexity compared to the oracle-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10679v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arpan Mukherjee, Shashanka Ubaru, Keerthiram Murugesan, Karthikeyan Shanmugam, Ali Tajer</dc:creator>
    </item>
    <item>
      <title>Fast Convergence of $\Phi$-Divergence Along the Unadjusted Langevin Algorithm and Proximal Sampler</title>
      <link>https://arxiv.org/abs/2410.10699</link>
      <description>arXiv:2410.10699v1 Announce Type: cross 
Abstract: We study the mixing time of two popular discrete time Markov chains in continuous space, the unadjusted Langevin algorithm and the proximal sampler, which are discretizations of the Langevin dynamics. We extend mixing time analyses for these Markov chains to hold in $\Phi$-divergence. We show that any $\Phi$-divergence arising from a twice-differentiable strictly convex function $\Phi$ converges to $0$ exponentially fast along these Markov chains, under the assumption that their stationary distributions satisfies the corresponding $\Phi$-Sobolev inequality. Our rates of convergence are tight and include as special cases popular mixing time regimes, namely the mixing in chi-squared divergence under a Poincar\'e inequality, and the mixing in relative entropy under a log-Sobolev inequality. Our results follow by bounding the contraction coefficients arising in the appropriate strong data processing inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10699v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddharth Mitra, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Online Statistical Inference for Time-varying Sample-averaged Q-learning</title>
      <link>https://arxiv.org/abs/2410.10737</link>
      <description>arXiv:2410.10737v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) has emerged as a key approach for training agents in complex and uncertain environments. Incorporating statistical inference in RL algorithms is essential for understanding and managing uncertainty in model performance. This paper introduces a time-varying batch-averaged Q-learning algorithm, termed sampleaveraged Q-learning, which improves upon traditional single-sample Q-learning by aggregating samples of rewards and next states to better account for data variability and uncertainty. We leverage the functional central limit theorem (FCLT) to establish a novel framework that provides insights into the asymptotic normality of the sample-averaged algorithm under mild conditions. Additionally, we develop a random scaling method for interval estimation, enabling the construction of confidence intervals without requiring extra hyperparameters. Numerical experiments conducted on classic OpenAI Gym environments show that the time-varying sample-averaged Q-learning method consistently outperforms both single-sample and constant-batch Q-learning methods, achieving superior accuracy while maintaining comparable learning speeds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10737v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saunak Kumar Panda, Ruiqi Liu, Yisha Xiang</dc:creator>
    </item>
    <item>
      <title>Exponents for classical-quantum channel simulation in purified distance</title>
      <link>https://arxiv.org/abs/2410.10770</link>
      <description>arXiv:2410.10770v1 Announce Type: cross 
Abstract: We determine the exact error and strong converse exponent for entanglement-assisted classical-quantum channel simulation in worst case input purified distance. The error exponent is expressed as a single-letter formula optimized over sandwiched R\'enyi divergences of order $\alpha \in [1, \infty)$, notably without the need for a critical rate--a sharp contrast to the error exponent for classical-quantum channel coding. The strong converse exponent is expressed as a single-letter formula optimized over sandwiched R\'enyi divergences of order $\alpha\in [\frac{1}{2},1]$. As in the classical work [Oufkir et al., arXiv:2410.07051], we start with the goal of asymptotically expanding the meta-converse for channel simulation in the relevant regimes. However, to deal with non-commutativity issues arising from classical-quantum channels and entanglement-assistance, we critically use various properties of the quantum fidelity, additional auxiliary channel techniques, approximations via Chebyshev inequalities, and entropic continuity bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10770v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aadil Oufkir, Yongsheng Yao, Mario Berta</dc:creator>
    </item>
    <item>
      <title>The Local Landscape of Phase Retrieval Under Limited Samples</title>
      <link>https://arxiv.org/abs/2311.15221</link>
      <description>arXiv:2311.15221v2 Announce Type: replace 
Abstract: In this paper, we present a fine-grained analysis of the local landscape of phase retrieval under the regime of limited samples. Specifically, we aim to ascertain the minimal sample size required to guarantee a benign local landscape surrounding global minima in high dimensions. Let $n$ and $d$ denote the sample size and input dimension, respectively. We first explore the local convexity and establish that when $n=o(d\log d)$, for almost every fixed point in the local ball, the Hessian matrix has negative eigenvalues, provided $d$ is sufficiently large. % Consequently, the local landscape is highly non-convex. We next consider the one-point convexity and show that, as long as $n=\omega(d)$, with high probability, the landscape is one-point strongly convex in the local annulus: $\{w\in\mathbb{R}^d: o_d(1)\leqslant \|w-w^*\|\leqslant c\}$, where $w^*$ is the ground truth and $c$ is an absolute constant. This implies that gradient descent, initialized from any point in this domain, can converge to an $o_d(1)$-loss solution exponentially fast. Furthermore, we show that when $n=o(d\log d)$, there is a radius of $\widetilde\Theta\left(\sqrt{1/d}\right)$ such that one-point convexity breaks down in the corresponding smaller local ball. This indicates an impossibility of establishing a convergence to the exact $w^*$ for gradient descent under limited samples by relying solely on one-point convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15221v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaizhao Liu, Zihao Wang, Lei Wu</dc:creator>
    </item>
    <item>
      <title>Multiple Spectrally Null Constrained Complete Complementary Codes of Various Lengths Over Small Alphabet</title>
      <link>https://arxiv.org/abs/2403.10644</link>
      <description>arXiv:2403.10644v2 Announce Type: replace 
Abstract: Complete complementary codes (CCCs) are highly valuable in the fields of information security, radar and communication. The spectrally null constrained (SNC) problem arises in radar and modern communication systems due to the reservation or prohibition of specific spectrums from transmission. The literature on SNC-CCCs is somewhat limited in comparison to the literature on traditional CCCs. The main objective of this paper is to discover several configurations of SNC-CCCs that possess more flexibility in their parameters. The proposed construction utilised the existing CCCs and mutually orthogonal sequences. The proposed construction can cover almost all lengths with the smallest alphabets $\{-1,0,1\}$. Further, the idea of SNC-CCC is extended to multiple SNC-CCC with an inter-set zero cross-correlation zone (ZCCZ). Based on our construction, we can also control the correlation value outside the ZCCZ. The beauty of the obtained codes have aperiodic and periodic inter-set ZCCZ and low cross-correlation side-lobs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10644v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajen Kumar, Palash Sarkar, Prashant Kumar Srivastava, Sudhan Majhi</dc:creator>
    </item>
    <item>
      <title>Variable-Length Stop-Feedback Coding for Minimum Age of Incorrect Information</title>
      <link>https://arxiv.org/abs/2404.01276</link>
      <description>arXiv:2404.01276v5 Announce Type: replace 
Abstract: The Age of Incorrect Information (AoII) is studied within the context of remote monitoring a Markov source using variable-length stop-feedback (VLSF) coding. Leveraging recent results on the non-asymptotic channel coding rate, we consider sources with small cardinality, where feedback is non-instantaneous as the transmitted information and feedback message have comparable lengths. We focus on the feedback sequence, i.e. the times of feedback transmissions, and derive AoII-optimal and delay-optimal feedback sequences. Our results showcase the impact of the feedback sequence on the AoII, revealing that a lower average delay does not necessarily correspond to a lower average AoII. We discuss the implications of our findings and suggest directions for coding scheme design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01276v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos Bountrogiannis, Ioannis Papoutsidakis, Anthony Ephremides, Panagiotis Tsakalides, George Tzagkarakis</dc:creator>
    </item>
    <item>
      <title>Unified Timing Analysis for Closed-Loop Goal-Oriented Wireless Communication</title>
      <link>https://arxiv.org/abs/2405.16047</link>
      <description>arXiv:2405.16047v2 Announce Type: replace 
Abstract: Goal-oriented communication has become one of the focal concepts in sixth-generation communication systems owing to its potential to provide intelligent, immersive, and real-time mobile services. The emerging paradigms of goal-oriented communication constitute closed loops integrating communication, computation, and sensing. However, challenges arise for closed-loop timing analysis due to multiple random factors that affect the communication/computation latency, as well as the heterogeneity of feedback mechanisms across multi-modal sensing data. To tackle these problems, we aim to provide a unified timing analysis framework for closed-loop goal-oriented communication (CGC) systems over fading channels. The proposed framework is unified as it considers computation, compression, and communication latency in the loop with different configurations. To capture the heterogeneity across multi-modal feedback, we categorize the sensory data into the periodic-feedback and event-triggered, respectively. We formulate timing constraints based on average and tail performance, covering timeliness, jitter, and reliability of CGC systems. A method based on saddlepoint approximation is proposed to obtain the distribution of closed-loop latency. The results show that the modified saddlepoint approximation is capable of accurately characterizing the latency distribution of the loop with analytically tractable expressions. This sets the basis for low-complexity co-design of communication and computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16047v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lintao Li, Anders E. Kal{\o}r, Petar Popovski, Wei Chen</dc:creator>
    </item>
    <item>
      <title>Secure Offloading in NOMA-Aided Aerial MEC Systems Based on Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.08579</link>
      <description>arXiv:2409.08579v2 Announce Type: replace 
Abstract: Mobile edge computing (MEC) technology can reduce user latency and energy consumption by offloading computationally intensive tasks to the edge servers. Unmanned aerial vehicles (UAVs) and non-orthogonal multiple access (NOMA) technology enable the MEC networks to provide offloaded computing services for massively accessed terrestrial users conveniently. However, the broadcast nature of signal propagation in NOMA-based UAV-MEC networks makes it vulnerable to eavesdropping by malicious eavesdroppers. In this work, a secure offload scheme is proposed for NOMA-based UAV-MEC systems with the existence of an aerial eavesdropper. The long-term average network computational cost is minimized by jointly designing the UAV's trajectory, the terrestrial users' transmit power, and computational frequency while ensuring the security of users' offloaded data. Due to the eavesdropper's location uncertainty, the worst-case security scenario is considered through the estimated eavesdropping range. Due to the high-dimensional continuous action space, the deep deterministic policy gradient algorithm is utilized to solve the non-convex optimization problem. Simulation results validate the effectiveness of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08579v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongjiang Lei, Mingxu Yang, Ki-Hong Park, Gaofeng Pan</dc:creator>
    </item>
    <item>
      <title>On the Second-Order Achievabilities of Indirect Quadratic Lossy Source Coding</title>
      <link>https://arxiv.org/abs/2410.08110</link>
      <description>arXiv:2410.08110v2 Announce Type: replace 
Abstract: This paper studies the second-order achievabilities of indirect quadratic lossy source coding for a specific class of source models, where the term "quadratic" denotes that the reconstruction fidelity of the hidden source is quantified by a squared error distortion measure. Specifically, it is assumed that the hidden source $S$ can be expressed as $S = \varphi(X) + W$, where $X$ is the observable source with alphabet $\mathcal{X}$, $\varphi(\cdot)$ is a deterministic function, and $W$ is a random variable independent of $X$, satisfying $\mathbb{E}[W] = 0$, $\mathbb{E}[W^2] &gt; 0$, $\mathbb{E}[W^3] = 0$, and $\mathbb{E}[W^6] &lt; \infty$. Additionally, both the set $\{\varphi(x):\ x \in \mathcal{X} \}$ and the reconstruction alphabet for $S$ are assumed to be bounded. Under the above settings, a second-order achievability bound is established using techniques based on distortion-tilted information. This result is then generalized to the case of indirect quadratic lossy source coding with observed source reconstruction, where reconstruction is required for both the hidden source $S$ and the observable source $X$, and the distortion measure for $X$ is not necessarily quadratic. These obtained bounds are consistent in form with their finite-alphabet counterparts, which have been proven to be second-order tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08110v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiyuan Yang, Xiaojun Yuan</dc:creator>
    </item>
    <item>
      <title>Geometry, Computation, and Optimality in Stochastic Optimization</title>
      <link>https://arxiv.org/abs/1909.10455</link>
      <description>arXiv:1909.10455v3 Announce Type: replace-cross 
Abstract: We study computational and statistical consequences of problem geometry in stochastic and online optimization. By focusing on constraint set and gradient geometry, we characterize the problem families for which stochastic- and adaptive-gradient methods are (minimax) optimal and, conversely, when nonlinear updates -- such as those mirror descent employs -- are necessary for optimal convergence. When the constraint set is quadratically convex, diagonally pre-conditioned stochastic gradient methods are minimax optimal. We provide quantitative converses showing that the ``distance'' of the underlying constraints from quadratic convexity determines the sub-optimality of subgradient methods. These results apply, for example, to any $\ell_p$-ball for $p &lt; 2$, and the computation/accuracy tradeoffs they demonstrate exhibit a striking analogy to those in Gaussian sequence models.</description>
      <guid isPermaLink="false">oai:arXiv.org:1909.10455v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Cheng, Daniel Levy, John C. Duchi</dc:creator>
    </item>
    <item>
      <title>Cone-Restricted Information Theory</title>
      <link>https://arxiv.org/abs/2206.04300</link>
      <description>arXiv:2206.04300v3 Announce Type: replace-cross 
Abstract: The max-relative entropy and the conditional min-entropy it induces have become central to one-shot information theory. Both may be expressed in terms of a conic program over the positive semidefinite cone. Recently, it was shown that the same conic program altered to be over the separable cone admits an operational interpretation in terms of communicating classical information over a quantum channel. In this work, we generalize this framework of replacing the cone to determine which results in quantum information theory rely upon the positive semidefinite cone and which can be generalized. We show the fully quantum Stein's lemma and asymptotic equipartition property break down if the cone exponentially increases in resourcefulness but never approximates the positive semidefinite cone. However, we show for CQ states, the separable cone is sufficient to recover the asymptotic theory, thereby drawing a strong distinction between the fully and partial quantum settings. We present parallel results for the extended conditional min-entropy. In doing so, we extend the notion of k-superpositive channels to superchannels. We also present operational uses of this framework. We first show the cone restricted min-entropy of a Choi operator captures a measure of entanglement-assisted noiseless classical communication using restricted measurements. We show that quantum majorization results naturally generalize to other cones. As a novel example, we introduce a new min-entropy-like quantity that captures the quantum majorization of quantum channels in terms of bistochastic pre-processing. Lastly, we relate this framework to general conic norms and their non-additivity. Throughout this work we emphasize the introduced measures' relationship to general convex resource theories. In particular, we look at both resource theories that capture locality and resource theories of coherence/Abelian symmetries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.04300v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1751-8121/ad52d5</arxiv:DOI>
      <dc:creator>Ian George, Eric Chitambar</dc:creator>
    </item>
    <item>
      <title>Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA</title>
      <link>https://arxiv.org/abs/2303.06198</link>
      <description>arXiv:2303.06198v2 Announce Type: replace-cross 
Abstract: This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum of $\boldsymbol{X}^\star$ into well-conditioned and mutually well-separated subblocks, and applies $\textsf{HeteroPCA}$ to conquer each subblock successively. Further, an application of our algorithm and theory to two canonical examples -- the factor model and tensor PCA -- leads to remarkable improvement for each application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.06198v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Zhou, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Markov chain entropy games and the geometry of their Nash equilibria</title>
      <link>https://arxiv.org/abs/2310.04115</link>
      <description>arXiv:2310.04115v2 Announce Type: replace-cross 
Abstract: Consider the following two-person mixed strategy game of a probabilist against Nature with respect to the parameters $(f, \mathcal{B},\pi)$, where $f$ is a convex function satisfying certain regularity conditions, $\mathcal{B}$ is either the set $\{L_i\}_{i=1}^n$ or its convex hull with each $L_i$ being a Markov infinitesimal generator on a finite state space $\mathcal{X}$ and $\pi$ is a given positive discrete distribution on $\mathcal{X}$. The probabilist chooses a prior measure $\mu$ within the set of probability measures on $\mathcal{B}$ denoted by $\mathcal{P}(\mathcal{B})$ and picks a $L \in \mathcal{B}$ at random according to $\mu$, whereas Nature follows a pure strategy to select $M \in \mathcal{L}(\pi)$, the set of $\pi$-reversible Markov generators on $\mathcal{X}$. Nature pays an amount $D_f(M||L)$, the $f$-divergence from $L$ to $M$, to the probabilist. We prove that a mixed strategy Nash equilibrium always exists, and establish a minimax result on the expected payoff of the game. This also contrasts with the pure strategy version of the game where we show a Nash equilibrium may not exist. To find approximately a mixed strategy Nash equilibrium, we propose and develop a simple projected subgradient algorithm that provably converges with a rate of $\mathcal{O}(1/\sqrt{t})$, where $t$ is the number of iterations. In addition, we elucidate the relationships of Nash equilibrium with other seemingly disparate notions such as weighted information centroid, Chebyshev center and Bayes risk. This article generalizes the two-person game of a statistician against Nature developed in the literature, and highlights the powerful interplay and synergy between modern Markov chains theory and geometry, information theory, game theory, optimization and mathematical statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04115v2</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Geoffrey Wolfer</dc:creator>
    </item>
    <item>
      <title>Statistical Inference with Limited Memory: A Survey</title>
      <link>https://arxiv.org/abs/2312.15225</link>
      <description>arXiv:2312.15225v2 Announce Type: replace-cross 
Abstract: The problem of statistical inference in its various forms has been the subject of decades-long extensive research. Most of the effort has been focused on characterizing the behavior as a function of the number of available samples, with far less attention given to the effect of memory limitations on performance. Recently, this latter topic has drawn much interest in the engineering and computer science literature. In this survey paper, we attempt to review the state-of-the-art of statistical inference under memory constraints in several canonical problems, including hypothesis testing, parameter estimation, and distribution property testing/estimation. We discuss the main results in this developing field, and by identifying recurrent themes, we extract some fundamental building blocks for algorithmic construction, as well as useful techniques for lower bound derivations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15225v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tomer Berg, Or Ordentlich, Ofer Shayevitz</dc:creator>
    </item>
    <item>
      <title>Diff-eRank: A Novel Rank-Based Metric for Evaluating Large Language Models</title>
      <link>https://arxiv.org/abs/2401.17139</link>
      <description>arXiv:2401.17139v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have transformed natural language processing and extended their powerful capabilities to multi-modal domains. As LLMs continue to advance, it is crucial to develop diverse and appropriate metrics for their evaluation. In this paper, we introduce a novel rank-based metric, Diff-eRank, grounded in information theory and geometry principles. Diff-eRank assesses LLMs by analyzing their hidden representations, providing a quantitative measure of how efficiently they eliminate redundant information during training. We demonstrate the applicability of Diff-eRank in both single-modal (e.g., language) and multi-modal settings. For language models, our results show that Diff-eRank increases with model size and correlates well with conventional metrics such as loss and accuracy. In the multi-modal context, we propose an alignment evaluation method based on the eRank, and verify that contemporary multi-modal LLMs exhibit strong alignment performance based on our method. Our code is publicly available at https://github.com/waltonfuture/Diff-eRank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17139v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lai Wei, Zhiquan Tan, Chenghai Li, Jindong Wang, Weiran Huang</dc:creator>
    </item>
    <item>
      <title>Matrix denoising: Bayes-optimal estimators via low-degree polynomials</title>
      <link>https://arxiv.org/abs/2402.16719</link>
      <description>arXiv:2402.16719v2 Announce Type: replace-cross 
Abstract: We consider the additive version of the matrix denoising problem, where a random symmetric matrix $S$ of size $n$ has to be inferred from the observation of $Y=S+Z$, with $Z$ an independent random matrix modeling a noise. For prior distributions of $S$ and $Z$ that are invariant under conjugation by orthogonal matrices we determine, using results from first and second order free probability theory, the Bayes-optimal (in terms of the mean square error) polynomial estimators of degree at most $D$, asymptotically in $n$, and show that as $D$ increases they converge towards the estimator introduced by Bun, Allez, Bouchaud and Potters in [IEEE Transactions on Information Theory 62, 7475 (2016)]. We conjecture that this optimality holds beyond strictly orthogonally invariant priors, and provide partial evidences of this universality phenomenon when $S$ is an arbitrary Wishart matrix and $Z$ is drawn from the Gaussian Orthogonal Ensemble, a case motivated by the related extensive rank matrix factorization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16719v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guilhem Semerjian</dc:creator>
    </item>
    <item>
      <title>The Minimax Rate of HSIC Estimation for Translation-Invariant Kernels</title>
      <link>https://arxiv.org/abs/2403.07735</link>
      <description>arXiv:2403.07735v2 Announce Type: replace-cross 
Abstract: Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal O\!\left(n^{-1/2}\right)$. Specifically, our result implies the optimality in the minimax sense of many of the most-frequently used estimators (including the U-statistic, the V-statistic, and the Nystr\"om-based one) on $\mathbb R^d$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07735v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Kalinke, Zoltan Szabo</dc:creator>
    </item>
    <item>
      <title>Decision Transformers for Wireless Communications: A New Paradigm of Resource Management</title>
      <link>https://arxiv.org/abs/2404.05199</link>
      <description>arXiv:2404.05199v2 Announce Type: replace-cross 
Abstract: As the next generation of mobile systems evolves, artificial intelligence (AI) is expected to deeply integrate with wireless communications for resource management in variable environments. In particular, deep reinforcement learning (DRL) is an important tool for addressing stochastic optimization issues of resource allocation. However, DRL has to start each new training process from the beginning once the state and action spaces change, causing low sample efficiency and poor generalization ability. Moreover, each DRL training process may take a large number of epochs to converge, which is unacceptable for time-sensitive scenarios. In this paper, we adopt an alternative AI technology, namely, Decision Transformer (DT), and propose a DT-based adaptive decision architecture for wireless resource management. This architecture innovates through constructing pre-trained models in the cloud and then fine-tuning personalized models at the edges. By leveraging the power of DT models learned over offline datasets, the proposed architecture is expected to achieve rapid convergence with many fewer training epochs and higher performance in new scenarios with different state and action spaces, compared with DRL. We then design DT frameworks for two typical communication scenarios: intelligent reflecting surfaces-aided communications and unmanned aerial vehicle-aided mobile edge computing. Simulations demonstrate that the proposed DT frameworks achieve over $3$-$6$ times speedup in convergence and better performance relative to the classic DRL method, namely, proximal policy optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05199v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Zhang, Jun Li, Long Shi, Zhe Wang, Shi Jin, Wen Chen, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>A polynomial-time classical algorithm for noisy quantum circuits</title>
      <link>https://arxiv.org/abs/2407.12768</link>
      <description>arXiv:2407.12768v2 Announce Type: replace-cross 
Abstract: We provide a polynomial-time classical algorithm for noisy quantum circuits. The algorithm computes the expectation value of any observable for any circuit, with a small average error over input states drawn from an ensemble (e.g. the computational basis). Our approach is based upon the intuition that noise exponentially damps non-local correlations relative to local correlations. This enables one to classically simulate a noisy quantum circuit by only keeping track of the dynamics of local quantum information. Our algorithm also enables sampling from the output distribution of a circuit in quasi-polynomial time, so long as the distribution anti-concentrates. A number of practical implications are discussed, including a fundamental limit on the efficacy of noise mitigation strategies: for constant noise rates, any quantum circuit for which error mitigation is efficient on most input states, is also classically simulable on most input states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12768v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>physics.atom-ph</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Schuster, Chao Yin, Xun Gao, Norman Y. Yao</dc:creator>
    </item>
    <item>
      <title>Generalized Measures of Anticipation and Responsivity in Online Language Processing</title>
      <link>https://arxiv.org/abs/2409.10728</link>
      <description>arXiv:2409.10728v2 Announce Type: replace-cross 
Abstract: We introduce a generalization of classic information-theoretic measures of predictive uncertainty in online language processing, based on the simulation of expected continuations of incremental linguistic contexts. Our framework provides a formal definition of anticipatory and responsive measures, and it equips experimenters with the tools to define new, more expressive measures beyond standard next-symbol entropy and surprisal. While extracting these standard quantities from language models is convenient, we demonstrate that using Monte Carlo simulation to estimate alternative responsive and anticipatory measures pays off empirically: New special cases of our generalized formula exhibit enhanced predictive power compared to surprisal for human cloze completion probability as well as ELAN, LAN, and N400 amplitudes, and greater complementarity with surprisal in predicting reading times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10728v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Giulianelli, Andreas Opedal, Ryan Cotterell</dc:creator>
    </item>
    <item>
      <title>Sharp estimates for Gowers norms on discrete cubes</title>
      <link>https://arxiv.org/abs/2409.12579</link>
      <description>arXiv:2409.12579v2 Announce Type: replace-cross 
Abstract: We study optimal dimensionless inequalities $$ \|f\|_{U^k} \leq \|f\|_{\ell^{p_{k,n}}} $$ that hold for all functions $f\colon\mathbb{Z}^d\to\mathbb{C}$ supported in $\{0,1,\ldots,n-1\}^d$ and estimates $$ \|1_A\|_{U^k}^{2^k}\leq |A|^{t_{k,n}} $$ that hold for all subsets $A$ of the same discrete cubes. A general theory, analogous to the work of de Dios Pont, Greenfeld, Ivanisvili, and Madrid, is developed to show that the critical exponents are related by $p_{k,n} t_{k,n} = 2^k$. This is used to prove the three main results of the paper: an explicit formula for $t_{k,2}$, which generalizes a theorem by Kane and Tao, two-sided asymptotic estimates for $t_{k,n}$ as $n\to\infty$ for a fixed $k\geq2$, which generalize a theorem by Shao, and a precise asymptotic formula for $t_{k,n}$ as $k\to\infty$ for a fixed $n\geq2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12579v2</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.CA</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Beker, Ton\'ci Crmari\'c, Vjekoslav Kova\v{c}</dc:creator>
    </item>
  </channel>
</rss>
