<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 02:38:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the performance of sequential Bayesian update for database of diverse tsunami scenarios</title>
      <link>https://arxiv.org/abs/2407.03631</link>
      <description>arXiv:2407.03631v1 Announce Type: new 
Abstract: Although the sequential tsunami scenario detection framework was validated in our previous work, several tasks remain to be resolved from a practical point of view. This study aims to evaluate the performance of the previous tsunami scenario detection framework using a diverse database consisting of complex fault rupture patterns with heterogeneous slip distributions. Specifically, we compare the effectiveness of scenario superposition to that of the previous most likely scenario detection method. Additionally, how the length of the observation time window influences the accuracy of both methods is analyzed. We utilize an existing database comprising 1771 tsunami scenarios targeting the city Westport (WA, U.S.), which includes synthetic wave height records and inundation distributions as the result of fault rupture in the Cascadia subduction zone. The heterogeneous patterns of slips used in the database increase the diversity of the scenarios and thus make it a proper database for evaluating the performance of scenario superposition. To assess the performance, we consider various observation time windows shorter than 15 minutes and divide the database into five testing and learning sets. The evaluation accuracy of the maximum offshore wave, inundation depth, and its distribution is analyzed to examine the advantages of the scenario superposition method over the previous method. We introduce the dynamic time warping (DTW) method as an additional benchmark and compare its results to that of the Bayesian scenario detection method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03631v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reika Nomura, Louise A. Hirao Vermare, Saneiki Fujita, Donsub Rim, Shuji Moriguchi, Randall J. LeVeque, Kenjiro Terada</dc:creator>
    </item>
    <item>
      <title>Treatment of near-incompressibility and volumetric locking in higher order material point methods</title>
      <link>https://arxiv.org/abs/2407.03826</link>
      <description>arXiv:2407.03826v1 Announce Type: new 
Abstract: We propose a novel projection method to treat near-incompressibility and volumetric locking in small- and large-deformation elasticity and plasticity within the context of higher order material point methods. The material point method is well known to exhibit volumetric locking due to the presence of large numbers of material points per element that are used to decrease the quadrature error. Although there has been considerable research on the treatment of near-incompressibility in the traditional material point method, the issue has not been studied in depth for higher order material point methods. Using the Bbar and Fbar methods as our point of departure we develop an appropriate projection technique for material point methods that use higher order shape functions for the background discretization. The approach is based on the projection of the dilatational part of the appropriate strain rate measure onto a lower dimensional approximation space, according to the traditional Bbar and Fbar techniques, but tailored to the material point method. The presented numerical examples exhibit reduced stress oscillations and are free of volumetric locking and hourglassing phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03826v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2022.114985</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering 395 (2022) 114985</arxiv:journal_reference>
      <dc:creator>Ram Mohan Telikicherla, Georgios Moutsanidis</dc:creator>
    </item>
    <item>
      <title>TwinLab: a framework for data-efficient training of non-intrusive reduced-order models for digital twins</title>
      <link>https://arxiv.org/abs/2407.03924</link>
      <description>arXiv:2407.03924v1 Announce Type: new 
Abstract: Purpose: Simulation-based digital twins represent an effort to provide high-accuracy real-time insights into operational physical processes. However, the computation time of many multi-physical simulation models is far from real-time. It might even exceed sensible time frames to produce sufficient data for training data-driven reduced-order models. This study presents TwinLab, a framework for data-efficient, yet accurate training of neural-ODE type reduced-order models with only two data sets. Design/methodology/approach: Correlations between test errors of reduced-order models and distinct features of corresponding training data are investigated. Having found the single best data sets for training, a second data set is sought with the help of similarity and error measures to enrich the training process effectively. Findings: Adding a suitable second training data set in the training process reduces the test error by up to 49% compared to the best base reduced-order model trained only with one data set. Such a second training data set should at least yield a good reduced-order model on its own and exhibit higher levels of dissimilarity to the base training data set regarding the respective excitation signal. Moreover, the base reduced-order model should have elevated test errors on the second data set. The relative error of the time series ranges from 0.18% to 0.49%. Prediction speed-ups of up to a factor of 36,000 are observed. Originality: The proposed computational framework facilitates the automated, data-efficient extraction of non-intrusive reduced-order models for digital twins from existing simulation models, independent of the simulation software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03924v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1108/EC-11-2023-0855</arxiv:DOI>
      <dc:creator>Maximilian Kannapinn, Michael Sch\"afer, Oliver Weeger</dc:creator>
    </item>
    <item>
      <title>Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing</title>
      <link>https://arxiv.org/abs/2407.04031</link>
      <description>arXiv:2407.04031v1 Announce Type: new 
Abstract: Machine learning (ML)-based monitoring systems have been extensively developed to enhance the print quality of additive manufacturing (AM). In-situ and in-process data acquired using sensors can be used to train ML models that detect process anomalies, predict part quality, and adjust process parameters. However, the reproducibility of the proposed AM monitoring systems has not been investigated. There has not been a method to evaluate and improve reproducibility in the joint domain of AM and ML. Consequently, some crucial information for reproducing the research is usually missing from the publications; thus, systems reproduced based on the publications often cannot achieve the claimed performance. This paper establishes the definition of reproducibility in this domain, proposes a reproducibility investigation pipeline, and composes a reproducibility checklist. A research is reproducible if a performance comparable to the original research can be obtained when reproduced by a different team using a different experiment setup. The reproducibility investigation pipeline sequentially guides the readers through all the necessary reproduction steps, during which the reproducibility checklist will help extract the reproducibility information from the publication. A case study that reproduced a vision-based warping detection system demonstrated the usage and validated the efficacy of the proposed pipeline and checklist. It has been observed that the reproducibility checklist can help the authors verify that all the information critical to reproducibility is provided in the publications. The investigation pipeline can help identify the missing reproducibility information, which should be acquired from the original authors to achieve the claimed performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04031v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiarui Xie, Mutahar Safdar, Andrei Mircea, Yan Lu, Hyunwoong Ko, Zhuo Yang, Yaoyao Fiona Zhao</dc:creator>
    </item>
    <item>
      <title>Finite Operator Learning: Bridging Neural Operators and Numerical Methods for Efficient Parametric Solution and Optimization of PDEs</title>
      <link>https://arxiv.org/abs/2407.04157</link>
      <description>arXiv:2407.04157v1 Announce Type: new 
Abstract: We introduce a method that combines neural operators, physics-informed machine learning, and standard numerical methods for solving PDEs. The proposed approach extends each of the aforementioned methods and unifies them within a single framework. We can parametrically solve partial differential equations in a data-free manner and provide accurate sensitivities, meaning the derivatives of the solution space with respect to the design space. These capabilities enable gradient-based optimization without the typical sensitivity analysis costs, unlike adjoint methods that scale directly with the number of response functions. Our Finite Operator Learning (FOL) approach uses an uncomplicated feed-forward neural network model to directly map the discrete design space (i.e. parametric input space) to the discrete solution space (i.e. finite number of sensor points in the arbitrary shape domain) ensuring compliance with physical laws by designing them into loss functions. The discretized governing equations, as well as the design and solution spaces, can be derived from any well-established numerical techniques. In this work, we employ the Finite Element Method (FEM) to approximate fields and their spatial derivatives. Subsequently, we conduct Sobolev training to minimize a multi-objective loss function, which includes the discretized weak form of the energy functional, boundary conditions violations, and the stationarity of the residuals with respect to the design variables. Our study focuses on the steady-state heat equation within heterogeneous materials that exhibits significant phase contrast and possibly temperature-dependent conductivity. The network's tangent matrix is directly used for gradient-based optimization to improve the microstructure's heat transfer characteristics. ...</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04157v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shahed Rezaei, Reza Najian Asl, Kianoosh Taghikhani, Ahmad Moeineddin, Michael Kaliske, Markus Apel</dc:creator>
    </item>
    <item>
      <title>Statistical reduced order modelling for the parametric Helmholtz equation</title>
      <link>https://arxiv.org/abs/2407.04438</link>
      <description>arXiv:2407.04438v1 Announce Type: new 
Abstract: Predictive modeling involving simulation and sensor data at the same time, is a growing challenge in computational science. Even with large-scale finite element models, a mismatch to the sensor data often remains, which can be attributed to different sources of uncertainty. For such a scenario, the statistical finite element method (statFEM) can be used to condition a simulated field on given sensor data. This yields a posterior solution which resembles the data much better and additionally provides consistent estimates of uncertainty, including model misspecification. For frequency or parameter dependent problems, occurring, e.g. in acoustics or electromagnetism, solving the full order model at the frequency grid and conditioning it on data quickly results in a prohibitive computational cost. In this case, the introduction of a surrogate in form of a reduced order model yields much smaller systems of equations. In this paper, we propose a reduced order statFEM framework relying on Krylov-based moment matching. We introduce a data model which explicitly includes the bias induced by the reduced approximation, which is estimated by an inexpensive error indicator. The results of the new statistical reduced order method are compared to the standard statFEM procedure applied to a ROM prior, i.e. without explicitly accounting for the reduced order bias. The proposed method yields better accuracy and faster convergence throughout a given frequency range for different numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04438v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Hermann, Matthias Bollh\"ofer, Ulrich R\"omer</dc:creator>
    </item>
    <item>
      <title>C-ShipGen: A Conditional Guided Diffusion Model for Parametric Ship Hull Design</title>
      <link>https://arxiv.org/abs/2407.03333</link>
      <description>arXiv:2407.03333v1 Announce Type: cross 
Abstract: Ship design is a complex design process that may take a team of naval architects many years to complete. Improving the ship design process can lead to significant cost savings, while still delivering high-quality designs to customers. A new technology for ship hull design is diffusion models, a type of generative artificial intelligence. Prior work with diffusion models for ship hull design created high-quality ship hulls with reduced drag and larger displaced volumes. However, the work could not generate hulls that meet specific design constraints. This paper proposes a conditional diffusion model that generates hull designs given specific constraints, such as the desired principal dimensions of the hull. In addition, this diffusion model leverages the gradients from a total resistance regression model to create low-resistance designs. Five design test cases compared the diffusion model to a design optimization algorithm to create hull designs with low resistance. In all five test cases, the diffusion model was shown to create diverse designs with a total resistance less than the optimized hull, having resistance reductions over 25%. The diffusion model also generated these designs without retraining. This work can significantly reduce the design cycle time of ships by creating high-quality hulls that meet user requirements with a data-driven approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03333v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah J. Bagazinski, Faez Ahmed</dc:creator>
    </item>
    <item>
      <title>AI Driven Laser Parameter Search: Inverse Design of Photonic Surfaces using Greedy Surrogate-based Optimization</title>
      <link>https://arxiv.org/abs/2407.03356</link>
      <description>arXiv:2407.03356v1 Announce Type: cross 
Abstract: Photonic surfaces designed with specific optical characteristics are becoming increasingly important for use in in various energy harvesting and storage systems. , In this study, we develop a surrogate-based optimization approach for designing such surfaces. The surrogate-based optimization framework employs the Random Forest algorithm and uses a greedy, prediction-based exploration strategy to identify the laser fabrication parameters that minimize the discrepancy relative to a user-defined target optical characteristics. We demonstrate the approach on two synthetic benchmarks and two specific cases of photonic surface inverse design targets. It exhibits superior performance when compared to other optimization algorithms across all benchmarks. Additionally, we demonstrate a technique of inverse design warm starting for changed target optical characteristics which enhances the performance of the introduced approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03356v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.app-ph</category>
      <category>physics.optics</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luka Grbcic, Minok Park, Juliane M\"uller, Vassilia Zorba, Wibe Albert de Jong</dc:creator>
    </item>
    <item>
      <title>Topological Separation of Vortices</title>
      <link>https://arxiv.org/abs/2407.03384</link>
      <description>arXiv:2407.03384v1 Announce Type: cross 
Abstract: Vortices and their analysis play a critical role in the understanding of complex phenomena in turbulent flows. Traditional vortex extraction methods, notably region-based techniques, often overlook the entanglement phenomenon, resulting in the inclusion of multiple vortices within a single extracted region. Their separation is necessary for quantifying different types of vortices and their statistics. In this study, we propose a novel vortex separation method that extends the conventional contour tree-based segmentation approach with an additional step termed "layering". Upon extracting a vortical region using specified vortex criteria (e.g., $\lambda_2$), we initially establish topological segmentation based on the contour tree, followed by the layering process to allocate appropriate segmentation IDs to unsegmented cells, thus separating individual vortices within the region. However, these regions may still suffer from inaccurate splits, which we address statistically by leveraging the continuity of vorticity lines across the split boundaries. Our findings demonstrate a significant improvement in both the separation of vortices and the mitigation of inaccurate splits compared to prior methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03384v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adeel Zafar, Zahra Poorshayegh, Di Yang, Guoning Chen</dc:creator>
    </item>
    <item>
      <title>Block-diagonal idiosyncratic covariance estimation in high-dimensional factor models for financial time series</title>
      <link>https://arxiv.org/abs/2407.03781</link>
      <description>arXiv:2407.03781v1 Announce Type: cross 
Abstract: Estimation of high-dimensional covariance matrices in latent factor models is an important topic in many fields and especially in finance. Since the number of financial assets grows while the estimation window length remains of limited size, the often used sample estimator yields noisy estimates which are not even positive definite. Under the assumption of latent factor models, the covariance matrix is decomposed into a common low-rank component and a full-rank idiosyncratic component. In this paper we focus on the estimation of the idiosyncratic component, under the assumption of a grouped structure of the time series, which may arise due to specific factors such as industries, asset classes or countries. We propose a generalized methodology for estimation of the block-diagonal idiosyncratic component by clustering the residual series and applying shrinkage to the obtained blocks in order to ensure positive definiteness. We derive two different estimators based on different clustering methods and test their performance using simulation and historical data. The proposed methods are shown to provide reliable estimates and outperform other state-of-the-art estimators based on thresholding methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03781v1</guid>
      <category>q-fin.ST</category>
      <category>cs.CE</category>
      <category>q-fin.MF</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jocs.2024.102348</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Science, Volume 81, 2024, 102348</arxiv:journal_reference>
      <dc:creator>Lucija \v{Z}igni\'c, Stjepan Begu\v{s}i\'c, Zvonko Kostanj\v{c}ar</dc:creator>
    </item>
    <item>
      <title>Computational Graph Representation of Equations System Constructors in Hierarchical Circuit Simulation</title>
      <link>https://arxiv.org/abs/2407.04206</link>
      <description>arXiv:2407.04206v1 Announce Type: cross 
Abstract: Equations system constructors of hierarchical circuits play a central role in device modeling, nonlinear equations solving, and circuit design automation. However, existing constructors present limitations in applications to different extents. For example, the costs of developing and reusing device models -- especially coarse-grained equivalent models of circuit modules -- remain high while parameter sensitivity analysis is complex and inefficient. Inspired by differentiable programming and leveraging the ecosystem benefits of open-source software, we propose an equations system constructor using the computational graph representation, along with its JSON format netlist, to address these limitations. This representation allows for runtime dependencies between signals and subcircuit/device parameters. The proposed method streamlines the model development process and facilitates end-to-end computation of gradients of equations remainders with respect to parameters. This paper discusses in detail the overarching concept of hierarchical subcircuit/device decomposition and nested invocation by drawing parallels to functions in programming languages, and introduces rules for parameters passing and gradient propagation across hierarchical circuit modules. The presented numerical examples, including (1) an uncoupled CMOS model representation using "equivalent circuit decomposition+dynamic parameters" and (2) operational amplifier (OpAmp) auto device sizing, have demonstrated that the proposed method supports circuit simulation and design and particularly subcircuit modeling with improved efficiency, simplicity, and decoupling compared to existing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04206v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zichao Long, Lin Li, Lei Han, Xianglong Meng, Chongjun Ding, Ruiyan Li, Wu Jiang, Fuchen Ding, Jiaqing Yue, Zhichao Li, Yisheng Hu, Ding Li, Heng Liao</dc:creator>
    </item>
    <item>
      <title>Design Tasks and Their Complexity for the European Train Control System with Hybrid Train Detection</title>
      <link>https://arxiv.org/abs/2308.02572</link>
      <description>arXiv:2308.02572v2 Announce Type: replace-cross 
Abstract: Railway networks have become increasingly important in recent times, especially to move freight and public transportation from road traffic and planes to more environmentally friendly trains. Since expanding the global railway network is time and resource-consuming, maximizing the rail capacity on the existing infrastructure is desirable. However, simply running more trains is infeasible as certain constraints enforced by the train control system must be satisfied. The capacity of a network depends (amongst others) on the distance between trains allowed by this safety system. While most signaling systems rely on fixed blocks defined by costly hardware, new specifications provided by Level 2 with Hybrid Train Detection of the European Train Control System (ETCS L2 HTD), formerly known as ETCS Hybrid Level 3, allow the usage of virtual subsections. This additional degree of freedom allows for shorter train following times and, thus, more trains on existing railway tracks. On the other hand, new design tasks arise on which automated methods might be helpful for designers of modern railway networks. However, although first approaches exist that solve design problems arising within ETCS L2 HTD, neither formal descriptions nor results on the computational complexity of the corresponding design tasks exist. In this paper, we fill this gap by providing a formal description of design tasks for ETCS L2 HTD and proof that these tasks are NP-complete or NP-hard, respectively. By that, we are providing a solid basis for the future development of methods to solve those tasks, which will be integrated into the Munich Train Control Toolkit available open-source on GitHub at https://github.com/cda-tum/mtct.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02572v2</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Engels, Tom Peham, Judith Przigoda, Nils Przigoda, Robert Wille</dc:creator>
    </item>
    <item>
      <title>Evaluation of Activated Sludge Settling Characteristics from Microscopy Images with Deep Convolutional Neural Networks and Transfer Learning</title>
      <link>https://arxiv.org/abs/2402.09367</link>
      <description>arXiv:2402.09367v3 Announce Type: replace-cross 
Abstract: Microbial communities play a key role in biological wastewater treatment processes. Activated sludge settling characteristics, for example, are affected by microbial community composition, varying by changes in operating conditions and influent characteristics of wastewater treatment plants (WWTPs). Timely assessment and prediction of changes in microbial composition leading to settling problems, such as filamentous bulking (FB), can prevent operational challenges, reductions in treatment efficiency, and adverse environmental impacts. This study presents an innovative computer vision-based approach to assess activated sludge-settling characteristics based on the morphological properties of flocs and filaments in microscopy images. Implementing the transfer learning of deep convolutional neural network (CNN) models, this approach aims to overcome the limitations of existing quantitative image analysis techniques. The offline microscopy image dataset was collected over two years, with weekly sampling at a full-scale industrial WWTP in Belgium. Multiple data augmentation techniques were employed to enhance the generalizability of the CNN models. Various CNN architectures, including Inception v3, ResNet18, ResNet152, ConvNeXt-nano, and ConvNeXt-S, were tested to evaluate their performance in predicting sludge settling characteristics. The sludge volume index was used as the final prediction variable, but the method can easily be adjusted to predict any other settling metric of choice. The results showed that the suggested CNN-based approach provides less labour-intensive, objective, and consistent assessments, while transfer learning notably minimises the training phase, resulting in a generalizable system that can be employed in real-time applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09367v3</guid>
      <category>cs.CV</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jwpe.2024.105692</arxiv:DOI>
      <dc:creator>Sina Borzooei, Leonardo Scabini, Gisele Miranda, Saba Daneshgar, Lukas Deblieck, Piet De Langhe, Odemir Bruno, Bernard De Baets, Ingmar Nopens, Elena Torfs</dc:creator>
    </item>
    <item>
      <title>Diversity in Evolutionary Dynamics</title>
      <link>https://arxiv.org/abs/2406.03938</link>
      <description>arXiv:2406.03938v2 Announce Type: replace-cross 
Abstract: We consider the dynamics imposed by natural selection on the populations of two competing, sexually reproducing, haploid species. In this setting, the fitness of any genome varies over time due to the changing population mix of the competing species; crucially, this fitness variation arises naturally from the model itself, without the need for imposing it exogenously as is typically the case. Previous work on this model [14] showed that, in the special case where each of the two species exhibits just two phenotypes, genetic diversity is maintained at all times. This finding supported the tenet that sexual reproduction is advantageous because it promotes diversity, which increases the survivability of a species.
  In the present paper we consider the more realistic case where there are more than two phenotypes available to each species. The conclusions about diversity in general turn out to be very different from the two-phenotype case.
  Our first result is negative: namely, we show that sexual reproduction does not guarantee the maintenance of diversity at all times, i.e., the result of [14] does not generalize. Our counterexample consists of two competing species with just three phenotypes each. We show that, for any time~$t_0$ and any $\varepsilon&gt;0$, there is a time $t\ge t_0$ at which the combined diversity of both species is smaller than~$\varepsilon$. Our main result is a complementary positive statement, which says that in any non-degenerate example, diversity is maintained in a weaker, "infinitely often" sense.
  Thus, our results refute the supposition that sexual reproduction ensures diversity at all times, but affirm a weaker assertion that extended periods of high diversity are necessarily a recurrent event.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03938v2</guid>
      <category>q-bio.PE</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuval Rabani, Leonard J. Schulman, Alistair Sinclair</dc:creator>
    </item>
  </channel>
</rss>
