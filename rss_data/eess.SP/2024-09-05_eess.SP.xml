<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 01:38:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Target Detection in Sea Clutter with Application to Spaceborne SAR Imaging</title>
      <link>https://arxiv.org/abs/2409.02155</link>
      <description>arXiv:2409.02155v1 Announce Type: new 
Abstract: In this paper, the challenging task of target detection in sea clutter is addressed. We analyze the statistical properties of the signals received from the scene and based on that, we model the amplitude of the signals reflected from the sea clutter according to the Weibull distribution. Subsequently, we utilize the aforementioned information to design an adaptive threshold based on the Constant False Alarm Rate (CFAR) algorithm to detect the energy of the targets which have been buried in the sea clutter.
  Thorough analysis of the experimental data gathered from the Canadian RADARSAT-1 satellite demonstrates the overall effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02155v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shahrokh Hamidi</dc:creator>
    </item>
    <item>
      <title>Optimizing Multi-User Uplink Cooperative Rate-Splitting Multiple Access: Efficient User Pairing and Resource Allocation</title>
      <link>https://arxiv.org/abs/2409.02276</link>
      <description>arXiv:2409.02276v1 Announce Type: new 
Abstract: This paper investigates joint user pairing, power and time slot duration allocation in the uplink multiple-input single-output (MISO) multi-user cooperative rate-splitting multiple access (C-RSMA) networks in half-duplex (HD) mode. We assume two types of users: cell-center users (CCU) and cell-edge users (CEU); first, we propose a user pairing scheme utilizing a semi-orthogonal user selection (SUS) and a matching-game (MG)-based approach where the SUS algorithm is used to select CCU in each pair which assists in reducing inter-pair interference (IPI). Afterward, the CEU in each pair is selected by considering the highest channel gain between CCU and CEU. After pairing is performed, the communication takes place in two phases: in the first phase, in a given pair, CEUs broadcast their signal, which is received by the base station (BS) and CCUs. In the second phase, in a given pair, the CCU decodes the signal from its paired CEU, superimposes its own signal, and transmits it to the BS. We formulate a joint optimization problem in order to maximize the sum rate subject to the constraints of the power budget of the user equipment (UE) and Quality of Service (QoS) requirements at each UE. Since the formulated optimization problem is non-convex, we adopt a bi-level optimization to make the problem tractable. We decompose the original problem into two sub-problems: the user pairing sub-problem and the resource allocation sub-problem where user pairing sub-problem is independent of resource allocation sub-problem and once pairs are identified, resource allocation sub-problem is solved for a given pair. Resource allocation sub-problem is solved by invoking a successive convex approximation (SCA)-based approach. Simulation results demonstrate that the proposed SUS-MG-based algorithm with SCA outperforms other conventional schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02276v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreya Khisa, Mohamad Elhattab, Chadi Assi, Sanaa Sharafeddine</dc:creator>
    </item>
    <item>
      <title>Transfer-based Adversarial Poisoning Attacks for Online (MIMO-)Deep Receviers</title>
      <link>https://arxiv.org/abs/2409.02430</link>
      <description>arXiv:2409.02430v2 Announce Type: new 
Abstract: Recently, the design of wireless receivers using deep neural networks (DNNs), known as deep receivers, has attracted extensive attention for ensuring reliable communication in complex channel environments. To adapt quickly to dynamic channels, online learning has been adopted to update the weights of deep receivers with over-the-air data (e.g., pilots). However, the fragility of neural models and the openness of wireless channels expose these systems to malicious attacks. To this end, understanding these attack methods is essential for robust receiver design. In this paper, we propose a transfer-based adversarial poisoning attack method for online receivers.Without knowledge of the attack target, adversarial perturbations are injected to the pilots, poisoning the online deep receiver and impairing its ability to adapt to dynamic channels and nonlinear effects. In particular, our attack method targets Deep Soft Interference Cancellation (DeepSIC)[1] using online meta-learning. As a classical model-driven deep receiver, DeepSIC incorporates wireless domain knowledge into its architecture. This integration allows it to adapt efficiently to time-varying channels with only a small number of pilots, achieving optimal performance in a multi-input and multi-output (MIMO) scenario.The deep receiver in this scenario has a number of applications in the field of wireless communication, which motivates our study of the attack methods targeting it.Specifically, we demonstrate the effectiveness of our attack in simulations on synthetic linear, synthetic nonlinear, static, and COST 2100 channels. Simulation results indicate that the proposed poisoning attack significantly reduces the performance of online receivers in rapidly changing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02430v2</guid>
      <category>eess.SP</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunze Wu, Weiheng Jiang, Dusit Niyato, Yinghuan Li, Chuang Luo</dc:creator>
    </item>
    <item>
      <title>FDA-MIMO-Based Integrated Sensing and Communication System with Complex Coefficients Index Modulation for Multi-Target Sensing</title>
      <link>https://arxiv.org/abs/2409.02447</link>
      <description>arXiv:2409.02447v1 Announce Type: new 
Abstract: The echo signals of frequency diverse array multiple-input multiple-output (FDA-MIMO) feature angle-range coupling, enabling simultaneous discrimination and estimation of multiple targets at different locations. In light of this, based on FDA-MIMO, this paper explores an sensing-centric integrated sensing and communication (ISAC) system for multi-target sensing. On the transmitter side, the complex coefficients index modulation (CCIM) scheme is designed, which carries extra bits by selecting complex coefficients from the coefficient vector. At the sensing receiver, we propose the FDA-MIMO-based spatial spectrum multi-target estimation (SSMTE) method, which first jointly estimates the angle and distance of targets and then estimates the velocities. To reduce the sensing computational complexity, the low-complexity spatial spectrum estimation (LCSSE) algorithm is proposed. LCSSE reduces the complexity without degrading the sensing performance by converting the joint angle-range search into two one-dimensional searches. To address the range ambiguity caused by frequency offset, a frequency offset design criterion (FODC) is proposed. It designs the integer and fractional components of the frequency offset to ensure the ambiguity distance exceeds the maximum sensing range, thereby alleviating parameters pairing errors. Moreover, the closed-form expressions for the bit error rate (BER) tight upper bound and the Cram\'er-Rao bound (CRB) are derived. Simulation results show that the proposed system excels in multi-target sensing and communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02447v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiangwei Jian, Bang Huang, Wenkai Jia, Mingcheng Fu, Wen-Qin Wang, Qimao Huang</dc:creator>
    </item>
    <item>
      <title>Nonlinear Precoding in the RIS-Aided MIMO Broadcast Channel</title>
      <link>https://arxiv.org/abs/2409.02464</link>
      <description>arXiv:2409.02464v1 Announce Type: new 
Abstract: We propose to use Tomlinson-Harashima Precoding (THP) for the reconfigurable intelligent surface (RIS)-aided multiple-input multiple-output (MIMO) broadcast channel where we assume a line of sight (LOS) connection between the base station (BS) and the RIS. In this scenario, nonlinear precoding, like THP or dirty paper coding (DPC), has certain advantages compared to linear precoding as it is more robust in case the BS-RIS channel is not orthogonal to the direct channel. Additionally, THP and DPC allow a simple phase shift optimization which is in strong contrast to linear precoding for which the solution is quite intricate. Besides being difficult to optimize, it can be shown that linear precoding has fundamental limitations for statistical and random phase shifts which do not hold for nonlinear precoding. Moreover, we show that the advantages of THP/DPC are especially pronounced for discrete phase shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02464v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Semmler, Michael Joham, Wolfgang Utschick</dc:creator>
    </item>
    <item>
      <title>Rate-Adaptive Generative Semantic Communication Using Conditional Diffusion Models</title>
      <link>https://arxiv.org/abs/2409.02597</link>
      <description>arXiv:2409.02597v1 Announce Type: new 
Abstract: Recent advances in deep learning-based joint source-channel coding (DJSCC) have shown promise for end-to-end semantic image transmission. However, most existing schemes primarily focus on optimizing pixel-wise metrics, which often fail to align with human perception, leading to lower perceptual quality. In this letter, we propose a novel generative DJSCC approach using conditional diffusion models to enhance the perceptual quality of transmitted images. Specifically, by utilizing entropy models, we effectively manage transmission bandwidth based on the estimated entropy of transmitted sym-bols. These symbols are then used at the receiver as conditional information to guide a conditional diffusion decoder in image reconstruction. Our model is built upon the emerging advanced mamba-like linear attention (MLLA) skeleton, which excels in image processing tasks while also offering fast inference speed. Besides, we introduce a multi-stage training strategy to ensure the stability and improve the overall performance of the model. Simulation results demonstrate that our proposed method significantly outperforms existing approaches in terms of perceptual quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02597v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pujing Yang, Guangyi Zhang, Yunlong Cai</dc:creator>
    </item>
    <item>
      <title>Non-Orthogonal Multiple-Access Strategies for Direct-to-Satellite IoT Networks</title>
      <link>https://arxiv.org/abs/2409.02748</link>
      <description>arXiv:2409.02748v1 Announce Type: new 
Abstract: Direct-to-Satellite IoT (DtS-IoT) has the potential to support multiple verticals, including agriculture, industry, smart cities, and environmental disaster prevention. This work introduces two novel DtS-IoT schemes using power domain NonOrthogonal Multiple Access (NOMA) in the uplink with either fixed (FTP) or controlled (CTP) transmit power. We consider that the IoT devices use LoRa technology to transmit data packets to the satellite in orbit, equipped with a Successive Interference Cancellation (SIC)-enabled gateway. We also assume the IoT devices are empowered with a predictor of the satellite orbit. Using real geographic location and trajectory data, we evaluate the performance of the average number of successfully decoded transmissions, goodput (bytes/lap), and energy consumption (bytes/Joule) as a function of the number of network devices. Numerical results show the trade-off between goodput and energy efficiency for both proposed schemes. Comparing FTP and CTP with regular ALOHA for 100 (600) devices, we find goodput improvements of 65% (29%) and 52% (101%), respectively. Notably, CTP effectively leverages transmission opportunities as the network size increases, outperforming the other strategies. Moreover, CTP shows the best performance in energy efficiency compared to FTP and ALOHA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02748v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Augusto Tondo, Jean Michel de Souza Sant'Ana, Samuel Montejo-S\'anchez, Onel Luis Alcaraz L\'opez, Sandra C\'espedes, Richard Demo Souza</dc:creator>
    </item>
    <item>
      <title>A Novel Interference Minimizing Waveform for Wireless Channels with Fractional Delay: Inter-block Interference Analysis</title>
      <link>https://arxiv.org/abs/2409.02785</link>
      <description>arXiv:2409.02785v1 Announce Type: new 
Abstract: In the physical layer (PHY) of modern cellular systems, information is transmitted as a sequence of resource blocks (RBs) across various domains with each resource block limited to a certain time and frequency duration. In the PHY of 4G/5G systems, data is transmitted in the unit of transport block (TB) across a fixed number of physical RBs based on resource allocation decisions. This simultaneous time and frequency localized structure of resource allocation is at odds with the perennial time-frequency compactness limits. Specifically, the band-limiting operation will disrupt the time localization and lead to inter-block interference (IBI). The IBI extent, i.e., the number of neighboring blocks that contribute to the interference, depends mainly on the spectral concentration properties of the signaling waveforms. Deviating from the standard Gabor-frame based multi-carrier approaches which use time-frequency shifted versions of a single prototype pulse, the use of a set of multiple mutually orthogonal pulse shapes-that are not related by a time-frequency shift relationship-is proposed. We hypothesize that using discrete prolate spheroidal sequences (DPSS) as the set of waveform pulse shapes reduces IBI. Analytical expressions for upper bounds on IBI are derived as well as simulation results provided that support our hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02785v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karim A. Said (Louis), A. A. (Louis),  Beex, Elizabeth Bentley, Lingjia Liu</dc:creator>
    </item>
    <item>
      <title>Joint Beamforming for Backscatter Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2409.02797</link>
      <description>arXiv:2409.02797v2 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) is a key technology of next generation wireless communication. Backscatter communication (BackCom) plays an important role for internet of things (IoT). Then the integration of ISAC with BackCom technology enables low-power data transmission while enhancing the system sensing ability, which is expected to provide a potentially revolutionary solution for IoT applications. In this paper, we propose a novel backscatter-ISAC (B-ISAC) system and focus on the joint beamforming design for the system. We formulate the communication and sensing model of the B-ISAC system and derive the metrics of communication and sensing performance respectively, i.e., communication rate and detection probability. We propose a joint beamforming scheme aiming to optimize the communication rate under sensing constraint and power budget. A successive convex approximation (SCA) based algorithm and an iterative algorithm are developed for solving the complicated non-convex optimization problem. Numerical results validate the effectiveness of the proposed scheme and associated algorithms. The proposed B-ISAC system has broad application prospect in IoT scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02797v2</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongyao Zhao, Tiankuo Wei, Zhenyu Liu, Xinke Tang, Xiao-Ping Zhang, Yuhan Dong</dc:creator>
    </item>
    <item>
      <title>Diffraction Aided Wireless Positioning</title>
      <link>https://arxiv.org/abs/2409.02832</link>
      <description>arXiv:2409.02832v1 Announce Type: new 
Abstract: Wireless positioning in Non-Line-of-Sight (NLOS) scenarios is highly challenging due to multipath, which leads to deterioration in the positioning estimate. This study reexamines electromagnetic field principles and applies them to wireless positioning, resulting in new techniques that enhance positioning accuracy in NLOS scenarios. Further, we use the proposed method to analyze a public safety scenario where it is essential to determine the position of at-risk individuals within buildings, emphasizing improving the Z-axis position estimate. Our analysis uses the Geometrical Theory of Diffraction (GTD) to provide important signal propagation insights and develop a new NLOS path model. Next, we use Fisher information to derive necessary and sufficient conditions for 3D positioning using our proposed positioning technique and finally to lower bound the possible 3D and z-axis positioning performance. On applying this positioning technique in a public safety scenario, we show that it is possible to greatly improve both 3D and Z-axis positioning performance by directly estimating NLOS path lengths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02832v1</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaurav Duggal, R. Michael Buehrer, Harpreet S. Dhillon, Jeffrey H. Reed</dc:creator>
    </item>
    <item>
      <title>LSTM-QGAN: Scalable NISQ Generative Adversarial Network</title>
      <link>https://arxiv.org/abs/2409.02212</link>
      <description>arXiv:2409.02212v1 Announce Type: cross 
Abstract: Current quantum generative adversarial networks (QGANs) still struggle with practical-sized data. First, many QGANs use principal component analysis (PCA) for dimension reduction, which, as our studies reveal, can diminish the QGAN's effectiveness. Second, methods that segment inputs into smaller patches processed by multiple generators face scalability issues. In this work, we propose LSTM-QGAN, a QGAN architecture that eliminates PCA preprocessing and integrates quantum long short-term memory (QLSTM) to ensure scalable performance. Our experiments show that LSTM-QGAN significantly enhances both performance and scalability over state-of-the-art QGAN models, with visual data improvements, reduced Frechet Inception Distance scores, and reductions of 5x in qubit counts, 5x in single-qubit gates, and 12x in two-qubit gates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02212v1</guid>
      <category>quant-ph</category>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheng Chu, Aishwarya Hastak, Fan Chen</dc:creator>
    </item>
    <item>
      <title>A Lesion-aware Edge-based Graph Neural Network for Predicting Language Ability in Patients with Post-stroke Aphasia</title>
      <link>https://arxiv.org/abs/2409.02303</link>
      <description>arXiv:2409.02303v1 Announce Type: cross 
Abstract: We propose a lesion-aware graph neural network (LEGNet) to predict language ability from resting-state fMRI (rs-fMRI) connectivity in patients with post-stroke aphasia. Our model integrates three components: an edge-based learning module that encodes functional connectivity between brain regions, a lesion encoding module, and a subgraph learning module that leverages functional similarities for prediction. We use synthetic data derived from the Human Connectome Project (HCP) for hyperparameter tuning and model pretraining. We then evaluate the performance using repeated 10-fold cross-validation on an in-house neuroimaging dataset of post-stroke aphasia. Our results demonstrate that LEGNet outperforms baseline deep learning methods in predicting language ability. LEGNet also exhibits superior generalization ability when tested on a second in-house dataset that was acquired under a slightly different neuroimaging protocol. Taken together, the results of this study highlight the potential of LEGNet in effectively learning the relationships between rs-fMRI connectivity and language ability in a patient cohort with brain lesions for improved post-stroke aphasia evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02303v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian Chen, Maria Varkanitsa, Prakash Ishwar, Janusz Konrad, Margrit Betke, Swathi Kiran, Archana Venkataraman</dc:creator>
    </item>
    <item>
      <title>A Dynamic Resource Scheduling Algorithm Based on Traffic Prediction for Coexistence of eMBB and Random Arrival URLLC</title>
      <link>https://arxiv.org/abs/2409.02396</link>
      <description>arXiv:2409.02396v1 Announce Type: cross 
Abstract: In this paper, we propose a joint design for the coexistence of enhanced mobile broadband (eMBB) and ultra-reliable and random low-latency communication (URLLC) with different transmission time intervals (TTI): an eMBB scheduler operating at the beginning of each eMBB TTI to decide the coding redundancy of eMBB code blocks, and a URLLC scheduler at the beginning of each mini-slot to perform immediate preemption to ensure that the randomly arriving URLLC traffic is allocated with enough radio resource and the eMBB traffic keeps acceptable one-shot transmission successful probability and throughput. The framework for schedulers under hybrid-TTI is developed and a method to configure eMBB code block based on URLLC traffic arrival prediction is implemented. Simulations show that our work improves the throughput of eMBB traffic without sacrificing the reliablity while supporting randomly arriving URLLC traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02396v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizhou Jiang, Xiujun Zhang, Xiaofeng Zhong, Shidong Zhou</dc:creator>
    </item>
    <item>
      <title>Multi-Sources Fusion Learning for Multi-Points NLOS Localization in OFDM System</title>
      <link>https://arxiv.org/abs/2409.02454</link>
      <description>arXiv:2409.02454v1 Announce Type: cross 
Abstract: Accurate localization of mobile terminals is a pivotal aspect of integrated sensing and communication systems. Traditional fingerprint-based localization methods, which infer coordinates from channel information within pre-set rectangular areas, often face challenges due to the heterogeneous distribution of fingerprints inherent in non-line-of-sight (NLOS) scenarios, particularly within orthogonal frequency division multiplexing systems. To overcome this limitation, we develop a novel multi-sources information fusion learning framework referred to as the Autosync Multi-Domains NLOS Localization (AMDNLoc). Specifically, AMDNLoc employs a two-stage matched filter fused with a target tracking algorithm and iterative centroid-based clustering to automatically and irregularly segment NLOS regions, ensuring uniform distribution within channel state information across frequency, power, and time-delay domains. Additionally, the framework utilizes a segment-specific linear classifier array, coupled with deep residual network-based feature extraction and fusion, to establish the correlation function between fingerprint features and coordinates within these regions. Simulation results reveal that AMDNLoc achieves an impressive NLOS localization accuracy of 1.46 meters on typical wireless artificial intelligence research datasets and demonstrates significant improvements in interpretability, adaptability, and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02454v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JSTSP.2024.3453548</arxiv:DOI>
      <dc:creator>Bohao Wang, Zitao Shuai, Chongwen Huang, Qianqian Yang, Zhaohui Yang, Richeng Jin, Ahmed Al Hammadi, Zhaoyang Zhang, Chau Yuen, M\'erouane Debbah</dc:creator>
    </item>
    <item>
      <title>Learnable Wireless Digital Twins: Reconstructing Electromagnetic Field with Neural Representations</title>
      <link>https://arxiv.org/abs/2409.02564</link>
      <description>arXiv:2409.02564v1 Announce Type: cross 
Abstract: Fully harvesting the gain of multiple-input and multiple-output (MIMO) requires accurate channel information. However, conventional channel acquisition methods mainly rely on pilot training signals, resulting in significant training overheads (time, energy, spectrum). Digital twin-aided communications have been proposed in [1] to reduce or eliminate this overhead by approximating the real world with a digital replica. However, how to implement a digital twin-aided communication system brings new challenges. In particular, how to model the 3D environment and the associated EM properties, as well as how to update the environment dynamics in a coherent manner. To address these challenges, motivated by the latest advancements in computer vision, 3D reconstruction and neural radiance field, we propose an end-to-end deep learning framework for future generation wireless systems that can reconstruct the 3D EM field covered by a wireless access point, based on widely available crowd-sourced world-locked wireless samples between the access point and the devices. This visionary framework is grounded in classical EM theory and employs deep learning models to learn the EM properties and interaction behaviors of the objects in the environment. Simulation results demonstrate that the proposed learnable digital twin can implicitly learn the EM properties of the objects, accurately predict wireless channels, and generalize to changes in the environment, highlighting the prospect of this novel direction for future generation wireless platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02564v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shuaifeng Jiang, Qi Qu, Xiaqing Pan, Abhishek Agrawal, Richard Newcombe, Ahmed Alkhateeb</dc:creator>
    </item>
    <item>
      <title>GET-UP: GEomeTric-aware Depth Estimation with Radar Points UPsampling</title>
      <link>https://arxiv.org/abs/2409.02720</link>
      <description>arXiv:2409.02720v1 Announce Type: cross 
Abstract: Depth estimation plays a pivotal role in autonomous driving, facilitating a comprehensive understanding of the vehicle's 3D surroundings. Radar, with its robustness to adverse weather conditions and capability to measure distances, has drawn significant interest for radar-camera depth estimation. However, existing algorithms process the inherently noisy and sparse radar data by projecting 3D points onto the image plane for pixel-level feature extraction, overlooking the valuable geometric information contained within the radar point cloud. To address this gap, we propose GET-UP, leveraging attention-enhanced Graph Neural Networks (GNN) to exchange and aggregate both 2D and 3D information from radar data. This approach effectively enriches the feature representation by incorporating spatial relationships compared to traditional methods that rely only on 2D feature extraction. Furthermore, we incorporate a point cloud upsampling task to densify the radar point cloud, rectify point positions, and derive additional 3D features under the guidance of lidar data. Finally, we fuse radar and camera features during the decoding phase for depth estimation. We benchmark our proposed GET-UP on the nuScenes dataset, achieving state-of-the-art performance with a 15.3% and 14.7% improvement in MAE and RMSE over the previously best-performing model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02720v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huawei Sun, Zixu Wang, Hao Feng, Julius Ott, Lorenzo Servadei, Robert Wille</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Communication for Graph Data: A Graph Information Bottleneck Approach</title>
      <link>https://arxiv.org/abs/2409.02728</link>
      <description>arXiv:2409.02728v1 Announce Type: cross 
Abstract: Graph data, essential in fields like knowledge representation and social networks, often involves large networks with many nodes and edges. Transmitting these graphs can be highly inefficient due to their size and redundancy for specific tasks. This paper introduces a method to extract a smaller, task-focused subgraph that maintains key information while reducing communication overhead. Our approach utilizes graph neural networks (GNNs) and the graph information bottleneck (GIB) principle to create a compact, informative, and robust graph representation suitable for transmission. The challenge lies in the irregular structure of graph data, making GIB optimization complex. We address this by deriving a tractable variational upper bound for the objective function. Additionally, we propose the VQ-GIB mechanism, integrating vector quantization (VQ) to convert subgraph representations into a discrete codebook sequence, compatible with existing digital communication systems. Our experiments show that this GIB-based method significantly lowers communication costs while preserving essential task-related information. The approach demonstrates robust performance across various communication channels, suitable for both continuous and discrete systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02728v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shujing Li, Yanhu Wang, Shuaishuai Guo, Chenyuan Feng</dc:creator>
    </item>
    <item>
      <title>Hybrid-Segmentor: A Hybrid Approach to Automated Fine-Grained Crack Segmentation in Civil Infrastructure</title>
      <link>https://arxiv.org/abs/2409.02866</link>
      <description>arXiv:2409.02866v1 Announce Type: cross 
Abstract: Detecting and segmenting cracks in infrastructure, such as roads and buildings, is crucial for safety and cost-effective maintenance. In spite of the potential of deep learning, there are challenges in achieving precise results and handling diverse crack types. With the proposed dataset and model, we aim to enhance crack detection and infrastructure maintenance. We introduce Hybrid-Segmentor, an encoder-decoder based approach that is capable of extracting both fine-grained local and global crack features. This allows the model to improve its generalization capabilities in distinguish various type of shapes, surfaces and sizes of cracks. To keep the computational performances low for practical purposes, while maintaining the high the generalization capabilities of the model, we incorporate a self-attention model at the encoder level, while reducing the complexity of the decoder component. The proposed model outperforms existing benchmark models across 5 quantitative metrics (accuracy 0.971, precision 0.804, recall 0.744, F1-score 0.770, and IoU score 0.630), achieving state-of-the-art status.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02866v1</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>June Moh Goo, Xenios Milidonis, Alessandro Artusi, Jan Boehm, Carlo Ciliberto</dc:creator>
    </item>
    <item>
      <title>Design of a Standard-Compliant Real-Time Neural Receiver for 5G NR</title>
      <link>https://arxiv.org/abs/2409.02912</link>
      <description>arXiv:2409.02912v1 Announce Type: cross 
Abstract: We detail the steps required to deploy a multi-user multiple-input multiple-output (MU-MIMO) neural receiver (NRX) in an actual cellular communication system. This raises several exciting research challenges, including the need for real-time inference and compatibility with the 5G NR standard. As the network configuration in a practical setup can change dynamically within milliseconds, we propose an adaptive NRX architecture capable of supporting dynamic modulation and coding scheme (MCS) configurations without the need for any re-training and without additional inference cost. We optimize the latency of the neural network (NN) architecture to achieve inference times of less than 1ms on an NVIDIA A100 GPU using the TensorRT inference library. These latency constraints effectively limit the size of the NN and we quantify the resulting signal-to-noise ratio (SNR) degradation as less than 0.7 dB when compared to a preliminary non-real-time NRX architecture. Finally, we explore the potential for site-specific adaptation of the receiver by investigating the required size of the training dataset and the number of fine-tuning iterations to optimize the NRX for specific radio environments using a ray tracing-based channel model. The resulting NRX is ready for deployment in a real-time 5G NR system and the source code including the TensorRT experiments is available online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02912v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reinhard Wiesmayr, Sebastian Cammerer, Fay\c{c}al A\"it Aoudia, Jakob Hoydis, Jakub Zakrzewski, Alexander Keller</dc:creator>
    </item>
    <item>
      <title>A Framework of RIS-assisted ICSC User-centric Based Systems: Latency Optimization and Design</title>
      <link>https://arxiv.org/abs/2402.13692</link>
      <description>arXiv:2402.13692v3 Announce Type: replace 
Abstract: This paper studies a comprehensive framework for reconfigurable intelligent surface (RIS)-assisted integrated communication, sensing, and computation (ICSC) systems with a User-centric focus. The study encompasses two scenarios: the general multi-user equipment (UE) scenario and the simplified single-UE scenario. To satisfy the critical need for time-efficient sensing, we investigate the latency minimization problem, subject to constraints on UEs' transmit power, radar signal-to-interference-plus-noise-ratio (SINR), RIS phase shift, and computation capability. To address the formulated non-convex problem in the multi-UE scenario, we decouple the original problem into two subproblems, where the computational and beamforming settings are optimized alternately. Specifically, for the computational settings, we derive a closed-form solution for the offloading volume and propose a low-complexity algorithm based on the bisection search method to optimize the edge computing resource allocation. Additionally, we employ two equivalent transformations to address the challenge posed by the non-convex sum-of-ratios form in the objective function (OF) of the subproblem related to active and passive beamforming. Several techniques are then combined to address these subproblems. Furthermore, a low-complexity algorithm that offers closed-form solutions is developed for the simplified single UE scenario. Finally, simulation results substantiate the effectiveness of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13692v3</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahua Wan, Hong Ren, Zhiyuan Yu, Zhenkun Zhang, Yang Zhang, Cunhua Pan, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>Computational Efficient Width-Wise Early Exiting in Wireless Communication Systems</title>
      <link>https://arxiv.org/abs/2405.03222</link>
      <description>arXiv:2405.03222v2 Announce Type: replace 
Abstract: Deep learning (DL) techniques are increasingly pervasive across various domains, including wireless communication, where they extract insights from raw radio signals. However, the computational demands of DL pose significant challenges, particularly in distributed wireless networks like Cell-free networks, where deploying DL models on edge devices becomes hard due to heightened computational loads. These computational loads escalate with larger input sizes, often correlating with improved model performance. To mitigate this challenge, Early Exiting (EE) techniques have been introduced in DL, primarily targeting the depth of the model. This approach enables models to exit during inference based on specified criteria, leveraging entropy measures at intermediate exits. Doing so makes less complex samples exit early, reducing the average computational load and inference time. In our contribution, we propose a novel width-wise exiting strategy for Convolutional Neural Network (CNN)-based architectures. By selectively adjusting the input size, we aim to regulate computational demands effectively. Our approach aims to decrease the average computational load during inference while maintaining performance levels comparable to conventional models. We specifically investigate Modulation Classification, a well-established application of DL in wireless communication. Our experimental results show substantial reductions in computational load, with an average decrease of 26%, and particularly notable reductions of 60% in high-SNR scenarios. Through this work, we present a practical solution for reducing computational demands in deep learning applications, particularly within the domain of wireless communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03222v2</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dieter Verbruggen, Hazem Sallouha, Sofie Pollin</dc:creator>
    </item>
    <item>
      <title>Joint Transmission and Compression Design for 6G Networked Sensing with Limited-Capacity Backhaul</title>
      <link>https://arxiv.org/abs/2408.03174</link>
      <description>arXiv:2408.03174v2 Announce Type: replace 
Abstract: This paper considers networked sensing in cellular network, where multiple base stations (BSs) first compress their received echo signals from multiple targets and then forward the quantized signals to the central unit (CU) via limited-capacity fronthaul links, such that the CU can leverage all useful echo signals to perform high-resolution localization. Under this setup, we manage to characterize the posterior Cramer-Rao Bound (PCRB) for localizing all the targets with random positions as a function of the transmit covariance matrix and the compression noise covariance matrix of each BS. Then, a PCRB minimization problem subject to the transmit power constraints and the fronthaul capacity constraints is formulated to jointly design the BSs' transmission and compression strategies. We propose an efficient algorithm to solve this problem based on the alternating optimization technique. Specifically, it is shown that when either the transmit covariance matrices or the compression noise covariance matrices are fixed, the successive convex approximation (SCA) technique can be leveraged to optimize the other type of covariance matrices locally optimally. Moreover, we also propose a novel estimate-then-beamform-then-compress strategy for the massive receive antenna scenario, under which each BS first estimates targets' angle-of-arrivals (AOAs) locally, then beamforms its high-dimension received signals into low-dimension ones based on the estimated AOAs, and last compresses the beamformed signals for fronthaul transmission. An efficient beamforming and compression design method is devised under this strategy. Numerical results are provided to verify the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03174v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weifeng Zhu, Shuowen Zhang, Liang Liu</dc:creator>
    </item>
    <item>
      <title>Fundamentals of LEO Based Localization</title>
      <link>https://arxiv.org/abs/2408.16710</link>
      <description>arXiv:2408.16710v2 Announce Type: replace 
Abstract: In this paper, we derive the fundamental limits of low earth orbit (LEO) enabled localization by analyzing the available information in signals from multiple LEOs during different transmission time slots received on a multiple antennas and evaluate the utility of these signals for $9$D localization ($3$D position, $3$D orientation, and $3$D velocity estimation). We start by deriving the Fisher Information Matrix (FIM) for the channel parameters that are present in the signals received from LEOs in the same or multiple constellations during multiple transmission time slots. To accomplish this, we define a system model that captures i) time offset between LEOs caused by having relatively cheap clocks, ii) frequency offset between LEOs, iii) the unknown Doppler rate caused by high mobility LEOs, and iv) multiple transmission time slots from a particular LEO. We transform the FIM for the channel parameters to the FIM for the location parameters and determine the required conditions for localization. To do this, we start with the $3$D localization cases: i) $3$D positioning with known velocity and orientation, ii) $3$D orientation estimation with known position and velocity, and iii) $3$D velocity estimation with known position and orientation. Subsequently, we derive the FIM for the full $9$D localization case ($3$D position, $3$D orientation, and $3$D velocity estimation) in terms of the FIM for the $3$D localization. Using these results, we determine the number of LEOs, the operating frequency, the number of transmission time slots, and the number of receive antennas that allow for different levels of location estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16710v2</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Don-Roberts Emenonye, Harpreet S. Dhillon, R. Michael Buehrer</dc:creator>
    </item>
    <item>
      <title>Joint 9D Receiver Localization and Ephemeris Correction with LEO and $5$G Base Stations</title>
      <link>https://arxiv.org/abs/2408.16728</link>
      <description>arXiv:2408.16728v2 Announce Type: replace 
Abstract: In this paper, we use the Fisher information matrix (FIM) to analyze the interaction between low-earth orbit (LEO) satellites and $5$G base stations in providing $9$D receiver localization and correcting LEO ephemeris. First, we give a channel model that captures all the information in the LEO-receiver, LEO-BS, and BS-receiver links. Subsequently, we use FIM to capture the amount of information about the channel parameters in these links. Then, we transform these FIM for channel parameters to the FIM for the $9$D ($3$D position, $3$D orientation, and $3$D velocity estimation) receiver localization parameters and the LEO position and velocity offset. Closed-form expressions for the entries in the FIM for these location parameters are presented. Our results on identifiability utilizing the FIM for the location parameters indicate: i) with one LEO, we need three BSs and three time slots to both estimate the $9$D location parameters and correct the LEO position and velocity, ii) with two LEO, we need three BSs and three time slots to both estimate the $9$D location parameters and correct the LEO position and velocity, and iii) with three LEO, we need three BSs and four-time slots to both estimate the $9$D location parameters and correct the LEO position and velocity. Another key insight is that through the Cramer Rao lower bound we show that with a single LEO, three time slots, and three BSs, the receiver positioning error, velocity estimation error, orientation error, LEO position offset estimation error, and LEO velocity offset estimation error are $0.1 \text{ cm}$, $1 \text{ mm/s}$, $10^{-3} \text{ rad}$, $0.01 \text{ m}$, and $1 \text{ m/s}$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16728v2</guid>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Don-Roberts Emenonye, Harpreet S. Dhillon, R. Michael Buehrer</dc:creator>
    </item>
    <item>
      <title>A Novel Approach to Classify Power Quality Signals Using Vision Transformers</title>
      <link>https://arxiv.org/abs/2409.00025</link>
      <description>arXiv:2409.00025v2 Announce Type: replace 
Abstract: With the rapid integration of electronically interfaced renewable energy resources and loads into smart grids, there is increasing interest in power quality disturbances (PQD) classification to enhance the security and efficiency of these grids. This paper introduces a new approach to PQD classification based on the Vision Transformer (ViT) model. When a PQD occurs, the proposed approach first converts the power quality signal into an image and then utilizes a pre-trained ViT to accurately determine the class of the PQD. Unlike most previous works, which were limited to a few disturbance classes or small datasets, the proposed method is trained and tested on a large dataset with 17 disturbance classes. Our experimental results show that the proposed ViT-based approach achieves PQD classification precision and recall of 98.28% and 97.98%, respectively, outperforming recently proposed techniques applied to the same dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00025v2</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ahmad Mohammad Saber, Alaa Selim, Mohamed M. Hammad, Amr Youssef, Deepa Kundur, Ehab El-Saadany</dc:creator>
    </item>
    <item>
      <title>Two-Phase Channel Estimation for RIS-Assisted THz Systems with Beam Split</title>
      <link>https://arxiv.org/abs/2403.03015</link>
      <description>arXiv:2403.03015v2 Announce Type: replace-cross 
Abstract: Reconfigurable intelligent surface (RIS)-assisted terahertz (THz) communication is emerging as a key technology to support ultra-high data rates in future sixth-generation networks. However, the acquisition of accurate channel state information (CSI) in such systems is challenging due to the passive nature of RIS and the hybrid beamforming architecture typically employed in THz systems. To address these challenges, we propose a novel low-complexity two-phase channel estimation scheme for RIS-assisted THz systems with beam split effect. In the proposed scheme, we first estimate the full CSI over a small subset of subcarriers, then extract angular information at both the base station and RIS. Subsequently, we recover the full CSI across remaining subcarriers by determining the corresponding spatial directions and angle-excluded coefficients. Theoretical analysis and simulation results demonstrate that the proposed method achieves superior performance in terms of normalized mean-square error while significantly reducing computational complexity compared to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03015v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Su, Ruisi He, Peng Zhang, Bo Ai, Yong Niu, Gongpu Wang</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Channel Decoding for Wireless Federated Learning: Convergence Analysis and Adaptive Design</title>
      <link>https://arxiv.org/abs/2407.13703</link>
      <description>arXiv:2407.13703v3 Announce Type: replace-cross 
Abstract: One of the most critical challenges for deploying distributed learning solutions, such as federated learning (FL), in wireless networks is the limited battery capacity of mobile clients. While it is a common belief that the major energy consumption of mobile clients comes from the uplink data transmission, this paper presents a novel finding, namely channel decoding also contributes significantly to the overall energy consumption of mobile clients in FL. Motivated by this new observation, we propose an energy-efficient adaptive channel decoding scheme that leverages the intrinsic robustness of FL to model errors. In particular, the robustness is exploited to reduce the energy consumption of channel decoders at mobile clients by adaptively adjusting the number of decoding iterations. We theoretically prove that wireless FL with communication errors can converge at the same rate as the case with error-free communication provided the bit error rate (BER) is properly constrained. An adaptive channel decoding scheme is then proposed to improve the energy efficiency of wireless FL systems. Experimental results demonstrate that the proposed method maintains the same learning accuracy while reducing the channel decoding energy consumption by ~20% when compared to an existing approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13703v3</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linping Qu, Yuyi Mao, Shenghui Song, Chi-Ying Tsui</dc:creator>
    </item>
    <item>
      <title>Variational Mode Decomposition and Linear Embeddings are What You Need For Time-Series Forecasting</title>
      <link>https://arxiv.org/abs/2408.16122</link>
      <description>arXiv:2408.16122v2 Announce Type: replace-cross 
Abstract: Time-series forecasting often faces challenges due to data volatility, which can lead to inaccurate predictions. Variational Mode Decomposition (VMD) has emerged as a promising technique to mitigate volatility by decomposing data into distinct modes, thereby enhancing forecast accuracy. In this study, we integrate VMD with linear models to develop a robust forecasting framework. Our approach is evaluated on 13 diverse datasets, including ETTm2, WindTurbine, M4, and 10 air quality datasets from various Southeast Asian cities. The effectiveness of the VMD strategy is assessed by comparing Root Mean Squared Error (RMSE) values from models utilizing VMD against those without it. Additionally, we benchmark linear-based models against well-known neural network architectures such as LSTM, Bidirectional LSTM, and RNN. The results demonstrate a significant reduction in RMSE across nearly all models following VMD application. Notably, the Linear + VMD model achieved the lowest average RMSE in univariate forecasting at 0.619. In multivariate forecasting, the DLinear + VMD model consistently outperformed others, attaining the lowest RMSE across all datasets with an average of 0.019. These findings underscore the effectiveness of combining VMD with linear models for superior time-series forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16122v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hafizh Raihan Kurnia Putra, Novanto Yudistira, Tirana Noor Fatyanosa</dc:creator>
    </item>
  </channel>
</rss>
