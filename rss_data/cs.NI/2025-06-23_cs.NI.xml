<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Jun 2025 02:20:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>HybridRAG-based LLM Agents for Low-Carbon Optimization in Low-Altitude Economy Networks</title>
      <link>https://arxiv.org/abs/2506.15947</link>
      <description>arXiv:2506.15947v1 Announce Type: new 
Abstract: Low-Altitude Economy Networks (LAENets) are emerging as a promising paradigm to support various low-altitude services through integrated air-ground infrastructure. To satisfy low-latency and high-computation demands, the integration of Unmanned Aerial Vehicles (UAVs) with Mobile Edge Computing (MEC) systems plays a vital role, which offloads computing tasks from terminal devices to nearby UAVs, enabling flexible and resilient service provisions for ground users. To promote the development of LAENets, it is significant to achieve low-carbon multi-UAV-assisted MEC networks. However, several challenges hinder this implementation, including the complexity of multi-dimensional UAV modeling and the difficulty of multi-objective coupled optimization. To this end, this paper proposes a novel Retrieval Augmented Generation (RAG)-based Large Language Model (LLM) agent framework for model formulation. Specifically, we develop HybridRAG by combining KeywordRAG, VectorRAG, and GraphRAG, empowering LLM agents to efficiently retrieve structural information from expert databases and generate more accurate optimization problems compared with traditional RAG-based LLM agents. After customizing carbon emission optimization problems for multi-UAV-assisted MEC networks, we propose a Double Regularization Diffusion-enhanced Soft Actor-Critic (R\textsuperscript{2}DSAC) algorithm to solve the formulated multi-objective optimization problem. The R\textsuperscript{2}DSAC algorithm incorporates diffusion entropy regularization and action entropy regularization to improve the performance of the diffusion policy. Furthermore, we dynamically mask unimportant neurons in the actor network to reduce the carbon emissions associated with model training. Simulation results demonstrate the effectiveness and reliability of the proposed HybridRAG-based LLM agent framework and the R\textsuperscript{2}DSAC algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15947v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinbo Wen, Cheng Su, Jiawen Kang, Jiangtian Nie, Yang Zhang, Jianhang Tang, Dusit Niyato, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>LoRaIN: A Constructive Interference-Assisted Reliable and Energy-Efficient LoRa Indoor Network</title>
      <link>https://arxiv.org/abs/2506.16409</link>
      <description>arXiv:2506.16409v1 Announce Type: new 
Abstract: LoRa is a promising communication technology for enabling the next-generation indoor Internet of Things applications. Very few studies, however, have analyzed its performance indoors. Besides, these indoor studies investigate mostly the RSSI and SNR of the received packets at the gateway, which, as we show, may not unfold the poor performance of LoRa and its MAC protocol, LoRaWAN, indoors in terms of reliability and energy-efficiency. In this paper, we extensively evaluate the performance of LoRaWAN indoors and then use the key insights to boost its reliability and energy-efficiency by proposing LoRaIN, LoRa Indoor Network, a new link-layer protocol that can be effectively used for indoor deployments. The approach to boosting the reliability and energy efficiency in LoRaIN is underpinned by enabling constructive interference with specific timing requirements analyzed both empirically and mathematically for different pairs of channel bandwidth and spreading factor and relaying precious acknowledgments to the end-devices with the assistance of several booster nodes. The booster nodes do not need any special capability and can be a subset of the LoRa end-devices. To our knowledge, LoRaIN is the first protocol for boosting reliability and energy-efficiency in indoor LoRa networks. We evaluate its performance in an indoor testbed consisting of one LoRaWAN gateway and 20 end-devices. Our extensive evaluation shows that when 15% of the end-devices operate as booster nodes, the reliability at the gateway increases from 62% to 95%, and the end-devices are approximately 2.5x energy-efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16409v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahbubur Rahman, Abusayeed Saifullah</dc:creator>
    </item>
    <item>
      <title>Using SRv6 to access Edge Applications in 5G Networks</title>
      <link>https://arxiv.org/abs/2506.16808</link>
      <description>arXiv:2506.16808v1 Announce Type: new 
Abstract: With the emergence of Multi-Access Edge Computing in 5G and beyond, it has become essential for operators to optimize the data path for the end-user while ensuring resources are used according to their policy. In this paper, we review existing solutions to access edge resources, underline their limits, and propose the use of Segment Routing over IPv6 (SRv6) in a 5G/edge architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16808v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>19th International Conference on emerging Networking EXperiments and Technologies - Student Workshop (CoNEXT-SW 2023), Dec 2023, Paris, France. pp.23-24</arxiv:journal_reference>
      <dc:creator>Louis Royer (IRIT-RMESS), Emmanuel Lavinal (UT3, IRIT-SIERA), Emmanuel Chaput (IRIT-RMESS, Toulouse INP)</dc:creator>
    </item>
    <item>
      <title>Minimal Per-Flow Backlog Bounds at an Aggregate FIFO Server under Piecewise-Linear Arrival Curves</title>
      <link>https://arxiv.org/abs/2506.16914</link>
      <description>arXiv:2506.16914v1 Announce Type: new 
Abstract: Network Calculus (NC) is a versatile methodology based on min-plus algebra to derive worst-case per-flow performance bounds in networked systems with many concurrent flows. In particular, NC can analyze many scheduling disciplines; yet, somewhat surprisingly, an aggregate FIFO server is a notoriously hard case due to its min-plus non-linearity. A resort is to represent the FIFO residual service by a family of functions with a free parameter instead of just a single curve. For simple token-bucket arrival curves, literature provides optimal choices for that free parameter to minimize delay and backlog bounds. In this paper, we tackle the challenge of more general arrival curves than just token buckets. In particular, we derive residual service curves resulting in minimal backlog bounds for general piecewise-linear arrival curves. To that end, we first show that a backlog bound can always be calculated at a breakpoint of either the arrival curve of the flow of interest or its residual service curve. Further, we define a set of curves that characterize the backlog for a fixed breakpoint, depending on the free parameter of the residual service curve. We show that the backlog-minimizing residual service curve family parameter corresponds to the largest intersection of those curves with the arrival curve. In more complex scenarios finding this largest intersection can become inefficient as the search space grows in the number of flows. Therefore, we present an efficient heuristic that finds, in many cases, the optimal parameter or at least a close conservative approximation. This heuristic is evaluated in terms of accuracy and execution time. Finally, we utilize these backlog-minimizing residual service curves to enhance the DiscoDNC tool and observe considerable reductions in the corresponding backlog bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16914v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Wildberger, Anja Hamscher, Jens B. Schmitt</dc:creator>
    </item>
    <item>
      <title>Client Selection Strategies for Federated Semantic Communications in Heterogeneous IoT Networks</title>
      <link>https://arxiv.org/abs/2506.17063</link>
      <description>arXiv:2506.17063v1 Announce Type: new 
Abstract: The exponential growth of IoT devices presents critical challenges in bandwidth-constrained wireless networks, particularly regarding efficient data transmission and privacy preservation. This paper presents a novel federated semantic communication (SC) framework that enables collaborative training of bandwidth-efficient models for image reconstruction across heterogeneous IoT devices. By leveraging SC principles to transmit only semantic features, our approach dramatically reduces communication overhead while preserving reconstruction quality. We address the fundamental challenge of client selection in federated learning environments where devices exhibit significant disparities in dataset sizes and data distributions. Our framework implements three distinct client selection strategies that explore different trade-offs between system performance and fairness in resource allocation. The system employs an end-to-end SC architecture with semantic bottlenecks, coupled with a loss-based aggregation mechanism that naturally adapts to client heterogeneity. Experimental evaluation on image data demonstrates that while Utilitarian selection achieves the highest reconstruction quality, Proportional Fairness maintains competitive performance while significantly reducing participation inequality and improving computational efficiency. These results establish that federated SC can successfully balance reconstruction quality, resource efficiency, and fairness in heterogeneous IoT deployments, paving the way for sustainable and privacy-preserving edge intelligence applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17063v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samer Lahoud, Kinda Khawam</dc:creator>
    </item>
    <item>
      <title>Autonomous Trajectory Optimization for UAVs in Disaster Zone Using Henry Gas Optimization Scheme</title>
      <link>https://arxiv.org/abs/2506.15910</link>
      <description>arXiv:2506.15910v1 Announce Type: cross 
Abstract: The unmanned aerial vehicles (UAVs) in a disaster-prone environment plays important role in assisting the rescue services and providing the internet connectivity with the outside world. However, in such a complex environment the selection of optimum trajectory of UAVs is of utmost importance. UAV trajectory optimization deals with finding the shortest path in the minimal possible time. In this paper, a cluster optimization scheme (COS) is proposed using the Henry gas optimization (HGO) metaheuristic algorithm to identify the shortest path having minimal transportation cost and algorithm complexity. The mathematical model is designed for COS using the HGO algorithm and compared with the state-of-the-art metaheuristic algorithms such as particle swarm optimization (PSO), grey wolf optimization (GWO), cuckoo search algorithm (CSA) and barnacles mating optimizer (BMO). In order to prove the robustness of the proposed model, four different scenarios are evaluated that includes ambient environment, constrict environment, tangled environment, and complex environment. In all the aforementioned scenarios, the HGO algorithm outperforms the existing algorithms. Particularly, in the ambient environment, the HGO algorithm achieves a 39.3% reduction in transportation cost and a 16.8% reduction in computational time as compared to the PSO algorithm. Hence, the HGO algorithm can be used for autonomous trajectory optimization of UAVs in smart cities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15910v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zakria Qadir, Muhammad Bilal, Guoqiang Liu, Xiaolong Xu</dc:creator>
    </item>
    <item>
      <title>SAFER-D: A Self-Adaptive Security Framework for Distributed Computing Architectures</title>
      <link>https://arxiv.org/abs/2506.16545</link>
      <description>arXiv:2506.16545v1 Announce Type: cross 
Abstract: The rise of the Internet of Things and Cyber-Physical Systems has introduced new challenges on ensuring secure and robust communication. The growing number of connected devices increases network complexity, leading to higher latency and traffic. Distributed computing architectures (DCAs) have gained prominence to address these issues. This shift has significantly expanded the attack surface, requiring additional security measures to protect all components -- from sensors and actuators to edge nodes and central servers. Recent incidents highlight the difficulty of this task: Cyberattacks, like distributed denial of service attacks, continue to pose severe threats and cause substantial damage. Implementing a holistic defense mechanism remains an open challenge, particularly against attacks that demand both enhanced resilience and rapid response. Addressing this gap requires innovative solutions to enhance the security of DCAs. In this work, we present our holistic self-adaptive security framework which combines different adaptation strategies to create comprehensive and efficient defense mechanisms. We describe how to incorporate the framework into a real-world use case scenario and further evaluate its applicability and efficiency. Our evaluation yields promising results, indicating great potential to further extend the research on our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16545v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marco Stadler, Michael Vierhauser, Michael Riegler, Daniel Waghubinger, Johannes Sametinger</dc:creator>
    </item>
    <item>
      <title>Enabling Blockchain Interoperability Through Network Discovery Services</title>
      <link>https://arxiv.org/abs/2506.16611</link>
      <description>arXiv:2506.16611v1 Announce Type: cross 
Abstract: Web3 technologies have experienced unprecedented growth in the last decade, achieving widespread adoption. As various blockchain networks continue to evolve, we are on the cusp of a paradigm shift in which they could provide services traditionally offered by the Internet, but in a decentralized manner, marking the emergence of the Internet of Blockchains. While significant progress has been achieved in enabling interoperability between blockchain networks, existing solutions often assume that networks are already mutually aware. This reveals a critical gap: the initial discovery of blockchain networks remains largely unaddressed. This paper proposes a decentralized architecture for blockchain network discovery that operates independently of any centralized authority. We also introduce a mechanism for discovering assets and services within a blockchain from external networks. Given the decentralized nature of the proposed discovery architecture, we design an incentive mechanism to encourage nodes to actively participate in maintaining the discovery network. The proposed architecture implemented and evaluated, using the Substrate framework, demonstrates its resilience and scalability, effectively handling up to 130,000 concurrent requests under the tested network configurations, with a median response time of 5.5 milliseconds, demonstrating the ability to scale its processing capacity further by increasing its network size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16611v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khalid Hassan, Amirreza Sokhankhosh, Sara Rouhani</dc:creator>
    </item>
    <item>
      <title>JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows</title>
      <link>https://arxiv.org/abs/2506.17084</link>
      <description>arXiv:2506.17084v1 Announce Type: cross 
Abstract: In modern science, the growing complexity of large-scale projects has increased reliance on cross-facility workflows, where institutions share resources and expertise to accelerate discovery. These workflows often involve transferring massive data over wide-area networks. While high-speed networks like ESnet and data transfer services like Globus have improved data mobility, challenges remain. Large data volumes can strain bandwidth, TCP suffers from retransmissions due to packet loss, and traditional fault-tolerance methods like erasure coding introduce significant overhead.
  This paper presents JANUS, a resilient and adaptive data transmission approach for cross-facility scientific workflows. JANUS uses UDP, integrates erasure coding for fault tolerance, and applies error-bounded lossy compression to reduce overhead. This design enables users to balance transmission time and accuracy based on specific needs. JANUS also adapts coding parameters to real-time network conditions and uses optimization models to determine ideal configurations. Experiments show that JANUS significantly improves data transfer efficiency while preserving fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17084v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vladislav Esaulov, Jieyang Chen, Norbert Podhorszki, Fred Suter, Scott Klasky, Anu G Bourgeois, Lipeng Wan</dc:creator>
    </item>
    <item>
      <title>Semantic-Aware Resource Allocation Based on Deep Reinforcement Learning for 5G-V2X HetNets</title>
      <link>https://arxiv.org/abs/2406.07996</link>
      <description>arXiv:2406.07996v2 Announce Type: replace 
Abstract: This letter proposes a semantic-aware resource allocation (SARA) framework with flexible duty cycle (DC) coexistence mechanism (SARADC) for 5G-V2X Heterogeneous Network (HetNets) based on deep reinforcement learning (DRL) proximal policy optimization (PPO). Specifically, we investigate V2X networks within a two-tiered HetNets structure. In response to the needs of high-speed vehicular networking in urban environments, we design a semantic communication system and introduce two resource allocation metrics: high-speed semantic transmission rate (HSR) and semantic spectrum efficiency (HSSE). Our main goal is to maximize HSSE. Additionally, we address the coexistence of vehicular users and WiFi users in 5G New Radio Unlicensed (NR-U) networks. To tackle this complex challenge, we propose a novel approach that jointly optimizes flexible DC coexistence mechanism and the allocation of resources and base stations (BSs). Unlike traditional bit transmission methods, our approach integrates the semantic communication paradigm into the communication system. Experimental results demonstrate that our proposed solution outperforms traditional bit transmission methods with traditional DC coexistence mechanism in terms of HSSE and semantic throughput (ST) for both vehicular and WiFi users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07996v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Shao, Qiong Wu, Pingyi Fan, Nan Cheng, Qiang Fan, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation for 6G: MLR, ANOVA, and Residual Distribution Analysis</title>
      <link>https://arxiv.org/abs/2504.16688</link>
      <description>arXiv:2504.16688v3 Announce Type: replace 
Abstract: Modeling path loss in indoor LoRaWAN technology deployments is inherently challenging due to structural obstructions, occupant density and activities, and fluctuating environmental conditions. This study proposes a two-stage approach to capture and analyze these complexities using an extensive dataset of 1,328,334 field measurements collected over six months in a single-floor office at the University of Siegen's Hoelderlinstrasse Campus, Germany. First, we implement a multiple linear regression model that includes traditional propagation metrics (distance, structural walls) and an extension with proposed environmental variables (relative humidity, temperature, carbon dioxide, particulate matter, and barometric pressure). Using analysis of variance, we demonstrate that adding these environmental factors can reduce unexplained variance by 42.32 percent. Secondly, we examine residual distributions by fitting five candidate probability distributions: Normal, Skew-Normal, Cauchy, Student's t, and Gaussian Mixture Models (GMMs) with 2 to 5 components. Our results show that a four-component Gaussian Mixture Model captures the residual heterogeneity of indoor signal propagation most accurately, significantly outperforming single-distribution approaches. Given the push toward ultra-reliable, context-aware communications in 6G networks, our analysis shows that environment-aware modeling can substantially improve LoRaWAN network design in dynamic indoor IoT deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16688v3</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nahshon Mokua Obiri, Kristof Van Laerhoven</dc:creator>
    </item>
    <item>
      <title>Virtualizing RAN: Science, Strategy, and Architecture of Software-Defined Mobile Networks</title>
      <link>https://arxiv.org/abs/2506.09878</link>
      <description>arXiv:2506.09878v2 Announce Type: replace 
Abstract: Virtualising the Radio-Access Network (RAN) is increasingly viewed as an enabler of affordable 5G expansion and a stepping-stone toward AI-native 6G. Most discussions, however, still approach spectrum policy, cloud engineering and organisational practice as separate topics. This paper offers an integrated perspective spanning four pillars -- science, technology, business strategy and culture. A comparative U.S.\ case study illustrates how mid-band contiguity, complemented by selective mmWave capacity layers, can improve both coverage and churn when orchestrated through software-defined carrier aggregation. We derive analytic capacity and latency bounds for Split 7.2 $\times$ vRAN/O-RAN deployments, quantify the throughput penalty of end-to-end 256-bit encryption, and show how GPU/FPGA off-load plus digital-twin--driven automation keeps the hybrid-automatic-repeat request (HARQ) round-trip within a 0.5 ms budget. When these technical enablers are embedded in a physics-first delivery roadmap, average vRAN cycle time drops an order of magnitude -- even in the presence of cultural head-winds such as dual-ladder'' erosion. Three cybernetic templates -- the Clock-Hierarchy Law, Ashby's Requisite Variety and a delay-cost curve -- are then used to explain why silo-constrained automation can amplify, rather than absorb, integration debt. Looking forward, silicon-paced 6G evolution (9-12 month node shrinks, sub-THz joint communication-and-sensing, chiplet architectures and optical I/O) calls for a dual-resolution planning grid that couples five-year spectrum physics with six-month silicon sprints.'' The paper closes with balanced, action-oriented recommendations for operators, vendors and researchers on sub-THz fronthaul, AI-native security, energy-proportional accelerators and zero-touch assurance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09878v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Barker</dc:creator>
    </item>
    <item>
      <title>Deep-Reinforcement-Learning-Based AoI-Aware Resource Allocation for RIS-Aided IoV Networks</title>
      <link>https://arxiv.org/abs/2406.11245</link>
      <description>arXiv:2406.11245v2 Announce Type: replace-cross 
Abstract: Reconfigurable Intelligent Surface (RIS) is a pivotal technology in communication, offering an alternative path that significantly enhances the link quality in wireless communication environments. In this paper, we propose a RIS-assisted internet of vehicles (IoV) network, considering the vehicle-to-everything (V2X) communication method. In addition, in order to improve the timeliness of vehicle-to-infrastructure (V2I) links and the stability of vehicle-to-vehicle (V2V) links, we introduce the age of information (AoI) model and the payload transmission probability model. Therefore, with the objective of minimizing the AoI of V2I links and prioritizing transmission of V2V links payload, we construct this optimization problem as an Markov decision process (MDP) problem in which the BS serves as an agent to allocate resources and control phase-shift for the vehicles using the soft actor-critic (SAC) algorithm, which gradually converges and maintains a high stability. A AoI-aware joint vehicular resource allocation and RIS phase-shift control scheme based on SAC algorithm is proposed and simulation results show that its convergence speed, cumulative reward, AoI performance, and payload transmission probability outperforms those of proximal policy optimization (PPO), deep deterministic policy gradient (DDPG), twin delayed deep deterministic policy gradient (TD3) and stochastic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11245v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangwei Qi, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Jiangzhou Wang, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Intelligent Surface Assisted VEC Based on Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2406.11318</link>
      <description>arXiv:2406.11318v2 Announce Type: replace-cross 
Abstract: Vehicular edge computing (VEC) is an emerging technology that enables vehicles to perform high-intensity tasks by executing tasks locally or offloading them to nearby edge devices. However, obstacles such as buildings may degrade the communications and incur communication interruptions, and thus the vehicle may not meet the requirement for task offloading. Reconfigurable intelligent surfaces (RIS) is introduced to support vehicle communication and provide an alternative communication path. The system performance can be improved by flexibly adjusting the phase-shift of the RIS. For RIS-assisted VEC system where tasks arrive randomly, we design a control scheme that considers offloading power, local power allocation and phase-shift optimization. To solve this non-convex problem, we propose a new deep reinforcement learning (DRL) framework that employs modified multi-agent deep deterministic policy gradient (MADDPG) approach to optimize the power allocation for vehicle users (VUs) and block coordinate descent (BCD) algorithm to optimize the phase-shift of the RIS. Simulation results show that our proposed scheme outperforms the centralized deep deterministic policy gradient (DDPG) scheme and random scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11318v2</guid>
      <category>cs.MA</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangwei Qi, Qiong Wu, Pingyi Fan, Nan Cheng, Qiang Fan, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>Resource Allocation for Twin Maintenance and Computing Task Processing in Digital Twin Vehicular Edge Computing Network</title>
      <link>https://arxiv.org/abs/2407.07575</link>
      <description>arXiv:2407.07575v2 Announce Type: replace-cross 
Abstract: As a promising technology, vehicular edge computing (VEC) can provide computing and caching services by deploying VEC servers near vehicles. However, VEC networks still face challenges such as high vehicle mobility. Digital twin (DT), an emerging technology, can predict, estimate, and analyze real-time states by digitally modeling objects in the physical world. By integrating DT with VEC, a virtual vehicle DT can be created in the VEC server to monitor the real-time operating status of vehicles. However, maintaining the vehicle DT model requires ongoing attention from the VEC server, which also needs to offer computing services for the vehicles. Therefore, effective allocation and scheduling of VEC server resources are crucial. This study focuses on a general VEC network with a single VEC service and multiple vehicles, examining the two types of delays caused by twin maintenance and computational processing within the network. By transforming the problem using satisfaction functions, we propose an optimization problem aimed at maximizing each vehicle's resource utility to determine the optimal resource allocation strategy. Given the non-convex nature of the issue, we employ multi-agent Markov decision processes to reformulate the problem. Subsequently, we propose the twin maintenance and computing task processing resource collaborative scheduling (MADRL-CSTC) algorithm, which leverages multi-agent deep reinforcement learning. Through experimental comparisons with alternative algorithms, it demonstrates that our proposed approach is effective in terms of resource allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07575v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Xie, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Jiangzhou Wang, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of Age of Information and Energy Consumption in NR-V2X System based on Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2407.08458</link>
      <description>arXiv:2407.08458v2 Announce Type: replace-cross 
Abstract: Autonomous driving may be the most important application scenario of next generation, the development of wireless access technologies enabling reliable and low-latency vehicle communication becomes crucial. To address this, 3GPP has developed Vehicle-to-Everything (V2X) specifications based on 5G New Radio (NR) technology, where Mode 2 Side-Link (SL) communication resembles Mode 4 in LTE-V2X, allowing direct communication between vehicles. This supplements SL communication in LTE-V2X and represents the latest advancement in cellular V2X (C-V2X) with improved performance of NR-V2X. However, in NR-V2X Mode 2, resource collisions still occur, and thus degrade the age of information (AOI). Therefore, a interference cancellation method is employed to mitigate this impact by combining NR-V2X with Non-Orthogonal multiple access (NOMA) technology. In NR-V2X, when vehicles select smaller resource reservation interval (RRI), higher-frequency transmissions take ore energy to reduce AoI. Hence, it is important to jointly consider AoI and communication energy consumption based on NR-V2X communication. Then, we formulate such an optimization problem and employ the Deep Reinforcement Learning (DRL) algorithm to compute the optimal transmission RRI and transmission power for each transmitting vehicle to reduce the energy consumption of each transmitting vehicle and the AoI of each receiving vehicle. Extensive simulations have demonstrated the performance of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08458v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shulin Song, Zheng Zhang, Qiong Wu, Qiang Fan, Pingyi Fan</dc:creator>
    </item>
    <item>
      <title>Mobility-Aware Federated Self-supervised Learning in Vehicular Network</title>
      <link>https://arxiv.org/abs/2408.00256</link>
      <description>arXiv:2408.00256v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) is an advanced distributed machine learning approach, that protects the privacy of each vehicle by allowing the model to be trained on multiple devices simultaneously without the need to upload all data to a road side unit (RSU). This enables FL to handle scenarios with sensitive or widely distributed data. However, in these fields, it is well known that the labeling costs can be a significant expense, and models relying on labels are not suitable for these rapidly evolving fields especially in vehicular networks, or mobile internet of things (MIoT), where new data emerges constantly. To handle this issue, the self-supervised learning paves the way for training without labels. Additionally, for vehicles with high velocity, owing to blurred images, simple aggregation not only impacts the accuracy of the aggregated model but also reduces the convergence speed of FL. This paper proposes a FL algorithm based on image blur level to aggregation, called FLSimCo, which does not require labels and serves as a pre-training stage for self-supervised learning in the vehicular environment. Simulation results demonstrate that the proposed algorithm exhibits fast and stable convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00256v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xueying Gu, Qiong Wu, Pingyi Fan, Qiang Fan</dc:creator>
    </item>
    <item>
      <title>DRL-Based Federated Self-Supervised Learning for Task Offloading and Resource Allocation in ISAC-Enabled Vehicle Edge Computing</title>
      <link>https://arxiv.org/abs/2408.14831</link>
      <description>arXiv:2408.14831v2 Announce Type: replace-cross 
Abstract: Intelligent Transportation Systems (ITS) leverage Integrated Sensing and Communications (ISAC) to enhance data exchange between vehicles and infrastructure in the Internet of Vehicles (IoV). This integration inevitably increases computing demands, risking real-time system stability. Vehicle Edge Computing (VEC) addresses this by offloading tasks to Road Side Unit (RSU), ensuring timely services. Our previous work FLSimCo algorithm, which uses local resources for Federated Self-Supervised Learning (SSL), though vehicles often can't complete all iterations task. Our improved algorithm offloads partial task to RSU and optimizes energy consumption by adjusting transmission power, CPU frequency, and task assignment ratios, balancing local and RSU-based training. Meanwhile, setting an offloading threshold further prevents inefficiencies. Simulation results show that the enhanced algorithm reduces energy consumption, improves offloading efficiency and the accuracy of Federated SSL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14831v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xueying Gu, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Optimizing Age of Information in Internet of Vehicles Over Error-Prone Channels</title>
      <link>https://arxiv.org/abs/2412.13204</link>
      <description>arXiv:2412.13204v2 Announce Type: replace-cross 
Abstract: In the Internet of Vehicles (IoV), Age of Information (AoI) has become a vital performance metric for evaluating the freshness of information in communication systems. Although many studies aim to minimize the average AoI of the system through optimized resource scheduling schemes, they often fail to adequately consider the queue characteristics. Moreover, the vehicle mobility leads to rapid changes in network topology and channel conditions, making it difficult to accurately reflect the unique characteristics of vehicles with the calculated AoI under ideal channel conditions. This paper examines the impact of Doppler shifts caused by vehicle speeds on data transmission in error-prone channels. Based on the M/M/1 and D/M/1 queuing theory models, we derive expressions for the Age of Information and optimize the system's average AoI by adjusting the data extraction rates of vehicles (which affect system utilization). We propose an online optimization algorithm that dynamically adjusts the vehicles' data extraction rates based on environmental changes to ensure optimal AoI. Simulation results have demonstrated that adjusting the data extraction rates of vehicles can significantly reduce the system's AoI. Additionally, in the network scenario of this work, the AoI of the D/M/1 system is lower than that of the M/M/1 system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13204v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cui Zhang, Maoxin Ji, Qiong Wu, Pingyi Fan, Qiang Fan</dc:creator>
    </item>
    <item>
      <title>DVFS-Aware DNN Inference on GPUs: Latency Modeling and Performance Analysis</title>
      <link>https://arxiv.org/abs/2502.06295</link>
      <description>arXiv:2502.06295v2 Announce Type: replace-cross 
Abstract: The rapid development of deep neural networks (DNNs) is inherently accompanied by the problem of high computational costs. To tackle this challenge, dynamic voltage frequency scaling (DVFS) is emerging as a promising technology for balancing the latency and energy consumption of DNN inference by adjusting the computing frequency of processors. However, most existing models of DNN inference time are based on the CPU-DVFS technique, and directly applying the CPU-DVFS model to DNN inference on GPUs will lead to significant errors in optimizing latency and energy consumption. In this paper, we propose a DVFS-aware latency model to precisely characterize DNN inference time on GPUs. We first formulate the DNN inference time based on extensive experiment results for different devices and analyze the impact of fitting parameters. Then by dividing DNNs into multiple blocks and obtaining the actual inference time, the proposed model is further verified. Finally, we compare our proposed model with the CPU-DVFS model in two specific cases. Evaluation results demonstrate that local inference optimization with our proposed model achieves a reduction of no less than 66% and 69% in inference time and energy consumption respectively. In addition, cooperative inference with our proposed model can improve the partition policy and reduce the energy consumption compared to the CPU-DVFS model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06295v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunchu Han, Zhaojun Nan, Sheng Zhou, Zhisheng Niu</dc:creator>
    </item>
  </channel>
</rss>
