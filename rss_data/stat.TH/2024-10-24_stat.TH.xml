<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Oct 2024 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>About the matrix variate problem involved in the distribution of $\mathbf{E}^{-1}\mathbf{H}$</title>
      <link>https://arxiv.org/abs/2410.18310</link>
      <description>arXiv:2410.18310v1 Announce Type: new 
Abstract: This work studies the distribution of the nonsymmetric matrix $\mathbf{E}^{-1}\mathbf{H}$. This random product is of fundamental interest under the general multivariate linear hypothesis setting. Specifically when $\mathbf{H}$ and $\mathbf{E}$ are seen as the sums of squares and the sums of products due to the hypothesis and due to the error, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18310v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e A. D\'iaz-Garc\'ia, Francisco J. Caro-Lopera</dc:creator>
    </item>
    <item>
      <title>Multiple imputation and full law identifiability</title>
      <link>https://arxiv.org/abs/2410.18688</link>
      <description>arXiv:2410.18688v1 Announce Type: new 
Abstract: The key problems in missing data models involve the identifiability of two distributions: the target law and the full law. The target law refers to the joint distribution of the data variables, while the full law refers to the joint distribution of both the data variables and the response indicators. It has not been clearly stated how identifiability of the target law and the full law relate to multiple imputation. We show that imputations can be drawn from the correct conditional distributions if only if the full law is identifiable. This result means that direct application of multiple imputation may not be the method of choice in cases where the target law is identifiable but the full law is not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18688v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juha Karvanen, Santtu Tikka</dc:creator>
    </item>
    <item>
      <title>Limit Theorems for the Symbolic Correlation Integral and the Renyi-2 Entropy under Short-range Dependence</title>
      <link>https://arxiv.org/abs/2410.18726</link>
      <description>arXiv:2410.18726v1 Announce Type: new 
Abstract: The symbolic correlation integral provides a way to measure the complexity of time series and dynamical systems. In the present article we prove limit results for an estimator of this quantity which is based on U-statistics under the assumption of short-range dependence. To this end, we slightly generalize classical limit results in the framework of 1-approximating functionals. Furthermore, we carefully analyze the limit variance. A simulation study with ARMA and ARCH time series as well as a real world data example are also provided. In the latter we show how our method could be used to analyze EEG data in the context of epileptic seizures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18726v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Schnurr, Angelika Silbernagel, Manuel Ruiz Marin</dc:creator>
    </item>
    <item>
      <title>Can we spot a fake?</title>
      <link>https://arxiv.org/abs/2410.18880</link>
      <description>arXiv:2410.18880v1 Announce Type: new 
Abstract: The problem of detecting fake data inspires the following seemingly simple mathematical question. Sample a data point $X$ from the standard normal distribution in $\mathbb{R}^n$. An adversary observes $X$ and corrupts it by adding a vector $rt$, where they can choose any vector $t$ from a fixed set $T$ of the adversary's "tricks", and where $r&gt;0$ is a fixed radius. The adversary's choice of $t=t(X)$ may depend on the true data $X$. The adversary wants to hide the corruption by making the fake data $X+rt$ statistically indistinguishable from the real data $X$. What is the largest radius $r=r(T)$ for which the adversary can create an undetectable fake? We show that for highly symmetric sets $T$, the detectability radius $r(T)$ is approximately twice the scaled Gaussian width of $T$. The upper bound actually holds for arbitrary sets $T$ and generalizes to arbitrary, non-Gaussian distributions of real data $X$. The lower bound may fail for not highly symmetric $T$, but we conjecture that this problem can be solved by considering the focused version of the Gaussian width of $T$, which focuses on the most important directions of $T$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18880v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahar Mendelson, Grigoris Paouris, Roman Vershynin</dc:creator>
    </item>
    <item>
      <title>On the Existence of One-Sided Representations in the Generalised Dynamic Factor Model</title>
      <link>https://arxiv.org/abs/2410.18159</link>
      <description>arXiv:2410.18159v1 Announce Type: cross 
Abstract: We consider the generalised dynamic factor model (GDFM) and assume that the dynamic common component is purely non-deterministic. We show that then the common shocks (and therefore the dynamic common component) can always be represented in terms of current and past observed variables. Hence, we further generalise existing results on the so called One-Sidedness problem of the GDFM. We may conclude that the existence of a one-sided representation that is causally subordinated to the observed variables is in the very nature of the GDFM and the lack of one-sidedness is an artefact of the chosen representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18159v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Gersing</dc:creator>
    </item>
    <item>
      <title>Stochastic gradient descent in high dimensions for multi-spiked tensor PCA</title>
      <link>https://arxiv.org/abs/2410.18162</link>
      <description>arXiv:2410.18162v1 Announce Type: cross 
Abstract: We study the dynamics in high dimensions of online stochastic gradient descent for the multi-spiked tensor model. This multi-index model arises from the tensor principal component analysis (PCA) problem with multiple spikes, where the goal is to estimate $r$ unknown signal vectors within the $N$-dimensional unit sphere through maximum likelihood estimation from noisy observations of a $p$-tensor. We determine the number of samples and the conditions on the signal-to-noise ratios (SNRs) required to efficiently recover the unknown spikes from natural random initializations. We show that full recovery of all spikes is possible provided a number of sample scaling as $N^{p-2}$, matching the algorithmic threshold identified in the rank-one case [Ben Arous, Gheissari, Jagannath 2020, 2021]. Our results are obtained through a detailed analysis of a low-dimensional system that describes the evolution of the correlations between the estimators and the spikes, while controlling the noise in the dynamics. We find that the spikes are recovered sequentially in a process we term "sequential elimination": once a correlation exceeds a critical threshold, all correlations sharing a row or column index become sufficiently small, allowing the next correlation to grow and become macroscopic. The order in which correlations become macroscopic depends on their initial values and the corresponding SNRs, leading to either exact recovery or recovery of a permutation of the spikes. In the matrix case, when $p=2$, if the SNRs are sufficiently separated, we achieve exact recovery of the spikes, whereas equal SNRs lead to recovery of the subspace spanned by the spikes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18162v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\'erard Ben Arous, C\'edric Gerbelot, Vanessa Piccolo</dc:creator>
    </item>
    <item>
      <title>Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality</title>
      <link>https://arxiv.org/abs/2410.18784</link>
      <description>arXiv:2410.18784v1 Announce Type: cross 
Abstract: The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this prior work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Our theory is established based on a key observation: the DDPM update rule is equivalent to running a suitably parameterized SDE upon discretization, where the nonlinear component of the drift term is intrinsically low-dimensional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18784v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Huang, Yuting Wei, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>On the mean-field limit of diffusive games through the master equation: extreme value analysis</title>
      <link>https://arxiv.org/abs/2410.18869</link>
      <description>arXiv:2410.18869v1 Announce Type: cross 
Abstract: We consider an $N$-player game where the players control the drifts of their diffusive states which have no interaction in the noise terms. The aim of each player is to minimize the expected value of her cost, which is a function of the player's state and the empirical measure of the states of all the players. Our aim is to determine the $N \to \infty$ asymptotic behavior of the upper order statistics of the player's states under Nash equilibrium (the Nash states). For this purpose, we consider also a system of interacting diffusions which is constructed by using the Master PDE of the game and approximates the system of the Nash states, and we improve an $L^2$ estimate for the distance between the drifts of the two systems which has been used for establishing Central Limit Theorems and Large Deviations Principles for the Nash states in the past. By differentiating the Master PDE, we obtain that estimate also in $L^{\infty}$, which allows us to control the Radon-Nikodym derivative of a Girsanov transformation that connects the two systems. The latter allows us to reduce the problem to the case of $N$ uncontrolled diffusions with standard mean-field interaction in the drifts, which has been treated in a previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18869v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>q-fin.MF</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Nikolaos Kolliopoulos</dc:creator>
    </item>
    <item>
      <title>A Random Matrix Theory Perspective on the Spectrum of Learned Features and Asymptotic Generalization Capabilities</title>
      <link>https://arxiv.org/abs/2410.18938</link>
      <description>arXiv:2410.18938v1 Announce Type: cross 
Abstract: A key property of neural networks is their capacity of adapting to data during training. Yet, our current mathematical understanding of feature learning and its relationship to generalization remain limited. In this work, we provide a random matrix analysis of how fully-connected two-layer neural networks adapt to the target function after a single, but aggressive, gradient descent step. We rigorously establish the equivalence between the updated features and an isotropic spiked random feature model, in the limit of large batch size. For the latter model, we derive a deterministic equivalent description of the feature empirical covariance matrix in terms of certain low-dimensional operators. This allows us to sharply characterize the impact of training in the asymptotic feature spectrum, and in particular, provides a theoretical grounding for how the tails of the feature spectrum modify with training. The deterministic equivalent further yields the exact asymptotic generalization error, shedding light on the mechanisms behind its improvement in the presence of feature learning. Our result goes beyond standard random matrix ensembles, and therefore we believe it is of independent technical interest. Different from previous work, our result holds in the challenging maximal learning rate regime, is fully rigorous and allows for finitely supported second layer initialization, which turns out to be crucial for studying the functional expressivity of the learned features. This provides a sharp description of the impact of feature learning in the generalization of two-layer neural networks, beyond the random features and lazy training regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18938v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yatin Dandi, Luca Pesce, Hugo Cui, Florent Krzakala, Yue M. Lu, Bruno Loureiro</dc:creator>
    </item>
    <item>
      <title>Tail-adaptive Bayesian shrinkage</title>
      <link>https://arxiv.org/abs/2007.02192</link>
      <description>arXiv:2007.02192v5 Announce Type: replace 
Abstract: Robust Bayesian methods for high-dimensional regression problems under diverse sparse regimes are studied. Traditional shrinkage priors are primarily designed to detect a handful of signals from tens of thousands of predictors in the so-called ultra-sparsity domain. However, they may not perform desirably when the degree of sparsity is moderate. In this paper, we propose a robust sparse estimation method under diverse sparsity regimes, which has a tail-adaptive shrinkage property. In this property, the tail-heaviness of the prior adjusts adaptively, becoming larger or smaller as the sparsity level increases or decreases, respectively, to accommodate more or fewer signals, a posteriori. We propose a global-local-tail (GLT) Gaussian mixture distribution that ensures this property. We examine the role of the tail-index of the prior in relation to the underlying sparsity level and demonstrate that the GLT posterior contracts at the minimax optimal rate for sparse normal mean models. We apply both the GLT prior and the Horseshoe prior to a real data problem and simulation examples. Our findings indicate that the varying tail rule based on the GLT prior offers advantages over a fixed tail rule based on the Horseshoe prior in diverse sparsity regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.02192v5</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Se Yoon Lee, Peng Zhao, Debdeep Pati, Bani K. Mallick</dc:creator>
    </item>
    <item>
      <title>Approximation and estimation of scale functions for spectrally negative Levy processes</title>
      <link>https://arxiv.org/abs/2402.13599</link>
      <description>arXiv:2402.13599v2 Announce Type: replace 
Abstract: The scale function holds significant importance within the fluctuation theory of Levy processes, particularly in addressing exit problems. However, its definition is established through the Laplace transform, thereby lacking explicit representations in general. This paper introduces a novel series representation for this scale function, employing Laguerre polynomials to construct a uniformly convergent approximate sequence. Additionally, we derive statistical inference based on specific discrete observations, presenting estimators of scale functions that are asymptotically normal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13599v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haruka Irie, Yasutaka Shimizu</dc:creator>
    </item>
    <item>
      <title>Robust Estimation and Inference for Categorical Data</title>
      <link>https://arxiv.org/abs/2403.11954</link>
      <description>arXiv:2403.11954v2 Announce Type: replace-cross 
Abstract: While there is a rich literature on robust methodologies for contamination in continuously distributed data, contamination in categorical data is largely overlooked. This is regrettable because many datasets are categorical and oftentimes suffer from contamination. Examples include inattentive responding and bot responses in questionnaires or zero-inflated count data. We propose a novel class of contamination-robust estimators of models for categorical data, coined $C$-estimators (``$C$" for categorical). We show that the countable and possibly finite sample space of categorical data results in non-standard theoretical properties. Notably, in contrast to classic robustness theory, $C$-estimators can be simultaneously robust \textit{and} fully efficient at the postulated model. In addition, a certain particularly robust specification fails to be asymptotically Gaussian at the postulated model, but is asymptotically Gaussian in the presence of contamination. We furthermore propose a diagnostic test to identify categorical outliers and demonstrate the enhanced robustness of $C$-estimators in a simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11954v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Welz</dc:creator>
    </item>
    <item>
      <title>Robust Estimation of Polychoric Correlation</title>
      <link>https://arxiv.org/abs/2407.18835</link>
      <description>arXiv:2407.18835v2 Announce Type: replace-cross 
Abstract: Polychoric correlation is often an important building block in the analysis of rating data, particularly for structural equation models. However, the commonly employed maximum likelihood (ML) estimator is highly susceptible to misspecification of the polychoric correlation model, for instance through violations of latent normality assumptions. We propose a novel estimator that is designed to be robust to partial misspecification of the polychoric model, that is, the model is only misspecified for an unknown fraction of observations, for instance (but not limited to) careless respondents. In contrast to existing literature, our estimator makes no assumption on the type or degree of model misspecification. It furthermore generalizes ML estimation and is consistent as well as asymptotically normally distributed. We demonstrate the robustness and practical usefulness of our estimator in simulation studies and an empirical application on a Big Five administration. In the latter, the polychoric correlation estimates of our estimator and ML differ substantially, which, after further inspection, is likely due to the presence of careless respondents that the estimator helps identify.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18835v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Welz, Patrick Mair, Andreas Alfons</dc:creator>
    </item>
    <item>
      <title>Moment varieties of the inverse Gaussian and gamma distributions are nondefective</title>
      <link>https://arxiv.org/abs/2409.18421</link>
      <description>arXiv:2409.18421v2 Announce Type: replace-cross 
Abstract: We show that the parameters of a $k$-mixture of inverse Gaussian or gamma distributions are algebraically identifiable from the first $3k-1$ moments, and rationally identifiable from the first $3k+2$ moments. Our proofs are based on Terracini's classification of defective surfaces, careful analysis of the intersection theory of moment varieties, and a recent result on sufficient conditions for rational identifiability of secant varieties by Massarenti--Mella.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18421v2</guid>
      <category>math.AG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oskar Henriksson, Kristian Ranestad, Lisa Seccia, Teresa Yu</dc:creator>
    </item>
    <item>
      <title>Data Augmentation of Multivariate Sensor Time Series using Autoregressive Models and Application to Failure Prognostics</title>
      <link>https://arxiv.org/abs/2410.16419</link>
      <description>arXiv:2410.16419v2 Announce Type: replace-cross 
Abstract: This work presents a novel data augmentation solution for non-stationary multivariate time series and its application to failure prognostics. The method extends previous work from the authors which is based on time-varying autoregressive processes. It can be employed to extract key information from a limited number of samples and generate new synthetic samples in a way that potentially improves the performance of PHM solutions. This is especially valuable in situations of data scarcity which are very usual in PHM, especially for failure prognostics. The proposed approach is tested based on the CMAPSS dataset, commonly employed for prognostics experiments and benchmarks. An AutoML approach from PHM literature is employed for automating the design of the prognostics solution. The empirical evaluation provides evidence that the proposed method can substantially improve the performance of PHM solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16419v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Douglas Baptista de Souza, Bruno Paes Leao</dc:creator>
    </item>
    <item>
      <title>Estimating the Spectral Moments of the Kernel Integral Operator from Finite Sample Matrices</title>
      <link>https://arxiv.org/abs/2410.17998</link>
      <description>arXiv:2410.17998v2 Announce Type: replace-cross 
Abstract: Analyzing the structure of sampled features from an input data distribution is challenging when constrained by limited measurements in both the number of inputs and features. Traditional approaches often rely on the eigenvalue spectrum of the sample covariance matrix derived from finite measurement matrices; however, these spectra are sensitive to the size of the measurement matrix, leading to biased insights. In this paper, we introduce a novel algorithm that provides unbiased estimates of the spectral moments of the kernel integral operator in the limit of infinite inputs and features from finitely sampled measurement matrices. Our method, based on dynamic programming, is efficient and capable of estimating the moments of the operator spectrum. We demonstrate the accuracy of our estimator on radial basis function (RBF) kernels, highlighting its consistency with the theoretical spectra. Furthermore, we showcase the practical utility and robustness of our method in understanding the geometry of learned representations in neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17998v2</guid>
      <category>cs.LG</category>
      <category>math.SP</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chanwoo Chun, SueYeon Chung, Daniel D. Lee</dc:creator>
    </item>
  </channel>
</rss>
