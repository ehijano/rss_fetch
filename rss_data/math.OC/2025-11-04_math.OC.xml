<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 02:38:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Stochastic Optimal Control Problems for the Cost-Optimal Management of a Standalone Microgrid</title>
      <link>https://arxiv.org/abs/2511.00167</link>
      <description>arXiv:2511.00167v1 Announce Type: new 
Abstract: In this paper, we consider a domestic standalone microgrid equipped with local renewable energy generation such as photovoltaic panels, consumption units, and battery storage to balance supply and demand and investigate the stochastic optimal control problem for its cost-optimal management. As a special feature, the manager does not have access to the power grid but has a local generator, making it possible to produce energy using fuel when needed. Such systems are very important for rural electrification, particularly in developing countries. However, these systems are very complex to control due to uncertainties in the weather and environmental conditions, which affect the energy generation and the energy demand. In addition, we assume that the battery and the fuel tank have limited capacities and that the fuel tank can only be filled once at the beginning of the planning period. This leads us to the so-called finite fuel problem. In addition, we allow the energy demand to not always be satisfied, and we impose penalties on unsatisfied demand, the so-called discomfort cost. The main goal is to minimize the expected aggregated cost of generating power using the generator and operating the system. This leads to a mathematical optimization problem. The problem is formulated as a discrete-time stochastic control problem and solved numerically using methods from the theory of Markov decision processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00167v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Honore Takam, Nathalie Fruiba</dc:creator>
    </item>
    <item>
      <title>A Tight SDP Relaxation for the Cubic-Quartic Regularization Problem</title>
      <link>https://arxiv.org/abs/2511.00168</link>
      <description>arXiv:2511.00168v1 Announce Type: new 
Abstract: This paper studies how to compute global minimizers of the cubic-quartic regularization (CQR) problem \[ \min_{s \in \mathbb{R}^n} \quad f_0+g^Ts+\frac{1}{2}s^THs+\frac{\beta}{6} \| s \|^3+\frac{\sigma}{4} \| s \|^4, \] where $f_0$ is a constant, $g$ is an $n$-dimensional vector, $H$ is a $n$-by-$n$ symmetric matrix, and $\| s \|$ denotes the Euclidean norm of $s$. The parameter $\sigma \ge 0$ while $\beta$ can have any sign. The CQR problem arises as a critical subproblem for getting efficient regularization methods for solving unconstrained nonlinear optimization. Its properties are recently well studied by Cartis and Zhu [cubic-quartic regularization models for solving polynomial subproblems in third-order tensor methods, Math. Program, 2025]. However, a practical method for computing global minimizers of the CQR problem still remains elusive. To this end, we propose a semidefinite programming (SDP) relaxation method for solving the CQR problem globally. First, we show that our SDP relaxation is tight if and only if $\| s^* \| ( \beta + 3 \sigma \| s^* \|) \ge 0$ holds for a global minimizer $s^*$. In particular, if either $\beta \ge 0$ or $H$ has a nonpositive eigenvalue, then the SDP relaxation is shown to be tight. Second, we show that all nonzero global minimizers have the same length for the tight case. Third, we give an algorithm to detect tightness and to obtain the set of all global minimizers. Numerical experiments demonstrate that our SDP relaxation method is both effective and computationally efficient, providing the first practical method for globally solving the CQR problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00168v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinling Zhou, Xin Liu, Jiawang Nie, Xindong Tang</dc:creator>
    </item>
    <item>
      <title>SHAP values through General Fourier Representations: Theory and Applications</title>
      <link>https://arxiv.org/abs/2511.00185</link>
      <description>arXiv:2511.00185v1 Announce Type: new 
Abstract: This article establishes a rigorous spectral framework for the mathematical analysis of SHAP values. We show that any predictive model defined on a discrete or multi-valued input space admits a generalized Fourier expansion with respect to an orthonormalisation tensor-product basis constructed under a product probability measure. Within this setting, each SHAP attribution can be represented as a linear functional of the model's Fourier coefficients.
  Two complementary regimes are studied. In the deterministic regime, we derive quantitative stability estimates for SHAP values under Fourier truncation, showing that the attribution map is Lipschitz continuous with respect to the distance between predictors. In the probabilistic regime, we consider neural networks in their infinite-width limit and prove convergence of SHAP values toward those induced by the corresponding Gaussian process prior, with explicit error bounds in expectation and with high probability based on concentration inequalities.
  We also provide a numerical experiment on a clinical unbalanced dataset to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00185v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Morales</dc:creator>
    </item>
    <item>
      <title>Multivariable Gradient-Based Extremum Seeking Control with Saturation Constraints</title>
      <link>https://arxiv.org/abs/2511.00208</link>
      <description>arXiv:2511.00208v1 Announce Type: new 
Abstract: This paper addresses the multivariable gradient-based extremum seeking control (ESC) subject to saturation. Two distinct saturation scenarios are investigated here: saturation acting on the input of the function to be optimized, which is addressed using an anti-windup compensation strategy, and saturation affecting the gradient estimate. In both cases, the unknown Hessian matrix is represented using a polytopic uncertainty description, and sufficient conditions in the form of linear matrix inequalities (LMIs) are derived to design a stabilizing control gain. The proposed conditions guarantee exponential stability of the origin for the average closed-loop system under saturation constraints. With the proposed design conditions, non-diagonal control gain matrices can be obtained, generalizing conventional ESC designs that typically rely on diagonal structures. Stability and convergence are rigorously proven using the Averaging Theory for dynamical systems with Lipschitz continuous right-hand sides. Numerical simulations illustrate the effectiveness of the proposed ESC algorithms, confirming the convergence even in the presence of saturation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00208v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enzo Ferreira Tomaz Silva, Pedro Henrique Silva Coutinho, Tiago Roux Oliveira, Miroslav Krsti\'c, Sophie Tarbouriech</dc:creator>
    </item>
    <item>
      <title>A non-exchangeable mean field control problem with controlled interactions</title>
      <link>https://arxiv.org/abs/2511.00288</link>
      <description>arXiv:2511.00288v1 Announce Type: new 
Abstract: This paper introduces and analyzes a new class of mean-field control (\textsc{MFC}) problems in which agents interact through a \emph{fixed but controllable} network structure. In contrast with the classical \textsc{MFC} framework -- where agents are exchangeable and interact only through symmetric empirical distributions -- we consider systems with heterogeneous and possibly asymmetric interaction patterns encoded by a structural kernel, typically of graphon type. A key novelty of our approach is that this interaction structure is no longer static: it becomes a genuine \emph{control variable}. The planner therefore optimizes simultaneously two distinct components: a \emph{regular control}, which governs the local dynamics of individual agents, and an \emph{interaction control}, which shapes the way agents connect and influence each other through the fixed structural kernel.
  \medskip We develop a generalized notion of relaxed (randomized) control adapted to this setting, prove its equivalence with the strong formulation, and establish existence, compactness, and continuity results for the associated value function under minimal regularity assumptions. Moreover, we show that the finite $n$-agent control problems with general (possibly asymmetric) interaction matrices converge to the mean-field limit when the corresponding fixed step-kernels converge in cut-norm, with asymptotic consistency of the optimal values and control strategies. Our results provide a rigorous framework in which the \emph{interaction structure itself is viewed and optimized as a control object}, thereby extending mean-field control theory to non-exchangeable populations and controlled network interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00288v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mao Fabrice Djete</dc:creator>
    </item>
    <item>
      <title>A Finite Dominating Set Approach for the Multi-Item Multi-Period Order Allocation Problem under All-Unit Quantity Discounts and Blending Ratios</title>
      <link>https://arxiv.org/abs/2511.00300</link>
      <description>arXiv:2511.00300v1 Announce Type: new 
Abstract: This study addresses the multi-item multi-period order allocation problem under all-unit quantity discounts (AUQD) and blending ratios. A manufacturer makes a single product that requires mixing/assembling multiple ingredients/components with pre-determined blending ratios. We consider a single supplier offering quantity-based discounts which introduces non-linearities to the problem. The objective is to minimize procurement cost which includes purchasing, inventory, and ordering costs. We develop a solution procedure that systematically generates a finite dominating set (FDS) of order quantities guaranteed to include an optimal solution to the problem. A Mixed Integer Linear Programming (MILP) model based on the FDS. Our procedure guarantees optimality and eliminates the need for nonlinear discount modeling. Numerical experiments demonstrate that the proposed MILP achieves optimal solutions with significantly reduced computational effort, up to 99% faster for large-scale instances compared to conventional formulations. Sensitivity analyses reveal that the model dynamically adapts to changes in holding costs, shifting between bulk-purchasing and just-in-time strategies, and identifying cost-sensitive ingredients that drive total system cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00300v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fuhad Ahmed Opu, Moddassir Khan Nayeem, Hamid Najafzad, Omar Abbaas</dc:creator>
    </item>
    <item>
      <title>Transit-MP: Transit-Prioritized Max-Pressure Control in Sparse Connected Vehicle Environments</title>
      <link>https://arxiv.org/abs/2511.00309</link>
      <description>arXiv:2511.00309v1 Announce Type: new 
Abstract: Max-pressure (MP) control stands out among real-time network traffic signal control methods due to its simplicity, decentralized nature, and theoretical stability. However, existing MP control methods have limited consideration of public transportation and do not address the network stability problem of transit-prioritized MP in partially connected vehicle (CV) environments. In this study, we propose Transit-MP, which realizes transit-prioritized MP control in partially CV environments by considering real-time vehicle occupancy and the impact of transit dwell at stations. Theoretically, we demonstrate that Transit-MP, while using different traffic state measures for upstream and downstream links for pressure calculation, still achieves road network stability even in partially CV environments. Note that for MP controllers in sparse CV environments, some movements may have missing CV observations, leading to link spillovers, which create the queue starvation phenomenon: a movement no longer receives the green phase despite the queue spillover. Therefore, we further propose a modified Transit-MP (mTransit-MP) that incorporates historical traffic data to address this issue. We rigorously prove that the proposed mTransit-MP can effectively avoid the queue starvation phenomenon. Experimental results on a real-world corridor in Amsterdam with 15 transit lines and 31 stations show that our method significantly reduces the real-time vehicle and spillover count, and improves delays for both private vehicles and transit vehicles compared to a state-of-the-art MP controller for transit signal priority. In sparse CV environments, our mTransit-MP is effective in mitigating link spillovers while enhancing the overall performance of multi-modal traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00309v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaopeng Tan, Hao Liu, Dingshan Sun, Marco Rinaldi, Hans van Lint</dc:creator>
    </item>
    <item>
      <title>Accelerated primal dual fixed point algorithm</title>
      <link>https://arxiv.org/abs/2511.00385</link>
      <description>arXiv:2511.00385v1 Announce Type: new 
Abstract: This work proposes an Accelerated Primal-Dual Fixed-Point (APDFP) method that employs Nesterov type acceleration to solve composite problems of the form min f(x) + g(Bx), where g is nonsmooth and B is a linear operator. The APDFP features fully decoupled iterations and can be regarded as a generalization of Nesterov's accelerated gradient in the setting where B can be a non-identity matrix. Theoretically, we improve the convergence rate of the partial primal-dual gap with respect to the Lipschitz constant of the gradient of f from O(1/k) to O(1/k^2). Numerical experiments on graph-guided logistic regression and CT image reconstruction are conducted to validate the correctness and demonstrate the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00385v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-Nan Zhu</dc:creator>
    </item>
    <item>
      <title>On the Convexification of a Class of Mixed-Integer Conic Sets</title>
      <link>https://arxiv.org/abs/2511.00452</link>
      <description>arXiv:2511.00452v1 Announce Type: new 
Abstract: We investigate mixed-integer second-order conic (SOC) sets with a nonlinear right-hand side in the SOC constraint, a structure frequently arising in mixed-integer quadratically constrained programming (MIQCP). Under mild assumptions, we show that the convex hull can be exactly described by replacing the right-hand side with its concave envelope. This characterization enables strong relaxations for MIQCPs via reformulations and cutting planes. Computational experiments on distributionally robust chance-constrained knapsack variants demonstrate the efficacy of our reformulation techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00452v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guxin Du, Rui Chen, Linchuan Wei</dc:creator>
    </item>
    <item>
      <title>Optimization of continuous-flow over traffic networks with fundamental diagram constraints</title>
      <link>https://arxiv.org/abs/2511.00500</link>
      <description>arXiv:2511.00500v1 Announce Type: new 
Abstract: Optimal transport (OT) theory provides a principled framework for modeling mass movement in applications such as mobility, logistics, and economics. Classical formulations, however, generally ignore capacity limits that are intrinsic in applications, in particular in traffic flow problems. We address this limitation by incorporating fundamental diagrams into a dynamic continuous-flow OT model on graphs, thereby including empirical relations between local density and maximal flux. We adopt an Eulerian kinetic action on graphs that preserves displacement interpolation in direct analogy with the continuous theory. Momentum lives on edges and density on nodes, mirroring road-network semantics in which segments carry speed and intersections store mass. The resulting fundamental-diagram-constrained OT problem preserves mass conservation and admits a convex variational discretization, yielding optimal congestion-aware traffic flow over road networks. We establish the existence and uniqueness of the optimal flow with sources and sinks, and develop an efficient convex optimization method. Numerical studies begin with a single-lane line network and scale to a city-level road network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00500v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Karl Henrik Johansson, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>Cutting plane methods with gradient-based heuristics</title>
      <link>https://arxiv.org/abs/2511.00520</link>
      <description>arXiv:2511.00520v1 Announce Type: new 
Abstract: Cutting plane methods, particularly outer approximation, are a well-established approach for solving nonlinear discrete optimization problems without relaxing the integrality of decision variables. While powerful in theory, their computational performance can be highly variable. Recent research has shown that constructing cutting planes at the projection of infeasible points onto the feasible set can significantly improve the performance of cutting plane approaches. Motivated by this, we examine whether constructing cuts at feasible points closer to the optimal solution set could further enhance the effectiveness of cutting plane methods. We propose a hybrid method that combines the global convergence guarantees of cutting plane methods with the local exploration capabilities of first-order optimization techniques. Specifically, we use projected gradient methods as a heuristic to identify promising regions of the solution space and generate tighter, more informative cuts. We focus on binary optimization problems with convex differentiable objective functions, where projection operations can be efficiently computed via mixed-integer linear programming. By constructing cuts at points closer to the optimal solution set and eliminating non-optimal regions, the algorithm achieves better approximation of the feasible region and faster convergence. Numerical experiments confirm that our approach improves both the quality of the solution and computational efficiency across different solver configurations. This framework provides a flexible foundation for further extensions to more general discrete domains and offers a promising heuristic to the toolkit for nonlinear discrete optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00520v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H\`oa T. B\`ui, Alberto De Marchi</dc:creator>
    </item>
    <item>
      <title>Evolving School Transport Electrification: Integrated Dynamic Route Optimization and Partial Charging for Mixed Fleets</title>
      <link>https://arxiv.org/abs/2511.00600</link>
      <description>arXiv:2511.00600v1 Announce Type: new 
Abstract: School bus transportation, the largest fleet size for public transportation in the US, plays a significant role in sustainability through transport decarbonization. Thus, effective planning of electric school bus routes and recharge schedules is vital. This study proposes a novel approach that simultaneously addresses electric school bus dynamic routing and partial charge scheduling, considering practical scenarios such as varying student demands, bus capacities, maximum ride time, stop time window, and fleet mixes. The model incorporates constraints like bell time tolerance and battery capacity and charging infrastructure candidate location, making it robust for school bus electrification. A linearized Mixed Integer Programming (MIP) model for homogeneous and heterogeneous fleets with full and partial recharging strategies is formulated. The proposed objective function for nonlinear and linear models is executed and compared for computational effectiveness. The model is tested on various sizes of school networks using modified benchmark instances, and a real-world case study demonstrates the benefits of electrified school transportation. The results show that employing heterogeneous fleets can lead to cost savings, reduced routing distance, and travel time for both the tested networks and the case study. Sensitivity analyses highlight the trade-offs between battery size and total cost. Furthermore, the benefits of partial charging and optimum riding time for school bus routes are suggested. The proposed optimization approach can achieve significant reductions in travel distance, up to 56.4% compared to the current situation and fleet size, supporting the case for school transport electrification. Potential additional investment subsidies from federal and state governments are added benefits for accelerated school bus electrification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00600v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Megh Bahadur KC, Ziqi Song</dc:creator>
    </item>
    <item>
      <title>RNN-based linear parameter varying adaptive model predictive control for autonomous driving</title>
      <link>https://arxiv.org/abs/2511.00610</link>
      <description>arXiv:2511.00610v1 Announce Type: new 
Abstract: Autonomous driving is a complex and highly dynamic process that ensures controlling the coupled longitudinal and lateral vehicle dynamics. Model predictive control, distinguished by its predictive feature, optimal performance, and ability to handle constraints, makes it one of the most promising tools for this type of control application. The content of this article handles the problem of autonomous driving by proposing an adaptive linear parameter varying model predictive controller (LPV-MPC), where the controller's prediction model is adaptive by means of a recurrent neural network. The proposed LPV-MPC is further optimised by a hybrid Genetic and Particle Swarm Optimization Algorithm (GA-PSO). The developed controller is tested and evaluated on a challenging track under variable wind disturbance. Code can be found here : https://github.com/yassinekebbati/GA-PSO-optimized-RNN-MPC</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00610v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/00207721.2024.2414122</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Systems Science 2025</arxiv:journal_reference>
      <dc:creator>Yassine Kebbati, Naima Ait-Oufroukh, Dalil Ichalal, Vincent Vigneron</dc:creator>
    </item>
    <item>
      <title>From Generality to Specificity: Prior-Driven Optimal Sparse Transformation in Compressed Sensing</title>
      <link>https://arxiv.org/abs/2511.00611</link>
      <description>arXiv:2511.00611v1 Announce Type: new 
Abstract: This paper introduces a new paradigm for sparse transformation: the Prior-to-Posterior Sparse Transform (POST) framework, designed to overcome long-standing limitation on generalization and specificity in classical sparse transforms for compressed sensing. POST systematically unifies the generalization capacity of any existing transform domains with the specificity of reference knowledge, enabling flexible adaptation to diverse signal characteristics. Within this framework, we derive an explicit sparse transform domain termed HOT, which adaptively handles both real and complex-valued signals. We theoretically establish HOT's sparse representation properties under single and multiple reference settings, demonstrating its ability to preserve generalization while enhancing specificity even under weak reference information. Extensive experiments confirm that HOT delivers substantial meta-gains across audio sensing, 5G channel estimation, and image compression tasks, consistently boosting multiple compressed sensing algorithms under diverse multimodal settings with negligible computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00611v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Zhu, Yanhao Zhang, Yong Xia</dc:creator>
    </item>
    <item>
      <title>Isotropic Curvature Model for Understanding Deep Learning Optimization: Is Gradient Orthogonalization Optimal?</title>
      <link>https://arxiv.org/abs/2511.00674</link>
      <description>arXiv:2511.00674v1 Announce Type: new 
Abstract: In this paper, we introduce a model for analyzing deep learning optimization over a single iteration by leveraging the matrix structure of the weights. We derive the model by assuming isotropy of curvature, including the second-order Hessian and higher-order terms, of the loss function across all perturbation directions; hence, we call it the isotropic curvature model. This model is a convex optimization program amenable to analysis, which allows us to understand how an update on the weights in the form of a matrix relates to the change in the total loss function. As an application, we use the isotropic curvature model to analyze the recently introduced Muon optimizer and other matrix-gradient methods for training language models. First, we show that under a general growth condition on the curvature, the optimal update matrix is obtained by making the spectrum of the original gradient matrix more homogeneous -- that is, making its singular values closer in ratio -- which in particular improves the conditioning of the update matrix. Next, we show that the orthogonalized gradient becomes optimal for the isotropic curvature model when the curvature exhibits a phase transition in growth. Taken together, these results suggest that the gradient orthogonalization employed in Muon and other related methods is directionally correct but may not be strictly optimal. Finally, we discuss future research on how to leverage the isotropic curvature model for designing new optimization methods for training deep learning and language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00674v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weijie Su</dc:creator>
    </item>
    <item>
      <title>Accelerating Trust-Region Methods: An Attempt to Balance Global and Local Efficiency</title>
      <link>https://arxiv.org/abs/2511.00680</link>
      <description>arXiv:2511.00680v1 Announce Type: new 
Abstract: Historically speaking, it is hard to balance the global and local efficiency of second-order optimization algorithms. For instance, the classical Newton's method possesses excellent local convergence but lacks global guarantees, often exhibiting divergence when the starting point is far from the optimal solution~\cite{more1982newton,dennis1996numerical}. In contrast, accelerated second-order methods offer strong global convergence guarantees, yet they tend to converge with slower local rate~\cite{carmon2022optimal,chen2022accelerating,jiang2020unified}. Existing second-order methods struggle to balance global and local performance, leaving open the question of how much we can globally accelerate the second-order methods while maintaining excellent local convergence guarantee. In this paper, we tackle this challenge by proposing for the first time the accelerated trust-region-type methods, and leveraging their unique primal-dual information. Our primary technical contribution is \emph{Accelerating with Local Detection}, which utilizes the Lagrange multiplier to detect local regions and achieves a global complexity of $\tilde{O}(\epsilon^{-1/3})$, while maintaining quadratic local convergence. We further explore the trade-off when pushing the global convergence to the limit. In particular, we propose the \emph{Accelerated Trust-Region Extragradient Method} that has a global near-optimal rate of $\tilde{O}(\epsilon^{-2/7})$ but loses the quadratic local convergence. This reveals a phase transition in accelerated trust-region type methods: the excellent local convergence can be maintained when achieving a moderate global acceleration but becomes invalid when pursuing the extreme global efficiency. Numerical experiments further confirm the results indicated by our convergence analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00680v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuntian Jiang, Chuwen Zhang, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Projected Subgradient Ascent for Convex Maximization</title>
      <link>https://arxiv.org/abs/2511.00741</link>
      <description>arXiv:2511.00741v1 Announce Type: new 
Abstract: We consider the problem of maximizing a convex function over a closed convex set. Classical methods solve such problems using iterative schemes that repeatedly improve a solution. For linear maximization, we show that a single orthogonal projection suffices to obtain an approximate solution. For general convex functions over convex sets, we show that projected subgradient ascent converges to a first-order stationary point when using arbitrarily large step sizes. Taking the step size to infinity leads to the conditional gradient algorithm, and iterated linear optimization as a special case. We illustrate numerical experiments using a single projection for linear optimization in the elliptope, reducing the problem to the computation of a nearest correlation matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00741v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Felzenszwalb, Heon Lee</dc:creator>
    </item>
    <item>
      <title>Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results</title>
      <link>https://arxiv.org/abs/2511.00752</link>
      <description>arXiv:2511.00752v1 Announce Type: new 
Abstract: This paper introduces a novel model-free, real-time unicycle-based source seeking design. This design steers autonomously the unicycle dynamic system towards the extremum point of an objective function or physical/scaler signal that is unknown expression-wise, but accessible via measurements. A key contribution of this paper is that the introduced design converges exponentially to the extremum point of objective functions (or scaler signals) that behave locally like a higher-degree power functions (e.g., fourth degree polynomial function) as opposed to locally quadratic objective functions, the usual case in literature. We provide theoretical and simulation results to support out theoretical results. Also, for the first time in the literature, we provide experimental robotic results that demonstrate the effectiveness of the proposed design and its exponential convergence ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00752v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Palanikumar, Ahmed A. Elgohary, Victoria Grushkovskaya, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Remarks on the paper "Treatment of Set-Valued Robustness via Separation and Scalarization"</title>
      <link>https://arxiv.org/abs/2511.00928</link>
      <description>arXiv:2511.00928v1 Announce Type: new 
Abstract: In this paper, we remark on the published paper "Treatment of Set-Valued Robustness via Separation and Scalarization" [1], which deals with the robust solution to an uncertain constrained set-valued optimization problem via scalarization methods. We show many inconsistencies in the results of the above-mentioned paper. We improve most of these results. In the process, we introduce some new concepts of robust solutions for uncertain set-valued optimization problems. We also improve some results on scalarization methods applicable to set-valued optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00928v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhik Digar, Kuntal Som</dc:creator>
    </item>
    <item>
      <title>Parallel KKT Solver in PIQP for Multistage Optimization</title>
      <link>https://arxiv.org/abs/2511.00946</link>
      <description>arXiv:2511.00946v1 Announce Type: new 
Abstract: This paper presents an efficient parallel Cholesky factorization and triangular solve algorithm for the Karush-Kuhn-Tucker (KKT) systems arising in multistage optimization problems, with a focus on model predictive control and trajectory optimization for racing. The proposed approach directly parallelizes solving the KKT systems with block-tridiagonal-arrow KKT matrices on the linear algebra level arising in interior-point methods. The algorithm is implemented as a new backend of the PIQP solver and released as open source. Numerical experiments on the chain-of-masses benchmarks and a minimum curvature race line optimization problem demonstrate substantial performance gains compared to other state-of-the-art solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00946v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fenglong Song, Roland Schwan, Yuwen Chen, Colin N. Jones</dc:creator>
    </item>
    <item>
      <title>Dynamic Nash Equilibrium Seeking for a Class of Nonlinear Uncertain Multi-agent Systems</title>
      <link>https://arxiv.org/abs/2511.01002</link>
      <description>arXiv:2511.01002v1 Announce Type: new 
Abstract: We consider seeking a Nash equilibrium (NE) of a monotone game, played by dynamic agents which are modeled as a class of lower-triangular nonlinear uncertain dynamics with external disturbances. We establish a general framework that converts the problem into a distributed robust stabilization problem of an appropriately augmented system. To be specific, we construct a virtual single-integrator multi-agent system, as a reference signal generator, to compute an NE in a fully distributed manner. By introducing internal models to tackle the disturbances, as well as embedding the virtual system, we derive an augmented system. Following that, we show that the outputs of all agents reach an NE of the game if the augmented system can be stabilized by a control law. Finally, resorting to a backstepping procedure, we design a distributed state-feedback controller to stabilize the augmented system semi-globally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01002v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijian Li, Yutao Tang</dc:creator>
    </item>
    <item>
      <title>The problem of minimal resistance, old and new</title>
      <link>https://arxiv.org/abs/2511.01041</link>
      <description>arXiv:2511.01041v1 Announce Type: new 
Abstract: Since its original formulation by Isaac Newton in 1685, the problem of determining bodies of minimal resistance moving through a fluid has been one of the classical problems in the calculus of variations. Initially posed for cylindrically symmetric bodies, the problem was later extended to general convex shapes, as explored in \cite{BK93}, \cite{BFK95}. Since then, this broader formulation has inspired a number of articles dedicated to the study of the geometric and analytical properties of optimal shapes, with particular attention to their structure, regularity, and behavior under various constraints. In this article, we provide a comprehensive overview of the principal results that have been established, highlighting the main theoretical advancements. Furthermore, we introduce some new directions of research, some of which were described in \cite{P12}, that offer promising perspectives for future investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01041v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppe Buttazzo</dc:creator>
    </item>
    <item>
      <title>Projections onto Spectral Matrix Cones</title>
      <link>https://arxiv.org/abs/2511.01089</link>
      <description>arXiv:2511.01089v1 Announce Type: new 
Abstract: Semidefinite programming is a fundamental problem class in convex optimization, but despite recent advances in solvers, solving large-scale semidefinite programs remains challenging. Generally the matrix functions involved are spectral or unitarily invariant, i.e., they depend only on the eigenvalues or singular values of the matrix. This paper investigates how spectral matrix cones -- cones defined from epigraphs and perspectives of spectral or unitarily invariant functions -- can be used to enhance first-order conic solvers for semidefinite programs. Our main result shows that projecting a matrix can be reduced to projecting its eigenvalues or singular values, which we demonstrate can be done at a negligible cost compared to the eigenvalue or singular value decomposition itself. We have integrated support for spectral matrix cone projections into the Splitting Conic Solver (SCS). Numerical experiments show that SCS with this enhancement can achieve speedups of up to an order of magnitude for solving semidefinite programs arising in experimental design, robust principal component analysis, and graph partitioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01089v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Cederberg, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Ergodic Risk Sensitive Control of Diffusions under a General Structural Hypothesis</title>
      <link>https://arxiv.org/abs/2511.01100</link>
      <description>arXiv:2511.01100v1 Announce Type: new 
Abstract: We study the infinite-horizon average (ergodic) risk sensitive control problem for diffusion processes under a general structural hypothesis: there is a partition of state space into two subsets, where the controlled diffusion process satisfies a Foster-Lyapunov type drift condition in one subset, under any stationary Markov control, while the near-monotonicity condition is satisfied with the running cost function being inf-compact in its complement. Under these conditions, we completely characterize the optimal stationary Markov controls. To prove this, we consider an inf-compact perturbation to the running cost over the entire space such that the resulting ergodic risk sensitive control problem is well-defined and then use the corresponding existing results. The heart of the analysis lies in exploiting the variational formula of exponential functionals of Brownian motion and applying it to the objective exponential cost function of the controlled diffusion. This representation facilitates us to view the risk sensitive cost for any stationary Markov control as the optimal value of a control problem of an extended diffusion involving a new auxiliary control where the optimal criterion is to maximize the associated long-run average cost criterion that is a difference of the original running cost and an extra term that is quadratic in the auxiliary control. The main difficulty in using this approach lies in the fact that tightness of mean empirical measures of the extended diffusion is not a priori implied by the analogous tightness property of the original diffusion. We overcome this by establishing a priori estimates for the extended diffusion associated with the nearly optimal auxiliary controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01100v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumith Reddy Anugu, Guodong Pang</dc:creator>
    </item>
    <item>
      <title>A decomposition method in the multivariate feedback particle filter via tensor product Hermite polynomials</title>
      <link>https://arxiv.org/abs/2511.01227</link>
      <description>arXiv:2511.01227v1 Announce Type: new 
Abstract: The feedback particle filter (FPF), a resampling-free algorithm proposed over a decade ago, modifies the particle filter (PF) by incorporating a feedback structure. Each particle in FPF is regulated via a feedback gain function (lacking a closed-form expression), which solves a Poisson's equation with a probability-weighted Laplacian. While approximate solutions to this equation have been extensively studied in recent literature, no efficient multivariate algorithm exists. In this paper, we focus on the decomposition method for multivariate gain functions in FPF, which has been proven efficient for scalar FPF with polynomial observation functions. Its core is splitting the Poisson's equation into two exactly solvable sub-equations. Key challenges in extending it to multivariate FPF include ensuring the invertibility of the coefficient matrix in one sub-equation and constructing a weighted-radial solution in the other. The proposed method's computational complexity grows at most polynomially with the state dimension, a dramatic improvement over the exponential growth of most particle-based algorithms. Numerical experiments compare the decomposition method with traditional methods: the extended Kalman filter (EKF), PF, and FPF with constant-gain or kernel-based gain approximations. Results show it outperforms PF and FPF with other gain approximations in both accuracy and efficiency, achieving the shortest CPU time among methods with comparable performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01227v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoyu Wang, Xue Luo</dc:creator>
    </item>
    <item>
      <title>A parallel pull labelling algorithm for the resource constrained shortest path problem</title>
      <link>https://arxiv.org/abs/2511.01397</link>
      <description>arXiv:2511.01397v1 Announce Type: new 
Abstract: The Resource Constrained Shortest Path Problem (RCSPP) is a fundamental combinatorial optimisation problem in which the goal is to find a least-cost path in a directed graph subject to one or more resource constraints. In this paper we present a pull labelling algorithm for the RCSPP that introduces i) a highly parallelisable approach at a label bucket level, ii) an extension to bi-directional search with a dynamic midpoint, and iii) a vectorised dominance criterion that uses vector instructions to speed-up the label comparison with another level of parallelisation. Compared to a baseline version of the algorithm the optimisations result in a speed-up of around 14x on a set of hard instances and up to 200x on some of the hardest instances. The proposed algorithm demonstrates significant computational improvements that may enhance the efficiency of column generation frameworks incorporating resource constrained shortest path sub-problems, potentially enabling the efficient solution of larger-scale instances in routing, scheduling, supply chain and transportation network optimisation applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01397v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bj{\o}rn Petersen, Simon Spoorendonk</dc:creator>
    </item>
    <item>
      <title>Robust single-stage selection problems with budgeted interval uncertainty</title>
      <link>https://arxiv.org/abs/2511.01416</link>
      <description>arXiv:2511.01416v1 Announce Type: new 
Abstract: We study single-stage decision problems in which a subset of items with minimum total cost has to be selected at once from a given set of items, subject to two costs of each item -fixed and uncertain -and cardinality constraints for each cost type. The worst-case budgeted interval uncertainty is considered. At the time of decision making, the fixed costs are known, but for each uncertain cost, only the range of its values is available. Similar but two-stage selection problems have been studied in the literature, in which first-and second-stage decisions are made before and after uncertain costs become known, respectively. The problems studied are distinguished by continuous or discrete uncertain costs, and by uncertainty budgets based on cardinality or volume. An almost complete computational complexity classification is provided, including fast polynomial-time algorithms, NP-and $\Sigma$ p 2 -completeness and hardness proofs.  keyword robust optimization -budgeted uncertainty -selection problem -dynamic programming -computational complexity</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01416v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Lhomme (G-SCOP\_ROSP), Nadia Brauner (G-SCOP\_ROSP), Evgeny Gurevsky (LS2N - \'equipe MODELIS), Mikhail Kovalyov, Erwin Pesch</dc:creator>
    </item>
    <item>
      <title>Data-driven stabilization of nonlinear systems via descriptor embedding</title>
      <link>https://arxiv.org/abs/2511.01457</link>
      <description>arXiv:2511.01457v1 Announce Type: new 
Abstract: We introduce the notion of descriptor embedding for nonlinear systems and use it for the data-driven design of stabilizing controllers. Specifically, we provide sufficient data-dependent LMI conditions which, if feasible, return a stabilizing nonlinear controller of the form $u=K(x)Z(x)$ where $K(x)$ belongs to a polytope and $Z$ is a user-defined function. The proposed method is then extended to account for the presence of uncertainties and noisy data. Furthermore, a method to estimate the resulting region of attraction is given using only data. Simulation examples are used to illustrate the results and compare them to existing methods from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01457v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Alsalti, Claudio De Persis, Victor G. Lopez, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>Boscia.jl: A review and tutorial</title>
      <link>https://arxiv.org/abs/2511.01479</link>
      <description>arXiv:2511.01479v1 Announce Type: new 
Abstract: Mixed-integer nonlinear optimization (MINLP) comprises a large class of problems that are challenging to solve and exhibit a wide range of structures. The Boscia framework Hendrych et al. (2025b) focuses on convex MINLP where the nonlinearity appears in the objective only. This paper provides an overview of the framework and practical examples to illustrate its use and customizability. One key aspect is the integration and exploitation of Frank-Wolfe methods as continuous solvers within a branch-and-bound framework, enabling inexact node processing, warm-starting and explicit use of combinatorial structure among others. Three examples illustrate its flexibility, the user control over the optimization process and the benefit of oracle-based access to the objective and its gradient. The aim of this tutorial is to provide readers with an understanding of the main principles of the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01479v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjie Xiao, Deborah Hendrych, Mathieu Besan\c{c}on, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Structural and Solution Analysis for the Ordered Weber Problem under Spatial Uncertainty</title>
      <link>https://arxiv.org/abs/2511.01481</link>
      <description>arXiv:2511.01481v2 Announce Type: new 
Abstract: We propose a general analytical framework for single-facility continuous location problems under spatial demand uncertainty. In contrast to classical formulations based on discrete or regionally aggregated demands, the proposed model represents uncertainty through general probability measures on $\R^d$, thereby encompassing finite, bounded, and unbounded support distributions within a unified formulation. The objective aggregates expected distances by means of an ordered weighted averaging operator, providing a flexible mathematical structure that includes the classical Weber problem and its ordered extensions as special cases. We establish fundamental properties of this stochastic ordered Weber model, including convexity, continuity, and existence of optimal solutions, and we derive quantitative bounds on the proximity between stochastic minimizers and the convex hulls of demand supports. Building upon these results, we develop and analyze an adaptive sample average approximation scheme, proving its convergence and deriving finite-sample error estimates under mild regularity conditions. For spherically symmetric distributions, we further obtain explicit analytical expressions for the approximation error. Together, these results provide a rigorous mathematical foundation for a broad class of stochastic ordered location models and highlight new theoretical connections between convex analysis, stochastic programming, and ordered optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01481v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Miguel Mart\'inez-Ant\'on</dc:creator>
    </item>
    <item>
      <title>Mean Field Control of Thermostatically Controlled Loads as Piecewise Deterministic Markov Processes</title>
      <link>https://arxiv.org/abs/2511.01500</link>
      <description>arXiv:2511.01500v1 Announce Type: new 
Abstract: This paper presents a mean-field control approach for Piecewise Deterministic Markov Processes (PDMPs), specifically designed for controlling a large number of agents. By modeling the interactions of a large number of agents through an aggregate cost function, the proposed method mitigates the high dimensionality of the problem by focusing on a representative agent. The contribution of this work is the application of a PDMP-based mean-field control framework to the coordination of a large population of Thermostatically Controlled Loads (TCLs). Adapting this framework to TCLs requires incorporating a quality-of-service constraint ensuring that each agent's temperature remains within a specified comfort range. To achieve this, an additional jump intensity is introduced so that agents are very likely to switch between heating and cooling modes when they reach the boundaries of their temperature range. This extension to TCLs is demonstrated through Water Heaters (WHs) control, with a decentralized algorithm based on a dual formulation and stochastic gradient descent. The numerical results obtained illustrate this approach on two examples (signal tracking and taking into account energy price).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01500v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Le Corre, Adrien S\'eguret, Ana Bu\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>Mean-Field Game for Gene Expression of Beetles</title>
      <link>https://arxiv.org/abs/2511.01523</link>
      <description>arXiv:2511.01523v1 Announce Type: new 
Abstract: In this paper, we investigate the probability of the expression of genes that control the size of beetles under competitive relationships. We use the mean field game (MFG) theory in multiple populations to characterize the different competitive pressures of large and small beetles in the population, and simulate the probability of gene expression in finite time $[0, T]$. Therefore, we prove the existence and uniqueness of the solution of the equation under some assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01523v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Jiang, Yuan Lou, Yawei Wei, Fei Zeng, Zelin Zhang</dc:creator>
    </item>
    <item>
      <title>A New Algorithm for Zero-Sum Linear-Quadratic Stochastic Differential Games in Infinite Horizons</title>
      <link>https://arxiv.org/abs/2511.01538</link>
      <description>arXiv:2511.01538v1 Announce Type: new 
Abstract: We propose a new algorithm for Zero-Sum Linear-Quadratic Stochastic Differential Games by dissecting their inherent structures. Specifically, we construct dual-layer iterative matrix-increasing sequences, which reformulate the original problem into a set of mutually interconnected subproblems. By sequentially computing the stabilizing solutions to the associated algebraic Riccati equations within each subproblem, we derive the stabilizing solutions for the original problem and rigorously establish the convergence of the proposed algorithm. Numerical simulations further validate the effectiveness of the method. This work extends classical setting and provides the first complete unified numerical framework for solving a broader class of stochastic Game-Theoretic algebraic Riccati equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01538v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyuan Wang</dc:creator>
    </item>
    <item>
      <title>Mutual Consensus and its Application in Minimum Cost Consensus Models</title>
      <link>https://arxiv.org/abs/2511.01614</link>
      <description>arXiv:2511.01614v1 Announce Type: new 
Abstract: This paper introduces the concept of {mutual consensus} as a novel non-compensatory consensus measure that accounts for the maximum disparity among opinions to ensure robust consensus evaluation. Incorporating this concept, several new Minimum Cost Consensus (MCC) models are proposed, and their properties are analyzed. To show their applicability, these mutual consensus-based MCC models are then considered in the context of the {OWA-MCC} model, which employs Ordered Weighted Averaging (OWA) operators for preference aggregation. Concretely, we include a linearized formulation under symmetry conditions as well as examples of the non-convexity of the feasible region in the general case. Finally, mutual consensus is utilized to obtain approximate solutions for the OWA-MCC model, demonstrating its practical effectiveness and advancing the theoretical and applied dimensions of consensus modeling in group decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01614v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Diego Garc\'ia-Zamora, Bapi Dutta, Luis Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Observer-Based Sampled-Data Stabilisation of Switched Systems with Lipschitz Nonlinearities and Dwell-Time</title>
      <link>https://arxiv.org/abs/2511.01672</link>
      <description>arXiv:2511.01672v1 Announce Type: new 
Abstract: We investigate the stabilisation of nominally linear switched systems with uncertain Lipschitz nonlinearities under dwell-time constraints, using a sampled-data switching law based on a state observer. We design the switching law based on Lyapunov-Metzler inequalities, accounting for the sampled-data output measurements, and we derive time-dependent LMI conditions for global asymptotic stability of the resulting closed-loop system. We obtain an estimate of the average quadratic cost and a bound on its maximum deviation from the actual cost. We also discuss the feasibility of the derived LMIs, provide equivalent reduced-order LMI conditions, and prove that the time dependence of the LMIs can be removed by discretising on a finite grid. Numerical examples illustrate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01672v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Katz, Antonio Russo, Gian Paolo Incremona, Patrizio Colaneri, Giulia Giordano</dc:creator>
    </item>
    <item>
      <title>Turnpike Property of Mean-Field Linear-Quadratic Optimal Control Problems in Infinite-Horizon with Regime Switching</title>
      <link>https://arxiv.org/abs/2511.01731</link>
      <description>arXiv:2511.01731v1 Announce Type: new 
Abstract: This paper considers an optimal control problem for a linear mean-field stochastic differential equation having regime switching with quadratic functional in the large time horizons. Our main contribution lies in establishing the strong turnpike property for the optimal pairs when the time horizon tends to infinity. To work with the mean-field terms, we apply the orthogonal decomposition method to derive a closed-loop representation of the optimal control problem in a finite time horizon. To analyze the asymptotic behavior of the optimal controls, we examine the convergence of the solutions of Riccati equations and backward differential equations as the time horizon tends to infinity. The strong turnpike property can be obtained based on these convergence results. Finally, we verify the optimality of the limit optimal pair in two cases: integrable case and local-integrable case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01731v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongwei Mei, Svetlozar Rachev, Rui Wang</dc:creator>
    </item>
    <item>
      <title>Disciplined Biconvex Programming</title>
      <link>https://arxiv.org/abs/2511.01813</link>
      <description>arXiv:2511.01813v1 Announce Type: new 
Abstract: We introduce disciplined biconvex programming (DBCP), a modeling framework for specifying and solving biconvex optimization problems. Biconvex optimization problems arise in various applications, including machine learning, signal processing, computational science, and control. Solving a biconvex optimization problem in practice usually resolves to heuristic methods based on alternate convex search (ACS), which iteratively optimizes over one block of variables while keeping the other fixed, so that the resulting subproblems are convex and can be efficiently solved. However, designing and implementing an ACS solver for a specific biconvex optimization problem usually requires significant effort from the user, which can be tedious and error-prone. DBCP extends the principles of disciplined convex programming to biconvex problems, allowing users to specify biconvex optimization problems in a natural way based on a small number of syntax rules. The resulting problem can then be automatically split and transformed into convex subproblems, for which a customized ACS solver is then generated and applied. DBCP allows users to quickly experiment with different biconvex problem formulations, without expertise in convex optimization. We implement DBCP into the open source Python package dbcp, as an extension to the famous domain specific language CVXPY for convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01813v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zhu, Joschka Boedecker</dc:creator>
    </item>
    <item>
      <title>Sensitivity Analysis of Distributionally Robust BSDEs and RBSDEs</title>
      <link>https://arxiv.org/abs/2511.01828</link>
      <description>arXiv:2511.01828v2 Announce Type: new 
Abstract: We examine the sensitivity properties of backward stochastic differential equations and reflected backward stochastic differential equations, which naturally arise in the context of optimal control and optimal stopping problems. Motivated by issues of sensitivity analysis in distributionally robust optimization (DRO) control and optimal stopping problems, we establish explicit formulas for the corresponding sensitivities under drift reference measure uncertainty. Our work is closely related to \citeauthor{bartl2023sensitivity} \cite{bartl2023sensitivity}. In contrast to the existing literature, our analysis is carried out within a general non-Markovian framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01828v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Compoint Arthur, Sauldubois Nathan, Touzi Nizar</dc:creator>
    </item>
    <item>
      <title>Approximate Approach to Compute Characteristics of Inhomogeneous TASEP with Open Boundaries</title>
      <link>https://arxiv.org/abs/2511.00128</link>
      <description>arXiv:2511.00128v1 Announce Type: cross 
Abstract: A discrete-time totally asymmetric simple exclusion process on a lattice with open boundaries is considered. There are particles of different types. The type of a particle is characterized by the probability that a particle moves to a vacant site and the probability that a particle occupying the rightmost site departs the system. An approximate approach to compute the particle flow rate and density in sites is proposed. A version of the approach is proposed for an analogous continuous-time process. The accuracy of the approximation is estimated. The approach can be used in traffic models and models of statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00128v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina V. Yashina, Alexander G. Tatashev</dc:creator>
    </item>
    <item>
      <title>U-centrality: A Network Centrality Measure Based on Minimum Energy Control for Laplacian Dynamics</title>
      <link>https://arxiv.org/abs/2511.00339</link>
      <description>arXiv:2511.00339v1 Announce Type: cross 
Abstract: Network centrality is a foundational concept for quantifying the importance of nodes within a network. Many traditional centrality measures--such as degree and betweenness centrality--are purely structural and often overlook the dynamics that unfold across the network. However, the notion of a node's importance is inherently context-dependent and must reflect both the system's dynamics and the specific objectives guiding its operation. Motivated by this perspective, we propose a dynamic, task-aware centrality framework rooted in optimal control theory. By formulating a problem on minimum energy control of average opinion based on Laplacian dynamics and focusing on the variance of terminal state, we introduce a novel centrality measure--termed U-centrality--that quantifies a node's ability to unify the agents' state. We demonstrate that U-centrality interpolates between known measures: it aligns with degree centrality in the short-time horizon and converges to a new centrality over longer time scales which is closely related to current-flow closeness centrality. This work bridges structural and dynamical approaches to centrality, offering a principled, versatile tool for network analysis in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00339v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinran Zheng, Leonardo Massai, Massimo Franceschetti, Behrouz Touri</dc:creator>
    </item>
    <item>
      <title>Adaptive Federated Learning to Optimize the MultiCast flows in Data Centers</title>
      <link>https://arxiv.org/abs/2511.00623</link>
      <description>arXiv:2511.00623v1 Announce Type: cross 
Abstract: Data centers play an increasingly critical role in societal digitalization, yet their rapidly growing energy demand poses significant challenges for sustainable operation. To enhance the energy efficiency of geographically distributed data centers, this paper formulates a multi-period optimization model that captures the interdependence of electricity, heat, and data flows. The optimization of such multicast flows inherently involves mixed-integer formulations and the access to proprietary or sensitive datasets, which correspondingly exacerbate computational complexity and raise data-privacy concerns. To address these challenges, an adaptive federated learning-to-optimization approach is proposed, accounting for the heterogeneity of datasets across distributed data centers. To safeguard privacy, cryptography techniques are leveraged in both the learning and optimization processes. A model acceptance criterion with convergence guarantee is developed to improve learning performance and filter out potentially contaminated data, while a verifiable double aggregation mechanism is further proposed to simultaneously ensure privacy and integrity of shared data during optimization. Theoretical analysis and numerical simulations demonstrate that the proposed approach preserves the privacy and integrity of shared data, achieves near-optimal performance, and exhibits high computational efficiency, making it suitable for large-scale data center optimization under privacy constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00623v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junhong Liu, Lanxin Du, Yujia Li, Rong-Peng Liu, Fei Teng, Francis Yunhe Hou</dc:creator>
    </item>
    <item>
      <title>Infinite-dimensional nonholonomic and vakonomic systems</title>
      <link>https://arxiv.org/abs/2511.00629</link>
      <description>arXiv:2511.00629v1 Announce Type: cross 
Abstract: In this paper, we present a collection of infinite-dimensional systems with nonholonomic constraints. In finite dimensions the two essentially different types of dynamics, nonholonomic or vakonomic ones, are known to be obtained by taking certain limits of holonomic systems with Rayleigh dissipation, as in [Koz83]. After visualizing this phenomenon for the classical example of a skate on an inclined plane, we discuss its higher-dimensional analogue, the kinematics of a car with $n$ trailers, as well as its limit as $n\to \infty$. We show that its infinite-dimensional version is a snake-like motion of the Chaplygin sleigh with a string, and it is subordinated to an infinite-dimensional Goursat distribution.
  Other examples of nonholonomic and vakonomic systems include subriemannian and Euler-Poincar\'e-Suslov systems on infinite-dimensional Lie groups, the Heisenberg chain, the general Camassa-Holm equation, infinite-dimensional geometry of a nonholonomic Moser theorem, parity-breaking nonholonomic fluids, and potential solutions to Burgers-type equations arising in optimal mass transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00629v1</guid>
      <category>math.DG</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander G. Abanov, Boris Khesin</dc:creator>
    </item>
    <item>
      <title>Automatic Policy Search using Population-Based Hyper-heuristics for the Integrated Procurement and Perishable Inventory Problem</title>
      <link>https://arxiv.org/abs/2511.00762</link>
      <description>arXiv:2511.00762v1 Announce Type: cross 
Abstract: This paper addresses the problem of managing perishable inventory under multiple sources of uncertainty, including stochastic demand, unreliable supplier fulfillment, and probabilistic product shelf life. We develop a discrete-event simulation environment to compare two optimization strategies for this multi-item, multi-supplier problem. The first strategy optimizes uniform classic policies (e.g., Constant Order and Base Stock) by tuning their parameters globally, complemented by a direct search to select the best-fitting suppliers for the integrated problem. The second approach is a hyper-heuristic approach, driven by metaheuristics such as a Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). This framework constructs a composite policy by automating the selection of the heuristic type, its parameters, and the sourcing suppliers on an item-by-item basis. Computational results from twelve distinct instances demonstrate that the hyper-heuristic framework consistently identifies superior policies, with GA and EGA exhibiting the best overall performance. Our primary contribution is verifying that this item-level policy construction yields significant performance gains over simpler global policies, thereby justifying the associated computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00762v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo Kanashiro Felizardo, Edoardo Fadda, Mari\'a Cristina Vasconcelos Nascimento</dc:creator>
    </item>
    <item>
      <title>Information-theoretic minimax and submodular optimization algorithms for multivariate Markov chains</title>
      <link>https://arxiv.org/abs/2511.00769</link>
      <description>arXiv:2511.00769v1 Announce Type: cross 
Abstract: We study an information-theoretic minimax problem for finite multivariate Markov chains on $d$-dimensional product state spaces. Given a family $\mathcal B=\{P_1,\ldots,P_n\}$ of $\pi$-stationary transition matrices and a class $\mathcal F = \mathcal{F}(\mathbf{S})$ of factorizable models induced by a partition $\mathbf S$ of the coordinate set $[d]$, we seek to minimize the worst-case information loss by analyzing $$\min_{Q\in\mathcal F}\max_{P\in\mathcal B} D_{\mathrm{KL}}^{\pi}(P\|Q),$$ where $D_{\mathrm{KL}}^{\pi}(P\|Q)$ is the $\pi$-weighted KL divergence from $Q$ to $P$. We recast the above minimax problem into concave maximization over the $n$-probability-simplex via strong duality and Pythagorean identities that we derive. This leads us to formulate an information-theoretic game and show that a mixed strategy Nash equilibrium always exists; and propose a projected subgradient algorithm to approximately solve the minimax problem with provable guarantee. By transforming the minimax problem into an orthant submodular function in $\mathbf{S}$, this motivates us to consider a max-min-max submodular optimization problem and investigate a two-layer subgradient-greedy procedure to approximately solve this generalization. Numerical experiments for Markov chains on the Curie-Weiss and Bernoulli-Laplace models illustrate the practicality of these proposed algorithms and reveals sparse optimal structures in these examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00769v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheyuan Lai, Michael C. H. Choi</dc:creator>
    </item>
    <item>
      <title>Robust Hedging of path-dependent options using a min-max algorithm</title>
      <link>https://arxiv.org/abs/2511.00781</link>
      <description>arXiv:2511.00781v1 Announce Type: cross 
Abstract: We consider an investor who wants to hedge a path-dependent option with maturity $T$ using a static hedging portfolio using cash, the underlying, and vanilla put/call options on the same underlying with maturity $ t_1$, where $0 &lt; t_1 &lt; T$. We propose a model-free approach to construct such a portfolio. The framework is inspired by the \textit{primal-dual} Martingale Optimal Transport (MOT) problem, which was pioneered by \cite{beiglbock2013model}. The optimization problem is to determine the portfolio composition that minimizes the expected worst-case hedging error at $t_1$ (that coincides with the maturity of the options that are used in the hedging portfolio). The worst-case scenario corresponds to the distribution that yields the worst possible hedging performance. This formulation leads to a \textit{min-max} problem. We provide a numerical scheme for solving this problem when a finite number of vanilla option prices are available. Numerical results on the hedging performance of this model-free approach when the option prices are generated using a \textit{Black-Scholes} and a \textit{Merton Jump diffusion} model are presented. We also provide theoretical bounds on the hedging error at $T$, the maturity of the target option.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00781v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Purba Banerjee, Srikanth Iyer, Shashi Jain</dc:creator>
    </item>
    <item>
      <title>Online Energy Storage Arbitrage under Imperfect Predictions: A Conformal Risk-Aware Approach</title>
      <link>https://arxiv.org/abs/2511.01032</link>
      <description>arXiv:2511.01032v1 Announce Type: cross 
Abstract: This work proposes a conformal approach for energy storage arbitrage to control the downside risks arose from imperfect price forecasts. Energy storage arbitrage relies solely on predictions of future market prices, while inaccurate price predictions may lead to significant profit losses. Based on conformal decision theory, we describe a controller that dynamically adjusts decision conservativeness through prediction sets without distributional assumptions. To enable online calibration when online profit loss feedback is unobservable, we establish that a temporal difference error serves as a measurable proxy. Building on this insight, we develop two online calibration strategies: prediction error-based adaptation targeting forecast accuracy, and value error-based calibration focusing on decision quality. Analysis of the conformal controller proves bounded long-term risk with convergence guarantees in temporal difference error, which further effectively manages risk exposure in potential profit losses. Case studies demonstrate superior performance in balancing risk and opportunity compared to benchmarks under varying forecast conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01032v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiqian Wu, Ming Yi, Bolun Xu, James Anderson</dc:creator>
    </item>
    <item>
      <title>Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2511.01126</link>
      <description>arXiv:2511.01126v1 Announce Type: cross 
Abstract: Online bilevel optimization (OBO) is a powerful framework for machine learning problems where both outer and inner objectives evolve over time, requiring dynamic updates. Current OBO approaches rely on deterministic \textit{window-smoothed} regret minimization, which may not accurately reflect system performance when functions change rapidly. In this work, we introduce a novel search direction and show that both first- and zeroth-order (ZO) stochastic OBO algorithms leveraging this direction achieve sublinear {stochastic bilevel regret without window smoothing}. Beyond these guarantees, our framework enhances efficiency by: (i) reducing oracle dependence in hypergradient estimation, (ii) updating inner and outer variables alongside the linear system solution, and (iii) employing ZO-based estimation of Hessians, Jacobians, and gradients. Experiments on online parametric loss tuning and black-box adversarial attacks validate our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01126v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parvin Nazari, Bojian Hou, Davoud Ataee Tarzanagh, Li Shen, George Michailidis</dc:creator>
    </item>
    <item>
      <title>Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games -- Part I: Equilibria</title>
      <link>https://arxiv.org/abs/2511.01452</link>
      <description>arXiv:2511.01452v1 Announce Type: cross 
Abstract: We study a dynamic game with a large population of players who choose actions from a finite set in continuous time. Each player has a state in a finite state space that evolves stochastically with their actions. A player's reward depends not only on their own state and action but also on the distribution of states and actions across the population, capturing effects such as congestion in traffic networks. While prior work in evolutionary game theory has primarily focused on static games without individual player state dynamics, we present the first comprehensive evolutionary analysis of such dynamic games. We propose an evolutionary model together with a mean field approximation of the finite-population game and establish strong approximation guarantees. We show that standard solution concepts for dynamic games lack an evolutionary interpretation, and we propose a new concept - the Mixed Stationary Nash Equilibrium (MSNE) - which admits one. We analyze the relationship between MSNE and the rest points of the mean field evolutionary model and study the evolutionary stability of MSNE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01452v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leonardo Pedroso, Andrea Agazzi, W. P. M. H. Heemels, Mauro Salazar</dc:creator>
    </item>
    <item>
      <title>Variational Data-Consistent Assimilation</title>
      <link>https://arxiv.org/abs/2511.01759</link>
      <description>arXiv:2511.01759v1 Announce Type: cross 
Abstract: This work introduces a new class of four-dimensional variational data assimilation (4D-Var) methods grounded in data-consistent inversion (DCI) theory. The methods extend classical 4D-Var by incorporating a predictability-aware regularization term. The first method formulated is referred to as Data-Consistent 4D-Var (DC-4DVar), which is then enhanced using a Weighted Mean Error (WME) quantity-of-interest map to construct the DC-WME 4D-Var method. While the DC and DC-WME cost functions both involve a predictability-aware regularization term, the DC-WME function includes a modification to the model-data misfit, thereby improving estimation accuracy, robustness, and theoretical consistency in nonlinear and partially observed dynamical systems. Proofs are provided that establish the existence and uniqueness of the minimizer and analyze how a predictability assumption that is common within the DCI framework helps to promote solution stability. Numerical experiments are presented on benchmark dynamical systems (Lorenz-63 and Lorenz-96) as well as for the shallow water equations (SWE). In the benchmark dynamical systems, the DC-WME 4D-Var formulation is shown to consistently outperform standard 4D-Var in reducing both error and bias while maintaining robustness under high observation noise and short assimilation windows. Despite introducing modest computational overhead, DC-WME 4D-Var delivers improvements in estimation performance and forecast skill, demonstrating its potential practicality and scalability for high-dimensional data assimilation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01759v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rylan Spence, Troy Butler, Clint Dawson</dc:creator>
    </item>
    <item>
      <title>Stochastic Multigrid Method for Blind Ptychographic Phase Retrieval</title>
      <link>https://arxiv.org/abs/2511.01793</link>
      <description>arXiv:2511.01793v1 Announce Type: cross 
Abstract: We present eMAGPIE (extended Multilevel-Adaptive-Guided Ptychographic Iterative Engine), a stochastic multigrid method for blind ptychographic phase retrieval that jointly recovers the object and the probe. We recast the task as the iterative minimization of a quadratic surrogate that majorizes the exit-wave misfit. From this surrogate, we derive closed-form updates, combined in a geometric-mean, phase-aligned joint step, yielding a simultaneous update of the object and probe with guaranteed descent of the sampled surrogate. This formulation naturally admits a multigrid acceleration that speeds up convergence. In experiments, eMAGPIE attains lower data misfit and phase error at comparable compute budgets and produces smoother, artifact-reduced phase reconstructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01793v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borong Zhang, Junjing Deng, Yi Jiang, Zichao Wendy Di</dc:creator>
    </item>
    <item>
      <title>No-rank Tensor Decomposition Using Metric Learning</title>
      <link>https://arxiv.org/abs/2511.01816</link>
      <description>arXiv:2511.01816v1 Announce Type: cross 
Abstract: Tensor decomposition faces fundamental challenges in analyzing high-dimensional data, where traditional methods based on reconstruction and fixed-rank constraints often fail to capture semantically meaningful structures. This paper introduces a no-rank tensor decomposition framework grounded in metric learning, which replaces reconstruction objectives with a discriminative, similarity-based optimization. The proposed approach learns data-driven embeddings by optimizing a triplet loss with diversity and uniformity regularization, creating a feature space where distance directly reflects semantic similarity. We provide theoretical guarantees for the framework's convergence and establish bounds on its metric properties. Evaluations across diverse domains -- including face recognition (LFW, Olivetti), brain connectivity analysis (ABIDE), and simulated data (galaxy morphology, crystal structures) -- demonstrate that our method outperforms baseline techniques, including PCA, t-SNE, UMAP, and tensor decomposition baselines (CP and Tucker). Results show substantial improvements in clustering metrics (Silhouette Score, Davies-Bouldin Index, Calinski-Harabasz Index, Separation Ratio, Adjusted Rand Index, Normalized Mutual Information) and reveal a fundamental trade-off: while metric learning optimizes global class separation, it deliberately transforms local geometry to align with semantic relationships. Crucially, our approach achieves superior performance with smaller training datasets compared to transformer-based methods, offering an efficient alternative for domains with limited labeled data. This work establishes metric learning as a paradigm for tensor-based analysis, prioritizing semantic relevance over pixel-level fidelity while providing computational advantages in data-scarce scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01816v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Bagherian</dc:creator>
    </item>
    <item>
      <title>Kantorovich-Rubinstein duality theory for the Hessian</title>
      <link>https://arxiv.org/abs/2412.00516</link>
      <description>arXiv:2412.00516v3 Announce Type: replace 
Abstract: The classical Kantorovich-Rubinstein duality theorem establishes a significant connection between Monge optimal transport and maximization of a linear form on the set of 1-Lipschitz functions. This result has been widely used in various research areas. In particular, it unlocks the optimal transport methods in some of the optimal design problems. This paper puts forth a similar theory when the linear form is maximized over $C^{1,1}$ functions whose Hessian lies between minus and plus identity matrix. The problem will be identified as the dual of a specific optimal transport formulation that involves three-point plans. The first two marginals are fixed, while the third must dominate the other two in the sense of convex order. The existence of optimal plans allows to express solutions of the underlying Beckmann problem as a combination of rank-one tensor measures supported on a graph. In the context of two-dimensional mechanics, this graph encodes the optimal configuration of a grillage that transfers a given load system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00516v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karol Bo{\l}botowski, Guy Bouchitt\'e</dc:creator>
    </item>
    <item>
      <title>Optimization via Strategic Law of Large Numbers</title>
      <link>https://arxiv.org/abs/2412.05604</link>
      <description>arXiv:2412.05604v4 Announce Type: replace 
Abstract: This paper proposes a unified framework for the global optimization of a continuous function in a bounded rectangular domain. Specifically, we show that: (1) under the optimal strategy for a two-armed decision model, the sample mean converges to a global optimizer under the Strategic Law of Large Numbers, and (2) a sign-based strategy built upon the solution of a parabolic PDE is asymptotically optimal. Motivated by this result, we propose a class of {\bf S}trategic {\bf M}onte {\bf C}arlo {\bf O}ptimization (SMCO) algorithms, which uses a simple strategy that makes coordinate-wise two-armed decisions based on the signs of the partial gradient of the original function being optimized over (without the need of solving PDEs). While this simple strategy is not generally optimal, we show that it is sufficient for our SMCO algorithm to converge to local optimizer(s) from a single starting point, and to global optimizers under a growing set of starting points. Numerical studies demonstrate the suitability of our SMCO algorithms for global optimization, and illustrate the promise of our theoretical framework and practical approach. For a wide range of test functions with challenging optimization landscapes (including ReLU neural networks with square and hinge loss), our SMCO algorithms converge to the global maximum accurately and robustly, using only a small set of starting points (at most 100 for dimensions up to 1000) and a small maximum number of iterations (200). In fact, our algorithms outperform many state-of-the-art global optimizers, as well as local algorithms augmented with the same set of starting points as ours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05604v4</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Zengjing Chen, Wayne Yuan Gao, Xiaodong Yan, Guodong Zhang</dc:creator>
    </item>
    <item>
      <title>CuClarabel: GPU Acceleration for a Conic Optimization Solver</title>
      <link>https://arxiv.org/abs/2412.19027</link>
      <description>arXiv:2412.19027v3 Announce Type: replace 
Abstract: We present the GPU implementation of the general-purpose interior-point solver Clarabel for convex optimization problems with conic constraints. We introduce a mixed parallel computing strategy that processes linear constraints first, then handles other conic constraints in parallel. The GPU solver currently supports linear equality and inequality constraints, second-order cones, exponential cones, power cones and positive semidefinite cones of the same dimensionality. We demonstrate that integrating a mixed parallel computing strategy with GPU-based direct linear system solvers enhances the performance of GPU-based conic solvers, surpassing their CPU-based counterparts across a wide range of conic optimization problems. We also show that employing mixed-precision linear system solvers can potentially achieve additional acceleration without compromising solution accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19027v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwen Chen, Danny Tse, Parth Nobel, Paul Goulart, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>A fast approximate column-and-constraint generation method for two-stage robust mixed-integer programs</title>
      <link>https://arxiv.org/abs/2501.05388</link>
      <description>arXiv:2501.05388v2 Announce Type: replace 
Abstract: This paper presents a new column-and-constraint generation method for two-stage robust mixed-integer programs with finite uncertainty sets. Our method combines and extends speed-up techniques used in previous column-and-constraint generation methods and introduces several new techniques. In particular, it uses dual bounds for second-stage problems in order to allow a faster identification of the next promising scenario to be added to the master problem. Moreover, adaptive time limits are imposed to avoid getting stuck on particularly hard second-stage problems, and a gap propagation between master problem and second-stage problems is used to stop solving them earlier if only a given non-zero optimality gap is to be reached overall. This makes our method particularly effective for problems where solving the second-stage problem is computationally challenging. To evaluate the method's performance, we compare it to two recent column-and-constraint generation methods from the literature on two applications: a robust capacitated location routing problem and a robust integrated berth allocation and quay crane assignment and scheduling problem. The first problem features a particularly hard second stage, and we show that our method is able to solve considerably more and larger instances in a given time limit. Using the second problem, we verify the general applicability of our method, even for problems where the second stage is relatively easy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05388v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Goerigk, Dorothee Henke, Johannes Kager, Fabian Sch\"afer, Clemens Thielen</dc:creator>
    </item>
    <item>
      <title>Dimension Reduction of Distributionally Robust Optimization Problems</title>
      <link>https://arxiv.org/abs/2504.06381</link>
      <description>arXiv:2504.06381v2 Announce Type: replace 
Abstract: We study distributionally robust optimization (DRO) problems with uncertainty sets consisting of high-dimensional random vectors that are close in the multivariate Wasserstein distance to a reference random vector. We give conditions under which the images of these sets under scalar-valued aggregation functions are equal to or bounded by uncertainty sets of univariate random variables defined via a univariate Wasserstein distance. This allows us to rewrite or bound high-dimensional DRO problems with simpler DRO problems over the space of univariate random variables. We generalize the results to uncertainty sets defined via the Bregman-Wasserstein divergence and the max-sliced Wasserstein and Bregman-Wasserstein divergence. The max-sliced divergences allow us to jointly model distributional uncertainty around the reference random vector and uncertainty in the aggregation function. Finally, we derive explicit bounds for worst-case risk measures that belong to the class of signed Choquet integrals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06381v2</guid>
      <category>math.OC</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Tam, Silvana M. Pesenti</dc:creator>
    </item>
    <item>
      <title>Modeling and Optimal Control of Thermal Environment in Pig Houses</title>
      <link>https://arxiv.org/abs/2506.00502</link>
      <description>arXiv:2506.00502v3 Announce Type: replace 
Abstract: The management of thermal environments in pig farming is crucial for optimizing animal health, productivity, and operational energy efficiency. This study introduces a novel thermal ventilation model (TVM) based on enthalpy balance, which integrates both temperature and humidity control to address the specific thermal regulation requirements of pig housing in regions characterized by high temperatures and humidity, such as Guangdong, China. These challenging environmental conditions can lead to heat stress in pigs, adversely affecting their health and productivity. The TVM provides a precise representation of thermal comfort by accounting for the combined effects of temperature and humidity. Building on the TVM, we formulate an optimization problem using Model Predictive Control (MPC), which dynamically adjusts ventilation rates in real-time by modifying weight factors to minimize energy consumption while keeping the temperature and humidity within the comfort zone of the pigs. The accuracy of the TVM is validated against real-world environmental data from pig housing facilities in Guangdong. The root mean square error of temperature in winter, spring and summer were 1.23, 0.81, and 0.60, demonstrating its reliability and robustness across diverse climatic conditions. Furthermore, simulation results show that the proposed MPC strategy significantly improves energy efficiency and environmental comfort, achieving a 100% comfort temperature zone in spring and 83% in summer, compared to 91% and 43% with traditional rule-based control, respectively. However, the model's energy consumption in summer (91.2 kWh) was higher than that of rule-based control (80.8 kWh), reflecting the trade-off between maintaining optimal comfort and energy efficiency under extreme conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00502v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingxin Wei, Jinrui Zhang, Peter Groot Koerkamp, Andre Aarnink, Congcong Sun</dc:creator>
    </item>
    <item>
      <title>Human-in-the-loop: Real-time Preference Optimization</title>
      <link>https://arxiv.org/abs/2506.02225</link>
      <description>arXiv:2506.02225v2 Announce Type: replace 
Abstract: Optimization with preference feedback is an active research area with many applications in engineering systems where humans play a central role, such as building control and autonomous vehicles. While most existing studies focus on optimizing a static user utility, few have investigated its closed-loop behavior that accounts for system transients. In this work, we propose an online feedback optimization controller that can optimize user utility using pairwise comparison feedback with both optimality and closed-loop stability guarantees. By adding a random exploration signal, the controller estimates the gradient based on the binary utility comparison feedback between two consecutive time steps. We analyze its closed-loop behavior when interacting with a nonlinear plant and show that, under mild assumptions, the controller converges to the optimal point without inducing instability. Theoretical findings are further validated through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02225v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbin Wang, Wenjie Xu, Colin N. Jones</dc:creator>
    </item>
    <item>
      <title>Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization</title>
      <link>https://arxiv.org/abs/2508.06906</link>
      <description>arXiv:2508.06906v2 Announce Type: replace 
Abstract: Integer and mixed-integer nonlinear programming (INLP, MINLP) are central to logistics, energy, and scheduling, but remain computationally challenging. This survey examines how machine learning and reinforcement learning can enhance exact optimization methods-particularly branch-and-bound (BB)-without compromising global optimality. We cover discrete, continuous, and mixed-integer formulations, and highlight applications such as vehicle routing, hydropower planning, and crew scheduling. We introduce a unified BB framework that embeds learning-based strategies into branching, cut selection, node ordering, and parameter control. Classical algorithms are augmented using supervised, imitation, and reinforcement learning models to accelerate convergence while maintaining correctness. We conclude with a taxonomy of learning methods by solver class and learning paradigm, and outline open challenges in generalization, hybridization, and scaling intelligent solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06906v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morteza Kimiaei, Vyacheslav Kungurtsev, Brian Olimba</dc:creator>
    </item>
    <item>
      <title>Dual-Regularized Riccati Recursions for Interior-Point Optimal Control</title>
      <link>https://arxiv.org/abs/2509.16370</link>
      <description>arXiv:2509.16370v4 Announce Type: replace 
Abstract: We derive closed-form extensions of Riccati's recursions (both sequential and parallel) for solving dual-regularized LQR problems. We show how these methods can be used to solve general constrained, non-convex, discrete-time optimal control problems via a regularized interior point method, while guaranteeing that each primal step is a descent direction of an Augmented Barrier-Lagrangian merit function. We provide MIT-licensed implementations of our methods in C++ and JAX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16370v4</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Sousa-Pinto, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Model-Free Optimization and Control of Rigid Body Dynamics: An Extremum Seeking for Vibrational Stabilization Approach</title>
      <link>https://arxiv.org/abs/2510.22402</link>
      <description>arXiv:2510.22402v3 Announce Type: replace 
Abstract: In this paper, we introduce a model-free, real-time, dynamic optimization and control method for a class of rigid body dynamics. Our method is based on a recent extremum seeking control for vibrational stabilization (ESC-VS) approach that is applicable to a class of second-order mechanical systems. The new ESC-VS method is able to stabilize a rigid body dynamic system about the optimal state of an objective function that can be unknown expression-wise, but assessable through measurements; the ESC-VS is operable by using only one perturbation/vibrational signal. We demonstrate the effectiveness and the applicability of our ESC-VS approach via three rigid-body systems: (1) satellite attitude dynamics, (2) quadcopter attitude dynamics, and (3) acceleration-controlled unicycle dynamics. The results, including simulations, illustrate the ability of our ESC-VS to operate successfully as means of optimization and control for rigid body dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22402v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Palanikumar, Ahmed A. Elgohary, Simone Martini, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Gradient Flow Sampler-based Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2510.25956</link>
      <description>arXiv:2510.25956v2 Announce Type: replace 
Abstract: We propose a mathematically principled PDE gradient flow framework for distributionally robust optimization (DRO). Exploiting the recent advances in the intersection of Markov Chain Monte Carlo sampling and gradient flow theory, we show that our theoretical framework can be implemented as practical algorithms for sampling from worst-case distributions and, consequently, DRO. While numerous previous works have proposed various reformulation techniques and iterative algorithms, we contribute a sound gradient flow view of the distributional optimization that can be used to construct new algorithms. As an example of applications, we solve a class of Wasserstein and Sinkhorn DRO problems using the recently-discovered Wasserstein Fisher-Rao and Stein variational gradient flows. Notably, we also show some simple reductions of our framework recover exactly previously proposed popular DRO methods, and provide new insights into their theoretical limit and optimization dynamics. Numerical studies based on stochastic gradient descent provide empirical backing for our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25956v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zusen Xu, Jia-Jie Zhu</dc:creator>
    </item>
    <item>
      <title>Point Convergence Analysis of the Accelerated Gradient Method for Multiobjective Optimization: Continuous and Discrete</title>
      <link>https://arxiv.org/abs/2510.26382</link>
      <description>arXiv:2510.26382v2 Announce Type: replace 
Abstract: This paper studies the point convergence of accelerated gradient methods for unconstrained convex smooth multiobjective optimization problems, covering both continuous-time gradient flows and discrete-time algorithms. In single-objective optimization, the point convergence problem of Nesterov's accelerated gradient method at the critical damping parameter $\alpha = 3$ has recently been resolved. This paper extends this theoretical framework to the multiobjective setting, focusing on the multiobjective inertial gradient system with asymptotically vanishing damping (MAVD) with $\alpha =3 $ and the multiobjective accelerated proximal gradient algorithm (MAPG). For the continuous system, we construct a suitable Lyapunov function for the multiobjective setting and prove that, under appropriate assumptions, the trajectory $x(t)$ converges to a weakly Pareto optimal solution. For two discrete algorithms, we construct a corresponding discrete Lyapunov function and prove that the sequence $\{x_k\}$ generated by the algorithms converges to a weakly Pareto optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26382v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingdong Yin</dc:creator>
    </item>
    <item>
      <title>Selecting the Best Optimizing System</title>
      <link>https://arxiv.org/abs/2201.03065</link>
      <description>arXiv:2201.03065v2 Announce Type: replace-cross 
Abstract: We formulate selecting the best optimizing system (SBOS) problems and provide solutions for those problems. In an SBOS problem, a finite number of systems are contenders. Inside each system, a continuous decision variable affects the system's expected performance. An SBOS problem compares different systems based on their expected performances under their own optimally chosen decision to select the best, without advance knowledge of expected performances of the systems nor the optimizing decision inside each system. We design easy-to-implement algorithms that adaptively chooses a system and a choice of decision to evaluate the noisy system performance, sequentially eliminates inferior systems, and eventually recommends a system as the best after spending a user-specified budget. The proposed algorithms integrate the stochastic gradient descent method and the sequential elimination method to simultaneously exploit the structure inside each system and make comparisons across systems. For the proposed algorithms, we prove exponential rates of convergence to zero for the probability of false selection, as the budget grows to infinity. We conduct three numerical examples that represent three practical cases of SBOS problems. Our proposed algorithms demonstrate consistent and stronger performances in terms of the probability of false selection over benchmark algorithms under a range of problem settings and sampling budgets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.03065v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nian Si, Yifu Tang, Zeyu Zheng</dc:creator>
    </item>
    <item>
      <title>A note on large deviations for interacting particle dynamics for finding mixed Nash equilibria with applications to GANs</title>
      <link>https://arxiv.org/abs/2206.15177</link>
      <description>arXiv:2206.15177v3 Announce Type: replace-cross 
Abstract: Finding equilibrium points in continuous minmax games has become a key problem within machine learning, in part due to its connection to the training of generative adversarial networks and reinforcement learning. Because of existence and robustness issues, recent developments have shifted from pure equilibria to focusing on mixed equilibrium points. In this work we consider a method for finding mixed equilibria in two-layer zero-sum games based on entropic regularisation, where the two competing strategies are represented by two sets of interacting particles. We show that the sequence of empirical measures of the particle system satisfies a large deviation principle as the number of particles grows to infinity, and how this implies convergence of the empirical measure and the associated Nikaid\^o-Isoda error, complementing existing law of large numbers results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.15177v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Nilsson, Pierre Nyquist</dc:creator>
    </item>
    <item>
      <title>Breakdown points of Fermat-Weber problems under gauge distances</title>
      <link>https://arxiv.org/abs/2306.13424</link>
      <description>arXiv:2306.13424v3 Announce Type: replace-cross 
Abstract: We compute the robustness of Fermat-Weber points with respect to any finite gauge. We show a breakdown point of $1/(1+\sigma)$ where $\sigma$ is the asymmetry measure of the gauge. We obtain quantitative results indicating how far a corrupted Fermat-Weber point can lie from the true value in terms of the original sample and the size of the corrupted part. If the distance from the true value depends only on the original sample, then we call the gauge `uniformly robust.' We show that polyhedral gauges are uniformly robust, but locally strictly convex norms are not, while in dimension 2 any uniform robust gauge is polyhedral.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13424v3</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Com\u{a}neci, Frank Plastria</dc:creator>
    </item>
    <item>
      <title>Wait-Less Offline Tuning and Re-solving for Online Decision Making</title>
      <link>https://arxiv.org/abs/2412.09594</link>
      <description>arXiv:2412.09594v3 Announce Type: replace-cross 
Abstract: Online linear programming (OLP) has found broad applications in revenue management and resource allocation. State-of-the-art OLP algorithms achieve low regret by repeatedly solving linear programming (LP) subproblems that incorporate updated resource information. However, LP-based methods are computationally expensive and often inefficient for large-scale applications. In contrast, recent first-order OLP algorithms are more computationally efficient but typically suffer from worse regret guarantees. To address these shortcomings, we propose a new algorithm that combines the strengths of LP-based and first-order OLP methods. The algorithm re-solves the LP subproblems periodically at a predefined frequency $f$ and uses the latest dual prices to guide online decision-making. In addition, a first-order method runs in parallel during each interval between LP re-solves, smoothing resource consumption. Our algorithm achieves $\mathscr{O}(\log (T/f) + \sqrt{f})$ regret, delivering a "wait-less" online decision-making process that balances the computational efficiency of first-order methods and the superior regret guarantee of LP-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09594v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 42nd International Conference on Machine Learning, PMLR 267:57419-57449, 2025</arxiv:journal_reference>
      <dc:creator>Jingruo Sun, Wenzhi Gao, Ellen Vitercik, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Implicit Bias in Matrix Factorization and its Explicit Realization in a New Architecture</title>
      <link>https://arxiv.org/abs/2501.16322</link>
      <description>arXiv:2501.16322v2 Announce Type: replace-cross 
Abstract: Gradient descent for matrix factorization exhibits an implicit bias toward approximately low-rank solutions. While existing theories often assume the boundedness of iterates, empirically the bias persists even with unbounded sequences. This reflects a dynamic where factors develop low-rank structure while their magnitudes increase, tending to align with certain directions. To capture this behavior in a stable way, we introduce a new factorization model: $X\approx UDV^\top$, where $U$ and $V$ are constrained within norm balls, while $D$ is a diagonal factor allowing the model to span the entire search space. Experiments show that this model consistently exhibits a strong implicit bias, yielding truly (rather than approximately) low-rank solutions. Extending the idea to neural networks, we introduce a new model featuring constrained layers and diagonal components that achieves competitive performance on various regression and classification tasks while producing lightweight, low-rank representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16322v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yikun Hou, Suvrit Sra, Alp Yurtsever</dc:creator>
    </item>
    <item>
      <title>Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search</title>
      <link>https://arxiv.org/abs/2505.00162</link>
      <description>arXiv:2505.00162v2 Announce Type: replace-cross 
Abstract: Efficient optimization remains a fundamental challenge across numerous scientific and engineering domains, especially when objective function and gradient evaluations are computationally expensive. While zeroth-order optimization methods offer effective approaches when gradients are inaccessible, their practical performance can be limited by the high cost associated with function queries. This work introduces the bi-fidelity stochastic subspace descent (BF-SSD) algorithm, a novel zeroth-order optimization method designed to reduce this computational burden. BF-SSD leverages a bi-fidelity framework, constructing a surrogate model from a combination of computationally inexpensive low-fidelity (LF) and accurate high-fidelity (HF) function evaluations. This surrogate model facilitates an efficient backtracking line search for step size selection, for which we provide theoretical convergence guarantees under standard assumptions. We perform a comprehensive empirical evaluation of BF-SSD across four distinct problems: a synthetic optimization benchmark, dual-form kernel ridge regression, black-box adversarial attacks on machine learning models, and transformer-based black-box language model fine-tuning. Numerical results demonstrate that BF-SSD consistently achieves superior optimization performance while requiring significantly fewer HF function evaluations compared to relevant baseline methods. This study highlights the efficacy of integrating bi-fidelity strategies within zeroth-order optimization, positioning BF-SSD as a promising and computationally efficient approach for tackling large-scale, high-dimensional problems encountered in various real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00162v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nuojin Cheng, Alireza Doostan, Stephen Becker</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.10007</link>
      <description>arXiv:2505.10007v2 Announce Type: replace-cross 
Abstract: Motivated by practical applications where stable long-term performance is critical-such as robotics, operations research, and healthcare-we study the problem of distributionally robust (DR) average-reward reinforcement learning. We propose two algorithms that achieve near-optimal sample complexity. The first reduces the problem to a DR discounted Markov decision process (MDP), while the second, Anchored DR Average-Reward MDP, introduces an anchoring state to stabilize the controlled transition kernels within the uncertainty set. Assuming the nominal MDP is uniformly ergodic, we prove that both algorithms attain a sample complexity of $\widetilde{O}\left(|\mathbf{S}||\mathbf{A}| t_{\mathrm{mix}}^2\varepsilon^{-2}\right)$ for estimating the optimal policy as well as the robust average reward under KL and $f_k$-divergence-based uncertainty sets, provided the uncertainty radius is sufficiently small. Here, $\varepsilon$ is the target accuracy, $|\mathbf{S}|$ and $|\mathbf{A}|$ denote the sizes of the state and action spaces, and $t_{\mathrm{mix}}$ is the mixing time of the nominal MDP. This represents the first finite-sample convergence guarantee for DR average-reward reinforcement learning. We further validate the convergence rates of our algorithms through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10007v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijun Chen, Shengbo Wang, Nian Si</dc:creator>
    </item>
    <item>
      <title>Tight analyses of first-order methods with error feedback</title>
      <link>https://arxiv.org/abs/2506.05271</link>
      <description>arXiv:2506.05271v2 Announce Type: replace-cross 
Abstract: Communication between agents often constitutes a major computational bottleneck in distributed learning. One of the most common mitigation strategies is to compress the information exchanged, thereby reducing communication overhead. To counteract the degradation in convergence associated with compressed communication, error feedback schemes -- most notably $\mathrm{EF}$ and $\mathrm{EF}^{21}$ -- were introduced. In this work, we provide a tight analysis of both of these methods. Specifically, we find the Lyapunov function that yields the best possible convergence rate for each method -- with matching lower bounds. This principled approach yields sharp performance guarantees and enables a rigorous, apples-to-apples comparison between $\mathrm{EF}$, $\mathrm{EF}^{21}$, and compressed gradient descent. Our analysis is carried out in the simplified single-agent setting, which allows for clean theoretical insights and fair comparison of the underlying mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05271v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Berg Thomsen, Adrien Taylor, Aymeric Dieuleveut</dc:creator>
    </item>
    <item>
      <title>Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training</title>
      <link>https://arxiv.org/abs/2507.09846</link>
      <description>arXiv:2507.09846v4 Announce Type: replace-cross 
Abstract: As both model and dataset sizes continue to scale rapidly, conventional pretraining strategies with fixed compute budgets-such as cosine learning rate schedules-are increasingly inadequate for large-scale training. Recent alternatives, including warmup-stable-decay (WSD) schedules and weight averaging, offer greater flexibility. However, WSD relies on explicit decay phases to track progress, while weight averaging addresses this limitation at the cost of additional memory. In search of a more principled and scalable alternative, we revisit the Schedule-Free (SF) method [Defazio et al., 2024], which has shown strong empirical performance across diverse settings. We show that SF-AdamW effectively navigates the "river" structure of the loss landscape without decay phases or auxiliary averaging, making it particularly suitable for continuously scaling training workloads. To understand this behavior, we conduct a theoretical and empirical analysis of SF dynamics, revealing that it implicitly performs weight averaging without memory overhead. Guided by this analysis, we propose a refined variant of SF that improves robustness to momentum and performs better under large batch sizes, addressing key limitations of the original method. Together, these results establish SF as a practical, scalable, and theoretically grounded approach for language model training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09846v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minhak Song, Beomhan Baek, Kwangjun Ahn, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>Statistical Analysis of Conditional Group Distributionally Robust Optimization with Cross-Entropy Loss</title>
      <link>https://arxiv.org/abs/2507.09905</link>
      <description>arXiv:2507.09905v2 Announce Type: replace-cross 
Abstract: In multi-source learning with discrete labels, distributional heterogeneity across domains poses a central challenge to developing predictive models that transfer reliably to unseen domains. We study multi-source unsupervised domain adaptation, where labeled data are available from multiple source domains and only unlabeled data are observed from the target domain. To address potential distribution shifts, we propose a novel Conditional Group Distributionally Robust Optimization (CG-DRO) framework that learns a classifier by minimizing the worst-case cross-entropy loss over the convex combinations of the conditional outcome distributions from sources domains. We develop an efficient Mirror Prox algorithm for solving the minimax problem and employ a double machine learning procedure to estimate the risk function, ensuring that errors in nuisance estimation contribute only at higher-order rates. We establish fast statistical convergence rates for the empirical CG-DRO estimator by constructing two surrogate minimax optimization problems that serve as theoretical bridges. A distinguishing challenge for CG-DRO is the emergence of nonstandard asymptotics: the empirical CG-DRO estimator may fail to converge to a standard limiting distribution due to boundary effects and system instability. To address this, we introduce a perturbation-based inference procedure that enables uniformly valid inference, including confidence interval construction and hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09905v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian Guo, Zhenyu Wang, Yifan Hu, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization with Adversarial Data Contamination</title>
      <link>https://arxiv.org/abs/2507.10718</link>
      <description>arXiv:2507.10718v2 Announce Type: replace-cross 
Abstract: Distributionally Robust Optimization (DRO) provides a framework for decision-making under distributional uncertainty, yet its effectiveness can be compromised by outliers in the training data. This paper introduces a principled approach to simultaneously address both challenges. We focus on optimizing Wasserstein-1 DRO objectives for generalized linear models with convex Lipschitz loss functions, where an $\epsilon$-fraction of the training data is adversarially corrupted. Our primary contribution lies in a novel modeling framework that integrates robustness against training data contamination with robustness against distributional shifts, alongside an efficient algorithm inspired by robust statistics to solve the resulting optimization problem. We prove that our method achieves an estimation error of $O(\sqrt{\epsilon})$ for the true DRO objective value using only the contaminated data under the bounded covariance assumption. This work establishes the first rigorous guarantees, supported by efficient computation, for learning under the dual challenges of data contamination and distributional shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10718v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuyao Li, Ilias Diakonikolas, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Best weighted approximation of some kernels on the real axis</title>
      <link>https://arxiv.org/abs/2509.23890</link>
      <description>arXiv:2509.23890v2 Announce Type: replace-cross 
Abstract: We calculate the exact value and find the polynomial of the best weighted polynomial approximation of kernels of the form $\frac {A+Bt}{(t^2+\lambda^2)^{s+1}}$, where $A$ and $B$ are fixed complex numbers, $\lambda&gt;0$, $s\in {\mathbb N}$, in the mean square metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23890v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stanislav Chaichenko, Viktor Savchuk, Andrii Shidlich</dc:creator>
    </item>
    <item>
      <title>Particle system approximation of Nash equilibria in large games</title>
      <link>https://arxiv.org/abs/2510.19211</link>
      <description>arXiv:2510.19211v2 Announce Type: replace-cross 
Abstract: We develop a probabilistic framework to approximate Nash equilibria in symmetric $N$-player games in the large population regime, via the analysis of associated mean field games (MFGs). The approximation is achieved through the analysis of a McKean-Vlasov type Langevin dynamics and their associated particle systems, with convergence to the MFG solution established in the limit of vanishing temperature parameter. Relying on displacement monotonicity or Lasry-Lions monotonicity of the cost function, we prove contractility of the McKean-Vlasov process and uniform-in-time propagation of chaos for the particle system. Our results contribute to the general theory of interacting diffusions by showing that monotonicity can ensure convergence without requiring small interaction assumptions or functional inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19211v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovic Tangpi, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Computing intrinsic volumes of sublevel sets and applications</title>
      <link>https://arxiv.org/abs/2510.24001</link>
      <description>arXiv:2510.24001v2 Announce Type: replace-cross 
Abstract: Intrinsic volumes are fundamental geometric invariants generalizing volume, surface area, and mean width for convex bodies. We establish a unified Laplace-Grassmannian representation for intrinsic and dual volumes of convex polynomial sublevel sets. More precisely, let $f$ be a convex $d$-homogeneous polynomial of even degree $d \ge 2$ which is positive except at the origin. We show that the intrinsic and dual volumes of the sublevel set $[f \le 1]$ admit Laplace-type integral formulas obtained by averaging the infimal projection and restriction of $f$ over the Grassmannian. This explicit representation yields three main consequences: (1) L\"owner--John-type existence and uniqueness results extending beyond the classical volume case; (2) a block decomposition principle describing factorization of intrinsic volumes under direct-sum splitting; (3) a coordinate-free formulation of Lipschitz-type lattice discrepancy bounds. These formulas enable analytic treatment of a broad class of geometric quantities, providing direct access to variational and arithmetic applications as well as new structural insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24001v2</guid>
      <category>math.MG</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tr\'i Minh L\^e, Khai-Hoan Nguyen-Dang</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime</title>
      <link>https://arxiv.org/abs/2510.26303</link>
      <description>arXiv:2510.26303v2 Announce Type: replace-cross 
Abstract: Adam [Kingma and Ba, 2015] is the de facto optimizer in deep learning, yet its theoretical understanding remains limited. Prior analyses show that Adam favors solutions aligned with $\ell_\infty$-geometry, but these results are restricted to the full-batch regime. In this work, we study the implicit bias of incremental Adam (using one sample per step) for logistic regression on linearly separable data, and we show that its bias can deviate from the full-batch behavior. To illustrate this, we construct a class of structured datasets where incremental Adam provably converges to the $\ell_2$-max-margin classifier, in contrast to the $\ell_\infty$-max-margin bias of full-batch Adam. For general datasets, we develop a proxy algorithm that captures the limiting behavior of incremental Adam as $\beta_2 \to 1$ and we characterize its convergence direction via a data-dependent dual fixed-point formulation. Finally, we prove that, unlike Adam, Signum [Bernstein et al., 2018] converges to the $\ell_\infty$-max-margin classifier for any batch size by taking $\beta$ close enough to 1. Overall, our results highlight that the implicit bias of Adam crucially depends on both the batching scheme and the dataset, while Signum remains invariant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26303v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beomhan Baek, Minhak Song, Chulhee Yun</dc:creator>
    </item>
  </channel>
</rss>
