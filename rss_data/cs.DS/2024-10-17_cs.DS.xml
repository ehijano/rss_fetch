<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Improved Kernelization and Fixed-parameter Algorithms for Bicluster Editing</title>
      <link>https://arxiv.org/abs/2410.13123</link>
      <description>arXiv:2410.13123v1 Announce Type: new 
Abstract: Given a bipartite graph $G$, the \textsc{Bicluster Editing} problem asks for the minimum number of edges to insert or delete in $G$ so that every connected component is a bicluster, i.e. a complete bipartite graph. This has several applications, including in bioinformatics and social network analysis. In this work, we study the parameterized complexity under the natural parameter $k$, which is the number of allowed modified edges. We first show that one can obtain a kernel with $4.5k$ vertices, an improvement over the previously known quadratic kernel. We then propose an algorithm that runs in time $O^*(2.581^k)$. Our algorithm has the advantage of being conceptually simple and should be easy to implement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13123v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Lafond</dc:creator>
    </item>
    <item>
      <title>Fast Construction of Partitioned Learned Bloom Filter with Theoretical Guarantees</title>
      <link>https://arxiv.org/abs/2410.13278</link>
      <description>arXiv:2410.13278v1 Announce Type: new 
Abstract: Bloom filter is a widely used classic data structure for approximate membership queries. Learned Bloom filters improve memory efficiency by leveraging machine learning, with the partitioned learned Bloom filter (PLBF) being among the most memory-efficient variants. However, PLBF suffers from high computational complexity during construction, specifically $O(N^3k)$, where $N$ and $k$ are hyperparameters. In this paper, we propose three methods: fast PLBF, fast PLBF++, and fast PLBF#, that reduce the construction complexity to $O(N^2k)$, $O(Nk \log N)$, and $O(Nk \log k)$, respectively. Fast PLBF preserves the original PLBF structure and memory efficiency. Although fast PLBF++ and fast PLBF# may have different structures, we theoretically prove they are equivalent to PLBF under ideal data distribution. Furthermore, we theoretically bound the difference in memory efficiency between PLBF and fast PLBF++ for non-ideal scenarios. Experiments on real-world datasets demonstrate that fast PLBF, fast PLBF++, and fast PLBF# are up to 233, 761, and 778 times faster to construct than original PLBF, respectively. Additionally, fast PLBF maintains the same data structure as PLBF, and fast PLBF++ and fast PLBF# achieve nearly identical memory efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13278v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atsuki Sato, Yusuke Matsui</dc:creator>
    </item>
    <item>
      <title>Graph Exploration: The Impact of a Distance Constraint</title>
      <link>https://arxiv.org/abs/2410.13386</link>
      <description>arXiv:2410.13386v1 Announce Type: new 
Abstract: A mobile agent, starting from a node $s$ of a simple undirected connected graph $G=(V,E)$, has to explore all nodes and edges of $G$ using the minimum number of edge traversals. To do so, the agent uses a deterministic algorithm that allows it to gain information on $G$ as it traverses its edges. During its exploration, the agent must always respect the constraint of knowing a path of length at most $D$ to go back to node $s$. The upper bound $D$ is fixed as being equal to $(1+\alpha)r$, where $r$ is the eccentricity of node $s$ (i.e., the maximum distance from $s$ to any other node) and $\alpha$ is any positive real constant. This task has been introduced by Duncan et al. [ACM Trans. Algorithms 2006] and is known as \emph{distance-constrained exploration}.
  The \emph{penalty} of an exploration algorithm running in $G$ is the number of edge traversals made by the agent in excess of $|E|$. Panaite and Pelc [J. Algorithms 1999] gave an algorithm for solving exploration without any constraint on the moves that is guaranteed to work in every graph $G$ with a (small) penalty in $\mathcal{O}(|V|)$. Hence, a natural question is whether we could obtain a distance-constrained exploration algorithm with the same guarantee as well.
  In this paper, we provide a negative answer to this question. We also observe that an algorithm working in every graph $G$ with a linear penalty in $|V|$ cannot be obtained for the task of \emph{fuel-constrained exploration}, another variant studied in the literature.
  This solves an open problem posed by Duncan et al. [ACM Trans. Algorithms 2006] and shows a fundamental separation with the task of exploration without constraint on the moves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13386v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>St\'ephane Devismes, Yoann Dieudonn\'e, Arnaud Labourel</dc:creator>
    </item>
    <item>
      <title>Parallel and Distributed Expander Decomposition: Simple, Fast, and Near-Optimal</title>
      <link>https://arxiv.org/abs/2410.13451</link>
      <description>arXiv:2410.13451v1 Announce Type: new 
Abstract: Expander decompositions have become one of the central frameworks in the design of fast algorithms. For an undirected graph $G=(V,E)$, a near-optimal $\phi$-expander decomposition is a partition $V_1, V_2, \ldots, V_k$ of the vertex set $V$ where each subgraph $G[V_i]$ is a $\phi$-expander, and only an $\widetilde{O}(\phi)$-fraction of the edges cross between partition sets.
  In this article, we give the first near-optimal \emph{parallel} algorithm to compute $\phi$-expander decompositions in near-linear work $\widetilde{O}(m/\phi^2)$ and near-constant span $\widetilde{O}(1/\phi^4)$. Our algorithm is very simple and likely practical. Our algorithm can also be implemented in the distributed Congest model in $\tilde{O}(1/\phi^4)$ rounds.
  Our results surpass the theoretical guarantees of the current state-of-the-art parallel algorithms [Chang-Saranurak PODC'19, Chang-Saranurak FOCS'20], while being the first to ensure that only an $\tilde{O}(\phi)$ fraction of edges cross between partition sets. In contrast, previous algorithms [Chang-Saranurak PODC'19, Chang-Saranurak FOCS'20] admit at least an $O(\phi^{1/3})$ fraction of crossing edges, a polynomial loss in quality inherent to their random-walk-based techniques. Our algorithm, instead, leverages flow-based techniques and extends the popular sequential algorithm presented in [Saranurak-Wang SODA'19].</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13451v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daoyuan Chen, Simon Meierhans, Maximilian Probst Gutenberg, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>Adaptive and oblivious statistical adversaries are equivalent</title>
      <link>https://arxiv.org/abs/2410.13548</link>
      <description>arXiv:2410.13548v1 Announce Type: cross 
Abstract: We resolve a fundamental question about the ability to perform a statistical task, such as learning, when an adversary corrupts the sample. Such adversaries are specified by the types of corruption they can make and their level of knowledge about the sample. The latter distinguishes between sample-adaptive adversaries which know the contents of the sample when choosing the corruption, and sample-oblivious adversaries, which do not. We prove that for all types of corruptions, sample-adaptive and sample-oblivious adversaries are \emph{equivalent} up to polynomial factors in the sample size. This resolves the main open question introduced by \cite{BLMT22} and further explored in \cite{CHLLN23}.
  Specifically, consider any algorithm $A$ that solves a statistical task even when a sample-oblivious adversary corrupts its input. We show that there is an algorithm $A'$ that solves the same task when the corresponding sample-adaptive adversary corrupts its input. The construction of $A'$ is simple and maintains the computational efficiency of $A$: It requests a polynomially larger sample than $A$ uses and then runs $A$ on a uniformly random subsample.
  One of our main technical tools is a new structural result relating two distributions defined on sunflowers which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13548v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Blanc, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>On estimating the trace of quantum state powers</title>
      <link>https://arxiv.org/abs/2410.13559</link>
      <description>arXiv:2410.13559v1 Announce Type: cross 
Abstract: We investigate the computational complexity of estimating the trace of quantum state powers $\text{tr}(\rho^q)$ for an $n$-qubit mixed quantum state $\rho$, given its state-preparation circuit of size $\text{poly}(n)$. This quantity is closely related to and often interchangeable with the Tsallis entropy $\text{S}_q(\rho) = \frac{1-\text{tr}(\rho^q)}{q-1}$, where $q = 1$ corresponds to the von Neumann entropy. For any non-integer $q \geq 1 + \Omega(1)$, we provide a quantum estimator for $\text{S}_q(\rho)$ with time complexity $\text{poly}(n)$, exponentially improving the prior best results of $\exp(n)$ due to Acharya, Issa, Shende, and Wagner (ISIT 2019), Wang, Guan, Liu, Zhang, and Ying (TIT 2024), and Wang, Zhang, and Li (TIT 2024), and Wang and Zhang (ESA 2024). Our speedup is achieved by introducing efficiently computable uniform approximations of positive power functions into quantum singular value transformation.
  Our quantum algorithm reveals a sharp phase transition between the case of $q=1$ and constant $q&gt;1$ in the computational complexity of the Quantum $q$-Tsallis Entropy Difference Problem (TsallisQED$_q$), particularly deciding whether the difference $\text{S}_q(\rho_0) - \text{S}_q(\rho_1)$ is at least $0.001$ or at most $-0.001$:
  - For any $1+\Omega(1) \leq q \leq 2$, TsallisQED$_q$ is $\mathsf{BQP}$-complete, which implies that Purity Estimation is also $\mathsf{BQP}$-complete.
  - For any $1 \leq q \leq 1 + \frac{1}{n-1}$, TsallisQED$_q$ is $\mathsf{QSZK}$-hard, leading to hardness of approximating von Neumann entropy because $\text{S}_q(\rho) \leq \text{S}(\rho)$, as long as $\mathsf{BQP} \subsetneq \mathsf{QSZK}$.
  The hardness results are derived from reductions based on new inequalities for the quantum $q$-Jensen-(Shannon-)Tsallis divergence with $1\leq q \leq 2$, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13559v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yupan Liu, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>Almost-Optimal Sublinear Additive Spanners</title>
      <link>https://arxiv.org/abs/2303.12768</link>
      <description>arXiv:2303.12768v3 Announce Type: replace 
Abstract: Given an undirected unweighted graph $G = (V, E)$ on $n$ vertices and $m$ edges, a subgraph $H\subseteq G$ is a spanner of $G$ with stretch function $f: \mathbb{R}_+ \rightarrow \mathbb{R}_+$, if for every pair $s, t$ of vertices in $V$, $\text{dist}_{H}(s, t)\le f(\text{dist}_{G}(s, t))$. When $f(d) = d + o(d)$, $H$ is called a sublinear additive spanner; when $f(d) = d + o(n)$, $H$ is called an \emph{additive spanner}, and $f(d) - d$ is usually called the \emph{additive stretch} of $H$.
  As our primary result, we show that for any constant $\delta&gt;0$ and constant integer $k\geq 2$, every graph on $n$ vertices has a sublinear additive spanner with stretch function $f(d)=d+O(d^{1-1/k})$ and $O\big(n^{1+\frac{1+\delta}{2^{k+1}-1}}\big)$ edges. When $k = 2$, this improves upon the previous spanner construction with stretch function $f(d) = d + O(d^{1/2})$ and $\tilde{O}(n^{1+3/17})$ edges; for any constant integer $k\geq 3$, this improves upon the previous spanner construction with stretch function $f(d) = d + O(d^{1-1/k})$ and $O\bigg(n^{1+\frac{(3/4)^{k-2}}{7 - 2\cdot (3/4)^{k-2}}}\bigg)$ edges. Most importantly, the size of our spanners almost matches the lower bound of $\Omega\big(n^{1+\frac{1}{2^{k+1}-1}}\big)$, which holds for all compression schemes achieving the same stretch function.
  As our second result, we show a new construction of additive spanners with stretch $O(n^{0.403})$ and $\tilde{O}(n)$ edges, which slightly improves upon the previous stretch bound of $O(n^{3/7+\varepsilon})$ achieved by linear-size spanners. An additional advantage of our spanner is that it admits a subquadratic construction runtime of $\tilde{O}(m + n^{13/7})$, while the previous construction requires all-pairs shortest paths computation which takes $O(\min\{mn, n^{2.373}\})$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.12768v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zihan Tan, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>Lift-and-Project Integrality Gaps for Santa Claus</title>
      <link>https://arxiv.org/abs/2406.18273</link>
      <description>arXiv:2406.18273v2 Announce Type: replace 
Abstract: This paper is devoted to the study of the MaxMinDegree Arborescence (MMDA) problem in layered directed graphs of depth $\ell\le O(\log n/\log \log n)$, which is an important special case of the Santa Claus problem. Obtaining a polylogarithmic approximation for MMDA in polynomial time is of high interest as it is a necessary condition to improve upon the well-known 2-approximation for makespan scheduling on unrelated machines by Lenstra, Shmoys, and Tardos [FOCS'87]. The only way we have to solve the MMDA problem within a polylogarithmic factor is via an elegant recursive rounding of the $(\ell-1)^{th}$ level of the Sherali-Adams hierarchy, which needs time $n^{O(\ell)}$ to solve. However, it remains plausible that one could obtain a polylogarithmic approximation in polynomial time by using the same rounding with only $1$ round of the Sherali-Adams hierarchy. As a main result, we rule out this possibility by constructing an MMDA instance of depth $3$ for which an integrality gap of $n^{\Omega(1)}$ survives $1$ round of the Sherali-Adams hierarchy. This result is tight since it is known that after only $2$ rounds the gap is at most polylogarithmic on depth-3 graphs. Second, we show that our instance can be ``lifted'' via a simple trick to MMDA instances of any depth $\ell\in \Omega(1)\cap o(\log n/\log \log n)$ (the whole range of interest), for which we conjecture that an integrality gap of $n^{\Omega(1/\ell)}$ survives $\Omega(\ell)$ rounds of Sherali-Adams. We show a number of intermediate results towards this conjecture, which also suggest that our construction is a significant challenge to the techniques used so far for Santa Claus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18273v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Etienne Bamas</dc:creator>
    </item>
    <item>
      <title>Cut-Preserving Vertex Sparsifiers for Planar and Quasi-bipartite Graphs</title>
      <link>https://arxiv.org/abs/2407.10852</link>
      <description>arXiv:2407.10852v2 Announce Type: replace 
Abstract: We study vertex sparsification for preserving cuts. Given a graph $G$ with a subset $|T|=k$ of its vertices called terminals, a \emph{quality-$q$ cut sparsifier} is a graph $G'$ that contains $T$, such that, for any partition $(T_1,T_2)$ of $T$ into non-empty subsets, the value of the min-cut in $G'$ separating $T_1$ from $T_2$ is within factor $q$ from the value of the min-cut in $G$ separating $T_1$ from $T_2$. The construction of cut sparsifiers with good (small) quality and size has been a central problem in graph compression for years.
  Planar graphs and quasi-bipartite graphs are two important special families studied in this research direction. The main results in this paper are new cut sparsifier constructions for them in the high-quality regime (where $q=1$ or $1+\varepsilon$ for small $\varepsilon&gt;0$).
  We first show that every planar graph admits a planar quality-$(1+\varepsilon)$ cut sparsifier of size $\tilde O(k/\text{poly}(\varepsilon))$, which is in sharp contrast with the lower bound of $2^{\Omega(k)}$ for the quality-$1$ case.
  We then show that every quasi-bipartite graph admits a quality-$1$ cut sparsifier of size $2^{\tilde O(k^2)}$. This is the second to improve over the doubly-exponential bound for general graphs (previously only planar graphs have been shown to have single-exponential size quality-$1$ cut sparsifiers).
  Lastly, we show that contraction, a common approach for constructing cut sparsifiers adopted in most previous works, does not always give optimal bounds for cut sparsifiers. We demonstrate this by showing that the optimal size bound for quality-$(1+\varepsilon)$ contraction-based cut sparsifiers for quasi-bipartite graphs lies in the range $[k^{\tilde\Omega(1/\varepsilon)},k^{O(1/\varepsilon^2)}]$, while in previous work an upper bound of $\tilde O(k/\varepsilon^2)$ was achieved via a non-contraction approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10852v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Chen, Zihan Tan</dc:creator>
    </item>
    <item>
      <title>Path Partitions of Phylogenetic Networks</title>
      <link>https://arxiv.org/abs/2408.06489</link>
      <description>arXiv:2408.06489v2 Announce Type: replace 
Abstract: In phylogenetics, evolution is traditionally represented in a tree-like manner. However, phylogenetic networks can be more appropriate for representing evolutionary events such as hybridization, horizontal gene transfer, and others. In particular, the class of forest-based networks was recently introduced to represent introgression, in which genes are swapped between between species. A network is forest-based if it can be obtained by adding arcs to a collection of trees, so that the endpoints of the new arcs are in different trees. This contrasts with so-called tree-based networks, which are formed by adding arcs within a single tree.
  We are interested in the computational complexity of recognizing forest-based networks, which was recently left as an open problem by Huber et al. Forest-based networks coincide with directed acyclic graphs that can be partitioned into induced paths, each ending at a leaf of the original graph. Several types of path partitions have been studied in the graph theory literature, but to our knowledge this type of leaf induced path partition has not been considered before. The study of forest-based networks in terms of these partitions allows us to establish closer relationships between phylogenetics and algorithmic graph theory, and to provide answers to problems in both fields.
  We show that deciding whether a network is forest-based is NP-complete, even on input networks that are tree-based, binary, and have only three leaves. This shows that partitioning a directed acyclic graph into three induced paths is NP-complete, answering a recent question of Fernau et al. We then show that the problem is polynomial-time solvable on binary networks with two leaves and on the class of orchards. Finally, for undirected graphs, we introduce unrooted forest-based networks and provide hardness results for this class as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06489v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Lafond, Vincent Moulton</dc:creator>
    </item>
    <item>
      <title>Parallel Set Cover and Hypergraph Matching via Uniform Random Sampling</title>
      <link>https://arxiv.org/abs/2408.13362</link>
      <description>arXiv:2408.13362v2 Announce Type: replace 
Abstract: The SetCover problem has been extensively studied in many different models of computation, including parallel and distributed settings. From an approximation point of view, there are two standard guarantees: an $O(\log \Delta)$-approximation (where $\Delta$ is the maximum set size) and an $O(f)$-approximation (where $f$ is the maximum number of sets containing any given element).
  In this paper, we introduce a new, surprisingly simple, model-independent approach to solving SetCover in unweighted graphs. We obtain multiple improved algorithms in the MPC and CRCW PRAM models. First, in the MPC model with sublinear space per machine, our algorithms can compute an $O(f)$ approximation to SetCover in $\hat{O}(\sqrt{\log \Delta} + \log f)$ rounds, where we use the $\hat{O}(x)$ notation to suppress $\mathrm{poly} \log x$ and $\mathrm{poly} \log \log n$ terms, and a $O(\log \Delta)$ approximation in $O(\log^{3/2} n)$ rounds. Moreover, in the PRAM model, we give a $O(f)$ approximate algorithm using linear work and $O(\log n)$ depth. All these bounds improve the existing round complexity/depth bounds by a $\log^{\Omega(1)} n$ factor.
  Moreover, our approach leads to many other new algorithms, including improved algorithms for the HypergraphMatching problem in the MPC model, as well as simpler SetCover algorithms that match the existing bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13362v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Laxman Dhulipala, Michael Dinitz, Jakub {\L}\k{a}cki, Slobodan Mitrovi\'c</dc:creator>
    </item>
    <item>
      <title>Faster Diffusion Sampling with Randomized Midpoints: Sequential and Parallel</title>
      <link>https://arxiv.org/abs/2406.00924</link>
      <description>arXiv:2406.00924v2 Announce Type: replace-cross 
Abstract: Sampling algorithms play an important role in controlling the quality and runtime of diffusion model inference. In recent years, a number of works~\cite{chen2023sampling,chen2023ode,benton2023error,lee2022convergence} have proposed schemes for diffusion sampling with provable guarantees; these works show that for essentially any data distribution, one can approximately sample in polynomial time given a sufficiently accurate estimate of its score functions at different noise levels. In this work, we propose a new scheme inspired by Shen and Lee's randomized midpoint method for log-concave sampling~\cite{ShenL19}. We prove that this approach achieves the best known dimension dependence for sampling from arbitrary smooth distributions in total variation distance ($\widetilde O(d^{5/12})$ compared to $\widetilde O(\sqrt{d})$ from prior work). We also show that our algorithm can be parallelized to run in only $\widetilde O(\log^2 d)$ parallel rounds, constituting the first provable guarantees for parallel sampling with diffusion models.
  As a byproduct of our methods, for the well-studied problem of log-concave sampling in total variation distance, we give an algorithm and simple analysis achieving dimension dependence $\widetilde O(d^{5/12})$ compared to $\widetilde O(\sqrt{d})$ from prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00924v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivam Gupta, Linda Cai, Sitan Chen</dc:creator>
    </item>
    <item>
      <title>Efficient PAC Learning of Halfspaces with Constant Malicious Noise Rate</title>
      <link>https://arxiv.org/abs/2410.01186</link>
      <description>arXiv:2410.01186v2 Announce Type: replace-cross 
Abstract: Understanding noise tolerance of learning algorithms under certain conditions is a central quest in learning theory. In this work, we study the problem of computationally efficient PAC learning of halfspaces in the presence of malicious noise, where an adversary can corrupt both instances and labels of training samples. The best-known noise tolerance either depends on a target error rate under distributional assumptions or on a margin parameter under large-margin conditions. In this work, we show that when both types of conditions are satisfied, it is possible to achieve {\em constant} noise tolerance by minimizing a reweighted hinge loss. Our key ingredients include: 1) an efficient algorithm that finds weights to control the gradient deterioration from corrupted samples, and 2) a new analysis on the robustness of the hinge loss equipped with such weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01186v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Shen, Xiaoyu Li</dc:creator>
    </item>
  </channel>
</rss>
