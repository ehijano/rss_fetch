<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Tusqh: Topological Control of Volume-Fraction Meshes Near Small Features and Dirty Geometry</title>
      <link>https://arxiv.org/abs/2502.10609</link>
      <description>arXiv:2502.10609v1 Announce Type: new 
Abstract: This work develops a framework to create meshes with user-specified homology from potentially dirty geometry by coupling background grids, persistent homology, and a generalization of volume fractions. For a mesh with fixed grid size, the topology of the output mesh changes predictably and monotonically as its volume-fraction threshold decreases. Topological anti-aliasing methods are introduced to resolve pinch points and disconnected regions that are artifacts of user choice of grid size and orientation, making the output meshes suitable for downstream processes including analysis. The methodology is demonstrated on geographical, mechanical, and graphics models in 2D and 3D using a custom-made software called Tusqh. The work demonstrates that the proposed framework is viable for generating meshes on topologically invalid geometries and for automatic defeaturing of small geometric artifacts. Finally, the work shows that although subdividing the background grid frequently improves the topological and geometrical fidelity of the output mesh, there are simple 2D examples for which the topology does not converge under refinement for volume-fraction codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10609v1</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Shawcroft, Kendrick M. Shepherd, Scott Mitchell</dc:creator>
    </item>
    <item>
      <title>Outside-Obstacle Representations with All Vertices on the Outer Face</title>
      <link>https://arxiv.org/abs/2202.13015</link>
      <description>arXiv:2202.13015v4 Announce Type: replace 
Abstract: An obstacle representation of a graph $G$ consists of a set of polygonal obstacles and a drawing of $G$ as a visibility graph with respect to the obstacles: vertices are mapped to points and edges to straight-line segments such that each edge avoids all obstacles whereas each non-edge intersects at least one obstacle. Obstacle representations have been investigated quite intensely over the last few years. Here we focus on outside-obstacle representations (OORs) that use only one obstacle in the outer face of the drawing. It is known that every outerplanar graph admits such a representation.
  We strengthen this result by showing that every (partial) 2-tree has an OOR. We also consider restricted versions of OORs where the vertices of the graph form a convex polygon or even a regular polygon. We characterize when the complement of a tree and when a complete graph minus a simple cycle admits a convex OOR. We construct regular OORs for all (partial) outerpaths, cactus graphs, and grids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.13015v4</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.57717/cgt.v4i1.64</arxiv:DOI>
      <arxiv:journal_reference>Computing in Geometry and Topology, 4(1), 2:1-2:21, 2025</arxiv:journal_reference>
      <dc:creator>Oksana Firman, Philipp Kindermann, Jonathan Klawitter, Boris Klemz, Felix Klesen, Alexander Wolff</dc:creator>
    </item>
    <item>
      <title>No-dimensional Tverberg Partitions Revisited</title>
      <link>https://arxiv.org/abs/2306.01678</link>
      <description>arXiv:2306.01678v4 Announce Type: replace 
Abstract: $ \newcommand{\epsA}{\Mh{\delta}} \newcommand{\Re}{\mathbb{R}} \newcommand{\reals}{\mathbb{R}} \newcommand{\SetX}{\mathsf{X}} \renewcommand{\P}{P} \newcommand{\diam}{\Delta} \newcommand{\Mh}[1]{#1} \newcommand{\query}{q} \newcommand{\eps}{\varepsilon} \newcommand{\VorX}[1]{\mathcal{V} \pth{#1}} \newcommand{\IntRange}[1]{[ #1 ]} \newcommand{\Space}{\overline{\mathsf{m}}} \newcommand{\pth}[2][\!]{#1\left({#2}\right)} \newcommand{\polylog}{\mathrm{polylog}} \newcommand{\N}{\mathbb N} \newcommand{\Z}{\mathbb Z} \newcommand{\pt}{p} \newcommand{\distY}[2]{\left\| {#1} - {#2} \right\|} \newcommand{\PP}{P} \newcommand{\ptq}{q} \newcommand{\pts}{s}$Given a set $P \subset \Re^d$ of $n$ points, with diameter $\diam$, and a parameter $\epsA \in (0,1)$, it is known that there is a partition of $P$ into sets $P_1, \ldots, P_t$, each of size $O(1/\epsA^2)$, such that their convex-hulls all intersect a common ball of radius $\epsA \diam$. We prove that a random partition, with a simple alteration step, yields the desired partition, resulting in a (randomized) linear time algorithm. We also provide a deterministic algorithm with running time $O( dn \log n)$. Previous proofs were either existential (i.e., at least exponential time), or required much bigger sets. In addition, the algorithm and its proof of correctness are significantly simpler than previous work, and the constants are slightly better.
  We also include a number of applications and extensions using the same central ideas. For example, we provide a linear time algorithm for computing a ``fuzzy'' centerpoint, and prove a no-dimensional weak $\eps$-net theorem with an improved constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01678v4</guid>
      <category>cs.CG</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sariel Har-Peled, Eliot W. Robson</dc:creator>
    </item>
    <item>
      <title>PHLP: Sole Persistent Homology for Link Prediction - Interpretable Feature Extraction</title>
      <link>https://arxiv.org/abs/2404.15225</link>
      <description>arXiv:2404.15225v2 Announce Type: replace-cross 
Abstract: Link prediction (LP), inferring the connectivity between nodes, is a significant research area in graph data, where a link represents essential information on relationships between nodes. Although graph neural network (GNN)-based models have achieved high performance in LP, understanding why they perform well is challenging because most comprise complex neural networks. We employ persistent homology (PH), a topological data analysis method that helps analyze the topological information of graphs, to interpret the features used for prediction. We propose a novel method that employs PH for LP (PHLP) focusing on how the presence or absence of target links influences the overall topology. The PHLP utilizes the angle hop subgraph and new node labeling called degree double radius node labeling (Degree DRNL), distinguishing the information of graphs better than DRNL. Using only a classifier, PHLP performs similarly to state-of-the-art (SOTA) models on most benchmark datasets. Incorporating the outputs calculated using PHLP into the existing GNN-based SOTA models improves performance across all benchmark datasets. To the best of our knowledge, PHLP is the first method of applying PH to LP without GNNs. The proposed approach, employing PH while not relying on neural networks, enables the identification of crucial factors for improving performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15225v2</guid>
      <category>cs.LG</category>
      <category>cs.CG</category>
      <category>math.AT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junwon You, Eunwoo Heo, Jae-Hun Jung</dc:creator>
    </item>
    <item>
      <title>Core Bifiltration</title>
      <link>https://arxiv.org/abs/2405.01214</link>
      <description>arXiv:2405.01214v3 Announce Type: replace-cross 
Abstract: The motivation of this paper is to recognize a geometric shape from a noisy sample in the form of a point cloud. Inspired by the HDBSCAN clustering algorithm, we introduce the core dissimilarity, from which we construct the core bifiltration. We also consider the Delaunay core bifiltration by intersecting with Voronoi cells, giving us a filtered simplicial complex of smaller size. A major advantage of the (Delaunay) core bifiltration is that, for each filtration value, it admits a good cover of balls. By the persistent nerve theorem, the nerve of this cover is homotopy equivalent to the (Delaunay) core bifiltration. We show that the multicover-, core- and Delaunay core bifiltrations are all interleaved, and that they enjoy similar stability properties with respect to the Prohorov distance. We have performed experiments with the Delaunay core bifiltration. In the experiments, we calculated persistent homology along lines in the two-dimensional persistence parameter space, and computed multipersistence module approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01214v3</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nello Blaser, Morten Brun, Odin Hoff Gardaa, Lars M. Salbu</dc:creator>
    </item>
    <item>
      <title>Topological Stability and Latschev-type Reconstruction Theorems for $\boldsymbol{\mathrm{CAT}(\kappa)}$ Spaces</title>
      <link>https://arxiv.org/abs/2406.04259</link>
      <description>arXiv:2406.04259v2 Announce Type: replace-cross 
Abstract: We consider the problem of homotopy-type reconstruction of compact shapes $X\subset\mathbb{R}^N$ that are $\mathrm{CAT}(\kappa)$ in the intrinsic length metric. The reconstructed spaces are in the form of Vietoris--Rips complexes computed from a compact sample $S$, Hausdorff--close to the unknown shape $X$. Instead of the Euclidean metric on the sample, our reconstruction technique leverages a path-based metric to compute these complexes. As naturally emerging in the framework of reconstruction, we also study the Gromov--Hausdorff topological stability and finiteness problem for general compact $\mathrm{CAT}(\kappa)$ spaces. Our techniques provide novel sampling conditions alternative to the existing and commonly used techniques using weak feature size and $\mu$--reach. In particular, we introduce a new parameter, called the {\em restricted distortion}, which is a generalization of the well-known global distortion of embedding. We show examples of Euclidean subspaces, for which the known parameters such as the reach, $\mu$--reach and weak features size vanish, whereas the restricted distortion is finite, making our reconstruction results applicable for such spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04259v2</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <category>math.MG</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafal Komendarczyk, Sushovan Majhi, Will Tran</dc:creator>
    </item>
    <item>
      <title>Omnidirectional Sensor Placement: A Large-Scale Computational Study and Novel Hybrid Accelerated-Refinement Heuristics</title>
      <link>https://arxiv.org/abs/2410.08784</link>
      <description>arXiv:2410.08784v2 Announce Type: replace-cross 
Abstract: This paper studies the omnidirectional sensor-placement problem (OSPP), which involves placing static sensors in a continuous 2D environment to achieve a user-defined coverage requirement while minimizing sensor count. The problem is motivated by applications in mobile robotics, particularly for optimizing visibility-based route planning tasks such as environment inspection, target search, and region patrolling. We focus on omnidirectional visibility models, which eliminate sensor orientation constraints while remaining relevant to real-world sensing technologies like LiDAR, 360-degree cameras, and multi-sensor arrays. Three key models are considered: unlimited visibility, limited-range visibility to reflect physical or application-specific constraints, and localization-uncertainty visibility to account for sensor placement uncertainty in robotics. Our first contribution is a large-scale computational study comparing classical convex-partitioning and sampling-based heuristics for the OSPP, analyzing their trade-off between runtime efficiency and solution quality. Our second contribution is a new class of hybrid accelerated-refinement (HAR) heuristics, which combine and refine outputs from multiple sensor-placement methods while incorporating preprocessing techniques to accelerate refinement. Results demonstrate that HAR heuristics significantly outperform traditional methods, achieving the lowest sensor counts and improving the runtime of sampling-based approaches. Additionally, we adapt a specific HAR heuristic to the localization-uncertainty visibility model, showing that it achieves the required coverage for small to moderate localization uncertainty. Future work may apply HAR to visibility-based route planning tasks or explore novel sensor-placement approaches to achieve formal coverage guarantees under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08784v2</guid>
      <category>cs.RO</category>
      <category>cs.CG</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Mikula (Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague, Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University in Prague), Miroslav Kulich (Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague)</dc:creator>
    </item>
  </channel>
</rss>
