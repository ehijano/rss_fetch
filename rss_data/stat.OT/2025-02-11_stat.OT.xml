<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Feb 2025 02:58:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Leveraging Order-Theoretic Tournament Graphs for Assessing Internal Consistency in Survey-Based Instruments Across Diverse Scenarios</title>
      <link>https://arxiv.org/abs/2502.05336</link>
      <description>arXiv:2502.05336v1 Announce Type: new 
Abstract: This paper introduces Monotone Delta, an order-theoretic measure designed to enhance the reliability assessment of survey-based instruments in human-machine interactions. Traditional reliability measures, such as Cronbach's Alpha and McDonald's Omega, often yield misleading estimates due to their sensitivity to redundancy, multidimensional constructs, and assumptions of normality and uncorrelated errors. These limitations can compromise decision-making in human-centric evaluations, where survey instruments inform adaptive interfaces, cognitive workload assessments, and human-AI trust models. Monotone Delta addresses these issues by quantifying internal consistency through the minimization of ordinal contradictions and alignment with a unidimensional latent order using weighted tournaments. Unlike traditional approaches, it operates without parametric or model-based assumptions. We conducted theoretical analyses and experimental evaluations on four challenging scenarios: tau-equivalence, redundancy, multidimensionality, and non-normal distributions, and proved that Monotone Delta provides more stable reliability assessments compared to existing methods. The Monotone Delta is a valuable alternative for evaluating questionnaire-based assessments in psychology, human factors, healthcare, and interactive system design, enabling organizations to optimize survey instruments, reduce costly redundancies, and enhance confidence in human-system interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05336v1</guid>
      <category>stat.OT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhammad Umair Danish, Umair Rehman, Katarina Grolinger</dc:creator>
    </item>
    <item>
      <title>Random Variables aren't Random</title>
      <link>https://arxiv.org/abs/2502.06628</link>
      <description>arXiv:2502.06628v1 Announce Type: new 
Abstract: This paper examines the foundational concept of random variables in probability theory and statistical inference, demonstrating that their mathematical definition requires no reference to randomization or hypothetical repeated sampling. We show how measure-theoretic probability provides a framework for modeling populations through distributions, leading to three key contributions. First, we establish that random variables, properly understood as measurable functions, can be fully characterized without appealing to infinite hypothetical samples. Second, we demonstrate how this perspective enables statistical inference through logical rather than probabilistic reasoning, extending the reductio ad absurdum argument from deductive to inductive inference. Third, we show how this framework naturally leads to information-based assessment of statistical procedures, replacing traditional inference metrics that emphasize bias and variance with information-based approaches that better describe the families of distributions used in parametric inference. This reformulation addresses long-standing debates in statistical inference while providing a more coherent theoretical foundation. Our approach offers an alternative to traditional frequentist inference that maintains mathematical rigor while avoiding the philosophical complications inherent in repeated sampling interpretations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06628v1</guid>
      <category>stat.OT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul W. Vos</dc:creator>
    </item>
    <item>
      <title>Bhirkuti's Test of Bias Acceptance: Examining in Psychometric Simulations</title>
      <link>https://arxiv.org/abs/2411.18481</link>
      <description>arXiv:2411.18481v2 Announce Type: replace-cross 
Abstract: This study introduces Bhirkuti's Test of Bias Acceptance, a systematic graphical framework for evaluating bias and determining its acceptability under varying experimental conditions. Absolute Relative Bias (ARB), while useful for understanding bias, is sensitive to outliers and population parameter magnitudes, often overstating bias for small values and understating it for larger ones. Similarly, Relative Efficiency (RE) can be influenced by variance differences and outliers, occasionally producing counterintuitive values exceeding 100%, which complicates interpretation. By addressing the limitations of traditional metrics such as Absolute Relative Bias (ARB) and Relative Efficiency (RE), the proposed graphical methodology framework leverages ridgeline plots and standardized estimate to provide a comprehensive visualization of parameter estimate distributions. Ridgeline plots done this way offer a robust alternative by visualizing full distributions, highlighting variability, trends, outliers, descriptives and facilitating more informed decision-making. This study employs multivariate Latent Growth Models (LGM) and Monte Carlo simulations to examine the performance of growth curve modeling under planned missing data designs, focusing on parameter estimate recovery and efficiency. By combining innovative visualization techniques with rigorous simulation methods, Bhirkuti's Test of Bias Acceptance provides two methods of versatile and interpretable toolset for advancing quantitative research in bias evaluation and efficiency assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18481v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aneel Bhusal, Todd D. Little</dc:creator>
    </item>
  </channel>
</rss>
