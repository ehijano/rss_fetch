<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Jan 2026 02:36:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>AI-Assisted Authoring for Transparent, Data-Driven Documents</title>
      <link>https://arxiv.org/abs/2601.06027</link>
      <description>arXiv:2601.06027v1 Announce Type: new 
Abstract: We introduce _transparent documents_, interactive web-based scholarly articles which allow readers to explore the relationship to the underlying data by hovering over fragments of text, and present an LLM-based tool for authoring transparent documents, building on recent developments in data provenance for general-purpose programming languages. As a target platform, our implementation uses Fluid, an open source programming language with a provenance-tracking runtime. Our agent-based tool supports a human author during the creation of transparent documents, identifying fragments of text which can be computed from data, such as numerical values selected from records or computed by aggregations like sum and mean, comparatives and superlatives like _better than_ and _largest_, trend-adjectives like _growing_, and similar quantitative or semi-quantitative phrases, and then attempts to synthesise a suitable Fluid query over the data which generates the target string. The resulting expression is inserted into the article's web page, turning the static text fragment into an interactable data-driven element able to reveal the data that underwrites the natural language claim. We evaluate our approach on a subset of SciGen, an open source dataset consisting of tables from scientific articles and their corresponding descriptions, which we extend with hand-generated counterfactual test cases to evaluate how well machine-generated expressions generalise. Our results show that gpt4o is often able to synthesise compound expressions extensionally compatible with our gold solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06027v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>cs.PL</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alfonso Piscitelli, Cristina David, Mattia De Rosa, Ali Mohammed, Federico Nanni, Jacob Pake, Roly Perera, Jessy Sodimu, Chenyiqiu Zheng</dc:creator>
    </item>
    <item>
      <title>Leveraging Foundation Models for Calibration-Free c-VEP BCIs</title>
      <link>https://arxiv.org/abs/2601.06028</link>
      <description>arXiv:2601.06028v1 Announce Type: new 
Abstract: Foundation Models (FMs) have surged in popularity over the past five years, with applications spanning fields from computer vision to natural language processing. Brain-Computer Interfaces (BCIs) have also gained momentum due to their potential to support individuals with complex disabilities. Among BCI paradigms, code-modulated Visual Evoked Potentials (c-VEPs) remain relatively understudied, despite offering high information transfer rates and large selection target capacities. However, c-VEP systems require lengthy calibration sessions, limiting their practicality outside of laboratory settings. In this study, we use a FM for the first time to eliminate the need for lengthy calibration in c-VEP BCI systems. We evaluated two approaches: (1) a truly calibration-free approach requiring no subject-specific data, and (2) a limited calibration approach, where we assessed the benefit of incorporating incremental amounts of calibration data. In both cases, a classification head is trained on data from other subjects. For a new subject, no calibration data is required in the calibration-free setup, making the c-VEP system effectively plug-and-play. The proposed method was tested on two c-VEP datasets. For the calibration-free approach, the average accuracy on the first dataset (n = 17) was 68.8% +/- 17.6%, comparable to the full-calibration performance reported in the original study (66.2% +/- 13.8%), which required approximately 11 minutes of calibration. On the second dataset (n = 12), the calibration-free accuracy was 71.8% +/- 20.2%, versus 93.7% +/- 5.5% from the original study, which required around 3.5 minutes. A limited-calibration approach using only 20% of the subject's data (approximately 43 seconds) yielded 92% +/- 5.2% accuracy. These results indicate that our FM-based approach can effectively eliminate or significantly reduce the need for lengthy calibration in c-VEP BCIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06028v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadreza Behboodi, Eli Kinney-Lang, Ali Etemad, Adam Kirton, Hatem Abou-Zeid</dc:creator>
    </item>
    <item>
      <title>A Recommendation System-Based Framework for Enhancing Human-Machine Collaboration in Industrial Timetabling Rescheduling: Application in Preventive Maintenance</title>
      <link>https://arxiv.org/abs/2601.06029</link>
      <description>arXiv:2601.06029v1 Announce Type: new 
Abstract: Industrial timetabling is a critical task for decision-makers across various sectors to ensure efficient system operation. In real-world settings, it remains challenging because unexpected events often disrupt execution. When such events arise, effective rescheduling and collaboration between humans and machines becomes essential. This paper presents a recommendation system-based framework for handling rescheduling challenges, built on Timefold, a powerful AI-driven planning engine. Our experimental study evaluates nine instances inspired by a realworld preventive maintenance use case, aiming to identify the heuristic that best balances solution quality and computing time to support near-optimal decisionmaking when rescheduling is required due to unexpected events during operational days. Finally, we illustrate the complete process of our recommendation system through a simple use case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06029v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>26th IFIP WG 5.5 SOCOLNET Working Conference on Virtual Enterprises, PRO-VE 2025, Oct 2025, Porto, Portugal. pp.363-381</arxiv:journal_reference>
      <dc:creator>K\'evin Ducharlet, Liwen Zhang, Sara Maqrot, Houssem Saidi</dc:creator>
    </item>
    <item>
      <title>From Augmentation to Symbiosis: A Review of Human-AI Collaboration Frameworks, Performance, and Perils</title>
      <link>https://arxiv.org/abs/2601.06030</link>
      <description>arXiv:2601.06030v1 Announce Type: new 
Abstract: This paper offers a concise, 60-year synthesis of human-AI collaboration, from Licklider's ``man-computer symbiosis" (AI as colleague) and Engelbart's ``augmenting human intellect" (AI as tool) to contemporary poles: Human-Centered AI's ``supertool" and Symbiotic Intelligence's mutual-adaptation model. We formalize the mechanism for effective teaming as a causal chain: Explainable AI (XAI) -&gt; co-adaptation -&gt; shared mental models (SMMs). A meta-analytic ``performance paradox" is then examined: human-AI teams tend to show negative synergy in judgment/decision tasks (underperforming AI alone) but positive synergy in content creation and problem formulation. We trace failures to the algorithm-in-the-loop dynamic, aversion/bias asymmetries, and cumulative cognitive deskilling. We conclude with a unifying framework--combining extended-self and dual-process theories--arguing that durable gains arise when AI functions as an internalized cognitive component, yielding a unitary human-XAI symbiotic agency. This resolves the paradox and delineates a forward agenda for research and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06030v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Jiarui Tong</dc:creator>
    </item>
    <item>
      <title>Beyond Clicking:A Step Towards Generalist GUI Grounding via Text Dragging</title>
      <link>https://arxiv.org/abs/2601.06031</link>
      <description>arXiv:2601.06031v1 Announce Type: new 
Abstract: Graphical user interface (GUI) grounding, the process of mapping human instructions to GUI actions, serves as a fundamental basis to autonomous GUI agents. While existing grounding models achieve promising performance to simulate the mouse click action on various click-based benchmarks, another essential mode of mouse interaction, namely dragging, remains largely underexplored. Yet, dragging the mouse to select and manipulate textual content represents a prevalent and important usage in practical GUI scenarios. To narrow this gap, we first introduce GUI-Drag, a diverse dataset of 161K text dragging examples synthesized through a scalable pipeline. To support systematic and robust evaluation, we further construct ScreenDrag, a benchmark with 5,333 examples spanning three levels of interface context, together with three dedicated metrics designed for assessing text dragging capability. Models trained on GUI-Drag with an efficient continual training strategy achieve substantial improvements on ScreenDrag, while preserving the original click-based performance on ScreenSpot, ScreenSpot-v2, and OSWorld-G. Our work encourages further research on broader GUI grounding beyond just clicking and paves way toward a truly generalist GUI grounding model. All benchmark, data, checkpoints, and code are open-sourced and available at https://osu-nlp-group.github.io/GUI-Drag.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06031v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyi Liao, Yadong Lu, Boyu Gou, Huan Sun, Ahmed Awadallah</dc:creator>
    </item>
    <item>
      <title>Applied Theory of Mind and Large Language Models -- how good is ChatGPT at solving social vignettes?</title>
      <link>https://arxiv.org/abs/2601.06032</link>
      <description>arXiv:2601.06032v1 Announce Type: new 
Abstract: The rapid development of language-based artificial intelligence (AI) offers new possibilities for psychotherapy and assistive systems, particularly benefitting autistic individuals who often respond well to technology. Parents of autistic persons emphasize the importance of appropriate and context-specific communication behavior. This study investigated whether GPT-3.5 Turbo and GPT-4, as language-based AI applications, are fundamentally capable of replicating this type of adequate communication behavior in the form of applied Theory of Mind (ToM). GPT-3.5 Turbo and GPT-4 were evaluated on three established higher-order ToM tasks: the Faux Pas Test, the Social Stories Questionnaire, and the Story Comprehension Test in English and German. Two independent raters scored response accuracy based on standardized manuals. In addition, responses were rated for epistemic markers as indicators of uncertainty. GPT's results were compared to human neurotypical and neurodivergent samples from previous own and others' research. GPT-4 achieved near human accuracy on the Faux Pas Test and outperformed GPT-3.5 Turbo and individuals with autistic traits. On the Social Stories Questionnaire, GPT-4 scored comparable to neurotypical adults, while GPT-3.5 Turbo remained well below. In the Story Comprehension Test, GPT-4 reached scores that exceeded neurotypical adult and adolescent benchmarks. However, GPT-4 used epistemic markers in up to 42% of responses. GPT-4 shows encouraging performance in complex higher-order ToM tasks and may offer future potential as an assistive tool for individuals with (and without) social communication difficulties. Its ability to interpret complex social situations is promising; however, the frequent use of uncertainty markers highlights the need for further study for assistive use and possibly further refinement to ensure consistent and reliable support in real-world use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06032v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Katharina Holl-Etten, Nina Schnaderbeck, Elizaveta Kosareva, Leonhard Aron Prattke, Ralph Krueger, Lisa Marie Warner, Nora C. Vetter</dc:creator>
    </item>
    <item>
      <title>How Generative AI Empowers Attackers and Defenders Across the Trust &amp; Safety Landscape</title>
      <link>https://arxiv.org/abs/2601.06033</link>
      <description>arXiv:2601.06033v1 Announce Type: new 
Abstract: Generative AI (GenAI) is a powerful technology poised to reshape Trust &amp; Safety. While misuse by attackers is a growing concern, its defensive capacity remains underexplored. This paper examines these effects through a qualitative study with 43 Trust &amp; Safety experts across five domains: child safety, election integrity, hate and harassment, scams, and violent extremism. Our findings characterize a landscape in which GenAI empowers both attackers and defenders. GenAI dramatically increases the scale and speed of attacks, lowering the barrier to entry for creating harmful content, including sophisticated propaganda and deepfakes. Conversely, defenders envision leveraging GenAI to detect and mitigate harmful content at scale, conduct investigations, deploy persuasive counternarratives, improve moderator wellbeing, and offer user support. This work provides a strategic framework for understanding GenAI's impact on Trust &amp; Safety and charts a path for its responsible use in creating safer online environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06033v1</guid>
      <category>cs.HC</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Gage Kelley, Steven Rousso-Schindler, Renee Shelby, Kurt Thomas, Allison Woodruff</dc:creator>
    </item>
    <item>
      <title>Human-in-the-Loop Interactive Report Generation for Chronic Disease Adherence</title>
      <link>https://arxiv.org/abs/2601.06364</link>
      <description>arXiv:2601.06364v1 Announce Type: new 
Abstract: Chronic disease management requires regular adherence feedback to prevent avoidable hospitalizations, yet clinicians lack time to produce personalized patient communications. Manual authoring preserves clinical accuracy but does not scale; AI generation scales but can undermine trust in patient-facing contexts. We present a clinician-in-the-loop interface that constrains AI to data organization and preserves physician oversight through recognition-based review. A single-page editor pairs AI-generated section drafts with time-aligned visualizations, enabling inline editing with visual evidence for each claim. This division of labor (AI organizes, clinician decides) targets both efficiency and accountability. In a pilot with three physicians reviewing 24 cases, AI successfully generated clinically personalized drafts matching physicians' manual authoring practice (overall mean 4.86/10 vs. 5.0/10 baseline), requiring minimal physician editing (mean 8.3\% content modification) with zero safety-critical issues, demonstrating effective automation of content generation. However, review time remained comparable to manual practice, revealing an accountability paradox: in high-stakes clinical contexts, professional responsibility requires complete verification regardless of AI accuracy. We contribute three interaction patterns for clinical AI collaboration: bounded generation with recognition-based review via chart-text pairing, automated urgency flagging that analyzes vital trends and adherence patterns with fail-safe escalation for missed critical monitoring tasks, and progressive disclosure controls that reduce cognitive load while maintaining oversight. These patterns indicate that clinical AI efficiency requires not only accurate models, but also mechanisms for selective verification that preserve accountability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06364v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Zhang, Jinhong Yu, Pengwei Yan, Le Jiang, Xingyi Shen, Mumo Cheng, Xiaozhong Liu</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal Change-Points in Development Discourse: Insights from Social Media in Low-Resource Contexts</title>
      <link>https://arxiv.org/abs/2601.06402</link>
      <description>arXiv:2601.06402v1 Announce Type: new 
Abstract: This study investigates the spatiotemporal evolution of development discourse in low-resource settings. Analyzing more than two years of geotagged X data from Zambia, we introduce a mixed-methods pipeline utilizing topic modeling, change-point detection, and qualitative coding to identify critical shifts in public debate. We identify seven recurring themes, including public health challenges and frustration with government policy, shaped by regional events and national interventions. Notably, we detect discourse changepoints linked to the COVID19 pandemic and a geothermal project, illustrating how online conversations mirror policy flashpoints. Our analysis distinguishes between the ephemeral nature of acute crises like COVID19 and the persistent, structural reorientations driven by long-term infrastructure projects. We conceptualize "durable discourse" as sustained narrative engagement with development issues. Contributing to HCI and ICTD, we examine technology's socioeconomic impact, providing practical implications and future work for direct local engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06402v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Woojin Jung, Charles Chear, Andrew H. Kim, Vatsal Shah, Tawfiq Ammari</dc:creator>
    </item>
    <item>
      <title>Pareto-Optimal Model Selection for Low-Cost, Single-Lead EMG Control in Embedded Systems</title>
      <link>https://arxiv.org/abs/2601.06516</link>
      <description>arXiv:2601.06516v1 Announce Type: new 
Abstract: Consumer-grade biosensors offer a cost-effective alternative to medical-grade electromyography (EMG) systems, reducing hardware costs from thousands of dollars to approximately $13. However, these low-cost sensors introduce significant signal instability and motion artifacts. Deploying machine learning models on resource-constrained edge devices like the ESP32 presents a challenge: balancing classification accuracy with strict latency (&lt;100ms) and memory (&lt;320KB) constraints. Using a single-subject dataset comprising 1,540 seconds of raw data (1.54M data points, segmented into ~1,300 one-second windows), I evaluate 18 model architectures, ranging from statistical heuristics to deep transfer learning (ResNet50) and custom hybrid networks (MaxCRNN). While my custom "MaxCRNN" (Inception + Bi-LSTM + Attention) achieved the highest safety (99% Precision) and robustness, I identify Random Forest (74% accuracy) as the Pareto-optimal solution for embedded control on legacy microcontrollers. I demonstrate that reliable, low-latency EMG control is feasible on commodity hardware, with Deep Learning offering a path to near-perfect reliability on modern Edge AI accelerators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06516v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carl Vincent Ladres Kho</dc:creator>
    </item>
    <item>
      <title>AI Washing and the Erosion of Digital Legitimacy: A Socio-Technical Perspective on Responsible Artificial Intelligence in Business</title>
      <link>https://arxiv.org/abs/2601.06611</link>
      <description>arXiv:2601.06611v1 Announce Type: new 
Abstract: The rapid evolution of artificial intelligence (AI) systems, tools, and technologies has opened up novel, unprecedented opportunities for businesses to innovate, differentiate, and compete. However, growing concerns have emerged about the use of AI in businesses, particularly AI washing, in which firms exaggerate, misrepresent, or superficially signal their AI capabilities to gain financial and reputational advantages. This paper aims to establish a conceptual foundation for understanding AI washing. In this paper, we draw on analogies from greenwashing and insights from Information Systems (IS) research on ethics, trust, signaling, and digital innovation. This paper proposes a typology of AI washing practices across four primary domains: marketing and branding, technical capability inflation, strategic signaling, and governance-based washing. In addition, we examine their organizational, industry, and societal impacts. Our investigation and analysis reveal how AI washing can lead to short-term gains; however, it also proposes severe long-term consequences, including reputational damage, erosion of trust, and misallocation of resources. Moreover, this paper examines current research directions and open questions aimed at mitigating AI washing practices and enhancing the trust and reliability of legitimate AI systems and technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06611v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nelly Elsayed</dc:creator>
    </item>
    <item>
      <title>LLM-Driven Accessible Interface: A Model-Based Approach</title>
      <link>https://arxiv.org/abs/2601.06616</link>
      <description>arXiv:2601.06616v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into interactive systems opens new opportunities for adaptive user experiences, yet it also raises challenges regarding accessibility, explainability, and normative compliance. This paper presents an implemented model-driven architecture for generating personalised, multimodal, and accessibility-aligned user interfaces. The approach combines structured user profiles, declarative adaptation rules, and validated prompt templates to refine baseline accessible UI templates that conform to WCAG 2.2 and EN 301 549, tailored to cognitive and sensory support needs. LLMs dynamically transform language complexity, modality, and visual structure, producing outputs such as Plain-Language text, pictograms, and high-contrast layouts aligned with ISO 24495-1 and W3C COGA guidance. A healthcare use case demonstrates how the system generates accessible post-consultation medication instructions tailored to a user profile comprising cognitive disability and hearing impairment. SysML v2 models provide explicit traceability between user needs, adaptation rules, and normative requirements, ensuring explainable and auditable transformations. Grounded in Human-Centered AI (HCAI), the framework incorporates co-design processes and structured feedback mechanisms to guide iterative refinement and support trustworthy generative behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06616v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Blessing Jerry, Lourdes Moreno, Virginia Francisco, Raquel Hervas</dc:creator>
    </item>
    <item>
      <title>Learning Password Best Practices Through In-Task Instruction</title>
      <link>https://arxiv.org/abs/2601.06650</link>
      <description>arXiv:2601.06650v1 Announce Type: new 
Abstract: Users often make security- and privacy-relevant decisions without a clear understanding of the rules that govern safe behavior. We introduce pedagogical friction, a design approach that introduces brief, instructional interactions at the moment of action. We evaluate this approach in the context of password creation, a task with clear, objective quality criteria and broad familiarity. We conducted a randomized repeated-measures study with 128 participants across four interface conditions that varied the depth and interactivity of guidance. We assessed three outcomes: (1) rule compliance in a subsequent password task without guidance, (2) accuracy on survey questions matched to the rules shown earlier, and (3) behavior-knowledge alignment, which captures whether participants who correctly followed a rule also recognized it on the survey. Across all guided conditions, participants corrected most rule violations in the follow-up task, achieved moderate accuracy on matched rule questions, and showed high behavior-knowledge alignment. These results support pedagogical friction as a lightweight and generalizable intervention for security- and privacy-critical interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06650v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Ma, Yingfan Zhou, Shubhang Kaushik, Aamod Joshi, Aditya Majumdar, Noah Apthorpe, Yan Shvartzshnaider, Sarah Rajtmajer, Brett Frischmann</dc:creator>
    </item>
    <item>
      <title>ImmuniFraug: A Metacognitive Intervention Anti-Fraud Approach to Enhance Undergraduate Students' Cyber Fraud Awareness</title>
      <link>https://arxiv.org/abs/2601.06774</link>
      <description>arXiv:2601.06774v1 Announce Type: new 
Abstract: Cyber fraud now constitutes over half of criminal cases in China, with undergraduate students experiencing a disproportionate rise in victimization. Traditional anti-fraud training remains predominantly passive, yielding limited engagement and retention. This paper introduces ImmuniFraug, a Large Language Model (LLM)-based metacognitive intervention that delivers immersive, multimodal fraud simulations integrating text, voice, and visual avatars across ten prevalent fraud types. Each scenario is designed to replicate real-world persuasion tactics and psychological pressure, while post-interaction debriefs provide grounded feedback in protection motivation theory and reflective prompts to reinforce learning. In a controlled study with 846 Chinese undergraduates, ImmuniFraug was compared to official text-based materials. Linear Mixed-Effects Modeling (LMEM) reveals that the interactive intervention significantly improved fraud awareness (p = 0.026), successfully providing incremental learning value even when controlling for participants' extensive prior exposure to anti-fraud education, alongside high narrative immersion (M = 56.95/77). Thematic analysis of interviews revealed key effectiveness factors: perceived realism, adaptive deception, enforced time pressure, emotional manipulation awareness, and enhanced self-efficacy. Findings demonstrate that by shifting the focus from passive knowledge acquisition to active metacognitive engagement, LLM-based simulations offer a scalable and ecologically valid new paradigm for anti-fraud training and fostering fraud resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06774v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangzhe Yuan, Jiajun Wang, Huanchen Wang, Qian Wan, Siying Hu</dc:creator>
    </item>
    <item>
      <title>AutoTour: Automatic Photo Tour Guide with Smartphones and LLMs</title>
      <link>https://arxiv.org/abs/2601.06781</link>
      <description>arXiv:2601.06781v1 Announce Type: new 
Abstract: We present AutoTour, a system that enhances user exploration by automatically generating fine-grained landmark annotations and descriptive narratives for photos captured by users. The key idea of AutoTour is to fuse visual features extracted from photos with nearby geospatial features queried from open matching databases. Unlike existing tour applications that rely on pre-defined content or proprietary datasets, AutoTour leverages open and extensible data sources to provide scalable and context-aware photo-based guidance. To achieve this, we design a training-free pipeline that first extracts and filters relevant geospatial features around the user's GPS location. It then detects major landmarks in user photos through VLM-based feature detection and projects them into the horizontal spatial plane. A geometric matching algorithm aligns photo features with corresponding geospatial entities based on their estimated distance and direction. The matched features are subsequently grounded and annotated directly on the original photo, accompanied by large language model-generated textual and audio descriptions to provide an informative, tour-like experience. We demonstrate that AutoTour can deliver rich, interpretable annotations for both iconic and lesser-known landmarks, enabling a new form of interactive, context-aware exploration that bridges visual perception and geospatial understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06781v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huatao Xu, Zihe Liu, Zilin Zeng, Baichuan Li, Mo Li</dc:creator>
    </item>
    <item>
      <title>Generative Modeling of Human-Computer Interfaces with Diffusion Processes and Conditional Control</title>
      <link>https://arxiv.org/abs/2601.06823</link>
      <description>arXiv:2601.06823v1 Announce Type: new 
Abstract: This study investigates human-computer interface generation based on diffusion models to overcome the limitations of traditional template-based design and fixed rule-driven methods. It first analyzes the key challenges of interface generation, including the diversity of interface elements, the complexity of layout logic, and the personalization of user needs. A generative framework centered on the diffusion-reverse diffusion process is then proposed, with conditional control introduced in the reverse diffusion stage to integrate user intent, contextual states, and task constraints, enabling unified modeling of visual presentation and interaction logic. In addition, regularization constraints and optimization objectives are combined to ensure the rationality and stability of the generated interfaces. Experiments are conducted on a public interface dataset with systematic evaluations, including comparative experiments, hyperparameter sensitivity tests, environmental sensitivity tests, and data sensitivity tests. Results show that the proposed method outperforms representative models in mean squared error, structural similarity, peak signal-to-noise ratio, and mean absolute error, while maintaining strong robustness under different parameter settings and environmental conditions. Overall, the diffusion model framework effectively improves the diversity, rationality, and intelligence of interface generation, providing a feasible solution for automated interface generation in complex interaction scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06823v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Liu, Liuqingqing Yang, Runsheng Zhang, Shixiao Wang</dc:creator>
    </item>
    <item>
      <title>Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation</title>
      <link>https://arxiv.org/abs/2601.06877</link>
      <description>arXiv:2601.06877v1 Announce Type: new 
Abstract: Effective persuasive dialogue agents adapt their strategies to individual users, accounting for the evolution of their psychological states and intentions throughout conversations. We present a personality-aware reinforcement learning approach comprising three main modules: (1) a Strategy-Oriented Interaction Framework, which serves as an agenda-based strategy controller that selects strategy-level actions and generate responses via Maximal Marginal Relevance (MMR) retrieval to ensure contextual relevance, diversity, and scalable data generation; (2) Personality-Aware User Representation Learning, which produces an 81-dimensional mixed-type embedding predicted at each turn from recent exchanges and appended to the reinforcement learning state; and (3) a Dueling Double DQN (D3QN) model and Reward Prediction, in which the policy is conditioned on dialogue history and turn-level personality estimates and trained using a composite reward incorporating agreement intent, donation amount, and changeof-mind penalties. We use an agenda-based LLM simulation pipeline to generate diverse interactions, from which personality estimation is inferred from the generated utterances. Experiments on the PersuasionForGood (P4G) dataset augmented with simulated dialogues reveal three main findings: (i) turn-level personality conditioning improves policy adaptability and cumulative persuasion rewards; (ii) LLM-driven simulation enhances generalization to unseen user behaviors; and (iii) incorporating a change-of-mind penalty reduces post-agreement retractions while slightly improving donation outcomes. These results demonstrate that structured interaction, dynamic personality estimation, and behaviorally informed rewards together yield more effective persuasive policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06877v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donghuo Zeng, Roberto Legaspi, Kazushi Ikeda</dc:creator>
    </item>
    <item>
      <title>Santa Clara 3D: Digital Reconstruction and Storytelling of a Francoist Concentration Camp</title>
      <link>https://arxiv.org/abs/2601.06902</link>
      <description>arXiv:2601.06902v1 Announce Type: new 
Abstract: This paper explores the potential of digital reconstruction and interactive storytelling to preserve historically suppressed sites. The main objective of an interdisciplinary team of data scientists from the MEMORISE project and associates of the memory association Asociacion Recuerdo y Dignidad was to preserve the memory of the Francoist Santa Clara concentration camp in Soria, Spain, through the use of digital technology. Combining archival research, 3D modelling, 360-degree photography, and web development, a prototype digital platform was created to visualise the transformation of the site across three historical phases: its origin as a convent, its use as a Francoist concentration camp, and its present-day condition. The platform allows users to navigate through spatial and temporal layers. Clickable media markers encourage exploration and interaction. Drawing on principles of participatory design, narrative visualisation, and open-ended user engagement, the project demonstrates how digital tools can support memory work, public engagement, and historical reflection. Our low-cost concept is especially adaptable to other physical sites that have been erased or forgotten.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06902v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stinne Zacho, Chris Hall, Jakob Kusnick, Stefan J\"anicke</dc:creator>
    </item>
    <item>
      <title>The AI Cognitive Trojan Horse: How Large Language Models May Bypass Human Epistemic Vigilance</title>
      <link>https://arxiv.org/abs/2601.07085</link>
      <description>arXiv:2601.07085v1 Announce Type: new 
Abstract: Large language model (LLM)-based conversational AI systems present a challenge to human cognition that current frameworks for understanding misinformation and persuasion do not adequately address. This paper proposes that a significant epistemic risk from conversational AI may lie not in inaccuracy or intentional deception, but in something more fundamental: these systems may be configured, through optimization processes that make them useful, to present characteristics that bypass the cognitive mechanisms humans evolved to evaluate incoming information. The Cognitive Trojan Horse hypothesis draws on Sperber and colleagues' theory of epistemic vigilance -- the parallel cognitive process monitoring communicated information for reasons to doubt -- and proposes that LLM-based systems present 'honest non-signals': genuine characteristics (fluency, helpfulness, apparent disinterest) that fail to carry the information equivalent human characteristics would carry, because in humans these are costly to produce while in LLMs they are computationally trivial. Four mechanisms of potential bypass are identified: processing fluency decoupled from understanding, trust-competence presentation without corresponding stakes, cognitive offloading that delegates evaluation itself to the AI, and optimization dynamics that systematically produce sycophancy. The framework generates testable predictions, including a counterintuitive speculation that cognitively sophisticated users may be more vulnerable to AI-mediated epistemic influence. This reframes AI safety as partly a problem of calibration -- aligning human evaluative responses with the actual epistemic status of AI-generated content -- rather than solely a problem of preventing deception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07085v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrew D. Maynard</dc:creator>
    </item>
    <item>
      <title>EZBlender: Efficient 3D Editing with Plan-and-ReAct Agent</title>
      <link>https://arxiv.org/abs/2601.07143</link>
      <description>arXiv:2601.07143v1 Announce Type: new 
Abstract: As a cornerstone of the modern digital economy, 3D modeling and rendering demand substantial resources and manual effort when scene editing is performed in the traditional manner. Despite recent progress in VLM-based agents for 3D editing, the fundamental trade-off between editing precision and agent responsiveness remains unresolved. To overcome these limitations, we present EZBlender, a Blender agent with a hybrid framework that combines planning-based task decomposition and reactive local autonomy for efficient human AI collaboration and semantically faithful 3D editing. Specifically, this unexplored Plan-and-ReAct design not only preserves editing quality but also significantly reduces latency and computational cost. To further validate the efficiency and effectiveness of the proposed edge-autonomy architecture, we construct a dedicated multi-tasking benchmark that has not been systematically investigated in prior research. In addition, we provide a comprehensive analysis of language model preference, system responsiveness, and economic efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07143v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Wenhui Zhu, Shao Tang, Zhipeng Wang, Xuanzhao Dong, Xin Li, Xiwen Chen, Ashish Bastola, Xinhao Huang, Yalin Wang, Abolfazl Razi</dc:creator>
    </item>
    <item>
      <title>DiSCo: Making Absence Visible in Intelligent Summarization Interfaces</title>
      <link>https://arxiv.org/abs/2601.07229</link>
      <description>arXiv:2601.07229v1 Announce Type: new 
Abstract: Intelligent interfaces increasingly use large language models to summarize user-generated content, yet these summaries emphasize what is mentioned while overlooking what is missing. This presence bias can mislead users who rely on summaries to make decisions. We present Domain Informed Summarization through Contrast (DiSCo), an expectation-based computational approach that makes absences visible by comparing each entity's content with domain topical expectations captured in reference distributions of aspects typically discussed in comparable accommodations. This comparison identifies aspects that are either unusually emphasized or missing relative to domain norms and integrates them into the generated text. In a user study across three accommodation domains, namely ski, beach, and city center, DiSCo summaries were rated as more detailed and useful for decision making than baseline large language model summaries, although slightly harder to read. The findings show that modeling expectations reduces presence bias and improves both transparency and decision support in intelligent summarization interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07229v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eran Fainman, Hagit Ben Shoshan, Adir Solomon, Osnat Mokryn</dc:creator>
    </item>
    <item>
      <title>Making Absence Visible: The Roles of Reference and Prompting in Recognizing Missing Information</title>
      <link>https://arxiv.org/abs/2601.07234</link>
      <description>arXiv:2601.07234v1 Announce Type: new 
Abstract: Interactive systems that explain data, or support decision making often emphasize what is present while overlooking what is expected but missing. This presence bias limits users' ability to form complete mental models of a dataset or situation. Detecting absence depends on expectations about what should be there, yet interfaces rarely help users form such expectations. We present an experimental study examining how reference framing and prompting influence people's ability to recognize expected but missing categories in datasets. Participants compared distributions across three domains (energy, wealth, and regime) under two reference conditions: Global, presenting a unified population baseline, and Partial, showing several concrete exemplars. Results indicate that absence detection was higher with Partial reference than with Global reference, suggesting that partial, samples-based framing can support expectation formation and absence detection. When participants were prompted to look for what was missing, absence detection rose sharply. We discuss implications for interactive user interfaces and expectation-based visualization design, while considering cognitive trade-offs of reference structures and guided attention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07234v1</guid>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>stat.AP</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hagit Ben Shoshan, Joel Lanir, Pavel Goldstein, Osnat Mokryn</dc:creator>
    </item>
    <item>
      <title>MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences</title>
      <link>https://arxiv.org/abs/2601.07251</link>
      <description>arXiv:2601.07251v1 Announce Type: new 
Abstract: Recent advancements have expanded the role of Large Language Models in board games from playing agents to creative co-designers. However, a critical gap remains: current systems lack the capacity to offer constructive critique grounded in the emergent user experience. Bridging this gap is fundamental for harmonizing Human-AI collaboration, as it empowers designers to refine their creations via external perspectives while steering models away from biased or unpredictable outcomes. Automating critique for board games presents two challenges: inferring the latent dynamics connecting rules to gameplay without an explicit engine, and modeling the subjective heterogeneity of diverse player groups. To address these, we curate a dataset of 1,727 structurally corrected rulebooks and 150K reviews selected via quality scoring and facet-aware sampling. We augment this data with Mechanics-Dynamics-Aesthetics (MDA) reasoning to explicitly bridge the causal gap between written rules and player experience. We further distill player personas and introduce MeepleLM, a specialized model that internalizes persona-specific reasoning patterns to accurately simulate the subjective feedback of diverse player archetypes. Experiments demonstrate that MeepleLM significantly outperforms latest commercial models (e.g., GPT-5.1, Gemini3-Pro) in community alignment and critique quality, achieving a 70% preference rate in user studies assessing utility. MeepleLM serves as a reliable virtual playtester for general interactive systems, marking a pivotal step towards audience-aligned, experience-aware Human-AI collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07251v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zizhen Li, Chuanhao Li, Yibin Wang, Yukang Feng, Jianwen Sun, Jiaxin Ai, Fanrui Zhang, Mingzhu Sun, Yifei Huang, Kaipeng Zhang</dc:creator>
    </item>
    <item>
      <title>ColorBrowserAgent: An Intelligent GUI Agent for Complex Long-Horizon Web Automation</title>
      <link>https://arxiv.org/abs/2601.07262</link>
      <description>arXiv:2601.07262v1 Announce Type: new 
Abstract: The web browser serves as a primary interface for daily human activities, making its automation a critical frontier for Human-Centred AI. While Large Language Models (LLMs) have enabled autonomous agents to interact with web GUIs, their reliability in real-world scenarios is hampered by long-horizon instability and the vast heterogeneity of site designs. In this paper, we introduce ColorBrowserAgent, a framework designed for Collaborative Autonomy in complex web tasks. Our approach integrates two human-centred mechanisms: (1) Progressive Progress Summarization, which mimics human short-term memory to maintain coherence over extended interactions; and (2) Human-in-the-Loop Knowledge Adaptation, which bridges the knowledge gap in diverse environments by soliciting expert intervention only when necessary. This symbiotic design allows the agent to learn from human tips without extensive retraining, effectively combining the scalability of AI with the adaptability of human cognition. Evaluated on the WebArena benchmark using GPT-5, ColorBrowserAgent achieves a state-of-the-art success rate of 71.2\%, demonstrating the efficacy of interactive human assistance in robust web automation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07262v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiamu Zhou, Jihong Wang, Weiming Zhang, Weiwen Liu, Zhuosheng Zhang, Xingyu Lou, Weinan Zhang, Huarong Deng, Jun Wang</dc:creator>
    </item>
    <item>
      <title>Interactive visualizations for adolescents to understand and challenge algorithmic profiling in online platforms</title>
      <link>https://arxiv.org/abs/2601.07381</link>
      <description>arXiv:2601.07381v1 Announce Type: new 
Abstract: Social media platforms regularly track, aggregate, and monetize adolescents' data, yet provide them with little visibility or agency over how algorithms construct their digital identities and make inferences about them. We introduce Algorithmic Mirror, an interactive visualization tool that transforms opaque profiling practices into explorable landscapes of personal data. It uniquely leverages adolescents' real digital footprints across YouTube, TikTok, and Netflix, to provide situated, personalized insights into datafication over time. In our study with 27 participants (ages 12--16), we show how engaging with their own data enabled adolescents to uncover the scale and persistence of data collection, recognize cross-platform profiling, and critically reflect algorithmic categorizations of their interests. These findings highlight how identity is a powerful motivator for adolescents' desire for greater digital agency, underscoring the need for platforms and policymakers to move toward structural reforms that guarantee children better transparency and the agency to influence their online experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07381v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yui Kondo, Kevin Dunnell, Isobel Voysey, Qing Hu, Victoria Paesano, Phi H Nguyen, Qing Xiao, Jun Zhao, Luc Rocher</dc:creator>
    </item>
    <item>
      <title>Recommendation-as-Experience: A framework for context-sensitive adaptation in conversational recommender systems</title>
      <link>https://arxiv.org/abs/2601.07401</link>
      <description>arXiv:2601.07401v1 Announce Type: new 
Abstract: While Conversational Recommender Systems (CRS) have matured technically, they frequently lack principled methods for encoding latent experiential aims as adaptive state variables. Consequently, contemporary architectures often prioritise ranking accuracy at the expense of nuanced, context-sensitive interaction behaviours. This paper addresses this gap through a comprehensive multi-domain study ($N = 168$) that quantifies the joint prioritisation of three critical interaction aims: educative (to inform and justify), explorative (to diversify and inspire), and affective (to align emotionally and socially). Utilising Bayesian hierarchical ordinal regression, we establish domain profiles and perceived item value as systematic modulators of these priorities. Furthermore, we identify stable user-level preferences for autonomy that persist across distinct interactional goals, suggesting that agency is a fundamental requirement of the conversational experience. Drawing on these empirical foundations, we formalise the Recommendation-as-Experience (RAE) adaptation framework. RAE systematically encodes contextual and individual signals into structured state representations, mapping them to experience-aligned dialogue policies realised through retrieval diversification, heuristic logic, or Large Language Model based controllable generation. As an architecture-agnostic blueprint, RAE facilitates the design of context-sensitive CRS that effectively balance experiential quality with predictive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07401v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raj Mahmud, Shlomo Berkovsky, Mukesh Prasad, A. Baki Kocaballi</dc:creator>
    </item>
    <item>
      <title>Backpropagation-Free Test-Time Adaptation for Lightweight EEG-Based Brain-Computer Interfaces</title>
      <link>https://arxiv.org/abs/2601.07556</link>
      <description>arXiv:2601.07556v1 Announce Type: new 
Abstract: Electroencephalogram (EEG)-based brain-computer interfaces (BCIs) face significant deployment challenges due to inter-subject variability, signal non-stationarity, and computational constraints. While test-time adaptation (TTA) mitigates distribution shifts under online data streams without per-use calibration sessions, existing TTA approaches heavily rely on explicitly defined loss objectives that require backpropagation for updating model parameters, which incurs computational overhead, privacy risks, and sensitivity to noisy data streams. This paper proposes Backpropagation-Free Transformations (BFT), a TTA approach for EEG decoding that eliminates such issues. BFT applies multiple sample-wise transformations of knowledge-guided augmentations or approximate Bayesian inference to each test trial, generating multiple prediction scores for a single test sample. A learning-to-rank module enhances the weighting of these predictions, enabling robust aggregation for uncertainty suppression during inference under theoretical justifications. Extensive experiments on five EEG datasets of motor imagery classification and driver drowsiness regression tasks demonstrate the effectiveness, versatility, robustness, and efficiency of BFT. This research enables lightweight plug-and-play BCIs on resource-constrained devices, broadening the real-world deployment of decoding algorithms for EEG-based BCI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07556v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siyang Li, Jiayi Ouyang, Zhenyao Cui, Ziwei Wang, Tianwang Jia, Feng Wan, Dongrui Wu</dc:creator>
    </item>
    <item>
      <title>GPU accelerated surface-based gaze mapping for XR experiences</title>
      <link>https://arxiv.org/abs/2601.07571</link>
      <description>arXiv:2601.07571v1 Announce Type: new 
Abstract: Extended reality is a fast-growing domain for which there is an increasing need to analyze and understand user behavior. In particular, understanding human visual attention during immersive experiences is crucial for many applications. The visualization and analysis of visual attention are commonly done by building fixation density maps from eye-tracking data. Such visual attention mapping is well mastered for 3 degrees of freedom (3DoF) experiences (\textit{i.e.}, involving 360 images or videos) but much less so for 6DoFs data, when the user can move freely in the 3D space. In that case, the visual attention information has to be mapped onto the 3D objects themselves. Some solutions exist for constructing such surface-based 6DoFs attention maps, however, they own several drawbacks: processing time, strong dependence on mesh resolution and/or texture mapping, and/or unpractical data representation for further processing. In this context, we propose a novel GPU-based algorithm that resolves the issues above while being generated in interactive time and rendered in real-time. Experiment on a challenging scene demonstrates the accuracy and robustness of our approach. To stimulate research in this area, the source code is publicly released and integrated into PLUME for ease of use in XR experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07571v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Charles Javerliat, Guillaume Lavou\'e</dc:creator>
    </item>
    <item>
      <title>A Multimodal Dataset of Student Oral Presentations with Sensors and Evaluation Data</title>
      <link>https://arxiv.org/abs/2601.07576</link>
      <description>arXiv:2601.07576v1 Announce Type: new 
Abstract: Oral presentation skills are a critical component of higher education, yet comprehensive datasets capturing real-world student performance across multiple modalities remain scarce. To address this gap, we present SOPHIAS (Student Oral Presentation monitoring for Holistic Insights &amp; Analytics using Sensors), a 12-hour multimodal dataset containing recordings of 50 oral presentations (10-15-minute presentation followed by 5-15-minute Q&amp;A) delivered by 65 undergraduate and master's students at the Universidad Autonoma de Madrid. SOPHIAS integrates eight synchronized sensor streams from high-definition webcams, ambient and webcam audio, eye-tracking glasses, smartwatch physiological sensors, and clicker, keyboard, and mouse interactions. In addition, the dataset includes slides and rubric-based evaluations from teachers, peers, and self-assessments, along with timestamped contextual annotations. The dataset captures presentations conducted in real classroom settings, preserving authentic student behaviors, interactions, and physiological responses. SOPHIAS enables the exploration of relationships between multimodal behavioral and physiological signals and presentation performance, supports the study of peer assessment, and provides a benchmark for developing automated feedback and Multimodal Learning Analytics tools. The dataset is publicly available for research through GitHub and Science Data Bank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07576v1</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alvaro Becerra, Ruth Cobos, Roberto Daza</dc:creator>
    </item>
    <item>
      <title>Passing the Baton: Shift Handovers within Cybersecurity Incident Response Teams</title>
      <link>https://arxiv.org/abs/2601.07788</link>
      <description>arXiv:2601.07788v1 Announce Type: new 
Abstract: Effective shift transitions are crucial for cybersecurity incident response teams, yet there is limited guidance on managing these handovers. This exploratory study aimed to develop guidelines for such transitions through the analysis of existing literature and consultation with practitioners. Two draft guidelines (A and B) were created based on existing literature and online resources. Six participants from the UK and international incident response teams, with experience in shift handovers, were interviewed about handover structure, challenges, training practices, and their views on the draft guidelines. The collected data indicate the importance of signposting, evolving handover procedures, individual differences in handover style and detail, and streamlining the handover procedure. Participants agreed the drafts included all relevant details but suggested adding a post-incident review section and a service section for outages or technical difficulties. This study establishes a foundation for enhancing transition practices in cybersecurity incident response teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07788v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liberty Kent, Nilufer Tuptuk, Ingolf Becker</dc:creator>
    </item>
    <item>
      <title>Assessing novice programmers' perception of ChatGPT:performance, risk, decision-making, and intentions</title>
      <link>https://arxiv.org/abs/2601.06044</link>
      <description>arXiv:2601.06044v1 Announce Type: cross 
Abstract: This study explores the novice programmers' intention to use chat generative pretrained transformer (ChatGPT) for programming tasks with emphasis on performance expectancy (PE), risk-reward appraisal (RRA), and decision-making (DM). Utilizing partial least squares structural equation modeling (PLS-SEM) and a sample of 413 novice programmers, the analysis demonstrates that higher PE of ChatGPT is positively correlated with improved DM in programming tasks. Novice programmers view ChatGPT as a tool that enhances their learning and skill development. Additionally, novice programmers that have a favorable RRA of ChatGPT tend to make more confident and effective decisions, acknowledging potential risks but recognizing that benefits such as quick problem-solving and learning new techniques outweigh these risks. Moreover, a positive perception of ChatGPT's role in DM significantly increases the inclination to use the tool for programming tasks. These results highlight the critical roles of perceived capabilities, risk assessment, and positive DM experiences in promoting the adoption of artificial intelligence (AI) tools in programming education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06044v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.11591/edulearn.v19i4.22328</arxiv:DOI>
      <arxiv:journal_reference>Journal of Education and Learning (EduLearn) 19 (4) (2025) 2291-2301</arxiv:journal_reference>
      <dc:creator>John Paul P. Miranda, Jaymark A. Yambao</dc:creator>
    </item>
    <item>
      <title>Sports Business Administration and New Age Technology: Role of AI</title>
      <link>https://arxiv.org/abs/2601.06053</link>
      <description>arXiv:2601.06053v1 Announce Type: cross 
Abstract: This chapter explores the complexities of sports governance, taxation, dispute resolution, and the impact of digital transformation within the sports sector. This study identifies a critical research gap regarding the integration of innovative technologies to enhance governance and talent identification in sports law. The objective is to evaluate how data-driven approaches and AI can optimize recruitment processes; also ensuring compliance with existing regulations. A comprehensive analysis of current governance structures and taxation policies,(ie Income Tax Act and GST Act), reveals preliminary results indicating that reform is necessary to support sustainable growth in the sports economy. Key findings demonstrate that AI enhances player evaluation by minimizing biases and expanding access to diverse talent pools. While the Court of Arbitration for Sport provides an efficient mechanism for dispute resolution. The implications emphasize the need for regulatory reforms that align taxation policies with international best practices, promoting transparency and accountability in sports organizations. This research contributes valuable insights into the evolving dynamics of sports management, aiming to foster innovation and integrity in the industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06053v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Sports Law in India, Volume 1, pp. 122-142 (2024)</arxiv:journal_reference>
      <dc:creator>Sahibpreet Singh, Pawan Kumar</dc:creator>
    </item>
    <item>
      <title>From Values to Frameworks: A Qualitative Study of Ethical Reasoning in Agentic AI Practitioners</title>
      <link>https://arxiv.org/abs/2601.06062</link>
      <description>arXiv:2601.06062v1 Announce Type: cross 
Abstract: Agentic artificial intelligence systems are autonomous technologies capable of pursuing complex goals with minimal human oversight and are rapidly emerging as the next frontier in AI. While these systems promise major gains in productivity, they also raise new ethical challenges. Prior research has examined how different populations prioritize Responsible AI values, yet little is known about how practitioners actually reason through the trade-offs inherent in designing these autonomous systems. This paper investigates the ethical reasoning of AI practitioners through qualitative interviews centered on structured dilemmas in agentic AI deployment. We find that the responses of practitioners do not merely reflect value preferences but rather align with three distinct reasoning frameworks. First is a Customer-Centric framework where choices are justified by business interests, legality, and user autonomy. Second is a Design-Centric framework emphasizing technical safeguards and system constraints. Third is an Ethics-Centric framework prioritizing social good and moral responsibility beyond compliance. We argue that these frameworks offer distinct and necessary insights for navigating ethical trade-offs. Consequently, providers of agentic AI must look beyond general principles and actively manage how these diverse reasoning frameworks are represented in their decision-making processes to ensure robust ethical outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06062v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theodore Roberts, Bahram Zarrin</dc:creator>
    </item>
    <item>
      <title>L2CU: Learning to Complement Unseen Users</title>
      <link>https://arxiv.org/abs/2601.06119</link>
      <description>arXiv:2601.06119v1 Announce Type: cross 
Abstract: Recent research highlights the potential of machine learning models to learn to complement (L2C) human strengths; however, generalizing this capability to unseen users remains a significant challenge. Existing L2C methods oversimplify interaction between human and AI by relying on a single, global user model that neglects individual user variability, leading to suboptimal cooperative performance. Addressing this, we introduce L2CU, a novel L2C framework for human-AI cooperative classification with unseen users. Given sparse and noisy user annotations, L2CU identifies representative annotator profiles capturing distinct labeling patterns. By matching unseen users to these profiles, L2CU leverages profile-specific models to complement the user and achieve superior joint accuracy. We evaluate L2CU on datasets (CIFAR-10N, CIFAR-10H, Fashion-MNIST-H, Chaoyang and AgNews), demonstrating its effectiveness as a model-agnostic solution for improving human-AI cooperative classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06119v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2025.3648122</arxiv:DOI>
      <arxiv:journal_reference>in IEEE Access, vol. 13, pp. 217632-217643, 2025</arxiv:journal_reference>
      <dc:creator>Dileepa Pitawela, Gustavo Carneiro, Hsiang-Ting Chen</dc:creator>
    </item>
    <item>
      <title>Low-Back Pain Physical Rehabilitation by Movement Analysis in Clinical Trial</title>
      <link>https://arxiv.org/abs/2601.06138</link>
      <description>arXiv:2601.06138v1 Announce Type: cross 
Abstract: To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises and benchmark on state of the art human movement analysis algorithms. This dataset is valuable because it includes rehabilitation motions in a clinical setting with patients in their rehabilitation program. This paper introduces the Keraal dataset, a clinically collected dataset to enable intelligent tutoring systems (ITS) for rehabilitation. It addresses four challenges in exercise monitoring: motion assessment, error recognition, spatial localization, temporal localization</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06138v1</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sao Mai Nguyen (U2IS, ENSTA, IP Paris)</dc:creator>
    </item>
    <item>
      <title>An Intelligent AI glasses System with Multi-Agent Architecture for Real-Time Voice Processing and Task Execution</title>
      <link>https://arxiv.org/abs/2601.06235</link>
      <description>arXiv:2601.06235v1 Announce Type: cross 
Abstract: This paper presents an AI glasses system that integrates real-time voice processing, artificial intelligence(AI) agents, and cross-network streaming capabilities. The system employs dual-agent architecture where Agent 01 handles Automatic Speech Recognition (ASR) and Agent 02 manages AI processing through local Large Language Models (LLMs), Model Context Protocol (MCP) tools, and Retrieval-Augmented Generation (RAG). The system supports real-time RTSP streaming for voice and video data transmission, eye tracking data collection, and remote task execution through RabbitMQ messaging. Implementation demonstrates successful voice command processing with multilingual support and cross-platform task execution capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06235v1</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheng-Kai Chen, Jyh-Horng Wu, Ching-Yao Lin, Yen-Ting Lin</dc:creator>
    </item>
    <item>
      <title>Model Reconciliation through Explainability and Collaborative Recovery in Assistive Robotics</title>
      <link>https://arxiv.org/abs/2601.06552</link>
      <description>arXiv:2601.06552v1 Announce Type: cross 
Abstract: Whenever humans and robots work together, it is essential that unexpected robot behavior can be explained to the user. Especially in applications such as shared control the user and the robot must share the same model of the objects in the world, and the actions that can be performed on these objects.
  In this paper, we achieve this with a so-called model reconciliation framework. We leverage a Large Language Model to predict and explain the difference between the robot's and the human's mental models, without the need of a formal mental model of the user. Furthermore, our framework aims to solve the model divergence after the explanation by allowing the human to correct the robot. We provide an implementation in an assistive robotics domain, where we conduct a set of experiments with a real wheelchair-based mobile manipulator and its digital twin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06552v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Britt Besch, Tai Mai, Jeremias Thun, Markus Huff, J\"orn Vogel, Freek Stulp, Samuel Bustamante</dc:creator>
    </item>
    <item>
      <title>IDRBench: Interactive Deep Research Benchmark</title>
      <link>https://arxiv.org/abs/2601.06676</link>
      <description>arXiv:2601.06676v1 Announce Type: cross 
Abstract: Deep research agents powered by Large Language Models (LLMs) can perform multi-step reasoning, web exploration, and long-form report generation. However, most existing systems operate in an autonomous manner, assuming fully specified user intent and evaluating only final outputs. In practice, research goals are often underspecified and evolve during exploration, making sustained interaction essential for robust alignment. Despite its importance, interaction remains largely invisible to existing deep research benchmarks, which neither model dynamic user feedback nor quantify its costs. We introduce IDRBench, the first benchmark for systematically evaluating interactive deep research. IDRBench combines a modular multi-agent research framework with on-demand interaction, a scalable reference-grounded user simulator, and an interaction-aware evaluation suite that jointly measures interaction benefits (quality and alignment) and costs (turns and tokens). Experiments across seven state-of-the-art LLMs show that interaction consistently improves research quality and robustness, often outweighing differences in model capacity, while revealing substantial trade-offs in interaction efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06676v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingchaojie Feng, Qiang Huang, Xiaoya Xie, Zhaorui Yang, Jun Yu, Wei Chen, Anthony K. H. Tung</dc:creator>
    </item>
    <item>
      <title>DarwinTOD: LLM Driven Lifelong Self Evolution for Task Oriented Dialog Systems</title>
      <link>https://arxiv.org/abs/2601.07248</link>
      <description>arXiv:2601.07248v1 Announce Type: cross 
Abstract: Traditional task-oriented dialog systems are unable to evolve from ongoing interactions or adapt to new domains after deployment, that is a critical limitation in real-world dynamic environments. Continual learning approaches depend on episodic retraining with human curated data, failing to achieve autonomy lifelong improvement. While evolutionary computation and LLM driven self improvement offer promising mechanisms for dialog optimization, they lack a unified framework for holistic, iterative strategy refinement. To bridge this gap, we propose DarwinTOD, a lifelong self evolving dialog framework that systematically integrates these two paradigms, enabling continuous strategy optimization from a zero-shot base without task specific fine-tuning. DarwinTOD maintains an Evolvable Strategy Bank and operates through a dual-loop process: online multi-agent dialog execution with peer critique, and offline structured evolutionary operations that refine the strategy bank using accumulated feedback. This closed-loop design enables autonomous continuous improvement without human intervention. Extensive experiments show that DarwinTOD surpasses previous state-of-the-art methods and exhibits continuous performance gains throughout evolution. Our work provides a novel framework for building dialog systems with lifelong self evolution capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07248v1</guid>
      <category>cs.MA</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyu Zhang, Yujie Liu, Xinru Wang, Cheng Zhang, Yanmin Zhu, Bin Li</dc:creator>
    </item>
    <item>
      <title>OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent</title>
      <link>https://arxiv.org/abs/2601.07779</link>
      <description>arXiv:2601.07779v1 Announce Type: cross 
Abstract: While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents (CUAs), current frameworks struggle with robustness in long-horizon workflows and generalization in novel domains. These limitations stem from a lack of granular control over historical visual context curation and the absence of visual-aware tutorial retrieval. To bridge these gaps, we introduce OS-Symphony, a holistic framework that comprises an Orchestrator coordinating two key innovations for robust automation: (1) a Reflection-Memory Agent that utilizes milestone-driven long-term memory to enable trajectory-level self-correction, effectively mitigating visual context loss in long-horizon tasks; (2) Versatile Tool Agents featuring a Multimodal Searcher that adopts a SeeAct paradigm to navigate a browser-based sandbox to synthesize live, visually aligned tutorials, thereby resolving fidelity issues in unseen scenarios. Experimental results demonstrate that OS-Symphony delivers substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07779v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Yang, Kaiming Jin, Zhenyu Wu, Zhaoyang Liu, Qiushi Sun, Zehao Li, JingJing Xie, Zhoumianze Liu, Fangzhi Xu, Kanzhi Cheng, Qingyun Li, Yian Wang, Yu Qiao, Zun Wang, Zichen Ding</dc:creator>
    </item>
    <item>
      <title>Learning Through Dialogue: Unpacking the Dynamics of Human-LLM Conversations on Political Issues</title>
      <link>https://arxiv.org/abs/2601.07796</link>
      <description>arXiv:2601.07796v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly used as conversational partners for learning, yet the interactional dynamics supporting users' learning and engagement are understudied. We analyze the linguistic and interactional features from both LLM and participant chats across 397 human-LLM conversations about socio-political issues to identify the mechanisms and conditions under which LLM explanations shape changes in political knowledge and confidence. Mediation analyses reveal that LLM explanatory richness partially supports confidence by fostering users' reflective insight, whereas its effect on knowledge gain operates entirely through users' cognitive engagement. Moderation analyses show that these effects are highly conditional and vary by political efficacy. Confidence gains depend on how high-efficacy users experience and resolve uncertainty. Knowledge gains depend on high-efficacy users' ability to leverage extended interaction, with longer conversations benefiting primarily reflective users. In summary, we find that learning from LLMs is an interactional achievement, not a uniform outcome of better explanations. The findings underscore the importance of aligning LLM explanatory behavior with users' engagement states to support effective learning in designing Human-AI interactive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07796v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaz Furniturewala, Gerard Christopher Yeo, Kokil Jaidka</dc:creator>
    </item>
    <item>
      <title>Auxilio and Beyond: Comparative Evaluation, Usability, and Design Guidelines for Head Movement-based Assistive Mouse Controllers</title>
      <link>https://arxiv.org/abs/2210.04483</link>
      <description>arXiv:2210.04483v3 Announce Type: replace 
Abstract: Upper limb disability due to neurological disorders or other factors restricts computer interaction for affected individuals using a generic optical mouse. This work reports the findings of a comparative evaluation of Auxilio, a sensor-based wireless head-mounted Assistive Mouse Controller (AMC), that facilitates computer interaction for such individuals. Combining commercially available, low-cost motion and infrared sensors, Auxilio utilizes head movements and cheek muscle twitches for mouse control. Its performance in pointing tasks with subjects without motor impairments has been juxtaposed against a commercially available and patented vision-based head-tracking AMC developed for similar stakeholders. Furthermore, our study evaluates the usability of Auxilio using the System Usability Scale, supplemented by a qualitative analysis of participant interview transcripts to identify the strengths and weaknesses of both AMCs. Experimental results demonstrate the feasibility and effectiveness of Auxilio, and we summarize our key findings into design guidelines for the development of similar future AMCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.04483v3</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Ridwan Kabir (iStudio Lab, School of Computing, Queen's University, Kingston, Ontario, Canada), Mohammad Ishrak Abedin (Network and Data Analysis Group), Rizvi Ahmed (Network and Data Analysis Group), Saad Bin Ashraf (Network and Data Analysis Group), Hasan Mahmud (Systems and Software Lab), Md. Kamrul Hasan (Systems and Software Lab)</dc:creator>
    </item>
    <item>
      <title>Exploring Context-aware and LLM-driven Locomotion for Immersive Virtual Reality</title>
      <link>https://arxiv.org/abs/2504.17331</link>
      <description>arXiv:2504.17331v2 Announce Type: replace 
Abstract: Locomotion plays a crucial role in shaping the user experience within virtual reality environments. In particular, hands-free locomotion offers a valuable alternative by supporting accessibility and freeing users from reliance on handheld controllers. To this end, traditional speech-based methods often depend on rigid command sets, limiting the naturalness and flexibility of interaction. In this study, we propose a novel locomotion technique powered by large language models (LLMs), which allows users to navigate virtual environments using natural language with contextual awareness. We evaluate three locomotion methods: controller-based teleportation, voice-based steering, and our language model-driven approach. Our evaluation combines eye-tracking data analysis, including exploratory explainable machine learning analysis with SHAP, and standardized questionnaires (SUS, IPQ, CSQ-VR, NASA-TLX) to examine user experience through both objective gaze-based measures and subjective self-reports of usability, presence, cybersickness, and cognitive load. Our findings show no statistically significant differences in usability, presence, or cybersickness between LLM-driven locomotion and established methods such as teleportation, suggesting its potential as a viable, natural language-based, hands-free alternative. In addition, eye-tracking analysis revealed patterns suggesting tendency toward increased user attention and engagement in the LLM-driven condition. Complementary to these findings, exploratory SHAP analysis revealed that fixation, saccade, and pupil-related features vary across techniques, indicating distinct patterns of visual attention and cognitive processing. Overall, we state that our method can facilitate hands-free locomotion in virtual spaces, especially in supporting accessibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17331v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"uleyman \"Ozdel, Kadir Burak Buldu, Enkelejda Kasneci, Efe Bozkir</dc:creator>
    </item>
    <item>
      <title>Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias</title>
      <link>https://arxiv.org/abs/2507.11210</link>
      <description>arXiv:2507.11210v3 Announce Type: replace 
Abstract: Well-being in family settings involves subtle psychological dynamics that conventional metrics often overlook. In particular, unconscious parental expectations, termed ideal parent bias, can suppress children's emotional expression and autonomy. This suppression, referred to as suppressed emotion, often stems from well-meaning but value-driven communication, which is difficult to detect or address from outside the family. Focusing on these latent dynamics, this study explores Large Language Model (LLM)-based support for psychologically safe family communication. We constructed a Japanese parent-child dialogue corpus of 30 scenarios, each annotated with metadata on ideal parent bias and suppressed emotion. Based on this corpus, we developed a Role-Playing LLM-based multi-agent dialogue support framework that analyzes dialogue and generates feedback. Specialized agents detect suppressed emotion, describe implicit ideal parent bias in parental speech, and infer contextual attributes such as the child's age and background. A meta-agent compiles these outputs into a structured report, which is then passed to five selected expert agents. These agents collaboratively generate empathetic and actionable feedback through a structured four-step discussion process. Experiments show that the system can detect categories of suppressed emotion with moderate accuracy and produce feedback rated highly in empathy and practicality. Moreover, simulated follow-up dialogues incorporating this feedback exhibited signs of improved emotional expression and mutual understanding, suggesting the framework's potential in supporting positive transformation in family interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11210v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rushia Harada, Yuken Kimura, Keito Inoshita</dc:creator>
    </item>
    <item>
      <title>Person Parametric Physics-informed Representation for mmWave-based Human Pose Estimation</title>
      <link>https://arxiv.org/abs/2512.23054</link>
      <description>arXiv:2512.23054v4 Announce Type: replace 
Abstract: Millimeter-wave (mmWave) radar enables privacy-preserving, illumination-invariant Human Pose Estimation (HPE). However, current mmWave-based HPE systems face a signal-noise dilemma: Heatmaps retain human reflections but embed environmental clutter, while Point Clouds (PC) suppress noise through aggressive thresholding but discard informative human reflections, limiting robustness across environments and radar configurations. To address this intrinsic bottleneck, we introduce Person Parametric Physics-informed Representation (PPPR), a physics-informed parametric intermediate representation that replaces purely signal-level encodings with human-centric parameterization. PPPR models each human joint as a Gaussian primitive encoding both kinematic properties, which include position, velocity, orientation, and electromagnetic properties, which include scattering intensity and Doppler signature. These parameters enable optimization through a dual-constraint process: kinematic objectives enforce biomechanical consistency to suppress spatial artifacts, while electromagnetic objectives ensure adherence to mmWave propagation physics, decoupling input representations from non-human noise. Experiments across three mmWave-based HPE datasets with four HPE models demonstrate that replacing conventional inputs with PPPR consistently yields substantial accuracy gains. Furthermore, cross-scenes and cross-datasets experiments confirm PPPR's noise decoupling capability: models trained with PPPR maintain stable performance across diverse furniture arrangements and different radar chipsets, demonstrating its promising generalization capability in the challenging cross-dataset settings. Code will be released upon publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23054v4</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuntian Zheng, Jiaqi Li, Guangming Wang, Minzhe Ni, Arnad Palit, Giovanni Montana, Yu Guan</dc:creator>
    </item>
    <item>
      <title>How to Analyse Interviews: A Documentary Method of Interpretation</title>
      <link>https://arxiv.org/abs/2601.05871</link>
      <description>arXiv:2601.05871v2 Announce Type: replace 
Abstract: Interviews are commonplace in HCI. This paper presents a novel documentary method of interpretation that supports analysis of the topics contained within a collection of transcripts, topics that are endogenous to it and which elaborate participants collective reasoning about issues of relevance to research. We contrast endogenous topic analysis with established qualitative approaches, including content analysis, grounded theory, interpretative phenomenological analysis, and thematic analysis, to draw out the distinctive character of the documentary method of interpretation. Unlike established methods, the DMI does not require that the analyst be proficient in qualitative analysis, or have sound knowledge of underlying theories and methods. The DMI is a members method, not a social science method, that relies on mastery of natural language; a competence most people possess.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05871v2</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andy Crabtree</dc:creator>
    </item>
    <item>
      <title>A Framework for Optimizing Human-Machine Interaction in Classification Systems</title>
      <link>https://arxiv.org/abs/2601.05974</link>
      <description>arXiv:2601.05974v2 Announce Type: replace 
Abstract: Automated decision systems increasingly rely on human oversight to ensure accuracy in uncertain cases. This paper presents a practical framework for optimizing such human-in-the-loop classification systems using a double-threshold policy. Conventional classifiers usually produce a confidence score and apply a single cutoff, but our approach uses two thresholds (a lower and an upper) to automatically accept or reject high-confidence cases while routing ambiguous instances to human reviewers. We formulate this problem as an optimization task that balances system accuracy against the cost of human review. Through analytical derivations and Monte Carlo simulations, we show how different confidence score distributions impact the efficiency of human intervention and reveal regions of diminishing returns, where additional review yields minimal benefit. The framework provides a general, reproducible method for improving reliability in any decision pipeline requiring selective human validation, including applications in entity resolution, fraud detection, medical triage, and content moderation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05974v2</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Goran Muric, Steven Minton</dc:creator>
    </item>
    <item>
      <title>Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization</title>
      <link>https://arxiv.org/abs/2502.11140</link>
      <description>arXiv:2502.11140v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have become a cornerstone for automated visualization code generation, enabling users to create charts through natural language instructions. Despite improvements from techniques like few-shot prompting and query expansion, existing methods often struggle when requests are underspecified in actionable details (e.g., data preprocessing assumptions, solver or library choices, etc.), frequently necessitating manual intervention. To overcome these limitations, we propose VisPath: a Multi-Path Reasoning and Feedback-Driven Optimization Framework for Visualization Code Generation. VisPath handles underspecified queries through structured, multi-stage processing. It begins by using Chain-of-Thought (CoT) prompting to reformulate the initial user input, generating multiple extended queries in parallel to surface alternative plausible concretizations of the request. These queries then generate candidate visualization scripts, which are executed to produce diverse images. By assessing the visual quality and correctness of each output, VisPath generates targeted feedback that is aggregated to synthesize an optimal final result. Extensive experiments on MatPlotBench and Qwen-Agent Code Interpreter Benchmark show that VisPath outperforms state-of-the-art methods, providing a more reliable framework for AI-driven visualization generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11140v3</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wonduk Seo, Daye Kang, Hyunjin An, Taehan Kim, Soohyuk Cho, Seungyong Lee, Minhyeong Yu, Jian Park, Yi Bu, Seunghyun Lee</dc:creator>
    </item>
    <item>
      <title>Contextual Embedding-based Clustering to Identify Topics for Healthcare Service Improvement</title>
      <link>https://arxiv.org/abs/2504.14068</link>
      <description>arXiv:2504.14068v2 Announce Type: replace-cross 
Abstract: Understanding patient feedback is crucial for improving healthcare services, yet analyzing unlabeled short-text feedback presents significant challenges due to limited data and domain-specific nuances. Traditional supervised learning approaches require extensive labeled datasets, making unsupervised methods more viable for uncovering meaningful insights from patient feedback. This study explores unsupervised methods to extract meaningful topics from 439 survey responses collected from a healthcare system in Wisconsin, USA. A keyword-based filtering approach was applied to isolate complaint-related feedback using a domain-specific lexicon. To delve deeper and analyze dominant topics in feedback, we explored traditional topic modeling methods, including Latent Dirichlet Allocation (LDA) and Gibbs Sampling Dirichlet Multinomial Mixture (GSDMM), alongside BERTopic, an advanced neural embedding-based clustering approach. To improve coherence and interpretability where data are scarce and consist of short-texts, we propose kBERT, an integration of BERT embeddings with k-means clustering. Model performance was assessed using coherence scores (Cv ) for topic interpretability and average Inverted Rank-Biased Overlap (IRBOavg) for topic diversity. Results indicate that kBERT achieves the highest coherence (Cv = 0.53) and distinct topic separation (IRBOavg = 1.00), outperforming all other models in short-text healthcare feedback analysis. Our findings emphasize the importance of embedding-based techniques for topic identification and highlight the need for context-aware models in healthcare analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14068v2</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/COMPSAC65507.2025.00106</arxiv:DOI>
      <dc:creator>K M Sajjadul Islam, Ravi Teja Karri, Srujan Vegesna, Jiawei Wu, Praveen Madiraju</dc:creator>
    </item>
    <item>
      <title>The CASE Framework -- A New Architecture for Participatory Research and Digital Health Surveillance</title>
      <link>https://arxiv.org/abs/2505.23516</link>
      <description>arXiv:2505.23516v3 Announce Type: replace-cross 
Abstract: We present CASE, an open-source framework for adaptive participatory research and disease surveillance. Unlike traditional survey platforms with static branching logic, CASE uses an event-driven architecture that adjusts survey workflows in real time based on participant responses, external data, temporal conditions, and evolving participant state. This design supports everything from simple one-time questionnaires to complex longitudinal studies with sophisticated conditional logic.
  Built on over a decade of practical experience, CASE underwent major architectural changes in 2024. We replaced a complex microservice design with a streamlined monolithic architecture, significantly improving maintainability and deployment accessibility, particularly for institutions with limited technical resources.
  CASE has been successfully deployed across diverse domains, powering national disease surveillance platforms, supporting post-COVID cohort studies, and enabling real-time sentiment analysis during political events. These applications, involving tens of thousands of participants, demonstrate the framework's scalability, versatility, and practical value.
  This paper describes the foundations of CASE, documents its architectural evolution, and shares lessons learned from real-world deployments across diverse research domains and regulatory environments. We position CASE as a mature research infrastructure that balances sophisticated functionality with practical deployment needs for sustainable and institutionally controlled data collection systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23516v3</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Hirsch, Peter Hevesi, Paul Lukowicz</dc:creator>
    </item>
    <item>
      <title>Digital Wargames to Enhance Military Medical Evacuation Decision-Making</title>
      <link>https://arxiv.org/abs/2507.06373</link>
      <description>arXiv:2507.06373v2 Announce Type: replace-cross 
Abstract: Medical evacuation is one of the United States Army's most storied and critical mission sets, responsible for efficiently and expediently evacuating the battlefield ill and injured. Medical evacuation planning involves designing a robust network of medical platforms and facilities capable of moving and treating large numbers of casualties. Until now, there has not been a medium to simulate these networks in a classroom setting and evaluate both offline planning and online decision-making performance. This work describes the Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer simulation developed in Unity that replicates battlefield constraints and uncertainties. MEWI accurately models patient interactions at casualty collection points, ambulance exchange points, medical treatment facilities, and evacuation platforms. Two operational scenarios are introduced: an amphibious island assault in the Pacific and a Eurasian conflict across a sprawling road and river network. These scenarios pit students against the clock to save as many casualties as possible while adhering to doctrinal lessons learned during didactic training. We visualize performance data collected from two iterations of the MEWI Pacific scenario executed in the United States Army's Medical Evacuation Doctrine Course. We consider post-wargame Likert survey data from student participants and external observer notes to identify key planning decision points, document medical evacuation lessons learned, and quantify general utility. Results indicate that MEWI participation substantially improves uptake of medical evacuation lessons learned and co-operative decision-making. MEWI is a substantial step forward in the field of high-fidelity training tools for medical education, and our study findings offer critical insights into improving medical evacuation education and operations across the joint force.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06373v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy Fischer, Mahdi Al-Husseini, Ram Krishnamoorthy, Vishal Kumar, Mykel J. Kochenderfer</dc:creator>
    </item>
    <item>
      <title>From Wearables to Warnings: Predicting Pain Spikes in Patients with Opioid Use Disorder</title>
      <link>https://arxiv.org/abs/2511.19577</link>
      <description>arXiv:2511.19577v2 Announce Type: replace-cross 
Abstract: Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (&gt;0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19577v2</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhay Goyal, Navin Kumar, Kimberly DiMeola, Rafael Trujillo, Soorya Ram Shimgekar, Christian Poellabauer, Pi Zonooz, Ermonda Gjoni-Markaj, Declan Barry, Lynn Madden</dc:creator>
    </item>
    <item>
      <title>From Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection</title>
      <link>https://arxiv.org/abs/2512.20951</link>
      <description>arXiv:2512.20951v2 Announce Type: replace-cross 
Abstract: As artificial agents increasingly integrate into professional environments, fundamental questions have emerged about how societal biases influence human-robot selection decisions. We conducted two comprehensive experiments (N = 1,038) examining how occupational contexts and stereotype activation shape robotic agent choices across construction, healthcare, educational, and athletic domains. Participants made selections from artificial agents that varied systematically in skin tone and anthropomorphic characteristics. Our study revealed distinct context-dependent patterns. Healthcare and educational scenarios demonstrated strong favoritism toward lighter-skinned artificial agents, while construction and athletic contexts showed greater acceptance of darker-toned alternatives. Participant race was associated with systematic differences in selection patterns across professional domains. The second experiment demonstrated that exposure to human professionals from specific racial backgrounds systematically shifted later robotic agent preferences in stereotype-consistent directions. These findings show that occupational biases and color-based discrimination transfer directly from human-human to human-robot evaluation contexts. The results highlight mechanisms through which robotic deployment may unintentionally perpetuate existing social inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20951v2</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3757279.3788658</arxiv:DOI>
      <dc:creator>Jiangen He, Wanqi Zhang, Jessica Barfield</dc:creator>
    </item>
    <item>
      <title>Pearmut: Human Evaluation of Translation Made Trivial</title>
      <link>https://arxiv.org/abs/2601.02933</link>
      <description>arXiv:2601.02933v2 Announce Type: replace-cross 
Abstract: Human evaluation is the gold standard for multilingual NLP, but is often skipped in practice and substituted with automatic metrics, because it is notoriously complex and slow to set up with existing tools with substantial engineering and operational overhead. We introduce Pearmut, a lightweight yet feature-rich platform that makes end-to-end human evaluation as easy to run as automatic evaluation. Pearmut removes common entry barriers and provides support for evaluating multilingual tasks, with a particular focus on machine translation. The platform implements standard evaluation protocols, including DA, ESA, or MQM, but is also extensible to allow prototyping new protocols. It features document-level context, absolute and contrastive evaluation, attention checks, ESAAI pre-annotations and both static and active learning-based assignment strategies. Pearmut enables reliable human evaluation to become a practical, routine component of model development and diagnosis rather than an occasional effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02933v2</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vil\'em Zouhar, Tom Kocmi</dc:creator>
    </item>
  </channel>
</rss>
