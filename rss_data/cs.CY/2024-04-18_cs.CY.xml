<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Apr 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Designing an Intelligent Parcel Management System using IoT &amp; Machine Learning</title>
      <link>https://arxiv.org/abs/2404.11661</link>
      <description>arXiv:2404.11661v1 Announce Type: new 
Abstract: Parcels delivery is a critical activity in railways. More importantly, each parcel must be thoroughly checked and sorted according to its destination address. We require an efficient and robust IoT system capable of doing all of these tasks with great precision and minimal human interaction. This paper discusses, We created a fully-fledged solution using IoT and machine learning to assist trains in performing this operation efficiently. In this study, we covered the product, which consists mostly of two phases. Scanning is the first step, followed by sorting. During the scanning process, the parcel will be passed through three scanners that will look for explosives, drugs, and any dangerous materials in the parcel and will trash it if any of the tests fail. When the scanning step is over, the parcel moves on to the sorting phase, where we use QR codes to retrieve the details of the parcels and sort them properly. The simulation of the system is done using the blender software. Our research shows that our procedure significantly improves accuracy as well as the assessment of cutting-edge technology and existing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11661v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/GlobConET53749.2022.9872449</arxiv:DOI>
      <arxiv:journal_reference>2022 IEEE IAS Global Conference on Emerging Technologies (GlobConET), Arad, Romania, 2022, pp. 751-756</arxiv:journal_reference>
      <dc:creator>Mohit Gupta, Nitesh Garg, Jai Garg, Vansh Gupta, Devraj Gautam</dc:creator>
    </item>
    <item>
      <title>Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions</title>
      <link>https://arxiv.org/abs/2404.11734</link>
      <description>arXiv:2404.11734v1 Announce Type: new 
Abstract: Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11734v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3639474.3640058</arxiv:DOI>
      <dc:creator>Teemu Lehtinen, Charles Koutcheme, Arto Hellas</dc:creator>
    </item>
    <item>
      <title>Finding A Taxi with Illegal Driver Substitution Activity via Behavior Modelings</title>
      <link>https://arxiv.org/abs/2404.11844</link>
      <description>arXiv:2404.11844v1 Announce Type: new 
Abstract: In our urban life, Illegal Driver Substitution (IDS) activity for a taxi is a grave unlawful activity in the taxi industry, possibly causing severe traffic accidents and painful social repercussions. Currently, the IDS activity is manually supervised by law enforcers, i.e., law enforcers empirically choose a taxi and inspect it. The pressing problem of this scheme is the dilemma between the limited number of law-enforcers and the large volume of taxis. In this paper, motivated by this problem, we propose a computational method that helps law enforcers efficiently find the taxis which tend to have the IDS activity. Firstly, our method converts the identification of the IDS activity to a supervised learning task. Secondly, two kinds of taxi driver behaviors, i.e., the Sleeping Time and Location (STL) behavior and the Pick-Up (PU) behavior are proposed. Thirdly, the multiple scale pooling on self-similarity is proposed to encode the individual behaviors into the universal features for all taxis. Finally, a Multiple Component- Multiple Instance Learning (MC-MIL) method is proposed to handle the deficiency of the behavior features and to align the behavior features simultaneously. Extensive experiments on a real-world data set shows that the proposed behavior features have a good generalization ability across different classifiers, and the proposed MC-MIL method suppresses the baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11844v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junbiao Pang, Muhammad Ayub Sabir, Zhuyun Wang, Anjing Hu, Xue Yang, Haitao Yu, Qingming Huang</dc:creator>
    </item>
    <item>
      <title>TeachNow: Enabling Teachers to Provide Spontaneous, Realtime 1:1 Help in Massive Online Courses</title>
      <link>https://arxiv.org/abs/2404.11918</link>
      <description>arXiv:2404.11918v1 Announce Type: new 
Abstract: One-on-one help from a teacher is highly impactful for students, yet extremely challenging to support in massive online courses (MOOCs). In this work, we present TeachNow: a novel system that lets volunteer teachers from anywhere in the world instantly provide 1:1 help sessions to students in MOOCs, without any scheduling or coordination overhead. TeachNow works by quickly finding an online student to help and putting them in a collaborative working session with the teacher. The spontaneous, on-demand nature of TeachNow gives teachers the flexibility to help whenever their schedule allows.
  We share our experiences deploying TeachNow as an experimental feature in a six week online CS1 course with 9,000 students and 600 volunteer teachers. Even as an optional activity, TeachNow was used by teachers to provide over 12,300 minutes of 1:1 help to 375 unique students. Through a carefully designed randomised control trial, we show that TeachNow sessions increased student course retention rate by almost 15%. Moreover, the flexibility of our system captured valuable volunteer time that would otherwise go to waste. Lastly, TeachNow was rated by teachers as one of the most enjoyable and impactful aspects of their involvement in the course. We believe TeachNow is an important step towards providing more human-centered support in massive online courses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11918v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3649217.3653629</arxiv:DOI>
      <arxiv:journal_reference>In Proceedings of the 2024 Innovation and Technology in Computer Science Education (ITiCSE 2024)</arxiv:journal_reference>
      <dc:creator>Ali Malik, Juliette Woodrow, Chao Wang, Chris Piech</dc:creator>
    </item>
    <item>
      <title>Preserving Nature's Ledger: Blockchains in Biodiversity Conservation</title>
      <link>https://arxiv.org/abs/2404.12086</link>
      <description>arXiv:2404.12086v1 Announce Type: new 
Abstract: In the contemporary era, biodiversity conservation emerges as a paramount challenge, necessitating innovative approaches to monitoring, preserving, and enhancing the natural world. This paper explores the integration of blockchain technology in biodiversity conservation, offering a novel perspective on how digital resilience can be built within ecological contexts. Blockchain, with its decentralized and immutable ledger and tokenization affordances, presents a groundbreaking solution for the accurate monitoring and tracking of environmental assets, thereby addressing the critical need for transparency and trust in conservation efforts. Unlike previous more theoretical approaches, by addressing the research question of how blockchain supports digital resilience in biodiversity conservation, this study presents a grounded framework that justifies which blockchain features are essential to decipher specific data contribution and data leveraging processes in an effort to protect our planet's biodiversity, while boosting potential economic benefits for all actors involved, from local farmers, to hardware vendors and artificial intelligence experts, to investors and regular users, volunteers and donors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12086v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kostas Kryptos Chalkias, Angelos Kostis, Ali Alnuaimi, Peter Knez, John Naulty, Allen Salmasi, Ryan Servatius, Rodrigo Veloso</dc:creator>
    </item>
    <item>
      <title>Intelligence Education made in Europe</title>
      <link>https://arxiv.org/abs/2404.12125</link>
      <description>arXiv:2404.12125v1 Announce Type: new 
Abstract: Global conflicts and trouble spots have thrown the world into turmoil. Intelligence services have never been as necessary as they are today when it comes to providing political decision-makers with concrete, accurate, and up-to-date decision-making knowledge. This requires a common co-operation, a common working language and a common understanding of each other. The best way to create this "intelligence community" is through a harmonized intelligence education.
  In this paper, we show how joint intelligence education can succeed. We draw on the experience of Germany, where all intelligence services and the Bundeswehr are academically educated together in a single degree program that lays the foundations for a common working language. We also show how these experiences have been successfully transferred to a European level, namely to ICE, the Intelligence College in Europe. Our experience has shown that three aspects are particularly important: firstly, interdisciplinarity or better, transdisciplinarity, secondly, the integration of IT knowhow and thirdly, the development and learning of methodological skills. Using the example of the cyber intelligence module with a special focus on data-driven decision support, additionally with its many points of reference to numerous other academic modules, we show how the specific analytic methodology presented is embedded in our specific European teaching context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12125v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lars Berger, Uwe M. Borghoff, Gerhard Conrad, Stefan Pickl</dc:creator>
    </item>
    <item>
      <title>Evaluating Tenant-Landlord Tensions Using Generative AI on Online Tenant Forums</title>
      <link>https://arxiv.org/abs/2404.11681</link>
      <description>arXiv:2404.11681v1 Announce Type: cross 
Abstract: Tenant-landlord relationships exhibit a power asymmetry where landlords' power to evict the tenants at a low-cost results in their dominating status in such relationships. Tenant concerns are thus often unspoken, unresolved, or ignored and this could lead to blatant conflicts as suppressed tenant concerns accumulate. Modern machine learning methods and Large Language Models (LLM) have demonstrated immense abilities to perform language tasks. In this study, we incorporate Latent Dirichlet Allocation (LDA) with GPT-4 to classify Reddit post data scraped from the subreddit r/Tenant, aiming to unveil trends in tenant concerns while exploring the adoption of LLMs and machine learning methods in social science research. We find that tenant concerns in topics like fee dispute and utility issues are consistently dominant in all four states analyzed while each state has other common tenant concerns special to itself. Moreover, we discover temporal trends in tenant concerns that provide important implications regarding the impact of the pandemic and the Eviction Moratorium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11681v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Chen, Cheng Ren, Tim A Thomas</dc:creator>
    </item>
    <item>
      <title>Mapping Violence: Developing an Extensive Framework to Build a Bangla Sectarian Expression Dataset from Social Media Interactions</title>
      <link>https://arxiv.org/abs/2404.11752</link>
      <description>arXiv:2404.11752v1 Announce Type: cross 
Abstract: Communal violence in online forums has become extremely prevalent in South Asia, where many communities of different cultures coexist and share resources. These societies exhibit a phenomenon characterized by strong bonds within their own groups and animosity towards others, leading to conflicts that frequently escalate into violent confrontations. To address this issue, we have developed the first comprehensive framework for the automatic detection of communal violence markers in online Bangla content accompanying the largest collection (13K raw sentences) of social media interactions that fall under the definition of four major violence class and their 16 coarse expressions. Our workflow introduces a 7-step expert annotation process incorporating insights from social scientists, linguists, and psychologists. By presenting data statistics and benchmarking performance using this dataset, we have determined that, aside from the category of Non-communal violence, Religio-communal violence is particularly pervasive in Bangla text. Moreover, we have substantiated the effectiveness of fine-tuning language models in identifying violent comments by conducting preliminary benchmarking on the state-of-the-art Bangla deep learning model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11752v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nazia Tasnim, Sujan Sen Gupta, Md. Istiak Hossain Shihab, Fatiha Islam Juee, Arunima Tahsin, Pritom Ghum, Kanij Fatema, Marshia Haque, Wasema Farzana, Prionti Nasir, Ashique KhudaBukhsh, Farig Sadeque, Asif Sushmit</dc:creator>
    </item>
    <item>
      <title>REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models</title>
      <link>https://arxiv.org/abs/2404.11782</link>
      <description>arXiv:2404.11782v1 Announce Type: cross 
Abstract: The extensive scope of large language models (LLMs) across various domains underscores the critical importance of responsibility in their application, beyond natural language processing. In particular, the randomized nature of LLMs, coupled with inherent biases and historical stereotypes in data, raises critical concerns regarding reliability and equity. Addressing these challenges are necessary before using LLMs for applications with societal impact. Towards addressing this gap, we introduce REQUAL-LM, a novel method for finding reliable and equitable LLM outputs through aggregation. Specifically, we develop a Monte Carlo method based on repeated sampling to find a reliable output close to the mean of the underlying distribution of possible outputs. We formally define the terms such as reliability and bias, and design an equity-aware aggregation to minimize harmful bias while finding a highly reliable output. REQUAL-LM does not require specialized hardware, does not impose a significant computing load, and uses LLMs as a blackbox. This design choice enables seamless scalability alongside the rapid advancement of LLM technologies. Our system does not require retraining the LLMs, which makes it deployment ready and easy to adapt. Our comprehensive experiments using various tasks and datasets demonstrate that REQUAL- LM effectively mitigates bias and selects a more equitable response, specifically the outputs that properly represents minority groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11782v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sana Ebrahimi, Nima Shahbazi, Abolfazl Asudeh</dc:creator>
    </item>
    <item>
      <title>Challenging Negative Gender Stereotypes: A Study on the Effectiveness of Automated Counter-Stereotypes</title>
      <link>https://arxiv.org/abs/2404.11845</link>
      <description>arXiv:2404.11845v1 Announce Type: cross 
Abstract: Gender stereotypes are pervasive beliefs about individuals based on their gender that play a significant role in shaping societal attitudes, behaviours, and even opportunities. Recognizing the negative implications of gender stereotypes, particularly in online communications, this study investigates eleven strategies to automatically counter-act and challenge these views. We present AI-generated gender-based counter-stereotypes to (self-identified) male and female study participants and ask them to assess their offensiveness, plausibility, and potential effectiveness. The strategies of counter-facts and broadening universals (i.e., stating that anyone can have a trait regardless of group membership) emerged as the most robust approaches, while humour, perspective-taking, counter-examples, and empathy for the speaker were perceived as less effective. Also, the differences in ratings were more pronounced for stereotypes about the different targets than between the genders of the raters. Alarmingly, many AI-generated counter-stereotypes were perceived as offensive and/or implausible. Our analysis and the collected dataset offer foundational insight into counter-stereotype generation, guiding future efforts to develop strategies that effectively challenge gender stereotypes in online interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11845v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isar Nejadgholi, Kathleen C. Fraser, Anna Kerkhof, Svetlana Kiritchenko</dc:creator>
    </item>
    <item>
      <title>The Emerging AI Divide in the United States</title>
      <link>https://arxiv.org/abs/2404.11988</link>
      <description>arXiv:2404.11988v1 Announce Type: cross 
Abstract: The digital divide describes disparities in access to and usage of digital tooling between social and economic groups. Emerging generative artificial intelligence tools, which strongly affect productivity, could magnify the impact of these divides. However, the affordability, multi-modality, and multilingual capabilities of these tools could also make them more accessible to diverse users in comparison with previous forms of digital tooling. In this study, we characterize spatial differences in U.S. residents' knowledge of a new generative AI tool, ChatGPT, through an analysis of state- and county-level search query data. In the first six months after the tool's release, we observe the highest rates of users searching for ChatGPT in West Coast states and persistently low rates of search in Appalachian and Gulf states. Counties with the highest rates of search are relatively more urbanized and have proportionally more educated, more economically advantaged, and more Asian residents in comparison with other counties or with the U.S. average. In multilevel models adjusting for socioeconomic and demographic factors as well as industry makeup, education is the strongest positive predictor of rates of search for generative AI tooling. Although generative AI technologies may be novel, early differences in uptake appear to be following familiar paths of digital marginalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11988v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Madeleine I. G. Daepp, Scott Counts</dc:creator>
    </item>
    <item>
      <title>RAGAR, Your Falsehood RADAR: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models</title>
      <link>https://arxiv.org/abs/2404.12065</link>
      <description>arXiv:2404.12065v1 Announce Type: cross 
Abstract: The escalating challenge of misinformation, particularly in the context of political discourse, necessitates advanced solutions for fact-checking. We introduce innovative approaches to enhance the reliability and efficiency of multimodal fact-checking through the integration of Large Language Models (LLMs) with Retrieval-augmented Generation (RAG)- based advanced reasoning techniques. This work proposes two novel methodologies, Chain of RAG (CoRAG) and Tree of RAG (ToRAG). The approaches are designed to handle multimodal claims by reasoning the next questions that need to be answered based on previous evidence. Our approaches improve the accuracy of veracity predictions and the generation of explanations over the traditional fact-checking approach of sub-question generation with chain of thought veracity prediction. By employing multimodal LLMs adept at analyzing both text and images, this research advances the capability of automated systems in identifying and countering misinformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12065v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>M. Abdul Khaliq, P. Chang, M. Ma, B. Pflugfelder, F. Mileti\'c</dc:creator>
    </item>
    <item>
      <title>The Neutrality Fallacy: When Algorithmic Fairness Interventions are (Not) Positive Action</title>
      <link>https://arxiv.org/abs/2404.12143</link>
      <description>arXiv:2404.12143v1 Announce Type: cross 
Abstract: Various metrics and interventions have been developed to identify and mitigate unfair outputs of machine learning systems. While individuals and organizations have an obligation to avoid discrimination, the use of fairness-aware machine learning interventions has also been described as amounting to 'algorithmic positive action' under European Union (EU) non-discrimination law. As the Court of Justice of the European Union has been strict when it comes to assessing the lawfulness of positive action, this would impose a significant legal burden on those wishing to implement fair-ml interventions. In this paper, we propose that algorithmic fairness interventions often should be interpreted as a means to prevent discrimination, rather than a measure of positive action. Specifically, we suggest that this category mistake can often be attributed to neutrality fallacies: faulty assumptions regarding the neutrality of fairness-aware algorithmic decision-making. Our findings raise the question of whether a negative obligation to refrain from discrimination is sufficient in the context of algorithmic decision-making. Consequently, we suggest moving away from a duty to 'not do harm' towards a positive obligation to actively 'do no harm' as a more adequate framework for algorithmic decision-making and fair ml-interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12143v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3659025</arxiv:DOI>
      <arxiv:journal_reference>2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24)</arxiv:journal_reference>
      <dc:creator>Hilde Weerts, Rapha\"ele Xenidis, Fabien Tarissan, Henrik Palmer Olsen, Mykola Pechenizkiy</dc:creator>
    </item>
    <item>
      <title>Large Language Models for Synthetic Participatory Planning of Shared Automated Electric Mobility Systems</title>
      <link>https://arxiv.org/abs/2404.12317</link>
      <description>arXiv:2404.12317v1 Announce Type: cross 
Abstract: Unleashing the synergies of rapidly evolving mobility technologies in a multi-stakeholder landscape presents unique challenges and opportunities for addressing urban transportation problems. This paper introduces a novel synthetic participatory method, critically leveraging large language models (LLMs) to create digital avatars representing diverse stakeholders to plan shared automated electric mobility systems (SAEMS). These calibratable agents collaboratively identify objectives, envision and evaluate SAEMS alternatives, and strategize implementation under risks and constraints. The results of a Montreal case study indicate that a structured and parameterized workflow provides outputs with high controllability and comprehensiveness on an SAEMS plan than generated using a single LLM-enabled expert agent. Consequently, the approach provides a promising avenue for cost-efficiently improving the inclusivity and interpretability of multi-objective transportation planning, suggesting a paradigm shift in how we envision and strategize for sustainable and equitable transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12317v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiangbo Yu</dc:creator>
    </item>
    <item>
      <title>Accounting for AI and Users Shaping One Another: The Role of Mathematical Models</title>
      <link>https://arxiv.org/abs/2404.12366</link>
      <description>arXiv:2404.12366v1 Announce Type: cross 
Abstract: As AI systems enter into a growing number of societal domains, these systems increasingly shape and are shaped by user preferences, opinions, and behaviors. However, the design of AI systems rarely accounts for how AI and users shape one another. In this position paper, we argue for the development of formal interaction models which mathematically specify how AI and users shape one another. Formal interaction models can be leveraged to (1) specify interactions for implementation, (2) monitor interactions through empirical analysis, (3) anticipate societal impacts via counterfactual analysis, and (4) control societal impacts via interventions. The design space of formal interaction models is vast, and model design requires careful consideration of factors such as style, granularity, mathematical complexity, and measurability. Using content recommender systems as a case study, we critically examine the nascent literature of formal interaction models with respect to these use-cases and design axes. More broadly, we call for the community to leverage formal interaction models when designing, evaluating, or auditing any AI system which interacts with users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12366v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Dean, Evan Dong, Meena Jagadeesan, Liu Leqi</dc:creator>
    </item>
    <item>
      <title>Online Advertisements with LLMs: Opportunities and Challenges</title>
      <link>https://arxiv.org/abs/2311.07601</link>
      <description>arXiv:2311.07601v3 Announce Type: replace 
Abstract: This paper explores the potential for leveraging Large Language Models (LLM) in the realm of online advertising systems. We delve into essential requirements including privacy, latency, reliability as well as the satisfaction of users and advertisers that such a system must fulfill. We further introduce a general framework for LLM advertisement, consisting of modification, bidding, prediction, and auction modules. Different design considerations for each module are presented. Fundamental questions regarding practicality, efficiency, and implementation challenges of these designs are raised for future research. Finally, we explore the prospect of LLM-based dynamic creative optimization as a means to significantly enhance the appeal of advertisements to users and discuss its additional challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07601v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soheil Feizi, MohammadTaghi Hajiaghayi, Keivan Rezaei, Suho Shin</dc:creator>
    </item>
    <item>
      <title>Twenty Constructionist Things to Do with Artificial Intelligence and Machine Learning</title>
      <link>https://arxiv.org/abs/2402.06775</link>
      <description>arXiv:2402.06775v2 Announce Type: replace 
Abstract: In this paper, we build on the 1971 memo "Twenty Things to Do With a Computer" by Seymour Papert and Cynthia Solomon and propose twenty constructionist things to do with artificial intelligence and machine learning. Several proposals build on ideas developed in the original memo while others are new and address topics in science, mathematics, and the arts. In reviewing the big themes, we notice a renewed interest in children's engagement not just for technical proficiency but also to cultivate a deeper understanding of their own cognitive processes. Furthermore, the ideas stress the importance of designing personally relevant AI/ML applications, moving beyond isolated models and off-the-shelf datasets disconnected from their interests. We also acknowledge the social aspects of data production involved in making AI/ML applications. Finally, we highlight the critical dimensions necessary to address potential harmful algorithmic biases and consequences of AI/ML applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06775v2</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yasmin Kafai, Luis Morales-Navarro</dc:creator>
    </item>
    <item>
      <title>Epistemic Power in AI Ethics Labor: Legitimizing Located Complaints</title>
      <link>https://arxiv.org/abs/2402.08171</link>
      <description>arXiv:2402.08171v4 Announce Type: replace 
Abstract: What counts as legitimate AI ethics labor, and consequently, what are the epistemic terms on which AI ethics claims are rendered legitimate? Based on 75 interviews with technologists including researchers, developers, open source contributors, and activists, this paper explores the various epistemic bases from which AI ethics is discussed and practiced. In the context of outside attacks on AI ethics as an impediment to "progress," I show how some AI ethics practices have reached toward authority from automation and quantification, and achieved some legitimacy as a result, while those based on richly embodied and situated lived experience have not. This paper draws together the work of feminist Anthropology and Science and Technology Studies scholars Diana Forsythe and Lucy Suchman with the works of postcolonial feminist theorist Sara Ahmed and Black feminist theorist Kristie Dotson to examine the implications of dominant AI ethics practices.
  By entrenching the epistemic power of quantification, dominant AI ethics practices -- employing Model Cards and similar interventions -- risk legitimizing AI ethics as a project in equal and opposite measure to which they marginalize embodied lived experience as a legitimate part of the same project. In response, I propose humble technical practices: quantified or technical practices which specifically seek to make their epistemic limits clear in order to flatten hierarchies of epistemic power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08171v4</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3658973</arxiv:DOI>
      <dc:creator>David Gray Widder</dc:creator>
    </item>
    <item>
      <title>Information Fusion in Multimodal IoT Systems for physical activity level monitoring</title>
      <link>https://arxiv.org/abs/2403.14707</link>
      <description>arXiv:2403.14707v2 Announce Type: replace 
Abstract: This study exploits information fusion in IoT systems and uses a clustering method to identify similarities in behaviours and key characteristics within each cluster. This approach facilitates early detection of behaviour changes and provides a more in-depth understanding of behaviour routines for continuous health monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14707v2</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohsen Shirali, Zahra Ahmadi, Carlos Fern\'andez-Llatas, Jose-Luis Bayo-Monton</dc:creator>
    </item>
    <item>
      <title>Social Links vs. Language Barriers: Decoding the Global Spread of Streaming Content</title>
      <link>https://arxiv.org/abs/2402.19329</link>
      <description>arXiv:2402.19329v2 Announce Type: replace-cross 
Abstract: The development of the internet has allowed for the global distribution of content, redefining media communication and property structures through various streaming platforms. Previous studies successfully clarified the factors contributing to trends in each streaming service, yet the similarities and differences between platforms are commonly unexplored; moreover, the influence of social connections and cultural similarity is usually overlooked. We hereby examine the social aspects of three significant streaming services--Netflix, Spotify, and YouTube--with an emphasis on the dissemination of content across countries. Using two-year-long trending chart datasets, we find that streaming content can be divided into two types: video-oriented (Netflix) and audio-oriented (Spotify). This characteristic is differentiated by accounting for the significance of social connectedness and linguistic similarity: audio-oriented content travels via social links, but video-oriented content tends to spread throughout linguistically akin countries. Interestingly, user-generated contents, YouTube, exhibits a dual characteristic by integrating both visual and auditory characteristics, indicating the platform is evolving into unique medium rather than simply residing a midpoint between video and audio media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19329v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seoyoung Park, Sanghyeok Park, Taekho You, Jinhyuk Yun</dc:creator>
    </item>
    <item>
      <title>Improving Socratic Question Generation using Data Augmentation and Preference Optimization</title>
      <link>https://arxiv.org/abs/2403.00199</link>
      <description>arXiv:2403.00199v2 Announce Type: replace-cross 
Abstract: The Socratic method is a way of guiding students toward solving a problem independently without directly revealing the solution to the problem. Although this method has been shown to significantly improve student learning outcomes, it remains a complex labor-intensive task for instructors. Large language models (LLMs) can be used to augment human effort by automatically generating Socratic questions for students. However, existing methods that involve prompting these LLMs sometimes produce invalid outputs, e.g., those that directly reveal the solution to the problem or provide irrelevant or premature questions. To alleviate this problem, inspired by reinforcement learning with AI feedback (RLAIF), we first propose a data augmentation method to enrich existing Socratic questioning datasets with questions that are invalid in specific ways. Next, we propose a method to optimize open-source LLMs such as LLama 2 to prefer ground-truth questions over generated invalid ones, using direct preference optimization (DPO). Our experiments on a Socratic questions dataset for student code debugging show that a DPO-optimized 7B LLama 2 model can effectively avoid generating invalid questions, and as a result, outperforms existing state-of-the-art prompting methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00199v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nischal Ashok Kumar, Andrew Lan</dc:creator>
    </item>
    <item>
      <title>Negotiating the Shared Agency between Humans &amp; AI in the Recommender System</title>
      <link>https://arxiv.org/abs/2403.15919</link>
      <description>arXiv:2403.15919v2 Announce Type: replace-cross 
Abstract: Smart recommendation algorithms have revolutionized information dissemination, enhancing efficiency and reshaping content delivery across various domains. However, concerns about user agency have arisen due to the inherent opacity (information asymmetry) and the nature of one-way output (power asymmetry) on algorithms. While both issues have been criticized by scholars via advocating explainable AI (XAI) and human-AI collaborative decision-making (HACD), few research evaluates their integrated effects on users, and few HACD discussions in recommender systems beyond improving and filtering the results. This study proposes an incubating idea as a missing step in HACD that allows users to control the degrees of AI-recommended content. Then, we integrate it with existing XAI to a flow prototype aimed at assessing the enhancement of user agency. We seek to understand how types of agency impact user perception and experience, and bring empirical evidence to refine the guidelines and designs for human-AI interactive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15919v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengke Wu, Weizi Liu, Yanyun Wang, Mike Zhengyu Yao</dc:creator>
    </item>
    <item>
      <title>Urban highways are barriers to social ties</title>
      <link>https://arxiv.org/abs/2404.11596</link>
      <description>arXiv:2404.11596v2 Announce Type: replace-cross 
Abstract: Urban highways are common, especially in the US, making cities more car-centric. They promise the annihilation of distance but obstruct pedestrian mobility, thus playing a key role in limiting social interactions locally. Although this limiting role is widely acknowledged in urban studies, the quantitative relationship between urban highways and social ties is barely tested. Here we define a Barrier Score that relates massive, geolocated online social network data to highways in the 50 largest US cities. At the unprecedented granularity of individual social ties, we show that urban highways are associated with decreased social connectivity. This barrier effect is especially strong for short distances and consistent with historical cases of highways that were built to purposefully disrupt or isolate Black neighborhoods. By combining spatial infrastructure with social tie data, our method adds a new dimension to demographic studies of social segregation. Our study can inform reparative planning for an evidence-based reduction of spatial inequality, and more generally, support a better integration of the social fabric in urban planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11596v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Maria Aiello, Anastassia Vybornova, S\'andor Juh\'asz, Michael Szell, Eszter Bok\'anyi</dc:creator>
    </item>
  </channel>
</rss>
