<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Nov 2025 05:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Uncertainty Removal in Verification of Nonlinear Systems against Signal Temporal Logic via Incremental Reachability Analysis</title>
      <link>https://arxiv.org/abs/2511.17617</link>
      <description>arXiv:2511.17617v1 Announce Type: cross 
Abstract: A framework is presented for the verification of Signal Temporal Logic (STL) specifications over continuous-time nonlinear systems under uncertainty. Based on reachability analysis, the proposed method addresses indeterminate satisfaction caused by over-approximated reachable sets or incomplete simulations. STL semantics is extended via Boolean interval arithmetic, enabling the decomposition of satisfaction signals into unitary components with traceable uncertainty markers. These are propagated through the satisfaction tree, supporting precise identification even in nested formulas. To improve efficiency, only the reachable sets contributing to uncertainty are refined, identified through the associated markers. The framework allows online or offline monitoring to adapt to incremental system evolution while avoiding unnecessary recomputation. A case study on a nonlinear oscillator demonstrates a significant reduction in satisfaction ambiguity, highlighting the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17617v1</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Antoine Besset, Joris Tillet, Julien Alexandre dit Sandretto</dc:creator>
    </item>
    <item>
      <title>Comparing Labeled Markov Chains: A Cantor-Kantorovich Approach</title>
      <link>https://arxiv.org/abs/2511.18103</link>
      <description>arXiv:2511.18103v1 Announce Type: cross 
Abstract: Labeled Markov Chains (or LMCs for short) are useful mathematical objects to model complex probabilistic languages. A central challenge is to compare two LMCs, for example to assess the accuracy of an abstraction or to quantify the effect of model perturbations. In this work, we study the recently introduced Cantor-Kantorovich (or CK) distance. In particular we show that the latter can be framed as a discounted sum of finite-horizon Total Variation distances, making it an instance of discounted linear distance, but arising from the natural Cantor topology. Building on the latter observation, we analyze the properties of the CK distance along three dimensions: computational complexity, continuity properties and approximation. More precisely, we show that the exact computation of the CK distance is #P-hard. We also provide an upper bound on the CK distance as a function of the approximation relation between the two LMCs, and show that a bounded CK distance implies a bounded error between probabilities of finite-horizon traces. Finally, we provide a computable approximation scheme, and show that the latter is also #P-hard. Altogether, our results provide a rigorous theoretical foundation for the CK distance and clarify its relationship with existing distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18103v1</guid>
      <category>cs.LO</category>
      <category>cs.CL</category>
      <category>cs.FL</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrien Banse, Alessandro Abate, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>ObjectAlign: Neuro-Symbolic Object Consistency Verification and Correction</title>
      <link>https://arxiv.org/abs/2511.18701</link>
      <description>arXiv:2511.18701v1 Announce Type: cross 
Abstract: Video editing and synthesis often introduce object inconsistencies, such as frame flicker and identity drift that degrade perceptual quality. To address these issues, we introduce ObjectAlign, a novel framework that seamlessly blends perceptual metrics with symbolic reasoning to detect, verify, and correct object-level and temporal inconsistencies in edited video sequences. The novel contributions of ObjectAlign are as follows: First, we propose learnable thresholds for metrics characterizing object consistency (i.e. CLIP-based semantic similarity, LPIPS perceptual distance, histogram correlation, and SAM-derived object-mask IoU). Second, we introduce a neuro-symbolic verifier that combines two components: (a) a formal, SMT-based check that operates on masked object embeddings to provably guarantee that object identity does not drift, and (b) a temporal fidelity check that uses a probabilistic model checker to verify the video's formal representation against a temporal logic specification. A frame transition is subsequently deemed "consistent" based on a single logical assertion that requires satisfying both the learned metric thresholds and this unified neuro-symbolic constraint, ensuring both low-level stability and high-level temporal correctness. Finally, for each contiguous block of flagged frames, we propose a neural network based interpolation for adaptive frame repair, dynamically choosing the interpolation depth based on the number of frames to be corrected. This enables reconstruction of the corrupted frames from the last valid and next valid keyframes. Our results show up to 1.4 point improvement in CLIP Score and up to 6.1 point improvement in warp error compared to SOTA baselines on the DAVIS and Pexels video datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18701v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustafa Munir, Harsh Goel, Xiwen Wei, Minkyu Choi, Sahil Shah, Kartikeya Bhardwaj, Paul Whatmough, Sandeep Chinchali, Radu Marculescu</dc:creator>
    </item>
    <item>
      <title>HERMES: Towards Efficient and Verifiable Mathematical Reasoning in LLMs</title>
      <link>https://arxiv.org/abs/2511.18760</link>
      <description>arXiv:2511.18760v1 Announce Type: cross 
Abstract: Informal mathematics has been central to modern large language model (LLM) reasoning, offering flexibility and enabling efficient construction of arguments. However, purely informal reasoning is prone to logical gaps and subtle errors that are difficult to detect and correct. In contrast, formal theorem proving provides rigorous, verifiable mathematical reasoning, where each inference step is checked by a trusted compiler in systems such as Lean, but lacks the exploratory freedom of informal problem solving. This mismatch leaves current LLM-based math agents without a principled way to combine the strengths of both paradigms. In this work, we introduce Hermes, the first tool-assisted agent that explicitly interleaves informal reasoning with formally verified proof steps in Lean. The framework performs intermediate formal checking to prevent reasoning drift and employs a memory module that maintains proof continuity across long, multi-step reasoning chains, enabling both exploration and verification within a single workflow. We evaluate Hermes on four challenging mathematical reasoning benchmarks using LLMs of varying parameter scales, from small models to state-of-the-art systems. Across all settings, Hermes reliably improves the reasoning accuracy of base models while substantially reducing token usage and computational cost compared to reward-based approaches. On difficult datasets such as AIME'25, Hermes achieves up to a 67% accuracy improvement while using 80% fewer total inference FLOPs. The implementation and codebase are publicly available at https://github.com/aziksh-ospanov/HERMES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18760v1</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Azim Ospanov, Zijin Feng, Jiacheng Sun, Haoli Bai, Xin Shen, Farzan Farnia</dc:creator>
    </item>
    <item>
      <title>Extracting Robust Register Automata from Neural Networks over Data Sequences</title>
      <link>https://arxiv.org/abs/2511.19100</link>
      <description>arXiv:2511.19100v1 Announce Type: cross 
Abstract: Automata extraction is a method for synthesising interpretable surrogates for black-box neural models that can be analysed symbolically. Existing techniques assume a finite input alphabet, and thus are not directly applicable to data sequences drawn from continuous domains. We address this challenge with deterministic register automata (DRAs), which extend finite automata with registers that store and compare numeric values. Our main contribution is a framework for robust DRA extraction from black-box models: we develop a polynomial-time robustness checker for DRAs with a fixed number of registers, and combine it with passive and active automata learning algorithms. This combination yields surrogate DRAs with statistical robustness and equivalence guarantees. As a key application, we use the extracted automata to assess the robustness of neural networks: for a given sequence and distance metric, the DRA either certifies local robustness or produces a concrete counterexample. Experiments on recurrent neural networks and transformer architectures show that our framework reliably learns accurate automata and enables principled robustness evaluation. Overall, our results demonstrate that robust DRA extraction effectively bridges neural network interpretability and formal reasoning without requiring white-box access to the underlying network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19100v1</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chih-Duo Hong, Hongjian Jiang, Anthony W. Lin, Oliver Markgraf, Julian Parsert, Tony Tan</dc:creator>
    </item>
    <item>
      <title>Formalizing Computational Paths and Fundamental Groups in Lean</title>
      <link>https://arxiv.org/abs/2511.19142</link>
      <description>arXiv:2511.19142v1 Announce Type: cross 
Abstract: Computational paths treat propositional equality as explicit paths built from labelled deduction steps and rewrite rules. This view originates in work by de Queiroz and collaborators and yields a weak groupoid structure for equality, together with a computational account of homotopy inspired by homotopy type theory. In this paper we present a complete mechanization of this framework in Lean 4 and show how it supports concrete homotopy theoretic computations. Our contributions are threefold. First, we formalize the theory of computational paths in Lean, including path formation, composition, inverses, and a rewrite system that identifies redundant or trivial paths. We prove that equality types with computational paths carry a weak groupoid structure in the sense of the original theory. Second, we organize this material into a reusable Lean library, ComputationalPathsLean, which exposes an interface for paths, rewrites, and loop spaces. This library allows later developments to treat computational paths as a drop-in replacement for propositional equality when reasoning about homotopical structure. Third, we apply the library to two canonical examples in algebraic topology. We give Lean proofs that the fundamental group of the circle is isomorphic to the integers and that the fundamental group of the torus is isomorphic to the product of two copies of the integers, both via computational paths. These case studies demonstrate that the computational paths approach scales to nontrivial homotopical computations in a modern proof assistant. All the definitions and proofs described here are available in an open-source Lean 4 repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19142v1</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur F. Ramos, Anjolina G. de Oliveira, Ruy J. G. B. de Queiroz, Tiago M. L. de Veras</dc:creator>
    </item>
    <item>
      <title>Preprint: Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems</title>
      <link>https://arxiv.org/abs/2504.15668</link>
      <description>arXiv:2504.15668v2 Announce Type: replace-cross 
Abstract: Explaining unsolvability of planning problems is of significant research interest in Explainable AI Planning. AI planning literature has reported several research efforts on generating explanations of solutions to planning problems. However, explaining the unsolvability of planning problems remains a largely open and understudied problem. A widely practiced approach to plan generation and automated problem solving, in general, is to decompose tasks into sub-problems that help progressively converge towards the goal. In this paper, we propose to adopt the same philosophy of sub-problem identification as a mechanism for analyzing and explaining unsolvability of planning problems in hybrid systems. In particular, for a given unsolvable planning problem, we propose to identify common waypoints, which are universal obstacles to plan existence; in other words, they appear on every plan from the source to the planning goal. This work envisions such waypoints as sub-problems of the planning problem and the unreachability of any of these waypoints as an explanation for the unsolvability of the original planning problem. We propose a novel method of waypoint identification by casting the problem as an instance of the longest common subsequence problem, a widely popular problem in computer science, typically considered as an illustrative example for the dynamic programming paradigm. Once the waypoints are identified, we perform symbolic reachability analysis on them to identify the earliest unreachable waypoint and report it as the explanation of unsolvability. We present experimental results on unsolvable planning problems in hybrid domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15668v2</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/376774</arxiv:DOI>
      <arxiv:journal_reference>ACM Transactions on Embedded Computing Systems, Volume 24, Issue 6, Article No.: 163, Year: 09 Oct0ber 2025, Pages 1 - 20</arxiv:journal_reference>
      <dc:creator>Mir Md Sajid Sarwar, Rajarshi Ray</dc:creator>
    </item>
    <item>
      <title>Computing Sound and Accurate Upper and Lower Bounds on Hamilton-Jacobi Reachability Value Functions</title>
      <link>https://arxiv.org/abs/2511.15238</link>
      <description>arXiv:2511.15238v2 Announce Type: replace-cross 
Abstract: Hamilton-Jacobi (HJ) reachability analysis is a fundamental tool for safety verification and control synthesis for nonlinear-control systems. Classical HJ reachability analysis methods discretize the continuous state space and solve the HJ partial differential equation over a grid, but these approaches do not account for discretization errors and can under-approximate backward reachable sets, which represent unsafe sets of states. We present a framework for computing sound upper and lower bounds on the HJ value functions via value iteration over grids. Additionally, we develop a refinement algorithm that splits cells that were not possible to classify as safe or unsafe given the computed bounds. This algorithm enables computing accurate over-approximations of backward reachable sets even when starting from coarse grids. Finally, we validate the effectiveness of our method in two case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15238v2</guid>
      <category>eess.SY</category>
      <category>cs.FL</category>
      <category>cs.SC</category>
      <category>cs.SY</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ihab Tabbara, Eliya Badr, Hussein Sibai</dc:creator>
    </item>
  </channel>
</rss>
