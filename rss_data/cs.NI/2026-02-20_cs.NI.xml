<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Feb 2026 05:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>HyRA: A Hybrid Resource Allocation Framework for RAN Slicing</title>
      <link>https://arxiv.org/abs/2602.16952</link>
      <description>arXiv:2602.16952v1 Announce Type: new 
Abstract: The advent of 5G and the emergence of 6G networks demand unprecedented flexibility and efficiency in Radio Access Network (RAN) resource management to satisfy diverse service-level agreements (SLAs). Existing RAN slicing frameworks predominantly rely on per-slice resource reservation, which ensures performance isolation but leads to inefficient utilization, particularly under bursty traffic. We introduce HyRA, a hybrid resource allocation framework for RAN slicing that combines dedicated per-slice allocations with shared resource pooling across slices. HyRA preserves performance isolation while improving resource efficiency by leveraging multiplexing gains in bursty traffic conditions. We formulate this design as a bi-level stochastic optimization problem, where the outer loop determines the dedicated and shared resource budgets and the inner loop performs per-UE scheduling under a novel water-filling approach. By using the sample-average approximation, the Karush-Kuhn-Tucker (KKT) conditions of the inner loop, and Big-M encoding, we transform the problem into a tractable mixed-integer program that standard optimization solvers can solve. Extensive simulations under diverse demand patterns, SLA configurations, and traffic burstiness show that HyRA achieves up to 50-75% spectrum savings compared to dedicated-only and shared-only baselines. These results highlight HyRA as a viable approach for resource-efficient, SLA-compliant RAN slicing in future mobile networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16952v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Zangooei, Bo Sun, Noura Limam, Raouf Boutaba</dc:creator>
    </item>
    <item>
      <title>Robust and Extensible Measurement of Broadband Plans with BQT+</title>
      <link>https://arxiv.org/abs/2602.16969</link>
      <description>arXiv:2602.16969v1 Announce Type: new 
Abstract: Independent, street address-level broadband data is essential for evaluating Internet infrastructure investments, such as the $42B Broadband Equity, Access, and Deployment (BEAD) program. Evaluating these investments requires longitudinal visibility into broadband availability, quality, and affordability, including data on pre-disbursement baselines and changes in providers' advertised plans. While such data can be obtained through Internet Service Provider (ISP) web interfaces, these workloads impose three fundamental system requirements: robustness to frequent interface evolution, extensibility across hundreds of providers, and low technical overhead for non-expert users. Existing systems fail to meet these three essential requirements.
  We present BQT+, a broadband plan measurement framework that replaces monolithic workflows with declarative state/action specifications. BQT+ models querying intent as an interaction state space, formalized as an abstract nondeterministic finite automaton (NFA), and selects execution paths at runtime to accommodate alternative interaction flows and localized interface changes. We show that BQT+ sustains longitudinal monitoring of 64 ISPs, supporting querying for over 100 ISPs. We apply it to two policy studies: constructing a BEAD pre-disbursement baseline and benchmarking broadband affordability across over 124,000 addresses in four states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16969v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laasya Koduru, Sylee Beltiukov, Alexander Nguyen, Eugene Vuong, Jaber Daneshamooz, Tejas Narechania, Elizabeth Belding, Arpit Gupta</dc:creator>
    </item>
    <item>
      <title>RIS Control through the Lens of Stochastic Network Calculus: An O-RAN Framework for Delay-Sensitive 6G Applications</title>
      <link>https://arxiv.org/abs/2602.17198</link>
      <description>arXiv:2602.17198v1 Announce Type: new 
Abstract: Reconfigurable Intelligent Surfaces (RIS) enable dynamic electromagnetic control for 6G networks, but existing control schemes lack responsiveness to fast-varying network conditions, limiting their applicability for ultra-reliable low latency communications. This work addresses uplink delay minimization in multi-RIS scenarios with heterogeneous per-user latency and reliability demands. We propose Delay-Aware RIS Orchestrator (DARIO), an O-RAN-compliant framework that dynamically assigns RIS devices to users within short time windows, adapting to traffic fluctuations to meet per-user delay and reliability targets. DARIO relies on a novel Stochastic Network Calculus (SNC) model to analytically estimate the delay bound for each possible user-RIS assignment under specific traffic and service dynamics. These estimations are used by DARIO to formulate a Nonlinear Integer Program (NIP), for which an online heuristic provides near-optimal performance with low computational overhead. Extensive evaluations with simulations and real traffic traces show consistent delay reductions up to 95.7% under high load or RIS availability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17198v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar Adamuz-Hinojosa, Lanfranco Zanzi, Vincenzo Sciancalepore, Marco Di Renzo, Xavier Costa-P\'erez</dc:creator>
    </item>
    <item>
      <title>Hierarchical Edge-Cloud Task Offloading in NTN for Remote Healthcare</title>
      <link>https://arxiv.org/abs/2602.17209</link>
      <description>arXiv:2602.17209v1 Announce Type: new 
Abstract: In this work, we study a hierarchical non-terrestrial network as an edge-cloud platform for remote computing of tasks generated by remote ad-hoc healthcare facility deployments, or internet of medical things (IoMT) devices. We consider a high altitude platform station (HAPS) to provide local multiaccess edge server (MEC) services to a set of remote ground medical devices, and a low-earth orbit (LEO) satellite, serving as a bridge to a remote cloud computing server through a ground gateway (GW), providing a large amount of computing resources to the HAPS. In this hierarchical system, the HAPS and the cloud server charges the ground users and the HAPS for the use of the spectrum and the computing of their tasks respectively. Each tier seeks to maximize their own utility in a selfish manner. To encourage the prompt computation of the tasks, a local delay cost is assumed. We formulate the optimal per-task cost at each tier that influences the corresponding offloading policies, and find the corresponding optimal bandwidth allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17209v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Flores, Danial Shafaie, Konstantinos Ntontin, Elli Kartsakli, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>End-to-End Latency Measurement Methodology for Connected and Autonomous Vehicle Teleoperation</title>
      <link>https://arxiv.org/abs/2602.17381</link>
      <description>arXiv:2602.17381v1 Announce Type: new 
Abstract: Connected and Autonomous Vehicles (CAVs) continue to evolve rapidly, and system latency remains one of their most critical performance parameters, particularly when vehicles are operated remotely. Existing latency-assessment methodologies focus predominantly on Glass-to-Glass (G2G) latency, defined as the delay between an event occurring in the operational environment, its capture by a camera, and its subsequent display to the remote operator. However, G2G latency accounts for only one component of the total delay experienced by the driver. The complementary component, Motion-to-Motion (M2M) latency, represents the delay between the initiation of a control input by the remote driver and the corresponding physical actuation by the vehicle. Together, M2M and G2G constitute the overall End-to-End (E2E) latency. This paper introduces a measurement framework capable of quantifying M2M, G2G, and E2E latencies using gyroscopes, a phototransistor, and two GPS-synchronized Raspberry Pi 5 units. The system employs low-pass filtering and threshold-based detection to identify steering-wheel motion on both the remote operator and vehicle sides. An interrupt is generated when the phototransistor detects the activation of an LED positioned within the camera's Field Of View (FOV). Initial measurements obtained from our teleoperated prototype vehicle over commercial 4G and 5G networks indicate an average E2E latency of approximately 500 ms (measurement precision +/- 4 ms). The M2M latency contributes up to 60% of this value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17381v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Provost, Faisal Hawlader, Mehdi Testouri, Rapha\"el Frank</dc:creator>
    </item>
    <item>
      <title>Voice-Driven Semantic Perception for UAV-Assisted Emergency Networks</title>
      <link>https://arxiv.org/abs/2602.17394</link>
      <description>arXiv:2602.17394v1 Announce Type: new 
Abstract: Unmanned Aerial Vehicle (UAV)-assisted networks are increasingly foreseen as a promising approach for emergency response, providing rapid, flexible, and resilient communications in environments where terrestrial infrastructure is degraded or unavailable. In such scenarios, voice radio communications remain essential for first responders due to their robustness; however, their unstructured nature prevents direct integration with automated UAV-assisted network management. This paper proposes SIREN, an AI-driven framework that enables voice-driven perception for UAV-assisted networks. By integrating Automatic Speech Recognition (ASR) with Large Language Model (LLM)-based semantic extraction and Natural Language Processing (NLP) validation, SIREN converts emergency voice traffic into structured, machine-readable information, including responding units, location references, emergency severity, and Quality-of-Service (QoS) requirements. SIREN is evaluated using synthetic emergency scenarios with controlled variations in language, speaker count, background noise, and message complexity. The results demonstrate robust transcription and reliable semantic extraction across diverse operating conditions, while highlighting speaker diarization and geographic ambiguity as the main limiting factors. These findings establish the feasibility of voice-driven situational awareness for UAV-assisted networks and show a practical foundation for human-in-the-loop decision support and adaptive network management in emergency response operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17394v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.SD</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nuno Saavedra, Pedro Ribeiro, Andr\'e Coelho, Rui Campos</dc:creator>
    </item>
    <item>
      <title>ACOS: Arrays of Cheap Optical Switches</title>
      <link>https://arxiv.org/abs/2602.17449</link>
      <description>arXiv:2602.17449v1 Announce Type: new 
Abstract: Machine learning training places immense demands on cluster networks, motivating specialized architectures and co-design with parallelization strategies. Recent designs incorporating optical circuit switches (OCSes) are promising, offering improved cost, power efficiency, and long-term bandwidth scaling than packet switches. However, most existing approaches rely on costly high-radix OCSes and/or combine them with packet switches to achieve competitive performance at scale. Unfortunately, high-radix OCSes are both expensive and slow to reconfigure, limiting both scalability and performance.
  We propose Arrays of Cheap Optical Switches (ACOS), which bring application co-design directly to the structure of the reconfigurable fabric. Using low-radix OCSes as building blocks, ACOS supports the forms of reconfiguration needed in training clusters including topology selection, workload adaptation, and failure resilience. The cost of ACOS scales with supported topologies and adaptations rather than with port count, breaking past the scalability barriers of current specialized ML networks. We show through simulation that ACOS-based deployments match the performance of fully provisioned packet-switched networks when training state-of-the-art LLMs at scale, while delivering significant cost savings using existing off-the-shelf OCSes, with strong bandwidth scaling and higher cost savings in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17449v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Amir, Ori Cohen, Jakob Krebs, Mark Silberstein</dc:creator>
    </item>
    <item>
      <title>HAP Networks for the Future: Applications in Sensing, Computing, and Communication</title>
      <link>https://arxiv.org/abs/2602.17534</link>
      <description>arXiv:2602.17534v1 Announce Type: new 
Abstract: High Altitude Platforms (HAPs) are a major advancement in non-terrestrial networks, offering broad coverage and unique capabilities. They form a vital link between satellite systems and terrestrial networks and play a key role in next-generation communication technologies. This study reviews HAP network applications, focusing on advanced airborne communications, integrated sensing, and airborne informatics. Our survey assesses the current state of HAP-centric applications by examining data processing, network performance, computational and storage requirements, economic feasibility, and regulatory challenges. The analysis highlights the evolving role of HAPs in global communication and identifies future research directions to support their deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17534v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sultan \c{C}o\u{g}ay (Department of Computer Engineering, Istanbul Technical University, Istanbul, Turkey), T. Tolga Sari (Department of Computer Engineering, Istanbul Technical University, Istanbul, Turkey), Muhammad Nadeem Ali (Department of Software and Communications Engineering, Hongik University, Sejong, South Korea), Byung-Seo Kim (Department of Software and Communications Engineering, Hongik University, Sejong, South Korea), G\"okhan Se\c{c}inti (Department of Computer Engineering, Istanbul Technical University, Istanbul, Turkey, BTS - Digital Twin Application and Research Center, Istanbul Technical University, Istanbul, Turkey)</dc:creator>
    </item>
    <item>
      <title>EDRP: Enhanced Dynamic Relay Point Protocol for Data Dissemination in Multi-hop Wireless IoT Networks</title>
      <link>https://arxiv.org/abs/2602.17619</link>
      <description>arXiv:2602.17619v1 Announce Type: new 
Abstract: Emerging IoT applications are transitioning from battery-powered to grid-powered nodes. DRP, a contention-based data dissemination protocol, was developed for these applications. Traditional contention-based protocols resolve collisions through control packet exchanges, significantly reducing goodput. DRP mitigates this issue by employing a distributed delay timer mechanism that assigns transmission-start delays based on the average link quality between a sender and its children, prioritizing highly connected nodes for early transmission. However, our in-field experiments reveal that DRP is unable to accommodate real-world link quality fluctuations, leading to overlapping transmissions from multiple senders. This overlap triggers CSMA's random back-off delays, ultimately degrading the goodput performance.
  To address these shortcomings, we first conduct a theoretical analysis that characterizes the design requirements induced by real-world link quality fluctuations and DRP's passive acknowledgments. Guided by this analysis, we design EDRP, which integrates two novel components: (i) Link-Quality Aware CSMA (LQ-CSMA) and (ii) a Machine Learning-based Block Size Selection (ML-BSS) algorithm for rateless codes. LQ-CSMA dynamically restricts the back-off delay range based on real-time link quality estimates, ensuring that nodes with stronger connectivity experience shorter delays. ML-BSS algorithm predicts future link quality conditions and optimally adjusts the block size for rateless coding, reducing overhead and enhancing goodput. In-field evaluations of EDRP demonstrate an average goodput improvement of 39.43\% than the competing protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17619v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jothi Prasanna Shanmuga Sundaram (Perry), Magzhan Gabidolla (Perry), Luis Fujarte (Perry), Shawn Duong (Perry), Jianlin Guo (Perry), Toshiaki Koike-Akino (Perry),  Pu (Perry),  Wang, Kieran Parsons, Philip V. Orlik, Takenori Sumi, Yukimasa Nagai, Miguel A. Carreira-Perpinan, Alberto E. Cerpa</dc:creator>
    </item>
    <item>
      <title>Attending to Routers Aids Indoor Wireless Localization</title>
      <link>https://arxiv.org/abs/2602.16762</link>
      <description>arXiv:2602.16762v1 Announce Type: cross 
Abstract: Modern machine learning-based wireless localization using Wi-Fi signals continues to face significant challenges in achieving groundbreaking performance across diverse environments. A major limitation is that most existing algorithms do not appropriately weight the information from different routers during aggregation, resulting in suboptimal convergence and reduced accuracy. Motivated by traditional weighted triangulation methods, this paper introduces the concept of attention to routers, ensuring that each router's contribution is weighted differently when aggregating information from multiple routers for triangulation. We demonstrate, by incorporating attention layers into a standard machine learning localization architecture, that emphasizing the relevance of each router can substantially improve overall performance. We have also shown through evaluation over the open-sourced datasets and demonstrate that Attention to Routers outperforms the benchmark architecture by over 30% in accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16762v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayush Roy, Tahsin Fuad Hassan, Roshan Ayyalasomayajula, Vishnu Suresh Lokhande</dc:creator>
    </item>
    <item>
      <title>On the Value of Base Station Motion Knowledge for Goal-Oriented Remote Monitoring with Energy-Harvesting Sensors</title>
      <link>https://arxiv.org/abs/2602.17247</link>
      <description>arXiv:2602.17247v1 Announce Type: cross 
Abstract: This paper investigates goal-oriented remote monitoring of an unobservable Markov source using energy-harvesting sensors that communicate with a mobile receiver, such as a Low Earth Orbit (LEO) satellite or Unmanned Aerial Vehicle (UAV). Unlike conventional systems that assume stationary base stations, the proposed framework explicitly accounts for receiver mobility, which induces time-varying channel characteristics modeled as a finite-state Markov process. The remote monitoring problem is formulated as a partially observable Markov decision process (POMDP), which is transformed into a tractable belief-state MDP and solved using relative value iteration to obtain optimal sampling and transmission policies. Two estimation strategies are considered: Maximum Likelihood (ML) and Minimum Mean Distortion (MMD). Numerical results demonstrate that incorporating receiver mobility and channel state information into the optimization reduces the average distortion by 10% to 42% compared to baseline policies and constant-channel assumptions, highlighting the importance of base station motion knowledge for effective goal-oriented communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17247v1</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sehani Siriwardana, Jean Michel de Souza Sant'Ana, Richard Demo Souza, Abolfazl Zakeri, Onel Luis Alcaraz L\'opez</dc:creator>
    </item>
    <item>
      <title>Trivance: Latency-Optimal AllReduce by Shortcutting Multiport Networks</title>
      <link>https://arxiv.org/abs/2602.17254</link>
      <description>arXiv:2602.17254v1 Announce Type: cross 
Abstract: AllReduce is a fundamental collective operation in distributed computing and a key performance bottleneck for large-scale training and inference. Its completion time is determined by the number of communication steps, which dominates latency-sensitive workloads, and the communication distance affecting both latency- and bandwidth-bound regimes. Direct-connect topologies, such as torus networks used in Google's TPUv4, are particularly prone to large communication distances due to limited bisection bandwidth. Latency-optimal algorithms such as Bruck's complete AllReduce in $\log_3 n$ steps on a bidirectional ring, but incur large communication distances that result in substantial congestion. In contrast, recent approaches such as Swing reduce communication distance and congestion, but are inherently required to perform $\log_2 n$ steps to complete AllReduce, sacrificing latency-optimality.
  In this paper, we present Trivance, a novel AllReduce algorithm that completes within $\log_3 n$ steps, while reducing congestion compared to Bruck's algorithm by a factor of three and preserving bandwidth-optimality. Trivance exploits both transmission ports of a bidirectional ring within each step to triple the communication distance along both directions simultaneously. Furthermore, by performing joint reductions, Trivance improves both the number of steps and network congestion. We further show that Trivance extends naturally to multidimensional torus networks, retaining its latency advantage while achieving performance comparable to bandwidth-optimal algorithms for large messages.
  Our empirical evaluation shows that Trivance improves state-of-the-art approaches by 5-30% for message sizes up to 8\,MiB, in high-bandwidth settings up to 32MiB and for 3D tori up to 128MiB. Throughout the evaluation, Trivance remains the best-performing latency-optimal algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17254v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anton Juerss, Vamsi Addanki, Stefan Schmid</dc:creator>
    </item>
    <item>
      <title>GraFSTNet: Graph-based Frequency SpatioTemporal Network for Cellular Traffic Prediction</title>
      <link>https://arxiv.org/abs/2602.13282</link>
      <description>arXiv:2602.13282v2 Announce Type: replace 
Abstract: With rapid expansion of cellular networks and the proliferation of mobile devices, cellular traffic data exhibits complex temporal dynamics and spatial correlations, posing challenges to accurate traffic prediction. Previous methods often focus predominantly on temporal modeling or depend on predefined spatial topologies, which limits their ability to jointly model spatio-temporal dependencies and effectively capture periodic patterns in cellular traffic. To address these issues, we propose a cellular traffic prediction framework that integrates spatio-temporal modeling with time-frequency analysis. First, we construct a spatial modeling branch to capture inter-cell dependencies through an attention mechanism, minimizing the reliance on predefined topological structures. Second, we build a time-frequency modeling branch to enhance the representation of periodic patterns. Furthermore, we introduce an adaptive-scale LogCosh loss function, which adjusts the error penalty based on traffic magnitude, preventing large errors from dominating the training process and helping the model maintain relatively stable prediction accuracy across different traffic intensities. Experiments on three open-sourced datasets demonstrate that the proposed method achieves prediction performance superior to state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13282v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyi Li, Hui Ma, Fei Xing, Chunjiong Zhang, Ming Yan</dc:creator>
    </item>
    <item>
      <title>Collection: UAV-Based Wireless Multi-modal Measurements from AERPAW Autonomous Data Mule (AADM) Challenge in Digital Twin and Real-World Environments</title>
      <link>https://arxiv.org/abs/2602.16163</link>
      <description>arXiv:2602.16163v2 Announce Type: replace 
Abstract: In this work, we present an unmanned aerial vehicle (UAV) wireless dataset collected as part of the AERPAW Autonomous Aerial Data Mule (AADM) challenge, organized by the NSF Aerial Experimentation and Research Platform for Advanced Wireless (AERPAW) project. The AADM challenge was the second competition in which an autonomous UAV acted as a data mule, where the UAV downloaded data from multiple base stations (BSs) in a dynamic wireless environment. Participating teams designed flight control and decision-making algorithms for choosing which BSs to communicate with and how to plan flight trajectories to maximize data download within a mission completion time. The competition was conducted in two stages: Stage 1 involved development and experimentation using a digital twin (DT) environment, and in Stage 2, the final test run was conducted on the outdoor testbed. The total score for each team was compiled from both stages. The resulting dataset includes link quality and data download measurements, both in DT and physical environments. Along with the USRP measurements used in the contest, the dataset also includes UAV telemetry, Keysight RF sensors position estimates, link quality measurements from LoRa receivers, and Fortem radar measurements. It supports reproducible research on autonomous UAV networking, multi-cell association and scheduling, air-to-ground propagation modeling, DT-to-real-world transfer learning, and integrated sensing and communication, which serves as a benchmark for future autonomous wireless experimentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16163v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Sharif Hossen, Cole Dickerson, Ozgur Ozdemir, Anil Gurses, Mohamed Rabeek Sarbudeen, Thomas Zajkowski, Ahmed Manavi Alam, Everett Tucker, William Bjorndahl, Fred Solis, Sadaf Javed, Anirudh Kamath, Xiangyao Tang, Joarder Jafor Sadique, Kevin Liu Hermstein, Kaies Al Mahmud, Jose Angel Sanchez Viloria, Skyler Hawkins, Yuqing Cui, Annoy Dey, Yuchen Liu, Ali Gurbuz, Joseph Camp, Rizwan Ahmad, Jacobus van der Merwe, Ahmed Ibrahim Mohamed, Gil Zussman, Mehmet Kurum, Namuduri Kamesh, Zhangyu Guan, Dimitris Pados, George Sklivanitis, Ismail Guvenc, Mihail Sichitiu, Magreth Mushi, Rudra Dutta</dc:creator>
    </item>
    <item>
      <title>Fast-MCS: A Scalable Open-Source Tool to Find Minimal Cut Sets</title>
      <link>https://arxiv.org/abs/2602.16686</link>
      <description>arXiv:2602.16686v2 Announce Type: replace 
Abstract: A network is represented as a graph consisting of nodes and edges. A cut set for a source-destination pair in a network is a set of elements that, when failed, cause the source-destination pair to lose connectivity. A Minimal Cut Set (MCS) is a cut set that cannot be further reduced while maintaining its status as a cut set. MCSs are crucial in identifying the critical elements in the network that have the most significant impact on failure. This work introduces Fast-MCS, an open-source, scalable tool for evaluating MCSs in large, complex networks. Additionally, we compare the computation time of Fast-MCS with the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16686v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shakthivelu Janardhanan, Yaxuan Chen, Wolfgang Kellerer, Carmen Mas-Machuca</dc:creator>
    </item>
  </channel>
</rss>
