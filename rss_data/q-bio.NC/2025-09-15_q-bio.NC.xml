<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Sep 2025 02:41:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>DCHO: A Decomposition-Composition Framework for Predicting Higher-Order Brain Connectivity to Enhance Diverse Downstream Applications</title>
      <link>https://arxiv.org/abs/2509.09696</link>
      <description>arXiv:2509.09696v1 Announce Type: new 
Abstract: Higher-order brain connectivity (HOBC), which captures interactions among three or more brain regions, provides richer organizational information than traditional pairwise functional connectivity (FC). Recent studies have begun to infer latent HOBC from noninvasive imaging data, but they mainly focus on static analyses, limiting their applicability in dynamic prediction tasks. To address this gap, we propose DCHO, a unified approach for modeling and forecasting the temporal evolution of HOBC based on a Decomposition-Composition framework, which is applicable to both non-predictive tasks (state classification) and predictive tasks (brain dynamics forecasting). DCHO adopts a decomposition-composition strategy that reformulates the prediction task into two manageable subproblems: HOBC inference and latent trajectory prediction. In the inference stage, we propose a dual-view encoder to extract multiscale topological features and a latent combinatorial learner to capture high-level HOBC information. In the forecasting stage, we introduce a latent-space prediction loss to enhance the modeling of temporal trajectories. Extensive experiments on multiple neuroimaging datasets demonstrate that DCHO achieves superior performance in both non-predictive tasks (state classification) and predictive tasks (brain dynamics forecasting), significantly outperforming existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09696v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weibin Li, Wendu Li, Quanying Liu</dc:creator>
    </item>
    <item>
      <title>Cerebellar Contributions to Action and Cognition: Prediction, Timescale, and Continuity</title>
      <link>https://arxiv.org/abs/2509.09818</link>
      <description>arXiv:2509.09818v1 Announce Type: new 
Abstract: The cerebellum is implicated in nearly every domain of human cognition, yet our understanding of how this subcortical structure contributes to cognition remains elusive. Efforts on this front have tended to fall into one of two camps. On one side are those who seek to identify a universal cerebellar transform, a single algorithm that can be applied across domains as diverse as sensorimotor learning, social cognition, and decision making. On the other side are those who focus on functional specializations tailored for different task domains. In this perspective, we propose an integrated approach, one that recognizes functional specialization across different cerebellar subregions, but also builds on common constraints that help define the conditions that engage the cerebellum. Drawing on recurring principles from the cerebellum's well-established role in motor control, we identify three core constraints: Prediction - the cerebellum performs anticipatory, not reactive, computations; Timescale - the cerebellum generates predictions limited to short intervals; and Continuity - the cerebellum transforms continuous representations such as space and time. Together, these constraints define the boundary conditions underlying when and how the cerebellum supports cognition, and, just as importantly, specify the types of computations that should not depend on the cerebellum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09818v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Tsay, Richard Ivry</dc:creator>
    </item>
    <item>
      <title>The nature of alpha modulation through neurofeedback</title>
      <link>https://arxiv.org/abs/2509.10046</link>
      <description>arXiv:2509.10046v1 Announce Type: new 
Abstract: Electroencephalographic neurofeedback (EEG-NF) has been proposed as a promising technique to modulate brain activity through real-time EEG-based feedback. Alpha neurofeedback in particular is believed to induce rapid self-regulation of brain rhythms, with applications in cognitive enhancement and clinical treatment. However, whether this modulation reflects specific volitional control or non-specific influences remains unresolved. In a preregistered, double-blind, sham-controlled study, we evaluated alpha upregulation in healthy participants receiving either genuine or sham EEG-NF during a single-session design. A third arm composed of a passive control group was also included to differentiate between non-specific influences related or not to the active engagement in EEG-NF. Throughout the session, alpha power increased robustly, yet independently of feedback veracity, engagement in self-regulation, or feedback update frequency. Parallel increases in theta and sensorimotor rhythms further suggest broadband non-specific modulation. Importantly, these results challenge the foundational assumption of EEG-NF: that feedback enables volitional EEG control. Instead, they point to spontaneous repetition-related processes as primary drivers, calling for a critical reassessment of neurofeedback efficacy and its underlying mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10046v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Maaz (CRPN), Laurent Waroquier (PsyCL\'E), Alexandra Dia (CRPN), V\'eronique Paban (LNIA, CRPN), Arnaud Rey (CRPN)</dc:creator>
    </item>
    <item>
      <title>Near-Hamiltonian dynamics and energy-like quantities of next-generation neural mass models</title>
      <link>https://arxiv.org/abs/2509.10428</link>
      <description>arXiv:2509.10428v1 Announce Type: new 
Abstract: Neural mass models describe the mean-field dynamics of populations of neurons. In this work we illustrate how fundamental ideas of physics, such as energy and conserved quantities, can be explored for such models. We show that time-rescaling renders recent next-generation neural mass models Hamiltonian in the limit of a homogeneous population or strong coupling. The corresponding energy-like quantity provides considerable insight into the model dynamics even in the case of heterogeneity, and explain for example why orbits are near-ellipsoidal and predict spike amplitude during bursting dynamics. We illustrate how these energy considerations provide a possible link between neuronal population behavior and energy landscape theory, which has been used to analyze data from brain recordings. Our introduction of near-Hamiltonian descriptions of neuronal activity could permit the application of highly developed physics theory to get insight into brain behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10428v1</guid>
      <category>q-bio.NC</category>
      <category>math.DS</category>
      <category>physics.class-ph</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniele Andrean, Morten Gram Pedersen</dc:creator>
    </item>
    <item>
      <title>Overground gait transitions are not sharp but involve gradually changing walk-run mixtures even over long distances</title>
      <link>https://arxiv.org/abs/2501.00720</link>
      <description>arXiv:2501.00720v3 Announce Type: replace 
Abstract: Humans typically walk at low speeds and run at higher speeds. Previous studies of transitions between walking and running were mostly on treadmills, but real-world locomotion allows more flexibility. Here, we study overground locomotion over long distances (800 m or 2400 m) under time constraints, simulating everyday scenarios like going to an appointment. Unlike on treadmills, participants can vary both speed and gait during this task. We find that gait transition in this overground task occurs over a broad `gait transition regime' spanning average speeds from 1.9 m/s to 3.0 m/s. In this regime, people use mixtures of walking and running: mostly walking at low average speeds (around 1.9 m/s) and mostly running at high average speeds (3.0 m/s); the walk vs run fraction gradually changes between these speed limits. Within any walk-run mixture, there is a speed gap between the walking and running. These gait mixtures and their specific structure are predicted by energy optimality. These findings extend earlier results from much shorter distance tasks, showing that similar energetic principles govern longer, more physically and cognitively demanding tasks. Overall, our results highlight the role of whole-task energy minimization including transients in shaping human locomotion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00720v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas S. Baker, Leroy Long, Manoj Srinivasan</dc:creator>
    </item>
    <item>
      <title>Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach</title>
      <link>https://arxiv.org/abs/2508.04435</link>
      <description>arXiv:2508.04435v2 Announce Type: replace 
Abstract: High-level theories rooted in the Bayesian Brain Hypothesis often frame cognitive effort as the cost of resolving the conflict between habits and optimal policies. In parallel, evidence accumulator models (EAMs) provide a mechanistic account of how effort arises from competition between the subjective values of available options. Although EAMs have been combined with frameworks like Reinforcement Learning to bridge the gap between high-level theories and process-level mechanisms, relatively less attention has been paid to their implications for a unified notion of cognitive effort. Here, we combine Active Inference (AIF) with the Drift-Diffusion Model (DDM) to investigate whether the resulting AIF-DDM can simultaneously account for effort arising from both habit violation and value discriminability. To our knowledge, this is the first time AIF has been combined with an EAM. We tested the AIF-DDM on a behavioral dataset from the two-step task and compared its predictions to an information-theoretic definition of cognitive effort based on AIF. The model's predictions successfully accounted for second-stage reaction times but failed to capture the dynamics of the first stage. We argue the latter discrepancy likely stems from the experimental design rather than a fundamental flaw in the model's assumptions about cognitive effort. Accordingly, we propose several modifications of the two-step task to better measure and isolate cognitive effort. Finally, we found that integrating the DDM significantly improved parameter recovery, which could help future studies to obtain more reliable parameter estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04435v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alvaro Garrido Perez, Viktor Lemoine, Amrapali Pednekar, Yara Khaluf, Pieter Simoens</dc:creator>
    </item>
    <item>
      <title>Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster</title>
      <link>https://arxiv.org/abs/2509.06426</link>
      <description>arXiv:2509.06426v2 Announce Type: replace 
Abstract: Computational models are critical to advance our understanding of how neural, biomechanical, and physical systems interact to orchestrate animal behaviors. Despite the availability of near-complete reconstructions of the Drosophila melanogaster central nervous system, musculature, and exoskeleton, anatomically and physically grounded models of fly leg muscles are still missing. These models provide an indispensable bridge between motor neuron activity and joint movements. Here, we introduce the first 3D, data-driven musculoskeletal model of Drosophila legs, implemented in both OpenSim and MuJoCo simulation environments. Our model incorporates a Hill-type muscle representation based on high-resolution X-ray scans from multiple fixed specimens. We present a pipeline for constructing muscle models using morphological imaging data and for optimizing unknown muscle parameters specific to the fly. We then combine our musculoskeletal models with detailed 3D pose estimation data from behaving flies to achieve muscle-actuated behavioral replay in OpenSim. Simulations of muscle activity across diverse walking and grooming behaviors predict coordinated muscle synergies that can be tested experimentally. Furthermore, by training imitation learning policies in MuJoCo, we test the effect of different passive joint properties on learning speed and find that damping and stiffness facilitate learning. Overall, our model enables the investigation of motor control in an experimentally tractable model organism, providing insights into how biomechanics contribute to generation of complex limb movements. Moreover, our model can be used to control embodied artificial agents to generate naturalistic and compliant locomotion in simulated environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06426v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pembe Gizem \"Ozdil, Chuanfang Ning, Jasper S. Phelps, Sibo Wang-Chen, Guy Elisha, Alexander Blanke, Auke Ijspeert, Pavan Ramdya</dc:creator>
    </item>
  </channel>
</rss>
