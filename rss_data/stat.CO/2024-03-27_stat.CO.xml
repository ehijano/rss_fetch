<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Mar 2024 04:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>baskexact: An R package for analytical calculation of basket trial operating characteristics</title>
      <link>https://arxiv.org/abs/2403.17510</link>
      <description>arXiv:2403.17510v1 Announce Type: new 
Abstract: Basket trials are a new type of clinical trial in which a treatment is investigated in several subgroups. For the analysis of these trials, information is shared between the subgroups based on the observed data to increase the power. Many approaches for the analysis of basket trials have been suggested, but only a few have been implemented in open source software packages. The R package baskexact facilitates the evaluation of two basket trial designs which use empirical Bayes techniques for sharing information. With baskexact, operating characteristics for single-stage and two-stage designs can be calculated analytically and optimal tuning parameters can be selected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17510v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Baumann</dc:creator>
    </item>
    <item>
      <title>Statistical Inference on Hierarchical Simultaneous Autoregressive Models with Missing Data</title>
      <link>https://arxiv.org/abs/2403.17257</link>
      <description>arXiv:2403.17257v1 Announce Type: cross 
Abstract: Efficient estimation methods for simultaneous autoregressive (SAR) models with missing data in the response variable have been well-developed in the literature. It is common practice to introduce a measurement error into SAR models. The measurement error serves to distinguish the noise component from the spatial process. However, the previous literature has not considered adding a measurement error to the SAR models with missing data. The maximum likelihood estimation for such models with large datasets is challenging and computationally expensive. This paper proposes two efficient likelihood-based estimation methods: the marginal maximum likelihood (ML) and expectation-maximisation (EM) algorithms for estimating SAR models with both measurement errors and missing data in the response variable. The spatial error model (SEM) and the spatial autoregressive model (SAM), two popular SAR model types, are considered. The missing data mechanism is assumed to follow missing at random (MAR). While naive calculation approaches lead to computational complexities of $O(n^3)$, where n is the total number of observations, our computational approaches for both the marginal ML and EM algorithms are designed to reduce the computational complexity. The performance of the proposed methods is investigated empirically using simulated and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17257v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anjana Wijayawardhana, Thomas Suesse, David Gunawan</dc:creator>
    </item>
    <item>
      <title>A location Invariant Statistic-Based Consistent Estimation Method for Three-Parameter Generalized Exponential Distribution</title>
      <link>https://arxiv.org/abs/2403.17609</link>
      <description>arXiv:2403.17609v1 Announce Type: cross 
Abstract: In numerous instances, the generalized exponential distribution can be used as an alternative to the gamma distribution or the Weibull distribution when analyzing lifetime or skewed data. This article offers a consistent method for estimating the parameters of a three-parameter generalized exponential distribution that sidesteps the issue of an unbounded likelihood function. The method is hinged on a maximum likelihood estimation of shape and scale parameters that uses a location-invariant statistic. Important estimator properties, such as uniqueness and consistency, are demonstrated. In addition, quantile estimates for the lifetime distribution are provided. We present a Monte Carlo simulation study along with comparisons to a number of well-known estimation techniques in terms of bias and root mean square error. For illustrative purposes, a real-world lifetime data set is analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17609v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiran Prajapat, Sharmishtha Mitra, Debasis Kundu</dc:creator>
    </item>
    <item>
      <title>Manifold-Guided Lyapunov Control with Diffusion Models</title>
      <link>https://arxiv.org/abs/2403.17692</link>
      <description>arXiv:2403.17692v1 Announce Type: cross 
Abstract: This paper presents a novel approach to generating stabilizing controllers for a large class of dynamical systems using diffusion models. The core objective is to develop stabilizing control functions by identifying the closest asymptotically stable vector field relative to a predetermined manifold and adjusting the control function based on this finding. To achieve this, we employ a diffusion model trained on pairs consisting of asymptotically stable vector fields and their corresponding Lyapunov functions. Our numerical results demonstrate that this pre-trained model can achieve stabilization over previously unseen systems efficiently and rapidly, showcasing the potential of our approach in fast zero-shot control and generalizability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17692v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amartya Mukherjee, Thanin Quartz, Jun Liu</dc:creator>
    </item>
    <item>
      <title>Inverse Uncertainty Quantification by Hierarchical Bayesian Modeling and Application in Nuclear System Thermal-Hydraulics Codes</title>
      <link>https://arxiv.org/abs/2305.16622</link>
      <description>arXiv:2305.16622v3 Announce Type: replace 
Abstract: Inverse Uncertainty Quantification (IUQ) method has been widely used to quantify the uncertainty of Physical Model Parameters (PMPs) in nuclear Thermal Hydraulics (TH) systems. This paper introduces a novel hierarchical Bayesian model which aims to mitigate two existing challenges in IUQ: the high variability of PMPs under varying experimental conditions, and unknown model discrepancies or outliers causing over-fitting issues.
  The proposed hierarchical model is compared with the conventional single-level Bayesian model using TRACE code and the measured void fraction data in the BFBT benchmark. A Hamiltonian Monte Carlo Method - No U-Turn Sampler (NUTS) is used for posterior sampling. The results demonstrate the effectiveness of the proposed hierarchical model in providing better estimates of the posterior distributions of PMPs and being less prone to over-fitting. The proposed method also demonstrates a promising approach for generalizing IUQ to larger databases with broad ranges of experimental conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16622v3</guid>
      <category>stat.CO</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Wang, Xu Wu, Tomasz Kozlowski</dc:creator>
    </item>
    <item>
      <title>A Practical Introduction to Regression Discontinuity Designs: Extensions</title>
      <link>https://arxiv.org/abs/2301.08958</link>
      <description>arXiv:2301.08958v2 Announce Type: replace-cross 
Abstract: This monograph, together with its accompanying first part Cattaneo, Idrobo and Titiunik (2020), collects and expands the instructional materials we prepared for more than $50$ short courses and workshops on Regression Discontinuity (RD) methodology that we taught between 2014 and 2023. In this second monograph, we discuss several topics in RD methodology that build on and extend the analysis of RD designs introduced in Cattaneo, Idrobo and Titiunik (2020). Our first goal is to present an alternative RD conceptual framework based on local randomization ideas. This methodological approach can be useful in RD designs with discretely-valued scores, and can also be used more broadly as a complement to the continuity-based approach in other settings. Then, employing both continuity-based and local randomization approaches, we extend the canonical Sharp RD design in multiple directions: fuzzy RD designs, RD designs with discrete scores, and multi-dimensional RD designs. The goal of our two-part monograph is purposely practical and hence we focus on the empirical analysis of RD designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08958v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1017/9781009441896</arxiv:DOI>
      <dc:creator>Matias D. Cattaneo, Nicolas Idrobo, Rocio Titiunik</dc:creator>
    </item>
    <item>
      <title>Estimation of Long-Range Dependent Models with Missing Data: to Impute or not to Impute?</title>
      <link>https://arxiv.org/abs/2303.04754</link>
      <description>arXiv:2303.04754v2 Announce Type: replace-cross 
Abstract: Among the most important models for long-range dependent time series is the class of ARFIMA$(p,d,q)$ (Autoregressive Fractionally Integrated Moving Average) models. Estimating the long-range dependence parameter $d$ in ARFIMA models is a well-studied problem, but the literature regarding the estimation of $d$ in the presence of missing data is very sparse. There are two basic approaches to dealing with the problem: missing data can be imputed using some plausible method, and then the estimation can proceed as if no data were missing, or we can use a specially tailored methodology to estimate $d$ in the presence of missing data. In this work, we review some of the methods available for both approaches and compare them through a Monte Carlo simulation study. We present a comparison among 35 different setups to estimate $d$, under tenths of different scenarios, considering percentages of missing data ranging from as few as 10\% up to 70\% and several levels of dependence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.04754v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guilherme Pumi, Gladys Choque Ulloa, Taiane Schaedler Prass</dc:creator>
    </item>
    <item>
      <title>Electron-Tunnelling-Noise Programmable Random Variate Accelerator for Monte Carlo Sampling</title>
      <link>https://arxiv.org/abs/2403.16421</link>
      <description>arXiv:2403.16421v2 Announce Type: replace-cross 
Abstract: This article presents an electron tunneling noise programmable random variate accelerator for accelerating the sampling stage of Monte Carlo simulations. We used the LiteX framework to generate a FemtoRV imfc RISC-V instruction set soft processor and deploy it on a Digilent Arty-100T FPGA development board. The RISC-V soft processor augmented with our programmable random variate accelerator achieves an average speedup of 8.70 times and a median speedup of 8.68 times for a suite of twelve different benchmark applications when compared to GNU Scientific Library software random number generation. These speedups are achievable because the benchmarks spend an average of 90.0 % of their execution time generating random samples. The results of the Monte Carlo benchmark programs run over the programmable random variate accelerator have an average Wasserstein distance of 1.48 times and a median Wasserstein distance of 1.41 times$that of the results produced by the GNU Scientific Library random number generators. The soft processor samples the electron tunneling noise source using the hardened XADC block in the FPGA. The flexibility of the LiteX framework allows for the deployment of any LiteX-supported soft processor with an electron tunneling noise programmable random variate accelerator on any LiteX-supported development board that contains an FPGA with an XADC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16421v2</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>physics.comp-ph</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James T. Meech, Vasileios Tsoutsouras, Phillip Stanley-Marbell</dc:creator>
    </item>
    <item>
      <title>Adaptive Frequency Bin Interval in FFT via Dense Sampling Factor $\alpha$</title>
      <link>https://arxiv.org/abs/2403.16665</link>
      <description>arXiv:2403.16665v2 Announce Type: replace-cross 
Abstract: The Fast Fourier Transform (FFT) is a fundamental tool for signal analysis, widely used across various fields. However, traditional FFT methods encounter challenges in adjusting the frequency bin interval, which may impede accurate spectral analysis. In this study, we propose a method for adjusting the frequency bin interval in FFT by introducing a parameter $\alpha$. We elucidate the underlying principles of the proposed method and discuss its potential applications across various contexts. Our findings suggest that the proposed method offers a promising approach to overcome the limitations of traditional FFT methods and enhance spectral analysis accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16665v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>eess.SP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haichao Xu</dc:creator>
    </item>
  </channel>
</rss>
