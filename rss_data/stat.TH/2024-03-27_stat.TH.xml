<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Mar 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Statistical inference for multi-regime threshold Ornstein-Uhlenbeck processes</title>
      <link>https://arxiv.org/abs/2403.18255</link>
      <description>arXiv:2403.18255v1 Announce Type: new 
Abstract: In this paper, we investigate the parameter estimation for threshold Ornstein$\mathit{-}$Uhlenbeck processes. Least squares method is used to obtain continuous-type and discrete-type estimators for the drift parameters based on continuous and discrete observations, respectively. The strong consistency and asymptotic normality of the proposed least squares estimators are studied. We also propose a modified quadratic variation estimator based on the long-time observations for the diffusion parameters and prove its consistency. Our simulation results suggest that the performance of our proposed estimators for the drift parameters may show improvements compared to generalized moment estimators. Additionally, the proposed modified quadratic variation estimator exhibits potential advantages over the usual quadratic variation estimator with relatively small sample sizes. In particular, our method can be applied to the multi-regime cases ($m&gt;2$), while the generalized moment method only deals with the two regime cases ($m=2$). The U.S. treasury rate data is used to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18255v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuecai Han, Dingwen Zhang</dc:creator>
    </item>
    <item>
      <title>Early Stopping for Ensemble Kalman-Bucy Inversion</title>
      <link>https://arxiv.org/abs/2403.18353</link>
      <description>arXiv:2403.18353v1 Announce Type: new 
Abstract: Bayesian linear inverse problems aim to recover an unknown signal from noisy observations, incorporating prior knowledge. This paper analyses a data dependent method to choose the scale parameter of a Gaussian prior. The method we study arises from early stopping methods, which have been successfully applied to a range of problems for statistical inverse problems in the frequentist setting. These results are extended to the Bayesian setting. We study the use of a discrepancy based stopping rule in the setting of random noise. Our proposed stopping rule results in optimal rates under certain conditions on the prior covariance operator. We furthermore derive for which class of signals this method is adaptive. It is also shown that the associated posterior contracts at the optimal rate and provides a conservative measure of uncertainty. We implement the proposed stopping rule using the continuous-time ensemble Kalman--Bucy filter (EnKBF). The fictitious time parameter replaces the scale parameter, and the ensemble size is appropriately adjusted in order to not lose statistical optimality of the computed estimator. The EnKBF, then, gives a continuous process from the prior distribution to the posterior which is terminated using the proposed stopping rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18353v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maia Tienstra</dc:creator>
    </item>
    <item>
      <title>Minimax density estimation in the adversarial framework under local differential privacy</title>
      <link>https://arxiv.org/abs/2403.18357</link>
      <description>arXiv:2403.18357v1 Announce Type: new 
Abstract: We consider the problem of nonparametric density estimation under privacy constraints in an adversarial framework. To this end, we study minimax rates under local differential privacy over Sobolev spaces. We first obtain a lower bound  which allows us to quantify the impact of privacy compared with the classical framework. Next, we introduce a new Coordinate block privacy mechanism that guarantees local differential privacy, which, coupled with a projection estimator, achieves the minimax optimal rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18357v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M\'elisande Albert (IMT, INSA Toulouse), Juliette Chevallier (IMT, INSA Toulouse), B\'eatrice Laurent (INSA Toulouse, IMT), Ousmane Sacko (UPN, MODAL'X)</dc:creator>
    </item>
    <item>
      <title>Poisson Regression in one Covariate on Massive Data</title>
      <link>https://arxiv.org/abs/2403.18432</link>
      <description>arXiv:2403.18432v1 Announce Type: new 
Abstract: The goal of subsampling is to select an informative subset of all observations, when using the full data for statistical analysis is not viable. We construct locally $ D $-optimal subsampling designs under a Poisson regression model with a log link in one covariate. A Representation of the support of locally $ D $-optimal subsampling designs is established. We make statements on scale-location transformations of the covariate that require a simultaneous transformation of the regression parameter. The performance of the methods is demonstrated by illustrating examples. To show the advantage of the optimal subsampling designs, we examine the efficiency of uniform random subsampling as well as of two heuristic designs. Further, the efficiency of locally $ D $-optimal subsampling designs is studied when the parameter is misspecified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18432v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Torsten Reuter, Rainer Schwabe</dc:creator>
    </item>
    <item>
      <title>Theoretical Guarantees for the Subspace-Constrained Tyler's Estimator</title>
      <link>https://arxiv.org/abs/2403.18658</link>
      <description>arXiv:2403.18658v1 Announce Type: new 
Abstract: This work analyzes the subspace-constrained Tyler's estimator (STE) designed for recovering a low-dimensional subspace within a dataset that may be highly corrupted with outliers. It assumes a weak inlier-outlier model and allows the fraction of inliers to be smaller than a fraction that leads to computational hardness of the robust subspace recovery problem. It shows that in this setting, if the initialization of STE, which is an iterative algorithm, satisfies a certain condition, then STE can effectively recover the underlying subspace. It further shows that under the generalized haystack model, STE initialized by the Tyler's M-estimator (TME), can recover the subspace when the fraction of iniliers is too small for TME to handle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18658v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gilad Lerman, Feng Yu, Teng Zhang</dc:creator>
    </item>
    <item>
      <title>Beyond boundaries: Gary Lorden's groundbreaking contributions to sequential analysis</title>
      <link>https://arxiv.org/abs/2403.18782</link>
      <description>arXiv:2403.18782v1 Announce Type: new 
Abstract: Gary Lorden provided a number of fundamental and novel insights to sequential hypothesis testing and changepoint detection. In this article we provide an overview of Lorden's contributions in the context of existing results in those areas, and some extensions made possible by Lorden's work, mentioning also areas of application including threat detection in physical-computer systems, near-Earth space informatics, epidemiology, clinical trials, and finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18782v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jay Bartroff, Alexander G. Tartakovsky</dc:creator>
    </item>
    <item>
      <title>A Correction of Pseudo Log-Likelihood Method</title>
      <link>https://arxiv.org/abs/2403.18127</link>
      <description>arXiv:2403.18127v1 Announce Type: cross 
Abstract: Pseudo log-likelihood is a type of maximum likelihood estimation (MLE) method used in various fields including contextual bandits, influence maximization of social networks, and causal bandits. However, in previous literature \citep{li2017provably, zhang2022online, xiong2022combinatorial, feng2023combinatorial1, feng2023combinatorial2}, the log-likelihood function may not be bounded, which may result in the algorithm they proposed not well-defined. In this paper, we give a counterexample that the maximum pseudo log-likelihood estimation fails and then provide a solution to correct the algorithms in \citep{li2017provably, zhang2022online, xiong2022combinatorial, feng2023combinatorial1, feng2023combinatorial2}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18127v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shi Feng, Nuoya Xiong, Zhijie Zhang, Wei Chen</dc:creator>
    </item>
    <item>
      <title>Minimax Optimal Fair Classification with Bounded Demographic Disparity</title>
      <link>https://arxiv.org/abs/2403.18216</link>
      <description>arXiv:2403.18216v1 Announce Type: cross 
Abstract: Mitigating the disparate impact of statistical machine learning methods is crucial for ensuring fairness. While extensive research aims to reduce disparity, the effect of using a \emph{finite dataset} -- as opposed to the entire population -- remains unclear. This paper explores the statistical foundations of fair binary classification with two protected groups, focusing on controlling demographic disparity, defined as the difference in acceptance rates between the groups. Although fairness may come at the cost of accuracy even with infinite data, we show that using a finite sample incurs additional costs due to the need to estimate group-specific acceptance thresholds. We study the minimax optimal classification error while constraining demographic disparity to a user-specified threshold. To quantify the impact of fairness constraints, we introduce a novel measure called \emph{fairness-aware excess risk} and derive a minimax lower bound on this measure that all classifiers must satisfy. Furthermore, we propose FairBayes-DDP+, a group-wise thresholding method with an offset that we show attains the minimax lower bound. Our lower bound proofs involve several innovations. Experiments support that FairBayes-DDP+ controls disparity at the user-specified level, while being faster and having a more favorable fairness-accuracy tradeoff than several baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18216v1</guid>
      <category>stat.ML</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianli Zeng, Guang Cheng, Edgar Dobriban</dc:creator>
    </item>
    <item>
      <title>Representatividad Muestral en la Incertidumbre Sim\'etrica Multivariada para la Selecci\'on de Atributos</title>
      <link>https://arxiv.org/abs/2403.18685</link>
      <description>arXiv:2403.18685v1 Announce Type: cross 
Abstract: In this work, we analyze the behavior of the multivariate symmetric uncertainty (MSU) measure through the use of statistical simulation techniques under various mixes of informative and non-informative randomly generated features. Experiments show how the number of attributes, their cardinalities, and the sample size affect the MSU. In this thesis, through observation of results, it is proposed an heuristic condition that preserves good quality in the MSU under different combinations of these three factors, providing a new useful criterion to help drive the process of dimension reduction.
  --
  En el presente trabajo hemos analizado el comportamiento de una versi\'on multivariada de la incertidumbre sim\'etrica a trav\'es de t\'ecnicas de simulaci\'on estad\'isticas sobre varias combinaciones de atributos informativos y no-informativos generados de forma aleatoria. Los experimentos muestran como el n\'umero de atributos, sus cardinalidades y el tama\~no muestral afectan al MSU como medida. En esta tesis, mediante la observaci\'on de resultados hemos propuesto una condici\'on que preserva una buena calidad en el MSU bajo diferentes combinaciones de los tres factores mencionados, lo cual provee un nuevo y valioso criterio para llevar a cabo el proceso de reducci\'on de dimensionalidad.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18685v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gustavo Sosa-Cabrera</dc:creator>
    </item>
    <item>
      <title>Functional linear and single-index models: A unified approach via Gaussian Stein identity</title>
      <link>https://arxiv.org/abs/2206.03975</link>
      <description>arXiv:2206.03975v2 Announce Type: replace 
Abstract: Functional linear and single-index models are core regression methods in functional data analysis and are widely used for performing regression in a wide range of applications when the covariates are random functions coupled with scalar responses. In the existing literature, however, the construction of associated estimators and the study of their theoretical properties is invariably carried out on a case-by-case basis for specific models under consideration. In this work, assuming the predictors are Gaussian processes, we provide a unified methodological and theoretical framework for estimating the index in functional linear, and its direction in single-index models. In the latter case, the proposed approach does not require the specification of the link function. In terms of methodology, we show that the reproducing kernel Hilbert space (RKHS) based functional linear least-squares estimator, when viewed through the lens of an infinite-dimensional Gaussian Stein's identity, also provides an estimator of the index of the single-index model. Theoretically, we characterize the convergence rates of the proposed estimators for both linear and single-index models. Our analysis has several key advantages: (i) it does not require restrictive commutativity assumptions for the covariance operator of the random covariates and the integral operator associated with the reproducing kernel; and (ii) the true index parameter can lie outside of the chosen RKHS, thereby allowing for index misspecification as well as for quantifying the degree of such index misspecification. Several existing results emerge as special cases of our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.03975v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnakumar Balasubramanian, Hans-Georg M\"uller, Bharath K. Sriperumbudur</dc:creator>
    </item>
    <item>
      <title>A nonparametric test for elliptical distribution based on kernel embedding of probabilities</title>
      <link>https://arxiv.org/abs/2306.10594</link>
      <description>arXiv:2306.10594v2 Announce Type: replace 
Abstract: Elliptical distribution is a basic assumption underlying many multivariate statistical methods. For example, in sufficient dimension reduction and statistical graphical models, this assumption is routinely imposed to simplify the data dependence structure. Before applying such methods, we need to decide whether the data are elliptically distributed. Currently existing tests either focus exclusively on spherical distributions, or rely on bootstrap to determine the null distribution, or require specific forms of the alternative distribution. In this paper, we introduce a general nonparametric test for elliptical distribution based on kernel embedding of the probability measure that embodies the two properties that characterize an elliptical distribution: namely, after centering and rescaling, (1) the direction and length of the random vector are independent, and (2) the directional vector is uniformly distributed on the unit sphere. We derive the asymptotic distributions of the test statistic via von-Mises expansion, develop the sample-level procedure to determine the rejection region, and establish the consistency and validity of the proposed test. We also develop the concentration bounds of the test statistic, allowing the dimension to grow with the sample size, and further establish the consistency in this high-dimension setting. We compare our method with several existing methods via simulation studies, and apply our test to a SENIC dataset with and without a transformation aimed to achieve ellipticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10594v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yin Tang, Bing Li</dc:creator>
    </item>
    <item>
      <title>A log-linear model for non-stationary time series of counts</title>
      <link>https://arxiv.org/abs/2307.01315</link>
      <description>arXiv:2307.01315v2 Announce Type: replace 
Abstract: We propose a new model for nonstationary integer-valued time series which is particularly suitable for data with a strong trend. In contrast to popular Poisson-INGARCH models, but in line with classical GARCH models, we propose to pick the conditional distributions from nearly scale invariant families where the mean absolute value and the standard deviation are of the same order of magnitude. As an important prerequisite for applications in statistics, we prove absolute regularity of the count process with exponentially decaying coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01315v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anne Leucht, Michael H. Neumann</dc:creator>
    </item>
    <item>
      <title>Stability of Sequential Lateration and of Stress Minimization in the Presence of Noise</title>
      <link>https://arxiv.org/abs/2310.10900</link>
      <description>arXiv:2310.10900v2 Announce Type: replace 
Abstract: Sequential lateration is a class of methods for multidimensional scaling where a suitable subset of nodes is first embedded by some method, e.g., a clique embedded by classical scaling, and then the remaining nodes are recursively embedded by lateration. A graph is a lateration graph when it can be embedded by such a procedure. We provide a stability result for a particular variant of sequential lateration. We do so in a setting where the dissimilarities represent noisy Euclidean distances between nodes in a geometric lateration graph. We then deduce, as a corollary, a perturbation bound for stress minimization. To argue that our setting applies broadly, we show that a (large) random geometric graph is a lateration graph with high probability under mild conditions, extending a previous result of Aspnes et al (2006).</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10900v2</guid>
      <category>math.ST</category>
      <category>cs.NI</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ery Arias-Castro, Siddharth Vishwanath</dc:creator>
    </item>
    <item>
      <title>Frequentist Guarantees of Distributed (Non)-Bayesian Inference</title>
      <link>https://arxiv.org/abs/2311.08214</link>
      <description>arXiv:2311.08214v2 Announce Type: replace 
Abstract: Motivated by the need to analyze large, decentralized datasets, distributed Bayesian inference has become a critical research area across multiple fields, including statistics, electrical engineering, and economics. This paper establishes Frequentist properties, such as posterior consistency, asymptotic normality, and posterior contraction rates, for the distributed (non-)Bayes Inference problem among agents connected via a communication network. Our results show that, under appropriate assumptions on the communication graph, distributed Bayesian inference retains parametric efficiency while enhancing robustness in uncertainty quantification. We also explore the trade-off between statistical efficiency and communication efficiency by examining how the design and size of the communication graph impact the posterior contraction rate. Furthermore, We extend our analysis to time-varying graphs and apply our results to exponential family models, distributed logistic regression, and decentralized detection models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08214v2</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bohan Wu, C\'esar A. Uribe</dc:creator>
    </item>
    <item>
      <title>Log-rank test with coarsened exact matching</title>
      <link>https://arxiv.org/abs/2403.16121</link>
      <description>arXiv:2403.16121v2 Announce Type: replace 
Abstract: It is of special importance in the clinical trial to compare survival times between the treatment group and the control group. Propensity score methods with a logistic regression model are often used to reduce the effects of confounders. However, the modeling of complex structures between the covariates, the treatment assignment and the survival time is difficult. In this paper, we consider coarsened exact matching (CEM), which does not need any parametric models, and we propose the weighted log-rank statistic based on CEM. We derive asymptotic properties of the weighted log-rank statistic, such as the weak convergence to a Gaussian process in Skorokhod space, in particular the asymptotic normality, under the null hypothesis and the consistency of the log-rank test. Simulation studies show that the log-rank statistic based on CEM is more robust than the log-rank statistic based on the propensity score.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16121v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Baba, Nakahiro Yoshida</dc:creator>
    </item>
    <item>
      <title>Asymptotics of predictive distributions driven by sample means and variances</title>
      <link>https://arxiv.org/abs/2403.16828</link>
      <description>arXiv:2403.16828v2 Announce Type: replace 
Abstract: Let $\alpha_n(\cdot)=P\bigl(X_{n+1}\in\cdot\mid X_1,\ldots,X_n\bigr)$ be the predictive distributions of a sequence $(X_1,X_2,\ldots)$ of $p$-variate random variables. Suppose $$\alpha_n=\mathcal{N}_p(M_n,Q_n)$$ where $M_n=\frac{1}{n}\sum_{i=1}^nX_i$ and $Q_n=\frac{1}{n}\sum_{i=1}^n(X_i-M_n)(X_i-M_n)^t$. Then, there is a random probability measure $\alpha$ on $\mathbb{R}^p$ such that $\alpha_n\rightarrow\alpha$ weakly a.s. If $p\in\{1,2\}$, one also obtains $\lVert\alpha_n-\alpha\rVert\overset{a.s.}\longrightarrow 0$ where $\lVert\cdot\rVert$ is total variation distance. Moreover, the convergence rate of $\lVert\alpha_n-\alpha\rVert$ is arbitrarily close to $n^{-1/2}$. These results (apart from the one regarding the convergence rate) still apply even if $\alpha_n=\mathcal{L}_p(M_n,Q_n)$, where $\mathcal{L}_p$ belongs to a class of distributions much larger than the normal. Finally, the asymptotic behavior of copula-based predictive distributions (introduced in [13]) is investigated and a numerical experiment is performed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16828v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuele Garelli, Fabrizio Leisen, Luca Pratelli, Pietro Rigo</dc:creator>
    </item>
    <item>
      <title>Selective inference using randomized group lasso estimators for general models</title>
      <link>https://arxiv.org/abs/2306.13829</link>
      <description>arXiv:2306.13829v3 Announce Type: replace-cross 
Abstract: Selective inference methods are developed for group lasso estimators for use with a wide class of distributions and loss functions. The method includes the use of exponential family distributions, as well as quasi-likelihood modeling for overdispersed count data, for example, and allows for categorical or grouped covariates as well as continuous covariates. A randomized group-regularized optimization problem is studied. The added randomization allows us to construct a post-selection likelihood which we show to be adequate for selective inference when conditioning on the event of the selection of the grouped covariates. This likelihood also provides a selective point estimator, accounting for the selection by the group lasso. Confidence regions for the regression parameters in the selected model take the form of Wald-type regions and are shown to have bounded volume. The selective inference method for grouped lasso is illustrated on data from the national health and nutrition examination survey while simulations showcase its behaviour and favorable comparison with other methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13829v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiling Huang, Sarah Pirenne, Snigdha Panigrahi, Gerda Claeskens</dc:creator>
    </item>
    <item>
      <title>Generalization Bounds: Perspectives from Information Theory and PAC-Bayes</title>
      <link>https://arxiv.org/abs/2309.04381</link>
      <description>arXiv:2309.04381v2 Announce Type: replace-cross 
Abstract: A fundamental question in theoretical machine learning is generalization. Over the past decades, the PAC-Bayesian approach has been established as a flexible framework to address the generalization capabilities of machine learning algorithms, and design new ones. Recently, it has garnered increased interest due to its potential applicability for a variety of learning algorithms, including deep neural networks. In parallel, an information-theoretic view of generalization has developed, wherein the relation between generalization and various information measures has been established. This framework is intimately connected to the PAC-Bayesian approach, and a number of results have been independently discovered in both strands. In this monograph, we highlight this strong connection and present a unified treatment of PAC-Bayesian and information-theoretic generalization bounds. We present techniques and results that the two perspectives have in common, and discuss the approaches and interpretations that differ. In particular, we demonstrate how many proofs in the area share a modular structure, through which the underlying ideas can be intuited. We pay special attention to the conditional mutual information (CMI) framework; analytical studies of the information complexity of learning algorithms; and the application of the proposed methods to deep learning. This monograph is intended to provide a comprehensive introduction to information-theoretic generalization bounds and their connection to PAC-Bayes, serving as a foundation from which the most recent developments are accessible. It is aimed broadly towards researchers with an interest in generalization and theoretical machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.04381v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fredrik Hellstr\"om, Giuseppe Durisi, Benjamin Guedj, Maxim Raginsky</dc:creator>
    </item>
    <item>
      <title>Modeling lower-truncated and right-censored insurance claims with an extension of the MBBEFD class</title>
      <link>https://arxiv.org/abs/2310.11471</link>
      <description>arXiv:2310.11471v2 Announce Type: replace-cross 
Abstract: In general insurance, claims are often lower-truncated and right-censored because insurance contracts may involve deductibles and maximal covers. Most classical statistical models are not (directly) suited to model lower-truncated and right-censored claims. A surprisingly flexible family of distributions that can cope with lower-truncated and right-censored claims is the class of MBBEFD distributions that originally has been introduced by Bernegger (1997) for reinsurance pricing, but which has not gained much attention outside the reinsurance literature. Interestingly, in general insurance, we mainly rely on unimodal skewed densities, whereas the reinsurance literature typically proposes monotonically decreasing densities within the MBBEFD class. We show that this class contains both types of densities, and we extend it to a bigger family of distribution functions suitable for modeling lower-truncated and right-censored claims. In addition, we discuss how changes in the deductible or the maximal cover affect the chosen distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11471v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Selim Gatti, Mario V. W\"uthrich</dc:creator>
    </item>
    <item>
      <title>Partial Information Decomposition for Continuous Variables based on Shared Exclusions: Analytical Formulation and Estimation</title>
      <link>https://arxiv.org/abs/2311.06373</link>
      <description>arXiv:2311.06373v3 Announce Type: replace-cross 
Abstract: Describing statistical dependencies is foundational to empirical scientific research. For uncovering intricate and possibly non-linear dependencies between a single target variable and several source variables within a system, a principled and versatile framework can be found in the theory of Partial Information Decomposition (PID). Nevertheless, the majority of existing PID measures are restricted to categorical variables, while many systems of interest in science are continuous. In this paper, we present a novel analytic formulation for continuous redundancy--a generalization of mutual information--drawing inspiration from the concept of shared exclusions in probability space as in the discrete PID definition of $I^\mathrm{sx}_\cap$. Furthermore, we introduce a nearest-neighbor based estimator for continuous PID, and showcase its effectiveness by applying it to a simulated energy management system provided by the Honda Research Institute Europe GmbH. This work bridges the gap between the measure-theoretically postulated existence proofs for a continuous $I^\mathrm{sx}_\cap$ and its practical application to real-world scientific problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06373v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David A. Ehrlich, Kyle Schick-Poland, Abdullah Makkeh, Felix Lanfermann, Patricia Wollstadt, Michael Wibral</dc:creator>
    </item>
  </channel>
</rss>
