<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Dec 2025 05:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>TreeVQA: A Tree-Structured Execution Framework for Shot Reduction in Variational Quantum Algorithms</title>
      <link>https://arxiv.org/abs/2512.12068</link>
      <description>arXiv:2512.12068v1 Announce Type: cross 
Abstract: Variational Quantum Algorithms (VQAs) are promising for near- and intermediate-term quantum computing, but their execution cost is substantial. Each task requires many iterations and numerous circuits per iteration, and real-world applications often involve multiple tasks, scaling with the precision needed to explore the application's energy landscape. This demands an enormous number of execution shots, making practical use prohibitively expensive. We observe that VQA costs can be significantly reduced by exploiting execution similarities across an application's tasks. Based on this insight, we propose TreeVQA, a tree-based execution framework that begins by executing tasks jointly and progressively branches only as their quantum executions diverge. Implemented as a VQA wrapper, TreeVQA integrates with typical VQA applications. Evaluations on scientific and combinatorial benchmarks show shot count reductions of $25.9\times$ on average and over $100\times$ for large-scale problems at the same target accuracy. The benefits grow further with increasing problem size and precision requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12068v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuewen Hou, Dhanvi Bharadwaj, Gokul Subramanian Ravi</dc:creator>
    </item>
    <item>
      <title>The PPKN Gate: An Optimal 1-Toffoli Input-Preserving Full Adder for Quantum Arithmetic</title>
      <link>https://arxiv.org/abs/2512.12073</link>
      <description>arXiv:2512.12073v1 Announce Type: cross 
Abstract: Efficient arithmetic operations are a prerequisite for practical quantum computing. Optimization efforts focus on two primary metrics: Quantum Cost (QC), determined by the number of non-linear gates, and Logical Depth, which defines the execution speed. Existing literature identifies the HNG gate as the standard for Input-Preserving Reversible Full Adders. HNG gate typically requires a QC of 12 and a logical depth of 5, in the area of classical reversible circuits. This paper proposes the PPKN Gate, a novel design that achieves the same inputpreserving functionality using only one Toffoli gate and five CNOT gates. With a Quantum Cost of 10 and a reduced logical depth of 4, the PPKN gate outperforms the standard HNG gate in both complexity and speed. Furthermore, we present a modular architecture for constructing an n-bit Ripple Carry Adder by cascading PPKN modules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12073v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G. Papakonstantinou</dc:creator>
    </item>
    <item>
      <title>Learning Dynamics in Memristor-Based Equilibrium Propagation</title>
      <link>https://arxiv.org/abs/2512.12428</link>
      <description>arXiv:2512.12428v1 Announce Type: cross 
Abstract: Memristor-based in-memory computing has emerged as a promising paradigm to overcome the constraints of the von Neumann bottleneck and the memory wall by enabling fully parallelisable and energy-efficient vector-matrix multiplications. We investigate the effect of nonlinear, memristor-driven weight updates on the convergence behaviour of neural networks trained with equilibrium propagation (EqProp). Six memristor models were characterised by their voltage-current hysteresis and integrated into the EBANA framework for evaluation on two benchmark classification tasks. EqProp can achieve robust convergence under nonlinear weight updates, provided that memristors exhibit a sufficiently wide resistance range of at least an order of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12428v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael D\"oll, Andreas M\"uller, Bernd Ulmann</dc:creator>
    </item>
    <item>
      <title>Optimised Fermion-Qubit Encodings for Quantum Simulation with Reduced Transpiled Circuit Depth</title>
      <link>https://arxiv.org/abs/2512.13580</link>
      <description>arXiv:2512.13580v1 Announce Type: cross 
Abstract: Simulation of fermionic Hamiltonians with gate-based quantum computers requires the selection of an encoding from fermionic operators to quantum gates, the most widely used being the Jordan-Wigner transform. Many alternative encodings exist, with quantum circuits and simulation results being sensitive to choice of encoding, device connectivity and Hamiltonian characteristics. Non-stochastic optimisation of the ternary tree class of encodings to date has targeted either the device or Hamiltonian. We develop a deterministic method which optimises ternary tree encodings without changing the underlying tree structure. This enables reduction in Pauli-weight without ancillae or additional swap-gate overhead. We demonstrate this method for a variety of encodings, including those which are derived from the qubit connectivity graph of a quantum computer. Across a suite of standard encoding methods applied to water in STO-3G basis, including Jordan-Wigner, our method reduces qDRIFT circuit depths on average by $27.7\%$ and $26.0\%$ for untranspiled and transpiled circuits respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13580v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Williams de la Bastida, Thomas M. Bickley, Peter V. Coveney</dc:creator>
    </item>
    <item>
      <title>Large-Language Memorization During the Classification of United States Supreme Court Cases</title>
      <link>https://arxiv.org/abs/2512.13654</link>
      <description>arXiv:2512.13654v1 Announce Type: cross 
Abstract: Large-language models (LLMs) have been shown to respond in a variety of ways for classification tasks outside of question-answering. LLM responses are sometimes called "hallucinations" since the output is not what is ex pected. Memorization strategies in LLMs are being studied in detail, with the goal of understanding how LLMs respond. We perform a deep dive into a classification task based on United States Supreme Court (SCOTUS) decisions. The SCOTUS corpus is an ideal classification task to study for LLM memory accuracy because it presents significant challenges due to extensive sentence length, complex legal terminology, non-standard structure, and domain-specific vocabulary. Experimentation is performed with the latest LLM fine tuning and retrieval-based approaches, such as parameter-efficient fine-tuning, auto-modeling, and others, on two traditional category-based SCOTUS classification tasks: one with 15 labeled topics and another with 279. We show that prompt-based models with memories, such as DeepSeek, can be more robust than previous BERT-based models on both tasks scoring about 2 points better than previous models not based on prompting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13654v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.IR</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John E. Ortega, Dhruv D. Joshi, Matt P. Borkowski</dc:creator>
    </item>
    <item>
      <title>Neuromorphic Photonic Computing with an Electro-Optic Analog Memory</title>
      <link>https://arxiv.org/abs/2401.16515</link>
      <description>arXiv:2401.16515v4 Announce Type: replace 
Abstract: In neuromorphic photonic systems, device operations are typically governed by analog signals, necessitating digital-to-analog converters (DAC) and analog-to-digital converters (ADC). However, data movement between memory and these converters in conventional von Neumann architectures incur significant energy costs. We propose an analog electronic memory co-located with photonic computing units to eliminate repeated long-distance data movement. Here, we demonstrate a monolithically integrated neuromorphic photonic circuit with on-chip capacitive analog memory and evaluate its performance in machine learning for in situ training and inference using the MNIST dataset. Our analysis shows that integrating analog memory into a neuromorphic photonic architecture can achieve over 26x power savings compared to conventional SRAM-DAC architectures. Furthermore, maintaining a minimum analog memory retention-to-network-latency ratio of 100 maintains &gt;90% inference accuracy, enabling leaky analog memories without substantial performance degradation. This approach reduces reliance on DACs, minimizes data movement, and offers a scalable pathway toward energy-efficient, high-speed neuromorphic photonic computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16515v4</guid>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>physics.optics</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sean Lam, Ahmed Khaled, Simon Bilodeau, Bicky A. Marquez, Paul R. Prucnal, Lukas Chrostowski, Bhavin J. Shastri, Sudip Shekhar</dc:creator>
    </item>
    <item>
      <title>A SAT Encoding for Optimal Clifford Circuit Synthesis</title>
      <link>https://arxiv.org/abs/2208.11713</link>
      <description>arXiv:2208.11713v2 Announce Type: replace-cross 
Abstract: Executing quantum algorithms on a quantum computer requires compilation to representations that conform to all restrictions imposed by the device. Due to devices' limited coherence times and gate fidelities, the compilation process has to be optimized as much as possible. To this end, an algorithm's description first has to be synthesized using the device's gate library. In this paper, we consider the optimal synthesis of Clifford circuits -- an important subclass of quantum circuits, with various applications. Such techniques are essential to establish lower bounds for (heuristic) synthesis methods and gauging their performance. Due to the huge search space, existing optimal techniques are practically limited to small qubit counts (around six qubits for typical instances). In this work, we propose an optimal synthesis method for Clifford circuits based on encoding the task as a satisfiability (SAT) problem and solving it using a SAT solver in conjunction with a binary search scheme. Experiments on random instances with up to 6 qubits demonstrate that state-of-the-art heuristics on average produce more than twice the number of gates necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.11713v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3566097.3567929</arxiv:DOI>
      <dc:creator>Sarah Schneider, Lukas Burgholzer, Robert Wille</dc:creator>
    </item>
    <item>
      <title>Decoding and Engineering the Phytobiome Communication for Smart Agriculture</title>
      <link>https://arxiv.org/abs/2508.03584</link>
      <description>arXiv:2508.03584v2 Announce Type: replace-cross 
Abstract: Smart agriculture applications, integrating technologies like the Internet of Things and machine learning/artificial intelligence (ML/AI) into agriculture, hold promise to address modern challenges of rising food demand, environmental pollution, and water scarcity. Alongside the concept of the phytobiome, which defines the area including the plant, its environment, and associated organisms, and the recent emergence of molecular communication (MC), there exists an important opportunity to advance agricultural science and practice using communication theory. In this article, we motivate to use the communication engineering perspective for developing a holistic understanding of the phytobiome communication and bridge the gap between the phytobiome communication and smart agriculture. Firstly, an overview of phytobiome communication via molecular and electrophysiological signals is presented and a multi-scale framework modeling the phytobiome as a communication network is conceptualized. Then, how this framework is used to model electrophysiological signals is demonstrated with plant experiments. Furthermore, possible smart agriculture applications, such as smart irrigation and targeted delivery of agrochemicals, through engineering the phytobiome communication are proposed. These applications merge ML/AI methods with the Internet of Bio-Nano-Things enabled by MC and pave the way towards more efficient, sustainable, and eco-friendly agricultural production. Finally, the implementation challenges, open research issues, and industrial outlook for these applications are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03584v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>q-bio.MN</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatih Gulec, Hamdan Awan, Nigel Wallbridge, Andrew W. Eckford</dc:creator>
    </item>
    <item>
      <title>cuAPO: A CUDA-based Parallelization of Artificial Protozoa Optimizer</title>
      <link>https://arxiv.org/abs/2510.14982</link>
      <description>arXiv:2510.14982v2 Announce Type: replace-cross 
Abstract: Metaheuristic algorithms are widely used for solving complex problems due to their ability to provide near-optimal solutions. But the execution time of these algorithms increases with the problem size and/or solution space. And, to get more promising results, we have to execute these algorithms for a large number of iterations, requiring a large amount of time and this is one of the main issues found with these algorithms. To handle the same, researchers are now-a-days working on design and development of parallel versions of state-of-the-art metaheuristic optimization algorithms. We, in this paper, present a CUDA-based parallelization of state-of-the-art Artificial Protozoa Optimizer leveraging GPU acceleration. We implement both the existing sequential version and the proposed parallel version of Artificial Protozoa Optimizer for a performance comparison. Our experimental results calculated over a set of CEC2022 benchmark functions demonstrate a significant performance gain i.e. up to 6.7 times speed up is achieved with proposed parallel version. We also use a real world application, i.e., Image Thresholding to compare both algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14982v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Henish Soliya, Anugrah Jain</dc:creator>
    </item>
    <item>
      <title>Hierarchical Molecular Language Models (HMLMs)</title>
      <link>https://arxiv.org/abs/2512.00696</link>
      <description>arXiv:2512.00696v3 Announce Type: replace-cross 
Abstract: Artificial intelligence (AI) is reshaping computational and network biology by enabling new approaches to decode cellular communication networks. We introduce Hierarchical Molecular Language Models (HMLMs), a novel framework that models cellular signaling as a specialized molecular language, where signaling molecules function as tokens, protein interactions define syntax, and functional consequences constitute semantics. HMLMs employ a transformer-based architecture adapted to accommodate graph-structured signaling networks through information transducers, mathematical entities that capture how molecules receive, process, and transmit signals. The architecture integrates multi-modal data sources across molecular, pathway, and cellular scales through hierarchical attention mechanisms and scale-bridging operators that enable information flow across biological hierarchies. Applied to a complex network of cardiac fibroblast signaling, HMLMs outperformed traditional approaches in temporal dynamics prediction, particularly under sparse sampling conditions. Attention-based analysis revealed biologically meaningful crosstalk patterns, including previously uncharacterized interactions between signaling pathways. By bridging molecular mechanisms with cellular phenotypes through AI-driven molecular language representation, HMLMs establish a foundation for biology-oriented large language models (LLMs) that could be pre-trained on comprehensive pathway datasets and applied across diverse signaling systems and tissues, advancing precision medicine and therapeutic discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00696v3</guid>
      <category>q-bio.MN</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hasi Hays, Yue Yu, William J. Richardson</dc:creator>
    </item>
  </channel>
</rss>
