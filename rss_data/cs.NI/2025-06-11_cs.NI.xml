<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Jun 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>MOSE: A Novel Orchestration Framework for Stateful Microservice Migration at the Edge</title>
      <link>https://arxiv.org/abs/2506.09159</link>
      <description>arXiv:2506.09159v1 Announce Type: new 
Abstract: Stateful migration has emerged as the dominant technology to support microservice mobility at the network edge while ensuring a satisfying experience to mobile end users. This work addresses two pivotal challenges, namely, the implementation and the orchestration of the migration process. We first introduce a novel framework that efficiently implements stateful migration and effectively orchestrates the migration process by fulfilling both network and application KPI targets. Through experimental validation using realistic microservices, we then show that our solution (i) greatly improves migration performance, yielding up to 77% decrease of the migration downtime with respect to the state of the art, and (ii) successfully addresses the strict user QoE requirements of critical scenarios featuring latency-sensitive microservices. Further, we consider two practical use cases, featuring, respectively, a UAV autopilot microservice and a multi-object tracking task, and demonstrate how our framework outperforms current state-of-the-art approaches in configuring the migration process and in meeting KPI targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09159v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Calagna, Yenchia Yu, Paolo Giaccone, Carla Fabiana Chiasserini</dc:creator>
    </item>
    <item>
      <title>Adaptive Bandwidth Sharing for Optimizing QoE of Real-Time Video</title>
      <link>https://arxiv.org/abs/2506.09197</link>
      <description>arXiv:2506.09197v1 Announce Type: new 
Abstract: The concept of spectrum or bandwidth sharing has gained significant global attention as a means to enhance the efficiency of real-time traffic management in wireless networks. Effective bandwidth sharing enables optimal utilization of available resources, reducing congestion and improving QoE for delay-sensitive applications such as real-time video transmission. In this paper, we propose a novel iterative semi-static bandwidth sharing policy that balances the advantages of both static and dynamic sharing approaches. Our approach minimizes the frequency of coordination between network operators while ensuring efficient resource allocation and meeting the stringent QoE demands of real-time traffic. The proposed policy iteratively optimizes both the spectrum sharing between operators and the resource allocation for individual clients. We establish strong theoretical guarantees for the optimality of the proposed policy and prove that it converges to the optimal static sharing policy irrespective of initial conditions or fluctuations in traffic arrival rates. Additionally, we conduct extensive simulations to evaluate the impact of key system parameters - including step size, hyperperiod length, and arrival process dynamics - on the performance of our policy. Our results demonstrate the effectiveness of the proposed approach in achieving near-optimal bandwidth allocation with reduced overhead, making it a practical solution for real-time wireless applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09197v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushi Anna George, Vinay Joseph</dc:creator>
    </item>
    <item>
      <title>Age of Information in Unreliable Tandem Queues</title>
      <link>https://arxiv.org/abs/2506.09245</link>
      <description>arXiv:2506.09245v1 Announce Type: new 
Abstract: Stringent demands for timely information delivery, driven by the widespread adoption of real-time applications and the Internet of Things, have established the age of information (AoI) as a critical metric for quantifying data freshness. Existing AoI models often assume multi-hop communication networks with fully reliable nodes, which may not accurately capture scenarios involving node transmission failures. This paper presents an analytical framework for two configurations of tandem queue systems, where status updates generated by a single sensor are relayed to a destination monitor through unreliable intermediate nodes. Using the probability generating function, we first derive the sojourn time distribution for an infinite-buffer M/M/1 tandem system with two unreliable nodes. We then extend our analysis to an M/G/1 tandem system with an arbitrary number of unreliable nodes, employing the supplementary variable technique while assuming that only the first node has an infinite buffer. Numerical results demonstrate the impact of key system parameters on the average AoI in unreliable tandem queues with Markovian and non-Markovian service times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09245v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muthukrishnan Senthilkumar, Aresh Dadlani, Hina Tabassum</dc:creator>
    </item>
    <item>
      <title>A Multi-Armed Bandit Framework for Online Optimisation in Green Integrated Terrestrial and Non-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2506.09268</link>
      <description>arXiv:2506.09268v1 Announce Type: new 
Abstract: Integrated terrestrial and non-terrestrial network (TN-NTN) architectures offer a promising solution for expanding coverage and improving capacity for the network. While non-terrestrial networks (NTNs) are primarily exploited for these specific reasons, their role in alleviating terrestrial network (TN) load and enabling energy-efficient operation has received comparatively less attention. In light of growing concerns associated with the densification of terrestrial deployments, this work aims to explore the potential of NTNs in supporting a more sustainable network. In this paper, we propose a novel online optimisation framework for integrated TN-NTN architectures, built on a multi-armed bandit (MAB) formulation and leveraging the Bandit-feedback Constrained Online Mirror Descent (BCOMD) algorithm. Our approach adaptively optimises key system parameters--including bandwidth allocation, user equipment (UE) association, and macro base station (MBS) shutdown--to balance network capacity and energy efficiency in real time. Extensive system-level simulations over a 24-hour period show that our framework significantly reduces the proportion of unsatisfied UEs during peak hours and achieves up to 19% throughput gains and 5% energy savings in low-traffic periods, outperforming standard network settings following 3GPP recommendations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09268v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henri Alam, Antonio de Domenico, Tareq Si Salem, Florian Kaltenberger</dc:creator>
    </item>
    <item>
      <title>Real-Time Network Traffic Forecasting with Missing Data: A Generative Model Approach</title>
      <link>https://arxiv.org/abs/2506.09647</link>
      <description>arXiv:2506.09647v1 Announce Type: new 
Abstract: Real-time network traffic forecasting is crucial for network management and early resource allocation. Existing network traffic forecasting approaches operate under the assumption that the network traffic data is fully observed. However, in practical scenarios, the collected data are often incomplete due to various human and natural factors. In this paper, we propose a generative model approach for real-time network traffic forecasting with missing data. Firstly, we model the network traffic forecasting task as a tensor completion problem. Secondly, we incorporate a pre-trained generative model to achieve the low-rank structure commonly associated with tensor completion. The generative model effectively captures the intrinsic low-rank structure of network traffic data during pre-training and enables the mapping from a compact latent representation to the tensor space. Thirdly, rather than directly optimizing the high-dimensional tensor, we optimize its latent representation, which simplifies the optimization process and enables real-time forecasting. We also establish a theoretical recovery guarantee that quantifies the error bound of the proposed approach. Experiments on real-world datasets demonstrate that our approach achieves accurate network traffic forecasting within 100 ms, with a mean absolute error (MAE) below 0.002, as validated on the Abilene dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09647v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Deng, Wenhan Xu, Jingwei Li, Danny H. K. Tsang</dc:creator>
    </item>
    <item>
      <title>Multi-Level Damage-Aware Graph Learning for Resilient UAV Swarm Networks</title>
      <link>https://arxiv.org/abs/2506.09703</link>
      <description>arXiv:2506.09703v1 Announce Type: new 
Abstract: Unmanned aerial vehicle (UAV) swarm networks leverage resilient algorithms to address communication network split issues and restore connectivity. However, existing graph learning-based resilient algorithms face over-aggregation and non-convergence problems caused by uneven and sparse topology under massive damage scenarios. To alleviate these problems, we propose a novel Multi-Level Damage-Aware Graph Learning (ML-DAGL) algorithm, which generates recovery trajectories by mining information from destroyed UAVs. We first introduce a Multi-Branch Damage Attention (MBDA) module, which forms a sequence of multi-hop Damage Attentive Graphs (mDAG) with different ranges of receptive fields. Each mDAG links only remaining and damaged nodes to ensure a more even degree distribution for mitigating over-aggregation, and utilizes multi-hop dilation to establish more links for sparse topology enhancement. To resort to the mDAG, we propose a Dilated Graph Convolution Network (DGCN), which generates the optimal recovery trajectories with theoretically proven convergence under massive damage cases. Simulation results show that the proposed algorithm can guarantee the connectivity restoration under large swarm and damage scales, while significantly expediting the recovery time by 75.94% and improving the topology uniformity after recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09703v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huan Lin, Chenguang Zhu, Lianghui Ding, Feng Yang</dc:creator>
    </item>
    <item>
      <title>Virtualizing RAN: Science, Strategy, and Architecture of Software-Defined Mobile Networks</title>
      <link>https://arxiv.org/abs/2506.09878</link>
      <description>arXiv:2506.09878v1 Announce Type: new 
Abstract: Virtualising the Radio Access Network (RAN) is widely touted as the corner-stone of affordable 5G and a prerequisite for AI-native 6G. Yet current discourse often isolates spectrum policy, cloud engineering and organisational readiness into silos. This paper delivers an integrated analysis that spans science, technology, business strategy and culture. I first review spectrum-auction economics and show-via a comparative study of T-Mobile US and Verizon-that mid-band contiguity leveraged through software-defined carrier aggregation outperforms mmWave-centric deployments in both coverage and churn metrics. I then formalise the technical foundations of virtualised and open RAN, deriving capacity limits from contiguous and dis-contiguous spectrum maths and quantifying hardware ceilings for 400 MHz mmWave channels. Edge compute platforms (NVIDIA EGX, Samsung vRAN 3.0) and SDN-controlled RAN Intelligent Controllers are examined alongside AI ML pipelines that enable digital-twin-driven optimisation. A security cost model extends recent O-RAN measurements to show how 256-bit cipher enforcement adds 35-60 us latency unless mitigated by inline crypto off-load. Finally, a national automation case study of live vRAN sites -- demonstrates an 81 to 13 day cycle-time reduction once cultural change errors are corrected. I conclude with open research challenges for sub-THz 6G, energy-neutral AI accelerators and zero-trust orchestration, offering actionable recommendations for operators, vendors and researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09878v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Barker</dc:creator>
    </item>
    <item>
      <title>SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving</title>
      <link>https://arxiv.org/abs/2506.09397</link>
      <description>arXiv:2506.09397v1 Announce Type: cross 
Abstract: Regardless the advancements in device capabilities, efficient inferencing advanced large language models (LLMs) at the edge remains challenging due to limited device memory and power constraints. Existing strategies, such as aggressive quantization, pruning, or remote inference, trade accuracy for efficiency or lead to substantial cost burdens. This position paper introduces a new approach that leverages speculative decoding, previously viewed primarily as a decoding acceleration technique for autoregressive generation of LLMs, as a promising approach specifically adapted for edge computing by orchestrating computation across heterogeneous devices. We propose SLED, a method that allows lightweight edge devices to draft multiple candidate tokens locally using diverse draft models, while a single, shared edge server efficiently batches and verifies the tokens utilizing a more precise target model. This approach supports device heterogeneity and reduces server-side memory footprint by avoiding the need to deploy multiple target models. Our initial experiments with Jetson Orin Nano, Raspberry Pi 5, and an RTX 6000 edge server indicate substantial benefits: significantly reduced latency, improved energy efficiency, and increased concurrent inference sessions, all without sacrificing model accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09397v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangchen Li, Dimitrios Spatharakis, Saeid Ghafouri, Jiakun Fan, Dimitrios Nikolopoulos</dc:creator>
    </item>
    <item>
      <title>Securing Open RAN: A Survey of Cryptographic Challenges and Emerging Solutions for 5G</title>
      <link>https://arxiv.org/abs/2506.09418</link>
      <description>arXiv:2506.09418v1 Announce Type: cross 
Abstract: The advent of Open Radio Access Networks (O-RAN) introduces modularity and flexibility into 5G deployments but also surfaces novel security challenges across disaggregated interfaces. This literature review synthesizes recent research across thirteen academic and industry sources, examining vulnerabilities such as cipher bidding-down attacks, partial encryption exposure on control/user planes, and performance trade-offs in securing O-RAN interfaces like E2 and O1. The paper surveys key cryptographic tools -- SNOW-V, AES-256, and ZUC-256 -- evaluating their throughput, side-channel resilience, and adaptability to heterogeneous slices (eMBB, URLLC, mMTC). Emphasis is placed on emerging testbeds and AI-driven controllers that facilitate dynamic orchestration, anomaly detection, and secure configuration. We conclude by outlining future research directions, including hardware offloading, cross-layer cipher adaptation, and alignment with 3GPP TS 33.501 and O-RAN Alliance security mandates, all of which point toward the need for integrated, zero-trust architectures in 6G.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09418v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Barker, Fatemeh Afghah</dc:creator>
    </item>
    <item>
      <title>Energy-and Spectral-Efficiency Trade-off in Distributed Massive-MIMO Networks</title>
      <link>https://arxiv.org/abs/2501.01271</link>
      <description>arXiv:2501.01271v5 Announce Type: replace 
Abstract: This paper investigates a fundamental yet under-explored trade-off between energy efficiency (EE) and spectral efficiency (SE) in distributed massive MIMO (D-mMIMO) systems. Unlike conventional EE-SE trade-off studies that primarily focus on transmission power, D-mMIMO systems introduce new energy consumption factors including fronthaul signaling and distributed signal processing, which are heavily influenced by AP-UE association. This work highlights the critical need for a system-level EE-SE trade-off framework that accounts for these unique aspects of D-mMIMO. We formulate a joint optimization problem that maximizes EE while satisfying uplink sum-SE constraints, through the coordinated design of power allocation and AP-UE association strategies. By explicitly considering both transmission and infrastructure-related energy costs, our approach enables energy-aware network design without compromising throughput. Numerical simulations demonstrate the substantial impact of dynamic AP-UE association and power control on the EE-SE trade-off, providing actionable insights for an efficient deployment of large-scale distributed MIMO networks in next-generation wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01271v5</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohd Saif Ali Khan, Karthik RM, Samar Agnihotri</dc:creator>
    </item>
    <item>
      <title>Federated Learning Assisted Edge Caching Scheme Based on Lightweight Architecture DDPM</title>
      <link>https://arxiv.org/abs/2506.04593</link>
      <description>arXiv:2506.04593v2 Announce Type: replace 
Abstract: Edge caching is an emerging technology that empowers caching units at edge nodes, allowing users to fetch contents of interest that have been pre-cached at the edge nodes. The key to pre-caching is to maximize the cache hit percentage for cached content without compromising users' privacy. In this letter, we propose a federated learning (FL) assisted edge caching scheme based on lightweight architecture denoising diffusion probabilistic model (LDPM). Our simulation results verify that our proposed scheme achieves a higher cache hit percentage compared to existing FL-based methods and baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04593v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xun Li, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Khaled B. Letaief</dc:creator>
    </item>
  </channel>
</rss>
