<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Jul 2025 02:16:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Constant-Factor Approximability of Minimum Cost Constraint Satisfaction Problems</title>
      <link>https://arxiv.org/abs/2507.08693</link>
      <description>arXiv:2507.08693v1 Announce Type: cross 
Abstract: We study minimum cost constraint satisfaction problems (MinCostCSP) through the algebraic lens. We show that for any constraint language $\Gamma$ which has the dual discriminator operation as a polymorphism, there exists a $|D|$-approximation algorithm for MinCostCSP$(\Gamma)$ where $D$ is the domain. Complementing our algorithmic result, we show that any constraint language $\Gamma$ where MinCostCSP$(\Gamma)$ admits a constant-factor approximation must have a \emph{near-unanimity} (NU) polymorphism unless P = NP, extending a similar result by Dalmau et al. on MinCSPs. These results imply a dichotomy of constant-factor approximability for constraint languages that contain all permutation relations (a natural generalization for Boolean CSPs that allow variable negation): either MinCostCSP$(\Gamma)$ has an NU polymorphism and is $|D|$-approximable, or it does not have any NU polymorphism and is NP-hard to approximate within any constant factor. Finally, we present a constraint language which has a majority polymorphism, but is nonetheless NP-hard to approximate within any constant factor assuming the Unique Games Conjecture, showing that the condition of having an NU polymorphism is in general not sufficient unless UGC fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08693v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian DeHaan, Neng Huang, Euiwoong Lee</dc:creator>
    </item>
    <item>
      <title>Black-Box Identity Testing of Noncommutative Rational Formulas in Deterministic Quasipolynomial Time</title>
      <link>https://arxiv.org/abs/2309.15647</link>
      <description>arXiv:2309.15647v4 Announce Type: replace 
Abstract: Rational Identity Testing (RIT) is the decision problem of determining whether or not a noncommutative rational formula computes zero in the free skew field. It admits a deterministic polynomial-time white-box algorithm [Garg, Gurvits, Oliveira, and Wigderson (2016); Ivanyos, Qiao, Subrahmanyam (2018); Hamada and Hirai (2021)], and a randomized polynomial-time algorithm [Derksen and Makam (2017)] in the black-box setting, via singularity testing of linear matrices over the free skew field. Indeed, a randomized NC algorithm for RIT in the white-box setting follows from the result of Derksen and Makam (2017).
  Designing an efficient deterministic black-box algorithm for RIT and understanding the parallel complexity of RIT are major open problems in this area. Despite being open since the work of Garg, Gurvits, Oliveira, and Wigderson (2016), these questions have seen limited progress. In fact, the only known result in this direction is the construction of a quasipolynomial-size hitting set for rational formulas of only inversion height two [Arvind, Chatterjee, Mukhopadhyay (2022)].
  In this paper, we significantly improve the black-box complexity of this problem and obtain the first quasipolynomial-size hitting set for all rational formulas of polynomial size. Our construction also yields the first deterministic quasi-NC upper bound for RIT in the white-box setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15647v4</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V. Arvind, Abhranil Chatterjee, Partha Mukhopadhyay</dc:creator>
    </item>
    <item>
      <title>Sequence graphs realizations and ambiguity in language models</title>
      <link>https://arxiv.org/abs/2402.08830</link>
      <description>arXiv:2402.08830v2 Announce Type: replace-cross 
Abstract: Several popular language models represent local contexts in an input text $x$ as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in $x$, with edges representing the (ordered) co-occurrence of two words within a sliding window of size $w$. However, this compressed representation is not generally bijective: some may be ambiguous, admitting several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and algorithmic point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size $w$, presence/absence of graph orientation, and presence/absence of weights (multiplicities). When $w=2$, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirected/weighted setting, where we show the $\#$P-hardness of enumeration. For $w \ge 3$, we prove the hardness of all variants, even when $w$ is considered as a constant, with the notable exception of the undirected unweighted case for which we propose XP algorithms for both problems, tight due to a corresponding $W[1]-$hardness result. We conclude with an integer program formulation to solve the realizability problem, and a dynamic programming algorithm to solve the enumeration problem in instances of moderate sizes. This work leaves open the membership to NP of both problems, a non-trivial question due to the existence of minimum realizations having size exponential on the instance encoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08830v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sammy Khalife, Yann Ponty, Laurent Bulteau</dc:creator>
    </item>
    <item>
      <title>New constructions of pseudorandom codes</title>
      <link>https://arxiv.org/abs/2409.07580</link>
      <description>arXiv:2409.07580v2 Announce Type: replace-cross 
Abstract: Introduced in [CG24], pseudorandom error-correcting codes (PRCs) are a new cryptographic primitive with applications in watermarking generative AI models. These are codes where a collection of polynomially many codewords is computationally indistinguishable from random for an adversary that does not have the secret key, but anyone with the secret key is able to efficiently decode corrupted codewords. In this work, we examine the assumptions under which PRCs with robustness to a constant error rate exist.
  1. We show that if both the planted hyperloop assumption introduced in [BKR23] and security of a version of Goldreich's PRG hold, then there exist public-key PRCs for which no efficient adversary can distinguish a polynomial number of codewords from random with better than $o(1)$ advantage.
  2. We revisit the construction of [CG24] and show that it can be based on a wider range of assumptions than presented in [CG24]. To do this, we introduce a weakened version of the planted XOR assumption which we call the weak planted XOR assumption and which may be of independent interest.
  3. We initiate the study of PRCs which are secure against space-bounded adversaries. We show how to construct secret-key PRCs of length $O(n)$ which are $\textit{unconditionally}$ indistinguishable from random by $\text{poly}(n)$ time, $O(n^{1.5-\varepsilon})$ space adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07580v2</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surendra Ghentiyala, Venkatesan Guruswami</dc:creator>
    </item>
    <item>
      <title>Sharp Phase Transitions in Estimation with Low-Degree Polynomials</title>
      <link>https://arxiv.org/abs/2502.14407</link>
      <description>arXiv:2502.14407v2 Announce Type: replace-cross 
Abstract: High-dimensional planted problems, such as finding a hidden dense subgraph within a random graph, often exhibit a gap between statistical and computational feasibility. While recovering the hidden structure may be statistically possible, it is conjectured to be computationally intractable in certain parameter regimes. A powerful approach to understanding this hardness involves proving lower bounds on the efficacy of low-degree polynomial algorithms. We introduce new techniques for establishing such lower bounds, leading to novel results across diverse settings: planted submatrix, planted dense subgraph, the spiked Wigner model, and the stochastic block model. Notably, our results address the estimation task -- whereas most prior work is limited to hypothesis testing -- and capture sharp phase transitions such as the "BBP" transition in the spiked Wigner model (named for Baik, Ben Arous, and P\'{e}ch\'{e}) and the Kesten-Stigum threshold in the stochastic block model. Existing work on estimation either falls short of achieving these sharp thresholds or is limited to polynomials of very low (constant or logarithmic) degree. In contrast, our results rule out estimation with polynomials of degree $n^{\delta}$ where $n$ is the dimension and $\delta &gt; 0$ is a constant, and in some cases we pin down the optimal constant $\delta$. Our work resolves open problems posed by Hopkins &amp; Steurer (2017) and Schramm &amp; Wein (2022), and provides rigorous support within the low-degree framework for conjectures by Abbe &amp; Sandon (2018) and Lelarge &amp; Miolane (2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14407v2</guid>
      <category>math.ST</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youngtak Sohn, Alexander S. Wein</dc:creator>
    </item>
    <item>
      <title>On the order of the shortest solution sequences for the pebble motion problems</title>
      <link>https://arxiv.org/abs/2503.20550</link>
      <description>arXiv:2503.20550v4 Announce Type: replace-cross 
Abstract: Let $G$ be a connected graph with $N$ vertices. Let $k$ be the number of vertices in a longest path of $G$ such that every vertex on the path is a cut vertex of $G$, and every intermediate vertex of the path is a degree-two vertex of $G$. Let $k$ be the number of vertices of such a longest path of $T$ that every vertex of the path is a cut vertex and that every intermediate vertex of the path is a degree-two vertex of $T$. Let $P=\{1,\ldots,n\}$ be a set of pebbles with $n+k &lt; N$. A configuration of $P$ on $G$ is defined as a function $f$ from $V(G)$ to $\{0, 1, \ldots, n \}$ with $|f^{-1}(i)| = 1$ for $1 \le i \le n$, where $f^{-1}(i)$ is a vertex occupied with the $i$th pebble for $1 \le i \le n$ and $f^{-1}(0)$ is a set of unoccupied vertices. A move is defined as shifting a pebble from a vertex to some unoccupied neighbor. The pebble motion problem on the pair $(G,P)$ is to decide whether a given configuration of pebbles is reachable from another by executing a sequence of moves. In this paper, we show that the length of the shortest solution sequence of the pebble motion problem on the pair $(G,P)$ is in $O(Nn + n^2 \log(\min\{n,k\}))$ if $G$ is a $N$-vertex tree, and it is in $O(N^2 + \frac{n^3}{N-n} + n^2 \log(\min\{n,N-n\}))$ if $G$ is a connected general $N$-vertex graph. We provide an algorithm that can obtain a solution sequence of lengths that satisfy these orders, with the same computational complexity as the order of the length.
  Keywords: pebble motion, motion planning, multi-agent path finding, $15$-puzzle, tree</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20550v4</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoki Nakamigawa, Tadashi Sakuma</dc:creator>
    </item>
    <item>
      <title>On the (In)Approximability of the Monitoring Edge Geodetic Set Problem</title>
      <link>https://arxiv.org/abs/2507.00708</link>
      <description>arXiv:2507.00708v2 Announce Type: replace-cross 
Abstract: We study the minimum \emph{Monitoring Edge Geodetic Set} (\megset) problem introduced in [Foucaud et al., CALDAM'23]: given a graph $G$, we say that an edge is monitored by a pair $u,v$ of vertices if \emph{all} shortest paths between $u$ and $v$ traverse $e$; the goal of the problem consists in finding a subset $M$ of vertices of $G$ such that each edge of $G$ is monitored by at least one pair of vertices in $M$, and $|M|$ is minimized.
  In this paper, we prove that all polynomial-time approximation algorithms for the minimum \megset problem must have an approximation ratio of $\Omega(\log n)$, unless \p = \np. To the best of our knowledge, this is the first non-constant inapproximability result known for this problem. We also strengthen the known \np-hardness of the problem on $2$-apex graphs by showing that the same result holds for $1$-apex graphs. This leaves open the problem of determining whether the problem remains \np-hard on planar (i.e., $0$-apex) graphs.
  On the positive side, we design an algorithm that computes good approximate solutions for hereditary graph classes that admit efficiently computable balanced separators of truly sublinear size. This immediately results in polynomial-time approximation algorithms achieving an approximation ratio of $O(n^{\frac{1}{4}} \sqrt{\log n})$ on planar graphs, graphs with bounded genus, and $k$-apex graphs with $k=O(n^{\frac{1}{4}})$. On graphs with bounded treewidth, we obtain an approximation ratio of $O(\log^{3/2} n)$ for any constant $\varepsilon &gt; 0$. This compares favorably with the best-known approximation algorithm for general graphs, which achieves an approximation ratio of $O(\sqrt{n \log n})$ via a simple reduction to the \textsc{Set Cover} problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00708v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Davide Bil\`o, Giordano Colli, Luca Forlizzi, Stefano Leucci</dc:creator>
    </item>
    <item>
      <title>Finding One Local Optimum Is Easy -- But What about Two?</title>
      <link>https://arxiv.org/abs/2507.07524</link>
      <description>arXiv:2507.07524v2 Announce Type: replace-cross 
Abstract: The class PLS (Polynomial Local Search) captures the complexity of finding a solution that is locally optimal and has proven to be an important concept in the theory of local search. It has been shown that local search versions of various combinatorial optimization problems, such as Maximum Independent Set and Max Cut, are complete for this class. Such computational intractability typically arises in local search problems allowing arbitrary weights; in contrast, for unweighted problems, locally optimal solutions can be found in polynomial time under standard settings. In this paper, we pursue the complexity of local search problems from a different angle: We show that computing two locally optimal solutions is NP-hard for various natural unweighted local search problems, including Maximum Independent Set, Minimum Dominating Set, Max SAT, and Max Cut. We also discuss several tractable cases for finding two (or more) local optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07524v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi</dc:creator>
    </item>
  </channel>
</rss>
