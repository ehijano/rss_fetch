<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 02:40:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Quantum Model for Constrained Markowitz Modern Portfolio Using Slack Variables to Process Mixed-Binary Optimization under QAOA</title>
      <link>https://arxiv.org/abs/2601.03278</link>
      <description>arXiv:2601.03278v1 Announce Type: new 
Abstract: Effectively encoding inequality constraints is a primary obstacle in applying quantum algorithms to financial optimization. A quantum model for Markowitz portfolio optimization is presented that resolves this by embedding slack variables directly into the problem Hamiltonian. The method maps each slack variable to a dedicated ancilla qubit, transforming the problem into a Quadratic Unconstrained Binary Optimization (QUBO) formulation suitable for the Quantum Approximate Optimization Algorithm (QAOA). This process internalizes the constraints within the quantum state, altering the problem's energy landscape to facilitate optimization. The model is empirically validated through simulation, showing it consistently finds the optimal portfolio where a standard penalty-based QAOA fails. This work demonstrates that modifying the Hamiltonian architecture via a slack-ancilla scheme provides a robust and effective pathway for solving constrained optimization problems on quantum computers. A fundamental quantum limit on the simultaneous precision of portfolio risk and return is also posited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03278v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s42484-025-00330-z</arxiv:DOI>
      <arxiv:journal_reference>Quantum Mach. Intell. 7, 102 (2025)</arxiv:journal_reference>
      <dc:creator>Pablo Thomassin, Guillaume Guerard, Sonia Djebali, Vincent Marc Lambert</dc:creator>
    </item>
    <item>
      <title>An overview of the fractional-order gradient descent method and its applications</title>
      <link>https://arxiv.org/abs/2601.03318</link>
      <description>arXiv:2601.03318v2 Announce Type: new 
Abstract: Recent studies have shown that fractional calculus is an effective alternative mathematical tool in various scientific fields. However, some investigations indicate that results established in differential and integral calculus do not necessarily hold true in fractional calculus. In this work we will compare various methods presented in the literature to improve the Gradient Descent Method, in terms of convergence of the method, convergence to the extreme point, and convergence rate. In general, these methods that generalize the gradient descent algorithm by replacing the gradient with a fractional-order operator are inefficient in achieving convergence to the extremum point of the objective function. To avoid these difficulties, we proposed to choose the Fractional Continuous Time algorithm to generalize the gradient method. In this approach, the convergence of the method to the extreme point of the function is guaranteed by introducing the fractional order in the time derivative, rather than in of the gradient. In this case, the issue of finding the extreme point is resolved, while the issue of stability at the equilibrium point remains.
  Fractional Continuous Time method converges to extreme point of cost function when fractional-order is between 0 and 1. The simulations shown in this work suggests that a similar result can be found when $1 \leq \alpha \leq 2$. { This paper highlights the main advantages and disadvantages of generalizations of the gradient method using fractional derivatives, aiming to optimize convergence in complex problems. Some chemical problems, with n=11 and 24 optimization parameters, are employed as means of evaluating the efficacy of the propose algorithms. In general, previous studies are restricted to mathematical questions and simple illustrative examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03318v2</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Higor V. M. Ferreira, Camila A. Tavares, Nelson H. T. Lemes, Jos\'e P. C. dos Santos</dc:creator>
    </item>
    <item>
      <title>Optimal Quantization of Finite Uniform Data on the Sphere</title>
      <link>https://arxiv.org/abs/2601.03333</link>
      <description>arXiv:2601.03333v1 Announce Type: new 
Abstract: This paper develops a systematic and geometric theory of optimal quantization on the unit sphere $\mathbb S^2$, focusing on finite uniform probability distributions supported on the spherical surface - rather than on lower-dimensional geodesic subsets such as circles or arcs. We first establish the existence of optimal sets of $n$-means and characterize them through centroidal spherical Voronoi tessellations. Three fundamental structural results are obtained. First, a cluster - purity theorem shows that when the support consists of well-separated components, each optimal Voronoi region remains confined to a single component. Second, a ring - allocation (discrete water - filling) theorem provides an explicit rule describing how optimal representatives are distributed across multiple latitudinal rings, together with closed-form distortion formulas. Third, a Lipschitz - type stability theorem quantifies the robustness of optimal configurations under small geodesic perturbations of the support. In addition, a spherical analogue of Lloyd's algorithm is presented, in which intrinsic (Karcher) means replace Euclidean centroids for iterative refinement. These results collectively provide a unified and transparent framework for understanding the geometric and algorithmic structure of optimal quantization on $\mathbb S^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03333v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mrinal Kanti Roychowdhury</dc:creator>
    </item>
    <item>
      <title>Provably Convergent Decentralized Optimization over Directed Graphs under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2601.03566</link>
      <description>arXiv:2601.03566v1 Announce Type: new 
Abstract: Decentralized optimization has become a fundamental tool for large-scale learning systems; however, most existing methods rely on the classical Lipschitz smoothness assumption, which is often violated in problems with rapidly varying gradients. Motivated by this limitation, we study decentralized optimization under the generalized $(L_0, L_1)$-smoothness framework, in which the Hessian norm is allowed to grow linearly with the gradient norm, thereby accommodating rapidly varying gradients beyond classical Lipschitz smoothness. We integrate gradient-tracking techniques with gradient clipping and carefully design the clipping threshold to ensure accurate convergence over directed communication graphs under generalized smoothness. In contrast to existing distributed optimization results under generalized smoothness that require a bounded gradient dissimilarity assumption, our results remain valid even when the gradient dissimilarity is unbounded, making the proposed framework more applicable to realistic heterogeneous data environments. We validate our approach via numerical experiments on standard benchmark datasets, including LIBSVM and CIFAR-10, using regularized logistic regression and convolutional neural networks, demonstrating superior stability and faster convergence over existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03566v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanan Bo, Yongqiang Wang</dc:creator>
    </item>
    <item>
      <title>Matrix Riccati BSDEs with singular terminal condition and stochastic LQ control with linear terminal constraint</title>
      <link>https://arxiv.org/abs/2601.03747</link>
      <description>arXiv:2601.03747v1 Announce Type: new 
Abstract: We analyze a class of multidimensional linear-quadratic stochastic control problems with random coefficients, motivated by multi-asset optimal trade execution. The problems feature non-diffusive controlled state dynamics and a terminal constraint that restricts the terminal state to a prescribed random linear subspace. We derive the associated Riccati backward stochastic differential equation (BSDE) and identify a suitable formalization of its singular terminal condition. Via a penalization approach, we establish existence of a minimal supersolution of the Riccati BSDE and use it to characterize both the value function and the optimal control. We analyze the asymptotic behavior of the supersolution near terminal time and discuss special cases where closed-form solutions can be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03747v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Ackermann (LMM), Thomas Kruse (LMM), Petr Petrov (LMM), Alexandre Popier (LMM)</dc:creator>
    </item>
    <item>
      <title>GPU-Accelerated Cholesky Factorization of Block Tridiagonal Matrices</title>
      <link>https://arxiv.org/abs/2601.03754</link>
      <description>arXiv:2601.03754v1 Announce Type: new 
Abstract: This paper presents a GPU-accelerated framework for solving block tridiagonal linear systems that arise naturally in numerous real-time applications across engineering and scientific computing. Through a multi-stage permutation strategy based on nested dissection, we reduce the computational complexity from $\mathcal{O}(Nn^3)$ for sequential Cholesky factorization to $\mathcal{O}(\log_2(N)n^3)$ when sufficient parallel resources are available, where $n$ is the block size and $N$ is the number of blocks. The algorithm is implemented using NVIDIA's Warp library and CUDA to exploit parallelism at multiple levels within the factorization algorithm. Our implementation achieves speedups exceeding 100x compared to the sparse solver QDLDL, 25x compared to a highly optimized CPU implementation using BLASFEO, and more than 2x compared to NVIDIA's CUDSS library. The logarithmic scaling with horizon length makes this approach particularly attractive for long-horizon problems in real-time applications. Comprehensive numerical experiments on NVIDIA GPUs demonstrate the practical effectiveness across different problem sizes and precisions. The framework provides a foundation for GPU-accelerated optimization solvers in robotics, autonomous systems, and other domains requiring repeated solution of structured linear systems. The implementation is open-source and available at https://github.com/PREDICT-EPFL/socu.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03754v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roland Schwan, Daniel Kuhn, Colin N. Jones</dc:creator>
    </item>
    <item>
      <title>Connecting Max-entropy With Computational Geometry, LP And SDP</title>
      <link>https://arxiv.org/abs/2601.03759</link>
      <description>arXiv:2601.03759v1 Announce Type: new 
Abstract: We consider the well-known max-(relative) entropy problem $\Theta$(y) = infQ$\ll$P DKL(Q P ) with Kullback-Leibler divergence on a domain $\Omega$ $\subset$ R d , and with ''moment'' constraints h dQ = y, y $\in$ R m . We show that when m $\le$ d, $\Theta$ is the Cram{\'e}r transform of a function v that solves a simply related computational geometry problem. Also, and remarkably, to the canonical LP: min x$\ge$0 {c T x\,: A x = y}, with A $\in$ R mxd , one may associate a max-entropy problem with a suitably chosen reference measure P on R d + and linear mapping h(x) = Ax, such that its associated perspective function $\epsilon$ $\Theta$(y/$\epsilon$) is the optimal value of the log-barrier formulation (with parameter $\epsilon$) of the dual LP (and so it converges to the LP optimal value as $\epsilon$ $\rightarrow$ 0). An analogous result also holds for the canonical SDP: min X 0 { C, X\,: A(X) = y }.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03759v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean B Lasserre (TSE-R, LAAS-POP)</dc:creator>
    </item>
    <item>
      <title>Provably Finding a Hidden Dense Submatrix among Many Planted Dense Submatrices via Convex Programming</title>
      <link>https://arxiv.org/abs/2601.03946</link>
      <description>arXiv:2601.03946v1 Announce Type: new 
Abstract: We consider the densest submatrix problem, which seeks the submatrix of fixed size of a given binary matrix that contains the most nonzero entries. This problem is a natural generalization of fundamental problems in combinatorial optimization, e.g., the densest subgraph, maximum clique, and maximum edge biclique problems, and has wide application the study of complex networks. Much recent research has focused on the development of sufficient conditions for exact solution of the densest submatrix problem via convex relaxation. The vast majority of these sufficient conditions establish identification of the densest submatrix within a graph containing exactly one large dense submatrix hidden by noise. The assumptions of these underlying models are not observed in real-world networks, where the data may correspond to a matrix containing many dense submatrices of varying sizes.
  We extend and generalize these results to the more realistic setting where the input matrix may contain \emph{many} large dense subgraphs. Specifically, we establish sufficient conditions under which we can expect to solve the densest submatrix problem in polynomial time for random input matrices sampled from a generalization of the stochastic block model. Moreover, we also provide sufficient conditions for perfect recovery under a deterministic adversarial. Numerical experiments involving randomly generated problem instances and real-world collaboration and communication networks are used empirically to verify the theoretical phase-transitions to perfect recovery given by these sufficient conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03946v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentine Olanubi (University of Alabama, Department of Mathematics), Phineas Agar (University of Alabama, Department of Mathematics), Brendan Ames (University of Southampton, School of Mathematical Sciences)</dc:creator>
    </item>
    <item>
      <title>Continuation methods for higher-order topology optimization</title>
      <link>https://arxiv.org/abs/2601.04003</link>
      <description>arXiv:2601.04003v1 Announce Type: new 
Abstract: We aim to solve a topology optimization problem where the distribution of material in the design domain is represented by a density function. To obtain candidates for local minima, we want to solve the first order optimality system via Newton's method. This requires the initial guess to be sufficiently close to the a priori unknown solution. Introducing a stepsize rule often allows for less restrictions on the initial guess while still preserving convergence. In topology optimization one typically encounters nonconvex problems where this approach might fail. We therefore opt for a homotopy (continuation) approach which is based on solving a sequence of parametrized problems to approach the solution of the original problem. In the density based framework the values of the design variable are constrained by 0 from below and 1 from above. Coupling the homotopy method with a barrier strategy enforces these constraints to be satisified. The numerical results for a PDE-constrained compliance minimization problem demonstrate that this combined approach maintains feasibility of the density function and converges to a (candidate for a) locally optimal design without a priori knowledge of the solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04003v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Gangl, M. Winkler</dc:creator>
    </item>
    <item>
      <title>A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems</title>
      <link>https://arxiv.org/abs/2601.04120</link>
      <description>arXiv:2601.04120v1 Announce Type: new 
Abstract: Optimal control of obstacle problems arises in a wide range of applications and is computationally challenging due to its nonsmoothness, nonlinearity, and bilevel structure. Classical numerical approaches rely on mesh-based discretization and typically require solving a sequence of costly subproblems. In this work, we propose a single-loop bilevel deep learning method, which is mesh-free, scalable to high-dimensional and complex domains, and avoids repeated solution of discretized subproblems. The method employs constraint-embedding neural networks to approximate the state and control and preserves the bilevel structure. To train the neural networks efficiently, we propose a Single-Loop Stochastic First-Order Bilevel Algorithm (S2-FOBA), which eliminates nested optimization and does not rely on restrictive lower-level uniqueness assumptions. We analyze the convergence behavior of S2-FOBA under mild assumptions. Numerical experiments on benchmark examples, including distributed and obstacle control problems with regular and irregular obstacles on complex domains, demonstrate that the proposed method achieves satisfactory accuracy while reducing computational cost compared to classical numerical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04120v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongcun Song, Shangzhi Zeng, Jin Zhang, Lvgang Zhang</dc:creator>
    </item>
    <item>
      <title>Advances and Challenges in Semantic Textual Similarity: A Comprehensive Survey</title>
      <link>https://arxiv.org/abs/2601.03270</link>
      <description>arXiv:2601.03270v1 Announce Type: cross 
Abstract: Semantic Textual Similarity (STS) research has expanded rapidly since 2021, driven by advances in transformer architectures, contrastive learning, and domain-specific techniques. This survey reviews progress across six key areas: transformer-based models, contrastive learning, domain-focused solutions, multi-modal methods, graph-based approaches, and knowledge-enhanced techniques. Recent transformer models such as FarSSiBERT and DeBERTa-v3 have achieved remarkable accuracy, while contrastive methods like AspectCSE have established new benchmarks. Domain-adapted models, including CXR-BERT for medical texts and Financial-STS for finance, demonstrate how STS can be effectively customized for specialized fields. Moreover, multi-modal, graph-based, and knowledge-integrated models further enhance semantic understanding and representation. By organizing and analyzing these developments, the survey provides valuable insights into current methods, practical applications, and remaining challenges. It aims to guide researchers and practitioners alike in navigating rapid advancements, highlighting emerging trends and future opportunities in the evolving field of STS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03270v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lokendra Kumar, Neelesh S. Upadhye, Kannan Piedy</dc:creator>
    </item>
    <item>
      <title>Policy Synthesis for Interval MDPs via Polyhedral Lyapunov Functions</title>
      <link>https://arxiv.org/abs/2601.03445</link>
      <description>arXiv:2601.03445v1 Announce Type: cross 
Abstract: Decision-making under uncertainty is central to many safety-critical applications, where decisions must be guided by probabilistic modeling formalisms. This paper introduces a novel approach to policy synthesis in multi-objective interval Markov decision processes using polyhedral Lyapunov functions. Unlike previous Lyapunov-based methods that mainly rely on quadratic functions, our method utilizes polyhedral functions to enhance accuracy in managing uncertainties within value iteration of dynamic programming. We reformulate the value iteration algorithm as a switched affine system with interval uncertainties and apply control-theoretic stability principles to synthesize policies that guide the system toward a desired target set. By constructing an invariant set of attraction, we ensure that the synthesized policies provide convergence guarantees while minimizing the impact of transition uncertainty in the underlying model. Our methodology removes the need for computationally intensive Pareto curve computations by directly determining a policy that brings objectives within a specified range of their target values. We validate our approach through numerical case studies, including a recycling robot and an electric vehicle battery, demonstrating its effectiveness in achieving policy synthesis under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03445v1</guid>
      <category>eess.SY</category>
      <category>cs.FL</category>
      <category>cs.SY</category>
      <category>math.LO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Negar Monir, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>Quantum Classical Ridgelet Neural Network For Time Series Model</title>
      <link>https://arxiv.org/abs/2601.03654</link>
      <description>arXiv:2601.03654v1 Announce Type: cross 
Abstract: In this study, we present a quantum computing method that incorporates ridglet transforms into the quantum processing pipelines for time series data. Here, the Ridgelet neural network is integrated with a single-qubit quantum computing method, which improves feature extraction and forecasting capabilities. Furthermore, experimental results using financial time series data demonstrate the superior performance of our model compared to existing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03654v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.QA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bahadur Yadav, Sanjay Kumar Mohanty</dc:creator>
    </item>
    <item>
      <title>Exact Continuous Reformulations of Logic Constraints in Nonlinear Optimization and Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2601.03906</link>
      <description>arXiv:2601.03906v1 Announce Type: cross 
Abstract: Many nonlinear optimal control and optimization problems involve constraints that combine continuous dynamics with discrete logic conditions. Standard approaches typically rely on mixed-integer programming, which introduces scalability challenges and requires specialized solvers. This paper presents an exact reformulation of broad classes of logical constraints as binary-variable-free expressions whose differentiability properties coincide with those of the underlying predicates, enabling their direct integration into nonlinear programming models. Our approach rewrites arbitrary logical propositions into conjunctive normal form, converts them into equivalent max--min constraints, and applies a smoothing procedure that preserves the exact feasible set. The method is evaluated on two benchmark problems, a quadrotor trajectory optimization with obstacle avoidance and a hybrid two-tank system with temporal logic constraints, and is shown to obtain optimal solutions more consistently and efficiently than existing binary variable elimination techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03906v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jad Wehbeh, Eric C. Kerrigan</dc:creator>
    </item>
    <item>
      <title>Constrained dynamics for searching saddle points on general Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2601.03931</link>
      <description>arXiv:2601.03931v1 Announce Type: cross 
Abstract: Finding constrained saddle points on Riemannian manifolds is significant for analyzing energy landscapes arising in physics and chemistry. Existing works have been limited to special manifolds that admit global regular level-set representations, excluding applications such as electronic excited-state calculations. In this paper, we develop a constrained saddle dynamics applicable to smooth functions on general Riemannian manifolds. Our dynamics is formulated compactly over the Grassmann bundle of the tangent bundle. By analyzing the Grassmann bundle geometry, we achieve universality via incorporating the second fundamental form, which captures variations of tangent spaces along the trajectory. We rigorously establish the local linear stability of the dynamics and the local linear convergence of the resulting algorithms. Remarkably, our analysis provides the first convergence guarantees for discretized saddle-search algorithms in manifold settings. Moreover, by respecting the intrinsic quotient structure, we remove unnecessary nondegeneracy assumptions on the eigenvalues of the Riemannian Hessian that are present in existing works. We also point out that locating saddle points can be more ill-conditioning than finding local minimizers, and requires using nonredundant parametrizations. Finally, numerical experiments on linear eigenvalue problems and electronic excited-state calculations showcase the effectiveness of the proposed algorithms and corroborate the established local theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03931v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yukuan Hu, Laura Grazioli</dc:creator>
    </item>
    <item>
      <title>On the importance of smoothness, interface resolution and numerical sensitivities in shape and topological sensitivity analysis</title>
      <link>https://arxiv.org/abs/2601.03967</link>
      <description>arXiv:2601.03967v1 Announce Type: cross 
Abstract: In this paper we investigate the influence of the discretization of PDE constraints on shape and topological derivatives. To this end, we study a tracking-type functional and a two-material Poisson problem in one spatial dimension. We consider the discretization by a standard method and an enriched method. In the standard method we use splines of degree $p$ such that we can control the smoothness of the basis functions easily, but do not take any interface location into consideration. This includes for p=1 the usual hat basis functions. In the enriched method we additionally capture the interface locations in the ansatz space by enrichment functions. For both discretization methods shape and topological sensitivity analysis is performed. It turns out that the regularity of the shape derivative depends on the regularity of the basis functions. Furthermore, for point-wise convergence of the shape derivative the interface has to be considered in the ansatz space. For the topological derivative we show that only the enriched method converges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03967v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. H. Gfrerer, P. Gangl</dc:creator>
    </item>
    <item>
      <title>An inexact infeasible arc-search interior-point method for linear optimization problems</title>
      <link>https://arxiv.org/abs/2403.18155</link>
      <description>arXiv:2403.18155v4 Announce Type: replace 
Abstract: We propose an inexact infeasible arc-search interior-point method for solving linear optimization problems. The method combines an arc-search strategy with inexact solutions to Newton systems and admits a polynomial iteration complexity bound. In existing inexact infeasible interior-point methods, both the linearization error of the central path and the inexactness of the Newton system accumulate along the search direction, which forces the algorithm to take very small steps. The proposed method mitigates this effect by using an arc-search strategy: the curved search path provides a more accurate approximation of the central path, so the step size can remain larger even when the Newton system is solved inexactly. As a result, the proposed method achieves a provably tighter worst-case iteration bound than existing inexact infeasible line-search methods. Numerical experiments on NETLIB benchmark problems demonstrate that the proposed method reduces both the number of iterations and the computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18155v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Einosuke Iida, Makoto Yamashita</dc:creator>
    </item>
    <item>
      <title>Common Noise by Random Measures: Constructing Mean-Field Equilibria for Competitive Investment and Hedging</title>
      <link>https://arxiv.org/abs/2408.01175</link>
      <description>arXiv:2408.01175v3 Announce Type: replace 
Abstract: We construct Nash-equilibria in mean-field portfolio games of optimal investment and hedging under relative performance concerns with exponential (CARA) utility preferences. Common noise dynamics are modeled by integer-valued random measures, for instance Poisson random measures, in addition to Brownian motions. Agents differ in individual risk aversions, competition weights, and initial capital endowments, while their contingent claim liabilities depend on both common and idiosyncratic risk factors. Mean-field equilibria are characterized by solutions to McKean-Vlasov backward stochastic differential equations with jumps, for which we prove existence and uniqueness of solutions, without assuming mean field interaction to be small. Moreover, we show how the equilibrium can be constructed from the optimal strategy of a single-agent optimization problem (without mean-field interaction) via an appropriate projection. Using successive changes of measure, our derivation provides a decomposition of the equilibrium strategy into three components with clear interpretations. Finally, we show how a limiting mean-field game of quadratic (instead of utility-based) hedging with relative performance concerns arises for vanishing risk aversion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01175v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dirk Becherer, Stefanie Hesse</dc:creator>
    </item>
    <item>
      <title>A Class of Degenerate Mean Field Games, Associated FBSDEs and Master Equations</title>
      <link>https://arxiv.org/abs/2410.12404</link>
      <description>arXiv:2410.12404v3 Announce Type: replace 
Abstract: In this paper, we study a class of degenerate mean field games (MFGs) with state-distribution dependent and unbounded functional diffusion coefficients. With a probabilistic method, we study the well-posedness of the forward-backward stochastic differential equations (FBSDEs) associated with the MFG and arising from the maximum principle, and estimate the corresponding Jacobian and Hessian flows. We further establish the classical regularity of the value functional $V$; in particular, we show that when the cost function is $C^3$ in the spatial and control variables and $C^2$ in the distribution argument, then the value functional is $C^1$ in time and $C^2$ in the spatial and distribution variables. As a consequence, the value functional $V$ is the unique classical solution of the degenerate MFG master equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12404v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alain Bensoussan, Ziyu Huang, Shanjian Tang, Sheung Chi Phillip Yam</dc:creator>
    </item>
    <item>
      <title>Delayed Feedback in Online Non-Convex Optimization: A Non-Stationary Approach with Applications</title>
      <link>https://arxiv.org/abs/2412.14506</link>
      <description>arXiv:2412.14506v4 Announce Type: replace 
Abstract: We study non-convex delayed-noise online optimization problems by evaluating dynamic regret in the non-stationary setting when the loss functions are quasar-convex. In particular, we consider scenarios involving quasar-convex functions either with a Lipschitz gradient or weakly smooth and, for each case, we ensure bounded dynamic regret in terms of cumulative path variation achieving sub-linear regret rates. Furthermore, we illustrate the flexibility of our framework by applying it to both theoretical settings such as zeroth-order (bandit) and also to practical applications with quadratic fractional functions. Moreover, we provide new examples of non-convex functions that are quasar-convex by proving that the class of differentiable strongly quasiconvex functions (Polyak 1966) are strongly quasar-convex on convex compact sets. Finally, several numerical experiments validate our theoretical findings, illustrating the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14506v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Lara, Cristian Vega</dc:creator>
    </item>
    <item>
      <title>Spatial exponential decay of perturbations in optimal control of general evolution equations</title>
      <link>https://arxiv.org/abs/2501.12279</link>
      <description>arXiv:2501.12279v4 Announce Type: replace 
Abstract: We analyze the robustness of optimally controlled evolution equations with respect to spatially localized perturbations. We prove that if the involved operators are domain-uniformly stabilizable and detectable, then these localized perturbations only have a local effect on the optimal solution. We characterize this domain-uniform stabilizability and detectability for the transport equation with constant transport velocity, showing that even for unitary semigroups, optimality implies exponential damping. We extend this result to the case of a space-dependent transport velocity. Finally we leverage the results for the transport equation to characterize domain-uniform stabilizability of the wave equation. Numerical examples in one space dimension complement the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12279v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Benedikt Oppeneiger, Manuel Schaller, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Nonlinear Open-Loop Mean field Stackelberg Stochastic Differential Game</title>
      <link>https://arxiv.org/abs/2502.07390</link>
      <description>arXiv:2502.07390v2 Announce Type: replace 
Abstract: This paper studies a nonlinear open-loop mean field Stackelberg stochastic differential game by using the probabilistic method through the FBSDE system and the idea of taking control as the fixed point. We successively construct the decentralized optimal control problems for the followers and the leader, among which the leader's decentralized optimal control problem is a partial information optimal control problem with the fully coupled conditional mean-field forward-backward stochastic differential equation (FBSDE, in short) as the state equation. We successively derive the maximum principles for the corresponding decentralized optimal control problems of the followers and the leader. To obtain the existence, uniqueness and estimations of solutions of the state equation, the variational equation and the adjoint equation for the leader's decentralized optimal control problem, we study the well-posedness of a new form of conditional mean-field FBSDE. And the decentralized optimal controls of the leader and followers are proved to be the approximate Stackelberg equilibrium of the nonlinear mean field Stackelberg game. Finally, we apply the theoretical results developed in this paper to solve a nonlinear mean field Stackelberg game problem between a robot control center and unicycle-type swarm robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07390v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianhui Huang, Qi Huang</dc:creator>
    </item>
    <item>
      <title>Optimal Control of an Epidemic with Intervention Design</title>
      <link>https://arxiv.org/abs/2503.22928</link>
      <description>arXiv:2503.22928v2 Announce Type: replace 
Abstract: This paper investigates the optimal control of an epidemic governed by a SEIR model with operational delays in vaccination and non pharmaceutical interventions. We address the mathematical challenge of imposing hard healthcare capacity constraints (e.g., ICU limits) over an infinite time horizon. To rigorously bridge the gap between theoretical constraints and numerical tractability, we employ a variational framework based on Moreau--Yosida regularization and establish the connection between finite- and infinite-horizon solutions via $\Gamma$-convergence. The necessary conditions for optimality are derived using the Pontryagin Maximum Principle, allowing for the characterization of singular regimes where the optimal strategy maintains the infection level precisely at the capacity boundary. Numerical simulations illustrate these theoretical findings, quantifying the shadow prices of infection and costs associated with intervention delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22928v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Behrooz Moosavi Ramezanzadeh</dc:creator>
    </item>
    <item>
      <title>Model-Free Design and Analysis of 2DOF PI Controller for Noisy LTI Systems</title>
      <link>https://arxiv.org/abs/2504.21341</link>
      <description>arXiv:2504.21341v2 Announce Type: replace 
Abstract: Set-point tracking for systems with unknown model parameters is a fundamental problem in control, and two-degree-of-freedom (2DOF) Proportional-Integral (PI) controllers -- consisting of a feedforward controller and PI controller -- are widely employed for this task. In this paper, we propose a model-free design of 2DOF PI controllers, establish its theoretical properties, and compare them with a model-based method from both theoretical and numerical perspectives. For the feedforward design, we extend an existing model-free algorithm to systems subject to Gaussian process and measurement noises. We derive a nonasymptotic lower bound on the required control input/output data length and characterize the resulting estimation error. For PI gain tuning, we formulate a constrained optimization problem and establish sample complexity of a zeroth-order optimization method. Moreover, we quantify how inaccuracies in the feedforward design propagate to the performance of the PI controller, highlighting an interaction that has not been examined in prior work. We further provide a theoretical comparison between the proposed method and the model-based method. In particular, for PI gain tuning, the proposed method is computationally more efficient by avoiding explicit gradient computations. Numerical experiments demonstrate that the 2DOF PI controller designed by the proposed method exhibits better control performance than the model-based method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21341v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taiga Kiyota, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>A Fully Data-Driven Value Iteration for Stochastic LQR: Convergence, Robustness and Stability</title>
      <link>https://arxiv.org/abs/2505.02970</link>
      <description>arXiv:2505.02970v2 Announce Type: replace 
Abstract: Unlike traditional model-based reinforcement learning approaches that estimate system parameters from data, non-model-based data-driven control learns the optimal policy directly from input-state data without any intermediate model identification. Although this direct reinforcement learning approach offers increased adaptability and resilience to model misspecification, its reliance on raw data leaves it vulnerable to system noise and disturbances that may undermine convergence, robustness, and stability. In this article, we establish the convergence, robustness, and stability of value iteration (VI) for data-driven control of stochastic linear quadratic (LQ) systems in discrete-time with entirely unknown dynamics and cost. Our contributions are three-fold. First, we prove that VI is globally exponentially stable for any positive semidefinite initial value matrix in noise-free settings, thereby significantly relaxing restrictive assumptions on initial value functions in existing literature. Second, we extend our analysis to settings with external disturbances, proving that VI maintains small-disturbance input-to-state stability (ISS) and converges within a small neighborhood of the optimal solution when disturbances are sufficiently small. Third, we propose a new non-model-based robust adaptive dynamic programming (ADP) algorithm for adaptive optimal controller design, which, unlike existing procedures, requires no prior knowledge of an initial admissible control policy. Numerical experiments on a ``data center cooling'' problem demonstrate the convergence and stability of the algorithm compared to established methods, highlighting its robustness and adaptability for data-driven control in noisy environments. Finally, we apply the method to dynamic portfolio allocation, demonstrating its practical relevance outside traditional control tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02970v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Leilei Cui, Zhong-Ping Jiang, Petter N. Kolm, Gr\'egoire G. Macqueron</dc:creator>
    </item>
    <item>
      <title>Block Coordinate Descent Network Simplex Methods for Optimal Transport</title>
      <link>https://arxiv.org/abs/2506.21231</link>
      <description>arXiv:2506.21231v3 Announce Type: replace 
Abstract: We propose the Block Coordinate Descent Network Simplex (BCDNS) method for solving large-scale discrete Optimal Transport (OT) problems. BCDNS integrates the Network Simplex (NS) algorithm with a block coordinate descent (BCD) strategy, decomposing the full problem into smaller subproblems per iteration and reusing basis variables to ensure feasibility. We prove that BCDNS terminates in a finite number of iterations with an exact optimal solution, and we characterize its per-iteration complexity as O(s N), where s is a user-defined parameter in (0,1) and N is the total number of variables. Numerical experiments demonstrate that BCDNS matches the classical NS method in solution accuracy, reduces memory footprint compared to the Sinkhorn algorithm, achieves speed-ups of up to tens of times over the classical NS method, and exhibits runtime comparable to a high-precision Sinkhorn implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21231v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingrui Li, Nobuo Yamashita</dc:creator>
    </item>
    <item>
      <title>Fast Convergence of Multiobjective Inertial Gradient Systems with Time Scaling</title>
      <link>https://arxiv.org/abs/2508.07254</link>
      <description>arXiv:2508.07254v3 Announce Type: replace 
Abstract: In multiobjective optimization, inertial gradient systems accelerate convergence toward weakly Pareto optimal solutions. To achieve even faster convergence, we introduce a multiobjective inertial gradient system with time scaling (MITS), formulated as a second-order differential equation comprising an inertial term, asymptotically vanishing damping, and a time-scaled gradient term. We first establish the existence of solution trajectories for MITS. Through Lyapunov analysis, we show that with suitable parameters, the trajectory attains a convergence rate of $O(1/t^{2}\beta(t))$ with respect to a merit function, where $\beta(t)$ is a time-scaling function. Specifically, choosing $\beta(t)=t^{p}$ for $0\leq p&lt;\alpha-3$ yields the rate $O(1/t^{2+p})$, enabling arbitrarily fast sublinear convergence by tuning $p$. We also prove that the trajectory converges to a weakly Pareto optimal solution. Furthermore, an implicit discretization of MITS leads to a multiobjective inertial proximal point method (MIPP), whose iterates share the $O(1/k^{2}\beta_{k})$ rate and converge to a weakly Pareto optimum under appropriate conditions. Numerical experiments support the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07254v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingdong Yin</dc:creator>
    </item>
    <item>
      <title>An Interval Hessian-based line-search method for unconstrained nonconvex optimization problems</title>
      <link>https://arxiv.org/abs/2510.22342</link>
      <description>arXiv:2510.22342v2 Announce Type: replace 
Abstract: Second-order Newton-type algorithms that leverage the exact Hessian or its approximation are central to solve nonlinear optimization problems. However, their applications in solving large-scale nonconvex problems are hindered by three primary challenges: (1) the high computational cost associated with Hessian evaluations, (2) its inversion, and (3) ensuring descent direction at points where the Hessian becomes indefinite. We propose INTHOP, an interval Hessian-based optimization algorithm for nonconvex problems to deal with these primary challenges. The proposed search direction is based on approximating the original Hessian matrix by a positive definite matrix. The novelty of the proposed method is that the proposed search direction is guaranteed to be descent and requires approximation of Hessian and its inversion only at specific iterations. We prove that the difference between the calculated approximate and exact Hessian is bounded within an interval. Accordingly, the approximate Hessian matrix is reused if the iterates are in that chosen interval while computing the gradients at each iteration. We develop various algorithm variants based on the interval size updating methods and minimum eigenvalue computation methods. We also prove the global convergence of the proposed algorithm. Further, we apply the algorithm to an extensive set of test problems and compare its performance with the existing methods such as steepest descent, quasi-Newton, and Newton method. We show empirically that the proposed method solves more problems in fewer function and gradient evaluations than steepest descent and the quasi-Newton method. While in the comparison to the Newton method, we illustrate that for nonconvex optimization problems, we require substantially less $O(n^3)$ operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22342v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krishan Kumar, Ashutosh Sharma, Gauransh Dingwani, Nikhil Gupta, Vaishnavi Gupta, Ishan Bajaj</dc:creator>
    </item>
    <item>
      <title>Halpern Acceleration of the Inexact Proximal Point Method of Rockafellar</title>
      <link>https://arxiv.org/abs/2511.10372</link>
      <description>arXiv:2511.10372v2 Announce Type: replace 
Abstract: This paper investigates a Halpern acceleration of the inexact proximal point method for solving maximal monotone inclusion problems in Hilbert spaces. The proposed Halpern inexact proximal point method (HiPPM) is shown to be globally convergent, and a unified framework is developed to analyze its worst-case convergence behavior. Under mild conditions on the inexactness tolerances, HiPPM achieves an $\mathcal{O}(1/k^{2})$ convergence rate in terms of the squared fixed-point residual. Moreover, under additional well-studied regularity conditions, the method attains a fast linear convergence rate. Building on this framework, we further extend the Halpern acceleration to the inexact augmented Lagrangian method for constrained convex optimization. In the spirit of Rockafellar's classical results, the resulting accelerated inexact augmented Lagrangian method inherits the convergence rate and iteration complexity guarantees of HiPPM. Numerical experiments are provided to support the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10372v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Liwei Zhang, Fanli Zhuang, Ning Zhang</dc:creator>
    </item>
    <item>
      <title>Revisiting Johnson's rule for minimizing makespan in the Two-Machine Flow Shop scheduling problem</title>
      <link>https://arxiv.org/abs/2512.06119</link>
      <description>arXiv:2512.06119v4 Announce Type: replace 
Abstract: We consider Johnson's rule for minimizing the makespan in the two-machine flow shop problem. Although its worst-case time complexity is O(n log n), we show that it is possible to detect in linear time whether a full sorting of jobs can be avoided and an optimal solution can be computed in O(n) time. A probabilistic analysis indicates that linear time complexity holds with high probability under uniformly distributed processing times, a result further supported by extensive computational experimentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06119v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Federico Della Croce, Quentin Schau</dc:creator>
    </item>
    <item>
      <title>Compressed Momentum-based Single-Point Zero-Order Algorithm for Stochastic Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2512.06366</link>
      <description>arXiv:2512.06366v2 Announce Type: replace 
Abstract: This paper studies a compressed momentum-based single-point zeroth-order algorithm for stochastic distributed nonconvex optimization, aiming to alleviate communication overhead and address the unavailability of explicit gradient information. In the developed framework, each agent has access only to stochastic zeroth-order information of its local objective function, performs local stochastic updates with momentum, and exchanges compressed updates with its neighbors. We theoretically prove that the proposed algorithm can achieve the exact solution with diminishing step sizes and can achieve a sublinear convergence rate towards a neighborhood of the stationary point with fixed step sizes. Numerical experiments validate the effectiveness and communication efficiency of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06366v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linjing Chen, Antai Xie, Xinlei Yi, Xiaoqiang Ren, Xiaofan Wang</dc:creator>
    </item>
    <item>
      <title>Solving Matrix Games with Near-Optimal Matvec Complexity</title>
      <link>https://arxiv.org/abs/2601.02347</link>
      <description>arXiv:2601.02347v2 Announce Type: replace 
Abstract: We study the problem of computing an $\epsilon$-approximate Nash equilibrium of a two-player, bilinear game with a bounded payoff matrix $A \in \mathbb{R}^{m \times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\tilde{O}(\epsilon^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\ell_1$-$\ell_1$ (or zero-sum) games, where the players' strategies are both in the probability simplex, and $\ell_2$-$\ell_1$ games (encompassing hard-margin SVMs), where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\tilde{O}(\epsilon^{-8/9})$ for $\ell_1$-$\ell_1$ and $\tilde{O}(\epsilon^{-7/9})$ for $\ell_2$-$\ell_1$ due to [KOS '25]. In both settings our results are nearly-optimal as they match lower bounds of [KS '25] up to polylogarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02347v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ishani Karmarkar, Liam O'Carroll, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Optimal dividend payout with path-dependent drawdown constraint</title>
      <link>https://arxiv.org/abs/2312.01668</link>
      <description>arXiv:2312.01668v2 Announce Type: replace-cross 
Abstract: This paper studies an optimal dividend problem with a drawdown constraint in a Brownian motion model, requiring the dividend payout rate to remain above a fixed proportion of its historical maximum. This leads to a path-dependent stochastic control problem, as the admissible control depends on its own past values. The associated Hamilton-Jacobi-Bellman (HJB) equation is a novel two-dimensional variational inequality with a gradient constraint, a type of problem previously only analyzed in the literature using viscosity solution techniques. In contrast, this paper employs delicate PDE methods to establish the existence of a strong solution. This stronger regularity allows us to explicitly characterize an optimal feedback control strategy, expressed in terms of two free boundaries and the running maximum surplus process. Furthermore, we derive key properties of the value function and the free boundaries, including boundedness and continuity. Numerical examples are provided to verify the theoretical results and to offer new financial insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01668v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chonghu Guan, Jiacheng Fan, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>Causal Invariance Learning via Efficient Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2412.11850</link>
      <description>arXiv:2412.11850v3 Announce Type: replace-cross 
Abstract: Identifying the causal relationship among variables from observational data is an important yet challenging task. This work focuses on identifying the direct causes of an outcome and estimating their magnitude, i.e., learning the causal outcome model. Data from multiple environments provide valuable opportunities to uncover causality by exploiting the invariance principle that the causal outcome model holds across heterogeneous environments. Based on the invariance principle, we propose the Negative Weighted Distributionally Robust Optimization (NegDRO) framework to learn an invariant prediction model. NegDRO minimizes the worst-case combination of risks across multiple environments and enforces invariance by allowing potential negative weights. Under the additive interventions regime, we establish three major contributions: (i) On the statistical side, we provide sufficient and nearly necessary identification conditions under which the invariant prediction model coincides with the causal outcome model; (ii) On the optimization side, despite the nonconvexity of NegDRO, we establish its benign optimization landscape, where all stationary points lie close to the true causal outcome model; (iii) On the computational side, we develop a gradient-based algorithm that provably converges to the causal outcome model, with non-asymptotic convergence rates in both sample size and gradient-descent iterations. In particular, our method avoids exhaustive combinatorial searches over exponentially many subsets of covariates found in the literature, ensuring scalability even when the dimension of the covariates is large. To our knowledge, this is the first causal invariance learning method that finds the approximate global optimality for a nonconvex optimization problem efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11850v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenyu Wang, Yifan Hu, Peter B\"uhlmann, Zijian Guo</dc:creator>
    </item>
    <item>
      <title>Architecture independent generalization bounds for overparametrized deep ReLU networks</title>
      <link>https://arxiv.org/abs/2504.05695</link>
      <description>arXiv:2504.05695v4 Announce Type: replace-cross 
Abstract: We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove a uniform generalization bound that is independent of the network architecture. We perform computational experiments of our theoretical results with MNIST, and obtain agreement with the true test error within a 22 % margin on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05695v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anandatheertha Bapu, Thomas Chen, Chun-Kai Kevin Chien, Patricia Mu\~noz Ewald, Andrew G. Moore</dc:creator>
    </item>
    <item>
      <title>Latent Representations for Control Design with Provable Stability and Safety Guarantees</title>
      <link>https://arxiv.org/abs/2505.23210</link>
      <description>arXiv:2505.23210v2 Announce Type: replace-cross 
Abstract: We initiate a formal study on the use of low-dimensional latent representations of dynamical systems for verifiable control synthesis. Our main goal is to enable the application of verification techniques -- such as Lyapunov or barrier functions -- that might otherwise be computationally prohibitive when applied directly to the full state representation. Towards this goal, we first provide dynamics-aware approximate conjugacy conditions which formalize the notion of reconstruction error necessary for systems analysis. We then utilize our conjugacy conditions to transfer the stability and invariance guarantees of a latent certificate function (e.g., a Lyapunov or barrier function) for a latent space controller back to the original system. Importantly, our analysis contains several important implications for learning latent spaces and dynamics, by highlighting the necessary geometric properties which need to be preserved by the latent space, in addition to providing concrete loss functions for dynamics reconstruction that are directly related to control design. We conclude by demonstrating the applicability of our theory to two case studies: (1) stabilization of a cartpole system, and (2) collision avoidance for a two vehicle system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23210v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Lutkus, Kaiyuan Wang, Lars Lindemann, Stephen Tu</dc:creator>
    </item>
    <item>
      <title>Real-time Velocity Profile Optimization for Time-Optimal Maneuvering with Generic Acceleration Constraints</title>
      <link>https://arxiv.org/abs/2509.26428</link>
      <description>arXiv:2509.26428v2 Announce Type: replace-cross 
Abstract: The computation of time-optimal velocity profiles along prescribed paths, subject to generic acceleration constraints, is a crucial problem in robot trajectory planning, with particular relevance to autonomous racing. However, the existing methods either support arbitrary acceleration constraints at high computational cost or use conservative box constraints for computational efficiency. We propose FBGA, a new \underline{F}orward-\underline{B}ackward algorithm with \underline{G}eneric \underline{A}cceleration constraints, which achieves both high accuracy and low computation time. FBGA operates forward and backward passes to maximize the velocity profile in short, discretized path segments, while satisfying user-defined performance limits. Tested on five racetracks and two vehicle classes, FBGA handles complex, non-convex acceleration constraints with custom formulations. Its maneuvers and lap times closely match optimal control baselines (within $0.11\%$-$0.36\%$), while being up to three orders of magnitude faster. FBGA maintains high accuracy even with coarse discretization, making it well-suited for online multi-query trajectory planning. Our open-source \texttt{C++} implementation is available at: https://anonymous.4open.science/r/FB_public_RAL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26428v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LRA.2025.3643297</arxiv:DOI>
      <arxiv:journal_reference>IEEE Robotics and Automation Letters, vol. 11, no. 2, pp. 1674-1681, Feb. 2026</arxiv:journal_reference>
      <dc:creator>Mattia Piazza, Mattia Piccinini, Sebastiano Taddei, Francesco Biral, Enrico Bertolazzi</dc:creator>
    </item>
    <item>
      <title>Robust Differential Evolution via Nonlinear Population Size Reduction and Adaptive Restart: The ARRDE Algorithm</title>
      <link>https://arxiv.org/abs/2511.18429</link>
      <description>arXiv:2511.18429v2 Announce Type: replace-cross 
Abstract: This study is motivated by a robustness issue in numerical optimization of bound-constrained problems: many algorithms that perform well on a particular benchmark suite, such as the IEEE CEC2017 problems, struggle to maintain the same level of performance when applied to other suites that differ in dimensionality, landscape complexity, or the maximum number of function evaluations ($N_{\text{max}}$). To address this, we propose the Adaptive Restart-Refine Differential Evolution (ARRDE) algorithm, a new variant of Differential Evolution (DE). ARRDE builds upon the LSHADE algorithm, incorporates key mechanisms from jSO, and introduces a nonlinear population-size reduction strategy combined with an adaptive restart-refine mechanism.
  We evaluate ARRDE on five benchmark suites (CEC2011, CEC2017, CEC2019, CEC2020, and CEC2022) which, to the best of our knowledge, constitutes the most extensive experimental study to date in the context of algorithmic comparison, as most prior works consider only one or two suites. This broad evaluation enables a rigorous assessment of generalization across markedly different problem characteristics. To further support fair cross-suite comparisons, we also introduce a bounded accuracy-based scoring metric derived from relative error. Using both rank-based and accuracy-based metrics, and comparing against algorithms that perform strongly on CEC2017 (e.g., jSO and LSHADE-cnEpSin) as well as those that excel on CEC2020 (e.g., j2020 and NLSHADE-RSP), ARRDE consistently demonstrates top-tier performance, ranking first across all benchmark suites considered. These results highlight ARRDE's robustness and its superior generalization capability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18429v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khoirul Faiq Muzakka, Ahsani Hafizhu Shali, Haris Suhendar, S\"oren M\"oller, Martin Finsterbusch</dc:creator>
    </item>
    <item>
      <title>Towards a Principled Muon under $\mu\mathsf{P}$: Ensuring Spectral Conditions throughout Training</title>
      <link>https://arxiv.org/abs/2601.01306</link>
      <description>arXiv:2601.01306v2 Announce Type: replace-cross 
Abstract: The $\mu$-parameterization ($\mu$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $\mu$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $\mu$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $\mu$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $\mu$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $\mu$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01306v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Zhao</dc:creator>
    </item>
  </channel>
</rss>
