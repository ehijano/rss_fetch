<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Jun 2025 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Inverse initial data reconstruction for Maxwell's equations via time-dimensional reduction method</title>
      <link>https://arxiv.org/abs/2506.20777</link>
      <description>arXiv:2506.20777v1 Announce Type: new 
Abstract: We study an inverse problem for the time-dependent Maxwell system in an inhomogeneous and anisotropic medium. The objective is to recover the initial electric field $\mathbf{E}_0$ in a bounded domain $\Omega \subset \mathbb{R}^3$, using boundary measurements of the electric field and its normal derivative over a finite time interval. Informed by practical constraints, we adopt an under-determined formulation of Maxwell's equations that avoids the need for initial magnetic field data and charge density information. To address this inverse problem, we develop a time-dimension reduction approach by projecting the electric field onto a finite-dimensional Legendre polynomial-exponential basis in time. This reformulates the original space-time problem into a sequence of spatial systems for the projection coefficients. The reconstruction is carried out using the quasi-reversibility method within a minimum-norm framework, which accommodates the inherent non-uniqueness of the under-determined setting. We prove a convergence theorem that ensures the quasi-reversibility solution approximates the true solution as the noise and regularization parameters vanish. Numerical experiments in a fully three-dimensional setting validate the method's performance. The reconstructed initial electric field remains accurate even with $10\%$ noise in the data, demonstrating the robustness and applicability of the proposed approach to realistic inverse electromagnetic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20777v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thuy T. Le, Cong B. Van, Trong D. Dang, Loc H. Nguyen</dc:creator>
    </item>
    <item>
      <title>Boundary integral equation analysis for spheroidal suspensions</title>
      <link>https://arxiv.org/abs/2506.20809</link>
      <description>arXiv:2506.20809v1 Announce Type: new 
Abstract: In this work, we provide a fast, spectrally accurate method for the evaluation of boundary integral operators (BIOs) on a suspension of prolate and oblate spheroids. We first derive formulas for the standard layer potential operators for the Laplace equation applied to an expansion of the integral densities in the appropriate spheroidal harmonic basis. These then lead to analytical expressions in solid harmonics that allow spectrally accurate evaluation of near-field particle interactions. Finally, a standard quadrature scheme is used to evaluate smooth, far-field interactions; these are then accelerated using the fast multipole method.
  Through a number of numerical test cases, we verify the accuracy and efficiency of our BIO evaluation framework for dense, polydisperse suspensions of spheroids. Through the use of standard formulas linking Stokes and Laplace potentials, we show our scheme can be readily applied to problems involving particulate suspension flows. For both Laplace and Stokes, our method allows us to evaluate BIOs for suspensions up to hundreds of particles on a single processor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20809v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo Crowder, Tianyue Li, Eduardo Corona, Shravan Veerapaneni</dc:creator>
    </item>
    <item>
      <title>Multicontinuum Homogenization for Poroelasticity Model</title>
      <link>https://arxiv.org/abs/2506.20890</link>
      <description>arXiv:2506.20890v1 Announce Type: new 
Abstract: In this paper, we derive multicontinuum poroelasticity models using the multicontinuum homogenization method. Poroelasticity models are widely used in many areas of science and engineering to describe coupled flow and mechanics processes in porous media. However, in many applications, the properties of poroelastic media possess high contrast, presenting serious computational challenges. It is well known that standard homogenization approaches often fail to give an accurate solution due to the lack of macroscopic parameters. Multicontinuum approaches allow us to consider such cases by defining several average states known as continua. In the field of poroelasticity, multiple-network models arising from the multiple porous media theory are representatives of these approaches. In this work, we extend previous findings by deriving the generalized multicontinuum poroelasticity model. We apply the recently developed multicontinuum homogenization method and provide a rigorous derivation of multicontinuum equations. For this purpose, we formulate coupled constraint cell problems in oversampled regions to consider different homogenized effects. Then, we obtain a multicontinuum expansion of the fine-scale fields and derive the multicontinuum model supposing the smoothness of macroscopic variables. We present the most general version of equations and the simplified ones based on our numerical experiments. Numerical results are presented for different heterogeneous media cases and demonstrate the high accuracy of our proposed multicontinuum models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20890v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitry Ammosov, Mohammed Al-Kobaisi, Yalchin Efendiev</dc:creator>
    </item>
    <item>
      <title>Two-dimensional greedy randomized Kaczmarz methods for solving large-scale linear systems</title>
      <link>https://arxiv.org/abs/2506.20940</link>
      <description>arXiv:2506.20940v1 Announce Type: new 
Abstract: In this paper, we consider a novel two-dimensional randomized Kaczmarz method and its improved version with simple random sampling, which chooses two active rows with probability proportional to the square of their cross-product-like constant, for solving large-scale linear systems. From the greedy selection strategy with grasping two larger entries of the residual vector at each iteration, we then devise a two-dimensional greedy randomized Kaczmarz method. To improve the above methods further, motivated by the semi-randomized Kaczmarz method and Chebyshev's law of large numbers, we propose a two-dimensional semi-randomized Kaczmarz method and its modified version with simple random sampling, which is particularly advantageous for big data problems. Theoretically, we prove that the proposed methods converge to the unique least-norm solution of the consistent linear systems. Numerical results on some practical applications illustrate the superiority of the proposed methods compared with some existing ones in terms of computing time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20940v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Li, Meng-Long Xiao, Xin-Fang Zhang</dc:creator>
    </item>
    <item>
      <title>An energy-stable parametric finite element method for the Willmore flow in three dimensions</title>
      <link>https://arxiv.org/abs/2506.21025</link>
      <description>arXiv:2506.21025v1 Announce Type: new 
Abstract: This work develops novel energy-stable parametric finite element methods (ES-PFEM) for the Willmore flow and curvature-dependent geometric gradient flows of surfaces in three dimensions. The key to achieving the energy stability lies in the use of two novel geometric identities: (i) a reformulated variational form of the normal velocity field, and (ii) incorporation of the temporal evolution of the mean curvature into the governing equations. These identities enable the derivation of a new variational formulation. By using the parametric finite element method, an implicit fully discrete scheme is subsequently developed, which maintains the energy dissipative property at the fully discrete level. Based on the ES-PFEM, comprehensive insights into the design of ES-PFEM for general curvature-dependent geometric gradient flows and a new understanding of mesh quality improvement in PFEM are provided. In particular, we develop the first PFEM for the Gauss curvature flow of surfaces. Furthermore, a tangential velocity control methodology is applied to improve the mesh quality and enhance the robustness of the proposed numerical method. Extensive numerical experiments confirm that the proposed method preserves energy dissipation properties and maintain good mesh quality in the surface evolution under the Willmore flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21025v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weizhu Bao, Yifei Li, Dongmin Wang</dc:creator>
    </item>
    <item>
      <title>Entropy-stable in- and outflow boundary conditions for the compressible Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2506.21065</link>
      <description>arXiv:2506.21065v1 Announce Type: new 
Abstract: We propose inflow and outflow boundary conditions for the compressible Navier-Stokes equations and prove that they allow a priori estimates of the entropy, mass and total energy. Furthermore, we demonstrate how to approximate these boundary conditions in conjunction with an entropy-stable finite-volume scheme. The method is also applicable to other types of entropy-stable schemes. Finally, we carry out some numerical computations with the finite-volume scheme and demonstrate their robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21065v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Magnus Sv\"ard, Anita Gjesteland</dc:creator>
    </item>
    <item>
      <title>Inverse source problem with a posteriori interior measurements for space-time fractional diffusion equations</title>
      <link>https://arxiv.org/abs/2506.21070</link>
      <description>arXiv:2506.21070v1 Announce Type: new 
Abstract: This paper investigates an inverse source problem for space-time fractional diffusion equations from a posteriori interior measurements. The uniqueness result is established by the memory effect of fractional derivatives and the unique continuation property. For the numerical reconstruction, the inverse problem is reformulated as an optimization problem with the Tikhonov regularization. We use the Levenberg-Marquardt method to identity the unknown source from noisy measurements. Finally, we give some numerical examples to illustrate the efficiency and accuracy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21070v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Yu, Zhiyuan Li, Yikan Liu</dc:creator>
    </item>
    <item>
      <title>Robust space-time multiscale upscaling via multicontinuum homogenization for evolving perforated media</title>
      <link>https://arxiv.org/abs/2506.21104</link>
      <description>arXiv:2506.21104v1 Announce Type: new 
Abstract: Time-evolving perforated domains arise in many engineering and geoscientific applications, including reactive transport, particle deposition, and structural degradation in porous media. Accurately capturing the macroscopic behavior of such systems poses significant computational challenges due to the dynamic fine-scale geometries. In this paper, we develop a robust and generalizable multiscale modeling framework based on multicontinuum homogenization to derive effective macroscopic equations in shrinking domains. The method distinguishes multiple continua according to the physical characteristics (e.g., channel widths), and couples them via space-time local cell problems formulated on representative volume elements. These local problems incorporate temporal derivatives and domain evolution, ensuring consistency with underlying fine-scale dynamics. The resulting upscaled system yields computable macroscopic coefficients and is suitable for large-scale simulations. Several numerical experiments are presented to validate the accuracy, efficiency, and potential applicability of the method to complex time-dependent engineering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21104v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Xie, Viet Ha Hoang, Yin Yang, Yunqing Huang</dc:creator>
    </item>
    <item>
      <title>Robust and efficient pre-processing techniques for particle-based methods including dynamic boundary generation</title>
      <link>https://arxiv.org/abs/2506.21206</link>
      <description>arXiv:2506.21206v1 Announce Type: new 
Abstract: Obtaining high-quality particle distributions for stable and accurate particle-based simulations poses significant challenges, especially for complex geometries. We introduce a preprocessing technique for 2D and 3D geometries, optimized for smoothed particle hydrodynamics (SPH) and other particle-based methods. Our pipeline begins with the generation of a resolution-adaptive point cloud near the geometry's surface employing a face-based neighborhood search. This point cloud forms the basis for a signed distance field, enabling efficient, localized computations near surface regions. To create an initial particle configuration, we apply a hierarchical winding number method for fast and accurate inside-outside segmentation. Particle positions are then relaxed using an SPH-inspired scheme, which also serves to pack boundary particles. This ensures full kernel support and promotes isotropic distributions while preserving the geometry interface. By leveraging the meshless nature of particle-based methods, our approach does not require connectivity information and is thus straightforward to integrate into existing particle-based frameworks. It is robust to imperfect input geometries and memory-efficient without compromising performance. Moreover, our experiments demonstrate that with increasingly higher resolution, the resulting particle distribution converges to the exact geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21206v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niklas S. Neher, Erik Faulhaber, Sven Berger, Christian Wei{\ss}enfels, Gregor J. Gassner, Michael Schlottke-Lakemper</dc:creator>
    </item>
    <item>
      <title>On the coordinate system-dependence of the accuracy of symplectic numerical methods</title>
      <link>https://arxiv.org/abs/2506.21241</link>
      <description>arXiv:2506.21241v1 Announce Type: new 
Abstract: Symplectic numerical methods have become a widely-used choice for the accurate simulation of Hamiltonian systems in various fields, including celestial mechanics, molecular dynamics and robotics. Even though their characteristics are well-understood mathematically, relatively little attention has been paid in general to the practical aspect of how the choice of coordinates affects the accuracy of the numerical results, even though the consequences can be computationally significant. The present article aims to fill this gap by giving a systematic overview of how coordinate transformations can influence the results of simulations performed using symplectic methods. We give a derivation for the non-invariance of the modified Hamiltonian of symplectic methods under coordinate transformations, as well as a sufficient condition for the non-preservation of a first integral corresponding to a cyclic coordinate for the symplectic Euler method. We also consider the possibility of finding order-compensating coordinate transformations that improve the order of accuracy of a numerical method. Various numerical examples are presented throughout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21241v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.class-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Don\'at M. Tak\'acs, Tam\'as F\"ul\"op</dc:creator>
    </item>
    <item>
      <title>Runge--Kutta generalized Convolution Quadrature for sectorial problems</title>
      <link>https://arxiv.org/abs/2506.21242</link>
      <description>arXiv:2506.21242v1 Announce Type: new 
Abstract: We study the application of the generalized convolution quadrature (gCQ) based on Runge--Kutta methods to approximate the solution of an important class of sectorial problems. The gCQ generalizes Lubich's original convolution quadrature (CQ) to variable steps. High-order versions of the gCQ have been developed in the last decade, relying on certain Runge--Kutta methods. The Runge--Kutta based gCQ has been studied so far in a rather general setting, which includes applications to boundary integral formulations of wave problems. The available stability and convergence results for these new methods are suboptimal compared to those known for the uniform-step CQ, both in terms of convergence order and regularity requirements of the data. Here we focus on a special class of sectorial problems and prove that in these important applications it is possible to achieve the same order of convergence as for the original CQ, under the same regularity hypotheses on the data, and for very general time meshes. In the particular case of data with some known algebraic type of singularity, we also show how to choose an optimally graded time mesh to achieve convergence with maximal order, overcoming the well-known order reduction of the original CQ in these situations. An important advantage of the gCQ method is that it allows for a fast and memory-efficient implementation. We describe how the fast and oblivious Runge--Kutta based gCQ can be implemented and illustrate our theoretical results with several numerical experiments. The codes implementing the examples in this article are available in [13].</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21242v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Guo, Maria Lopez-Fernandez</dc:creator>
    </item>
    <item>
      <title>On Uniform Weighted Deep Polynomial approximation</title>
      <link>https://arxiv.org/abs/2506.21306</link>
      <description>arXiv:2506.21306v1 Announce Type: new 
Abstract: It is a classical result in rational approximation theory that certain non-smooth or singular functions, such as $|x|$ and $x^{1/p}$, can be efficiently approximated using rational functions with root-exponential convergence in terms of degrees of freedom \cite{Sta, GN}. In contrast, polynomial approximations admit only algebraic convergence by Jackson's theorem \cite{Lub2}. Recent work shows that composite polynomial architectures can recover exponential approximation rates even without smoothness \cite{KY}. In this work, we introduce and analyze a class of weighted deep polynomial approximants tailored for functions with asymmetric behavior-growing unbounded on one side and decaying on the other. By multiplying a learnable deep polynomial with a one-sided weight, we capture both local non-smoothness and global growth. We show numerically that this framework outperforms Taylor, Chebyshev, and standard deep polynomial approximants, even when all use the same number of parameters. To optimize these approximants in practice, we propose a stable graph-based parameterization strategy building on \cite{Jar}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21306v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kingsley Yeon, Steven B. Damelin</dc:creator>
    </item>
    <item>
      <title>A Sampling-Based Adaptive Rank Approach to the Wigner-Poisson System</title>
      <link>https://arxiv.org/abs/2506.21314</link>
      <description>arXiv:2506.21314v1 Announce Type: new 
Abstract: We develop a mass-conserving, adaptive-rank solver for the 1D1V Wigner-Poisson system. Our work is motivated by applications to the study of the stopping power of $\alpha$ particles at the National Ignition Facility (NIF). In this regime, electrons are in a warm dense state, requiring more than a standard kinetic model. They are hot enough to neglect Pauli exclusion, yet quantum enough to require accounting for uncertainty. The Wigner-Poisson system captures these effects but presents challenges due to its nonlocal nature. Based on a second-order Strang splitting method, we first design a full-rank solver with a structure-preserving Fourier update that ensures the intermediate solutions remain real-valued (up to machine precision), improving upon previous methods. Simulations demonstrate that the solutions exhibit a low rank structure for moderate to high dimensionless Planck constants ($H \ge 0.1$). This observed low rank structure motivates the development of an adaptive-rank solver, built on a Semi-Lagrangian adaptive-rank (SLAR) scheme for advection and an adaptive-rank, structure-preserving Fourier update for the Wigner integral terms, with a rigorous proof of structure-preserving property provided. Our solver achieves $O(N)$ complexity in both storage and computation time, while preserving mass and maintaining momentum accuracy up to the truncation error. The adaptive rank simulations are visually indistinguishable from the full-rank simulations in capturing solution structures. These results highlight the potential of adaptive rank methods for high-dimensional Wigner-Poisson simulations, paving the way toward fully kinetic studies of stopping power in warm dense plasmas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21314v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Christlieb, Sining Gong, Jing-Mei Qiu, Nanyi Zheng</dc:creator>
    </item>
    <item>
      <title>A discontinuous in time Streamline Diffusion Virtual Element Method for Darcy-transport problem</title>
      <link>https://arxiv.org/abs/2506.21326</link>
      <description>arXiv:2506.21326v1 Announce Type: new 
Abstract: We present a first numerical study of transport phenomena involving chemically reactive species, modeled by advection-diffusion-reaction systems with flow fields governed by Darcy's law. Among the various discretisation approaches, we consider the Streamline Diffusion method. Both the velocity field and the species concentrations are computed using the Virtual Element Method using a Discontinuous Galerkin scheme for time. An abstract error estimate has been derived using a special technique that utilizes Gauss-Radau interpolation in conjunction with numerical integration. These theoretical findings are supported by numerical experiments with arbitrary-order accuracy in both space and time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21326v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R A Caraballo Diaz, F Dassi</dc:creator>
    </item>
    <item>
      <title>Efficient parameter-robust preconditioners for linear poroelasticity and elasticity in the primal formulation</title>
      <link>https://arxiv.org/abs/2506.21361</link>
      <description>arXiv:2506.21361v1 Announce Type: new 
Abstract: Poroelasticity problems play an important role in various engineering, geophysical, and biological applications. Their full discretization results in a large-scale saddle-point system at each time step that is becoming singular for locking cases and needs effective preconditioners for its fast iterative solution. Instead of constructing spectrally equivalent ones, we develop nonsingular preconditioners so that the eigenvalues of the preconditioned system consist of a cluster around $1$ and an outlier in the order of $1/\lambda$, where $\lambda$ is a Lam\'{e} constant that is large for locking cases. It is known that the convergence factor of GMRES is bounded by the radius of the cluster for this type of systems. Both two- and three-field block triangular Schur complement preconditioners are studied. Upper bounds of the radius of the eigenvalue cluster for those systems are obtained and shown to be related to the inf-sup condition but independent of mesh size, time step, and locking parameters, which reflects the robustness of the preconditioners with respect to parameter variations. Moreover, the developed preconditioners do not need to compute the Schur complement and neither require exact inversion of diagonal blocks except the leading one. A locking-free weak Galerkin finite element method and the implicit Euler scheme are used for the discretization of the governing equation. Both two- and three-dimensional numerical results are presented to confirm the effectiveness and parameter-robustness of the developed preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21361v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weizhang Huang, Zhuoran Wang</dc:creator>
    </item>
    <item>
      <title>Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes</title>
      <link>https://arxiv.org/abs/2506.21395</link>
      <description>arXiv:2506.21395v1 Announce Type: new 
Abstract: This work presents a nonlinear extension of the high-order discretisation framework based on the Variational Multiscale (VMS) method previously introduced for steady linear problems. Building on the concept of an optimal projector defined via the symmetric part of the governing operator, we generalise the formulation to treat the 2D incompressible Navier-Stokes equations. The arroach maintains a clear separation between the resolved and unresolved scales, with the fine-scale contributions approximated through the approximate Fine-Scale Greens' function of the associated symmetric operator. This enables a consistent variational treatment of the nonlinearity while preserving high-order accuracy. We show that the method yields numerical solutions that closely approximate the optimal projection of the continuous/highly resolved solution and inherits desirable conservation properties. Numerical results confirm the framework's robustness, accuracy, and its potential for application to a broad class of nonlinear multiscale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21395v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suyash Shrestha, Marc Gerritsma, Gonzalo Rubio, Steven Hulshoff, Esteban Ferrer</dc:creator>
    </item>
    <item>
      <title>An adaptive dynamical low-rank optimizer for solving kinetic parameter identification inverse problems</title>
      <link>https://arxiv.org/abs/2506.21405</link>
      <description>arXiv:2506.21405v1 Announce Type: new 
Abstract: The numerical solution of parameter identification inverse problems for kinetic equations can exhibit high computational and memory costs. In this paper, we propose a dynamical low-rank scheme for the reconstruction of the scattering parameter in the radiative transfer equation from a number of macroscopic time-independent measurements. We first work through the PDE constrained optimization procedure in a continuous setting and derive the adjoint equations using a Lagrangian reformulation. For the scattering coefficient, a periodic B-spline approximation is introduced and a gradient descent step for updating its coefficients is formulated. After the discretization, a dynamical low-rank approximation (DLRA) is applied. We make use of the rank-adaptive basis update &amp; Galerkin integrator and a line search approach for the adaptive refinement of the gradient descent step size and the DLRA tolerance. We show that the proposed scheme significantly reduces both memory and computational cost. Numerical results computed with different initial conditions validate the accuracy and efficiency of the proposed DLRA scheme compared to solutions computed with a full solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21405v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lena Baumann, Lukas Einkemmer, Christian Klingenberg, Jonas Kusch</dc:creator>
    </item>
    <item>
      <title>An Iterative Methodology for Unitary Quantum Channel Search</title>
      <link>https://arxiv.org/abs/2506.21455</link>
      <description>arXiv:2506.21455v1 Announce Type: new 
Abstract: In this paper, we propose an iterative algorithm using polar decomposition to approximate a channel characterized by a single unitary matrix based on input-output quantum state pairs. In limited data, we state and prove that the optimal solution obtained from our method using one pair with a specific structure will generate an equivalent class, significantly reducing the dimension of the searching space. Furthermore, we prove that the unitary matrices describing the same channel differ by a complex number with modulus 1. We rigorously prove our proposed algorithm can ultimately identify a critical point, which is also a local minimum of the established objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21455v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew M. Lin, Hao-Wei Huang, Bing-Ze Lu</dc:creator>
    </item>
    <item>
      <title>A generalised framework for phase field-based modelling of coupled problems: application to thermo-mechanical fracture, hydraulic fracture, hydrogen embrittlement and corrosion</title>
      <link>https://arxiv.org/abs/2506.20763</link>
      <description>arXiv:2506.20763v1 Announce Type: cross 
Abstract: We present a novel, generalised formulation to treat coupled structural integrity problems by combining phase field and multi-physics modelling. The approach exploits the versatility of the heat transfer equation and is therefore well suited to be adopted in commercial finite element packages, requiring only integration point-level implementation. This aspect is demonstrated here by implementing coupled, multi-variable phenomena through simple \texttt{UMAT} and \texttt{UMATHT} subroutines in the finite element package \texttt{Abaqus}. The generalised theoretical and computational framework presented is particularised to four problems of engineering and scientific relevance: thermo-mechanical fracture, hydraulic fracture, hydrogen-assisted cracking and metallic corrosion. 2D and 3D problems are considered. The results reveal a very good agreement with experimental data, and existing numerical and analytical solutions.The user subroutines developed are made freely available at https://mechmat.web.ox.ac.uk/codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20763v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.app-ph</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Y. Navidtehrani, C. Beteg\'on, E. Mart\'inez-Pa\~neda</dc:creator>
    </item>
    <item>
      <title>Quantum Adaptive Search: A Hybrid Quantum-Classical Algorithm for Global Optimization of Multivariate Functions</title>
      <link>https://arxiv.org/abs/2506.21124</link>
      <description>arXiv:2506.21124v1 Announce Type: cross 
Abstract: This work presents Quantum Adaptive Search (QAGS), a hybrid quantum-classical algorithm for the global optimization of multivariate functions. The method employs an adaptive mechanism that dynamically narrows the search space based on a quantum-estimated probability distribution of the objective function. A quantum state encodes information about solution quality through an appropriate complex amplitude mapping, enabling the identification of the most promising regions, and thus progressively tightening the search bounds; then a classical optimizer performs local refinement of the solution. The analysis demonstrates that QAGS ensures a contraction of the search space toward global optima, with controlled computational complexity. The numerical results on the benchmark functions show that, compared to the classical methods, QAGS achieves higher accuracy while offering advantages in both time and space complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21124v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G. Intoccia, U. Chirico, V. Schiano Di Cola, G. Pepe, S. Cuomo</dc:creator>
    </item>
    <item>
      <title>Surrogate normal-forms for the numerical bifurcation and stability analysis of navier-stokes flows via machine learning</title>
      <link>https://arxiv.org/abs/2506.21275</link>
      <description>arXiv:2506.21275v1 Announce Type: cross 
Abstract: Inspired by the Equation-Free multiscale modeling approach, we demonstrate how the embed-learn-lift framework enables the construction of surrogate normal-forms, namely minimal-dimensional reduced-order models (ROMs), from high-fidelity Navier-Stokes simulations. These surrogate models are then used for efficient and accurate bifurcation and stability analysis. The framework proceeds in four steps. First, manifold learning reveals the intrinsic latent dimension of the high-dimensional spatio-temporal Navier-Stokes dynamics across parameter space. Second, we construct low-dimensional "normal-form" like ROMs on this latent space using Gaussian Process Regression (GPR), capturing the emergent dynamics. Third, using these models, we apply numerical bifurcation tools to compute bifurcation diagrams and perform stability analysis in the latent space. This includes tracing branches of limit cycles arising from Andronov-Hopf bifurcations - tasks intractable in full space due to computational cost. Finally, solving the pre-image problem allows reconstruction of the bifurcation structure in the original high-dimensional space. We demonstrate the methodology on two canonical flows: wake flow past an infinite circular cylinder and planar sudden-expansion channel flow. These exhibit Andronov-Hopf and pitchfork bifurcations, respectively, as Reynolds number increases. Our method identifies the latent dimensionality and constructs GPR-based surrogate normal-forms that enable the tracing and stability analysis of bifurcating solutions, including limit cycles, their period, and stability via Floquet multipliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21275v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Della Pia, Dimitrios G. Patsatzis, Gianluigi Rozza, Lucia Russo, Constantinos Siettos</dc:creator>
    </item>
    <item>
      <title>Solving high-dimensional Hamilton-Jacobi-Bellman equation with functional hierarchical tensor</title>
      <link>https://arxiv.org/abs/2408.04209</link>
      <description>arXiv:2408.04209v2 Announce Type: replace 
Abstract: This work proposes a novel numerical scheme for solving the high-dimensional Hamilton-Jacobi-Bellman equation with a functional hierarchical tensor ansatz. We consider the setting of stochastic control, whereby one applies control to a particle under Brownian motion. In particular, the existence of diffusion presents a new challenge to conventional tensor network methods for deterministic optimal control. To overcome the difficulty, we use a general regression-based formulation where the loss term is the Bellman consistency error combined with a Sobolev-type penalization term. We propose two novel sketching-based subroutines for obtaining the tensor-network approximation to the action-value functions and the value functions, which greatly accelerate the convergence for the subsequent regression phase. We apply the proposed approach successfully to two challenging control problems with Ginzburg-Landau potential in 1D and 2D with 64 variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04209v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xun Tang, Nan Sheng, Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Discrete Laplacians on the hyperbolic space -- a compared study</title>
      <link>https://arxiv.org/abs/2409.01211</link>
      <description>arXiv:2409.01211v2 Announce Type: replace 
Abstract: The main motivation behind this paper stems from a notable gap in the existing literature: the absence of a discrete counterpart to the Laplace-Beltrami operator on Riemannian manifolds, which can be effectively used to solve PDEs. We consider that the natural approach to pioneer this field is first to explore one of the simplest non-trivial (i.e., non-Euclidean) scenarios, specifically focusing on the $2$-dimensional hyperbolic space $\mathbb{H}^2$. We present two variants of discrete finite-difference operator tailored to this constant negatively curved space, both serving as approximations to the (continuous) Laplace-Beltrami operator within the $\mathrm{L}^2$ framework.
  We prove that the discrete heat equation associated with both operators mentioned above exhibits stability and converges towards the continuous heat-Beltrami Cauchy problem on $\mathbb{H}^2$. Moreover, using techniques inspired from the sharp analysis of discrete functional inequalities, we prove that the solutions of the discrete heat equations corresponding to both variants of discrete Laplacian exhibit an exponential decay asymptotically equal to the one induced by the Poincar\'e inequality on $\mathbb{H}^2$.
  Eventually, we illustrate that a discrete Laplacian specifically designed for the geometry of the hyperbolic space yields a more precise approximation and offers advantages from both theoretical and computational perspectives. Furthermore, this discrete operator can be effectively generalized to the three-dimensional hyperbolic space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01211v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mihai Bucataru, Drago\c{s} Manea</dc:creator>
    </item>
    <item>
      <title>Uniform accuracy of implicit-explicit Runge-Kutta methods for linear hyperbolic relaxation systems</title>
      <link>https://arxiv.org/abs/2410.07254</link>
      <description>arXiv:2410.07254v2 Announce Type: replace 
Abstract: In this paper, we study the uniform accuracy of implicit-explicit (IMEX) Runge-Kutta (RK) schemes for general linear hyperbolic relaxation systems satisfying the structural stability condition proposed in \cite{yong_singular_1999}. We establish the uniform stability and accuracy of a class of IMEX-RK schemes with spatial discretization using a Fourier spectral method. Our results demonstrate that the accuracy of the fully discretized schemes is independent of the relaxation time across all regimes. Numerical experiments on applications in traffic flows and kinetic theory verify our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07254v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiting Ma, Juntao Huang</dc:creator>
    </item>
    <item>
      <title>Matrix-free stochastic calculation of operator norms without using adjoints</title>
      <link>https://arxiv.org/abs/2410.08297</link>
      <description>arXiv:2410.08297v2 Announce Type: replace 
Abstract: This paper considers the problem of computing the operator norm of a linear map between finite dimensional Hilbert spaces when only evaluations of the linear map are available and under restrictive storage assumptions. We propose a stochastic method of random search type to maximize the Rayleigh quotient and employ an exact line search in the random search directions. Moreover, we show that the proposed algorithm converges to the global maximum (the operator norm) almost surely, show a sublinear convergence behavior for the corresponding eigenvector and eigenvalue equation, and illustrate the performance of the method with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08297v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Bresch, Dirk A. Lorenz, Felix Schneppe, Maximilian Winkler</dc:creator>
    </item>
    <item>
      <title>A posteriori error estimates for the wave equation with mesh change in the leapfrog method</title>
      <link>https://arxiv.org/abs/2411.16933</link>
      <description>arXiv:2411.16933v2 Announce Type: replace 
Abstract: We derive a fully computable aposteriori error estimator for a Galerkin finite element solution of the wave equation with explicit leapfrog time-stepping. Our discrete formulation accommodates both time evolving meshes and leapfrog based local time-stepping (Diaz &amp; Grote, 2009), which overcomes the stringent stability restriction on the time-step due to local mesh refinement. Thus we account for adaptive time-stepping with mesh change in a fully explicit time integration while retaining its efficiency. The error analysis relies on elliptic reconstructors and abstract grid transfer operators, which allows for use-defined elliptic error estimators. Numerical results using the elliptic Babu\v{s}ka-Rheinboldt estimators illustrate the optimal rate of convergence with mesh size of the aposteriori error estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16933v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcus J. Grote, Omar Lakkis, Carina Santos</dc:creator>
    </item>
    <item>
      <title>Local analysis of iterative reconstruction from discrete generalized Radon transform data in the plane</title>
      <link>https://arxiv.org/abs/2412.15910</link>
      <description>arXiv:2412.15910v2 Announce Type: replace 
Abstract: Local reconstruction analysis (LRA) is a powerful and flexible technique to study images reconstructed from discrete generalized Radon transform (GRT) data, $g=\mathcal R f$. The main idea of LRA is to obtain a simple formula to accurately approximate an image, $f_\epsilon(x)$, reconstructed from discrete data $g(y_j)$ in an $\epsilon$-neighborhood of a point, $x_0$. The points $y_j$ lie on a grid with step size of order $\epsilon$ in each direction. In this paper we study an iterative reconstruction algorithm, which consists of minimizing a quadratic cost functional. The cost functional is the sum of a data fidelity term and a Tikhonov regularization term. The function $f$ to be reconstructed has a jump discontinuity across a smooth surface $\mathcal S$. Fix a point $x_0\in\mathcal S$ and any $A&gt;0$. The main result of the paper is the computation of the limit $\Delta F_0(\check x;x_0):=\lim_{\epsilon\to0}(f_\epsilon(x_0+\epsilon\check x)-f_\epsilon(x_0))$, where $f_\epsilon$ is the solution to the minimization problem and $|\check x|\le A$. A numerical experiment with a circular GRT demonstrates that $\Delta F_0(\check x;x_0)$ accurately approximates the actual reconstruction obtained by the cost functional minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15910v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Katsevich</dc:creator>
    </item>
    <item>
      <title>Compression Properties for large Toeplitz-like matrices</title>
      <link>https://arxiv.org/abs/2502.09823</link>
      <description>arXiv:2502.09823v2 Announce Type: replace 
Abstract: Toeplitz matrices are abundant in computational mathematics, and there is a rich literature on the development of fast and superfast algorithms for solving linear systems involving such matrices. Any Toeplitz matrix can be transformed into a matrix with off-diagonal blocks that are of low numerical rank.This compressibility is relied upon in practice in a number of superfast Toeplitz solvers. In this paper, we show that the compression properties of these matrices can be thoroughly explained using their displacement structure. We provide explicit bounds on the numerical ranks of important submatrices that arise when applying HSS, HODLR and other approximations with hierarchical low-rank structure to transformed Toeplitz and Toeplitz-like matrices. Our results lead to very efficient displacement-based compression strategies that can be used to formulate adaptive superfast rank-structured solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09823v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bernhard Beckermann, Daniel Kressner, Heather Wilber</dc:creator>
    </item>
    <item>
      <title>Lagrangian finite elements in Sobolev-like spaces of order $3/2$</title>
      <link>https://arxiv.org/abs/2504.11920</link>
      <description>arXiv:2504.11920v3 Announce Type: replace 
Abstract: This paper introduces a Sobolev-like space of order $3/2$, denoted as $\widehat{H}^{3/2}$, for Lagrangian finite elements, especially for $C^0$ elements. It is motivated by the limitations of current stability analysis of the evolving surface finite element method (ESFEM), which relies exclusively on an energy estimate framework. To establish a PDE-based analysis framework for ESFEM, we encounter a fundamental regularity mismatch: the ESFEM adopts the $C^0$ elements, while the PDE regularity theory requires $H^{3/2}$ regularity for solutions. To overcome this difficulty, we first examine the properties of the continuous $H^{3/2}$ space, then introduce a Dirichlet lift and Scott-Zhang type interpolation operators to bridge to the discrete $\widehat{H}^{3/2}$ space. Our new $\widehat{H}^{3/2}$ space is shown to be compatible with the elliptic PDE regularity theory, the trace inequality, and the inverse inequality. Notably, we extend the critical domain deformation estimate in ESFEM to the $\widehat{H}^{3/2}$ setting. The $\widehat{H}^{3/2}$ theory provides a foundation for establishing a PDE-based convergence analysis framework of ESFEM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11920v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Li</dc:creator>
    </item>
    <item>
      <title>Convergence of finite elements for the Eyles-King-Styles model of tumour growth</title>
      <link>https://arxiv.org/abs/2504.11926</link>
      <description>arXiv:2504.11926v2 Announce Type: replace 
Abstract: This paper presents a convergence analysis of evolving surface finite element methods (ESFEM) applied to the original Eyles-King-Styles model of tumour growth. The model consists of a Poisson equation in the bulk, a forced mean curvature flow on the surface, and a coupled velocity law between bulk and surface. Due to the non-trivial bulk-surface coupling, all previous analyses -- which exclusively relied on energy-estimate based approaches -- required an additional regularization term. By adopting the $\widehat{H}^{3/2}$ theory and the multilinear forms, we develop an essentially new theoretical framework that enables the application of PDE regularity theory to stability analysis. Based on this framework, we provide the first rigorous convergence proof for the original model without regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11926v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Li</dc:creator>
    </item>
    <item>
      <title>Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems</title>
      <link>https://arxiv.org/abs/2505.00460</link>
      <description>arXiv:2505.00460v2 Announce Type: replace 
Abstract: In situations where the solution of a high-fidelity dynamical system needs to be evaluated repeatedly, over a vast pool of parametric configurations and in absence of access to the underlying governing equations, data-driven model reduction techniques are preferable. We propose a novel active learning approach to build a parametric data-driven reduced-order model (ROM) by greedily picking the most important parameter samples from the parameter domain. As a result, during the ROM construction phase, the number of high-fidelity solutions dynamically grow in a principled fashion. The high-fidelity solution snapshots are expressed in several parameter-specific linear subspaces, with the help of proper orthogonal decomposition (POD), and the relative distance between these subspaces is used as a guiding mechanism to perform active learning. For successfully achieving this, we provide a distance measure to evaluate the similarity between pairs of linear subspaces with different dimensions, and also show that this distance measure is a metric. The usability of the proposed subspace-distance-enabled active learning (SDE-AL) framework is demonstrated by augmenting two existing non-intrusive reduced-order modeling approaches, and providing their active-learning-driven (ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN. Furthermore, we report positive results for two parametric physical models, highlighting the efficiency of the proposed SDE-AL approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00460v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harshit Kapadia, Peter Benner, Lihong Feng</dc:creator>
    </item>
    <item>
      <title>Exact operator inference with minimal data</title>
      <link>https://arxiv.org/abs/2506.01244</link>
      <description>arXiv:2506.01244v2 Announce Type: replace 
Abstract: This work introduces a novel method to generate snapshot data for operator inference that guarantees the exact reconstruction of intrusive projection-based reduced-order models (ROMs). To ensure exact reconstruction, the operator inference least squares matrix must have full rank, without regularization. Existing works have achieved this full rank using heuristic strategies to generate snapshot data and a-posteriori checks on full rank, but without a guarantee of success. Our novel snapshot data generation method provides this guarantee thanks to two key ingredients: first we identify ROM states that induce full rank, then we generate snapshots corresponding to exactly these states by simulating multiple trajectories for only a single time step. This way, the number of required snapshots is minimal and orders of magnitude lower than typically reported with existing methods. The method avoids non-Markovian terms and does not require re-projection. Since the number of snapshots is minimal, the least squares problem simplifies to a linear system that is numerically more stable. In addition, because the inferred operators are exact, properties of the intrusive ROM operators such as symmetry or skew-symmetry are preserved. Numerical results for differential equations involving 2nd, 3rd and 8th order polynomials demonstrate that the novel snapshot data generation method leads to exact reconstruction of the intrusive reduced order models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01244v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Henrik Rosenberger, Benjamin Sanderse, Giovanni Stabile</dc:creator>
    </item>
    <item>
      <title>A fast and memoryless numerical method for solving fractional differential equations</title>
      <link>https://arxiv.org/abs/2506.04188</link>
      <description>arXiv:2506.04188v2 Announce Type: replace 
Abstract: The numerical solution of implicit and stiff differential equations by implicit numerical integrators has been largely investigated and there exist many excellent efficient codes available in the scientific community, as Radau5 (based on a Runge-Kutta collocation method at Radau points) and Dassl, based on backward differentiation formulas, among the others. When solving fractional ordinary differential equations (ODEs), the derivative operator is replaced by a non-local one and the fractional ODE is reformulated as a Volterra integral equation, to which these codes cannot be directly applied.
  This article is a follow-up of the article by the authors (Guglielmi and Hairer, SISC, 2025) for differential equations with distributed delays. The main idea is to approximate the fractional kernel $t^{\alpha -1}/ \Gamma (\alpha )$ ($\alpha &gt;0$) by a sum of exponential functions or by a sum of exponential functions multiplied by a monomial, and then to transform the fractional integral (of convolution type) into a set of ordinary differential equations. The augmented system is typically stiff and thus requires the use of an implicit method. It can have a very large dimension and requires a special treatment of the arising linear systems.
  The present work presents an algorithm for the construction of an approximation of the fractional kernel by a sum of exponential functions, and it shows how the arising linear systems in a stiff time integrator can be solved efficiently. It is explained how the code Radau5 can be used for solving fractional differential equations. Numerical experiments illustrate the accuracy and the efficiency of the proposed method. Driver examples are publicly available from the homepages of the authors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04188v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Guglielmi, Ernst Hairer</dc:creator>
    </item>
    <item>
      <title>From eigenvector nonlinearities to eigenvalue nonlinearities</title>
      <link>https://arxiv.org/abs/2506.16182</link>
      <description>arXiv:2506.16182v2 Announce Type: replace 
Abstract: Over the past decades, transformations between different classes of eigenvalue problems have played a central role in the development of numerical methods for eigenvalue computations. One of the most well-known and successful examples of this is the companion linearization for polynomial eigenvalue problems. In this paper, we construct a transformation that equivalently reframes a specific type of eigenvalue problem with eigenvector nonlinearities (NEPv) into an eigenvalue problem with eigenvalue nonlinearities (NEP). The NEPv class considered consists of nonlinearities expressed as sums of products of matrices and scalar functions, where the scalar functions depend nonlinearly on the eigenvector. Our transformation defines scalar eigenvalue nonlinearities through a polynomial system, resulting in NEP nonlinearities of algebraic type. We propose methods to solve the polynomial system, one of which involves a multiparameter eigenvalue problem (MEP). We adapt well-established NEP solvers to this setting, with the most effective strategy being a combination of deflation and a locally quadratically convergent iterative method. The efficiency and properties of the approach are illustrated by solving a problem related to a modification of a Gross-Pitaevskii equation (GPE). The simulations are reproducible and publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16182v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elias Jarlebring, Vilhelm P. Lithell</dc:creator>
    </item>
    <item>
      <title>A quasi-Grassmannian gradient flow model for eigenvalue problems</title>
      <link>https://arxiv.org/abs/2506.20195</link>
      <description>arXiv:2506.20195v2 Announce Type: replace 
Abstract: We propose a quasi-Grassmannian gradient flow model for eigenvalue problems of linear operators, aiming to efficiently address many eigenpairs. Our model inherently ensures asymptotic orthogonality: without the need for initial orthogonality, the solution naturally evolves toward being orthogonal over time. We establish the well-posedness of the model, and provide the analytical representation of solutions. Through asymptotic analysis, we show that the gradient converges exponentially to zero and that the energy decreases exponentially to its minimum. This implies that the solution of the quasi-Grassmannian gradient flow model converges to the solution of the eigenvalue problems as time progresses. These properties not only eliminate the need for explicit orthogonalization in numerical computation but also significantly enhance robustness of the model, rendering it far more resilient to numerical perturbations than conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20195v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengyue Wang, Aihui Zhou</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap Between Approximation and Learning via Optimal Approximation by ReLU MLPs of Maximal Regularity</title>
      <link>https://arxiv.org/abs/2409.12335</link>
      <description>arXiv:2409.12335v4 Announce Type: replace-cross 
Abstract: The foundations of deep learning are supported by the seemingly opposing perspectives of approximation or learning theory. The former advocates for large/expressive models that need not generalize, while the latter considers classes that generalize but may be too small/constrained to be universal approximators. Motivated by real-world deep learning implementations that are both expressive and statistically reliable, we ask: "Is there a class of neural networks that is both large enough to be universal but structured enough to generalize?" This paper constructively provides a positive answer to this question by identifying a highly structured class of ReLU multilayer perceptions (MLPs), which are optimal function approximators and are statistically well-behaved. We show that any $(L,\alpha)$-H\"{o}lder function from $[0,1]^d$ to $[-n,n]$ can be approximated to a uniform $\mathcal{O}(1/n)$ error on $[0,1]^d$ with a sparsely connected ReLU MLP with the same H\"{o}lder exponent $\alpha$ and coefficient $L$, of width $\mathcal{O}(dn^{d/\alpha})$, depth $\mathcal{O}(\log(d))$, with $\mathcal{O}(dn^{d/\alpha})$ nonzero parameters, and whose weights and biases take values in $\{0,\pm 1/2\}$ except in the first and last layers which instead have magnitude at-most $n$. Further, our class of MLPs achieves a near-optimal sample complexity of $\mathcal{O}(\log(N)/\sqrt{N})$ when given $N$ i.i.d. normalized sub-Gaussian training samples. We achieve this through a new construction that perfectly fits together linear pieces using Kuhn triangulations, along with a new proof technique which shows that our construction preserves the regularity of not only the H\"{o}lder functions, but also any uniformly continuous function. Our results imply that neural networks can solve the McShane extension problem on suitable finite sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12335v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiyang Hong, Anastasis Kratsios</dc:creator>
    </item>
    <item>
      <title>Error bounds for Physics Informed Neural Networks in Nonlinear Schr\"odinger equations placed on unbounded domains</title>
      <link>https://arxiv.org/abs/2409.17938</link>
      <description>arXiv:2409.17938v3 Announce Type: replace-cross 
Abstract: We consider the subcritical nonlinear Schr\"odinger (NLS) in dimension one posed on the unbounded real line. Several previous works have considered the deep neural network approximation of NLS solutions from the numerical and theoretical point of view in the case of bounded domains. In this paper, we introduce a new PINNs method to treat the case of unbounded domains and show rigorous bounds on the associated approximation error in terms of the energy and Strichartz norms, provided a reasonable integration scheme is available. Applications to traveling waves, breathers and solitons, as well as numerical experiments confirming the validity of the approximation are also presented as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17938v3</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miguel \'A. Alejo, Lucrezia Cossetti, Luca Fanelli, Claudio Mu\~noz, Nicol\'as Valenzuela</dc:creator>
    </item>
    <item>
      <title>The Sample Complexity of Learning Lipschitz Operators with respect to Gaussian Measures</title>
      <link>https://arxiv.org/abs/2410.23440</link>
      <description>arXiv:2410.23440v3 Announce Type: replace-cross 
Abstract: Operator learning, the approximation of mappings between infinite-dimensional function spaces using machine learning, has gained increasing research attention in recent years. Approximate operators, learned from data, can serve as efficient surrogate models for problems in computational science and engineering, complementing traditional methods. However, despite their empirical success, our understanding of the underlying mathematical theory is in large part still incomplete. In this paper, we study the approximation of Lipschitz operators with respect to Gaussian measures. We prove higher Gaussian Sobolev regularity of Lipschitz operators and establish lower and upper bounds on the Hermite polynomial approximation error. We then study general reconstruction strategies of Lipschitz operators from $m$ arbitrary (potentially adaptive) linear samples. As a key finding, we tightly characterize the corresponding sample complexity, that is, the smallest achievable worst-case error among all possible choices of (adaptive) sampling and reconstruction strategies in terms of $m$. As a consequence, we identify an inherent curse of sample complexity: No method to approximate Lipschitz operators based on $m$ linear samples can achieve algebraic convergence rates in $m$. On the positive side, we prove that a sufficiently fast spectral decay of the covariance operator of the underlying Gaussian measure guarantees convergence rates which are arbitrarily close to any algebraic rate. Overall, by tightly characterizing the sample complexity, our work confirms the intrinsic difficulty of learning Lipschitz operators, regardless of the data or learning technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23440v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Adcock, Michael Griebel, Gregor Maier</dc:creator>
    </item>
    <item>
      <title>A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques</title>
      <link>https://arxiv.org/abs/2506.16663</link>
      <description>arXiv:2506.16663v3 Announce Type: replace-cross 
Abstract: High-dimensional image data often require dimensionality reduction before further analysis. This paper provides a purely analytical comparison of two linear techniques-Principal Component Analysis (PCA) and Singular Value Decomposition (SVD). After the derivation of each algorithm from first principles, we assess their interpretability, numerical stability, and suitability for differing matrix shapes. We synthesize rule-of-thumb guidelines for choosing one out of the two algorithms without empirical benchmarking, building on classical and recent numerical literature. Limitations and directions for future experimental work are outlined at the end.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16663v3</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Gyimadu, Gregory Bell, Ph. D</dc:creator>
    </item>
  </channel>
</rss>
