<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jul 2025 01:27:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping</title>
      <link>https://arxiv.org/abs/2507.01411</link>
      <description>arXiv:2507.01411v1 Announce Type: new 
Abstract: Grey matter loss in the hippocampus is a hallmark of neurobiological aging, yet understanding the corresponding changes in its functional connectivity remains limited. Seed-based functional connectivity (FC) analysis enables voxel-wise mapping of the hippocampus's synchronous activity with cortical regions, offering a window into functional reorganization during aging. In this study, we develop an interpretable deep learning framework to predict brain age from hippocampal FC using a three-dimensional convolutional neural network (3D CNN) combined with LayerCAM saliency mapping. This approach maps key hippocampal-cortical connections, particularly with the precuneus, cuneus, posterior cingulate cortex, parahippocampal cortex, left superior parietal lobule, and right superior temporal sulcus, that are highly sensitive to age. Critically, disaggregating anterior and posterior hippocampal FC reveals distinct mapping aligned with their known functional specializations. These findings provide new insights into the functional mechanisms of hippocampal aging and demonstrate the power of explainable deep learning to uncover biologically meaningful patterns in neuroimaging data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01411v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Sun, Marshall A. Dalton, Robert D. Sanders, Yixuan Yuan, Xiang Li, Sharon L. Naismith, Fernando Calamante, Jinglei Lv</dc:creator>
    </item>
    <item>
      <title>Reduced Efficiency in the Attentional Network During Distractor Suppression in Mild Cognitive Impairment</title>
      <link>https://arxiv.org/abs/2507.01433</link>
      <description>arXiv:2507.01433v2 Announce Type: new 
Abstract: Mild Cognitive Impairment (MCI) is a critical transitional stage between normal cognitive aging and dementia, making its early detection essential. This study investigates the neural mechanisms of distractor suppression in MCI patients using EEG and behavioral data during an attention-cueing Eriksen flanker task. A cohort of 56 MCIs and 26 healthy controls (HCs) performed tasks with congruent and incongruent stimuli of varying saliency levels. During these tasks, EEG data were analyzed for alpha band coherence's functional connectivity, focusing on Global Efficiency (GE), while Reaction Time (RT) and Hit Rate (HR) were also collected.
  Our findings reveal significant interactions between congruency, saliency, and cognitive status on GE, RT, and HR. In HCs, congruent conditions resulted in higher GE (p = 0.0114, multivariate t-distribution correction, MVT), faster RTs (p &lt; 0.0001, MVT), and higher HRs (p &lt; 0.0001, MVT) compared to incongruent conditions. HCs also showed increased GE in salient conditions for incongruent trials (p = 0.0406, MVT). MCIs exhibited benefits from congruent conditions with shorter RTs and higher HRs (both p &lt; 0.0001, MVT) compared to incongruent conditions but showed reduced adaptability in GE, with no significant GE differences between conditions.
  These results highlight the potential of alpha band coherence and GE as early markers for cognitive impairment. By integrating GE, RT, and HR, this study provides insights into the interplay between neural efficiency, processing speed, and task accuracy. This approach offers valuable insights into cognitive load management and interference effects, indicating benefits for interventions aimed at improving attentional control and processing speed in MCIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01433v2</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jatupong Oboun, Piyanon Charoenpoonpanich, Anna Raksapatcharawong, Chaipat Chunharas, Itthi Chatnuntawech, Chainarong Amornbunchornvej, Sirawaj Itthipuripat</dc:creator>
    </item>
    <item>
      <title>Proof of a perfect platonic representation hypothesis</title>
      <link>https://arxiv.org/abs/2507.01098</link>
      <description>arXiv:2507.01098v1 Announce Type: cross 
Abstract: In this note, we elaborate on and explain in detail the proof given by Ziyin et al. (2025) of the "perfect" Platonic Representation Hypothesis (PRH) for the embedded deep linear network model (EDLN). We show that if trained with SGD, two EDLNs with different widths and depths and trained on different data will become Perfectly Platonic, meaning that every possible pair of layers will learn the same representation up to a rotation. Because most of the global minima of the loss function are not Platonic, that SGD only finds the perfectly Platonic solution is rather extraordinary. The proof also suggests at least six ways the PRH can be broken. We also show that in the EDLN model, the emergence of the Platonic representations is due to the same reason as the emergence of progressive sharpening. This implies that these two seemingly unrelated phenomena in deep learning can, surprisingly, have a common cause. Overall, the theory and proof highlight the importance of understanding emergent "entropic forces" due to the irreversibility of SGD training and their role in representation learning. The goal of this note is to be instructive and avoid lengthy technical details.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01098v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liu Ziyin, Isaac Chuang</dc:creator>
    </item>
    <item>
      <title>A Dynamical Cartography of the Epistemic Diffusion of Artificial Intelligence in Neuroscience</title>
      <link>https://arxiv.org/abs/2507.01651</link>
      <description>arXiv:2507.01651v1 Announce Type: cross 
Abstract: Neuroscience and AI have an intertwined history, largely relayed in the literature of both fields. In recent years, due to the engineering orientations of AI research and the monopoly of industry for its large-scale applications, the mutual expansion of neuroscience and AI in fundamental research seems challenged. In this paper, we bring some empirical evidences that, on the contrary, AI and neuroscience are continuing to grow together, but with a pronounced interest in the fields of study related to neurodegenerative diseases since the 1990s. With a temporal knowledge cartography of neuroscience drawn with advanced document embedding techniques, we draw the dynamical shaping of the discipline since the 1970s and identified the conceptual articulation of AI with this particular subfield mentioned before. However, a further analysis of the underlying citation network of the studied corpus shows that the produced AI technologies remain confined in the different subfields and are not transferred from one subfield to another. This invites us to discuss the genericity capability of AI in the context of an intradisciplinary development, especially in the diffusion of its associated metrology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01651v1</guid>
      <category>cs.DL</category>
      <category>physics.soc-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sylvain Fontaine</dc:creator>
    </item>
    <item>
      <title>Characterizing control between interacting subsystems with deep Jacobian estimation</title>
      <link>https://arxiv.org/abs/2507.01946</link>
      <description>arXiv:2507.01946v1 Announce Type: cross 
Abstract: Biological function arises through the dynamical interactions of multiple subsystems, including those between brain areas, within gene regulatory networks, and more. A common approach to understanding these systems is to model the dynamics of each subsystem and characterize communication between them. An alternative approach is through the lens of control theory: how the subsystems control one another. This approach involves inferring the directionality, strength, and contextual modulation of control between subsystems. However, methods for understanding subsystem control are typically linear and cannot adequately describe the rich contextual effects enabled by nonlinear complex systems. To bridge this gap, we devise a data-driven nonlinear control-theoretic framework to characterize subsystem interactions via the Jacobian of the dynamics. We address the challenge of learning Jacobians from time-series data by proposing the JacobianODE, a deep learning method that leverages properties of the Jacobian to directly estimate it for arbitrary dynamical systems from data alone. We show that JacobianODEs outperform existing Jacobian estimation methods on challenging systems, including high-dimensional chaos. Applying our approach to a multi-area recurrent neural network (RNN) trained on a working memory selection task, we show that the "sensory" area gains greater control over the "cognitive" area over learning. Furthermore, we leverage the JacobianODE to directly control the trained RNN, enabling precise manipulation of its behavior. Our work lays the foundation for a theoretically grounded and data-driven understanding of interactions among biological subsystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01946v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adam J. Eisen, Mitchell Ostrow, Sarthak Chandra, Leo Kozachkov, Earl K. Miller, Ila R. Fiete</dc:creator>
    </item>
    <item>
      <title>Strong, but not weak, noise correlations are beneficial for population coding</title>
      <link>https://arxiv.org/abs/2406.18439</link>
      <description>arXiv:2406.18439v3 Announce Type: replace 
Abstract: Neural correlations play a critical role in sensory information coding. They are of two kinds: signal correlations, when neurons have overlapping sensitivities, and noise correlations from network effects and shared noise. In experiments from early sensory systems and cortex, many pairs of neurons typically show both types of correlations to be positive and large, especially between nearby neurons with similar stimulus sensitivity. However, theoretical arguments have suggested that stimulus and noise correlations should have opposite signs to improve coding, at odds with experimental observations. We analyze retinal recording in response to a large variety of stimuli, and show that, contrary to common belief, large noise correlations are beneficial for coding, even if aligned with signal correlations. To understand this result, we develop a theory of visual information coding by correlated neurons, which resolves that paradox. We show that noise correlations are always beneficial if they are strong enough, unless neurons are perfectly correlated by the stimulus. Finally, using neuronal recordings and modeling, we show that for high dimensional stimuli noise correlation benefits the encoding of fine-grained details of visual stimuli, at the expense of large-scale features, which are already well encoded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18439v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Mahuas, Thomas Buffet, Olivier Marre, Ulisse Ferrari, Thierry Mora</dc:creator>
    </item>
    <item>
      <title>How Metacognitive Architectures Remember Their Own Thoughts: A Systematic Review</title>
      <link>https://arxiv.org/abs/2503.13467</link>
      <description>arXiv:2503.13467v2 Announce Type: replace 
Abstract: Background: Metacognition has gained significant attention for its potential to enhance autonomy and adaptability of artificial agents but remains a fragmented field: diverse theories, terminologies, and design choices have led to disjointed developments and limited comparability across systems. Existing overviews remain at a conceptual level that is undiscerning to the underlying algorithms, representations, and their respective success.
  Methods: We address this gap by performing an explorative systematic review. Reports were included if they described techniques enabling Computational Metacognitive Architectures (CMAs) to model, store, remember, and process their episodic metacognitive experiences, one of Flavell's (1979a) three foundational components of metacognition. Searches were conducted in 16 databases, consulted between December 2023 and June 2024. Data were extracted using a 20-item framework considering pertinent aspects.
  Results: A total of 101 reports on 35 distinct CMAs were included. Our findings show that metacognitive experiences may boost system performance and explainability, e.g., via self-repair. However, lack of standardization and limited evaluations may hinder progress: only 17% of CMAs were quantitatively evaluated regarding this review's focus, and significant terminological inconsistency limits cross-architecture synthesis. Systems also varied widely in memory content, data types, and employed algorithms.
  Discussion: Limitations include the non-iterative nature of the search query, heterogeneous data availability, and an under-representation of emergent, sub-symbolic CMAs. Future research should focus on standardization and evaluation, e.g., via community-driven challenges, and on transferring promising principles to emergent architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13467v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Nolte, Mihai Pomarlan, Ayden Janssen, Daniel Be{\ss}ler, Kamyar Javanmardi, Sascha Jongebloed, Robert Porzel, John Bateman, Michael Beetz, Rainer Malaka</dc:creator>
    </item>
    <item>
      <title>Convergent and divergent connectivity patterns of the arcuate fasciculus in macaques and humans</title>
      <link>https://arxiv.org/abs/2506.19266</link>
      <description>arXiv:2506.19266v2 Announce Type: replace 
Abstract: The organization and connectivity of the arcuate fasciculus (AF) in nonhuman primates remain contentious, especially concerning how its anatomy diverges from that of humans. Here, we combined cross-scale single-neuron tracing - using viral-based genetic labeling and fluorescence micro-optical sectioning tomography in macaques (n = 4; age 3 - 11 years) - with whole-brain tractography from 11.7T diffusion MRI. Complemented by spectral embedding analysis of 7.0T MRI in humans, we performed a comparative connectomic analysis of the AF across species. We demonstrate that the macaque AF originates in the temporal-parietal cortex, traverses the auditory cortex and parietal operculum, and projects into prefrontal regions. In contrast, the human AF exhibits greater expansion into the middle temporal gyrus and stronger prefrontal and parietal operculum connectivity - divergences quantified by Kullback-Leibler analysis that likely underpin the evolutionary specialization of human language networks. These interspecies differences - particularly the human AF's broader temporal integration and strengthened frontoparietal linkages - suggest a connectivity-based substrate for the emergence of advanced language processing unique to humans. Furthermore, our findings offer a neuroanatomical framework for understanding AF-related disorders such as aphasia and dyslexia, where aberrant connectivity disrupts language function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19266v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahao Huang, Ruifeng Li, Wenwen Yu, Anan Li, Xiangning Li, Mingchao Yan, Lei Xie, Qingrun Zeng, Xueyan Jia, Shuxin Wang, Ronghui Ju, Feng Chen, Qingming Luo, Hui Gong, Andrew Zalesky, Xiaoquan Yang, Yuanjing Feng, Zheng Wang</dc:creator>
    </item>
  </channel>
</rss>
