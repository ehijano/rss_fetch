<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Mar 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Digital Twin Simulator of a Pastillation Process with Applications to Automatic Control based on Computer Vision</title>
      <link>https://arxiv.org/abs/2503.16539</link>
      <description>arXiv:2503.16539v1 Announce Type: new 
Abstract: We present a digital-twin simulator for a pastillation process. The simulation framework produces realistic thermal image data of the process that is used to train computer vision-based soft sensors based on convolutional neural networks (CNNs); the soft sensors produce output signals for temperature and product flow rate that enable real-time monitoring and feedback control. Pastillation technologies are high-throughput devices that are used in a broad range of industries; these processes face operational challenges such as real-time identification of clog locations (faults) in the rotating shell and the automatic, real-time adjustment of conveyor belt speed and operating conditions to stabilize output. The proposed simulator is able to capture this behavior and generates realistic data that can be used to benchmark different algorithms for image processing and different control architectures. We present a case study to illustrate the capabilities; the study explores behavior over a range of equipment sizes, clog locations, and clog duration. A feedback controller (tuned using Bayesian optimization) is used to adjust the conveyor belt speed based on the CNN output signal to achieve the desired process outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16539v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo D. Gonz\'alez (Department of Chemical &amp; Biological Engineering, University of Wisconsin-Madison, Madison, USA), Joshua L. Pulsipher (Department of Chemical Engineering, University of Waterloo, Waterloo, Canada), Shengli Jiang (Chemical &amp; Biological Engineering Department, Princeton University, Princeton, USA), Tyler Soderstrom (Advanced Process Control, ExxonMobil Technology and Engineering, Spring, USA), Victor M. Zavala (Department of Chemical &amp; Biological Engineering, University of Wisconsin-Madison, Madison, USA)</dc:creator>
    </item>
    <item>
      <title>Concurrent Optimization of Satellite Phasing and Tasking for Cislunar Space Situational Awareness</title>
      <link>https://arxiv.org/abs/2503.16617</link>
      <description>arXiv:2503.16617v1 Announce Type: new 
Abstract: Recently, renewed interest in cislunar space spurred by private and public organizations has driven research for future infrastructure in the region. As Earth-Moon traffic increases amidst a growing space economy, monitoring architectures supporting this traffic must also develop. These are likely to be realized as constellations of patrol satellites surveying traffic between the Earth and the Moon. This work investigates the concurrent optimization of patrol satellite phasing and tasking to provide information-maximal coverage of traffic in periodic orbits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16617v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Malav Patel, Kento Tomita, Koki Ho</dc:creator>
    </item>
    <item>
      <title>Gradient sampling algorithm for subsmooth functions</title>
      <link>https://arxiv.org/abs/2503.16638</link>
      <description>arXiv:2503.16638v1 Announce Type: new 
Abstract: This paper considers non-smooth optimization problems where we seek to minimize the pointwise maximum of a continuously parameterized family of functions. Since the objective function is given as the solution to a maximization problem, neither its values nor its gradients are available in closed form, which calls for approximation. Our approach hinges upon extending the so-called gradient sampling algorithm, which approximates the Clarke generalized gradient of the objective function at a point by sampling its derivative at nearby locations. This allows us to select descent directions around points where the function may fail to be differentiable and establish algorithm convergence to a stationary point from any initial condition. Our key contribution is to prove this convergence by alleviating the requirement on continuous differentiability of the objective function on an open set of full measure. We further provide assumptions under which a desired convex subset of the decision space is rendered attractive for the iterates of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16638v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitris Boskos, Jorge Cort\'es, Sonia Mart\'inez</dc:creator>
    </item>
    <item>
      <title>A Unified Column Generation and Elimination Method for Solving Large-Scale Set Partitioning Problems</title>
      <link>https://arxiv.org/abs/2503.16652</link>
      <description>arXiv:2503.16652v1 Announce Type: new 
Abstract: The Set Partitioning Problem is a combinatorial optimization problem with wide-ranging applicability, used to model various real-world tasks such as facility location and crew scheduling. However, real-world applications often require solving large-scale instances that involve hundreds of thousands of variables. Although the conventional Column Generation method is popular for its computational efficiency, it lacks a guarantee for exact solutions. This paper proposes a novel solution method integrating relaxation of Column Generation conditions and automatic elimination of redundant columns, aimed at overcoming the limitations of conventional Column Generation methods in guaranteeing exact optimal solutions. Numerical experiments using actual bus route data reveal that while the traditional method achieves an exact solution rate of only about 3%, the proposed method attains a rate of approximately 99% and remarkably improves solution accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16652v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasuyuki Ihara</dc:creator>
    </item>
    <item>
      <title>Subgradient Method for System Identification with Non-Smooth Objectives</title>
      <link>https://arxiv.org/abs/2503.16673</link>
      <description>arXiv:2503.16673v1 Announce Type: new 
Abstract: This paper investigates a subgradient-based algorithm to solve the system identification problem for linear time-invariant systems with non-smooth objectives. This is essential for robust system identification in safety-critical applications. While existing work provides theoretical exact recovery guarantees using optimization solvers, the design of fast learning algorithms with convergence guarantees for practical use remains unexplored. We analyze the subgradient method in this setting where the optimization problems to be solved change over time as new measurements are taken, and we establish linear convergence results for both the best and Polyak step sizes after a burn-in period. Additionally, we characterize the asymptotic convergence of the best average sub-optimality gap under diminishing and constant step sizes. Finally, we compare the time complexity of standard solvers with the subgradient algorithm and support our findings with experimental results. This is the first work to analyze subgradient algorithms for system identification with non-smooth objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16673v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Baturalp Yalcin, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>One-Point Residual Feedback Algorithms for Distributed Online Convex and Non-convex Optimization</title>
      <link>https://arxiv.org/abs/2503.16845</link>
      <description>arXiv:2503.16845v1 Announce Type: new 
Abstract: This paper mainly addresses the distributed online optimization problem where the local objective functions are assumed to be convex or non-convex. First, the distributed algorithms are proposed for the convex and non-convex situations, where the one-point residual feedback technology is introduced to estimate gradient of local objective functions. Then the regret bounds of the proposed algorithms are derived respectively under the assumption that the local objective functions are Lipschitz or smooth, which implies that the regrets are sublinear. Finally, we give two numerical examples of distributed convex optimization and distributed resources allocation problem to illustrate the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16845v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaowen Wang, Lipo Mo, Min Zuo, Yuanshi Zheng</dc:creator>
    </item>
    <item>
      <title>Second Order Fully Nonlinear Mean Field Games with Degenerate Diffusions</title>
      <link>https://arxiv.org/abs/2503.16869</link>
      <description>arXiv:2503.16869v1 Announce Type: new 
Abstract: In this article, we study the global-in-time well-posedness of second order mean field games (MFGs) with both nonlinear drift functions simultaneously depending on the state, distribution and control variables, and the diffusion term depending on both state and distribution. Besides, the diffusion term is allowed to be degenerate, unbounded and even nonlinear in the distribution, but it does not depend on the control. First, we establish the global well-posedness of the corresponding forward-backward stochastic differential equations (FBSDEs), which arise from the maximum principle under a so-called $\beta$-monotonicity commonly used in the optimal control theory. The $\beta$-monotonicity admits more interesting cases, as representative examples including but not limited to the displacement monotonicity, the small mean field effect condition or the Lasry-Lions monotonicity; and ensures the well-posedness result in diverse non-convex examples. In our settings, we pose assumptions directly on the drift and diffusion coefficients and the cost functionals, rather than indirectly on the Hamiltonian, to make the conditions more visible. Our probabilistic method tackles the nonlinear dynamics with a linear but infinite dimensional version, and together with our recently proposed cone property for the adjoint processes, following in an almost straightforward way the conventional approach to the classical stochastic control problem, we derive a sufficiently good regularity of the value functional, and finally show that it is the unique classical solution to the MFG master equation. Our results require fairly few conditions on the functional coefficients for solution of the MFG, and a bit more conditions -- which are least stringent in the contemporary literature -- for classical solution of the MFG master equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16869v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alain Bensoussan, Ziyu Huang, Shanjian Tang, Sheung Chi Phillip Yam</dc:creator>
    </item>
    <item>
      <title>Revisiting implicit variables in mathematical optimization: simplified modeling and a numerical evidence</title>
      <link>https://arxiv.org/abs/2503.16902</link>
      <description>arXiv:2503.16902v1 Announce Type: new 
Abstract: Implicit variables of an optimization problem are used to model variationally challenging feasibility conditions in a tractable way while not entering the objective function. Hence, it is a standard approach to treat implicit variables as explicit ones. Recently, it has been shown in terms of a comparatively complex model problem that this approach, generally, is theoretically disadvantageous as the surrogate problem typically suffers from the presence of artificial stationary points and the need for stronger constraint qualifications. The purpose of the present paper is twofold. First, it introduces a much simpler and easier accessible model problem which can be used to recapitulate and even broaden the aforementioned findings. Indeed, we will extend the analysis to two more classes of stationary points and the associated constraint qualifications. These theoretical results are accompanied by illustrative examples from cardinality-constrained, vanishing-constrained, and bilevel optimization. Second, the present paper illustrates, in terms of cardinality-constrained portfolio optimization problems, that treating implicit variables as explicit ones may also be disadvantageous from a numerical point of view.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16902v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Patrick Mehlitz</dc:creator>
    </item>
    <item>
      <title>Optimal Investment Portfolio of Thyristor- and IGBT-based Electrolysis Rectifiers in Utility-scale Renewable P2H Systems</title>
      <link>https://arxiv.org/abs/2503.17092</link>
      <description>arXiv:2503.17092v1 Announce Type: new 
Abstract: Renewable power-to-hydrogen (ReP2H) systems require rectifiers to supply power to electrolyzers (ELZs). Two main types of rectifiers, insulated-gate bipolar transistor rectifiers (IGBT-Rs) and thyristor rectifiers (TRs), offer distinct tradeoffs. IGBT-Rs provide flexible reactive power control but are costly, whereas TRs are more affordable with lower power loss but consume a large amount of uncontrollable reactive power. A mixed configuration of rectifiers in utility-scale ReP2H systems could achieve an decent tradeoff and increase overall profitability. To explore this potential, this paper proposes an optimal investment portfolio model. First, we model and compare the active and reactive power characteristics of ELZs powered by TRs and IGBT-Rs. Second, we consider the investment of ELZs, rectifiers, and var resources and coordinate the operation of renewables, energy storage, var resources, and the on-off switching and load allocation of multiple ELZs. Subsequently, a two-stage stochastic programming (SP) model based on weighted information gap decision theory (W-IGDT) is developed to address the uncertainties of the renewable power and hydrogen price, and we apply the progressive hedging (PH) algorithm to accelerate its solution. Case studies demonstrate that optimal rectifier configurations increase revenue by at most 2.56% compared with using only TRs or IGBT-Rs, as well as those in existing projects. Under the optimal portfolio, reactive power compensation investment is nearly eliminated, with a preferred TR-to-IGBT-R ratio of 3:1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17092v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangjun Zeng (College of Electrical Engineering, Sichuan University), Yiwei Qiu (College of Electrical Engineering, Sichuan University), Liuchao Xu (College of Electrical Engineering, Sichuan University), Chenjia Gu (College of Electrical Engineering, Sichuan University), Yi Zhou (College of Electrical Engineering, Sichuan University), Jiarong Li (Harvard John A. Paulson School of Engineering and Applied Sciences), Shi Chen (College of Electrical Engineering, Sichuan University), Buxiang Zhou (College of Electrical Engineering, Sichuan University)</dc:creator>
    </item>
    <item>
      <title>Social Optimization in Noncooperative Games under Central Regulation</title>
      <link>https://arxiv.org/abs/2503.17100</link>
      <description>arXiv:2503.17100v1 Announce Type: new 
Abstract: This paper proposes a novel optimization problem building on noncooperative games under central regulation, which can be formulated as a bilevel structure. In the low-level, each player competes to minimize its own cost function that depends not only on the strategies of all players, but also on an intervention decision of the central regulator, while the central regulator located at the high-level attempts to achieve the social optimum, that is, to minimize the sum of cost functions of all players through an adjustable intervention decision. In this setting, under the intervention of the central regulator, the low-level players perform in a noncooperative game and aim to seek the Nash equilibrium, which indeed is related with the regulator's decision. Meanwhile, the objective of the regulator is to choose a decision such that the social cost, i.e., the sum of cost functions of all players is minimum. This formulated bilevel social optimization problem is proven to be constrained, nonconvex and nonsmooth. To address this intricate problem, an inexact zeroth-order algorithm is developed by virtue of the smoothing techniques, allowing for the Nash equilibrium of the low-level game to be computed in an inexact manner. Levering the properties of smoothing techniques, it is rigorously shown that the devised algorithm achieves a sublinear convergence rate for computing a stationary point of a related optimization problem with a smoothed objective. Moreover, the sublinear convergence rate in the scenario where the exact equilibrium of the low-level game is available is also discussed. Finally, numerical simulations are conducted to demonstrate the efficiency of theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17100v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaixin Du, Min Meng, Xiuxian Li</dc:creator>
    </item>
    <item>
      <title>Isoperimetric bubbles in spaces with density $r^p + a$</title>
      <link>https://arxiv.org/abs/2503.17177</link>
      <description>arXiv:2503.17177v1 Announce Type: new 
Abstract: Least perimeter solutions for a region with fixed mass are sought in ${\mathbb{R}^d}$ on which a density function $\rho(r) = r^p+a$, with $p&gt;0, a&gt;0$, weights both perimeter and mass. On the real line ($d=1$) this is a single interval that includes the origin. For $p \le 1$ the isoperimetric interval has one end at the origin; for larger $p$ there is a critical value of $a$ above which the interval is symmetric about the origin. In the case $p=2$, for $d=2$ and $3$, the isoperimetric region is a circle or sphere, respectively, that includes the origin; the centre moves towards the origin as $a$ increases, with constant radius, and then remains centred on the origin for $a$ above the critical value as the radius decreases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17177v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Martyn Gwynne, Simon Cox</dc:creator>
    </item>
    <item>
      <title>Procrustes Wasserstein Metric: A Modified Benamou-Brenier Approach with Applications to Latent Gaussian Distributions</title>
      <link>https://arxiv.org/abs/2503.16580</link>
      <description>arXiv:2503.16580v1 Announce Type: cross 
Abstract: We introduce a modified Benamou-Brenier type approach leading to a Wasserstein type distance that allows global invariance, specifically, isometries, and we show that the problem can be summarized to orthogonal transformations. This distance is defined by penalizing the action with a costless movement of the particle that does not change the direction and speed of its trajectory. We show that for Gaussian distribution resume to measuring the Euclidean distance between their ordered vector of eigenvalues and we show a direct application in recovering Latent Gaussian distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16580v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevine Meugang Toukam</dc:creator>
    </item>
    <item>
      <title>A variational problem to calculate probabilities</title>
      <link>https://arxiv.org/abs/2503.16727</link>
      <description>arXiv:2503.16727v1 Announce Type: cross 
Abstract: In this paper, we prove the existence and uniqueness of the conditional expectation of an event $A$ given a $\sigma$-algebra $\mathcal{G}$ as a linear problem in the Lebesgue spaces $L^{p}$ associated with a probability space through the Riesz Representation Theorems. For the $L^{2}$ case, we state the Dirichlet's principle. Then, we extend this principle for specific values of $p$, framing the existence of the conditional expectation as a variational problem. We conclude with a proof of the law of total probability using these tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16727v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hugo Guadalupe Reyna-Casta\~neda, Mar\'ia de los \'Angeles Sandoval Romero</dc:creator>
    </item>
    <item>
      <title>Parallel splitting method for large-scale quadratic programs</title>
      <link>https://arxiv.org/abs/2503.16977</link>
      <description>arXiv:2503.16977v1 Announce Type: cross 
Abstract: Current algorithms for large-scale industrial optimization problems typically face a trade-off: they either require exponential time to reach optimal solutions, or employ problem-specific heuristics. To overcome these limitations, we introduce SPLIT, a general-purpose quantum-inspired framework for decomposing large-scale quadratic programs into smaller subproblems, which are then solved in parallel. SPLIT accounts for cross-interactions between subproblems, which are usually neglected in other decomposition techniques. The SPLIT framework can integrate generic subproblem solvers, ranging from standard branch-and-bound methods to quantum optimization algorithms. We demonstrate its effectiveness through comparisons with commercial solvers on the MaxCut and Antenna Placement Problems, with up to 20,000 decision variables. Our results show that SPLIT is capable of providing drastic reductions in computational time, while delivering high-quality solutions. In these regards, the proposed method is particularly suited for near real-time applications that require a solution within a strict time frame, or when the problem size exceeds the hardware limitations of dedicated devices, such as current quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16977v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Vandelli, Francesco Ferrari, Daniele Dragoni</dc:creator>
    </item>
    <item>
      <title>Optimal control on a brain tumor growth model with lactate metabolism, viscoelastic effects, and tissue damage</title>
      <link>https://arxiv.org/abs/2503.17049</link>
      <description>arXiv:2503.17049v1 Announce Type: cross 
Abstract: In this paper, we study an optimal control problem for a brain tumor growth model that incorporates lactate metabolism, viscoelastic effects, and tissue damage. The PDE system, introduced in [G. Cavalleri, P. Colli, A. Miranville, E. Rocca, On a Brain Tumor Growth Model with Lactate Metabolism, Viscoelastic Effects, and Tissue Damage (2025)], couples a Fisher-Kolmogorov type equation for tumor cell density with a reaction-diffusion equation for the lactate, a quasi-static force balance governing the displacement, and a nonlinear differential inclusion for tissue damage. The control variables, representing chemotherapy and a lactate-targeting drug, influence tumor progression and treatment response. Starting from well-posedness, regularity, and continuous dependence results already established, we define a suitable cost functional and prove the existence of optimal controls. Then, we analyze the differentiability of the control-to-state operator and establish a necessary first-order condition for treatment optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17049v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulia Cavalleri, Alain Miranville</dc:creator>
    </item>
    <item>
      <title>Throughput Maximizing Takeoff Scheduling for eVTOL Vehicles in On-Demand Urban Air Mobility Systems</title>
      <link>https://arxiv.org/abs/2503.17313</link>
      <description>arXiv:2503.17313v1 Announce Type: cross 
Abstract: Urban Air Mobility (UAM) offers a solution to current traffic congestion by using electric Vertical Takeoff and Landing (eVTOL) vehicles to provide on-demand air mobility in urban areas. Effective traffic management is crucial for efficient operation of UAM systems, especially for high-demand scenarios. In this paper, we present a centralized framework for conflict-free takeoff scheduling of eVTOLs in on-demand UAM systems. Specifically, we provide a scheduling policy, called VertiSync, which jointly schedules UAM vehicles for servicing trip requests and rebalancing, subject to safety margins and energy requirements. We characterize the system-level throughput of VertiSync, which determines the demand threshold at which the average waiting time transitions from being stable to being increasing over time. We show that the proposed policy maximizes throughput for sufficiently large fleet size and if the UAM network has a certain symmetry property. We demonstrate the performance of VertiSync through a case study for the city of Los Angeles, and show that it significantly reduces average passenger waiting time compared to a first-come first-serve scheduling policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17313v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Milad Pooladsanj, Ketan Savla, Petros A. Ioannou</dc:creator>
    </item>
    <item>
      <title>Stochastic control on the half-line and applications to the optimal dividend/consumption problem</title>
      <link>https://arxiv.org/abs/1703.07339</link>
      <description>arXiv:1703.07339v3 Announce Type: replace 
Abstract: We consider a stochastic control problem with the assumption that the system is controlled until the state process breaks the fixed barrier. Assuming some general conditions, it is proved that the resulting Hamilton Jacobi Bellman equations has smooth solution. The aforementioned result is used to solve the optimal dividend and consumption problem. In the proof we use a fixed point type argument, with an operator which is based on the stochastic representation for a linear equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:1703.07339v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dariusz Zawisza</dc:creator>
    </item>
    <item>
      <title>Blended Conditional Gradients: the unconditioning of conditional gradients</title>
      <link>https://arxiv.org/abs/1805.07311</link>
      <description>arXiv:1805.07311v4 Announce Type: replace 
Abstract: We present a blended conditional gradient approach for minimizing a smooth convex function over a polytope P, combining the Frank--Wolfe algorithm (also called conditional gradient) with gradient-based steps, different from away steps and pairwise steps, but still achieving linear convergence for strongly convex functions, along with good practical performance. Our approach retains all favorable properties of conditional gradient algorithms, notably avoidance of projections onto P and maintenance of iterates as sparse convex combinations of a limited number of extreme points of P. The algorithm is lazy, making use of inexpensive inexact solutions of the linear programming subproblem that characterizes the conditional gradient approach. It decreases measures of optimality (primal and dual gaps) rapidly, both in the number of iterations and in wall-clock time, outperforming even the lazy conditional gradient algorithms of [arXiv:1410.8816]. We also present a streamlined version of the algorithm for the probability simplex.</description>
      <guid isPermaLink="false">oai:arXiv.org:1805.07311v4</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\'abor Braun, Sebastian Pokutta, Dan Tu, Stephen Wright</dc:creator>
    </item>
    <item>
      <title>Sparse PCA With Multiple Components</title>
      <link>https://arxiv.org/abs/2209.14790</link>
      <description>arXiv:2209.14790v3 Announce Type: replace 
Abstract: Sparse Principal Component Analysis (sPCA) is a cardinal technique for obtaining combinations of features, or principal components (PCs), that explain the variance of high-dimensional datasets in an interpretable manner. This involves solving a sparsity and orthogonality constrained convex maximization problem, which is extremely computationally challenging. Most existing works address sparse PCA via methods-such as iteratively computing one sparse PC and deflating the covariance matrix-that do not guarantee the orthogonality, let alone the optimality, of the resulting solution when we seek multiple mutually orthogonal PCs. We challenge this status by reformulating the orthogonality conditions as rank constraints and optimizing over the sparsity and rank constraints simultaneously. We design tight semidefinite relaxations to supply high-quality upper bounds, which we strengthen via additional second-order cone inequalities when each PC's individual sparsity is specified. Further, we derive a combinatorial upper bound on the maximum amount of variance explained as a function of the support. We exploit these relaxations and bounds to propose exact methods and rounding mechanisms that, together, obtain solutions with a bound gap on the order of 0%-15% for real-world datasets with p = 100s or 1000s of features and r \in {2, 3} components. Numerically, our algorithms match (and sometimes surpass) the best performing methods in terms of fraction of variance explained and systematically return PCs that are sparse and orthogonal. In contrast, we find that existing methods like deflation return solutions that violate the orthogonality constraints, even when the data is generated according to sparse orthogonal PCs. Altogether, our approach solves sparse PCA problems with multiple components to certifiable (near) optimality in a practically tractable fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.14790v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Jean Pauphilet</dc:creator>
    </item>
    <item>
      <title>Primal Methods for Variational Inequality Problems with Functional Constraints</title>
      <link>https://arxiv.org/abs/2403.12859</link>
      <description>arXiv:2403.12859v2 Announce Type: replace 
Abstract: Variational inequality problems are recognized for their broad applications across various fields including machine learning and operations research. First-order methods have emerged as the standard approach for solving these problems due to their simplicity and scalability. However, they typically rely on projection or linear minimization oracles to navigate the feasible set, which becomes computationally expensive in practical scenarios featuring multiple functional constraints. Existing efforts to tackle such functional constrained variational inequality problems have centered on primal-dual algorithms grounded in the Lagrangian function. These algorithms along with their theoretical analysis often require the existence and prior knowledge of the optimal Lagrange multipliers. In this work, we propose a simple primal method, termed Constrained Gradient Method (CGM), for addressing functional constrained variational inequality problems, without requiring any information on the optimal Lagrange multipliers. We establish a non-asymptotic convergence analysis of the algorithm for Minty variational inequality problems with monotone operators under smooth constraints. Remarkably, our algorithms match the complexity of projection-based methods in terms of operator queries for both monotone and strongly monotone settings, while using significantly cheaper oracles based on quadratic programming. Furthermore, we provide several numerical examples to evaluate the efficacy of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12859v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-025-02206-3</arxiv:DOI>
      <arxiv:journal_reference>Math. Program. (2025)</arxiv:journal_reference>
      <dc:creator>Liang Zhang, Niao He, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>Symplectic Extra-gradient Type Method for Solving General Non-monotone Inclusion Problem</title>
      <link>https://arxiv.org/abs/2406.10793</link>
      <description>arXiv:2406.10793v2 Announce Type: replace 
Abstract: In recent years, accelerated extra-gradient methods have attracted much attention by researchers, for solving monotone inclusion problems. A limitation of most current accelerated extra-gradient methods lies in their direct utilization of the initial point, which can potentially decelerate numerical convergence rate. In this work, we present a new accelerated extra-gradient method, by utilizing the symplectic acceleration technique. We establish the inverse of quadratic convergence rate by employing the Lyapunov function technique. Also, we demonstrate a faster inverse of quadratic convergence rate alongside its weak convergence property under stronger assumptions. To improve practical efficiency, we introduce a line search technique for our symplectic extra-gradient method. Theoretically, we prove the convergence of the symplectic extra-gradient method with line search. Numerical tests show that this adaptation exhibits faster convergence rates in practice compared to several existing extra-gradient type methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10793v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-xiang Yuan, Yi Zhang</dc:creator>
    </item>
    <item>
      <title>Unified continuous-time q-learning for mean-field game and mean-field control problems</title>
      <link>https://arxiv.org/abs/2407.04521</link>
      <description>arXiv:2407.04521v2 Announce Type: replace 
Abstract: This paper studies the continuous-time q-learning in mean-field jump-diffusion models when the population distribution is not directly observable. We propose the integrated q-function in decoupled form (decoupled Iq-function) from the representative agent's perspective and establish its martingale characterization, which provides a unified policy evaluation rule for both mean-field game (MFG) and mean-field control (MFC) problems. Moreover, we consider the learning procedure where the representative agent updates the population distribution based on his own state values. Depending on the task to solve the MFG or MFC problem, we can employ the decoupled Iq-function differently to characterize the mean-field equilibrium policy or the mean-field optimal policy respectively. Based on these theoretical findings, we devise a unified q-learning algorithm for both MFG and MFC problems by utilizing test policies and the averaged martingale orthogonality condition. For several financial applications in the jump-diffusion setting, we obtain the exact parameterization of the decoupled Iq-functions and the value functions, and illustrate our q-learning algorithm with satisfactory performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04521v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoli Wei, Xiang Yu, Fengyi Yuan</dc:creator>
    </item>
    <item>
      <title>Parabolic Approximation &amp; Relaxation for MINLP</title>
      <link>https://arxiv.org/abs/2407.06143</link>
      <description>arXiv:2407.06143v2 Announce Type: replace 
Abstract: We propose an approach based on quadratic approximations for solving general Mixed-Integer Nonlinear Programming (MINLP) problems. Specifically, our approach entails the global approximation of the epigraphs of constraint functions by means of paraboloids, which are polynomials of degree two with univariate quadratic terms, and relies on a Lipschitz property only. These approximations are then integrated into the original problem. To this end, we introduce a novel approach to compute globally valid epigraph approximations by paraboloids via a Mixed-Integer Linear Programming (MIP) model. We emphasize the possibility of performing such approximations a-priori and providing them in form of a lookup table, and then present several ways of leveraging the approximations to tackle the original problem. We provide the necessary theoretical background and conduct computational experiments on instances of the MINLPLib. As a result, this approach significantly accelerates the solution process of MINLP problems, particularly those involving many trigonometric or few exponential functions. In general, we highlight that the proposed technique is able to exploit advances in Mixed-Integer Quadratically-Constrained Programming (MIQCP) to solve MINLP problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06143v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrian G\"o{\ss}, Robert Burlacu, Alexander Martin</dc:creator>
    </item>
    <item>
      <title>Exact Recovery Guarantees for Parameterized Nonlinear System Identification Problem under Sparse Disturbances or Semi-Oblivious Attacks</title>
      <link>https://arxiv.org/abs/2409.00276</link>
      <description>arXiv:2409.00276v3 Announce Type: replace 
Abstract: In this work, we study the problem of learning a nonlinear dynamical system by parameterizing its dynamics using basis functions. We assume that disturbances occur at each time step with an arbitrary probability $p$, which models the sparsity level of the disturbance vectors over time. These disturbances are drawn from an arbitrary, unknown probability distribution, which may depend on past disturbances, provided that it satisfies a zero-mean assumption. The primary objective of this paper is to learn the system's dynamics within a finite time and analyze the sample complexity as a function of $p$. To achieve this, we examine a LASSO-type non-smooth estimator, and establish necessary and sufficient conditions for its well-specifiedness and the uniqueness of the global solution to the underlying optimization problem. We then provide exact recovery guarantees for the estimator under two distinct conditions: boundedness and Lipschitz continuity of the basis functions. We show that finite-time exact recovery is achieved with high probability, even when $p$ approaches 1. Unlike prior works, which primarily focus on independent and identically distributed (i.i.d.) disturbances and provide only asymptotic guarantees for system learning, this study presents the first finite-time analysis of nonlinear dynamical systems under a highly general disturbance model. Our framework allows for possible temporal correlations in the disturbances and accommodates semi-oblivious adversarial attacks, significantly broadening the scope of existing theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00276v3</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haixiang Zhang, Baturalp Yalcin, Javad Lavaei, Eduardo D. Sontag</dc:creator>
    </item>
    <item>
      <title>Continuous-Time Online Distributed Seeking for Generalized Nash Equilibrium of Nonmonotone Online Game</title>
      <link>https://arxiv.org/abs/2409.04765</link>
      <description>arXiv:2409.04765v2 Announce Type: replace 
Abstract: This paper mainly investigates a class of distributed generalized Nash equilibrium (GNE) seeking problems for online nonmonotone game with time-varying coupling inequality constraints. Based on a time-varying control gain, a novel continuous-time distributed GNE seeking algorithm is proposed, which realizes the constant regret bound and sublinear fit bound, matching those of the criteria for online optimization problems. Furthermore, to reduce unnecessary communication among players, a dynamic event-triggered mechanism involving internal variables is introduced into the distributed GNE seeking algorithm, while the constant regret bound and sublinear fit bound are still achieved. Also, the Zeno behavior is strictly prohibited. Finally, a numerical example is given to demonstrate the validity of the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04765v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianing Chen, Sichen Qian, Chuangyin Dang, Sitian Qin</dc:creator>
    </item>
    <item>
      <title>A novel necessary and sufficient condition for the stability of $2\times 2$ first-order linear hyperbolic systems</title>
      <link>https://arxiv.org/abs/2412.13929</link>
      <description>arXiv:2412.13929v2 Announce Type: replace 
Abstract: In this paper, we establish a necessary and sufficient stability condition for a class of two coupled first-order linear hyperbolic partial differential equations. Through a backstepping transform, the problem is reformulated as a stability problem for an integral difference equation, that is, a difference equation with distributed delay. Building upon a St\'ep\'an--Hassard argument variation theorem originally designed for time-delay systems of retarded type, we then introduce a theorem that counts the number of unstable roots of our integral difference equation. This leads to the expected necessary and sufficient stability criterion for the system of first-order linear hyperbolic partial differential equations. Finally, we validate our theoretical findings through simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13929v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysconle.2025.106066</arxiv:DOI>
      <arxiv:journal_reference>Systems Control Lett., 199:Paper No. 106066, 9 pp., 2025</arxiv:journal_reference>
      <dc:creator>Isma\"ila Balogoun (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France), Jean Auriol (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France), Islam Boussaada (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France, IPSA Paris, Ivry-sur-Seine, France), Guilherme Mazanti (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France, F\'ed\'eration de Math\'ematiques de CentraleSup\'elec, Gif-sur-Yvette, France)</dc:creator>
    </item>
    <item>
      <title>Douglas-Rachford algorithm for nonmonotone multioperator inclusion problems</title>
      <link>https://arxiv.org/abs/2501.02752</link>
      <description>arXiv:2501.02752v2 Announce Type: replace 
Abstract: The Douglas-Rachford algorithm is a classic splitting method for finding a zero of the sum of two maximal monotone operators. It has also been applied to settings that involve one weakly and one strongly monotone operator. In this work, we extend the Douglas-Rachford algorithm to address multioperator inclusion problems involving $m$ ($m\geq 2$) weakly and strongly monotone operators, reformulated as a two-operator inclusion in a product space. By selecting appropriate parameters, we establish the convergence of the algorithm to a fixed point, from which solutions can be extracted. Furthermore, we illustrate its applicability to sum-of-$m$-functions minimization problems characterized by weakly convex and strongly convex functions. For general nonconvex problems in finite-dimensional spaces, comprising Lipschitz continuously differentiable functions and a proper closed function, we provide global subsequential convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02752v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Harold Alcantara, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>How much should we care about what others know? Jump signals in optimal investment under relative performance concerns</title>
      <link>https://arxiv.org/abs/2503.16039</link>
      <description>arXiv:2503.16039v2 Announce Type: replace 
Abstract: We present a multi-agent and mean-field formulation of a game between investors who receive private signals informing their investment decisions and who interact through relative performance concerns. A key tool in our model is a Poisson random measure which drives jumps in both market prices and signal processes and thus captures common and idiosyncratic noise. Upon receiving a jump signal, an investor evaluates not only the signal's implications for stock price movements but also its implications for the signals received by her peers and for their subsequent investment decisions. A crucial aspect of this assessment is the distribution of investor types in the economy. These types determine their risk aversion, performance concerns, and the quality and quantity of their signals. We demonstrate how these factors are reflected in the corresponding HJB equations, characterizing an agent's optimal response to her peers' signal-based strategies. The existence of equilibria in both the multi-agent and mean-field game is established using Schauder's Fixed Point Theorem under suitable conditions on investor characteristics, particularly their signal processes. Finally, we present numerical case studies that illustrate these equilibria from a financial-economic perspective. This allows us to address questions such as how much investors should care about the information known by their peers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16039v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Bank, Gemma Sedrakjan</dc:creator>
    </item>
    <item>
      <title>Knowledge Transfer based Evolutionary Deep Neural Network for Intelligent Fault Diagnosis</title>
      <link>https://arxiv.org/abs/2109.13479</link>
      <description>arXiv:2109.13479v5 Announce Type: replace-cross 
Abstract: A faster response with commendable accuracy in intelligent systems is essential for the reliability and smooth operations of industrial machines. Two main challenges affect the design of such intelligent systems: (i) the selection of a suitable model and (ii) domain adaptation if there is a continuous change in operating conditions. Therefore, we propose an evolutionary Net2Net transformation (EvoN2N) that finds the best suitable DNN architecture with limited availability of labeled data samples. Net2Net transformation-based quick learning algorithm has been used in the evolutionary framework of Non-dominated sorting genetic algorithm II to obtain the best DNN architecture. Net2Net transformation-based quick learning algorithm uses the concept of knowledge transfer from one generation to the next for faster fitness evaluation. The proposed framework can obtain the best model for intelligent fault diagnosis without a long and time-consuming search process. The proposed framework has been validated on the Case Western Reserve University dataset, the Paderborn University dataset, and the gearbox fault detection dataset under different operating conditions. The best models obtained are capable of demonstrating an excellent diagnostic performance and classification accuracy of almost up to 100% for most of the operating conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.13479v5</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arun K. Sharma, Nishchal K. Verma</dc:creator>
    </item>
    <item>
      <title>Contraction Theory for Nonlinear Stability Analysis and Learning-based Control: A Tutorial Overview</title>
      <link>https://arxiv.org/abs/2110.00675</link>
      <description>arXiv:2110.00675v5 Announce Type: replace-cross 
Abstract: Contraction theory is an analytical tool to study differential dynamics of a non-autonomous (i.e., time-varying) nonlinear system under a contraction metric defined with a uniformly positive definite matrix, the existence of which results in a necessary and sufficient characterization of incremental exponential stability of multiple solution trajectories with respect to each other. By using a squared differential length as a Lyapunov-like function, its nonlinear stability analysis boils down to finding a suitable contraction metric that satisfies a stability condition expressed as a linear matrix inequality, indicating that many parallels can be drawn between well-known linear systems theory and contraction theory for nonlinear systems. Furthermore, contraction theory takes advantage of a superior robustness property of exponential stability used in conjunction with the comparison lemma. This yields much-needed safety and stability guarantees for neural network-based control and estimation schemes, without resorting to a more involved method of using uniform asymptotic stability for input-to-state stability. Such distinctive features permit the systematic construction of a contraction metric via convex optimization, thereby obtaining an explicit exponential bound on the distance between a time-varying target trajectory and solution trajectories perturbed externally due to disturbances and learning errors. The objective of this paper is, therefore, to present a tutorial overview of contraction theory and its advantages in nonlinear stability analysis of deterministic and stochastic systems, with an emphasis on deriving formal robustness and stability guarantees for various learning-based and data-driven automatic control methods. In particular, we provide a detailed review of techniques for finding contraction metrics and associated control and estimation laws using deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.00675v5</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.arcontrol.2021.10.001</arxiv:DOI>
      <arxiv:journal_reference>Annual Reviews in Control; Volume 52; 2021; Pages 135-169; ISSN 1367-5788</arxiv:journal_reference>
      <dc:creator>Hiroyasu Tsukamoto, Soon-Jo Chung, Jean-Jacques E. Slotine</dc:creator>
    </item>
    <item>
      <title>Generating Likely Counterfactuals Using Sum-Product Networks</title>
      <link>https://arxiv.org/abs/2401.14086</link>
      <description>arXiv:2401.14086v4 Announce Type: replace-cross 
Abstract: The need to explain decisions made by AI systems is driven by both recent regulation and user demand. The decisions are often explainable only post hoc. In counterfactual explanations, one may ask what constitutes the best counterfactual explanation. Clearly, multiple criteria must be taken into account, although "distance from the sample" is a key criterion. Recent methods that consider the plausibility of a counterfactual seem to sacrifice this original objective. Here, we present a system that provides high-likelihood explanations that are, at the same time, close and sparse. We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using Mixed-Integer Optimization (MIO). We use a Sum-Product Network (SPN) to estimate the likelihood of a counterfactual. To achieve that, we propose an MIO formulation of an SPN, which can be of independent interest. The source code with examples is available at https://github.com/Epanemu/LiCE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14086v4</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The Thirteenth International Conference on Learning Representations (ICLR 2025)</arxiv:journal_reference>
      <dc:creator>Jiri Nemecek, Tomas Pevny, Jakub Marecek</dc:creator>
    </item>
    <item>
      <title>Some notes concerning preconditioning of linear parabolic optimal control problems</title>
      <link>https://arxiv.org/abs/2408.04954</link>
      <description>arXiv:2408.04954v2 Announce Type: replace-cross 
Abstract: In this paper we study the conditioning of optimal control problems constrained by linear parabolic equations with Neumann boundary conditions. While we concentrate on a given end-time target function the results hold also when the target function is given over the whole time horizon. When implicit time discretization and conforming finite elements in space are employed we show that the reduced problem formulation has condition numbers which are bounded independently of the discretization level in arbitrary space dimension. In addition we propose for the all-at-once approach, i.e. for the first-order conditions of the unreduced system a preconditioner based on work by Greif and Sch\"otzau, which provides also bounds on the eigenvalue distribution independently of the discretization level. Numerical experiments demonstrate the obtained results and the efficiency of the suggested preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04954v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luise Blank</dc:creator>
    </item>
    <item>
      <title>Sparse Actuation for LPV Systems with Full-State Feedback in $\mathcal{H}_2/\mathcal{H}_\infty$ Framework</title>
      <link>https://arxiv.org/abs/2410.01118</link>
      <description>arXiv:2410.01118v2 Announce Type: replace-cross 
Abstract: This paper addresses the sparse actuation problem for nonlinear systems represented in the Linear Parameter-Varying (LPV) form. We propose a convex optimization framework that concurrently determines actuator magnitude limits and the state-feedback law that guarantees a user-specified closed-loop performance in the $\mathcal{H}_2/\mathcal{H}_\infty$ sense. We also demonstrate that sparse actuation is achieved when the actuator magnitude-limits are minimized in the $l_1$ sense. This is the first paper that addresses this problem for LPV systems. The formulation is demonstrated in a vibration control problem for a flexible wing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01118v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanay Kumar, Raktim Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Nonlinear Stochastic Gradient Descent and Heavy-tailed Noise: A Unified Framework and High-probability Guarantees</title>
      <link>https://arxiv.org/abs/2410.13954</link>
      <description>arXiv:2410.13954v2 Announce Type: replace-cross 
Abstract: We study high-probability convergence in online learning, in the presence of heavy-tailed noise. To combat the heavy tails, a general framework of nonlinear SGD methods is considered, subsuming several popular nonlinearities like sign, quantization, component-wise and joint clipping. In our work the nonlinearity is treated in a black-box manner, allowing us to establish unified guarantees for a broad range of nonlinear methods. For symmetric noise and non-convex costs we establish convergence of gradient norm-squared, at a rate $\widetilde{\mathcal{O}}(t^{-1/4})$, while for the last iterate of strongly convex costs we establish convergence to the population optima, at a rate $\mathcal{O}(t^{-\zeta})$, where $\zeta \in (0,1)$ depends on noise and problem parameters. Further, if the noise is a (biased) mixture of symmetric and non-symmetric components, we show convergence to a neighbourhood of stationarity, whose size depends on the mixture coefficient, nonlinearity and noise. Compared to state-of-the-art, who only consider clipping and require unbiased noise with bounded $p$-th moments, $p \in (1,2]$, we provide guarantees for a broad class of nonlinearities, without any assumptions on noise moments. While the rate exponents in state-of-the-art depend on noise moments and vanish as $p \rightarrow 1$, our exponents are constant and strictly better whenever $p &lt; 6/5$ for non-convex and $p &lt; 8/7$ for strongly convex costs. Experiments validate our theory, showing that clipping is not always the optimal nonlinearity, further underlining the value of a general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13954v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Shuhua Yu, Pranay Sharma, Gauri Joshi, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Low-Rank Thinning</title>
      <link>https://arxiv.org/abs/2502.12063</link>
      <description>arXiv:2502.12063v2 Announce Type: replace-cross 
Abstract: The goal in thinning is to summarize a dataset using a small set of representative points. Remarkably, sub-Gaussian thinning algorithms like Kernel Halving and Compress can match the quality of uniform subsampling while substantially reducing the number of summary points. However, existing guarantees cover only a restricted range of distributions and kernel-based quality measures and suffer from pessimistic dimension dependence. To address these deficiencies, we introduce a new low-rank analysis of sub-Gaussian thinning that applies to any distribution and any kernel, guaranteeing high-quality compression whenever the kernel or data matrix is approximately low-rank. To demonstrate the broad applicability of the techniques, we design practical sub-Gaussian thinning approaches that improve upon the best known guarantees for approximating attention in transformers, accelerating stochastic gradient training through reordering, and distinguishing distributions in near-linear time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12063v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annabelle Michael Carrell, Albert Gong, Abhishek Shetty, Raaz Dwivedi, Lester Mackey</dc:creator>
    </item>
    <item>
      <title>Differential topology of the spaces of asymptotically stable vector fields and Lyapunov functions</title>
      <link>https://arxiv.org/abs/2503.10828</link>
      <description>arXiv:2503.10828v2 Announce Type: replace-cross 
Abstract: We study the topology of the space of all smooth asymptotically stable vector fields on $\mathbb{R}^n$, as well as the space of all proper smooth Lyapunov functions for such vector fields. We prove that both spaces are path-connected and simply connected when $n\neq 4,5$ and weakly contractible when $n\leq 3$. Moreover, both spaces have the weak homotopy type of the nonlinear Grassmannian of submanifolds of $\mathbb{R}^n$ diffeomorphic to the $n$-disc.
  The proofs rely on Lyapunov theory and differential topology, such as the work of Smale and Perelman on the generalized Poincar\'{e} conjecture and results of Smale, Cerf, and Hatcher on the topology of diffeomorphism groups of discs. Applications include a partial answer to a question of Conley, a parametric Hartman-Grobman theorem for nonyperbolic but asymptotically stable equilibria, and a parametric Morse lemma for degenerate minima. We also study the related topics of hyperbolic equilibria, Morse minima, and relative homotopy groups of the space of asymptotically stable vector fields inside the space of those vanishing at a single point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10828v2</guid>
      <category>math.DS</category>
      <category>math.AT</category>
      <category>math.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew D. Kvalheim</dc:creator>
    </item>
  </channel>
</rss>
