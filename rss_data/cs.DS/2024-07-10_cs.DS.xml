<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2024 01:33:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Stochastic Traveling Salesperson Problem with Neighborhoods for Object Detection</title>
      <link>https://arxiv.org/abs/2407.06366</link>
      <description>arXiv:2407.06366v1 Announce Type: new 
Abstract: We introduce a new route-finding problem which considers perception and travel costs simultaneously. Specifically, we consider the problem of finding the shortest tour such that all objects of interest can be detected successfully. To represent a viable detection region for each object, we propose to use an entropy-based viewing score that generates a diameter-bounded region as a viewing neighborhood. We formulate the detection-based trajectory planning problem as a stochastic traveling salesperson problem with neighborhoods and propose a center-visit method that obtains an approximation ratio of O(DmaxDmin) for disjoint regions. For non-disjoint regions, our method -provides a novel finite detour in 3D, which utilizes the region's minimum curvature property. Finally, we show that our method can generate efficient trajectories compared to a baseline method in a photo-realistic simulation environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06366v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheng Peng, Minghan Wei, Volkan Isler</dc:creator>
    </item>
    <item>
      <title>A Lossless Deamortization for Dynamic Greedy Set Cover</title>
      <link>https://arxiv.org/abs/2407.06431</link>
      <description>arXiv:2407.06431v1 Announce Type: new 
Abstract: The dynamic set cover problem has been subject to growing research attention in recent years. In this problem, we are given as input a dynamic universe of at most $n$ elements and a fixed collection of $m$ sets, where each element appears in a most $f$ sets and the cost of each set is in $[1/C, 1]$, and the goal is to efficiently maintain an approximate minimum set cover under element updates.
  Two algorithms that dynamize the classic greedy algorithm are known, providing $O(\log n)$ and $((1+\epsilon)\ln n)$-approximation with amortized update times $O(f \log n)$ and $O(\frac{f \log n}{\epsilon^5})$, respectively [GKKP (STOC'17); SU (STOC'23)]. The question of whether one can get approximation $O(\log n)$ (or even worse) with low worst-case update time has remained open -- only the naive $O(f \cdot n)$ time bound is known, even for unweighted instances.
  In this work we devise the first amortized greedy algorithm that is amenable to an efficient deamortization, and also develop a lossless deamortization approach suitable for the set cover problem, the combination of which yields a $((1+\epsilon)\ln n)$-approximation algorithm with a worst-case update time of $O(\frac{f\log n}{\epsilon^2})$. Our worst-case time bound -- the first to break the naive $O(f \cdot n)$ bound -- matches the previous best amortized bound, and actually improves its $\epsilon$-dependence.
  Further, to demonstrate the applicability of our deamortization approach, we employ it, in conjunction with the primal-dual amortized algorithm of [BHN (FOCS'19)], to obtain a $((1+\epsilon)f)$-approximation algorithm with a worst-case update time of $O(\frac{f\log n}{\epsilon^2})$, improving over the previous best bound of $O(\frac{f \cdot \log^2(Cn)}{\epsilon^3})$ [BHNW (SODA'21)].
  Finally, as direct implications of our results for set cover, we [...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06431v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shay Solomon, Amitai Uzrad, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient Stochastic Routing in Path-Centric Uncertain Road Networks -- Extended Version</title>
      <link>https://arxiv.org/abs/2407.06881</link>
      <description>arXiv:2407.06881v1 Announce Type: new 
Abstract: The availability of massive vehicle trajectory data enables the modeling of road-network constrained movement as travel-cost distributions rather than just single-valued costs, thereby capturing the inherent uncertainty of movement and enabling improved routing quality. Thus, stochastic routing has been studied extensively in the edge-centric model, where such costs are assigned to the edges in a graph representation of a road network. However, as this model still disregards important information in trajectories and fails to capture dependencies among cost distributions, a path-centric model, where costs are assigned to paths, has been proposed that captures dependencies better and provides an improved foundation for routing. Unfortunately, when applied in this model, existing routing algorithms are inefficient due to two shortcomings that we eliminate. First, when exploring candidate paths, existing algorithms only consider the costs of candidate paths from the source to intermediate vertices, while disregarding the costs of travel from the intermediate vertices to the destination, causing many non-competitive paths to be explored. We propose two heuristics for estimating the cost from an intermediate vertex to the destination, thus improving routing efficiency. Second, the edge-centric model relies on stochastic dominance-based pruning to improve efficiency. This pruning assumes that costs are independent and is therefore inapplicable in the path-centric model that takes dependencies into account. We introduce a notion of virtual path that effectively enables stochastic dominance-based pruning in the path-based model, thus further improving efficiency. Empirical studies using two real-world trajectory sets offer insight into the properties of the proposed solution, indicating that it enables efficient stochastic routing in the path-centric model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06881v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenjuan Guo, Ronghui Xu, Bin Yang, Ye Yuan, Tung Kieu, Yan Zhao, Christian S. Jensen</dc:creator>
    </item>
    <item>
      <title>Optimal Neighborhood Exploration for Dynamic Independent Sets</title>
      <link>https://arxiv.org/abs/2407.06912</link>
      <description>arXiv:2407.06912v1 Announce Type: new 
Abstract: A dynamic graph algorithm is a data structure that supports edge insertions, deletions, and specific problem queries. While extensive research exists on dynamic algorithms for graph problems solvable in polynomial time, most of these algorithms have not been implemented or empirically evaluated.
  This work addresses the NP-complete maximum weight and cardinality independent set problems in a dynamic setting, applicable to areas like dynamic map-labeling and vehicle routing. Real-world instances can be vast, with millions of vertices and edges, making it challenging to find near-optimal solutions quickly. Exact solvers can find optimal solutions but have exponential worst-case runtimes. Conversely, heuristic algorithms use local search techniques to improve solutions by optimizing vertices.
  In this work, we introduce a novel local search technique called optimal neighborhood exploration. This technique creates independent subproblems that are solved to optimality, leading to improved overall solutions. Through numerous experiments, we assess the effectiveness of our approach and compare it with other state-of-the-art dynamic solvers. Our algorithm features a parameter, the subproblem size, that balances running time and solution quality. With this parameter, our configuration matches state-of-the-art performance for the cardinality independent set problem. By increasing the parameter, we significantly enhance solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06912v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannick Borowitz, Ernestine Gro{\ss}mann, Christian Schulz</dc:creator>
    </item>
    <item>
      <title>A Simple, Nearly-Optimal Algorithm for Differentially Private All-Pairs Shortest Distances</title>
      <link>https://arxiv.org/abs/2407.06913</link>
      <description>arXiv:2407.06913v1 Announce Type: new 
Abstract: The all-pairs shortest distances (APSD) with differential privacy (DP) problem takes as input an undirected, weighted graph $G = (V,E, \mathbf{w})$ and outputs a private estimate of the shortest distances in $G$ between all pairs of vertices. In this paper, we present a simple $\widetilde{O}(n^{1/3}/\varepsilon)$-accurate algorithm to solve APSD with $\varepsilon$-DP, which reduces to $\widetilde{O}(n^{1/4}/\varepsilon)$ in the $(\varepsilon, \delta)$-DP setting, where $n = |V|$. Our algorithm greatly improves upon the error of prior algorithms, namely $\widetilde{O}(n^{2/3}/\varepsilon)$ and $\widetilde{O}(\sqrt{n}/\varepsilon)$ in the two respective settings, and is the first to be optimal up to a polylogarithmic factor, based on a lower bound of $\widetilde{\Omega}(n^{1/4})$.
  In the case where a multiplicative approximation is allowed, we give two different constructions of algorithms with reduced additive error. Our first construction allows a multiplicative approximation of $O(k\log{\log{n}})$ and has additive error $\widetilde{O}(k\cdot n^{1/k}/\varepsilon)$ in the $\varepsilon$-DP case and $\widetilde{O}(\sqrt{k}\cdot n^{1/(2k)}/\varepsilon)$ in the $(\varepsilon, \delta)$-DP case. Our second construction allows multiplicative approximation $2k-1$ and has the same asymptotic additive error as the first construction. Both constructions significantly improve upon the currently best-known additive error of, $\widetilde{O}(k\cdot n^{1/2 + 1/(4k+2)}/\varepsilon)$ and $\widetilde{O}(k\cdot n^{1/3 + 2/(9k+3)}/\varepsilon)$, respectively. Our algorithms are straightforward and work by decomposing a graph into a set of spanning trees, and applying a key observation that we can privately release APSD in trees with $O(\text{polylog}(n))$ error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06913v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesse Campbell, Chunjiang Zhu</dc:creator>
    </item>
    <item>
      <title>An efficient implementation for solving the all pairs minimax path problem in an undirected dense graph</title>
      <link>https://arxiv.org/abs/2407.07058</link>
      <description>arXiv:2407.07058v1 Announce Type: new 
Abstract: We provide an efficient $ O(n^2) $ implementation for solving the all pairs minimax path problem or widest path problem in an undirected dense graph. It is a code implementation of the Algorithm 4 (MMJ distance by Calculation and Copy) in a previous paper. The distance matrix is also called the all points path distance (APPD). We conducted experiments to test the implementation and algorithm, compared it with several other algorithms for solving the APPD matrix. Result shows Algorithm 4 works good for solving the widest path or minimax path APPD matrix. It can drastically improve the efficiency for computing the APPD matrix. There are several theoretical outcomes which claim the APPD matrix can be solved accurately in $ O(n^2) $ . However, they are impractical because there is no code implementation of these algorithms. It seems Algorithm 4 is the first algorithm that has an actual code implementation for solving the APPD matrix of minimax path or widest path problem in $ O(n^2) $, in an undirected dense graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07058v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gangli Liu</dc:creator>
    </item>
    <item>
      <title>Tight bounds for stream decodable error-correcting codes</title>
      <link>https://arxiv.org/abs/2407.06446</link>
      <description>arXiv:2407.06446v1 Announce Type: cross 
Abstract: In order to communicate a message over a noisy channel, a sender (Alice) uses an error-correcting code to encode her message $x$ into a codeword. The receiver (Bob) decodes it correctly whenever there is at most a small constant fraction of adversarial error in the transmitted codeword. This work investigates the setting where Bob is computationally bounded. Specifically, Bob receives the message as a stream and must process it and write $x$ in order to a write-only tape while using low (say polylogarithmic) space. We show three basic results about this setting, which are informally as follows:
  (1) There is a stream decodable code of near-quadratic length.
  (2) There is no stream decodable code of sub-quadratic length.
  (3) If Bob need only compute a private linear function of the input bits, instead of writing them all to the output tape, there is a stream decodable code of near-linear length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06446v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meghal Gupta, Venkatesan Guruswami, Mihir Singhal</dc:creator>
    </item>
    <item>
      <title>Algorithmic aspects of semistability of quiver representations</title>
      <link>https://arxiv.org/abs/2407.06493</link>
      <description>arXiv:2407.06493v1 Announce Type: cross 
Abstract: We study the semistability of quiver representations from an algorithmic perspective. We present efficient algorithms for several fundamental computational problems on the semistability of quiver representations: deciding semistability and $\sigma$-semistability, finding maximizers of King's criterion, and finding the Harder-Narasimhan filtration. We also investigate a class of polyhedral cones defined by the linear system in King's criterion, which we call King cones. We demonstrate that the King cones for rank-one representations can be encoded by submodular flow polytopes, allowing us to decide the $\sigma$-semistability of rank-one representations in strongly polynomial time. Our argument employs submodularity in quiver representations, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06493v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.RT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuni Iwamasa, Taihei Oki, Tasuku Soma</dc:creator>
    </item>
    <item>
      <title>From Graph Properties to Graph Parameters: Tight Bounds for Counting on Small Subgraphs</title>
      <link>https://arxiv.org/abs/2407.06801</link>
      <description>arXiv:2407.06801v1 Announce Type: cross 
Abstract: A graph property is a function $\Phi$ that maps every graph to {0, 1} and is invariant under isomorphism. In the $\#IndSub(\Phi)$ problem, given a graph $G$ and an integer $k$, the task is to count the number of $k$-vertex induced subgraphs $G'$ with $\Phi(G')=1$. $\#IndSub(\Phi)$ can be naturally generalized to graph parameters, that is, to functions $\Phi$ on graphs that do not necessarily map to {0, 1}: now the task is to compute the sum $\sum_{G'} \Phi(G')$ taken over all $k$-vertex induced subgraphs $G'$. This problem setting can express a wider range of counting problems (for instance, counting $k$-cycles or $k$-matchings) and can model problems involving expected values (for instance, the expected number of components in a subgraph induced by $k$ random vertices). Our main results are lower bounds on $\#IndSub(\Phi)$ in this setting, which simplify, generalize, and tighten the recent lower bounds of D\"oring, Marx, and Wellnitz [STOC'24] in various ways.
  (1) We show a lower bound for every nontrivial edge-monotone graph parameter $\Phi$ with finite codomain (not only for parameters that take value in {0, 1}).
  (2) The lower bound is tight: we show that, assuming ETH, there is no $f(k)n^{o(k)}$ time algorithm.
  (3) The lower bound applies also to the modular counting versions of the problem.
  (4) The lower bound applies also to the multicolored version of the problem.
  We can extend the #W[1]-hardness result to the case when the codomain of $\Phi$ is not finite, but has size at most $(1 - \varepsilon)\sqrt{k}$ on $k$-vertex graphs. However, if there is no bound on the size of the codomain, the situation changes significantly: for example, there is a nontrivial edge-monotone function $\Phi$ where the size of the codomain is $k$ on $k$-vertex graphs and $\#IndSub(\Phi)$ is FPT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06801v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon D\"oring, D\'aniel Marx, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>Differentially Private Multiway and $k$-Cut</title>
      <link>https://arxiv.org/abs/2407.06911</link>
      <description>arXiv:2407.06911v1 Announce Type: cross 
Abstract: In this paper, we address the challenge of differential privacy in the context of graph cuts, specifically focusing on the minimum $k$-cut and multiway cut problems. We introduce edge-differentially private algorithms that achieve nearly optimal performance for these problems.
  For the multiway cut problem, we first provide a private algorithm with a multiplicative approximation ratio that matches the state-of-the-art non-private algorithm. We then present a tight information-theoretic lower bound on the additive error, demonstrating that our algorithm on weighted graphs is near-optimal for constant $k$. For the minimum $k$-cut problem, our algorithms leverage a known bound on the number of approximate $k$-cuts, resulting in a private algorithm with optimal additive error $O(k\log n)$ for fixed privacy parameter. We also establish a information-theoretic lower bound that matches this additive error. Additionally, we give an efficient private algorithm for $k$-cut even for non-constant $k$, including a polynomial-time 2-approximation with an additive error of $\widetilde{O}(k^{1.5})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06911v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rishi Chandra, Michael Dinitz, Chenglin Fan, Zongrui Zou</dc:creator>
    </item>
    <item>
      <title>Counting Small Induced Subgraphs: Hardness via Fourier Analysis</title>
      <link>https://arxiv.org/abs/2407.07051</link>
      <description>arXiv:2407.07051v1 Announce Type: cross 
Abstract: For a fixed graph property $\Phi$ and integer $k \geq 1$, the problem $\#\mathrm{IndSub}(\Phi,k)$ asks to count the induced $k$-vertex subgraphs satisfying $\Phi$ in an input graph $G$. If $\Phi$ is trivial on $k$-vertex graphs (i.e., if $\Phi$ contains either all or no $k$-vertex graphs), this problem is trivial. Otherwise we prove, among other results:
  - If $\Phi$ is edge-monotone (i.e., closed under deleting edges), then $\#\mathrm{IndSub}(\Phi,k)$ cannot be solved in time $n^{o(k)}$ assuming ETH. This strengthens a result by D\"oring, Marx and Wellnitz [STOC 2024] that only ruled out an exponent of $o(\sqrt{\log k}/ \log \log k)$. Our results also hold when counting modulo fixed primes.
  - If there is some fixed $\varepsilon &gt; 0$ such that at most $(2-\varepsilon)^{\binom{k}{2}}$ graphs on $k$ vertices satisfy $\Phi$, then $\#\mathrm{IndSub}(\Phi,k)$ cannot be solved in time $n^{o(k/\sqrt{\log k})}$ assuming ETH. Our results hold even when each of the graphs in $\Phi$ may come with an arbitrary individual weight. This generalizes previous results for hereditary properties by Focke and Roth [SIAM J.\ Comput.\ 2024] up to a $\sqrt{\log k}$ factor in the exponent of the lower bound.
  - If $\Phi$ only depends on the number of edges, then $\#\mathrm{IndSub}(\Phi,k)$ cannot be solved in time $n^{o(k)}$ assuming ETH. This improves on a lower bound by Roth, Schmitt and Wellnitz [FOCS 2020] that only ruled out an exponent of $o(k / \sqrt{\log k})$.
  In all cases, we also obtain $\mathsf{\#W[1]}$-hardness if $k$ is part of the input and the problem is parameterized by $k$. We also obtain lower bounds on the Weisfeiler-Leman dimension. Our results follow from relatively straightforward Fourier analysis, and our paper subsumes most of the known $\mathsf{\#W[1]}$-hardness results known in the area, often with tighter lower bounds under ETH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07051v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Curticapean, Daniel Neuen</dc:creator>
    </item>
    <item>
      <title>Scalable Multilevel and Memetic Signed Graph Clustering</title>
      <link>https://arxiv.org/abs/2208.13618</link>
      <description>arXiv:2208.13618v3 Announce Type: replace 
Abstract: In this study, we address the complex issue of graph clustering in signed graphs, which are characterized by positive and negative weighted edges representing attraction and repulsion among nodes, respectively. The primary objective is to efficiently partition the graph into clusters, ensuring that nodes within a cluster are closely linked by positive edges while minimizing negative edge connections between them. To tackle this challenge, we first develop a scalable multilevel algorithm based on label propagation and FM local search. Then we develop a memetic algorithm that incorporates a multilevel strategy. This approach meticulously combines elements of evolutionary algorithms with local refinement techniques, aiming to explore the search space more effectively than repeated executions. Our experimental analysis reveals that this our new algorithms significantly outperforms existing state-of-the-art algorithms. For example, our memetic algorithm can reach solution quality of the previous state-of-the-art algorithm up to four orders of magnitude faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.13618v3</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Hausberger, Marcelo Fonseca Faraj, Christian Schulz</dc:creator>
    </item>
    <item>
      <title>SQUID: Faster Analytics via Sampled Quantile Estimation</title>
      <link>https://arxiv.org/abs/2211.01726</link>
      <description>arXiv:2211.01726v3 Announce Type: replace 
Abstract: Streaming algorithms are fundamental in the analysis of large and online datasets. A key component of many such analytic tasks is $q$-MAX, which finds the largest $q$ values in a number stream. Modern approaches attain a constant runtime by removing small items in bulk and retaining the largest $q$ items at all times. Yet, these approaches are bottlenecked by an expensive quantile calculation.
  This work introduces a quantile-sampling approach called SQUID and shows its benefits in multiple analytic tasks. Using this approach, we design a novel weighted heavy hitters data structure that is faster and more accurate than the existing alternatives. We also show SQUID's practicality for improving network-assisted caching systems with a hardware-based cache prototype that uses SQUID to implement the cache policy. The challenge here is that the switch's dataplane does not allow the general computation required to implement many cache policies, while its CPU is orders of magnitude slower. We overcome this issue by passing just SQUID's samples to the CPU, thus bridging this gap.
  In software implementations, we show that our method is up to 6.6x faster than the state-of-the-art alternatives when using real workloads. For switch-based caching, SQUID enables a wide spectrum of data-plane-based caching policies and achieves higher hit ratios than the state-of-the-art P4LRU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01726v3</guid>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ran Ben-Basat, Gil Einziger, Wenchen Han, Bilal Tayh</dc:creator>
    </item>
    <item>
      <title>Coresets for Constrained Clustering: General Assignment Constraints and Improved Size Bounds</title>
      <link>https://arxiv.org/abs/2301.08460</link>
      <description>arXiv:2301.08460v5 Announce Type: replace 
Abstract: Designing small-sized \emph{coresets}, which approximately preserve the costs of the solutions for large datasets, has been an important research direction for the past decade. We consider coreset construction for a variety of general constrained clustering problems. We introduce a general class of assignment constraints, including capacity constraints on cluster centers, and assignment structure constraints for data points (modeled by a convex body $\mathcal{B}$). We give coresets for clustering problems with such general assignment constraints that significantly generalize and improve known results. Notable implications include the first $\varepsilon$-coreset for capacitated and fair $k$-Median with $m$ outliers in Euclidean spaces whose size is $\tilde{O}(m + k^2 \varepsilon^{-4})$, generalizing and improving upon the prior bounds in [Braverman et al., FOCS' 22; Huang et al., ICLR' 23] (for capacitated $k$-Median, the coreset size bound obtained in [Braverman et al., FOCS' 22] is $\tilde{O}(k^3 \varepsilon^{-6})$, and for $k$-Median with $m$ outliers, the coreset size bound obtained in [Huang et al., ICLR' 23]} is $\tilde{O}(m + k^3 \varepsilon^{-5})$), and the first $\epsilon$-coreset of size $\mathrm{poly}(k \varepsilon^{-1})$ for fault-tolerant clustering for various types of metric spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08460v5</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingxiao Huang, Jian Li, Pinyan Lu, Xuan Wu</dc:creator>
    </item>
    <item>
      <title>CAGRA: Highly Parallel Graph Construction and Approximate Nearest Neighbor Search for GPUs</title>
      <link>https://arxiv.org/abs/2308.15136</link>
      <description>arXiv:2308.15136v2 Announce Type: replace 
Abstract: Approximate Nearest Neighbor Search (ANNS) plays a critical role in various disciplines spanning data mining and artificial intelligence, from information retrieval and computer vision to natural language processing and recommender systems. Data volumes have soared in recent years and the computational cost of an exhaustive exact nearest neighbor search is often prohibitive, necessitating the adoption of approximate techniques. The balanced performance and recall of graph-based approaches have more recently garnered significant attention in ANNS algorithms, however, only a few studies have explored harnessing the power of GPUs and multi-core processors despite the widespread use of massively parallel and general-purpose computing. To bridge this gap, we introduce a novel parallel computing hardware-based proximity graph and search algorithm. By leveraging the high-performance capabilities of modern hardware, our approach achieves remarkable efficiency gains. In particular, our method surpasses existing CPU and GPU-based methods in constructing the proximity graph, demonstrating higher throughput in both large- and small-batch searches while maintaining compatible accuracy. In graph construction time, our method, CAGRA, is 2.2~27x faster than HNSW, which is one of the CPU SOTA implementations. In large-batch query throughput in the 90% to 95% recall range, our method is 33~77x faster than HNSW, and is 3.8~8.8x faster than the SOTA implementations for GPU. For a single query, our method is 3.4~53x faster than HNSW at 95% recall.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15136v2</guid>
      <category>cs.DS</category>
      <category>cs.CV</category>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroyuki Ootomo, Akira Naruse, Corey Nolet, Ray Wang, Tamas Feher, Yong Wang</dc:creator>
    </item>
    <item>
      <title>On The Maximum Linear Arrangement Problem for Trees</title>
      <link>https://arxiv.org/abs/2312.04487</link>
      <description>arXiv:2312.04487v5 Announce Type: replace 
Abstract: Linear arrangements of graphs are a well-known type of graph labeling and are found in many important computational problems, such as the Minimum Linear Arrangement Problem ($\texttt{minLA}$). A linear arrangement is usually defined as a permutation of the $n$ vertices of a graph. An intuitive geometric setting is that of vertices lying on consecutive integer positions in the real line, starting at 1; edges are often drawn as semicircles above the real line. In this paper we study the Maximum Linear Arrangement problem ($\texttt{MaxLA}$), the maximization variant of $\texttt{minLA}$. We devise a new characterization of maximum arrangements of general graphs, and prove that $\texttt{MaxLA}$ can be solved for cycle graphs in constant time, and for $k$-linear trees ($k\le2$) in time $O(n)$. We present two constrained variants of $\texttt{MaxLA}$ we call $\texttt{bipartite MaxLA}$ and $\texttt{1-thistle MaxLA}$. We prove that the former can be solved in time $O(n)$ for any bipartite graph; the latter, by an algorithm that typically runs in time $O(n^4)$ on unlabelled trees. The combination of the two variants has two promising characteristics. First, it solves $\texttt{MaxLA}$ for almost all trees consisting of a few tenths of nodes. Second, we prove that it constitutes a $3/2$-approximation algorithm for $\texttt{MaxLA}$ for trees. Furthermore, we conjecture that $\texttt{bipartite MaxLA}$ solves $\texttt{MaxLA}$ for at least $50\%$ of all free trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04487v5</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Llu\'is Alemany-Puig, Juan Luis Esteban, Ramon Ferrer-i-Cancho</dc:creator>
    </item>
    <item>
      <title>Deterministic Simple $(\Delta+\varepsilon\alpha)$-Edge-Coloring in Near-Linear Time</title>
      <link>https://arxiv.org/abs/2401.10538</link>
      <description>arXiv:2401.10538v2 Announce Type: replace 
Abstract: We study the edge-coloring problem in simple $n$-vertex $m$-edge graphs with maximum degree $\Delta$. This is one of the most classical and fundamental graph-algorithmic problems. Vizing's celebrated theorem provides $(\Delta+1)$-edge-coloring in $O(m\cdot n)$ deterministic time. This running time was improved to $O\left(m\cdot\min\left\{\Delta\cdot\log n,\sqrt{n}\right\}\right)$, and very recently to randomized $\tilde{O}\left(m\cdot n^{1/3}\right)$. A randomized $(1+\varepsilon)\Delta$-edge-coloring algorithm can be computed in $O\left(m\cdot\frac{\log^6 n}{\varepsilon^2}\right)$ time, and for large values of $\Delta$, this task requires randomized $O\left(\frac{m\cdot\log\varepsilon^{-1}}{\varepsilon^2}\right)$ time. It was however open if there exists a deterministic near-linear time algorithm for this basic problem. We devise a simple deterministic $(1+\varepsilon)\Delta$-edge-coloring algorithm with running time $O\left(m\cdot\frac{\log n}{\varepsilon}\right)$. A randomized variant of our algorithm has running time $O(m\cdot(\varepsilon^{-18}+\log(\varepsilon\cdot\Delta)))$.
  We also study edge-coloring of graphs with arboricity at most $\alpha$. A randomized computation of $(\Delta+1)$-edge-coloring requires $\tilde{O}\left(\min\{m\cdot\sqrt{n},m\cdot\Delta\}\cdot\frac{\alpha}{\Delta}\right)$ time. Deterministically, this task can be done in $O\left(m\cdot\alpha^7\cdot\log n\right)$ time. However, for large values of $\alpha$, these algorithms require super-linear time. We devise a deterministic $(\Delta+\varepsilon\alpha)$-edge-coloring algorithm with running time $O\left(\frac{m\cdot\log n}{\varepsilon^7}\right)$. A randomized version of our algorithm requires $O\left(\frac{m\cdot\log n}{\varepsilon}\right)$ expected time.
  Our algorithm is based on a novel two-way degree-splitting, which we devise in this paper. We believe that this technique is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10538v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Elkin, Ariel Khuzman</dc:creator>
    </item>
    <item>
      <title>Stochastic Multi-round Submodular Optimization with Budget</title>
      <link>https://arxiv.org/abs/2404.13737</link>
      <description>arXiv:2404.13737v2 Announce Type: replace 
Abstract: In this work we study the problem of {\em Stochastic Budgeted Multi-round Submodular Maximization} (SBMSm), in which we would like to adaptively maximize the sum over multiple rounds of the value of a monotone and submodular objective function defined on a subset of items, subject to the fact that the values of this function depend on the realization of stochastic events and the number of items that we can select over all rounds is limited by a given budget. This problem extends, and generalizes to multiple round settings, well-studied problems such as (adaptive) influence maximization and stochastic probing.
  We first show that, if the number of items and stochastic events is somehow bounded, there is a polynomial time dynamic programming algorithm for SBMSm. Then, we provide a simple greedy approximation algorithm for SBMSm, that first non-adaptively allocates the budget to be spent at each round, and then greedily and adaptively maximizes the objective function by using the budget assigned at each round. Such algorithm guarantees a $(1-1/e-\epsilon)$-approximation to the optimal adaptive value.
  Finally, by introducing a metric called {\em budget-adaptivity gap}, we measure how much an optimal policy for SBMSm, that is adaptive in both the budget allocation and item selection, is better than an optimal partially adaptive policy that, as in our greedy algorithm, determined the budget allocation in advance. We show a tight bound of $e/(e-1)$ on the budget-adaptivity gap, and this result implies that our greedy algorithm guarantees the best approximation among all partially adaptive policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13737v2</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincenzo Auletta, Diodato Ferraioli, Cosimo Vinci</dc:creator>
    </item>
    <item>
      <title>Pointwise Lipschitz Continuous Graph Algorithms via Proximal Gradient Analysis</title>
      <link>https://arxiv.org/abs/2405.08938</link>
      <description>arXiv:2405.08938v2 Announce Type: replace 
Abstract: In many real-world applications, it is prohibitively expensive to drastically change the solution to a problem after a small perturbation in the environment. Therefore, the stability of an algorithm is a very desirable property. In this paper, we study the class of pointwise Lipschitz continuous algorithms as introduced in the recent work of Kumabe and Yoshida [FOCS'23]. The Lipschitz constant of an algorithm, intuitively, bounds the ratio of the changes in its output (measured in $\ell_1$ distance) over the $\ell_1$ perturbations of the weights of the underlying graph.
  In this work, we give a general and simple framework for bounding the Lipschitz constant of algorithms measured through the unweighted $\ell_1$ distance of their outputs. Our approach consists of three main steps. First, we consider a natural continuous relaxation of the underlying graph problem by adding a smooth and strongly convex regularizer to the objective function. Then, we give upper bounds on the $\ell_1$ distance of the optimal solutions of the convex programs, under small perturbations of the weights, via a stability analysis of the trajectory of the proximal gradient method. Finally, we present new problem-specific rounding techniques to obtain integral solutions to several graph problems that approximately maintain the stability guarantees of the fractional solutions. We apply our framework to a number of problems including minimum $s$-$t$ cut, densest subgraph, maximum $b$-matching, and packing integer programs. To complement our algorithms, we show the tightness of our results for certain problems by establishing tight lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08938v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quanquan C. Liu, Grigoris Velegkas, Yuichi Yoshida, Felix Zhou</dc:creator>
    </item>
    <item>
      <title>Challenges for quantum computation of nonlinear dynamical systems using linear representations</title>
      <link>https://arxiv.org/abs/2202.02188</link>
      <description>arXiv:2202.02188v3 Announce Type: replace-cross 
Abstract: A number of recent studies have proposed that linear representations are appropriate for solving nonlinear dynamical systems with quantum computers, which fundamentally act linearly on a wave function in a Hilbert space. Linear representations, such as the Koopman representation and Koopman von Neumann mechanics, have regained attention from the dynamical-systems research community. Here, we aim to present a unified theoretical framework, currently missing in the literature, with which one can compare and relate existing methods, their conceptual basis, and their representations. We also aim to show that, despite the fact that quantum simulation of nonlinear classical systems may be possible with such linear representations, a necessary projection into a feasible finite-dimensional space will in practice eventually induce numerical artifacts which can be hard to eliminate or even control. As a result, a practical, reliable and accurate way to use quantum computation for solving general nonlinear dynamical systems is still an open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.02188v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yen Ting Lin, Robert B. Lowrie, Denis Aslangil, Yi\u{g}it Suba\c{s}{\i}, Andrew T. Sornborger</dc:creator>
    </item>
  </channel>
</rss>
