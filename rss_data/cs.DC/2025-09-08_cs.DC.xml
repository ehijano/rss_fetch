<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Sep 2025 02:22:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs</title>
      <link>https://arxiv.org/abs/2509.04719</link>
      <description>arXiv:2509.04719v1 Announce Type: new 
Abstract: The escalating adoption of diffusion models for applications such as image generation demands efficient parallel inference techniques to manage their substantial computational cost. However, existing diffusion parallelism inference schemes often underutilize resources in heterogeneous multi-GPU environments, where varying hardware capabilities or background tasks cause workload imbalance. This paper introduces Spatio-Temporal Adaptive Diffusion Inference (STADI), a novel framework to accelerate diffusion model inference in such settings. At its core is a hybrid scheduler that orchestrates fine-grained parallelism across both temporal and spatial dimensions. Temporally, STADI introduces a novel computation-aware step allocator applied after warmup phases, using a least-common-multiple-minimizing quantization technique to reduce denoising steps on slower GPUs and execution synchronization. To further minimize GPU idle periods, STADI executes an elastic patch parallelism mechanism that allocates variably sized image patches to GPUs according to their computational capability, ensuring balanced workload distribution through a complementary spatial mechanism. Extensive experiments on both load-imbalanced and heterogeneous multi-GPU clusters validate STADI's efficacy, demonstrating improved load balancing and mitigation of performance bottlenecks. Compared to patch parallelism, a state-of-the-art diffusion inference framework, our method significantly reduces end-to-end inference latency by up to 45% and significantly improves resource utilization on heterogeneous GPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04719v1</guid>
      <category>cs.DC</category>
      <category>cs.CV</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Liang, Jiahui Zhou, Zicheng Zhou, Xiaoxi Zhang, Xu Chen</dc:creator>
    </item>
    <item>
      <title>VoltanaLLM: Feedback-Driven Frequency Control and State-Space Routing for Energy-Efficient LLM Serving</title>
      <link>https://arxiv.org/abs/2509.04827</link>
      <description>arXiv:2509.04827v1 Announce Type: new 
Abstract: Modern Large Language Model (LLM) serving systems increasingly support interactive applications, like real-time chat assistants, code generation tools, and agentic workflows. However, the soaring energy cost of LLM inference presents a growing challenge for sustainable and cost-effective deployment. This paper introduces VoltanaLLM, a system for SLO-aware, energy-efficient LLM serving, built from a control theory perspective. VoltanaLLM co-designs frequency scaling and request routing in emerging prefill/decode disaggregated architectures, leveraging their decoupled execution to enable fine-grained phase-specific control. It consists of a feedback-driven frequency controller that dynamically adapts GPU frequency for prefill and decode phases, and a state-space router that explores routing decisions across frequency-scaled instances to minimize energy under latency constraints. We implement VoltanaLLM in SGLang and evaluate its performance over multiple state-of-the-art LLMs and real-world datasets. The results demonstrate that VoltanaLLM achieves up to 36.3% energy savings while maintaining near-perfect SLO attainment rate, paving the way for sustainable and intelligent LLM serving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04827v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiahuan Yu (University of Illinois Urbana-Champaign), Aryan Taneja (University of Illinois Urbana-Champaign), Junfeng Lin (Tsinghua University), Minjia Zhang (University of Illinois Urbana-Champaign)</dc:creator>
    </item>
    <item>
      <title>Toward Distributed 3D Gaussian Splatting for High-Resolution Isosurface Visualization</title>
      <link>https://arxiv.org/abs/2509.05216</link>
      <description>arXiv:2509.05216v1 Announce Type: new 
Abstract: We present a multi-GPU extension of the 3D Gaussian Splatting (3D-GS) pipeline for scientific visualization. Building on previous work that demonstrated high-fidelity isosurface reconstruction using Gaussian primitives, we incorporate a multi-GPU training backend adapted from Grendel-GS to enable scalable processing of large datasets. By distributing optimization across GPUs, our method improves training throughput and supports high-resolution reconstructions that exceed single-GPU capacity. In our experiments, the system achieves a 5.6X speedup on the Kingsnake dataset (4M Gaussians) using four GPUs compared to a single-GPU baseline, and successfully trains the Miranda dataset (18M Gaussians) that is an infeasible task on a single A100 GPU. This work lays the groundwork for integrating 3D-GS into HPC-based scientific workflows, enabling real-time post hoc and in situ visualization of complex simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05216v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE eScience 2025 Poster</arxiv:journal_reference>
      <dc:creator>Mengjiao Han, Andres Sewell, Joseph Insley, Janet Knowles, Victor A. Mateevitsi, Michael E. Papka, Steve Petruzza, Silvio Rizzi</dc:creator>
    </item>
    <item>
      <title>Dynamic reconfiguration for malleable applications using RMA</title>
      <link>https://arxiv.org/abs/2509.05248</link>
      <description>arXiv:2509.05248v1 Announce Type: new 
Abstract: This paper investigates the novel one-sided communication methods based on remote memory access (RMA) operations in MPI for dynamic resizing of malleable applications, enabling data redistribution with minimal impact on application execution. After their integration into the MaM library, these methods are compared with traditional collective-based approaches. In addition, the existing strategy Wait Drains is extended to support efficient background reconfiguration. Results show comparable performance, though high initialization costs currently limit their advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05248v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iker Mart\'in-\'Alvarez, Jos\'e I. Aliaga, Maribel Castillo</dc:creator>
    </item>
    <item>
      <title>Scaling Performance of Large Language Model Pretraining</title>
      <link>https://arxiv.org/abs/2509.05258</link>
      <description>arXiv:2509.05258v1 Announce Type: new 
Abstract: Large language models (LLMs) show best-in-class performance across a wide range of natural language processing applications. Training these models is an extremely computationally expensive task; frontier Artificial Intelligence (AI) research companies are investing billions of dollars into supercomputing infrastructure to train progressively larger models on increasingly massive datasets. Unfortunately, information about the scaling performance and training considerations of these large training pipelines is scarce in public literature. Working with large-scale datasets and models can be complex and practical recommendations are scarce in the public literature for tuning training performance when scaling up large language models. In this paper, we aim to demystify the large language model pretraining pipeline somewhat - in particular with respect to distributed training, managing large datasets across hundreds of nodes, and scaling up data parallelism with an emphasis on fully leveraging available GPU compute capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05258v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Interrante-Grant, Carla Varela-Rosa, Suhaas Narayan, Chris Connelly, Albert Reuther</dc:creator>
    </item>
    <item>
      <title>An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data</title>
      <link>https://arxiv.org/abs/2509.05213</link>
      <description>arXiv:2509.05213v1 Announce Type: cross 
Abstract: This work addresses the key challenges of applying federated learning to large-scale deep neural networks, particularly the issue of client drift due to data heterogeneity across clients and the high costs of communication, computation, and memory. We propose FedSub, an efficient subspace algorithm for federated learning on heterogeneous data. Specifically, FedSub utilizes subspace projection to guarantee local updates of each client within low-dimensional subspaces, thereby reducing communication, computation, and memory costs. Additionally, it incorporates low-dimensional dual variables to mitigate client drift. We provide convergence analysis that reveals the impact of key factors such as step size and subspace projection matrices on convergence. Experimental results demonstrate its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05213v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaojiao Zhang, Yuqi Xu, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>A LOCAL View of the Polynomial Hierarchy</title>
      <link>https://arxiv.org/abs/2305.09538</link>
      <description>arXiv:2305.09538v4 Announce Type: replace 
Abstract: We extend classical methods of computational complexity to the realm of distributed computing, where they sometimes prove more effective than in their original context. Our focus is on decision problems in the LOCAL model, a setting in which networked computers use synchronous message passing to collectively answer questions about their network topology. We impose two time constraints on this model: the number of communication rounds is bounded by a constant, and the number of computation steps of each computer is polynomially bounded in the size of its local input and received messages.
  By letting two players alternately assign certificates to all computers, we obtain a distributed generalization of the polynomial hierarchy (and thus of the complexity classes $\mathbf{P}$ and $\mathbf{NP}$). We then extend key results of complexity theory to this setting, including the Cook-Levin theorem (which identifies Boolean satisfiability as a complete problem for $\mathbf{NP}$) and Fagin's theorem (which characterizes $\mathbf{NP}$ as the class of problems expressible in existential second-order logic). The original results can be recovered as the special case where the network consists of a single computer.
  But perhaps more surprisingly, separating complexity classes becomes easier in the distributed setting: we can show that our hierarchy is infinite, while it remains notoriously open whether the same holds when restricted to a single computer. (By contrast, a collapse of our hierarchy would have implied a collapse of the classical polynomial hierarchy.)
  As an application, we propose quantifier alternation as a new tool for measuring the locality of problems in distributed computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09538v4</guid>
      <category>cs.DC</category>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Reiter</dc:creator>
    </item>
    <item>
      <title>Taking GPU Programming Models to Task for Performance Portability</title>
      <link>https://arxiv.org/abs/2402.08950</link>
      <description>arXiv:2402.08950v4 Announce Type: replace 
Abstract: Portability is critical to ensuring high productivity in developing and maintaining scientific software as the diversity in on-node hardware architectures increases. While several programming models provide portability for diverse GPU systems, they don't make any guarantees about performance portability. In this work, we explore several programming models -- CUDA, HIP, Kokkos, RAJA, OpenMP, OpenACC, and SYCL, to assess the consistency of their performance across NVIDIA and AMD GPUs. We use five proxy applications from different scientific domains, create implementations where missing, and use them to present a comprehensive comparative evaluation of the performance portability of these programming models. We provide a Spack scripting-based methodology to ensure reproducibility of experiments conducted in this work. Finally, we analyze the reasons for why some programming models underperform in certain scenarios and in some cases, present performance optimizations to the proxy applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08950v4</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3721145.3730423</arxiv:DOI>
      <dc:creator>Joshua H. Davis, Pranav Sivaraman, Joy Kitson, Konstantinos Parasyris, Harshitha Menon, Isaac Minn, Giorgis Georgakoudis, Abhinav Bhatele</dc:creator>
    </item>
    <item>
      <title>Hiding Latencies in Network-Based Image Loading for Deep Learning</title>
      <link>https://arxiv.org/abs/2503.22643</link>
      <description>arXiv:2503.22643v2 Announce Type: replace 
Abstract: In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.
  In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22643v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Versaci, Giovanni Busonera</dc:creator>
    </item>
    <item>
      <title>ParEval-Repo: A Benchmark Suite for Evaluating LLMs with Repository-level HPC Translation Tasks</title>
      <link>https://arxiv.org/abs/2506.20938</link>
      <description>arXiv:2506.20938v2 Announce Type: replace 
Abstract: GPGPU architectures have become significantly more diverse in recent years, which has led to an emergence of a variety of specialized programming models and software stacks to support them. Portable programming models exist, but they require significant developer effort to port to and optimize for different hardware architectures. Large language models (LLMs) may help to reduce this programmer burden. In this paper, we present a novel benchmark and testing framework, ParEval-Repo, which can be used to evaluate the efficacy of LLM-based approaches in automatically translating entire codebases across GPGPU execution models. ParEval-Repo includes several scientific computing and AI mini-applications in a range of programming models and levels of repository complexity. We use ParEval-Repo to evaluate a range of state-of-the-art open-source and commercial LLMs, with both a non-agentic and a top-down agentic approach. We assess code generated by the LLMs and approaches in terms of compilability, functional correctness, categories of build errors, and the cost of translation in terms of the number of inference tokens. Our results demonstrate that LLM translation of scientific applications is feasible for small programs but difficulty with generating functional build systems and cross-file dependencies pose challenges in scaling to larger codebases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20938v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua H. Davis, Daniel Nichols, Ishan Khillan, Abhinav Bhatele</dc:creator>
    </item>
    <item>
      <title>OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks</title>
      <link>https://arxiv.org/abs/2508.04833</link>
      <description>arXiv:2508.04833v3 Announce Type: replace 
Abstract: Gossip algorithms are pivotal in the dissemination of information within decentralized systems. Consequently, numerous gossip libraries have been developed and widely utilized especially in blockchain protocols for the propagation of blocks and transactions. A well-established library is libp2p, which provides two gossip algorithms: floodsub and gossipsub. These algorithms enable the delivery of published messages to a set of peers. In this work we aim to enhance the performance and reliability of libp2p by introducing OPTIMUMP2P, a novel gossip algorithm that leverages the capabilities of Random Linear Network Coding (RLNC) to expedite the dissemination of information in a peer-to-peer (P2P) network while ensuring reliable delivery, even in the presence of malicious actors capable of corrupting the transmitted data. Preliminary research from the Ethereum Foundation has demonstrated the use of RLNC in the significant improvement in the block propagation time [14]. Here we present extensive evaluation results both in simulation and real-world environments that demonstrate the performance gains of OPTIMUMP2P over the Gossipsub protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04833v3</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Nicolaou, Onyeka Obi, Aayush Rajasekaran, Alejandro Bergasov, Aleksandr Bezobchuk, Kishori M. Konwar, Michael Meier, Santiago Paiva, Har Preet Singh, Swarnabha Sinha. Sriram Vishwanath, Muriel Medard</dc:creator>
    </item>
    <item>
      <title>Your Trust, Your Terms: A General Paradigm for Near-Instant Cross-Chain Transfer</title>
      <link>https://arxiv.org/abs/2403.15191</link>
      <description>arXiv:2403.15191v4 Announce Type: replace-cross 
Abstract: Cross-chain transactions today remain slow, costly, and fragmented. Existing custodial exchanges expose users to counterparty and centralization risks, while non-custodial liquidity bridges suffer from capital inefficiency and slow settlement; critically, neither approach guarantees users a unilateral path to recover assets if the infrastructure fails.
  We introduce the Delegated Ownership Transfer (DOT) paradigm, which decouples key ownership from value ownership to enable secure, high-performance cross-chain payments. In DOT, a user deposits funds into a sandboxed on-chain Temporary Account (TA) (value ownership) while delegating its private key (key ownership) to an abstract Trusted Entity (TE). Payments and swaps are thus reframed as near-instant, off-chain ownership handoffs. Security follows from dual guarantees: the TE's exclusive control prevents double-spending, while a pre-signed, unilateral recovery transaction ensures users retain ultimate authority over their assets. Building on this foundation, we design a novel off-chain atomic swap that executes optimistically in near real time and remains fair even if the TE fails.
  We formalize the security of DOT in the Universal Composability framework and present two concrete instantiations: a high-performance design based on Trusted Execution Environments (TEEs) and a cryptographically robust variant leveraging threshold cryptography. Our geo-distributed prototype shows that cross-chain payments complete in under 16.70 ms and atomic swaps in under 33.09 ms, with costs fully decoupled from Layer-1 gas fees. These results provide a practical blueprint for building secure, efficient, and interoperable cross-chain payment systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15191v4</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Wu, Jingyu Liu, Xuechao Wang, Jian Liu, Yingjie Xue, Kui Ren, Chun Chen</dc:creator>
    </item>
    <item>
      <title>MULTI-SCOUT: Multistatic Integrated Sensing and Communications in 5G and Beyond for Moving Target Detection, Positioning, and Tracking</title>
      <link>https://arxiv.org/abs/2507.02613</link>
      <description>arXiv:2507.02613v2 Announce Type: replace-cross 
Abstract: This paper presents a complete signal-processing chain for multistatic integrated sensing and communications (ISAC) using 5G Positioning Reference Signal (PRS). We consider a distributed architecture in which one gNB transmits a periodic OFDM-PRS waveform while multiple spatially separated receivers exploit the same signal for target detection, parameter estimation and tracking. A coherent cross-ambiguity function (CAF) is evaluated to form a range-Doppler map from which the bistatic delay and radial velocity are extracted for every target. For a single target, bistatic delays are fused through nonlinear least-squares trilateration, yielding a geometric position estimate, and a regularized linear inversion of the radial-speed equations yields a two-dimensional velocity vector, where speed and heading are obtained. The approach is applied to 2D and 3D settings, extended to account for receiver clock synchronization bias, and generalized to multiple targets by resolving target association. The sequence of position-velocity estimates is then fed to standard and extended Kalman filters to obtain smoothed tracks. Our results show high-fidelity moving-target detection, positioning, and tracking using 5G PRS signals for multistatic ISAC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02613v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>eess.SP</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sastry Kompella, Gustave Anderson, Jonathan Ashdown</dc:creator>
    </item>
  </channel>
</rss>
