<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Mar 2025 04:00:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>High-dimensional Array Bayesian Screening Based on Distributions with Structural Zeroes</title>
      <link>https://arxiv.org/abs/2503.13605</link>
      <description>arXiv:2503.13605v1 Announce Type: new 
Abstract: In many biomedical applications with high-dimensional features, such as single-cell RNA-sequencing, it is not uncommon to observe numerous structural zeros. Identifying important features from a pool of high-dimensional data for subsequent detailed analysis is often of interest. Here, we describe an exact, rapid Bayesian screening approach with attractive diagnostic properties, utilizing a Tweedie model. The method provides the likelihood that a feature with structural zeros merits further investigation, as well as distributions of the effect magnitudes and the proportion of features with the same expected responses under alternative conditions. The method is agnostic to assay, data type, and application. Through numerical studies, we demonstrate that the proposed methodology is effective in identifying important features for follow-up experimentation across a range of applications, including single-cell differential expression analysis of embryonic stem cells and embryonic fibroblasts in mice and differential analysis of CD4 and CD8 Peripheral Blood Mononuclear Cells (PBMCs) in humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13605v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>A. Lawrence Gould, Erina Paul, Piyali Basak, Arinjita Bhattacharyya, Himel Mallick</dc:creator>
    </item>
    <item>
      <title>Bayesian high-dimensional biological pathway-guided mediation analysis with application to metabolomics</title>
      <link>https://arxiv.org/abs/2503.13894</link>
      <description>arXiv:2503.13894v1 Announce Type: new 
Abstract: With advances in high-resolution mass spectrometry technologies, metabolomics data are increasingly used to investigate biological mechanisms underlying associations between exposures and health outcomes in clinical and epidemiological studies. Mediation analysis is a powerful framework for investigating a hypothesized causal chain and when applied to metabolomics data, a large number of correlated metabolites belonging to interconnected metabolic pathways need to be considered as mediators. To identify metabolic pathways as active mediators, existing approaches typically focus on first identifying individual metabolites as active mediators, followed by post-hoc metabolic pathway determination. These multi-stage procedures make statistical inference challenging. We propose a Bayesian biological pathway-guided mediation analysis that aims to jointly analyze all metabolites together, identify metabolic pathways directly, and estimate metabolic pathway-specific indirect effects. This is accomplished by incorporating existing biological knowledge of metabolic pathways to account for correlations among mediators, along with variable selection and dimension reduction techniques. Advantages of the proposed method is demonstrated in extensive simulation studies with real-word metabolic pathway structure. We apply the proposed method to two studies examining the role of metabolism in mediating (1) the effect of Roux-en-Y gastric bypass on glycemic control, and (2) the effect of prenatal exposure to per- and polyfluoroalkyl substances (PFAS) on gestational age at birth. Our analyses confirm metabolic pathways previously identified and provide additional uncertainty quantification for the mediation effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13894v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzi Zhang, Donghai Liang, Youran Tan, Anne L. Dunlop, Howard H. Chang</dc:creator>
    </item>
    <item>
      <title>Four checks for low-fidelity synthetic data: recommendations for disclosure control and quality evaluation</title>
      <link>https://arxiv.org/abs/2503.14211</link>
      <description>arXiv:2503.14211v1 Announce Type: new 
Abstract: Confidential administrative data is usually only available to researchers within a trusted research environment (TRE). Recently, some UK groups have proposed that low-fidelity synthetic data (LFSD) is available to researchers outside the TRE to allow code-testing and data discovery. There is a need for transparency so that those who access LFSD know how it has been created and what to expect from it. Relationships between variables are not maintained in LFSD, but a real or apparent data breach can occur from its release. To be useful to researchers for preliminary analyses LFSD needs to meet some minimum quality standards. Researchers who will use the LFSD need to have details of how it compares with the data they will access in the TRE clearly explained and documented. We propose that these checks should be run by data controllers before releasing LFSD to ensure it is well documented, useful and non-disclosive. 1.Labelling To avoid an apparent data breach, steps must be taken to ensure that the SD is clearly identified as not being real data. 2.Disclosure The LFSD should undergo disclosure risk evaluation as described below and any risks identified mitigated. 3.Structure The structure of the SD should be as similar as possible to the TRE data. 4.Documentation Differences in the structure of the SD compared to data in the TRE must be documented, and the way(s) that analyses of the SD expect to differ from those of data in the TRE must be clarified.
  We propose details of each of these below; but a strict, rule-based approach should not be used. Instead, the data holders should modify the rules to take account of the type of information that may be disclosed and the circumstances of the data release (to whom and under what conditions).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14211v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gillian M Raab, Sophie McCall, Liam Cavin</dc:creator>
    </item>
    <item>
      <title>Spatial and temporal analysis of political violence in the United States</title>
      <link>https://arxiv.org/abs/2503.14399</link>
      <description>arXiv:2503.14399v1 Announce Type: new 
Abstract: Acts of political violence in the continental United States have increased dramatically in the last decade. For this rise in political violence, we are interested in where and when such incidents occur: how are the locations and times of incidents of political violence distributed across the continental United States, and what can we learn from a detailed examination of these distributions? We find the distribution of locations of political violence is neither uniform nor Poisson random, and that such locations cluster into well-defined geographic regions. Focusing on the county level we find a markedly skewed distribution of county counts of incidents of political violence. Examination of news reports and commentaries provided by the Armed Conflict Location &amp; Event Data Project for the extreme outlier counties reveals compelling political and social background to the reported incidents of political violence. This, together with credible information on the role of social media in fomenting political violence leads us to postulate a field notion of upsetness as a major background to political violence. Using the time stamp on incidents of political violence we constructed a nearest neighbor model to predict future incidents of political violence at specific locations that involved a fatality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14399v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ravi Varma Pakalapati, Gary E. Davis</dc:creator>
    </item>
    <item>
      <title>Analysis of Learning-based Offshore Wind Power Prediction Models with Various Feature Combinations</title>
      <link>https://arxiv.org/abs/2503.13493</link>
      <description>arXiv:2503.13493v1 Announce Type: cross 
Abstract: Accurate wind speed prediction is crucial for designing and selecting sites for offshore wind farms. This paper investigates the effectiveness of various machine learning models in predicting offshore wind power for a site near the Gulf of Mexico by analyzing meteorological data. After collecting and preprocessing meteorological data, nine different input feature combinations were designed to assess their impact on wind power predictions at multiple heights. The results show that using wind speed as the output feature improves prediction accuracy by approximately 10% compared to using wind power as the output. In addition, the improvement of multi-feature input compared with single-feature input is not obvious mainly due to the poor correlation among key features and limited generalization ability of models. These findings underscore the importance of selecting appropriate output features and highlight considerations for using machine learning in wind power forecasting, offering insights that could guide future wind power prediction models and conversion techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13493v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linhan Fang, Fan Jiang, Ann Mary Toms, Xingpeng Li</dc:creator>
    </item>
    <item>
      <title>Improving the quasi-biennial oscillation via a surrogate-accelerated multi-objective optimization</title>
      <link>https://arxiv.org/abs/2503.13498</link>
      <description>arXiv:2503.13498v1 Announce Type: cross 
Abstract: Simulating the QBO remains a formidable challenge partly due to uncertainties in representing convectively generated gravity waves. We develop an end-to-end uncertainty quantification workflow that calibrates these gravity wave processes in E3SM to yield a more realistic QBO. Central to our approach is a domain knowledge-informed, compressed representation of high-dimensional spatio-temporal wind fields. By employing a parsimonious statistical model that learns the fundamental frequency of the underlying stochastic process from complex observations, we extract a concise set of interpretable and physically meaningful quantities of interest capturing key attributes, such as oscillation amplitude and period. Building on this, we train a probabilistic surrogate model. Leveraging the Karhunen-Loeve decomposition, our surrogate efficiently represents these characteristics as a set of orthogonal features, thereby capturing the cross-correlations among multiple physics quantities evaluated at different stratospheric pressure levels, and enabling rapid surrogate-based inference at a fraction of the computational cost of inference reliant only on full-scale simulations. Finally, we analyze the inverse problem using a multi-objective approach. Our study reveals a tension between amplitude and period that constrains the QBO representation, precluding a single optimal solution that simultaneously satisfies both objectives. To navigate this challenge, we quantify the bi-criteria trade-off and generate a representative set of Pareto optimal physics parameter values that balance the conflicting objectives. This integrated workflow not only improves the fidelity of QBO simulations but also advances toward a practical framework for tuning modes of variability and quasi-periodic phenomena, offering a versatile template for uncertainty quantification in complex geophysical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13498v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.flu-dyn</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Damiano, Walter M. Hannah, Chih-Chieh Chen, James J. Benedict, Khachik Sargsyan, Bert Debusschere, Michael S. Eldred</dc:creator>
    </item>
    <item>
      <title>Ranking matters: Does the new format select the best teams for the knockout phase in the UEFA Champions League?</title>
      <link>https://arxiv.org/abs/2503.13569</link>
      <description>arXiv:2503.13569v1 Announce Type: cross 
Abstract: Starting in the 2024/25 season, the Union of European Football Associations (UEFA) has fundamentally changed the format of its club competitions: the group stage has been replaced by a league phase played by 36 teams in an incomplete round robin format. This makes ranking the teams based on their results challenging because teams play against different sets of opponents, whose strengths vary. In this research note, we apply several well-known ranking methods for incomplete round robin tournaments to the 2024/25 UEFA Champions League league phase. Our results show that it is doubtful whether the currently used point-based system provides the best ranking of the teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13569v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o, Karel Devriesere, Dries Goossens, Andr\'as Gyimesi, Roel Lambers, Frits Spieksma</dc:creator>
    </item>
    <item>
      <title>Confidence Intervals Using Turing's Estimator: Simulations and Applications</title>
      <link>https://arxiv.org/abs/2503.14313</link>
      <description>arXiv:2503.14313v1 Announce Type: cross 
Abstract: Turing's estimator allows one to estimate the probabilities of outcomes that either do not appear or only rarely appear in a given random sample. We perform a simulation study to understand the finite sample performance of several related confidence intervals (CIs) and introduce an approach for selecting the appropriate CI for a given sample. We give an application to the problem of authorship attribution and apply it to a dataset comprised of tweets from users on X (Twitter). Further, we derive several theoretical results about asymptotic normality and asymptotic Poissonity of Turing's estimator for two important discrete distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14313v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Chang, Michael Grabchak, Jialin Zhang</dc:creator>
    </item>
    <item>
      <title>Partially Directed Configuration Model with Homophily and Respondent-Driven Sampling</title>
      <link>https://arxiv.org/abs/2503.14334</link>
      <description>arXiv:2503.14334v1 Announce Type: cross 
Abstract: Respondent-driven sampling (RDS) is a sampling scheme used in socially connected human populations lacking a sampling frame. One of the first steps to make design-based inferences from RDS data is to estimate the sampling probabilities. A classical approach for such estimation assumes that a first-order Markov chain over a fully connected and undirected network may adequately represent RDS. This convenient model, however, does not reflect that the network may be directed and homophilous. The methods proposed in this work aim to address this issue. The main methodological contributions of this manuscript are two fold: first, we introduce a partially directed and homophilous network configuration model, and second, we develop two mathematical representations of the RDS sampling process over the proposed configuration model. Our simulation study shows that the resulting sampling probabilities are similar to those of RDS, and they improve the prevalence estimation under various realistic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14334v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Sepulveda-Pe\~naloza, Isabelle S. Beaudry</dc:creator>
    </item>
    <item>
      <title>Wasserstein-based Kernels for Clustering: Application to Power Distribution Graphs</title>
      <link>https://arxiv.org/abs/2503.14357</link>
      <description>arXiv:2503.14357v1 Announce Type: cross 
Abstract: Many data clustering applications must handle objects that cannot be represented as vector data. In this context, the bag-of-vectors representation can be leveraged to describe complex objects through discrete distributions, and the Wasserstein distance can effectively measure the dissimilarity between them. Additionally, kernel methods can be used to embed data into feature spaces that are easier to analyze. Despite significant progress in data clustering, a method that simultaneously accounts for distributional and vectorial dissimilarity measures is still lacking. To tackle this gap, this work explores kernel methods and Wasserstein distance metrics to develop a computationally tractable clustering framework. The compositional properties of kernels allow the simultaneous handling of different metrics, enabling the integration of both vectors and discrete distributions for object representation. This approach is flexible enough to be applied in various domains, such as graph analysis and image processing. The framework consists of three main components. First, we efficiently approximate pairwise Wasserstein distances using multiple reference distributions. Second, we employ kernel functions based on Wasserstein distances and present ways of composing kernels to express different types of information. Finally, we use the kernels to cluster data and evaluate the quality of the results using scalable and distance-agnostic validity indices. A case study involving two datasets of 879 and 34,920 power distribution graphs demonstrates the framework's effectiveness and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14357v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alfredo Oneto, Blazhe Gjorgiev, Giovanni Sansavini</dc:creator>
    </item>
    <item>
      <title>A Non-parametric Approach to Inference about the Tail of a Continuous or a Discrete Distribution</title>
      <link>https://arxiv.org/abs/2204.12350</link>
      <description>arXiv:2204.12350v2 Announce Type: replace 
Abstract: This article introduces a non-parametric information-theoretic approach to inference about the tail of a continuous or a discrete distribution. Leveraging a new concept named tail profile -- a set of information-theoretic quantities developed from results of domains of attraction on countable alphabets -- theoretical evidence supports the identification of specific discrete distributional tail types through a sequence of plots. The approach discerns tail types by bench-marking against exponential, and three thicker-than-exponential families: near-exponential, sub-exponential, and power-law (zipf, Pareto). For tails thicker-than-exponential, the approach also provides point and interval estimates for some of the underlying distribution parameters. While primarily designed to streamline the selection of discrete parametric models for detailed statistical analysis, a supporting theorem enables the method's extension use to continuous data, stating that binning continuous data with a common width preserves the tail decay rate under certain conditions. Simulations are presented to demonstrate the method's performance across various scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.12350v2</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jialin Zhang, Zhiyi Zhang</dc:creator>
    </item>
    <item>
      <title>Comparative Judgement Modeling to Map Forced Marriage at Local Levels</title>
      <link>https://arxiv.org/abs/2212.01202</link>
      <description>arXiv:2212.01202v4 Announce Type: replace 
Abstract: Forcing someone into marriage against their will is a violation of their human rights. In 2021, the county of Nottinghamshire, UK, launched a strategy to tackle forced marriage and violence against women and girls. However, accessing information about where victims are located in the county could compromise their safety, so it is not possible to develop interventions for different areas of the county. Comparative judgement studies offer a way to map the risk of human rights abuses without collecting data that could compromise victim safety. Current methods require studies to have a large number of participants, so we develop a comparative judgement model that provides a more flexible spatial modelling structure and a mechanism to schedule comparisons more effectively. The methods reduce the data collection burden on participants and make a comparative judgement study feasible with a small number of participants. Underpinning these methods is a latent variable representation that improves on the scalability of previous comparative judgement models. We use these methods to map the risk of forced marriage across Nottinghamshire thereby supporting the county's strategy for tackling violence against women and girls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01202v4</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1214/24-AOAS1966</arxiv:DOI>
      <arxiv:journal_reference>Ann. Appl. Stat. 19 (1) 419 - 439, March 2025</arxiv:journal_reference>
      <dc:creator>R. G. Seymour, A. Nyarko-Agyei, H. R. McCabe, K. Severn, T. Kypraios, D. Sirl, A. Taylor</dc:creator>
    </item>
    <item>
      <title>Evidence of social learning across symbolic cultural barriers in sperm whales</title>
      <link>https://arxiv.org/abs/2307.05304</link>
      <description>arXiv:2307.05304v4 Announce Type: replace-cross 
Abstract: We provide quantitative evidence suggesting social learning in sperm whales across socio-cultural boundaries, using acoustic data from the Pacific and Atlantic Oceans. Traditionally, sperm whale populations are categorized into clans based on their vocal repertoire: the rhythmically patterned click sequences (codas) that they use. Among these codas, identity codas function as symbolic markers for each clan, accounting for 35-60% of codas they produce. We introduce a computational method to model whale speech, which encodes rhythmic micro-variations within codas, capturing their vocal style. We find that vocal style-clans closely align with repertoire-clans. However, contrary to vocal repertoire, we show that sympatry increases vocal style similarity between clans for non-identity codas, i.e. most codas, suggesting social learning across cultural boundaries. More broadly, this subcoda structure model offers a framework for comparing communication systems in other species, with potential implications for deeper understanding of vocal and cultural transmission within animal societies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05304v4</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ant\'onio Leit\~ao, Maxime Lucas, Simone Poetto, Taylor A. Hersh, Shane Gero, David Gruber, Michael Bronstein, Giovanni Petri</dc:creator>
    </item>
    <item>
      <title>Can artificial intelligence predict clinical trial outcomes?</title>
      <link>https://arxiv.org/abs/2411.17595</link>
      <description>arXiv:2411.17595v2 Announce Type: replace-cross 
Abstract: This study evaluates the performance of large language models (LLMs) and the HINT model in predicting clinical trial outcomes, focusing on metrics including Balanced Accuracy, Matthews Correlation Coefficient (MCC), Recall, and Specificity. Results show that GPT-4o achieves superior overall performance among LLMs but, like its counterparts (GPT-3.5, GPT-4mini, Llama3), struggles with identifying negative outcomes. In contrast, HINT excels in negative sample recognition and demonstrates resilience to external factors (e.g., recruitment challenges) but underperforms in oncology trials, a major component of the dataset. LLMs exhibit strengths in early-phase trials and simpler endpoints like Overall Survival (OS), while HINT shows consistency across trial phases and excels in complex endpoints (e.g., Objective Response Rate). Trial duration analysis reveals improved model performance for medium- to long-term trials, with GPT-4o and HINT displaying stability and enhanced specificity, respectively. We underscore the complementary potential of LLMs (e.g., GPT-4o, Llama3) and HINT, advocating for hybrid approaches to leverage GPT-4o's predictive power and HINT's specificity in clinical trial outcome forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17595v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyi Jin, Lu Chen, Hongru Ding, Meijie Wang, Lun Yu</dc:creator>
    </item>
    <item>
      <title>Sustainable Greenhouse Microclimate Modeling: A Comparative Analysis of Recurrent and Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2502.17371</link>
      <description>arXiv:2502.17371v3 Announce Type: replace-cross 
Abstract: The integration of photovoltaic (PV) systems into greenhouses not only optimizes land use but also enhances sustainable agricultural practices by enabling dual benefits of food production and renewable energy generation. However, accurate prediction of internal environmental conditions is crucial to ensure optimal crop growth while maximizing energy production. This study introduces a novel application of Spatio-Temporal Graph Neural Networks (STGNNs) to greenhouse microclimate modeling, comparing their performance with traditional Recurrent Neural Networks (RNNs). While RNNs excel at temporal pattern recognition, they cannot explicitly model the directional relationships between environmental variables. Our STGNN approach addresses this limitation by representing these relationships as directed graphs, enabling the model to capture both environmental dependencies and their directionality. Using high-frequency data collected at 15-minute intervals from a greenhouse in Volos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winter conditions ($R^2 = 0.985$) but show limitations during summer cooling system operation. Though STGNNs currently show lower performance (winter $R^2 = 0.947$), their architecture offers greater potential for integrating additional variables such as PV generation and crop growth indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17371v3</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emiliano Seri, Marcello Petitta, Cristina Cornaro</dc:creator>
    </item>
  </channel>
</rss>
