<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>TOFLUX: A Differentiable Topology Optimization Framework for Multiphysics Fluidic Problems</title>
      <link>https://arxiv.org/abs/2508.17564</link>
      <description>arXiv:2508.17564v1 Announce Type: new 
Abstract: Topology Optimization (TO) holds the promise of designing next-generation compact and efficient fluidic devices. However, the inherent complexity of fluid-based TO systems, characterized by multiphysics nonlinear interactions, poses substantial barriers to entry for researchers.
  Beyond the inherent intricacies of forward simulation models, design optimization is further complicated by the difficulty of computing sensitivities, i.e., gradients. Manual derivation and implementation of sensitivities are often laborious and prone to errors, particularly for non-trivial objectives, constraints, and material models. An alternative solution is automatic differentiation (AD). Although AD has been previously demonstrated for simpler TO problems, extending its use to complex nonlinear multiphysics systems, specifically in fluidic optimization, is key to reducing the entry barrier.
  To this end, we introduce TOFLUX, a TO framework for fluid devices leveraging the JAX library for high-performance automatic differentiation. The flexibility afforded by AD enables the rapid exploration and evaluation of various objectives and constraints. We illustrate this capability through challenging examples encompassing thermo-fluidic coupling, fluid-structure interaction, and non-Newtonian flows. Additionally, we demonstrate the seamless integration of our framework with neural networks and machine learning methodologies, enabling modern approaches to scientific computing. Ultimately, the framework aims to provide a foundational resource to accelerate research and innovation in fluid-based TO. The software accompanying this educational paper can be accessed at github.com/UW-ERSL/TOFLUX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17564v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Kumar Padhy, Krishnan Suresh, Aaditya Chandrasekhar</dc:creator>
    </item>
    <item>
      <title>Balancing the exploration-exploitation trade-off in active learning for surrogate model-based reliability analysis via multi-objective optimization</title>
      <link>https://arxiv.org/abs/2508.18170</link>
      <description>arXiv:2508.18170v1 Announce Type: new 
Abstract: Reliability assessment of engineering systems is often hindered by the need to evaluate limit-state functions through computationally expensive simulations, rendering standard sampling impractical. An effective solution is to approximate the limit-state function with a surrogate model iteratively refined through active learning, thereby reducing the number of expensive simulations. At each iteration, an acquisition strategy selects the next sample by balancing two competing goals: exploration, to reduce global predictive uncertainty, and exploitation, to improve accuracy near the failure boundary. Classical strategies, such as the U-function and the Expected Feasibility Function (EFF), implicitly condense exploration and exploitation into a scalar score derived from the surrogate predictive mean and variance, concealing the trade-off and biasing sampling. We introduce a multi-objective optimization (MOO) formulation for sample acquisition in reliability analysis, where exploration and exploitation are explicit, competing objectives. Within our framework, U and EFF correspond to specific Pareto-optimal solutions, providing a unifying perspective that connects classical and Pareto-based approaches. Solving the MOO problem discards dominated candidates, yielding a compact Pareto set, with samples representing a quantifiable exploration-exploitation trade-off. To select samples from the Pareto set, we adopt the knee point and the compromise solution, and further propose a strategy that adjusts the trade-off according to reliability estimates. Across benchmark limit-state functions, we assess the sample efficiency and active learning performance of all strategies. Results show that U and EFF exhibit case-dependent performance, knee and compromise are generally effective, and the adaptive strategy is robust, consistently reaching strict targets and maintaining relative errors below 0.1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18170v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan A. Moran, Pablo G. Morato</dc:creator>
    </item>
    <item>
      <title>Physics-Inspired Spatial Temporal Graph Neural Networks for Predicting Industrial Chain Resilience</title>
      <link>https://arxiv.org/abs/2508.16836</link>
      <description>arXiv:2508.16836v1 Announce Type: cross 
Abstract: Industrial chain plays an increasingly important role in the sustainable development of national economy. However, as a typical complex network, data-driven deep learning is still in its infancy in describing and analyzing the resilience of complex networks, and its core is the lack of a theoretical framework to describe the system dynamics. In this paper, we propose a physically informative neural symbolic approach to describe the evolutionary dynamics of complex networks for resilient prediction. The core idea is to learn the dynamics of the activity state of physical entities and integrate it into the multi-layer spatiotemporal co-evolution network, and use the physical information method to realize the joint learning of physical symbol dynamics and spatiotemporal co-evolution topology, so as to predict the industrial chain resilience. The experimental results show that the model can obtain better results and predict the elasticity of the industry chain more accurately and effectively, which has certain practical significance for the development of the industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16836v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bicheng Wang, Junping Wang, Yibo Xue</dc:creator>
    </item>
    <item>
      <title>A Decoupled LOB Representation Framework for Multilevel Manipulation Detection with Supervised Contrastive Learning</title>
      <link>https://arxiv.org/abs/2508.17086</link>
      <description>arXiv:2508.17086v1 Announce Type: cross 
Abstract: Financial markets are critical to global economic stability, yet trade-based manipulation (TBM) often undermines their fairness. Spoofing, a particularly deceptive TBM strategy, exhibits multilevel anomaly patterns that have not been adequately modeled. These patterns are usually concealed within the rich, hierarchical information of the Limit Order Book (LOB), which is challenging to leverage due to high dimensionality and noise. To address this, we propose a representation learning framework combining a cascaded LOB representation pipeline with supervised contrastive learning. Extensive experiments demonstrate that our framework consistently improves detection performance across diverse models, with Transformer-based architectures achieving state-of-the-art results. In addition, we conduct systematic analyses and ablation studies to investigate multilevel anomalies and the contributions of key components, offering broader insights into representation learning and anomaly detection for complex sequential data. Our code will be released later at this URL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17086v1</guid>
      <category>q-fin.CP</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yushi Lin, Peng Yang</dc:creator>
    </item>
    <item>
      <title>Easy Acceleration with Distributed Arrays</title>
      <link>https://arxiv.org/abs/2508.17493</link>
      <description>arXiv:2508.17493v1 Announce Type: cross 
Abstract: High level programming languages and GPU accelerators are powerful enablers for a wide range of applications. Achieving scalable vertical (within a compute node), horizontal (across compute nodes), and temporal (over different generations of hardware) performance while retaining productivity requires effective abstractions. Distributed arrays are one such abstraction that enables high level programming to achieve highly scalable performance. Distributed arrays achieve this performance by deriving parallelism from data locality, which naturally leads to high memory bandwidth efficiency. This paper explores distributed array performance using the STREAM memory bandwidth benchmark on a variety of hardware. Scalable performance is demonstrated within and across CPU cores, CPU nodes, and GPU nodes. Horizontal scaling across multiple nodes was linear. The hardware used spans decades and allows a direct comparison of hardware improvements for memory bandwidth over this time range; showing a 10x increase in CPU core bandwidth over 20 years, 100x increase in CPU node bandwidth over 20 years, and 5x increase in GPU node bandwidth over 5 years. Running on hundreds of MIT SuperCloud nodes simultaneously achieved a sustained bandwidth $&gt;$1 PB/s.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17493v1</guid>
      <category>cs.DC</category>
      <category>cs.CE</category>
      <category>cs.MS</category>
      <category>cs.PF</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy Kepner, Chansup Byun, LaToya Anderson, William Arcand, David Bestor, William Bergeron, Alex Bonn, Daniel Burrill, Vijay Gadepally, Ryan Haney, Michael Houle, Matthew Hubbell, Hayden Jananthan, Michael Jones, Piotr Luszczek, Lauren Milechin, Guillermo Morales, Julie Mullen, Andrew Prout, Albert Reuther, Antonio Rosa, Charles Yee, Peter Michaleas</dc:creator>
    </item>
    <item>
      <title>Boltzina: Efficient and Accurate Virtual Screening via Docking-Guided Binding Prediction with Boltz-2</title>
      <link>https://arxiv.org/abs/2508.17555</link>
      <description>arXiv:2508.17555v1 Announce Type: cross 
Abstract: In structure-based drug discovery, virtual screening using conventional molecular docking methods can be performed rapidly but suffers from limitations in prediction accuracy. Recently, Boltz-2 was proposed, achieving extremely high accuracy in binding affinity prediction, but requiring approximately 20 seconds per compound per GPU, making it difficult to apply to large-scale screening of hundreds of thousands to millions of compounds. This study proposes Boltzina, a novel framework that leverages Boltz-2's high accuracy while significantly improving computational efficiency. Boltzina achieves both accuracy and speed by omitting the rate-limiting structure prediction from Boltz-2's architecture and directly predicting affinity from AutoDock Vina docking poses. We evaluate on eight assays from the MF-PCBA dataset and show that while Boltzina performs below Boltz-2, it provides significantly higher screening performance compared to AutoDock Vina and GNINA. Additionally, Boltzina achieved up to 11.8$\times$ faster through reduced recycling iterations and batch processing. Furthermore, we investigated multi-pose selection strategies and two-stage screening combining Boltzina and Boltz-2, presenting optimization methods for accuracy and efficiency according to application requirements. This study represents the first attempt to apply Boltz-2's high-accuracy predictions to practical-scale screening, offering a pipeline that combines both accuracy and efficiency in computational biology. The Boltzina is available on github; https://github.com/ohuelab/boltzina.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17555v1</guid>
      <category>q-bio.BM</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kairi Furui, Masahito Ohue</dc:creator>
    </item>
    <item>
      <title>MetaGen: A DSL, Database, and Benchmark for VLM-Assisted Metamaterial Generation</title>
      <link>https://arxiv.org/abs/2508.17568</link>
      <description>arXiv:2508.17568v1 Announce Type: cross 
Abstract: Metamaterials are micro-architected structures whose geometry imparts highly tunable-often counter-intuitive-bulk properties. Yet their design is difficult because of geometric complexity and a non-trivial mapping from architecture to behaviour. We address these challenges with three complementary contributions. (i) MetaDSL: a compact, semantically rich domain-specific language that captures diverse metamaterial designs in a form that is both human-readable and machine-parsable. (ii) MetaDB: a curated repository of more than 150,000 parameterized MetaDSL programs together with their derivatives-three-dimensional geometry, multi-view renderings, and simulated elastic properties. (iii) MetaBench: benchmark suites that test three core capabilities of vision-language metamaterial assistants-structure reconstruction, property-driven inverse design, and performance prediction. We establish baselines by fine-tuning state-of-the-art vision-language models and deploy an omni-model within an interactive, CAD-like interface. Case studies show that our framework provides a strong first step toward integrated design and understanding of structure-representation-property relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17568v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liane Makatura, Benjamin Jones, Siyuan Bian, Wojciech Matusik</dc:creator>
    </item>
    <item>
      <title>Spectral-Prior Guided Multistage Physics-Informed Neural Networks for Highly Accurate PDE Solutions</title>
      <link>https://arxiv.org/abs/2508.17902</link>
      <description>arXiv:2508.17902v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) are becoming a popular method for solving PDEs, due to their mesh-free nature and their ability to handle high-dimensional problems where traditional numerical solvers often struggle. Despite their promise, the practical application of PINNs is still constrained by several fac- tors, a primary one being their often-limited accuracy. This paper is dedicated to enhancing the accuracy of PINNs by introducing spectral-prior guided multistage strategy. We propose two methods: Spectrum- Informed Multistage Physics-Informed Neural Networks (SI-MSPINNs) and Multistage Physics-Informed Neural Networks with Spectrum Weighted Random Fourier Features (RFF-MSPINNs). The SI-MSPINNs integrate the core mechanism of Spectrum-Informed Multistage Neural Network (SI-MSNNs) and PINNs, in which we extract the Dominant Spectral Pattern (DSP) of residuals by the discrete Fourier transform. This DSP guides the network initialization to alleviate spectral bias, and gradually optimizes the resolution accuracy using a multistage strategy. The RFF-MSPINNs combines random Fourier features with spectral weighting methods, dynamically adjusting the frequency sampling distribution based on the residual power spectral density, allowing the network to prioritize learning high-energy physical modes. Through experimental verification of the Burgers equation and the Helmholtz equation, we show that both models significantly improve the accuracy of the original PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17902v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzhen Li, Liang Li, St\'ephane Lanteri, Bin Li</dc:creator>
    </item>
    <item>
      <title>From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models</title>
      <link>https://arxiv.org/abs/2508.13491</link>
      <description>arXiv:2508.13491v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown promise for financial applications, yet their suitability for this high-stakes domain remains largely unproven due to inadequacies in existing benchmarks. Existing benchmarks solely rely on score-level evaluation, summarizing performance with a single score that obscures the nuanced understanding of what models truly know and their precise limitations. They also rely on datasets that cover only a narrow subset of financial concepts, while overlooking other essentials for real-world applications. To address these gaps, we introduce FinCDM, the first cognitive diagnosis evaluation framework tailored for financial LLMs, enabling the evaluation of LLMs at the knowledge-skill level, identifying what financial skills and knowledge they have or lack based on their response patterns across skill-tagged tasks, rather than a single aggregated number. We construct CPA-KQA, the first cognitively informed financial evaluation dataset derived from the Certified Public Accountant (CPA) examination, with comprehensive coverage of real-world accounting and financial skills. It is rigorously annotated by domain experts, who author, validate, and annotate questions with high inter-annotator agreement and fine-grained knowledge labels. Our extensive experiments on 30 proprietary, open-source, and domain-specific LLMs show that FinCDM reveals hidden knowledge gaps, identifies under-tested areas such as tax and regulatory reasoning overlooked by traditional benchmarks, and uncovers behavioral clusters among models. FinCDM introduces a new paradigm for financial LLM evaluation by enabling interpretable, skill-aware diagnosis that supports more trustworthy and targeted model development, and all datasets and evaluation scripts will be publicly released to support further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13491v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyan Kuang, Feiyu Zhu, Maowei Jiang, Yanzhao Lai, Zelin Wang, Zhitong Wang, Meikang Qiu, Jiajia Huang, Min Peng, Qianqian Xie, Sophia Ananiadou</dc:creator>
    </item>
    <item>
      <title>QUEENS: An Open-Source Python Framework for Solver-Independent Analyses of Large-Scale Computational Models</title>
      <link>https://arxiv.org/abs/2508.16316</link>
      <description>arXiv:2508.16316v2 Announce Type: replace 
Abstract: A growing challenge in research and industrial engineering applications is the need for repeated, systematic analysis of large-scale computational models, for example, patient-specific digital twins of diseased human organs: The analysis requires efficient implementation, data, resource management, and parallelization, possibly on distributed systems. To tackle these challenges and save many researchers from annoying, time-consuming tasks, we present QUEENS (Quantification of Uncertain Effects in Engineering Systems), an open-source Python framework for composing and managing simulation analyses with arbitrary (physics-based) solvers on distributed computing infrastructures. Besides simulation management capabilities, QUEENS offers a comprehensive collection of efficiently implemented state-of-the-art algorithms ranging from routines for convergence studies and common optimization algorithms to more advanced sampling algorithms for uncertainty quantification and Bayesian inverse analysis. Additionally, we provide our latest cutting-edge research in multi-fidelity uncertainty quantification, efficient multi-fidelity Bayesian inverse analysis, and probabilistic machine learning. QUEENS adopts a Bayesian, probabilistic mindset but equally supports standard deterministic analysis without requiring prior knowledge of probability theory. The modular architecture allows rapid switching between common types of analyses and facilitates building sophisticated hierarchical algorithms. Encouraging natural incremental steps and scaling towards complexity allows researchers to consider the big picture while building towards it through smaller, manageable steps. The open-source repository is available at https://github.com/queens-py/queens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16316v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Biehler, Jonas Nitzler, Sebastian Brandstaeter, Maximilian Dinkel, Volker Gravemeier, Lea J. Haeusel, Gil Robalo Rei, Harald Willmann, Barbara Wirthl, Wolfgang A. Wall</dc:creator>
    </item>
    <item>
      <title>Generative Machine Learning in Adaptive Control of Dynamic Manufacturing Processes: A Review</title>
      <link>https://arxiv.org/abs/2505.00210</link>
      <description>arXiv:2505.00210v2 Announce Type: replace-cross 
Abstract: Dynamic manufacturing processes exhibit complex characteristics defined by time-varying parameters, nonlinear behaviors, and uncertainties. These characteristics require sophisticated in-situ monitoring techniques utilizing multimodal sensor data and adaptive control systems that can respond to real-time feedback while maintaining product quality. Recently, generative machine learning (ML) has emerged as a powerful tool for modeling complex distributions and generating synthetic data while handling these manufacturing uncertainties. However, adopting these generative technologies in dynamic manufacturing systems lacks a functional control-oriented perspective to translate their probabilistic understanding into actionable process controls while respecting constraints. This review presents a functional classification of Prediction-Based, Direct Policy, Quality Inference, and Knowledge-Integrated approaches, offering a perspective for understanding existing ML-enhanced control systems and incorporating generative ML. The analysis of generative ML architectures within this framework demonstrates control-relevant properties and potential to extend current ML-enhanced approaches where conventional methods prove insufficient. We show generative ML's potential for manufacturing control through decision-making applications, process guidance, simulation, and digital twins, while identifying critical research gaps: separation between generation and control functions, insufficient physical understanding of manufacturing phenomena, and challenges adapting models from other domains. To address these challenges, we propose future research directions aimed at developing integrated frameworks that combine generative ML and control technologies to address the dynamic complexities of modern manufacturing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00210v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Suk Ki Lee, Hyunwoong Ko</dc:creator>
    </item>
    <item>
      <title>GUST: Quantifying Free-Form Geometric Uncertainty of Metamaterials Using Small Data</title>
      <link>https://arxiv.org/abs/2506.12051</link>
      <description>arXiv:2506.12051v2 Announce Type: replace-cross 
Abstract: This paper introduces GUST (Generative Uncertainty learning via Self-supervised pretraining and Transfer learning), a framework for quantifying free-form geometric uncertainties inherent in the manufacturing of metamaterials. GUST leverages the representational power of deep generative models to learn a high-dimensional conditional distribution of as-fabricated unit cell geometries given nominal designs, thereby enabling uncertainty quantification. To address the scarcity of real-world manufacturing data, GUST employs a two-stage learning process. First, it leverages self-supervised pretraining on a large-scale synthetic dataset to capture the structure variability inherent in metamaterial geometries and an approximated distribution of as-fabricated geometries given nominal designs. Subsequently, GUST employs transfer learning by fine-tuning the pretrained model on limited real-world manufacturing data, allowing it to adapt to specific manufacturing processes and nominal designs. With only 960 unit cells additively manufactured in only two passes, GUST can capture the variability in geometry and effective material properties. In contrast, directly training a generative model on the same amount of real-world data proves insufficient, as demonstrated through both qualitative and quantitative comparisons. This scalable and cost-effective approach significantly reduces data requirements while maintaining the effectiveness in learning complex, real-world geometric uncertainties, offering an affordable method for free-form geometric uncertainty quantification in the manufacturing of metamaterials. The capabilities of GUST hold significant promise for high-precision industries such as aerospace and biomedical engineering, where understanding and mitigating manufacturing uncertainties are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12051v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiahui Zheng, Cole Jahnke, Wei "Wayne" Chen</dc:creator>
    </item>
  </channel>
</rss>
