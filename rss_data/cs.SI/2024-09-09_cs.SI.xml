<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Sep 2024 02:49:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Survey on Signed Graph Embedding: Methods and Applications</title>
      <link>https://arxiv.org/abs/2409.03916</link>
      <description>arXiv:2409.03916v1 Announce Type: new 
Abstract: A signed graph (SG) is a graph where edges carry sign information attached to it. The sign of a network can be positive, negative, or neutral. A signed network is ubiquitous in a real-world network like social networks, citation networks, and various technical networks. There are many network embedding models have been proposed and developed for signed networks for both homogeneous and heterogeneous types. SG embedding learns low-dimensional vector representations for nodes of a network, which helps to do many network analysis tasks such as link prediction, node classification, and community detection. In this survey, we perform a comprehensive study of SG embedding methods and applications. We introduce here the basic theories and methods of SGs and survey the current state of the art of signed graph embedding methods. In addition, we explore the applications of different types of SG embedding methods in real-world scenarios. As an application, we have explored the citation network to analyze authorship networks. We also provide source code and datasets to give future direction. Lastly, we explore the challenges of SG embedding and forecast various future research directions in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03916v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shrabani Ghosh</dc:creator>
    </item>
    <item>
      <title>The Veracity Problem: Detecting False Information and its Propagation on Online Social Media Networks</title>
      <link>https://arxiv.org/abs/2409.03948</link>
      <description>arXiv:2409.03948v1 Announce Type: new 
Abstract: Detecting false information on social media is critical in mitigating its negative societal impacts. To reduce the propagation of false information, automated detection provide scalable, unbiased, and cost-effective methods. However, there are three potential research areas identified which once solved improve detection. First, current AI-based solutions often provide a uni-dimensional analysis on a complex, multi-dimensional issue, with solutions differing based on the features used. Furthermore, these methods do not account for the temporal and dynamic changes observed within the document's life cycle. Second, there has been little research on the detection of coordinated information campaigns and in understanding the intent of the actors and the campaign. Thirdly, there is a lack of consideration of cross-platform analysis, with existing datasets focusing on a single platform, such as X, and detection models designed for specific platform.
  This work aims to develop methods for effective detection of false information and its propagation. To this end, firstly we aim to propose the creation of an ensemble multi-faceted framework that leverages multiple aspects of false information. Secondly, we propose a method to identify actors and their intent when working in coordination to manipulate a narrative. Thirdly, we aim to analyse the impact of cross-platform interactions on the propagation of false information via the creation of a new dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03948v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3627673.3680265</arxiv:DOI>
      <dc:creator>Sarah Condran</dc:creator>
    </item>
    <item>
      <title>Understanding Online Discussion Across Difference: Insights from Gun Discourse on Reddit</title>
      <link>https://arxiv.org/abs/2409.03989</link>
      <description>arXiv:2409.03989v1 Announce Type: new 
Abstract: When discussing difficult topics online, is it common to meaningfully engage with people from diverse perspectives? Why or why not? Could features of the online environment be redesigned to encourage civil conversation across difference? In this paper, we study discussions of gun policy on Reddit, with the overarching goal of developing insights into the potential of the internet to support understanding across difference. We use two methods: a clustering analysis of Reddit posts to contribute insights about what people discuss, and an interview study of twenty Reddit users to help us understand why certain kinds of conversation take place and others don't. We find that the discussion of gun politics falls into three groups: conservative pro-gun, liberal pro-gun, and liberal anti-gun. Each type of group has its own characteristic topics. While our subjects state that they would be willing to engage with others across the ideological divide, in practice they rarely do. Subjects are siloed into like-minded subreddits through a two-pronged effect, where they are simultaneously pushed away from opposing-view communities while actively seeking belonging in like-minded ones. Another contributing factor is Reddit's "karma" mechanism: fear of being downvoted and losing karma points and social approval of peers causes our subjects to hesitate to say anything in conflict with group norms. The pseudonymous nature of discussion on Reddit plays a complex role, with some subjects finding it freeing and others fearing reprisal from others not bound by face-to-face norms of politeness. Our subjects believe that content moderation can help ameliorate these issues; however, our findings suggest that moderators need different tools to do so effectively. We conclude by suggesting platform design changes that might increase discussion across difference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03989v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rijul Magu, Nivedhitha Mathan Kumar, Yihe Liu, Xander Koo, Diyi Yang, Amy Bruckman</dc:creator>
    </item>
    <item>
      <title>Structure and dynamics of growing networks of Reddit threads</title>
      <link>https://arxiv.org/abs/2409.04085</link>
      <description>arXiv:2409.04085v1 Announce Type: new 
Abstract: Millions of people use online social networks to reinforce their sense of belonging, for example by giving and asking for feedback as a form of social validation and self-recognition. It is common to observe disagreement among people beliefs and points of view when expressing this feedback. Modeling and analyzing such interactions is crucial to understand social phenomena that happen when people face different opinions while expressing and discussing their values. In this work, we study a Reddit community in which people participate to judge or be judged with respect to some behavior, as it represents a valuable source to study how users express judgments online. We model threads of this community as complex networks of user interactions growing in time, and we analyze the evolution of their structural properties. We show that the evolution of Reddit networks differ from other real social networks, despite falling in the same category. This happens because their global clustering coefficient is extremely small and the average shortest path length increases over time. Such properties reveal how users discuss in threads, i.e. with mostly one other user and often by a single message. We strengthen such result by analyzing the role that disagreement and reciprocity play in such conversations. We also show that Reddit thread's evolution over time is governed by two subgraphs growing at different speeds. We discover that, in the studied community, the difference of such speed is higher than in other communities because of the user guidelines enforcing specific user interactions. Finally, we interpret the obtained results on user behavior drawing back to Social Judgment Theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04085v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s41109-024-00654-y</arxiv:DOI>
      <arxiv:journal_reference>Applied Network Science volume 9, Article number: 48 (2024)</arxiv:journal_reference>
      <dc:creator>Diletta Goglia, Davide Vega</dc:creator>
    </item>
    <item>
      <title>Fairness and Consensus in an Asynchronous Opinion Model for Social Networks (Technical Report)</title>
      <link>https://arxiv.org/abs/2312.12251</link>
      <description>arXiv:2312.12251v3 Announce Type: replace 
Abstract: We introduce a DeGroot-based model for opinion dynamics in social networks. A community of agents is represented as a weighted directed graph whose edges indicate how much agents influence one another. The model is formalized using labeled transition systems, henceforth called opinion transition systems (OTS), whose states represent the agents' opinions and whose actions are the edges of the influence graph. If a transition labeled $(i,j)$ is performed, agent $j$ updates their opinion taking into account the opinion of agent $i$ and the influence $i$ has over $j$. We study (convergence to) opinion consensus among the agents of strongly-connected graphs with influence values in the interval $(0,1)$. We show that consensus cannot be guaranteed under the standard strong fairness assumption on transition systems. We derive that consensus is guaranteed under a stronger notion from the literature of concurrent systems; bounded fairness. We argue that bounded-fairness is too strong of a notion for consensus as it almost surely rules out random runs and it is not a constructive liveness property. We introduce a weaker fairness notion, called $m$-bounded fairness, and show that it guarantees consensus. The new notion includes almost surely all random runs and it is a constructive liveness property. Finally, we consider OTS with dynamic influence and show convergence to consensus holds under $m$-bounded fairness if the influence changes within a fixed interval $[L,U]$ with $0&lt;L&lt;U&lt;1$. We illustrate OTS with examples and simulations, offering insights into opinion formation under fairness and dynamic influence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12251v3</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jes\'us Aranda, Sebasti\'an Betancourt, Juan Fco. D\'iaz, Frank Valencia</dc:creator>
    </item>
    <item>
      <title>Dynamic random graphs with vertex removal</title>
      <link>https://arxiv.org/abs/2207.05046</link>
      <description>arXiv:2207.05046v2 Announce Type: replace-cross 
Abstract: We introduce and analyse a Dynamic Random Graph with Vertex Removal (DRGVR) defined as follows. At every step, with probability $p &gt; 1/2$ a new vertex is introduced, and with probability $1-p$ a vertex, chosen uniformly at random among the present ones (if any), is removed from the graph together with all edges adjacent to it. In the former case, the new vertex connects by an edge to every other vertex with probability inversely proportional to the number of vertices already present.
  We prove that the DRGVR converges to a local limit and determine this limit. Moreover, we analyse its component structure and distinguish a subcritical and a supercritical regime with respect to the existence of a giant component. As a byproduct of this analysis, we obtain upper and lower bounds for the critical parameter. Furthermore, we provide precise expression of the maximum degree (as well as in- and out-degree for a natural orientation of the DRGVR). Several concentration and stability results complete the study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.05046v2</guid>
      <category>math.PR</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josep D\'iaz, Lyuben Lichev, Bas Lodewijks</dc:creator>
    </item>
    <item>
      <title>inGRASS: Incremental Graph Spectral Sparsification via Low-Resistance-Diameter Decomposition</title>
      <link>https://arxiv.org/abs/2402.16990</link>
      <description>arXiv:2402.16990v2 Announce Type: replace-cross 
Abstract: This work presents inGRASS, a novel algorithm designed for incremental spectral sparsification of large undirected graphs. The proposed inGRASS algorithm is highly scalable and parallel-friendly, having a nearly-linear time complexity for the setup phase and the ability to update the spectral sparsifier in $O(\log N)$ time for each incremental change made to the original graph with $N$ nodes. A key component in the setup phase of inGRASS is a multilevel resistance embedding framework introduced for efficiently identifying spectrally-critical edges and effectively detecting redundant ones, which is achieved by decomposing the initial sparsifier into many node clusters with bounded effective-resistance diameters leveraging a low-resistance-diameter decomposition (LRD) scheme. The update phase of inGRASS exploits low-dimensional node embedding vectors for efficiently estimating the importance and uniqueness of each newly added edge. As demonstrated through extensive experiments, inGRASS achieves up to over $200 \times$ speedups while retaining comparable solution quality in incremental spectral sparsification of graphs obtained from various datasets, such as circuit simulations, finite element analysis, and social networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16990v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ali Aghdaei, Zhuo Feng</dc:creator>
    </item>
    <item>
      <title>UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images</title>
      <link>https://arxiv.org/abs/2405.03486</link>
      <description>arXiv:2405.03486v2 Announce Type: replace-cross 
Abstract: With the advent of text-to-image models and concerns about their misuse, developers are increasingly relying on image safety classifiers to moderate their generated unsafe images. Yet, the performance of current image safety classifiers remains unknown for both real-world and AI-generated images. In this work, we propose UnsafeBench, a benchmarking framework that evaluates the effectiveness and robustness of image safety classifiers, with a particular focus on the impact of AI-generated images on their performance. First, we curate a large dataset of 10K real-world and AI-generated images that are annotated as safe or unsafe based on a set of 11 unsafe categories of images (sexual, violent, hateful, etc.). Then, we evaluate the effectiveness and robustness of five popular image safety classifiers, as well as three classifiers that are powered by general-purpose visual language models. Our assessment indicates that existing image safety classifiers are not comprehensive and effective enough to mitigate the multifaceted problem of unsafe images. Also, there exists a distribution shift between real-world and AI-generated images in image qualities, styles, and layouts, leading to degraded effectiveness and robustness. Motivated by these findings, we build a comprehensive image moderation tool called PerspectiveVision, which addresses the main drawbacks of existing classifiers with improved effectiveness and robustness, especially on AI-generated images. UnsafeBench and PerspectiveVision can aid the research community in better understanding the landscape of image safety classification in the era of generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03486v2</guid>
      <category>cs.CR</category>
      <category>cs.CV</category>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiting Qu, Xinyue Shen, Yixin Wu, Michael Backes, Savvas Zannettou, Yang Zhang</dc:creator>
    </item>
  </channel>
</rss>
