<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 01:25:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Turnpike properties in linear quadratic Gaussian N-player differential games</title>
      <link>https://arxiv.org/abs/2507.11632</link>
      <description>arXiv:2507.11632v1 Announce Type: new 
Abstract: We consider the long-time behavior of equilibrium strategies and state trajectories in a linear quadratic $N$-player game with Gaussian initial data. By analyzing convergence toward the corresponding ergodic game, we establish exponential convergence estimates between the solutions of the finite-horizon Riccati system and the associated algebraic Riccati system arising in the ergodic setting. Building on these results, we prove the convergence of the time-averaged value function and derive a turnpike property for the equilibrium pairs of each player. Importantly, our approach avoids reliance on the mean field game limiting model, allowing for a fully uniform analysis with respect to the number of players $N$. As a result, we further establish a uniform turnpike property for the equilibrium pairs between the finite-horizon and ergodic games with $N$ players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11632v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asaf Cohen, Jiamin Jian</dc:creator>
    </item>
    <item>
      <title>Fast Distributed Nash Equilibrium Seeking in Monotone Games</title>
      <link>https://arxiv.org/abs/2507.11703</link>
      <description>arXiv:2507.11703v1 Announce Type: new 
Abstract: This work proposes a novel distributed approach for computing a Nash equilibrium in convex games with merely monotone and restricted strongly monotone pseudo-gradients. By leveraging the idea of the centralized operator extrapolation method presented in [5] to solve variational inequalities, we develop the algorithm converging to Nash equilibria in games, where players have no access to the full information but are able to communicate with neighbors over some communication graph. The convergence rate is demonstrated to be geometric and improves the rates obtained by the previously presented procedures seeking Nash equilibria in the class of games under consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11703v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatiana Tatarenko, Angelia Nedich</dc:creator>
    </item>
    <item>
      <title>An augmented Lagrangian method for strongly regular minimizers in a class of convex composite optimization problems</title>
      <link>https://arxiv.org/abs/2507.12040</link>
      <description>arXiv:2507.12040v1 Announce Type: new 
Abstract: In this paper, we study a class of convex composite optimization problems. We begin by characterizing the equivalence between the primal/dual strong second-order sufficient condition and the dual/primal nondegeneracy condition. Building on this foundation, we derive a specific set of equivalent conditions for the perturbation analysis of the problem. Furthermore, we employ the augmented Lagrangian method (ALM) to solve the problem and provide theoretical guarantees for its performance. Specifically, we establish the equivalence between the primal/dual second-order sufficient condition and the dual/primal strict Robinson constraint qualification, as well as the equivalence between the dual nondegeneracy condition and the nonsingularity of Clarke's generalized Jacobian for the ALM subproblem. These theoretical results form a solid foundation for designing efficient algorithms. Finally, we apply the ALM to the von Neumann entropy optimization problem and present numerical experiments to demonstrate the algorithm's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12040v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chengjing Wang, Peipei Tang</dc:creator>
    </item>
    <item>
      <title>Improved Analysis for Sign-based Methods with Momentum Updates</title>
      <link>https://arxiv.org/abs/2507.12091</link>
      <description>arXiv:2507.12091v1 Announce Type: new 
Abstract: In this paper, we present enhanced analysis for sign-based optimization algorithms with momentum updates. Traditional sign-based methods, under the separable smoothness assumption, guarantee a convergence rate of $\mathcal{O}(T^{-1/4})$, but they either require large batch sizes or assume unimodal symmetric stochastic noise. To address these limitations, we demonstrate that signSGD with momentum can achieve the same convergence rate using constant batch sizes without additional assumptions. Our analysis, under the standard $l_2$-smoothness condition, improves upon the result of the prior momentum-based signSGD method by a factor of $\mathcal{O}(d^{1/2})$, where $d$ is the problem dimension. Furthermore, we explore sign-based methods with majority vote in distributed settings and show that the proposed momentum-based method yields convergence rates of $\mathcal{O}\left( d^{1/2}T^{-1/2} + dn^{-1/2} \right)$ and $\mathcal{O}\left( \max \{ d^{1/4}T^{-1/4}, d^{1/10}T^{-1/5} \} \right)$, which outperform the previous results of $\mathcal{O}\left( dT^{-1/4} + dn^{-1/2} \right)$ and $\mathcal{O}\left( d^{3/8}T^{-1/8} \right)$, respectively. Numerical experiments further validate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12091v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Dingzhi Yu, Sifan Yang, Wenhao Yang, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence Rate of Generalized Nash Equilibrium Learning in Strongly Monotone Games with Linear Constraints</title>
      <link>https://arxiv.org/abs/2507.12112</link>
      <description>arXiv:2507.12112v1 Announce Type: new 
Abstract: We consider payoff-based learning of a generalized Nash equilibrium (GNE) in multi-agent systems. Our focus is on games with jointly convex constraints of a linear structure and strongly monotone pseudo-gradients. We present a convergent procedure based on a partial regularization technique and establish the convergence rate of its iterates under one- and two-point payoff-based feedback. To the best of our knowledge, this work is the first one characterizing the convergence speed of iterates to a variational GNE in the class of games under consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12112v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatiana Tatarenko, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Optimized Qubit Routing for Commuting Gates via Integer Programming</title>
      <link>https://arxiv.org/abs/2507.12199</link>
      <description>arXiv:2507.12199v1 Announce Type: new 
Abstract: Quantum computers promise to outperform their classical counterparts at certain tasks. However, existing quantum devices are error-prone and restricted in size. Thus, effective compilation methods are crucial to exploit limited quantum resources. In this work, we address the problem of qubit routing for commuting gates, which arises, for example, during the compilation of the well-known Quantum Approximate Optimization Algorithm. We propose a two-step decomposition approach based on integer programming, which is guaranteed to return an optimal solution. To justify the use of integer programming, we prove NP-hardness of the underlying optimization problem. Furthermore, we derive asymptotic upper and lower bounds on the quality of a solution. We develop several integer programming models and derive linear descriptions of related polytopes, which generalize to applications beyond this work. Finally, we conduct a computational study showing that our approach outperforms existing heuristics in terms of quality and exact methods in terms of runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12199v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moritz Stargalla, Friedrich Wagner</dc:creator>
    </item>
    <item>
      <title>Designing Algorithms for Entropic Optimal Transport from an Optimisation Perspective</title>
      <link>https://arxiv.org/abs/2507.12246</link>
      <description>arXiv:2507.12246v1 Announce Type: new 
Abstract: In this work, we develop a collection of novel methods for the entropic-regularised optimal transport problem, which are inspired by existing mirror descent interpretations of the Sinkhorn algorithm used for solving this problem. These are fundamentally proposed from an optimisation perspective: either based on the associated semi-dual problem, or based on solving a non-convex constrained problem over subset of joint distributions. This optimisation viewpoint results in non-asymptotic rates of convergence for the proposed methods under minimal assumptions on the problem structure. We also propose a momentum-equipped method with provable accelerated guarantees through this viewpoint, akin to those in the Euclidean setting. The broader framework we develop based on optimisation over the joint distributions also finds an analogue in the dynamical Schr\"{o}dinger bridge problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12246v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishwak Srinivasan, Qijia Jiang</dc:creator>
    </item>
    <item>
      <title>Convergence of drift-diffusion PDEs arising as Wasserstein gradient flows of convex functions</title>
      <link>https://arxiv.org/abs/2507.12385</link>
      <description>arXiv:2507.12385v1 Announce Type: new 
Abstract: We study the quantitative convergence of drift-diffusion PDEs that arise as Wasserstein gradient flows of linearly convex functions over the space of probability measures on ${\mathbb R}^d$. In this setting, the objective is in general not displacement convex, so it is not clear a priori whether global convergence even holds. Still, our analysis reveals that diffusion {allows} a favorable interaction between Wasserstein geometry and linear convexity, leading to a general quantitative convergence theory, analogous to that of gradient flows in convex settings in the Euclidean space.
  Specifically, we prove that if the objective is convex and suitably coercive, the suboptimality gap decreases at a rate $O(1/t)$. This improves to a rate faster than any polynomial -- or even exponential in compact settings -- when the objective is strongly convex relative to the entropy.
  Our results extend the range of mean-field Langevin dynamics that enjoy quantitative convergence guarantees, and enable new applications to optimization over the space of probability measures. To illustrate this, we show quantitative convergence results for the minimization of entropy-regularized nonconvex problems, we propose and study an \emph{approximate Fisher Information} regularization covered by our setting, and we apply our results to an estimator for trajectory inference which involves the minimization of the relative entropy with respect to the Wiener measure in path space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12385v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'ena\"ic Chizat, Maria Colombo, Xavier Fern\'andez-Real</dc:creator>
    </item>
    <item>
      <title>Linearization-Based Feedback Stabilization of McKean-Vlasov PDEs</title>
      <link>https://arxiv.org/abs/2507.12411</link>
      <description>arXiv:2507.12411v1 Announce Type: new 
Abstract: We study the feedback stabilization of the McKean-Vlasov PDE on the torus. Our goal is to steer the dynamics toward a prescribed stationary distribution or accelerate convergence to it using a time-dependent control potential. We reformulate the controlled PDE in a weighted-projected space and apply the ground-state transform to obtain a Schrodinger-type operator. The resulting operator framework enables spectral analysis, verification of the infinite-dimensional Hautus test, and the construction of Riccati-based feedback laws. We rigorously prove local exponential stabilization via maximal regularity arguments and nonlinear estimates. Numerical experiments on well-studied models (the noisy Kuramoto model for synchronization, the O(2) spin model in a magnetic field, and the Gaussian/von Mises attractive interaction potential) showcase the effectiveness of our control strategy, demonstrating convergence speed-ups and stabilization of otherwise unstable equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12411v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Kalise, Lucas M. Moschen, Grigorios A. Pavliotis</dc:creator>
    </item>
    <item>
      <title>Quasi-difference-convexity: Modernization of Quasi-differentiable Optimization</title>
      <link>https://arxiv.org/abs/2507.12413</link>
      <description>arXiv:2507.12413v1 Announce Type: new 
Abstract: Quasi-differentiable functions were introduced by Pshenichnyi in a 1969 monograph written in Russian and translated in an English version in 1971. This class of nonsmooth functions was studied extensively in two decades since but has not received much attention in today's wide optimization literature. This regrettable omission is in spite of the fact that many functions in modern day applications of optimization can be shown to be quasi-differentiable. In essence, a quasi-differentiable function is one whose directional derivative at an arbitrary reference vector, as a function of the direction, is the difference of two positively homogenous, convex functions. Thus, to bring quasi-differentiable functions closer to the class of difference-of-convex functions that has received fast growing attention in recent years in connection with many applied subjects, we propose to rename quasi-differentiable functions as quasi-difference-convex (quasi-dc) functions. Besides modernizing and advancing this class of nonconvex and nondifferentiable functions, our research aims to put together a unified treatment of iterative convex-programming based descent algorithms for solving a broad class of composite quasi-dc programs and to establish their subsequential convergence, sequential convergence, and rates of convergence; the latter two topics are in line with the modern focus of such analysis for convex programs and some extensions and are departures from the sole emphasis of subsequential convergence in the traditional studies of quasi-differentiable optimization. Through this research, we have gained significant new insights and understanding, advanced the fundamentals, and broadened the applications of this neglected yet pervasive class of nonconvex and nondifferentiable functions and their optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12413v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jong-Shi Pang, Yulin Peng</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Conditional Group Distributionally Robust Optimization with Cross-Entropy Loss</title>
      <link>https://arxiv.org/abs/2507.09905</link>
      <description>arXiv:2507.09905v1 Announce Type: cross 
Abstract: In multi-source learning with discrete labels, distributional heterogeneity across domains poses a central challenge to developing predictive models that transfer reliably to unseen domains. We study multi-source unsupervised domain adaptation, where labeled data are drawn from multiple source domains and only unlabeled data from a target domain. To address potential distribution shifts, we propose a novel Conditional Group Distributionally Robust Optimization (CG-DRO) framework that learns a classifier by minimizing the worst-case cross-entropy loss over the convex combinations of the conditional outcome distributions from the sources. To solve the resulting minimax problem, we develop an efficient Mirror Prox algorithm, where we employ a double machine learning procedure to estimate the risk function. This ensures that the errors of the machine learning estimators for the nuisance models enter only at higher-order rates, thereby preserving statistical efficiency under covariate shift. We establish fast statistical convergence rates for the estimator by constructing two surrogate minimax optimization problems that serve as theoretical bridges. A distinguishing challenge for CG-DRO is the emergence of nonstandard asymptotics: the empirical estimator may fail to converge to a standard limiting distribution due to boundary effects and system instability. To address this, we introduce a perturbation-based inference procedure that enables uniformly valid inference, including confidence interval construction and hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09905v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian Guo, Zhenyu Wang, Yifan Hu, Francis Bach</dc:creator>
    </item>
    <item>
      <title>State-based approach to the numerical solution of Dirichlet boundary optimal control problems for the Laplace equation</title>
      <link>https://arxiv.org/abs/2507.11646</link>
      <description>arXiv:2507.11646v1 Announce Type: cross 
Abstract: We investigate the Dirichlet boundary control of the Laplace equation, considering the control in $H^{1/2}(\partial \Omega)$, which is the natural space for Dirichlet data when the state belongs to $H^1(\Omega)$. The cost of the control is measured in the $H^{1/2}(\partial \Omega)$ norm that also plays the role of the regularization term. We discuss regularization and finite element error estimates enabling us to derive an optimal relation between the finite element mesh size $h$ and the regularization parameter $\varrho$, balancing the energy cost for the control and the accuracy of the approximation of the desired state. This relationship is also crucial in designing efficient solvers. We also discuss additional box constraints imposed on the control and the state. Our theoretical findings are complemented by numerical examples, including one example with box constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11646v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulrich Langer, Richard L\"oscher, Olaf Steinbach, Huidong Yang</dc:creator>
    </item>
    <item>
      <title>Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure</title>
      <link>https://arxiv.org/abs/2507.11724</link>
      <description>arXiv:2507.11724v1 Announce Type: cross 
Abstract: We provide new high-accuracy randomized algorithms for solving linear systems and regression problems that are well-conditioned except for $k$ large singular values. For solving such $d \times d$ positive definite system our algorithms succeed whp. and run in time $\tilde O(d^2 + k^\omega)$. For solving such regression problems in a matrix $\mathbf{A} \in \mathbb{R}^{n \times d}$ our methods succeed whp. and run in time $\tilde O(\mathrm{nnz}(\mathbf{A}) + d^2 + k^\omega)$ where $\omega$ is the matrix multiplication exponent and $\mathrm{nnz}(\mathbf{A})$ is the number of non-zeros in $\mathbf{A}$. Our methods nearly-match a natural complexity limit under dense inputs for these problems and improve upon a trade-off in prior approaches that obtain running times of either $\tilde O(d^{2.065}+k^\omega)$ or $\tilde O(d^2 + dk^{\omega-1})$ for $d\times d$ systems. Moreover, we show how to obtain these running times even under the weaker assumption that all but $k$ of the singular values have a suitably bounded generalized mean. Consequently, we give the first nearly-linear time algorithm for computing a multiplicative approximation to the nuclear norm of an arbitrary dense matrix. Our algorithms are built on three general recursive preconditioning frameworks, where matrix sketching and low-rank update formulas are carefully tailored to the problems' structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11724v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models</title>
      <link>https://arxiv.org/abs/2507.12201</link>
      <description>arXiv:2507.12201v1 Announce Type: cross 
Abstract: Diffusion models have achieved state-of-the-art performance in generative modeling, yet their sampling procedures remain vulnerable to hallucinations, often stemming from inaccuracies in score approximation. In this work, we reinterpret diffusion sampling through the lens of optimization and introduce RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that detects and corrects high-risk sampling steps using geometric cues from the loss landscape. RODS enforces smoother sampling trajectories and adaptively adjusts perturbations, reducing hallucinations without retraining and at minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands demonstrate that RODS improves both sampling fidelity and robustness, detecting over 70% of hallucinated samples and correcting more than 25%, all while avoiding the introduction of new artifacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12201v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiqi Tian, Pengfei Jin, Mingze Yuan, Na Li, Bo Zeng, Quanzheng Li</dc:creator>
    </item>
    <item>
      <title>Geometry, Computation, and Optimality in Stochastic Optimization</title>
      <link>https://arxiv.org/abs/1909.10455</link>
      <description>arXiv:1909.10455v4 Announce Type: replace 
Abstract: We study computational and statistical consequences of problem geometry in stochastic and online optimization. By focusing on constraint set and gradient geometry, we characterize the problem families for which stochastic- and adaptive-gradient methods are (minimax) optimal and, conversely, when nonlinear updates -- such as those mirror descent employs -- are necessary for optimal convergence. When the constraint set is quadratically convex, diagonally pre-conditioned stochastic gradient methods are minimax optimal. We provide quantitative converses showing that the ``distance'' of the underlying constraints from quadratic convexity determines the sub-optimality of subgradient methods. These results apply, for example, to any $\ell_p$-ball for $p &lt; 2$, and the computation/accuracy tradeoffs they demonstrate exhibit a striking analogy to those in Gaussian sequence models.</description>
      <guid isPermaLink="false">oai:arXiv.org:1909.10455v4</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Cheng, Daniel Levy, John C. Duchi</dc:creator>
    </item>
    <item>
      <title>Practical Experience with Stable Set and Coloring Relaxations</title>
      <link>https://arxiv.org/abs/2401.17069</link>
      <description>arXiv:2401.17069v3 Announce Type: replace 
Abstract: The stable set problem and the graph coloring problem are classes of NP-hard optimization problems on graphs. It is well known that even near-optimal solutions for these problems are difficult to find in polynomial time. The Lov\'asz theta function, introduced by Lov\'asz in the late 1970s, provides a powerful tool in the study of these problems. It can be expressed as the optimal value of a semidefinite program and serves as a relaxation for both problems. Over the years, considerable effort has been devoted to investigating additional cutting planes to strengthen these relaxations. In our work, we use these models and consider classes of cutting planes based on cliques, odd cycles, and odd antiholes contained in the underlying graph. We demonstrate that identifying such violated constraints can be done efficiently and that they often lead to significant improvements over previous bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17069v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dunja Pucher, Franz Rendl</dc:creator>
    </item>
    <item>
      <title>Duality theory in linear optimization and its extensions -- formally verified</title>
      <link>https://arxiv.org/abs/2409.08119</link>
      <description>arXiv:2409.08119v2 Announce Type: replace 
Abstract: Farkas established that a system of linear inequalities has a solution if and only if we cannot obtain a contradiction by taking a linear combination of the inequalities. We state and formally prove several Farkas-like theorems over linearly ordered fields in Lean 4. Furthermore, we extend duality theory to the case when some coefficients are allowed to take ``infinite values''.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08119v2</guid>
      <category>math.OC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Dvorak, Vladimir Kolmogorov</dc:creator>
    </item>
    <item>
      <title>Sparse Approximation in Lattices and Semigroups</title>
      <link>https://arxiv.org/abs/2410.23990</link>
      <description>arXiv:2410.23990v2 Announce Type: replace 
Abstract: This paper deals with the following question: Suppose that there exist an integer or a non-negative integer solution $x$ to a system $Ax = b$, where the number of non-zero components of $x$ is $n$. The target is, for a given natural number $k &lt; n$, to approximate $b$ with $Ay$ where $y$ is an integer or non-negative integer solution with at most $k$ non-zero components. We establish upper bounds for this question in general. In specific cases, these bounds are tight. If we view the approximation quality as a function of the parameter $k$, then the paper explains why the quality of the approximation increases exponentially as $k$ goes to $n$. This paper is a complete version of an extended abstract that appeared at the 26th International Conference on Integer Programming and Combinatorial Optimization (IPCO).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23990v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Kuhlmann, Timm Oertel, Robert Weismantel</dc:creator>
    </item>
    <item>
      <title>Problem-dependent convergence bounds for randomized linear gradient compression</title>
      <link>https://arxiv.org/abs/2411.12898</link>
      <description>arXiv:2411.12898v3 Announce Type: replace 
Abstract: In distributed optimization, the communication of model updates can be a performance bottleneck. Consequently, gradient compression has been proposed as a means of increasing optimization throughput. In general, due to information loss, compression introduces a penalty on the number of iterations needed to reach a solution. In this work, we investigate how the iteration penalty depends on the interaction between compression and problem structure, in the context of non-convex stochastic optimization. We focus on linear schemes, where compression and decompression can be modeled as multiplication with a random matrix. We consider several distributions of matrices, among them Haar-distributed orthogonal matrices and matrices with random Gaussian entries. We find that the impact of compression on convergence can be quantified in terms of a smoothness matrix associated with the objective function, using a norm defined by the compression scheme. The analysis reveals that in certain cases, compression performance is related to low-rank structure or other spectral properties of the problem and our bounds predict that the penalty introduced by compression is significantly reduced compared to worst-case bounds that only consider the compression level, ignoring problem data. We verify the theoretical findings experimentally, including fine-tuning an image classification model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12898v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Flynn, Patrick Johnstone, Shinjae Yoo</dc:creator>
    </item>
    <item>
      <title>Optimization via Strategic Law of Large Numbers</title>
      <link>https://arxiv.org/abs/2412.05604</link>
      <description>arXiv:2412.05604v2 Announce Type: replace 
Abstract: This paper proposes a unified framework for the global optimization of a continuous function in a bounded rectangular domain. Specifically, we show that: (1) under the optimal strategy for a two-armed decision model, the sample mean converges to a global optimizer under the Strategic Law of Large Numbers, and (2) a sign-based strategy built upon the solution of a parabolic PDE is asymptotically optimal. Motivated by this result, we propose a class of {\bf S}trategic {\bf M}onte {\bf C}arlo {\bf O}ptimization (SMCO) algorithms, which uses a simple strategy that makes coordinate-wise two-armed decisions based on the signs of the partial gradient of the original function being optimized over (without the need of solving PDEs). While this simple strategy is not generally optimal, we show that it is sufficient for our SMCO algorithm to converge to local optimizer(s) from a single starting point, and to global optimizers under a growing set of starting points. Numerical studies demonstrate the suitability of our SMCO algorithms for global optimization, and illustrate the promise of our theoretical framework and practical approach. For a wide range of test functions with challenging optimization landscapes (including ReLU neural networks with square and hinge loss), our SMCO algorithms converge to the global maximum accurately and robustly, using only a small set of starting points (at most 100 for dimensions up to 1000) and a small maximum number of iterations (200). In fact, our algorithms outperform many state-of-the-art global optimizers, as well as local algorithms augmented with the same set of starting points as ours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05604v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Zengjing Chen, Wayne Yuan Gao, Xiaodong Yan, Guodong Zhang</dc:creator>
    </item>
    <item>
      <title>MirrorCBO: A consensus-based optimization method in the spirit of mirror descent</title>
      <link>https://arxiv.org/abs/2501.12189</link>
      <description>arXiv:2501.12189v2 Announce Type: replace 
Abstract: In this work we propose MirrorCBO, a consensus-based optimization (CBO) method which generalizes standard CBO in the same way that mirror descent generalizes gradient descent. For this we apply the CBO methodology to a swarm of dual particles and retain the primal particle positions by applying the inverse of the mirror map, which we parametrize as the subdifferential of a strongly convex function $\phi$. In this way, we combine the advantages of a derivative-free non-convex optimization algorithm with those of mirror descent. As a special case, the method extends CBO to optimization problems with convex constraints. Assuming bounds on the Bregman distance associated to $\phi$, we provide asymptotic convergence results for MirrorCBO with explicit exponential rate. Another key contribution is an exploratory numerical study of this new algorithm across different application settings, focusing on (i) sparsity-inducing optimization, and (ii) constrained optimization, demonstrating the competitive performance of MirrorCBO. We observe empirically that the method can also be used for optimization on (non-convex) submanifolds of Euclidean space, can be adapted to mirrored versions of other recent CBO variants, and that it inherits from mirror descent the capability to select desirable minimizers, like sparse ones. We also include an overview of recent CBO approaches for constrained optimization and compare their performance to MirrorCBO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12189v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Bungert, Franca Hoffmann, Dohyeon Kim, Tim Roith</dc:creator>
    </item>
    <item>
      <title>Efficient Sparse Flow Decomposition Methods for RNA Multi-Assembly</title>
      <link>https://arxiv.org/abs/2501.14662</link>
      <description>arXiv:2501.14662v4 Announce Type: replace 
Abstract: Decomposing a flow on a Directed Acyclic Graph (DAG) into a weighted sum of a small number of paths is an essential task in operations research and bioinformatics. This problem, referred to as Sparse Flow Decomposition (SFD), has gained significant interest, in particular for its application in RNA transcript multi-assembly, the identification of the multiple transcripts corresponding to a given gene and their relative abundance. Several recent approaches cast SFD variants as integer optimization problems, motivated by the NP-hardness of the formulations they consider. We propose an alternative formulation of SFD as a data fitting problem on the conic hull of the flow polytope. By reformulating the problem on the flow polytope for compactness and solving it using specific variants of the Frank-Wolfe algorithm, we obtain a method converging rapidly to the minimizer of the chosen loss function while producing a parsimonious decomposition. Our approach subsumes previous formulations of SFD with exact and inexact flows and can model different priors on the error distributions. Computational experiments show that our method outperforms recent integer optimization approaches in runtime, but is also highly competitive in terms of reconstruction of the underlying transcripts, despite not explicitly minimizing the solution cardinality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14662v4</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Besan\c{c}on</dc:creator>
    </item>
    <item>
      <title>Moving-Boundary Port-Hamiltonian Systems</title>
      <link>https://arxiv.org/abs/2501.14930</link>
      <description>arXiv:2501.14930v2 Announce Type: replace 
Abstract: In this paper, we consider linear boundary port-Hamiltonian distributed parameter systems on a time-varying spatial domain. We derive the specific time-varying Dirac structure that these systems give rise to and use it to formally establish a new class of moving-boundary port-Hamiltonian systems by showing that these distributed parameter systems on a time-varying spatial domain admit a port-Hamiltonian representation. We demonstrate that our results can be leveraged to develop a spatial discretization scheme with dynamic meshing for approximating the telegrapher's equations on a time-varying spatial domain, which we subsequently verify numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14930v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. J. Meijer, A. Das, S. Weiland</dc:creator>
    </item>
    <item>
      <title>Breaking a Logarithmic Barrier in the Stopping Time Convergence Rate of Stochastic First-order Methods</title>
      <link>https://arxiv.org/abs/2506.23335</link>
      <description>arXiv:2506.23335v2 Announce Type: replace 
Abstract: This work provides a novel convergence analysis for stochastic optimization in terms of stopping times, addressing the practical reality that algorithms are often terminated adaptively based on observed progress. Unlike prior approaches, our analysis: 1. Directly characterizes convergence in terms of stopping times adapted to the underlying stochastic process. 2. Breaks a logarithmic barrier in existing results. Key to our results is the development of a lemma to control the large deviation property of almost super-martingales. This lemma might be of broader interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23335v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasong Feng, Yifan Jiang, Tianyu Wang, Zhiliang Ying</dc:creator>
    </item>
    <item>
      <title>Data-Driven Performance Guarantees for Parametric Optimization Problems</title>
      <link>https://arxiv.org/abs/2506.23819</link>
      <description>arXiv:2506.23819v2 Announce Type: replace 
Abstract: We propose a data-driven method to establish probabilistic performance guarantees for parametric optimization problems solved via iterative algorithms. Our approach addresses two key challenges: providing convergence guarantees to characterize the worst-case number of iterations required to achieve a predefined tolerance, and upper bounding a performance metric after a fixed number of iterations. These guarantees are particularly useful for online optimization problems with limited computational time, where existing performance guarantees are often unavailable or unduly conservative. We formulate the convergence analysis problem as a scenario optimization program based on a finite set of sampled parameter instances. Leveraging tools from scenario optimization theory enables us to derive probabilistic guarantees on the number of iterations needed to meet a given tolerance level. Using recent advancements in scenario optimization, we further introduce a relaxation approach to trade the number of iterations against the risk of violating convergence criteria thresholds. Additionally, we analyze the trade-off between solution accuracy and time efficiency for fixed-iteration optimization problems by casting them into scenario optimization programs. Numerical simulations demonstrate the efficacy of our approach in providing reliable probabilistic convergence guarantees and evaluating the trade-off between solution accuracy and computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23819v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jingyi Huang, Paul Goulart, Kostas Margellos</dc:creator>
    </item>
    <item>
      <title>GPU accelerated variant of Schroeppel-Shamir's algorithm for solving the market split problem</title>
      <link>https://arxiv.org/abs/2507.05045</link>
      <description>arXiv:2507.05045v2 Announce Type: replace 
Abstract: The market split problem (MSP), introduced by Cornuejols and Dawande (1998), is a challenging binary optimization problem that performs poorly on state-of-the-art linear programming-based branch-and-cut solvers. We present a novel algorithm for solving the feasibility version of this problem, derived from Schroeppel-Shamir's algorithm for the one-dimensional subset sum problem. Our approach is based on exhaustively enumerating one-dimensional solutions of MSP and utilizing GPUs to evaluate candidate solutions across the entire problem. The resulting hybrid CPU-GPU implementation efficiently solves instances with up to 10 constraints and 90 variables. We demonstrate the algorithm's performance on benchmark problems, solving instances of size (9, 80) in less than fifteen minutes and (10, 90) in up to one day.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05045v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils-Christian Kempke, Thorsten Koch</dc:creator>
    </item>
    <item>
      <title>Computer-aided analyses of stochastic first-order methods, via interpolation conditions for stochastic optimization</title>
      <link>https://arxiv.org/abs/2507.05466</link>
      <description>arXiv:2507.05466v4 Announce Type: replace 
Abstract: This work proposes a framework, embedded within the Performance Estimation framework (PEP), for obtaining worst-case performance guarantees on stochastic first-order methods. Given a first-order method, a function class, and a noise model with prescribed expectation and variance properties, we present a range of semidefinite programs (SDPs) of increasingly large size, whose solutions yield increasingly strong convergence guarantees on the problem. Eventually, we propose SDPs whose size depends on $2^N$, with $N$ the number of iterations analyzed, that yield tight guarantees, attained by specific functions and noise distributions within these classes. On the other side of the spectrum, we propose SDPs whose size depends linearly on $N$, and numerically show that, on many problems, they already provide tight guarantees.
  The framework accommodates a wide range of stochastic settings, with finite or infinite support, including the unstructured noise model with bounded variance, finite-sum optimization, and block-coordinate methods, in a unified manner, as guarantees apply to any setting consistent with the noise model, i.e., its expectation and variance. It covers both non-variance-reduced and variance-reduced methods. Using the framework, we analyze the stochastic gradient method under several noise models, and illustrate how the resulting numerical and analytical convergence rates connect with existing results. In particular, we provide improved convergence rates on the unstructured noise model with bounded variance and in the block-coordinate setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05466v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Rubbens, S\'ebastien Colla, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>Fast Accelerated Proximal Gradient Method with New Extrapolation Term for Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2507.06737</link>
      <description>arXiv:2507.06737v2 Announce Type: replace 
Abstract: In this paper, we propose a novel extrapolation coefficient scheme within the Nesterov framework and develop an accelerated proximal gradient algorithm. We establish that the algorithm achieves a sublinear convergence rate. The proposed scheme only requires the Lipschitz constant estimate sequence to satisfy mild initial conditions, under which a key equality property can be derived to support the convergence analysis. Numerical experiments are provided to demonstrate the effectiveness and practical performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06737v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengzhi Huang</dc:creator>
    </item>
    <item>
      <title>Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities</title>
      <link>https://arxiv.org/abs/2403.02004</link>
      <description>arXiv:2403.02004v3 Announce Type: replace-cross 
Abstract: We prove non-asymptotic error bounds for particle gradient descent (PGD, Kuntz et al., 2023), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that the flow converges exponentially fast to the free energy's minimizers for models satisfying a condition that generalizes both the log-Sobolev and the Polyak--{\L}ojasiewicz inequalities (LSI and P{\L}I, respectively). We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the P{\L}I implies the so-called quadratic growth condition), and applying the extension to our new setting. We also generalize the Bakry--\'Emery Theorem and show that the LSI/P{\L}I extension holds for models with strongly concave log-likelihoods. For such models, we further control PGD's discretization error and obtain the non-asymptotic error bounds. While we are motivated by the study of PGD, we believe that the inequalities and results we extend may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02004v3</guid>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research, 26(103):1-38, 2025</arxiv:journal_reference>
      <dc:creator>Rocco Caprio, Juan Kuntz, Samuel Power, Adam M. Johansen</dc:creator>
    </item>
    <item>
      <title>BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part I: PDE-Constrained Optimization</title>
      <link>https://arxiv.org/abs/2404.17789</link>
      <description>arXiv:2404.17789v5 Announce Type: replace-cross 
Abstract: We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We provide a theoretical analysis that justifies our approach. Through extensive experiments over multiple PDE systems, we demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to the soft PDE constraints in many existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17789v5</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ray Zirui Zhang, Christopher E. Miles, Xiaohui Xie, John S. Lowengrub</dc:creator>
    </item>
    <item>
      <title>Neural field equations with time-periodic external inputs and some applications to visual processing</title>
      <link>https://arxiv.org/abs/2407.17294</link>
      <description>arXiv:2407.17294v2 Announce Type: replace-cross 
Abstract: The aim of this work is to present a mathematical framework for the study of flickering inputs in visual processing tasks. When combined with geometric patterns, these inputs influence and induce interesting psychophysical phenomena, such as the MacKay and the Billock-Tsou effects, where the subjects perceive specific afterimages typically modulated by the flickering frequency. Due to the symmetry-breaking structure of the inputs, classical bifurcation theory and multi-scale analysis techniques are not very effective in our context. We thus take an approach based on the input-output framework of control theory for Amari-type neural fields. This allows us to prove that, when driven by periodic inputs, the dynamics converge to a periodic state. Moreover, we study under which assumptions these nonlinear dynamics can be effectively linearised, and in this case we present a precise approximation of the integral kernel for short-range excitatory and long-range inhibitory neuronal interactions. Finally, for inputs concentrated at the center of the visual field with a flickering background, we directly relate the width of the illusory contours appearing in the afterimage with both the flickering frequency and the strength of the inhibition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17294v2</guid>
      <category>q-bio.NC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Virginia Bolelli, Dario Prandi</dc:creator>
    </item>
    <item>
      <title>Functional Delsarte-Goethals-Seidel-Kabatianskii-Levenshtein-Pfender Bound</title>
      <link>https://arxiv.org/abs/2411.05047</link>
      <description>arXiv:2411.05047v2 Announce Type: replace-cross 
Abstract: Pfender \textit{[J. Combin. Theory Ser. A, 2007]} provided a one-line proof for a variant of the Delsarte-Goethals-Seidel-Kabatianskii-Levenshtein upper bound for spherical codes, which offers an upper bound for the celebrated (Newton-Gregory) kissing number problem. Motivated by this proof, we introduce the notion of codes in pointed metric spaces (in particular on Banach spaces) and derive a nonlinear (functional) Delsarte-Goethals-Seidel-Kabatianskii-Levenshtein-Pfender upper bound for spherical codes. We also introduce nonlinear (functional) Kissing Number Problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05047v2</guid>
      <category>math.FA</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. Mahesh Krishna</dc:creator>
    </item>
    <item>
      <title>MARS: Unleashing the Power of Variance Reduction for Training Large Models</title>
      <link>https://arxiv.org/abs/2411.10438</link>
      <description>arXiv:2411.10438v3 Announce Type: replace-cross 
Abstract: Training deep neural networks--and more recently, large models demands efficient and scalable optimizers. Adaptive gradient algorithms like Adam, AdamW, and their variants have been central to this task. Despite the development of numerous variance reduction algorithms in the past decade aimed at accelerating stochastic optimization in both convex and nonconvex settings, variance reduction has not found widespread success in training deep neural networks or large language models. Consequently, it has remained a less favored approach in modern AI. In this paper, to unleash the power of variance reduction for efficient training of large models, we propose a unified optimization framework, MARS (Make vAriance Reduction Shine), which reconciles preconditioned gradient methods with variance reduction via a scaled stochastic recursive momentum technique. Within our framework, we introduce three instances of MARS that leverage preconditioned gradient updates based on AdamW, Lion, and Shampoo, respectively. We also draw a connection between our algorithms and existing optimizers. Experimental results on training GPT-2 models indicate that MARS consistently outperforms AdamW by a large margin. The implementation of MARS is available at https://github.com/AGI-Arena/MARS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10438v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huizhuo Yuan, Yifeng Liu, Shuang Wu, Xun Zhou, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>The late-stage training dynamics of (stochastic) subgradient descent on homogeneous neural networks</title>
      <link>https://arxiv.org/abs/2502.05668</link>
      <description>arXiv:2502.05668v3 Announce Type: replace-cross 
Abstract: We analyze the implicit bias of constant step stochastic subgradient descent (SGD). We consider the setting of binary classification with homogeneous neural networks - a large class of deep neural networks with ReLU-type activation functions such as MLPs and CNNs without biases. We interpret the dynamics of normalized SGD iterates as an Euler-like discretization of a conservative field flow that is naturally associated to the normalized classification margin. Owing to this interpretation, we show that normalized SGD iterates converge to the set of critical points of the normalized margin at late-stage training (i.e., assuming that the data is correctly classified with positive normalized margin). Up to our knowledge, this is the first extension of the analysis of Lyu and Li (2020) on the discrete dynamics of gradient descent to the nonsmooth and stochastic setting. Our main result applies to binary classification with exponential or logistic losses. We additionally discuss extensions to more general settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05668v3</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sholom Schechtman, Nicolas Schreuder</dc:creator>
    </item>
    <item>
      <title>A Linearly Convergent Algorithm for Computing the Petz-Augustin Mean</title>
      <link>https://arxiv.org/abs/2502.06399</link>
      <description>arXiv:2502.06399v2 Announce Type: replace-cross 
Abstract: We study the computation of the Petz-Augustin mean of order $\alpha \in (0,1) \cup (1,\infty)$, defined as the minimizer of a weighted sum of $n$ Petz-R\'enyi divergences of order $\alpha$ over the set of $d$-by-$d$ quantum states, where the Petz-R\'enyi divergence is a quantum generalization of the classical R\'enyi divergence. We propose the first algorithm with a non-asymptotic convergence guarantee for solving this optimization problem. The iterates are guaranteed to converge to the Petz-Augustin mean at a linear rate of \( O\left( \lvert 1 - 1/\alpha \rvert^T \right) \) with respect to the Thompson metric for $\alpha\in(1/2,1)\cup(1,\infty)$, where \( T \) denotes the number of iterations. The algorithm has an initialization time complexity of $O\left(nd^3\right)$ and a per-iteration time complexity of $O\left(nd^2 + d^3\right)$.
  Two applications follow. First, we propose the first iterative method with a non-asymptotic convergence guarantee for computing the Petz capacity of order $\alpha\in(1/2,1)$, which generalizes the quantum channel capacity and characterizes the optimal error exponent in classical-quantum channel coding. Second, we establish that the Petz-Augustin mean of order $\alpha$, when all quantum states commute, is equivalent to the equilibrium prices in Fisher markets with constant elasticity of substitution (CES) utilities of common elasticity $\rho=1-1/\alpha$, and our proposed algorithm can be interpreted as a t\^{a}tonnement dynamic. We then extend the proposed algorithm to inhomogeneous Fisher markets, where buyers have different elasticities, and prove that it achieves a faster convergence rate compared to existing t\^{a}tonnement-type algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06399v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chun-Neng Chu, Wei-Fu Tseng, Yen-Huan Li</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Gradient Descent for Non-Homogeneous Deep Networks</title>
      <link>https://arxiv.org/abs/2502.16075</link>
      <description>arXiv:2502.16075v2 Announce Type: replace-cross 
Abstract: We establish the asymptotic implicit bias of gradient descent (GD) for generic non-homogeneous deep networks under exponential loss. Specifically, we characterize three key properties of GD iterates starting from a sufficiently small empirical risk, where the threshold is determined by a measure of the network's non-homogeneity. First, we show that a normalized margin induced by the GD iterates increases nearly monotonically. Second, we prove that while the norm of the GD iterates diverges to infinity, the iterates themselves converge in direction. Finally, we establish that this directional limit satisfies the Karush-Kuhn-Tucker (KKT) conditions of a margin maximization problem. Prior works on implicit bias have focused exclusively on homogeneous networks; in contrast, our results apply to a broad class of non-homogeneous networks satisfying a mild near-homogeneity condition. In particular, our results apply to networks with residual connections and non-homogeneous activation functions, thereby resolving an open problem posed by Ji and Telgarsky (2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16075v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>ICML 2025</arxiv:journal_reference>
      <dc:creator>Yuhang Cai, Kangjie Zhou, Jingfeng Wu, Song Mei, Michael Lindsey, Peter L. Bartlett</dc:creator>
    </item>
    <item>
      <title>Sharp Hybrid Zonotopes: Set Operations and the Reformulation-linearization Technique</title>
      <link>https://arxiv.org/abs/2503.17483</link>
      <description>arXiv:2503.17483v2 Announce Type: replace-cross 
Abstract: Mixed integer set representations, and specifically hybrid zonotopes, have enabled new techniques for reachability and verification of nonlinear and hybrid systems. Mixed-integer sets which have the property that their convex relaxation is equal to their convex hull are said to be sharp. This property allows the convex hull to be computed with minimal overhead, and is known to be important for improving the convergence rates of mixed-integer optimization algorithms that rely on convex relaxations. This paper examines methods for formulating sharp hybrid zonotopes and provides sharpness-preserving methods for performing several key set operations. The paper then shows how the reformulation-linearization technique can be applied to create a sharp realization of a hybrid zonotope that is initially not sharp. A numerical example applies this technique to find the convex hull of a level set of a feedforward ReLU neural network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17483v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3585953</arxiv:DOI>
      <dc:creator>Jonah J. Glunt, Joshua A. Robbins, Jacob A. Siefert, Daniel Silvestre, Herschel C. Pangborn</dc:creator>
    </item>
  </channel>
</rss>
