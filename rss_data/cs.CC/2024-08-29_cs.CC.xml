<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Aug 2024 01:35:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Approximability of Satisfiable k-CSPs: V</title>
      <link>https://arxiv.org/abs/2408.15377</link>
      <description>arXiv:2408.15377v1 Announce Type: new 
Abstract: We propose a framework of algorithm vs. hardness for all Max-CSPs and demonstrate it for a large class of predicates. This framework extends the work of Raghavendra [STOC, 2008], who showed a similar result for almost satisfiable Max-CSPs.
  Our framework is based on a new hybrid approximation algorithm, which uses a combination of the Gaussian elimination technique (i.e., solving a system of linear equations over an Abelian group) and the semidefinite programming relaxation. We complement our algorithm with a matching dictator vs. quasirandom test that has perfect completeness.
  The analysis of our dictator vs. quasirandom test is based on a novel invariance principle, which we call the mixed invariance principle. Our mixed invariance principle is an extension of the invariance principle of Mossel, O'Donnell and Oleszkiewicz [Annals of Mathematics, 2010] which plays a crucial role in Raghavendra's work. The mixed invariance principle allows one to relate 3-wise correlations over discrete probability spaces with expectations over spaces that are a mixture of Guassian spaces and Abelian groups, and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15377v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amey Bhangale, Subhash Khot, Dor Minzer</dc:creator>
    </item>
    <item>
      <title>Direct sum theorems beyond query complexity</title>
      <link>https://arxiv.org/abs/2408.15570</link>
      <description>arXiv:2408.15570v1 Announce Type: new 
Abstract: A fundamental question in computer science is: \emph{Is it harder to solve $n$ instances independently than to solve them simultaneously?} This question, known as the direct sum question or direct sum theorem, has been paid much attention in several research fields. Despite its importance, however, little has been discovered in many other research fields.
  In this paper, we introduce a novel framework that extends to classical/quantum query complexity, PAC-learning for machine learning, statistical estimation theory, and more. Within this framework, we establish several fundamental direct sum theorems. The main contributions of this paper include: (i) establishing a complete characterization of the amortized query/oracle complexities, and (ii) proving tight direct sum theorems when the error is small. Note that in our framework, every oracle access needs to be performed \emph{classically} even in the quantum setting. This can be thought of one limitation of this work.
  As a direct consequence of our results, we obtain the following: (A) The first known asymptotic separation of the randomized query complexity. Specifically, we show that there is a function $f: \{0, 1\}^k \to \{0, 1\}$ and small error $\varepsilon &gt; 0$ such that solving $n$ instances simultaneously requires the query complexity $\tilde{O}(n\sqrt{k})$ but solving one instance with the same error has the complexity $\tilde{\Omega}(k)$. In communication complexity this type of separation was previously given in~Feder, Kushilevitz, Naor and Nisan (1995). (B) The query complexity counterpart of the ``information = amortized communication" relation, one of the most influential results in communication complexity shown by Braverman and Rao (2011) and further investigated by Braverman (2015).
  We hope that our results will provide further interesting applications in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15570v1</guid>
      <category>cs.CC</category>
      <category>quant-ph</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daiki Suruga</dc:creator>
    </item>
    <item>
      <title>Partial and weighted matrix multiplication</title>
      <link>https://arxiv.org/abs/2408.15728</link>
      <description>arXiv:2408.15728v1 Announce Type: new 
Abstract: In a paper published in 1981, Sch\"onhage showed that large total matrix multiplications can be reduced to powers of partial matrix multiplication tensors, which correspond to the bilinear computation task of multiplying matrices with some of the entries fixed to be zero. It was left as an open problem to generalize the method to the case when the multiplication is also partial in the sense that only a subset of the entries need to be computed. We prove a variant of a more general case: reducing large weighted matrix multiplications to tensor powers of a partial matrix multiplication in the sense that every entry of the result is a partial version of the inner product of the corresponding row and column of the factors that would appear in the usual matrix product. The implication is that support rank upper bounds on partial matrix multiplication tensors in this general sense give upper bounds on the support rank exponent of matrix multiplication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15728v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P\'eter Vrana</dc:creator>
    </item>
  </channel>
</rss>
