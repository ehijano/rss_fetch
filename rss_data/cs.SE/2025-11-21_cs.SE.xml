<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 05:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Technique to Baseline QE Artefact Generation Aligned to Quality Metrics</title>
      <link>https://arxiv.org/abs/2511.15733</link>
      <description>arXiv:2511.15733v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15733v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eitan Farchi, Kiran Nayak, Papia Ghosh Majumdar, Saritha Route</dc:creator>
    </item>
    <item>
      <title>Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym</title>
      <link>https://arxiv.org/abs/2511.15757</link>
      <description>arXiv:2511.15757v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15757v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kareem Shehada, Yifan Wu, Wyatt D. Feng, Adithya Iyer, Gryphon Kumfert, Yangruibo Ding, Zhiyun Qian</dc:creator>
    </item>
    <item>
      <title>A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code</title>
      <link>https://arxiv.org/abs/2511.15817</link>
      <description>arXiv:2511.15817v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15817v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3744916.3773164</arxiv:DOI>
      <dc:creator>Alejandro Velasco, Daniel Rodriguez-Cardenas, Dipin Khati, David N. Palacio, Luftar Rahman Alif, Denys Poshyvanyk</dc:creator>
    </item>
    <item>
      <title>AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises</title>
      <link>https://arxiv.org/abs/2511.15852</link>
      <description>arXiv:2511.15852v1 Announce Type: new 
Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15852v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>https://www.ijcnis.org/index.php/ijcnis/article/view/8639,2025 , 11</arxiv:journal_reference>
      <dc:creator>Monu Sharma</dc:creator>
    </item>
    <item>
      <title>RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems</title>
      <link>https://arxiv.org/abs/2511.15859</link>
      <description>arXiv:2511.15859v1 Announce Type: new 
Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15859v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hina Saeeda, Mazen Mohamad, Eric Knauss, Jennifer Horkoff, Ali Nouri</dc:creator>
    </item>
    <item>
      <title>InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution</title>
      <link>https://arxiv.org/abs/2511.16004</link>
      <description>arXiv:2511.16004v1 Announce Type: new 
Abstract: Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16004v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>KeFan Li, Mengfei Wang, Hengzhi Zhang, Zhichao Li, Yuan Yuan, Mu Li, Xiang Gao, Hailong Sun, Chunming Hu, Weifeng Lv</dc:creator>
    </item>
    <item>
      <title>InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution</title>
      <link>https://arxiv.org/abs/2511.16005</link>
      <description>arXiv:2511.16005v1 Announce Type: new 
Abstract: Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16005v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingao Dong, Mengfei Wang, Hengzhi Zhang, Zhichao Li, Yuan Yuan, Mu Li, Xiang Gao, Hailong Sun, Chunming Hu, Weifeng Lv</dc:creator>
    </item>
    <item>
      <title>The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report</title>
      <link>https://arxiv.org/abs/2511.16092</link>
      <description>arXiv:2511.16092v1 Announce Type: new 
Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16092v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xing Hu, Raula Gaikovina Kula, Christoph Treude</dc:creator>
    </item>
    <item>
      <title>Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions</title>
      <link>https://arxiv.org/abs/2511.16123</link>
      <description>arXiv:2511.16123v1 Announce Type: new 
Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16123v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linyi Han, Shidong Pan, Zhenchang Xing, Sofonias Yitagesu, Xiaowang Zhang, Zhiyong Feng, Jiamou Sun, Qing Huang</dc:creator>
    </item>
    <item>
      <title>Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts</title>
      <link>https://arxiv.org/abs/2511.16224</link>
      <description>arXiv:2511.16224v1 Announce Type: new 
Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16224v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Salzano, Simone Scalabrino, Rocco Oliveto, Simone Scalabrino</dc:creator>
    </item>
    <item>
      <title>Data Annotation Quality Problems in AI-Enabled Perception System Development</title>
      <link>https://arxiv.org/abs/2511.16410</link>
      <description>arXiv:2511.16410v1 Announce Type: new 
Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16410v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hina Saeeda, Tommy Johansson, Mazen Mohamad, Eric Knauss</dc:creator>
    </item>
    <item>
      <title>Green Resilience of Cyber-Physical Systems: Doctoral Dissertation</title>
      <link>https://arxiv.org/abs/2511.16593</link>
      <description>arXiv:2511.16593v1 Announce Type: new 
Abstract: Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16593v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diaeddin Rimawi</dc:creator>
    </item>
    <item>
      <title>Mapping the Future of Human Digital Twin Adoption in Job-Shop Industries: A Strategic Prioritization Framework</title>
      <link>https://arxiv.org/abs/2511.15713</link>
      <description>arXiv:2511.15713v1 Announce Type: cross 
Abstract: Although Digital Twin is actively deployed in manufacturing, its human-centric counterpart - Human Digital Twin (HDT) is understudied, especially in job-shop production with high task variability and manual labor. HDT applications like ergonomic posture monitoring, fatigue prediction and health-based task assignment offer benefits to industries in emerging economies. However, poor digital maturity, lack of awareness and doubts about use-case applicability hinder adoption. This study provides a strategic prioritization framework to aid human-centric digital evolution in labor-intensive industries for guiding the selection of HDT applications delivering the highest value with the lowest implementation threshold. An integrated Fuzzy AHP-TOPSIS approach evaluates the use-cases based on criteria like implementation cost, technological maturity, scalability. These criteria and use-cases were identified based on input from a five-member expert panel and verified for consistency (CR &lt; 0.1). Analysis shows posture monitoring and fatigue prediction as most influential and practicable, especially in semi-digital environments. Strengths include compliance with Industry 5.0 principles incorporating technology and human factors. Lack of field validation and subjective knowledge pose drawbacks. Future work should include simulation-based validation and pilot tests on real job-shop settings. Ultimately, the research offers a decision-support system helping industries balance innovativeness and practicability in early stage of HDT adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15713v1</guid>
      <category>cs.OH</category>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samiran Sardar, Nasif Morshed, Shezan Ahmed</dc:creator>
    </item>
    <item>
      <title>Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response</title>
      <link>https://arxiv.org/abs/2511.15755</link>
      <description>arXiv:2511.15755v1 Announce Type: cross 
Abstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15755v1</guid>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Drammeh</dc:creator>
    </item>
    <item>
      <title>Identifying the Supply Chain of AI for Trustworthiness and Risk Management in Critical Applications</title>
      <link>https://arxiv.org/abs/2511.15763</link>
      <description>arXiv:2511.15763v1 Announce Type: cross 
Abstract: Risks associated with the use of AI, ranging from algorithmic bias to model hallucinations, have received much attention and extensive research across the AI community, from researchers to end-users. However, a gap exists in the systematic assessment of supply chain risks associated with the complex web of data sources, pre-trained models, agents, services, and other systems that contribute to the output of modern AI systems. This gap is particularly problematic when AI systems are used in critical applications, such as the food supply, healthcare, utilities, law, insurance, and transport.
  We survey the current state of AI risk assessment and management, with a focus on the supply chain of AI and risks relating to the behavior and outputs of the AI system. We then present a proposed taxonomy specifically for categorizing AI supply chain entities. This taxonomy helps stakeholders, especially those without extensive AI expertise, to "consider the right questions" and systematically inventory dependencies across their organization's AI systems. Our contribution bridges a gap between the current state of AI governance and the urgent need for actionable risk assessment and management of AI use in critical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15763v1</guid>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raymond K. Sheh, Karen Geappen</dc:creator>
    </item>
    <item>
      <title>An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models</title>
      <link>https://arxiv.org/abs/2511.16383</link>
      <description>arXiv:2511.16383v1 Announce Type: cross 
Abstract: Recently, using Large Language Models (LLMs) to generate optimization models from natural language descriptions has became increasingly popular. However, a major open question is how to validate that the generated models are correct and satisfy the requirements defined in the natural language description. In this work, we propose a novel agent-based method for automatic validation of optimization models that builds upon and extends methods from software testing to address optimization modeling . This method consists of several agents that initially generate a problem-level testing API, then generate tests utilizing this API, and, lastly, generate mutations specific to the optimization model (a well-known software testing technique assessing the fault detection power of the test suite). In this work, we detail this validation framework and show, through experiments, the high quality of validation provided by this agent ensemble in terms of the well-known software testing measure called mutation coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16383v1</guid>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Zadorojniy, Segev Wasserkrug, Eitan Farchi</dc:creator>
    </item>
    <item>
      <title>CorrectHDL: Agentic HDL Design with LLMs Leveraging High-Level Synthesis as Reference</title>
      <link>https://arxiv.org/abs/2511.16395</link>
      <description>arXiv:2511.16395v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated remarkable potential in hardware front-end design using hardware description languages (HDLs). However, their inherent tendency toward hallucination often introduces functional errors into the generated HDL designs. To address this issue, we propose the framework CorrectHDL that leverages high-level synthesis (HLS) results as functional references to correct potential errors in LLM-generated HDL designs.The input to the proposed framework is a C/C++ program that specifies the target circuit's functionality. The program is provided to an LLM to directly generate an HDL design, whose syntax errors are repaired using a Retrieval-Augmented Generation (RAG) mechanism. The functional correctness of the LLM-generated circuit is iteratively improved by comparing its simulated behavior with an HLS reference design produced by conventional HLS tools, which ensures the functional correctness of the result but can lead to suboptimal area and power efficiency. Experimental results demonstrate that circuits generated by the proposed framework achieve significantly better area and power efficiency than conventional HLS designs and approach the quality of human-engineered circuits. Meanwhile, the correctness of the resulting HDL implementation is maintained, highlighting the effectiveness and potential of agentic HDL design leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven IC design flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16395v1</guid>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangwei Xu, Grace Li Zhang, Ulf Schlichtmann, Bing Li</dc:creator>
    </item>
    <item>
      <title>Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework</title>
      <link>https://arxiv.org/abs/2511.15168</link>
      <description>arXiv:2511.15168v2 Announce Type: replace 
Abstract: Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15168v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen-Khang Le, Hiep Nguyen, Ngoc-Minh Nguyen, Son T. Luu, Trung Vo, Quan Minh Bui, Shoshin Nomura, Le-Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Securing Smart Contract Languages with a Unified Agentic Framework for Vulnerability Repair in Solidity and Move</title>
      <link>https://arxiv.org/abs/2502.18515</link>
      <description>arXiv:2502.18515v2 Announce Type: replace-cross 
Abstract: The rapid growth of the blockchain ecosystem and the increasing value locked in smart contracts necessitate robust security measures. While languages like Solidity and Move aim to improve smart contract security, vulnerabilities persist. This paper presents Smartify, a novel multi-agent framework leveraging Large Language Models (LLMs) to automatically detect and repair vulnerabilities in Solidity and Move smart contracts. Unlike traditional methods that rely solely on vast pre-training datasets, Smartify employs a team of specialized agents working on different specially fine-tuned LLMs to analyze code based on underlying programming concepts and language-specific security principles. We evaluated Smartify on a dataset for Solidity and a curated dataset for Move, demonstrating its effectiveness in fixing a wide range of vulnerabilities. Our results show that Smartify (Gemma2+codegemma) achieves state-of-the-art performance, surpassing existing LLMs and enhancing general-purpose models' capabilities, such as Llama 3.1. Notably, Smartify can incorporate language-specific knowledge, such as the nuances of Move, without requiring massive language-specific pre-training datasets. This work offers a detailed analysis of various LLMs' performance on smart contract repair, highlighting the strengths of our multi-agent approach and providing a blueprint for developing more secure and reliable decentralized applications in the growing blockchain landscape. We also provide a detailed recipe for extending this to other similar use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18515v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rabimba Karanjai, Lei Xu, Weidong Shi</dc:creator>
    </item>
    <item>
      <title>Who is using AI to code? Global diffusion and impact of generative AI</title>
      <link>https://arxiv.org/abs/2506.08945</link>
      <description>arXiv:2506.08945v2 Announce Type: replace-cross 
Abstract: Generative coding tools promise big productivity gains, but uneven uptake could widen skill and income gaps. We train a neural classifier to spot AI-generated Python functions in over 30 million GitHub commits by 170,000 developers, tracking how fast -- and where -- these tools take hold. Today, AI writes an estimated 29% of Python functions in the US, a modest and shrinking lead over other countries. We estimate that quarterly output, measured in online code contributions, has increased by 3.6% because of this. Our evidence suggests that programmers using AI may also more readily expand into new domains of software development. However, experienced programmers capture nearly all of these productivity and exploration gains, widening rather than closing the skill gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08945v2</guid>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Daniotti, Johannes Wachs, Xiangnan Feng, Frank Neffke</dc:creator>
    </item>
    <item>
      <title>Distributed Computing From First Principles</title>
      <link>https://arxiv.org/abs/2506.12959</link>
      <description>arXiv:2506.12959v2 Announce Type: replace-cross 
Abstract: This book on Distributed Computing aims to benefit a diverse audience, ranging from aspiring engineers, and seasoned researchers, to a wide range of professionals. Driven by my passion for making the core concepts of distributed computing accessible, this work is a significant undertaking designed to empower individuals from all backgrounds to gain valuable insight. Have you ever wondered how a typical distributed system works under the hood? Are you looking for a pedagogical guide with complete implementations? In this work, we have implemented several foundational algorithms in Distributed Computing. Whether your expertise lies in the theoretical foundations or the practical applications of the principles of Distributed Systems, this book is for you.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12959v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenneth Odoh</dc:creator>
    </item>
    <item>
      <title>Try-Mopsa: Relational Static Analysis in Your Pocket</title>
      <link>https://arxiv.org/abs/2509.13128</link>
      <description>arXiv:2509.13128v2 Announce Type: replace-cross 
Abstract: Static analyzers are complex pieces of software with large dependencies. They can be difficult to install, which hinders adoption and creates barriers for students learning static analysis. This work introduces Try-Mopsa: a scaled-down version of the Mopsa static analysis platform, compiled into JavaScript to run purely as a client-side application in web browsers. Try-Mopsa provides a responsive interface that works on both desktop and mobile devices. Try-Mopsa features all the core components of Mopsa. In particular, it supports relational numerical domains. We present the interface, changes and adaptations required to have a pure JavaScript version of Mopsa. We envision Try-Mopsa as a convenient platform for onboarding or teaching purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13128v2</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Monat</dc:creator>
    </item>
  </channel>
</rss>
