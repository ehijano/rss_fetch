<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Sep 2024 01:46:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Peephole Optimization for Quantum Approximate Synthesis</title>
      <link>https://arxiv.org/abs/2409.06020</link>
      <description>arXiv:2409.06020v1 Announce Type: cross 
Abstract: Peephole optimization of quantum circuits provides a method of leveraging standard circuit synthesis approaches into scalable quantum circuit optimization. One application of this technique partitions an entire circuit into a series of peepholes and produces multiple approximations of each partitioned subcircuit. A single approximation of each subcircuit is then selected to form optimized result circuits. We propose a series of improvements to the final phase of this architecture, which include the addition of error awareness and a better method of approximating the correctness of the result. We evaluated these proposed improvements on a set of benchmark circuits using the IBMQ FakeWashington simulator. The results demonstrate that our best-performing method provides an average reduction in Total Variational Distance (TVD) and Jensen-Shannon Divergence (JSD) of 18.2% and 15.8%, respectively, compared with the Qiskit optimizer. This also constitutes an improvement in TVD of 11.4% and JSD of 9.0% over existing solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06020v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISQED60706.2024.10528701</arxiv:DOI>
      <arxiv:journal_reference>2024 25th International Symposium on Quality Electronic Design (ISQED), 2024, pp. 1-8</arxiv:journal_reference>
      <dc:creator>Joseph Clark, Himanshu Thapliyal</dc:creator>
    </item>
    <item>
      <title>Integration of Beyond Diagonal RIS and UAVs in 6G NTNs: Enhancing Aerial Connectivity</title>
      <link>https://arxiv.org/abs/2409.06073</link>
      <description>arXiv:2409.06073v1 Announce Type: cross 
Abstract: The reconfigurable intelligent surface (RIS) technology shows great potential in sixth-generation (6G) terrestrial and non-terrestrial networks (NTNs) since it can effectively change wireless settings to improve connectivity. Extensive research has been conducted on traditional RIS systems with diagonal phase response matrices. The straightforward RIS architecture, while cost-effective, has restricted capabilities in manipulating the wireless channels. The beyond diagonal reconfigurable intelligent surface (BD-RIS) greatly improves control over the wireless environment by utilizing interconnected phase response elements. This work proposes the integration of unmanned aerial vehicle (UAV) communications and BD-RIS in 6G NTNs, which has the potential to further enhance wireless coverage and spectral efficiency. We begin with the preliminaries of UAV communications and then discuss the fundamentals of BD-RIS technology. Subsequently, we discuss the potential of BD-RIS and UAV communications integration. We then proposed a case study based on UAV-mounted transmissive BD-RIS communication. Finally, we highlight future research directions and conclude this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06073v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wali Ullah Khan, Eva Lagunas, Asad Mahmood, Muhammad Asif, Manzoor Ahmed, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>The Lynchpin of In-Memory Computing: A Benchmarking Framework for Vector-Matrix Multiplication in RRAMs</title>
      <link>https://arxiv.org/abs/2409.06140</link>
      <description>arXiv:2409.06140v1 Announce Type: cross 
Abstract: The Von Neumann bottleneck, a fundamental challenge in conventional computer architecture, arises from the inability to execute fetch and data operations simultaneously due to a shared bus linking processing and memory units. This bottleneck significantly limits system performance, increases energy consumption, and exacerbates computational complexity. Emerging technologies such as Resistive Random Access Memories (RRAMs), leveraging crossbar arrays, offer promising alternatives for addressing the demands of data-intensive computational tasks through in-memory computing of analog vector-matrix multiplication (VMM) operations. However, the propagation of errors due to device and circuit-level imperfections remains a significant challenge. In this study, we introduce MELISO (In-Memory Linear Solver), a comprehensive end-to-end VMM benchmarking framework tailored for RRAM-based systems. MELISO evaluates the error propagation in VMM operations, analyzing the impact of RRAM device metrics on error magnitude and distribution. This paper introduces the MELISO framework and demonstrates its utility in characterizing and mitigating VMM error propagation using state-of-the-art RRAM device metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06140v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Tawsif Rahman Chowdhury, Huynh Quang Nguyen Vo, Paritosh Ramanan, Murat Yildirim, Gozde Tutuncuoglu</dc:creator>
    </item>
    <item>
      <title>Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2409.06450</link>
      <description>arXiv:2409.06450v1 Announce Type: cross 
Abstract: The generation of corner cases has become increasingly crucial for efficiently testing autonomous vehicles prior to road deployment. However, existing methods struggle to accommodate diverse testing requirements and often lack the ability to generalize to unseen situations, thereby reducing the convenience and usability of the generated scenarios. A method that facilitates easily controllable scenario generation for efficient autonomous vehicles (AV) testing with realistic and challenging situations is greatly needed. To address this, we proposed OmniTester: a multimodal Large Language Model (LLM) based framework that fully leverages the extensive world knowledge and reasoning capabilities of LLMs. OmniTester is designed to generate realistic and diverse scenarios within a simulation environment, offering a robust solution for testing and evaluating AVs. In addition to prompt engineering, we employ tools from Simulation of Urban Mobility to simplify the complexity of codes generated by LLMs. Furthermore, we incorporate Retrieval-Augmented Generation and a self-improvement mechanism to enhance the LLM's understanding of scenarios, thereby increasing its ability to produce more realistic scenes. In the experiments, we demonstrated the controllability and realism of our approaches in generating three types of challenging and complex scenarios. Additionally, we showcased its effectiveness in reconstructing new scenarios described in crash report, driven by the generalization capability of LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06450v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiujing Lu, Xuanhan Wang, Yiwei Jiang, Guangming Zhao, Mingyue Ma, Shuo Feng</dc:creator>
    </item>
    <item>
      <title>"The struggle is a part of the experience": Engaging Discontents in the Design of Family Meal Technologies</title>
      <link>https://arxiv.org/abs/2409.06627</link>
      <description>arXiv:2409.06627v1 Announce Type: cross 
Abstract: Meals are a central (and messy) part of family life. Previous design framings for mealtime technologies have focused on supporting dietary needs or social and celebratory interactions at the dinner table; however, family meals involve the coordination of many activities and complicated family dynamics. In this paper, we report on findings from interviews and design sessions with 18 families from the Midwestern United States (including both partners/parents and children) to uncover important family differences and tensions that arise around domestic meal experiences. Drawing on feminist theory, we unpack the work of feeding a family as a form of care, drawing attention to the social and emotional complexity of family meals. Critically situating our data within current design narratives, we propose the sensitizing concepts of generative and systemic discontents as a productive way towards troubling the design space of family-food interaction to contend with the struggles that are a part of everyday family meal experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06627v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3687016</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Hum.-Comput. Interact 8, CSCW2, Article 477 (November 2024), 33 pages</arxiv:journal_reference>
      <dc:creator>Yuxing Wu, Andrew D Miller, Chia-Fang Chung, Elizabeth Kaziunas</dc:creator>
    </item>
    <item>
      <title>End-to-End Protocol for High-Quality QAOA Parameters with Few Shots</title>
      <link>https://arxiv.org/abs/2408.00557</link>
      <description>arXiv:2408.00557v2 Announce Type: replace-cross 
Abstract: The quantum approximate optimization algorithm (QAOA) is a quantum heuristic for combinatorial optimization that has been demonstrated to scale better than state-of-the-art classical solvers for some problems. For a given problem instance, QAOA performance depends crucially on the choice of the parameters. While average-case optimal parameters are available in many cases, meaningful performance gains can be obtained by fine-tuning these parameters for a given instance. This task is especially challenging, however, when the number of circuit executions (shots) is limited. In this work, we develop an end-to-end protocol that combines multiple parameter settings and fine-tuning techniques. We use large-scale numerical experiments to optimize the protocol for the shot-limited setting and observe that optimizers with the simplest internal model (linear) perform best. We implement the optimized pipeline on a trapped-ion processor using up to 32 qubits and 5 QAOA layers, and we demonstrate that the pipeline is robust to small amounts of hardware noise. To the best of our knowledge, these are the largest demonstrations of QAOA parameter fine-tuning on a trapped-ion processor in terms of 2-qubit gate count.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00557v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyi Hao, Zichang He, Ruslan Shaydulin, Jeffrey Larson, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>FrameCorr: Adaptive, Autoencoder-based Neural Compression for Video Reconstruction in Resource and Timing Constrained Network Settings</title>
      <link>https://arxiv.org/abs/2409.02453</link>
      <description>arXiv:2409.02453v2 Announce Type: replace-cross 
Abstract: Despite the growing adoption of video processing via Internet of Things (IoT) devices due to their cost-effectiveness, transmitting captured data to nearby servers poses challenges due to varying timing constraints and scarcity of network bandwidth. Existing video compression methods face difficulties in recovering compressed data when incomplete data is provided. Here, we introduce FrameCorr, a deep-learning based solution that utilizes previously received data to predict the missing segments of a frame, enabling the reconstruction of a frame from partially received data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02453v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.MM</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Li, Shehab Sarar Ahmed, Deepak Nair</dc:creator>
    </item>
  </channel>
</rss>
