<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Jan 2025 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Remote State Estimation over Unreliable Channels with Unreliable Feedback: Fundamental Limits</title>
      <link>https://arxiv.org/abs/2501.13192</link>
      <description>arXiv:2501.13192v1 Announce Type: new 
Abstract: This article is concerned with networked estimation in a system composed of a source that is observed by a sensor, a remote monitor that needs to estimate the state of the source in real time, and a communication channel that connects the source to the monitor. The source is a partially observable dynamical process, and the communication channel is a packet-erasure channel with feedback. Our main objective is to obtain the fundamental performance limits of the underlying networked system in the sense of a causal tradeoff between the packet rate and the mean square error when both forward and backward channels are unreliable. We characterize an optimal coding policy profile consisting of a scheduling policy for the encoder and an estimation policy for the decoder. We complement our theoretical results with a numerical analysis, and compare the performance limits of the networked system in different communication regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13192v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Touraj Soleymani, Mohamad Assaad, John S. Baras</dc:creator>
    </item>
    <item>
      <title>Covert Communication via Action-Dependent States</title>
      <link>https://arxiv.org/abs/2501.13212</link>
      <description>arXiv:2501.13212v1 Announce Type: new 
Abstract: This paper studies covert communication over channels with ADSI when the state is available either non-causally or causally at the transmitter. Covert communication refers to reliable communication between a transmitter and a receiver while ensuring a low probability of detection by an adversary, which we refer to as `warden'. It is well known that in a point-to-point DMC, it is possible to communicate on the order of $\sqrt{N}$ bits reliably and covertly over $N$ channel uses while the transmitter and the receiver are required to share a secret key on the order of $\sqrt{N}$ bits. This paper studies achieving reliable and covert communication of positive rate, i.e., reliable and covert communication on the order of N bits in N channel uses, over a channel with ADSI while the transmitter has non-causal or causal access to the ADSI, and the transmitter and the receiver share a secret key of negligible rate. We derive achievable rates for both the non-causal and causal scenarios by using block-Markov encoding and secret key generation from the ADSI, which subsumes the best achievable rates for channels with random states. We also derive upper bounds, for both non-causal and causal scenarios, that meet our achievable rates for some special cases. As an application of our problem setup, we study covert communication over channels with rewrite options, which are closely related to recording covert information on memory, and show that a positive covert rate can be achieved in such channels. As a special case of our problem, we study the AWGN channels and provide lower and upper bounds on the covert capacity that meet when the transmitter and the receiver share a secret key of sufficient rate and when the warden's channel is noisier than the legitimate receiver channel. As another application of our problem setup, we show that cooperation can lead to a positive covert rate in Gaussian channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13212v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hassan ZivariFard, Xiaodong Wang</dc:creator>
    </item>
    <item>
      <title>On Subset Retrieval and Group Testing Problems with Differential Privacy Constraints</title>
      <link>https://arxiv.org/abs/2501.13278</link>
      <description>arXiv:2501.13278v1 Announce Type: new 
Abstract: This paper focuses on the design and analysis of privacy-preserving techniques for group testing and infection status retrieval. Our work is motivated by the need to provide accurate information on the status of disease spread among a group of individuals while protecting the privacy of the infection status of any single individual involved. The paper is motivated by practical scenarios, such as controlling the spread of infectious diseases, where individuals might be reluctant to participate in testing if their outcomes are not kept confidential.
  The paper makes the following contributions. First, we present a differential privacy framework for the subset retrieval problem, which focuses on sharing the infection status of individuals with administrators and decision-makers. We characterize the trade-off between the accuracy of subset retrieval and the degree of privacy guaranteed to the individuals. In particular, we establish tight lower and upper bounds on the achievable level of accuracy subject to the differential privacy constraints. We then formulate the differential privacy framework for the noisy group testing problem in which noise is added either before or after the pooling process. We establish a reduction between the private subset retrieval and noisy group testing problems and show that the converse and achievability schemes for subset retrieval carry over to differentially private group testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13278v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mira Gonen, Michael Langberg, Alex Sprintson</dc:creator>
    </item>
    <item>
      <title>Collaborative Coded Caching for Partially Connected Networks</title>
      <link>https://arxiv.org/abs/2501.13298</link>
      <description>arXiv:2501.13298v1 Announce Type: new 
Abstract: Coded caching leverages the differences in user cache memories to achieve gains that scale with the total cache size, alleviating network congestion due to high-quality content requests. Additionally, distributing transmitters over a wide area can mitigate the adverse effects of path loss. In this work, we consider a partially connected network where the channel between distributed transmitters (helpers) and users is modeled as a distributed MIMO Gaussian broadcast channel. We propose a novel delivery scheme consisting of two phases: \emph{partitioning} and \emph{transmission}. In the partitioning phase, users with identical cache profiles are partitioned into the minimum number of sets, such that users within each set can successfully decode their desired message from a joint transmission enabled by MIMO precoding. To optimally partition the users, we employ the branch and bound method. In the transmission phase, each partition is treated as a single entity, and codewords are multicast to partitions with distinct cache profiles. The proposed delivery scheme is applicable to any partially connected network, and while the partitioning is optimal, the overall delivery scheme, including transmission, is heuristic. Interestingly, simulation results show that its performance closely approximates that of the fully connected optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13298v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kagan Akcay, Eleftherios Lampiris, MohammadJavad Salehi, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>On the Massive MIMO Channel Polarization</title>
      <link>https://arxiv.org/abs/2501.13380</link>
      <description>arXiv:2501.13380v1 Announce Type: new 
Abstract: In this work, we demonstrate that an $n \times n$ massive multiple-input multiple-output (MIMO) channel can be polarized using common matrix decomposition techniques: singular value decomposition (SVD) and QR decomposition. With full channel state information (CSI), we show that channel capacity is always attained by freezing certain number of worst subchannels, provided a total power constraint and sufficiently large $n$. We further prove that the capacity obtained through channel polarization is always greater than that achieved through channel equalization. Finally, we propose a low-complexity precoding scheme based on channel polarization, which outperforms the lattice-reduction-aided precoding scheme, in terms of capacity, decoding error rate, encoding complexity, and CSIT cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13380v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuiyin Liu, Amin Sakzad</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Fluid Antenna Multiple Access Assisted Wireless Powered Communication Network</title>
      <link>https://arxiv.org/abs/2501.13405</link>
      <description>arXiv:2501.13405v1 Announce Type: new 
Abstract: This paper investigates a novel fluid antenna multiple access (FAMA)-assisted wireless powered communication network (WPCN), in which a hybrid access point (HAP) equipped with multiple fixed position antennas (FPAs) provides integrated data and energy transfer (IDET) services towards low-power devices that are equipped with a single fluid antenna (FA), while the low-power devices use harvested energy to power their own uplink transmission. Using the block correlation channel model, both the downlink and uplink wireless data transfer (WDT) outage probabilities are analyzed under specific port selection strategies, including downlink signal-to-interference ratio-based port selection (DSPS) strategy, downlink energy harvesting power-based port selection (DEPS) strategy, uplink signal-to-noise ratio-based port selection (USPS) strategy, and uplink channel-based port selection (UCPS) strategy. A step function approximation (SFA) approach is also relied upon to derive closed-form expressions for the outage probabilities, while the lower bounds for uplink WDT outage probabilities are also formulated. Numerical results demonstrate the validity of our theoretical analysis, which also provide useful guidelines for the system design through the analytical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13405v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Lin, Yizhe Zhao, Halvin Yang, Jie Hu</dc:creator>
    </item>
    <item>
      <title>Physics-Aware Sparse Signal Recovery Through PDE-Governed Measurement Systems</title>
      <link>https://arxiv.org/abs/2501.13414</link>
      <description>arXiv:2501.13414v1 Announce Type: new 
Abstract: This paper introduces a novel framework for physics-aware sparse signal recovery in measurement systems governed by partial differential equations (PDEs). Unlike conventional compressed sensing approaches that treat measurement systems as simple linear systems, our method explicitly incorporates the underlying physics through numerical PDE solvers and automatic differentiation (AD). We present physics-aware iterative shrinkage-thresholding algorithm (PA-ISTA), which combines the computational efficiency of ISTA with accurate physical modeling to achieve improved signal reconstruction. Using optical fiber channels as a concrete example, we demonstrate how the nonlinear Schr\"odinger equation (NLSE) can be integrated into the recovery process. Our approach leverages deep unfolding techniques for parameter optimization. Numerical experiments show that PA-ISTA significantly outperforms conventional recovery methods. While demonstrated on optical fiber systems, our framework provides a general methodology for physics-aware signal recovery that can be adapted to various PDE-governed measurement systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13414v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tadashi Wadayama, Koji Igarashi, Takumi Takahashi</dc:creator>
    </item>
    <item>
      <title>Explicit Construction of Classical and Quantum Quasi-Cyclic Low-Density Parity-Check Codes with Column Weight 2 and Girth 12</title>
      <link>https://arxiv.org/abs/2501.13444</link>
      <description>arXiv:2501.13444v1 Announce Type: new 
Abstract: This study proposes an explicit construction method for classical and quantum quasi-cyclic low-density parity-check (QC-LDPC) codes with a girth of 12. The proposed method designs parity-check matrices that maximize the girth while maintaining an orthogonal structure suitable for quantum error correction. By utilizing algebraic techniques, short cycles are eliminated, which improves error correction performance. Additionally, this method is extended to non-binary LDPC codes and spatially-coupled LDPC codes, demonstrating that both the girth and orthogonality can be preserved. The results of this study enable the design of high-performance quantum error correction codes without the need for random search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13444v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daiki Komoto, Kenta Kasai</dc:creator>
    </item>
    <item>
      <title>A New Construction of Non-Binary Deletion Correcting Codes and their Decoding</title>
      <link>https://arxiv.org/abs/2501.13534</link>
      <description>arXiv:2501.13534v1 Announce Type: new 
Abstract: Non-binary codes correcting multiple deletions have recently attracted a lot of attention. In this work, we focus on multiplicity-free codes, a family of non-binary codes where all symbols are distinct. Our main contribution is a new explicit construction of such codes, based on set and permutation codes. We show that our multiplicity-free codes can correct multiple deletions and provide a decoding algorithm. We also show that, for a certain regime of parameters, our constructed codes have size larger than all the previously known non-binary codes correcting multiple deletions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13534v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Michael Schaller, Beatrice Toesca, Van Khu Vu</dc:creator>
    </item>
    <item>
      <title>Minimizing Queue Length Regret for Arbitrarily Varying Channels</title>
      <link>https://arxiv.org/abs/2501.13551</link>
      <description>arXiv:2501.13551v1 Announce Type: new 
Abstract: We consider an online channel scheduling problem for a single transmitter-receiver pair equipped with $N$ arbitrarily varying wireless channels. The transmission rates of the channels might be non-stationary and could be controlled by an oblivious adversary. At every slot, incoming data arrives at an infinite-capacity data queue located at the transmitter. A scheduler, which is oblivious to the current channel rates, selects one of the $N$ channels for transmission. At the end of the slot, the scheduler only gets to know the transmission rate of the selected channel. The objective is to minimize the queue length regret, defined as the difference between the queue length at some time $T$ achieved by an online policy and the queue length obtained by always transmitting over the single best channel in hindsight. We propose a weakly adaptive Multi-Armed Bandit (MAB) algorithm for minimizing the queue length regret in this setup. Unlike previous works, we do not make any stability assumptions about the queue or the arrival process. Hence, our result holds even when the queueing process is unstable. Our main observation is that the queue length regret can be upper bounded by the regret of a MAB policy that competes against the best channel in hindsight uniformly over all sub-intervals of $[T]$. As a technical contribution of independent interest, we then propose a weakly adaptive adversarial MAB policy which achieves $\tilde{O}(\sqrt{N}T^{\frac{3}{4}})$ regret with high probability, implying the same bound for queue length regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13551v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>G Krishnakumar, Abhishek Sinha</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic Oblivious Relaying and Variable-Length Noisy Lossy Source Coding</title>
      <link>https://arxiv.org/abs/2501.13582</link>
      <description>arXiv:2501.13582v1 Announce Type: new 
Abstract: The information bottleneck channel (or the oblivious relay channel) concerns a channel coding setting where the decoder does not directly observe the channel output. Rather, the channel output is relayed to the decoder by an oblivious relay (which does not know the codebook) via a rate-limited link. The capacity is known to be given by the information bottleneck. We study finite-blocklength achievability results of the channel, where the relay communicates to the decoder via fixed-length or variable-length codes. These two cases give rise to two different second-order versions of the information bottleneck. Our proofs utilize the nonasymptotic noisy lossy source coding results by Kostina and Verd\'{u}, the strong functional representation lemma, and the Poisson matching lemma. Moreover, we also give a novel nonasymptotic variable-length noisy lossy source coding result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13582v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanxiao Liu, Sepehr Heidari Advary, Cheuk Ting Li</dc:creator>
    </item>
    <item>
      <title>Two Step SOVA-Based Decoding Algorithm for Tailbiting Codes</title>
      <link>https://arxiv.org/abs/2501.13606</link>
      <description>arXiv:2501.13606v1 Announce Type: new 
Abstract: In this work we propose a novel decoding algorithm for tailbiting convolutional codes and evaluate its performance over different channels. The proposed method consists on a fixed two-step Viterbi decoding of the received data. In the first step, an estimation of the most likely state is performed based on a SOVA decoding. The second step consists of a conventional Viterbi decoding that employs the state estimated in the previous step as the initial and final states of the trellis. Simulations results show a performance close to that of maximum-likelihood decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13606v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCOMM.2009.090810</arxiv:DOI>
      <arxiv:journal_reference>IEEE Communications Letters, volume: 13, issue: 7, July 2009</arxiv:journal_reference>
      <dc:creator>Jorge Ortin, Paloma Garcia, Fernando Gutierrez, Antonio Valdovinos</dc:creator>
    </item>
    <item>
      <title>Information-theoretic limits and approximate message-passing for high-dimensional time series</title>
      <link>https://arxiv.org/abs/2501.13625</link>
      <description>arXiv:2501.13625v1 Announce Type: new 
Abstract: High-dimensional time series appear in many scientific setups, demanding a nuanced approach to model and analyze the underlying dependence structure. However, theoretical advancements so far often rely on stringent assumptions regarding the sparsity of the underlying signals. In this contribution, we expand the scope by investigating a high-dimensional time series model wherein the number of features grows proportionally to the number of sampling points, without assuming sparsity in the signal. Specifically, we consider the stochastic regression model and derive a single-letter formula for the normalized mutual information between observations and the signal. We also empirically study the vector approximate message passing (VAMP) algorithm and show that, despite a lack of theoretical guarantees, its performance for inference in our time series model is robust and often statistically optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13625v1</guid>
      <category>cs.IT</category>
      <category>cond-mat.dis-nn</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daria Tieplova, Samriddha Lahiry, Jean Barbier</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Turbo Decoding Algorithms in Wireless OFDM Systems</title>
      <link>https://arxiv.org/abs/2501.13650</link>
      <description>arXiv:2501.13650v1 Announce Type: new 
Abstract: Turbo codes are well known to be one of the error correction techniques which achieve closer results to the Shannon limit. Nevertheless, the specific performance of the code highly depends on the particular decoding algorithm used at the receiver. In this sense, the election of the decoding algorithm involves a trade off between the gain introduced by the code and the complexity of the decoding process. In this work we perform a thorough analysis of the different iterative decoding techniques and analyze their suitability for being implemented in the user terminals of new cellular and broadcast systems which are based on orthogonal frequency division multiplexing (OFDM). The analyzed iterative decoding algorithms are the Max-Log-MAP and the soft output Viterbi algorithm (SOVA), since both of them have a relative low computational complexity, simplifying their implementation in cost efficient terminals. Simulation results have been obtained for different encoder structures, block sizes and considering realistic channel conditions (an OFDM transmission over a wireless channel).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13650v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCE.2009.5277969</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Consumer Electronics, volume: 55, issue: 3, August 2009</arxiv:journal_reference>
      <dc:creator>Jorge Ortin, Paloma Garcia, Fernando Gutierrez, Antonio Valdovinos</dc:creator>
    </item>
    <item>
      <title>Dual-Domain Exponent of Maximum Mutual Information Decoding</title>
      <link>https://arxiv.org/abs/2501.13724</link>
      <description>arXiv:2501.13724v1 Announce Type: new 
Abstract: This paper provides a dual domain derivation of the error exponent of maximum mutual information (MMI) decoding with constant composition codes, showing it coincides with that of maximum likelihood decoding for discrete memoryless channels. The analysis is further extended to joint source-channel coding, demonstrating that the generalized MMI decoder achieves the same random coding error exponent as the maximum a posteriori decoder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13724v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>AmirPouya Moeini, Albert Guill\'en i F\`abregas</dc:creator>
    </item>
    <item>
      <title>Discrete Layered Entropy, Conditional Compression and a Tighter Strong Functional Representation Lemma</title>
      <link>https://arxiv.org/abs/2501.13736</link>
      <description>arXiv:2501.13736v1 Announce Type: new 
Abstract: We study a quantity called discrete layered entropy, which approximates the Shannon entropy within a logarithmic gap. Compared to the Shannon entropy, the discrete layered entropy is piecewise linear, approximates the expected length of the optimal one-to-one non-prefix-free encoding, and satisfies an elegant conditioning property. These properties make it useful for approximating the Shannon entropy in linear programming, studying the optimal length of conditional encoding, and bounding the entropy of monotonic mixture distributions. In particular, it can give a bound for the strong functional representation lemma that improves upon the best bound (as long as the mutual information is at least 2).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13736v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheuk Ting Li</dc:creator>
    </item>
    <item>
      <title>Matrix Completion in Group Testing: Bounds and Simulations</title>
      <link>https://arxiv.org/abs/2501.13780</link>
      <description>arXiv:2501.13780v1 Announce Type: new 
Abstract: The main goal of group testing is to identify a small number of defective items in a large population of items. A test on a subset of items is positive if the subset contains at least one defective item and negative otherwise. In non-adaptive design, all tests can be tested simultaneously and represented by a measurement matrix in which a row and a column represent a test and an item, respectively. An entry in row $i$ and column $j$ is 1 if item $j$ belongs to the test $i$ and is 0 otherwise. Given an unknown set of defective items, the objective is to design a measurement matrix such that, by observing its corresponding outcome vector, the defective items can be recovered efficiently. The basic trait of this approach is that the measurement matrix has remained unchanged throughout the course of generating the outcome vector and recovering defective items. In this paper, we study the case in which some entries in the measurement matrix are erased, called \emph{the missing measurement matrix}, before the recovery phase of the defective items, and our objective is to fully recover the measurement matrix from the missing measurement matrix. In particular, we show that some specific rows with erased entries provide information aiding the recovery while others do not. Given measurement matrices and erased entries follow the Bernoulli distribution, we show that before the erasing event happens, sampling sufficient sets of defective items and their corresponding outcome vectors can help us recover the measurement matrix from the missing measurement matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13780v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Trung-Khang Tran, Thach V. Bui</dc:creator>
    </item>
    <item>
      <title>Rate-Distortion Region for Distributed Indirect Source Coding with Decoder Side Information</title>
      <link>https://arxiv.org/abs/2501.13784</link>
      <description>arXiv:2501.13784v1 Announce Type: new 
Abstract: This paper studies a variant of the rate-distortion problem motivated by task-oriented semantic communication and distributed learning systems, where $M$ correlated sources are independently encoded for a central decoder. The decoder has access to correlated side information in addition to the messages received from the encoders and aims to recover a latent random variable under a given distortion constraint, rather than recovering the sources themselves. We characterize the exact rate-distortion function for the case where the sources are conditionally independent given the side information. Furthermore, we develop a distributed Blahut-Arimoto (BA) algorithm to numerically compute the rate-distortion function. Numerical examples are provided to demonstrate the effectiveness of the proposed approach in calculating the rate-distortion region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13784v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiancheng Tang, Qianqian Yang</dc:creator>
    </item>
    <item>
      <title>On entropy-constrained Gaussian channel capacity via the moment problem</title>
      <link>https://arxiv.org/abs/2501.13814</link>
      <description>arXiv:2501.13814v1 Announce Type: new 
Abstract: We study the capacity of the power-constrained additive Gaussian channel with an entropy constraint at the input. In particular, we characterize this capacity in the low signal-to-noise ratio regime, as a corollary of the following general result on a moment matching problem: we show that for any continuous random variable with finite moments, the largest number of initial moments that can be matched by a discrete random variable of sufficiently small but positive entropy is three.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13814v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adway Girish, Shlomo Shamai, Emre Telatar</dc:creator>
    </item>
    <item>
      <title>Tight relations and equivalences between smooth relative entropies</title>
      <link>https://arxiv.org/abs/2501.12447</link>
      <description>arXiv:2501.12447v1 Announce Type: cross 
Abstract: The precise one-shot characterisation of operational tasks in classical and quantum information theory relies on different forms of smooth entropic quantities. A particularly important connection is between the hypothesis testing relative entropy and the smoothed max-relative entropy, which together govern many operational settings. We first strengthen this connection into a type of equivalence: we show that the hypothesis testing relative entropy is equivalent to a variant of the smooth max-relative entropy based on the information spectrum divergence, which can be alternatively understood as a measured smooth max-relative entropy. Furthermore, we improve a fundamental lemma due to Datta and Renner that connects the different variants of the smoothed max-relative entropy, introducing a modified proof technique based on matrix geometric means and a tightened gentle measurement lemma. We use the unveiled connections and tools to strictly improve on previously known one-shot bounds and duality relations between the smooth max-relative entropy and the hypothesis testing relative entropy, sharpening also bounds that connect the max-relative entropy with R\'enyi divergences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12447v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bartosz Regula, Ludovico Lami, Nilanjana Datta</dc:creator>
    </item>
    <item>
      <title>Distributed Multiple Testing with False Discovery Rate Control in the Presence of Byzantines</title>
      <link>https://arxiv.org/abs/2501.13242</link>
      <description>arXiv:2501.13242v1 Announce Type: cross 
Abstract: This work studies distributed multiple testing with false discovery rate (FDR) control in the presence of Byzantine attacks, where an adversary captures a fraction of the nodes and corrupts their reported p-values. We focus on two baseline attack models: an oracle model with the full knowledge of which hypotheses are true nulls, and a practical attack model that leverages the Benjamini-Hochberg (BH) procedure locally to classify which p-values follow the true null hypotheses. We provide a thorough characterization of how both attack models affect the global FDR, which in turn motivates counter-attack strategies and stronger attack models. Our extensive simulation studies confirm the theoretical results, highlight key design trade-offs under attacks and countermeasures, and provide insights into more sophisticated attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13242v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ME</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daofu Zhang, Mehrdad Pournaderi, Yu Xiang, Pramod Varshney</dc:creator>
    </item>
    <item>
      <title>Learning to Bid in Non-Stationary Repeated First-Price Auctions</title>
      <link>https://arxiv.org/abs/2501.13358</link>
      <description>arXiv:2501.13358v1 Announce Type: cross 
Abstract: First-price auctions have recently gained significant traction in digital advertising markets, exemplified by Google's transition from second-price to first-price auctions. Unlike in second-price auctions, where bidding one's private valuation is a dominant strategy, determining an optimal bidding strategy in first-price auctions is more complex. From a learning perspective, the learner (a specific bidder) can interact with the environment (other bidders) sequentially to infer their behaviors. Existing research often assumes specific environmental conditions and benchmarks performance against the best fixed policy (static benchmark). While this approach ensures strong learning guarantees, the static benchmark can deviate significantly from the optimal strategy in environments with even mild non-stationarity. To address such scenarios, a dynamic benchmark, which represents the sum of the best possible rewards at each time step, offers a more suitable objective. However, achieving no-regret learning with respect to the dynamic benchmark requires additional constraints. By inspecting reward functions in online first-price auctions, we introduce two metrics to quantify the regularity of the bidding sequence, which serve as measures of non-stationarity. We provide a minimax-optimal characterization of the dynamic regret when either of these metrics is sub-linear in the time horizon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13358v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihao Hu, Xiaoyu Fan, Yuan Yao, Jiheng Zhang, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>ROMA: ROtary and Movable Antenna</title>
      <link>https://arxiv.org/abs/2501.13403</link>
      <description>arXiv:2501.13403v1 Announce Type: cross 
Abstract: The rotary and movable antenna (ROMA) architecture represents a next-generation multi-antenna technology that enables flexible adjustment of antenna position and array rotation angles of the transceiver. In this letter, we propose a ROMA-aided multi-user MIMO communication system to fully enhance the efficiency and reliability of system transmissions. By deploying ROMA panels at both the transmitter and receiver sides, and jointly optimizing the three-dimensional (3D) rotation angles of each ROMA panel and the relative positions of antenna elements based on the spatial distribution of users and channel state information (CSI), we can achieve the objective of maximizing the average spectral efficiency (SE). Subsequently, we conduct a detailed analysis of the average SE performance of the system under the consideration of maximum ratio (MR) precoding. Due to the non-convexity of the optimization problem in the ROMA multi-user MIMO system, we propose an efficient solution based on an alternating optimization (AO) algorithm. Finally, simulation results demonstrate that the AO-based ROMA architecture can significantly improve the average SE. Furthermore, the performance improvement becomes more pronounced as the size of the movable region and the transmission power increase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13403v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Zhang, Wenhui Yi, Bokai Xu, Zhe Wang, Huahua Xiao, Bo Ai</dc:creator>
    </item>
    <item>
      <title>Optimizing the Trade-off Between Throughput and PAoI Outage Exponents</title>
      <link>https://arxiv.org/abs/2501.13431</link>
      <description>arXiv:2501.13431v1 Announce Type: cross 
Abstract: This paper investigates the trade-off between throughput and peak age of information (PAoI) outage probability in a multi-sensor information collection system. Each sensor monitors a physical process, periodically samples its status, and transmits the updates to a central access point over a shared radio resource. The trade-off arises from the interplay between each sensor's sampling frequency and the allocation of the shared resource. To optimize this trade-off, we formulate a joint optimization problem for each sensor's sampling delay and resource allocation, aiming to minimize a weighted sum of sampling delay costs (representing a weighted sum of throughput) while satisfying PAoI outage probability exponent constraints. We derive an optimal solution and particularly propose a closed-form approximation for large-scale systems. This approximation provides an explicit expression for an approximately optimal trade-off, laying a foundation for designing resource-constrained systems in applications that demand frequent updates and also stringent statistical timeliness guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13431v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tai-Chun Yeh, Yu-Pin Hsu</dc:creator>
    </item>
    <item>
      <title>Generalized graph codes and thier minimum distances</title>
      <link>https://arxiv.org/abs/2501.13462</link>
      <description>arXiv:2501.13462v1 Announce Type: cross 
Abstract: Graph code is a linear code obtained from linear codes $C$ and a certain bipartite graph G. In this paper, I propose an expansion of the definition of graph code to general $l$-partite, and give its lower bound of minimum distance. I also give an example of generalized graph code and calculate its parameters $[n, k, d]$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13462v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noaoki Fujii</dc:creator>
    </item>
    <item>
      <title>Optimal Multi-Objective Best Arm Identification with Fixed Confidence</title>
      <link>https://arxiv.org/abs/2501.13607</link>
      <description>arXiv:2501.13607v1 Announce Type: cross 
Abstract: We consider a multi-armed bandit setting with finitely many arms, in which each arm yields an $M$-dimensional vector reward upon selection. We assume that the reward of each dimension (a.k.a. {\em objective}) is generated independently of the others. The best arm of any given objective is the arm with the largest component of mean corresponding to the objective. The end goal is to identify the best arm of {\em every} objective in the shortest (expected) time subject to an upper bound on the probability of error (i.e., fixed-confidence regime). We establish a problem-dependent lower bound on the limiting growth rate of the expected stopping time, in the limit of vanishing error probabilities. This lower bound, we show, is characterised by a max-min optimisation problem that is computationally expensive to solve at each time step. We propose an algorithm that uses the novel idea of {\em surrogate proportions} to sample the arms at each time step, eliminating the need to solve the max-min optimisation problem at each step. We demonstrate theoretically that our algorithm is asymptotically optimal. In addition, we provide extensive empirical studies to substantiate the efficiency of our algorithm. While existing works on pure exploration with multi-objective multi-armed bandits predominantly focus on {\em Pareto frontier identification}, our work fills the gap in the literature by conducting a formal investigation of the multi-objective best arm identification problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13607v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhirui Chen, P. N. Karthik, Yeow Meng Chee, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>On the Reasoning Capacity of AI Models and How to Quantify It</title>
      <link>https://arxiv.org/abs/2501.13833</link>
      <description>arXiv:2501.13833v1 Announce Type: cross 
Abstract: Recent advances in Large Language Models (LLMs) have intensified the debate surrounding the fundamental nature of their reasoning capabilities. While achieving high performance on benchmarks such as GPQA and MMLU, these models exhibit limitations in more complex reasoning tasks, highlighting the need for more rigorous evaluation methodologies. We propose a novel phenomenological approach that goes beyond traditional accuracy metrics to probe the underlying mechanisms of model behavior, establishing a framework that could broadly impact how we analyze and understand AI systems. Using positional bias in multiple-choice reasoning tasks as a case study, we demonstrate how systematic perturbations can reveal fundamental aspects of model decision-making. To analyze these behaviors, we develop two complementary phenomenological models: a Probabilistic Mixture Model (PMM) that decomposes model responses into reasoning, memorization, and guessing components and an Information-Theoretic Consistency (ITC) analysis that quantifies the relationship between model confidence and strategy selection. Through controlled experiments on reasoning benchmarks, we show that true reasoning remains challenging for current models, with apparent success often relying on sophisticated combinations of memorization and pattern matching rather than genuine logical deduction. More fundamentally, we demonstrate that accuracy alone often overstates a model's reasoning abilities, as model behavior can be characterized through underlying mechanisms in the phase space of cognitive strategies, revealing how models dynamically balance different approaches when responding to queries. This framework enables quantitative criteria for real-world deployments, allowing applications to specify reliability thresholds based on strategy distributions rather than aggregate performance metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13833v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santosh Kumar Radha, Oktay Goktas</dc:creator>
    </item>
    <item>
      <title>Threshold Selection for Iterative Decoding of $(v,w)$-regular Binary Codes</title>
      <link>https://arxiv.org/abs/2501.13865</link>
      <description>arXiv:2501.13865v1 Announce Type: cross 
Abstract: Iterative bit flipping decoders are an efficient and effective decoder choice for decoding codes which admit a sparse parity-check matrix. Among these, sparse $(v,w)$-regular codes, which include LDPC and MDPC codes are of particular interest both for efficient data correction and the design of cryptographic primitives. In attaining the decoding the choice of the bit flipping thresholds, which can be determined either statically, or during the decoder execution by using information coming from the initial syndrome value and its updates. In this work, we analyze a two-iterations parallel hard decision bit flipping decoders and propose concrete criteria for threshold determination, backed by a closed form model. In doing so, we introduce a new tightly fitting model for the distribution of the Hamming weight of the syndrome after the first decoder iteration and substantial improvements on the DFR estimation with respect to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13865v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandro Annechini, Alessandro Barenghi, Gerardo Pelosi</dc:creator>
    </item>
    <item>
      <title>Universal optimality of $T$-avoiding spherical codes and designs</title>
      <link>https://arxiv.org/abs/2501.13906</link>
      <description>arXiv:2501.13906v1 Announce Type: cross 
Abstract: Given an open set (a union of open intervals), $T\subset [-1,1]$ we introduce the concepts of $T$-avoiding spherical codes and designs, that is, spherical codes that have no inner products in the set $T$. We show that certain codes found in the minimal vectors of the Leech lattices, as well as the minimal vectors of the Barnes--Wall lattice and codes derived from strongly regular graphs, are universally optimal in the restricted class of $T$-avoiding codes. We also extend a result of Delsarte--Goethals--Seidel about codes with three inner products $\alpha, \beta, \gamma$ (in our terminology $(\alpha,\beta)$-avoiding $\gamma$-codes). Parallel to the notion of tight spherical designs, we also derive that these codes are minimal (tight) $T$-avoiding spherical designs of fixed dimension and strength. In some cases, we also find that codes under consideration have maximal cardinality in their $T$-avoiding class for given dimension and minimum distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13906v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.MG</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. G. Boyvalenkov, D. D. Cherkashin, P. D. Dragnev</dc:creator>
    </item>
    <item>
      <title>Efficient Mitigation of Error Floors in Quantum Error Correction using Non-Binary Low-Density Parity-Check Codes</title>
      <link>https://arxiv.org/abs/2501.13923</link>
      <description>arXiv:2501.13923v1 Announce Type: cross 
Abstract: In this paper, we propose an efficient method to reduce error floors in quantum error correction using non-binary low-density parity-check (LDPC) codes. We identify and classify cycle structures in the parity-check matrix where estimated noise becomes trapped, and develop tailored decoding methods for each cycle type. For Type-I cycles, we propose a method to make the difference between estimated and true noise degenerate. Type-II cycles are shown to be uncorrectable, while for Type-III cycles, we utilize the fact that cycles in non-binary LDPC codes do not necessarily correspond to codewords, allowing us to estimate the true noise. Our method significantly improves decoding performance and reduces error floors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13923v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenta Kasai</dc:creator>
    </item>
    <item>
      <title>Order Optimal Cascaded Code Distributed Computing With Low Complexity and Improved Flexibility</title>
      <link>https://arxiv.org/abs/2307.14927</link>
      <description>arXiv:2307.14927v3 Announce Type: replace 
Abstract: Coded distributed computing (CDC), proposed by Li \emph{et al.}, offers significant potential for reducing the communication load in MapReduce computing systems. In cascaded CDC with $K$ nodes, $N$ input files, and $Q$ output functions, each input file will be mapped by $r\geq 1$ nodes and each output function will be computed by $s&gt;1$ nodes such that coding techniques can be applied to generate multicast opportunities. However, a significant limitation of most existing coded distributed computing schemes is their requirement to split the original data into a large number of input files (or output functions) that grows exponentially with $K$, which significantly increases the coding complexity and degrades the system performance. In this paper, we focus on the case of $K/s\in\mathbb{N}$, deliberately designing the strategy of data placement and output functions assignment, such that a low-complexity CDC scheme is achievable. The main advantages of the proposed scheme include: 1) the multicast gains equal to $(r+s-1)(1-1/s)$ and $r+s-1$ which is approximately $r+s-1$ when $s$ is relatively large, and the communication load potentially better than the well-known scheme proposed by Li \emph{et al.}; 2) the proposed scheme requires significantly less input files and output functions; 3) all the operations are implemented over the binary field $\mathbb{F}_2$ with the one-shot fashion (i.e., each node can decode its requested content immediately upon receiving the multicast message during the current time slot). Finally, we derive a new information-theoretic converse bound for the cascaded CDC framework under the proposed strategies of data placement and output functions assignment. We demonstrate that the communication load of the proposed scheme is order optimal within a factor of $2$; and is also approximately optimal when $K$ is sufficiently large for a given $r$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14927v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingming Zhang, Youlong Wu, Minquan Cheng, Dianhua Wu</dc:creator>
    </item>
    <item>
      <title>Performance of Double-Stacked Intelligent Metasurface-Assisted Multiuser Massive MIMO Communications in the Wave Domain</title>
      <link>https://arxiv.org/abs/2402.16405</link>
      <description>arXiv:2402.16405v2 Announce Type: replace 
Abstract: Although reconfigurable intelligent surface (RIS) is a promising technology for shaping the propagation environment, it consists of a single-layer structure within inherent limitations regarding the number of beam steering patterns. Based on the recently revolutionary technology, denoted as stacked intelligent metasurface (SIM), we propose its implementation not only on the base station (BS) side in a massive multiple-input multiple-output (mMIMO) setup but also in the intermediate space between the base station and the users to adjust the environment further as needed. For the sake of convenience, we call the former BS SIM (BSIM), and the latter channel SIM (CSIM). Hence, we achieve wave-based combining at the BS and wave-based configuration at the intermediate space. Specifically, we propose a channel estimation method with reduced overhead, being crucial for SIMassisted communications. Next, we derive the uplink sum spectral efficiency (SE) in closed form in terms of statistical channel state information (CSI). Notably, we optimize the phase shifts of both BSIM and CSIM simultaneously by using the projected gradient ascent method (PGAM). Compared to previous works on SIMs, we study the uplink transmission, a mMIMO setup, channel estimation in a single phase, a second SIM at the intermediate space, and simultaneous optimization of the two SIMs. Simulation results show the impact of various parameters on the sum SE, and demonstrate the superiority of our optimization approach compared to the alternating optimization (AO) method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16405v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasios Papazafeiropoulos, Pandelis Kourtessis, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Learning-Based Compress-and-Forward Schemes for the Relay Channel</title>
      <link>https://arxiv.org/abs/2405.09534</link>
      <description>arXiv:2405.09534v2 Announce Type: replace 
Abstract: The relay channel, consisting of a source-destination pair along with a relay, is a fundamental component of cooperative communications. While the capacity of a general relay channel remains unknown, various relaying strategies, including compress-and-forward (CF), have been proposed. In CF, the relay forwards a quantized version of its received signal to the destination. Given the correlated signals at the relay and destination, distributed compression techniques, such as Wyner--Ziv coding, can be harnessed to utilize the relay-to-destination link more efficiently. Leveraging recent advances in neural network-based distributed compression, we revisit the relay channel problem and integrate a learned task-aware Wyner--Ziv compressor into a primitive relay channel with a finite-capacity out-of-band relay-to-destination link. The resulting neural CF scheme demonstrates that our compressor recovers binning of the quantized indices at the relay, mimicking the optimal asymptotic CF strategy, although no structure exploiting the knowledge of source statistics was imposed into the design. The proposed neural CF, employing finite order modulation, operates closely to the rate achievable in a primitive relay channel with a Gaussian codebook. We showcase the advantages of exploiting the correlated destination signal for relay compression through various neural CF architectures that involve end-to-end training of the compressor and the demodulator components. Our learned task-oriented compressors provide the first proof-of-concept work toward interpretable and practical neural CF relaying schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09534v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ezgi Ozyilkan, Fabrizio Carpi, Siddharth Garg, Elza Erkip</dc:creator>
    </item>
    <item>
      <title>Coded Beam Training for RIS Assisted Wireless Communications</title>
      <link>https://arxiv.org/abs/2406.15802</link>
      <description>arXiv:2406.15802v2 Announce Type: replace 
Abstract: Reconfigurable intelligent surface (RIS) is considered as one of the key technologies for future 6G communications. To fully unleash the performance of RIS, accurate channel state information (CSI) is crucial. Beam training is widely utilized to acquire the CSI. However, before aligning the beam correctly to establish stable connections, the signal-to-noise ratio (SNR) at UE is inevitably low, which reduces the beam training accuracy. To deal with this problem, we exploit the coded beam training framework for RIS systems, which leverages the error correction capability of channel coding to improve the beam training accuracy under low SNR. Specifically, we first extend the coded beam training framework to RIS systems by decoupling the base station-RIS channel and the RIS-user channel. For this framework, codewords that accurately steer to multiple angles is essential for fully unleashing the error correction capability. In order to realize effective codeword design in RIS systems, we then propose a new codeword design criterion, based on which we propose a relaxed Gerchberg-Saxton (GS) based codeword design scheme by considering the constant modulus constraints of RIS elements. In addition, considering the two dimensional structure of RIS, we further propose a dimension reduced encoder design scheme, which can not only guarentee a better beam shape, but also enable a stronger error correction capability. Simulation results reveal that the proposed scheme can realize effective and accurate beam training in low SNR scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15802v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhao Chen, Linglong Dai</dc:creator>
    </item>
    <item>
      <title>What If We Had Used a Different App? Reliable Counterfactual KPI Analysis in Wireless Systems</title>
      <link>https://arxiv.org/abs/2410.00150</link>
      <description>arXiv:2410.00150v3 Announce Type: replace 
Abstract: In modern wireless network architectures, such as Open Radio Access Network (O-RAN), the operation of the radio access network (RAN) is managed by applications, or apps for short, deployed at intelligent controllers. These apps are selected from a given catalog based on current contextual information. For instance, a scheduling app may be selected on the basis of current traffic and network conditions. Once an app is chosen and run, it is no longer possible to directly test the key performance indicators (KPIs) that would have been obtained with another app. In other words, we can never simultaneously observe both the actual KPI, obtained by the selected app, and the counterfactual KPI, which would have been attained with another app, for the same network condition, making individual-level counterfactual KPIs analysis particularly challenging. This what-if analysis, however, would be valuable to monitor and optimize the network operation, e.g., to identify suboptimal app selection strategies. This paper addresses the problem of estimating the values of KPIs that would have been obtained if a different app had been implemented by the RAN. To this end, we propose a conformal-prediction-based counterfactual analysis method for wireless systems that provides reliable error bars for the estimated KPIs, despite the inherent covariate shift between logged and test data. Experimental results for medium access control-layer apps and for physical-layer apps demonstrate the merits of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00150v3</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushuo Hou, Sangwoo Park, Matteo Zecchin, Yunlong Cai, Guanding Yu, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Higher-Order Staircase Codes: A Unified Generalization of High-Throughput Coding Techniques</title>
      <link>https://arxiv.org/abs/2410.16504</link>
      <description>arXiv:2410.16504v2 Announce Type: replace 
Abstract: We introduce a unified generalization of several well-established high-throughput coding techniques including staircase codes, tiled diagonal zipper codes, continuously interleaved codes, open forward error correction (OFEC) codes, and Robinson-Bernstein convolutional codes as special cases. This generalization which we term "higher-order staircase codes" arises from the marriage of two distinct combinatorial objects: difference triangle sets and finite-geometric nets, which have typically been applied separately to code design. We illustrate one possible realization of these codes, obtaining powerful, high-rate, low-error-floor, and low-complexity coding schemes based on simple iterative syndrome-domain decoding of coupled Hamming component codes. We study some properties of difference triangle sets having minimum scope and sum-of-lengths, which correspond to memory-optimal higher-order staircase codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16504v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohannad Shehadeh, Frank R. Kschischang</dc:creator>
    </item>
    <item>
      <title>New Channel Coding Lower Bounds for Noisy Permutation Channels</title>
      <link>https://arxiv.org/abs/2412.06497</link>
      <description>arXiv:2412.06497v5 Announce Type: replace 
Abstract: Motivated by the application of point-to-point communication networks and biological storage, we investigate new achievability bounds for noisy permutation channels with strictly positive and full-rank square matrices. Our new bounds use $\epsilon$-packing with Kullback-Leibler divergence as a metric to bound the distance between distributions and are tighter than existing bounds. Additionally, Gaussian approximations of achievability bounds are derived, and the numerical evaluation shows the precision of the approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06497v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lugaoze Feng, Xunan Li, Guocheng Lv, Ye jin</dc:creator>
    </item>
    <item>
      <title>On the structure of the Schur squares of Twisted Generalized Reed-Solomon codes and application to cryptanalysis</title>
      <link>https://arxiv.org/abs/2412.15160</link>
      <description>arXiv:2412.15160v2 Announce Type: replace 
Abstract: Twisted generalized Reed-Solomon (TGRS) codes constitute an interesting family of evaluation codes, containing a large class of maximum distance separable codes non-equivalent to generalized Reed-Solomon (GRS) ones. Moreover, the Schur squares of TGRS codes may be much larger than those of GRS codes with same dimension. Exploiting these structural differences, in 2018, Beelen, Bossert, Puchinger and Rosenkilde proposed a subfamily of Maximum Distance Separable (MDS) Twisted Reed-Solomon (TRS) codes over $\mathbb{F}_q$ with $\ell$ twists $q \approx n^{2^{\ell}}$ for McEliece encryption, claiming their resistance to both Sidelnikov Shestakov attack and Schur products--based attacks. In short, they claimed these codes to resist to classical key recovery attacks on McEliece encryption scheme instantiated with Reed-Solomon (RS) or GRS codes. In 2020, Lavauzelle and Renner presented an original attack on this system based on the computation of the subfield subcode of the public TRS code.
  In this paper, we show that the original claim on the resistance of TRS and TGRS codes to Schur products based--attacks is wrong. We identify a broad class of codes including TRS and TGRS ones that is distinguishable from random by computing the Schur square of some shortening of the code. Then, we focus on the case of single twist (i.e., $\ell = 1$), which is the most efficient one in terms of decryption complexity, to derive an attack. The technique is similar to the distinguisher-based attacks of RS code-based systems given by Couvreur, Gaborit, Gauthier-Uma\~na, Otmani, Tillich in 2014.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15160v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alain Couvreur, Rakhi Pratihar, Nihan Tan{\i}sal{\i}, Ilaria Zappatore</dc:creator>
    </item>
    <item>
      <title>Robust Joint Message and State Transmission under Arbitrarily Varying Jamming</title>
      <link>https://arxiv.org/abs/2501.10896</link>
      <description>arXiv:2501.10896v2 Announce Type: replace 
Abstract: Joint message and state transmission under arbitrarily varying jamming attack is investigated. An inner bound of the robust capacity-distortion region is provided, which includes the worst-case communication rate and the worst-case estimation rate. The bound is optimal for the joint message and lossless state communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10896v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqi Chen, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Multi-Stage Active Sequential Hypothesis Testing with Clustered Hypotheses</title>
      <link>https://arxiv.org/abs/2501.11459</link>
      <description>arXiv:2501.11459v3 Announce Type: replace 
Abstract: We consider the problem where an active Decision-Maker (DM) is tasked to identify the true hypothesis using as few as possible observations while maintaining accuracy. The DM collects observations according to its determined actions and knows the distributions under each hypothesis. We propose a deterministic and adaptive multi-stage hypothesis-elimination strategy where the DM selects an action, applies it repeatedly, and discards hypotheses in light of its obtained observations. The DM selects actions based on maximal separation expressed by the distance between the parameter vectors of each distribution under each hypothesis. Close distributions can be clustered, simplifying the search and significantly reducing the number of required observations.
  Our algorithms achieve vanishing Average Bayes Risk (ABR) as the error probability approaches zero, i.e., the algorithm is asymptotically optimal. Furthermore, we show that the ABR is bounded when the number of hypotheses grows. Simulations are carried out to evaluate the algorithm's performance compared to another multi-stage hypothesis-elimination algorithm, where an improvement of several orders of magnitude in the mean number of observations required is observed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11459v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Vershinin, Asaf Cohen, Omer Gurewitz</dc:creator>
    </item>
    <item>
      <title>CAT and DOG: Improved Codes for Private Distributed Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2501.12371</link>
      <description>arXiv:2501.12371v2 Announce Type: replace 
Abstract: We present novel constructions of polynomial codes for private distributed matrix multiplication (PDMM/SDMM) using outer product partitioning (OPP). We extend the degree table framework from the literature to cyclic-addition degree tables (CATs). By using roots of unity as evaluation points, we enable modulo-addition in the table. Based on CATs, we present an explicit construction, called CATx, that requires fewer workers than existing schemes in the low-privacy regime. Additionally, we present new families of schemes based on conventional degree tables, called GASPrs and DOGrs, that outperform the state-of-the-art for a wide range of parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12371v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hofmeister, Rawad Bitar, Antonia Wachter-Zeh</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Non-Adaptive Group Testing with Markovian Correlation</title>
      <link>https://arxiv.org/abs/2501.12588</link>
      <description>arXiv:2501.12588v2 Announce Type: replace 
Abstract: We study a correlated group testing model where items are infected according to a Markov chain, which creates bursty binfection patterns. Focusing on a very sparse infections regime, we propose a non adaptive testing strategy with an efficient decoding scheme that is nearly optimal. Specifically, it achieves asymptotically vanishing error with a number of tests that is within a $1/\ln(2) \approx 1.44$ multiplicative factor of the fundamental entropy bound a result that parallels the independent group testing setting. We show that the number of tests reduces with an increase in the expected burst length of infected items, quantifying the advantage of exploiting correlation in test design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12588v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Narayan Ravi, Ilan Shomorony</dc:creator>
    </item>
    <item>
      <title>Robust Hypothesis Testing with Abstention</title>
      <link>https://arxiv.org/abs/2501.12938</link>
      <description>arXiv:2501.12938v2 Announce Type: replace 
Abstract: We study the binary hypothesis testing problem where an adversary may potentially corrupt a fraction of the samples. The detector is, however, permitted to abstain from making a decision if (and only if) the adversary is present. We consider a few natural "contamination models" and characterize for them the trade-off between the error exponents of the four types of errors -- errors of deciding in favour of the incorrect hypothesis when the adversary is present and errors of abstaining or deciding in favour of the wrong hypothesis when the adversary is absent, under the two hypotheses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12938v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Malhar A. Managoli, K. R. Sahasranand, Vinod M. Prabhakaran</dc:creator>
    </item>
    <item>
      <title>Guaranteed Recovery of Unambiguous Clusters</title>
      <link>https://arxiv.org/abs/2501.13093</link>
      <description>arXiv:2501.13093v2 Announce Type: replace 
Abstract: Clustering is often a challenging problem because of the inherent ambiguity in what the "correct" clustering should be. Even when the number of clusters $K$ is known, this ambiguity often still exists, particularly when there is variation in density among different clusters, and clusters have multiple relatively separated regions of high density. In this paper we propose an information-theoretic characterization of when a $K$-clustering is ambiguous, and design an algorithm that recovers the clustering whenever it is unambiguous. This characterization formalizes the situation when two high density regions within a cluster are separable enough that they look more like two distinct clusters than two truly distinct clusters in the clustering. The algorithm first identifies $K$ partial clusters (or "seeds") using a density-based approach, and then adds unclustered points to the initial $K$ partial clusters in a greedy manner to form a complete clustering. We implement and test a version of the algorithm that is modified to effectively handle overlapping clusters, and observe that it requires little parameter selection and displays improved performance on many datasets compared to widely used algorithms for non-convex cluster recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13093v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kayvon Mazooji, Ilan Shomorony</dc:creator>
    </item>
    <item>
      <title>On the Service Rate Region of Reed-Muller Codes</title>
      <link>https://arxiv.org/abs/2501.13105</link>
      <description>arXiv:2501.13105v2 Announce Type: replace 
Abstract: We study the Service Rate Region (SRR) of Reed-Muller (RM) codes in the context of distributed storage systems. The SRR is a convex polytope comprising all achievable data access request rates under a given coding scheme. It represents a critical metric for evaluating system efficiency and scalability. Using the geometric properties of RM codes, we characterize recovery sets for data objects, including their existence, uniqueness, and enumeration. This analysis reveals a connection between recovery sets and minimum-weight codewords in the dual RM code, providing a framework for identifying small recovery sets. Using these results, we derive explicit and tight bounds for the maximal achievable demand for individual data objects, which define the maximal simplex within the service rate region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13105v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin, V. Lalitha</dc:creator>
    </item>
    <item>
      <title>Distributed Quantum Hypothesis Testing under Zero-rate Communication Constraints</title>
      <link>https://arxiv.org/abs/2410.08937</link>
      <description>arXiv:2410.08937v2 Announce Type: replace-cross 
Abstract: The trade-offs between error probabilities in quantum hypothesis testing are by now well-understood in the centralized setting, but much less is known for distributed settings. Here, we study a distributed binary hypothesis testing problem to infer a bipartite quantum state shared between two remote parties, where one of these parties communicates to the tester at zero-rate, while the other party communicates to the tester at zero-rate or higher. As our main contribution, we derive an efficiently computable single-letter formula for the Stein's exponent of this problem, when the state under the alternative is product. For the general case, we show that the Stein's exponent when (at least) one of the parties communicates classically at zero-rate is given by a multi-letter expression involving max-min optimization of regularized measured relative entropy. While this becomes single-letter for the fully classical case, we further prove that this already does not happen in the same way for classical-quantum states in general. As a key tool for proving the converse direction of our results, we develop a quantum version of the blowing-up lemma which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08937v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sreejith Sreekumar, Christoph Hirche, Hao-Chung Cheng, Mario Berta</dc:creator>
    </item>
    <item>
      <title>The Interference Channel with Entangled Transmitters</title>
      <link>https://arxiv.org/abs/2411.10067</link>
      <description>arXiv:2411.10067v2 Announce Type: replace-cross 
Abstract: This paper explores communication over a two-sender, two-receiver classical interference channel, enhanced by the availability of entanglement resources between transmitters. The central contributions are an inner and outer bound on the capacity region for a general interference channel with entangled transmitters. It addresses the persistent challenge of the lack of a general capacity formula, even in the purely classical case, and highlights the striking similarities in achievable rate expressions when assessing quantum advantages. Through a concrete example, it is shown that entanglement can significantly boost performance in certain types of channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10067v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Hawellek, Athin Mohan, Hadi Aghaee, Christian Deppe</dc:creator>
    </item>
    <item>
      <title>Continuous-variable designs and design-based shadow tomography from random lattices</title>
      <link>https://arxiv.org/abs/2412.17909</link>
      <description>arXiv:2412.17909v2 Announce Type: replace-cross 
Abstract: We investigate state designs for continuous-variable quantum systems using the aid of lattice-like quantum states. These are code states of Gottesman-Kitaev-Preskill (GKP) codes. We show that for an n-mode system, the set of all GKP states forms a rigged continuous-variable state 2-design. We use these lattice state designs to construct a continuous variable shadow tomography protocol, derive sample complexity bounds for both global- and local GKP shadows under reasonable physical assumptions, and provide the physical gadgets needed to implement this protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17909v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OA</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Conrad, Joseph T. Iosue, Ansgar G. Burchards, Victor V. Albert</dc:creator>
    </item>
    <item>
      <title>Quantum Error Correction near the Coding Theoretical Bound</title>
      <link>https://arxiv.org/abs/2412.21171</link>
      <description>arXiv:2412.21171v2 Announce Type: replace-cross 
Abstract: Recent advancements in quantum computing have led to the realization of systems comprising tens of reliable logical qubits, constructed from thousands of noisy physical qubits. However, many of the critical applications that quantum computers aim to solve require quantum computations involving millions or more logical qubits. This necessitates highly efficient quantum error correction capable of handling large numbers of logical qubits. Classical error correction theory is well-developed, with low-density parity-check (LDPC) codes achieving performance limits by encoding large classical bits. Despite more than two decades of effort, no efficiently decodable quantum error-correcting code that approaches the hashing bound, which is a fundamental lower bound on quantum capacity, had been discovered. Here, we present quantum error-correcting codes constructed from classical LDPC codes that approach the hashing bound while maintaining linear computational complexity in the number of physical qubits. This result establishes a pathway toward realizing large-scale, fault-tolerant quantum computers. By integrating our quantum error correction scheme with devices capable of managing vast numbers of qubits, the prospect of solving critical real-world problems through quantum computation is brought significantly closer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21171v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daiki Komoto, Kenta Kasai</dc:creator>
    </item>
  </channel>
</rss>
