<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Dec 2025 05:00:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Wealth or Stealth? The Camouflage Effect in Insider Trading</title>
      <link>https://arxiv.org/abs/2512.06309</link>
      <description>arXiv:2512.06309v1 Announce Type: new 
Abstract: We consider a Kyle-type model where insider trading takes place among a potentially large population of liquidity traders and is subject to legal penalties. Insiders exploit the liquidity provided by the trading masses to "camouflage" their actions and balance expected wealth with the necessary stealth to avoid detection. Under a diverse spectrum of prosecution schemes, we establish the existence of equilibria for arbitrary population sizes and a unique limiting equilibrium. A convergence analysis determines the scale of insider trading by a stealth index $\gamma$, revealing that the equilibrium can be closely approximated by a simple limit due to diminished price informativeness. Empirical aspects are derived from two calibration experiments using non-overlapping data sets spanning from 1980 to 2018, which underline the indispensable role of a large population in insider trading models with legal risk, along with important implications for the incidence of stealth trading and the deterrent effect of legal enforcement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06309v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Ma, Weixuan Xia, Jianfeng Zhang</dc:creator>
    </item>
    <item>
      <title>AI as "Co-founder": GenAI for Entrepreneurship</title>
      <link>https://arxiv.org/abs/2512.06506</link>
      <description>arXiv:2512.06506v1 Announce Type: new 
Abstract: This paper studies whether, how, and for whom generative artificial intelligence (GenAI) facilitates firm creation. Our identification strategy exploits the November 2022 release of ChatGPT as a global shock that lowered start-up costs and leverages variations across geo-coded grids with differential pre-existing AI-specific human capital. Using high-resolution and universal data on Chinese firm registrations by the end of 2024, we find that grids with stronger AI-specific human capital experienced a sharp surge in new firm formation$\unicode{x2013}$driven entirely by small firms, contributing to 6.0% of overall national firm entry. Large-firm entry declines, consistent with a shift toward leaner ventures. New firms are smaller in capital, shareholder number, and founding team size, especially among small firms. The effects are strongest among firms with potential AI applications, weaker financing needs, and among first-time entrepreneurs. Overall, our results highlight that GenAI serves as a pro-competitive force by disproportionately boosting small-firm entry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06506v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junhui Jeff Cai, Xian Gu, Liugang Sheng, Mengjia Xia, Linda Zhao, Wu Zhu</dc:creator>
    </item>
    <item>
      <title>Tournament-Based Performance Evaluation and Systematic Misallocation: Why Forced Ranking Systems Produce Random Outcomes</title>
      <link>https://arxiv.org/abs/2512.06583</link>
      <description>arXiv:2512.06583v1 Announce Type: new 
Abstract: Tournament-based compensation schemes with forced distributions represent a widely adopted class of relative performance evaluation mechanisms in technology and corporate environments. These systems mandate within-team ranking and fixed distributional requirements (e.g., bottom 15% terminated, top 15% promoted), ostensibly to resolve principal-agent problems through mandatory differentiation. We demonstrate through agent-based simulation that this mechanism produces systematic classification errors independent of implementation quality. With 994 engineers across 142 teams of 7, random team assignment yields 32% error in termination and promotion decisions, misclassifying employees purely through composition variance. Under realistic conditions reflecting differential managerial capability, error rates reach 53%, with false positives and false negatives each exceeding correct classifications. Cross-team calibration (often proposed as remedy) transforms evaluation into influence contests where persuasive managers secure promotions independent of merit. Multi-period dynamics produce adverse selection as employees observe random outcomes, driving risk-averse behavior and high-performer exit. The efficient solution (delegating judgment to managers with hierarchical accountability) cannot be formalized within the legal and coordination constraints that necessitated forced ranking. We conclude that this evaluation mechanism persists not through incentive alignment but through satisfying demands for demonstrable process despite producing outcomes indistinguishable from random allocation. This demonstrates how formalization intended to reduce agency costs structurally increases allocation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06583v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy McEntire</dc:creator>
    </item>
    <item>
      <title>Effectiveness of Carbon Pricing and Compensation Instruments: An Umbrella Review of the Empirical Evidence</title>
      <link>https://arxiv.org/abs/2512.06887</link>
      <description>arXiv:2512.06887v1 Announce Type: new 
Abstract: The growing urgency of the climate crisis has driven the implementation of diverse policy instruments to mitigate greenhouse gas (GHG) emissions. Among them, carbon pricing mechanisms such as carbon taxes and emissions trading systems (ETS), together with voluntary carbon markets (VCM) and compensation programs such as REDD+, are central components of global decarbonization strategies. However, academic and political debate persists regarding their true effectiveness, equity, and integrity. This paper presents an umbrella review of the empirical evidence, synthesizing key findings from systematic reviews and meta-analyses to provide a consolidated picture of the state of knowledge. A rigorous methodology based on PRISMA guidelines is used for study selection, and the methodological quality of included reviews is assessed with AMSTAR-2, while the risk of bias in frequently cited primary studies is examined through ROBINS-I. Results indicate that carbon taxes and ETS have demonstrated moderate effectiveness in reducing emissions, with statistically significant but heterogeneous elasticities across geographies and sectors. Nonetheless, persistent design problems -- such as insufficient price levels and allowance overallocation -- limit their impact. By contrast, compensation markets, especially VCM and REDD+ projects, face systemic critiques regarding integrity, primarily related to additionality, permanence, leakage, and double counting, leading to generalized overestimation of their real climate impact. We conclude that while no instrument is a panacea, compliance-based carbon pricing mechanisms are necessary, though insufficient, tools that require stricter design and higher prices. Voluntary offset mechanisms, in their current state, do not represent a reliable climate solution and may undermine the integrity of climate targets unless they undergo fundamental reform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06887v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ricardo Alonzo Fern\'andez Salguero</dc:creator>
    </item>
    <item>
      <title>Analysing the factors affecting electric vehicle adoption using the extended theory of planned behaviour framework</title>
      <link>https://arxiv.org/abs/2512.07188</link>
      <description>arXiv:2512.07188v1 Announce Type: new 
Abstract: This study uses the Theory of Planned Behaviour (TPB) framework and expands it by including Optimism, Innovativeness and Range Anxiety constructs. In this study, conducted in Lucknow, the capital of India's most populous province (Uttar Pradesh), a multi stage random sampling design was employed to select 432 respondents from different city areas. The survey instruments were adapted from similar studies and suitably modified to suit the context. Using exploratory factor analysis, 18 measurement items converged into six factors, namely attitude, subjective norms, perceived behavioural control, optimism, innovativeness and range anxiety. We confirmed the reliability and validity of the constructs using Cronbach's alpha, composite reliability, average variance extracted and discriminant validity analysis. We explored the relationship between them using structural equation modelling. All factors but Optimism were found to be significantly associated with adoption intention. We further employed mediation analysis to examine the mediation pathways. The TPB components mediated the effect of innovativeness but not range anxiety. The study's insights can help policymakers and marketers design targeted interventions that address consumer concerns, reshape consumer perceptions, and foster greater EV adoption. The interventions can target increasing the mediating variables or decreasing range anxiety to facilitate a smoother transition to sustainable transportation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07188v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pranshu Raghuvanshi (India Institute of Science, Bangalore, India), Anjula Gurtoo (India Institute of Science, Bangalore, India)</dc:creator>
    </item>
    <item>
      <title>Rice Price Dynamics during the 1945--1947 Famine in Post-War Taiwan: A Quantitative Reassessment</title>
      <link>https://arxiv.org/abs/2512.07492</link>
      <description>arXiv:2512.07492v1 Announce Type: new 
Abstract: We compiled the first high-frequency rice price panel for Taiwan from August 1945 to March 1947, during the transition from Japanese rule to China rule. Using regression models, we found that the pattern of rice price changes could be divided into four stages, each with distinct characteristics. Based on different stages, we combined the policies formulated by the Taiwan government at the time to demonstrate the correlation between rice prices and policies. The research results highlight the dominant role of policy systems in post-war food crises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07492v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Huaide Chen, Hailiang Yang</dc:creator>
    </item>
    <item>
      <title>Sell Data to AI Algorithms Without Revealing It: Secure Data Valuation and Sharing via Homomorphic Encryption</title>
      <link>https://arxiv.org/abs/2512.06033</link>
      <description>arXiv:2512.06033v1 Announce Type: cross 
Abstract: The rapid expansion of Artificial Intelligence is hindered by a fundamental friction in data markets: the value-privacy dilemma, where buyers cannot verify a dataset's utility without inspection, yet inspection may expose the data (Arrow's Information Paradox). We resolve this challenge by introducing the Trustworthy Influence Protocol (TIP), a privacy-preserving framework that enables prospective buyers to quantify the utility of external data without ever decrypting the raw assets. By integrating Homomorphic Encryption with gradient-based influence functions, our approach allows for the precise, blinded scoring of data points against a buyer's specific AI model. To ensure scalability for Large Language Models (LLMs), we employ low-rank gradient projections that reduce computational overhead while maintaining near-perfect fidelity to plaintext baselines, as demonstrated across BERT and GPT-2 architectures. Empirical simulations in healthcare and generative AI domains validate the framework's economic potential: we show that encrypted valuation signals achieve a high correlation with realized clinical utility and reveal a heavy-tailed distribution of data value in pre-training corpora where a minority of texts drive capability while the majority degrades it. These findings challenge prevailing flat-rate compensation models and offer a scalable technical foundation for a meritocratic, secure data economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06033v1</guid>
      <category>cs.CR</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael Yang (Eric), Ruijiang Gao (Eric),  Zhiqiang (Eric),  Zheng</dc:creator>
    </item>
    <item>
      <title>PoliFi Tokens and the Trump Effect</title>
      <link>https://arxiv.org/abs/2512.06036</link>
      <description>arXiv:2512.06036v1 Announce Type: cross 
Abstract: Cryptoassets launched by political figures, e.g., political finance (PoliFi) tokens, have recently attracted attention. Chief among them are the eponymous tokens backed by the 47th president and first lady of the United States, TRUMPandMELANIA. We empirically analyze both, and study their impact on the broad decentralized finance (DeFi) ecosystem. Via a comparative longitudinal study, we uncover a "Trump Effect": the behavior of these tokens correlates positively with presidential approval ratings, whereas the same tight coupling does not extend to other cryptoassets and administrations. We additionally quantify the ecosystemic impact, finding that the fervor surrounding the two assets was accompanied by capital flows towards associated platforms like the Solana blockchain, which also enjoyed record volumes and fee expenditure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06036v1</guid>
      <category>physics.soc-ph</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ignacy Nieweglowski, Aviv Yaish, Fahad Saleh, Fan Zhang</dc:creator>
    </item>
    <item>
      <title>The Suicide Region: Option Games and the Race to Artificial General Intelligence</title>
      <link>https://arxiv.org/abs/2512.07526</link>
      <description>arXiv:2512.07526v1 Announce Type: cross 
Abstract: Standard real options theory predicts delay in exercising the option to invest or deploy when extreme asset volatility or technological uncertainty are present. However, in the current race to develop artificial general intelligence (AGI), sovereign actors are exhibiting behaviors contrary to theoretical predictions: the US and China are accelerating AI investment despite acknowledging the potential for catastrophic failure from AGI misalignment. We resolve this puzzle by formalizing the AGI race as a continuous-time preemption game with endogenous existential risk. In our model, the cost of failure is no longer bounded only by the sunk cost of investment (I), but rather a systemic ruin parameter (D) that is correlated with development velocity and shared globally. As the disutility of catastrophe is embedded in both players' payoffs, the risk term mathematically cancels out of the equilibrium indifference condition. This creates a "suicide region" in the investment space where competitive pressures force rational agents to deploy AGI systems early, despite a negative risk-adjusted net present value. Furthermore, we show that "warning shots" (sub-existential disasters) will fail to deter AGI acceleration, as the winner-takes-all nature of the race remains intact. The race can only be halted if the cost of ruin is internalized, making safety research a prerequisite for economic viability. We derive the critical private liability threshold required to restore the option value of waiting and propose mechanism design interventions that can better ensure safe AGI research and socially responsible deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07526v1</guid>
      <category>q-fin.RM</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Tan</dc:creator>
    </item>
    <item>
      <title>The Adoption and Usage of AI Agents: Early Evidence from Perplexity</title>
      <link>https://arxiv.org/abs/2512.07828</link>
      <description>arXiv:2512.07828v1 Announce Type: cross 
Abstract: This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity &amp; Workflow and Learning &amp; Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07828v1</guid>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jeremy Yang, Noah Yonack, Kate Zyskowski, Denis Yarats, Johnny Ho, Jerry Ma</dc:creator>
    </item>
    <item>
      <title>Optimal Investment, Consumption, and Insurance with Durable Goods under Stochastic Depreciation Risk</title>
      <link>https://arxiv.org/abs/1903.00631</link>
      <description>arXiv:1903.00631v2 Announce Type: replace 
Abstract: We study an infinite-horizon optimal investment, consumption and insurance problem for an economic agent who consumes a perishable and a durable good. The agent trades in a risk-free asset, a risky asset, and a durable good whose price follows a correlated diffusion, while the stock of the durable good depreciates deterministically and is subject to insurable Poisson loss shocks. The agent can partially hedge these shocks via an insurance contract with loading and chooses optimal perishable consumption, portfolio holdings, and insurance coverage to maximise expected discounted CRRA utility. Exploiting the homogeneity of the problem, we reduce the Hamilton--Jacobi--Bellman equation to a static one-dimensional optimisation over constant portfolio shares and derive a semi-explicit optimal strategy. We then prove a verification theorem for the associated jump-diffusion wealth process with insurance, establishing the existence and optimality of this constant-fraction strategy under explicit transversality conditions for both risk-aversion regimes $0&lt;\gamma&lt;1$ and $\gamma&gt;1$. Numerical experiments illustrate the impact of stochastic depreciation risk and insurance loading on the optimal allocation to financial assets, durable goods, and insurance coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:1903.00631v2</guid>
      <category>econ.GN</category>
      <category>q-fin.CP</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Arandjelovi\'c, Ryle S. Perera, Pavel V. Shevchenko, Tak Kuen Siu, Jin Sun</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion under Observed Demand Shocks</title>
      <link>https://arxiv.org/abs/2502.15084</link>
      <description>arXiv:2502.15084v4 Announce Type: replace 
Abstract: This paper examines how the observability of demand shocks influences pricing patterns and market outcomes when firms delegate pricing decisions to Q-learning algorithms. Simulations show that demand observability induces Q-learning agents to adapt prices to demand fluctuations, giving rise to distinctive demand-contingent pricing patterns across the discount factor $\delta$, consistent with Rotemberg and Saloner (1986). When $\delta$ is high, they learn procyclical pricing, charging higher prices in higher demand states. In contrast, at low $\delta$, they lower prices during booms and raise them during downturns, exhibiting countercyclical pricing. Q-learning agents also autonomously sustain supracompetitive profits, indicating that demand observability does not hinder algorithmic collusion. I further explore how the information available to algorithms shapes their learned pricing behavior. Overall, the results suggest that, through pure trial and error, Q-learning algorithms internalize both the stronger deviation incentives during booms and the trade-off between short-term gains and long-term continuation values governed by the discount factor, thereby reproducing the cyclicality of pricing patterns predicted by collusion theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15084v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zexin Ye</dc:creator>
    </item>
    <item>
      <title>Attention vs Choice in Welfare Take-Up: What Works for WIC?</title>
      <link>https://arxiv.org/abs/2506.03457</link>
      <description>arXiv:2506.03457v5 Announce Type: replace 
Abstract: Incomplete take-up of welfare benefits remains a major policy puzzle. This paper decomposes the causes of incomplete welfare take-up into two mechanisms: inattention, where households do not consider program participation, and active choice, where households consider participation but find it not worthwhile. To capture these two mechanisms, we model households' take-up decision as a two-stage process: attention followed by choice. Applied to NLSY97 data on the Special Supplemental Nutrition Program for Women, Infants, and Children (WIC), our model reveals substantial household-level heterogeneity in both attention and choice probabilities. Furthermore, counterfactual simulations predict that choice-nudging policies outperform attention-boosting policies. We test this prediction using data from the WIC2Five pilot program that sent choice-nudging and attention-boosting text messages to different households. Consistent with the counterfactual prediction, choice-nudging messages increased retention much more effectively than attention-boosting messages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03457v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lei Bill Wang, Sooa Ahn</dc:creator>
    </item>
    <item>
      <title>The AI Productivity Index (APEX)</title>
      <link>https://arxiv.org/abs/2509.25721</link>
      <description>arXiv:2509.25721v5 Announce Type: replace 
Abstract: We present an extended version of the AI Productivity Index (APEX-v1-extended), a benchmark for assessing whether frontier models are capable of performing economically valuable tasks in four jobs: investment banking associate, management consultant, big law associate, and primary care physician (MD). This technical report details the extensions to APEX-v1, including an increase in the held-out evaluation set from n = 50 to n = 100 cases per job (n = 400 total) and updates to the grading methodology. We present a new leaderboard, where GPT5 (Thinking = High) remains the top performing model with a score of 67.0%. APEX-v1-extended shows that frontier models still have substantial limitations when performing typical professional tasks. To support further research, we are open sourcing n = 25 non-benchmark example cases per role (n = 100 total) along with our evaluation harness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25721v5</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bertie Vidgen, Abby Fennelly, Evan Pinnix, Julien Benchek, Daniyal Khan, Zach Richards, Austin Bridges, Calix Huang, Ben Hunsberger, Isaac Robinson, Akul Datta, Chirag Mahapatra, Dominic Barton, Cass R. Sunstein, Eric Topol, Brendan Foody, Osvald Nitski</dc:creator>
    </item>
    <item>
      <title>Gas supply shocks, uncertainty and price setting: evidence from Italian firms</title>
      <link>https://arxiv.org/abs/2510.03792</link>
      <description>arXiv:2510.03792v4 Announce Type: replace 
Abstract: This paper examines how natural gas supply shocks affect Italian firms' pricing decisions and inflation expectations using quarterly survey data from the Bank of Italy's Survey on Inflation and Growth Expectations (SIGE). We identify natural gas supply shocks through an external IV-VAR approach exploiting likely unexpected news about interruption to gas supplies to Europe. Our findings show that although gas supply shocks do not have huge effects on gas quantity and only modest effect on gas inventories, they are quickly transmitted to spot electricity prices with persistent effects. We then estimate a proxy internalizing BVAR incorporating firm-level variables from SIGE, documenting that gas supply shocks raise firms' current and expected prices as well as inflation uncertainty. Finally, we uncover substantial nonlinearities using state-dependent local projections: under high inflation uncertainty, firms successfully pass cost increases on to consumers, sustaining elevated prices; under low uncertainty, recessionary effects dominate, leading firms to cut prices below baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03792v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppe Pagano Giorgianni</dc:creator>
    </item>
  </channel>
</rss>
