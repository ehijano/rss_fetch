<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Jun 2024 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Simultaneous incremental support adjustment and metagame solving: An equilibrium-finding framework for continuous-action games</title>
      <link>https://arxiv.org/abs/2406.08683</link>
      <description>arXiv:2406.08683v1 Announce Type: new 
Abstract: We present a framework for computing approximate mixed-strategy Nash equilibria of continuous-action games. It is a modification of the traditional double oracle algorithm, extended to multiple players and continuous action spaces. Unlike prior methods, it maintains fixed-cardinality pure strategy sets for each player. Thus, unlike prior methods, only a constant amount of memory is necessary. Furthermore, it does not require exact metagame solving on each iteration, which can be computationally expensive for large metagames. Moreover, it does not require global best-response computation on each iteration, which can be computationally expensive or even intractable for high-dimensional action spaces and general games. Our method incrementally reduces the exploitability of the strategy profile in the finite metagame, pushing it toward Nash equilibrium. Simultaneously, it incrementally improves the pure strategies that best respond to this strategy profile in the full game. We evaluate our method on various continuous-action games, showing that it obtains approximate mixed-strategy Nash equilibria with low exploitability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08683v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Martin, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>Equilibrium Selection for Multi-agent Reinforcement Learning: A Unified Framework</title>
      <link>https://arxiv.org/abs/2406.08844</link>
      <description>arXiv:2406.08844v1 Announce Type: new 
Abstract: While there are numerous works in multi-agent reinforcement learning (MARL), most of them focus on designing algorithms and proving convergence to a Nash equilibrium (NE) or other equilibrium such as coarse correlated equilibrium. However, NEs can be non-unique and their performance varies drastically. Thus, it is important to design algorithms that converge to Nash equilibrium with better rewards or social welfare. In contrast, classical game theory literature has extensively studied equilibrium selection for multi-agent learning in normal-form games, demonstrating that decentralized learning algorithms can asymptotically converge to potential-maximizing or Pareto-optimal NEs. These insights motivate this paper to investigate equilibrium selection in the MARL setting. We focus on the stochastic game model, leveraging classical equilibrium selection results from normal-form games to propose a unified framework for equilibrium selection in stochastic games. The proposed framework is highly modular and can extend various learning rules and their corresponding equilibrium selection results from normal-form games to the stochastic game setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08844v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Jeff Shamma, Na Li</dc:creator>
    </item>
    <item>
      <title>Roping in Uncertainty: Robustness and Regularization in Markov Games</title>
      <link>https://arxiv.org/abs/2406.08847</link>
      <description>arXiv:2406.08847v1 Announce Type: new 
Abstract: We study robust Markov games (RMG) with $s$-rectangular uncertainty. We show a general equivalence between computing a robust Nash equilibrium (RNE) of a $s$-rectangular RMG and computing a Nash equilibrium (NE) of an appropriately constructed regularized MG. The equivalence result yields a planning algorithm for solving $s$-rectangular RMGs, as well as provable robustness guarantees for policies computed using regularized methods. However, we show that even for just reward-uncertain two-player zero-sum matrix games, computing an RNE is PPAD-hard. Consequently, we derive a special uncertainty structure called efficient player-decomposability and show that RNE for two-player zero-sum RMG in this class can be provably solved in polynomial time. This class includes commonly used uncertainty sets such as $L_1$ and $L_\infty$ ball uncertainty sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08847v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy McMahan, Giovanni Artiglio, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Characterising Interventions in Causal Games</title>
      <link>https://arxiv.org/abs/2406.09318</link>
      <description>arXiv:2406.09318v1 Announce Type: new 
Abstract: Causal games are probabilistic graphical models that enable causal queries to be answered in multi-agent settings. They extend causal Bayesian networks by specifying decision and utility variables to represent the agents' degrees of freedom and objectives. In multi-agent settings, whether each agent decides on their policy before or after knowing the causal intervention is important as this affects whether they can respond to the intervention by adapting their policy. Consequently, previous work in causal games imposed chronological constraints on permissible interventions. We relax this by outlining a sound and complete set of primitive causal interventions so the effect of any arbitrarily complex interventional query can be studied in multi-agent settings. We also demonstrate applications to the design of safe AI systems by considering causal mechanism design and commitment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09318v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuj Mishra, James Fox, Michael Wooldridge</dc:creator>
    </item>
    <item>
      <title>IMFL-AIGC: Incentive Mechanism Design for Federated Learning Empowered by Artificial Intelligence Generated Content</title>
      <link>https://arxiv.org/abs/2406.08526</link>
      <description>arXiv:2406.08526v1 Announce Type: cross 
Abstract: Federated learning (FL) has emerged as a promising paradigm that enables clients to collaboratively train a shared global model without uploading their local data. To alleviate the heterogeneous data quality among clients, artificial intelligence-generated content (AIGC) can be leveraged as a novel data synthesis technique for FL model performance enhancement. Due to various costs incurred by AIGC-empowered FL (e.g., costs of local model computation and data synthesis), however, clients are usually reluctant to participate in FL without adequate economic incentives, which leads to an unexplored critical issue for enabling AIGC-empowered FL. To fill this gap, we first devise a data quality assessment method for data samples generated by AIGC and rigorously analyze the convergence performance of FL model trained using a blend of authentic and AI-generated data samples. We then propose a data quality-aware incentive mechanism to encourage clients' participation. In light of information asymmetry incurred by clients' private multi-dimensional attributes, we investigate clients' behavior patterns and derive the server's optimal incentive strategies to minimize server's cost in terms of both model accuracy loss and incentive payments for both complete and incomplete information scenarios. Numerical results demonstrate that our proposed mechanism exhibits highest training accuracy and reduces up to 53.34% of the server's cost with real-world datasets, compared with existing benchmark mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08526v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangjing Huang, Qiong Wu, Jingyi Li, Xu Chen</dc:creator>
    </item>
    <item>
      <title>Matching with Nested and Bundled Pandora Boxes</title>
      <link>https://arxiv.org/abs/2406.08711</link>
      <description>arXiv:2406.08711v1 Announce Type: cross 
Abstract: We consider max-weighted matching with costs for learning the weights, modeled as a "Pandora's Box" on each endpoint of an edge. Each vertex has an initially-unknown value for being matched to a neighbor, and an algorithm must pay some cost to observe this value. The goal is to maximize the total matched value minus costs. Our model is inspired by two-sided settings, such as matching employees to employers. Importantly for such settings, we allow for negative values which cause existing approaches to fail.
  We first prove upper bounds for algorithms in two natural classes. Any algorithm that "bundles" the two Pandora boxes incident to an edge is an $o(1)$-approximation. Likewise, any "vertex-based" algorithm, which uses properties of the separate Pandora's boxes but does not consider the interaction of their value distributions, is an $o(1)$-approximation. Instead, we utilize Pandora's Nested-Box Problem, i.e. multiple stages of inspection. We give a self-contained, fully constructive optimal solution to the nested-boxes problem, which may have structural observations of interest compared to prior work. By interpreting each edge as a nested box, we leverage this solution to obtain a constant-factor approximation algorithm. Finally, we show any ``edge-based'' algorithm, which considers the interactions of values along an edge but not with the rest of the graph, is also an $o(1)$-approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08711v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Bowers, Bo Waggoner</dc:creator>
    </item>
    <item>
      <title>ElicitationGPT: Text Elicitation Mechanisms via Language Models</title>
      <link>https://arxiv.org/abs/2406.09363</link>
      <description>arXiv:2406.09363v1 Announce Type: cross 
Abstract: Scoring rules evaluate probabilistic forecasts of an unknown state against the realized state and are a fundamental building block in the incentivized elicitation of information and the training of machine learning models. This paper develops mechanisms for scoring elicited text against ground truth text using domain-knowledge-free queries to a large language model (specifically ChatGPT) and empirically evaluates their alignment with human preferences. The empirical evaluation is conducted on peer reviews from a peer-grading dataset and in comparison to manual instructor scores for the peer reviews.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09363v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Wu, Jason Hartline</dc:creator>
    </item>
    <item>
      <title>Strategic Facility Location with Clients that Minimize Total Waiting Time</title>
      <link>https://arxiv.org/abs/2211.14016</link>
      <description>arXiv:2211.14016v3 Announce Type: replace 
Abstract: We study a non-cooperative two-sided facility location game in which facilities and clients behave strategically. This is in contrast to many other facility location games in which clients simply visit their closest facility. Facility agents select a location on a graph to open a facility to attract as much purchasing power as possible, while client agents choose which facilities to patronize by strategically distributing their purchasing power in order to minimize their total waiting time. Here, the waiting time of a facility depends on its received total purchasing power. We show that our client stage is an atomic splittable congestion game, which implies existence, uniqueness and efficient computation of a client equilibrium. Therefore, facility agents can efficiently predict client behavior and make strategic decisions accordingly. Despite that, we prove that subgame perfect equilibria do not exist in all instances of this game and that their existence is NP-hard to decide. On the positive side, we provide a simple and efficient algorithm to compute 3-approximate subgame perfect equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.14016v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1609/aaai.v37i5.25709</arxiv:DOI>
      <dc:creator>Simon Krogmann, Pascal Lenzner, Alexander Skopalik</dc:creator>
    </item>
    <item>
      <title>ApproxED: Approximate exploitability descent via learned best responses</title>
      <link>https://arxiv.org/abs/2301.08830</link>
      <description>arXiv:2301.08830v3 Announce Type: replace 
Abstract: There has been substantial progress on finding game-theoretic equilibria. Most of that work has focused on games with finite, discrete action spaces. However, many games involving space, time, money, and other fine-grained quantities have continuous action spaces (or are best modeled as having such). We study the problem of finding an approximate Nash equilibrium of games with continuous action sets. The standard measure of closeness to Nash equilibrium is exploitability, which measures how much players can benefit from unilaterally changing their strategy. We propose two new methods that minimize an approximation of exploitability with respect to the strategy profile. The first method uses a learned best-response function, which takes the current strategy profile as input and outputs candidate best responses for each player. The strategy profile and best-response functions are trained simultaneously, with the former trying to minimize exploitability while the latter tries to maximize it. The second method maintains an ensemble of candidate best responses for each player. In each iteration, the best-performing elements of each ensemble are used to update the current strategy profile. The strategy profile and ensembles are simultaneously trained to minimize and maximize the approximate exploitability, respectively. We evaluate our methods on various continuous games and GAN training, showing that they outperform prior methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08830v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Martin, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>Strategic Resource Selection with Homophilic Agents</title>
      <link>https://arxiv.org/abs/2305.00843</link>
      <description>arXiv:2305.00843v2 Announce Type: replace 
Abstract: The strategic selection of resources by selfish agents is a classic research direction, with Resource Selection Games and Congestion Games as prominent examples. In these games, agents select available resources and their utility then depends on the number of agents using the same resources. This implies that there is no distinction between the agents, i.e., they are anonymous.
  We depart from this very general setting by proposing Resource Selection Games with heterogeneous agents that strive for joint resource usage with similar agents. So, instead of the number of other users of a given resource, our model considers agents with different types and the decisive feature is the fraction of same-type agents among the users. More precisely, similarly to Schelling Games, there is a tolerance threshold $\tau \in [0,1]$ which specifies the agents' desired minimum fraction of same-type agents on a resource. Agents strive to select resources where at least a $\tau$-fraction of those resources' users have the same type as themselves. For $\tau=1$, our model generalizes Hedonic Diversity Games with a peak at $1$.
  For our general model, we consider the existence and quality of equilibria and the complexity of maximizing social welfare. Additionally, we consider a bounded rationality model, where agents can only estimate the utility of a resource, since they only know the fraction of same-type agents on a given resource, but not the exact numbers. Thus, they cannot know the impact a strategy change would have on a target resource. Interestingly, we show that this type of bounded rationality yields favorable game-theoretic properties and specific equilibria closely approximate equilibria of the full knowledge setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00843v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.24963/ijcai.2023/301</arxiv:DOI>
      <dc:creator>Jonathan Gadea Harder, Simon Krogmann, Pascal Lenzner, Alexander Skopalik</dc:creator>
    </item>
    <item>
      <title>Scaling CheckMate for Game-Theoretic Security</title>
      <link>https://arxiv.org/abs/2403.10310</link>
      <description>arXiv:2403.10310v2 Announce Type: replace 
Abstract: We present the CheckMate tool for automated verification of game-theoretic security properties, with application to blockchain protocols. CheckMate applies automated reasoning techniques to determine whether a game-theoretic protocol model is game-theoretically secure, that is, Byzantine fault tolerant and incentive compatible. We describe CheckMate's input format and its various components, modes, and output. CheckMate is evaluated on 15 benchmarks, including models of decentralized protocols, board games, and game-theoretic examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10310v2</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sophie Rain, Lea Salome Brugger, Anja Petkovic Komel, Laura Kovacs, Michael Rawson</dc:creator>
    </item>
    <item>
      <title>The Ludii Game Description Language is Universal</title>
      <link>https://arxiv.org/abs/2205.00451</link>
      <description>arXiv:2205.00451v3 Announce Type: replace-cross 
Abstract: There are several different game description languages (GDLs), each intended to allow wide ranges of arbitrary games (i.e., general games) to be described in a single higher-level language than general-purpose programming languages. Games described in such formats can subsequently be presented as challenges for automated general game playing agents, which are expected to be capable of playing any arbitrary game described in such a language without prior knowledge about the games to be played. The language used by the Ludii general game system was previously shown to be capable of representing equivalent games for any arbitrary, finite, deterministic, fully observable extensive-form game. In this paper, we prove its universality by extending this to include finite non-deterministic and imperfect-information games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.00451v3</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dennis J. N. J. Soemers, \'Eric Piette, Matthew Stephenson, Cameron Browne</dc:creator>
    </item>
    <item>
      <title>Bandit Sequential Posted Pricing via Half-Concavity</title>
      <link>https://arxiv.org/abs/2312.12794</link>
      <description>arXiv:2312.12794v2 Announce Type: replace-cross 
Abstract: Sequential posted pricing auctions are popular because of their simplicity in practice and their tractability in theory. A usual assumption in their study is that the Bayesian prior distributions of the buyers are known to the seller, while in reality these priors can only be accessed from historical data. To overcome this assumption, we study sequential posted pricing in the bandit learning model, where the seller interacts with $n$ buyers over $T$ rounds: In each round the seller posts $n$ prices for the $n$ buyers and the first buyer with a valuation higher than the price takes the item. The only feedback that the seller receives in each round is the revenue.
  Our main results obtain nearly-optimal regret bounds for single-item sequential posted pricing in the bandit learning model. In particular, we achieve an $\tilde{O}(\mathsf{poly}(n)\sqrt{T})$ regret for buyers with (Myerson's) regular distributions and an $\tilde{O}(\mathsf{poly}(n)T^{{2}/{3}})$ regret for buyers with general distributions, both of which are tight in the number of rounds $T$. Our result for regular distributions was previously not known even for the single-buyer setting and relies on a new half-concavity property of the revenue function in the value space. For $n$ sequential buyers, our technique is to run a generalized single-buyer algorithm for all the buyers and to carefully bound the regret from the sub-optimal pricing of the suffix buyers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12794v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahil Singla, Yifan Wang</dc:creator>
    </item>
  </channel>
</rss>
