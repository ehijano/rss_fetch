<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Feb 2025 04:06:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Techniques for Barely Coupled Multiphysics</title>
      <link>https://arxiv.org/abs/2502.04480</link>
      <description>arXiv:2502.04480v1 Announce Type: new 
Abstract: A technique to combine codes to solve barely coupled multiphysics problems has been developed. Each field is advanced separately until a stop is triggered. This could be due to a preset time increment, a preset number of timesteps, a preset decrease of residuals, a preset change in unknowns, a preset change in geometry, or any other physically meaningful quantity. The technique allows for a simple implementation in coupled codes using the loose coupling approach. Examples from evaporative cooling of electric motors, a problem that has come to the forefront with the rise of electric propulsion in the aerospace sector (drones and air taxis in particular) shows the viability and accuracy of the proposed procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04480v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2514/6.2025-0576</arxiv:DOI>
      <arxiv:journal_reference>AIAA 2025-0576. AIAA SCITECH 2025 Forum. January 2025</arxiv:journal_reference>
      <dc:creator>Rainald L\"ohner, Harbir Antil, Sebastian Sch\"ops</dc:creator>
    </item>
    <item>
      <title>3DMolFormer: A Dual-channel Framework for Structure-based Drug Discovery</title>
      <link>https://arxiv.org/abs/2502.05107</link>
      <description>arXiv:2502.05107v1 Announce Type: new 
Abstract: Structure-based drug discovery, encompassing the tasks of protein-ligand docking and pocket-aware 3D drug design, represents a core challenge in drug discovery. However, no existing work can deal with both tasks to effectively leverage the duality between them, and current methods for each task are hindered by challenges in modeling 3D information and the limitations of available data. To address these issues, we propose 3DMolFormer, a unified dual-channel transformer-based framework applicable to both docking and 3D drug design tasks, which exploits their duality by utilizing docking functionalities within the drug design process. Specifically, we represent 3D pocket-ligand complexes using parallel sequences of discrete tokens and continuous numbers, and we design a corresponding dual-channel transformer model to handle this format, thereby overcoming the challenges of 3D information modeling. Additionally, we alleviate data limitations through large-scale pre-training on a mixed dataset, followed by supervised and reinforcement learning fine-tuning techniques respectively tailored for the two tasks. Experimental results demonstrate that 3DMolFormer outperforms previous approaches in both protein-ligand docking and pocket-aware 3D drug design, highlighting its promising application in structure-based drug discovery. The code is available at: https://github.com/HXYfighter/3DMolFormer .</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05107v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiuyuan Hu, Guoqing Liu, Can Chen, Yang Zhao, Hao Zhang, Xue Liu</dc:creator>
    </item>
    <item>
      <title>Automatic Ply Partitioning for Laminar Composite Process Planning</title>
      <link>https://arxiv.org/abs/2502.04586</link>
      <description>arXiv:2502.04586v1 Announce Type: cross 
Abstract: This work introduces an automated ply partitioning strategy for large-scale laminar composite manufacturing. It specifically targets the problem of fabricating large plies from available spooled materials, while minimizing the adverse effects on part quality. The proposed method inserts fiber-aligned seams sequentially until each resulting sub-ply can be manufactured from available materials, while simultaneously enforcing constraints to avoid quality issues induced by the stacking of seams across multiple plies. Leveraging the developable nature of individual plies, the partitioning problem is cast as a sequence of one-dimensional piecewise linear optimization problems, thus allowing for efficient local optimization via linear programming. We experimentally demonstrate that coupling the local search with a greedy global search produces the same results as an exhaustive search. The resulting automated method provides an efficient and robust alternative to the existing trial-and-error approach, and can be readily integrated into state-of-the-art composite design workflows. In addition, this formulation enables the inclusion of common constraints regarding laminate thickness tolerance, sub-ply geometry, stay-out zones, material wastage, etc. The efficacy of the proposed method is demonstrated through its application to the surface of an airplane wing and to the body panels of an armored vehicle, each subject to various performance and manufacturing-related geometric constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04586v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Garner, Amir Mirzendehdel</dc:creator>
    </item>
    <item>
      <title>CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements</title>
      <link>https://arxiv.org/abs/2502.04592</link>
      <description>arXiv:2502.04592v1 Announce Type: cross 
Abstract: Accurately forecasting the impact of macroeconomic events is critical for investors and policymakers. Salient events like monetary policy decisions and employment reports often trigger market movements by shaping expectations of economic growth and risk, thereby establishing causal relationships between events and market behavior. Existing forecasting methods typically focus either on textual analysis or time-series modeling, but fail to capture the multi-modal nature of financial markets and the causal relationship between events and price movements. To address these gaps, we propose CAMEF (Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a multi-modality framework that effectively integrates textual and time-series data with a causal learning mechanism and an LLM-based counterfactual event augmentation technique for causal-enhanced financial forecasting. Our contributions include: (1) a multi-modal framework that captures causal relationships between policy texts and historical price data; (2) a new financial dataset with six types of macroeconomic releases from 2008 to April 2024, and high-frequency real trading data for five key U.S. financial assets; and (3) an LLM-based counterfactual event augmentation strategy. We compare CAMEF to state-of-the-art transformer-based time-series and multi-modal baselines, and perform ablation studies to validate the effectiveness of the causal learning mechanism and event types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04592v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Zhang, Wenbo Yang, Jun Wang, Qiang Ma, Jie Xiong</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance</title>
      <link>https://arxiv.org/abs/2502.04695</link>
      <description>arXiv:2502.04695v1 Announce Type: cross 
Abstract: This position paper emphasizes the critical gap in the evaluation of Explainable AI (XAI) due to the lack of standardized and reliable metrics, which diminishes its practical value, trustworthiness, and ability to meet regulatory requirements. Current evaluation methods are often fragmented, subjective, and biased, making them prone to manipulation and complicating the assessment of complex models. A central issue is the absence of a ground truth for explanations, complicating comparisons across various XAI approaches. To address these challenges, we advocate for widespread research into developing robust, context-sensitive evaluation metrics. These metrics should be resistant to manipulation, relevant to each use case, and based on human judgment and real-world applicability. We also recommend creating domain-specific evaluation benchmarks that align with the user and regulatory needs of sectors such as healthcare and finance. By encouraging collaboration among academia, industry, and regulators, we can create standards that balance flexibility and consistency, ensuring XAI explanations are meaningful, trustworthy, and compliant with evolving regulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04695v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pratinav Seth, Vinay Kumar Sankarapu</dc:creator>
    </item>
    <item>
      <title>MTMD: Multi-Scale Temporal Memory Learning and Efficient Debiasing Framework for Stock Trend Forecasting</title>
      <link>https://arxiv.org/abs/2212.08656</link>
      <description>arXiv:2212.08656v2 Announce Type: replace 
Abstract: The endeavor of stock trend forecasting is principally focused on predicting the future trajectory of the stock market, utilizing either manual or technical methodologies to optimize profitability. Recent advancements in machine learning technologies have showcased their efficacy in discerning authentic profit signals within the realm of stock trend forecasting, predominantly employing temporal data derived from historical stock price patterns. Nevertheless, the inherently volatile and dynamic characteristics of the stock market render the learning and capture of multi-scale temporal dependencies and stable trading opportunities a formidable challenge. This predicament is primarily attributed to the difficulty in distinguishing real profit signal patterns amidst a plethora of mixed, noisy data. In response to these complexities, we propose a Multi-Scale Temporal Memory Learning and Efficient Debiasing (MTMD) model. This innovative approach encompasses the creation of a learnable embedding coupled with external attention, serving as a memory module through self-similarity. It aims to mitigate noise interference and bolster temporal consistency within the model. The MTMD model adeptly amalgamates comprehensive local data at each timestamp while concurrently focusing on salient historical patterns on a global scale. Furthermore, the incorporation of a graph network, tailored to assimilate global and local information, facilitates the adaptive fusion of heterogeneous multi-scale data. Rigorous ablation studies and experimental evaluations affirm that the MTMD model surpasses contemporary state-of-the-art methodologies by a substantial margin in benchmark datasets. The source code can be found at https://github.com/MingjieWang0606/MDMT-Public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.08656v2</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions on Emerging Topics in Computational Intelligence, 2025</arxiv:journal_reference>
      <dc:creator>Mingjie Wang, Juanxi Tian, Mingze Zhang, Jianxiong Guo, Weijia Jia</dc:creator>
    </item>
    <item>
      <title>A Layered Swarm Optimization Method for Fitting Battery Thermal Runaway Models to Accelerating Rate Calorimetry Data</title>
      <link>https://arxiv.org/abs/2412.16367</link>
      <description>arXiv:2412.16367v3 Announce Type: replace 
Abstract: Thermal runaway in lithium ion batteries is a critical safety concern for the battery industry due to its potential to cause uncontrolled temperature rises and subsequent fires that can engulf the battery pack and its surroundings. Modeling and simulation offer cost effective tools for designing strategies to mitigate thermal runaway. Accurately simulating the chemical kinetics of thermal runaway,commonly represented by systems of Arrhenius based Ordinary Differential Equations (ODEs), requires fitting kinetic parameters to experimental calorimetry data, such as Accelerating Rate Calorimetry (ARC) measurements. However, existing fitting methods often rely on empirical assumptions and simplifications that compromise generality or require manual tuning during the fitting process. Particle Swarm Optimization (PSO) offers a promising approach for directly fitting kinetic parameters to experimental data. Yet, for systems involving large search spaces, such as those created by multiple Arrhenius ODEs, the computational cost of fitting can become prohibitive. This work introduces a divide and conquer approach based on PSO to fit N equation Arrhenius ODE models to ARC data. The proposed method achieves accurate parameter fitting while maintaining low computational costs. The resulting fit is analyzed using two distinct ARC datasets, highlighting the methods flexibility. The resulting models are further validated through simulations of 3D ARC and oven tests, showing excellent agreement with experimental data and alignment with expected trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16367v3</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saakaar Bhatnagar, Andrew Comerford, Zelu Xu, Simone Reitano, Luigi Scrimieri, Luca Giuliano, Araz Banaeizadeh</dc:creator>
    </item>
    <item>
      <title>Neural Preconditioning Operator for Efficient PDE Solves</title>
      <link>https://arxiv.org/abs/2502.01337</link>
      <description>arXiv:2502.01337v2 Announce Type: replace 
Abstract: We introduce the Neural Preconditioning Operator (NPO), a novel approach designed to accelerate Krylov solvers in solving large, sparse linear systems derived from partial differential equations (PDEs). Unlike classical preconditioners that often require extensive tuning and struggle to generalize across different meshes or parameters, NPO employs neural operators trained via condition and residual losses. This framework seamlessly integrates with existing neural network models, serving effectively as a preconditioner to enhance the performance of Krylov subspace methods. Further, by melding algebraic multigrid principles with a transformer-based architecture, NPO significantly reduces iteration counts and runtime for solving Poisson, Diffusion, and Linear Elasticity problems on both uniform and irregular meshes. Our extensive numerical experiments demonstrate that NPO outperforms traditional methods and contemporary neural approaches across various resolutions, ensuring robust convergence even on grids as large as 4096, far exceeding its initial training limits. These findings underscore the potential of data-driven preconditioning to transform the computational efficiency of high-dimensional PDE applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01337v2</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihao Li, Di Xiao, Zhilu Lai, Wei Wang</dc:creator>
    </item>
    <item>
      <title>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</title>
      <link>https://arxiv.org/abs/2410.14059</link>
      <description>arXiv:2410.14059v3 Announce Type: replace-cross 
Abstract: This paper introduces the UCFE: User-Centric Financial Expertise benchmark, an innovative framework designed to evaluate the ability of large language models (LLMs) to handle complex real-world financial tasks. UCFE benchmark adopts a hybrid approach that combines human expert evaluations with dynamic, task-specific interactions to simulate the complexities of evolving financial scenarios. Firstly, we conducted a user study involving 804 participants, collecting their feedback on financial tasks. Secondly, based on this feedback, we created our dataset that encompasses a wide range of user intents and interactions. This dataset serves as the foundation for benchmarking 11 LLMs services using the LLM-as-Judge methodology. Our results show a significant alignment between benchmark scores and human preferences, with a Pearson correlation coefficient of 0.78, confirming the effectiveness of the UCFE dataset and our evaluation approach. UCFE benchmark not only reveals the potential of LLMs in the financial domain but also provides a robust framework for assessing their performance and user satisfaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14059v3</guid>
      <category>q-fin.CP</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzhe Yang, Yifei Zhang, Yan Hu, Yilin Guo, Ruoli Gan, Yueru He, Mingcong Lei, Xiao Zhang, Haining Wang, Qianqian Xie, Jimin Huang, Honghai Yu, Benyou Wang</dc:creator>
    </item>
    <item>
      <title>Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2412.08435</link>
      <description>arXiv:2412.08435v3 Announce Type: replace-cross 
Abstract: Time series forecasting always faces the challenge of concept drift, where data distributions evolve over time, leading to a decline in forecast model performance. Existing solutions are based on online learning, which continually organize recent time series observations as new training samples and update model parameters according to the forecasting feedback on recent data. However, they overlook a critical issue: obtaining ground-truth future values of each sample should be delayed until after the forecast horizon. This delay creates a temporal gap between the training samples and the test sample. Our empirical analysis reveals that the gap can introduce concept drift, causing forecast models to adapt to outdated concepts. In this paper, we present Proceed, a novel proactive model adaptation framework for online time series forecasting. Proceed first estimates the concept drift between the recently used training samples and the current test sample. It then employs an adaptation generator to efficiently translate the estimated drift into parameter adjustments, proactively adapting the model to the test sample. To enhance the generalization capability of the framework, Proceed is trained on synthetic diverse concept drifts. Extensive experiments on five real-world datasets across various forecast models demonstrate that Proceed brings more performance improvements than the state-of-the-art online learning methods, significantly facilitating forecast models' resilience against concept drifts. Code is available at https://github.com/SJTU-DMTai/OnlineTSF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08435v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>stat.ML</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3690624.3709210</arxiv:DOI>
      <dc:creator>Lifan Zhao, Yanyan Shen</dc:creator>
    </item>
  </channel>
</rss>
