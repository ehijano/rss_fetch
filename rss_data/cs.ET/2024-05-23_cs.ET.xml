<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 May 2024 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Reliable Target Evolved Node B Selection Scheme in LTE-Advanced Handover</title>
      <link>https://arxiv.org/abs/2405.13827</link>
      <description>arXiv:2405.13827v1 Announce Type: new 
Abstract: The problem of improving the handover performance in Long Term Evolution-Advanced (LTE-A) networks has not been fully solved yet. Traditionally, the selection of the target Evolved Node B (TeNB) in the handover procedure is based on the signal strength measurements, which may not produce a reliable handover. A reliable handover method may reduce the instances of unstable or frequent handovers that otherwise waste network resources. The signal strength measurement process is inherently time consuming as the user equipment (UE) has to measure multiple neighboring eNB (NeNB) frequencies in each measurement period. An efficient handover method is required to improve the overall performance of such systems. In this paper we propose a reliable and fast TeNB selection scheme for LTE-A handover. The proposed scheme outperforms the existing LTE-A handover methods. The improved performance is achieved by selecting the TeNB based on some three independent parameters, namely orientation matching (OM), current load (CL), and the received signal strengths. An UE essentially measures only the NeNBs shortlisted based on OM and CL; thus measurement time is reduced considerably leading to a reduction of overall handover time. The performance of the proposed scheme is validated by simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13827v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sayan Kumar Ray, NZ Jhanjhi, Akbar Hossain</dc:creator>
    </item>
    <item>
      <title>Fully parallel implementation of digital memcomputing on FPGA</title>
      <link>https://arxiv.org/abs/2405.14442</link>
      <description>arXiv:2405.14442v1 Announce Type: new 
Abstract: We present a fully parallel digital memcomputing solver implemented on a field-programmable gate array (FPGA) board. For this purpose, we have designed an FPGA code that solves the ordinary differential equations associated with digital memcomputing in parallel. A feature of the code is the use of only integer-type variables and integer constants to enhance optimization. Consequently, each integration step in our solver is executed in 96~ns. This method was utilized for difficult instances of the Boolean satisfiability (SAT) problem close to a phase transition, involving up to about 150 variables. Our results demonstrate that the parallel implementation reduces the scaling exponent by about 1 compared to a sequential C++ code on a standard computer. Additionally, compared to C++ code, we observed a time-to-solution advantage of about three orders of magnitude. Given the limitations of FPGA resources, the current implementation of digital memcomputing will be especially useful for solving compact but challenging problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14442v1</guid>
      <category>cs.ET</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dyk Chung Nguyen, Yuriy V. Pershin</dc:creator>
    </item>
    <item>
      <title>From the evolution of public data ecosystems to the evolving horizons of the forward-looking intelligent public data ecosystem empowered by emerging technologies</title>
      <link>https://arxiv.org/abs/2405.13606</link>
      <description>arXiv:2405.13606v1 Announce Type: cross 
Abstract: Public data ecosystems (PDEs) represent complex socio-technical systems crucial for optimizing data use in the public sector and outside it. Recognizing their multifaceted nature, previous research pro-posed a six-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed as a result of a systematic literature review on the topic spanning three decade, this model, while theoretically robust, necessitates empirical validation to enhance its practical applicability. This study addresses this gap by validating the theoretical model through a real-life examination in five European countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This empirical validation provides insights into PDEs dynamics and variations of implementations across contexts, particularly focusing on the 6th generation of forward-looking PDE generation named "Intelligent Public Data Generation" that represents a paradigm shift driven by emerging technologies such as cloud computing, Artificial Intelligence, Natural Language Processing tools, Generative AI, and Large Language Models (LLM) with potential to contribute to both automation and augmentation of business processes within these ecosystems. By transcending their traditional status as a mere component, evolving into both an actor and a stakeholder simultaneously, these technologies catalyze innovation and progress, enhancing PDE management strategies to align with societal, regulatory, and technical imperatives in the digital era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13606v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>In: Janssen, M, J. Crompvoets, J. Ramon Gil-Garcia, H. Lee, I Lindgren, A Nikiforova, G. Viale Pereira. Electronic Government. EGOV 2024. Lecture Notes in Computer Science, Springer, Cham</arxiv:journal_reference>
      <dc:creator>Anastasija Nikiforova, Martin Lnenicka, Petar Mili\'c, Mariusz Luterek, Manuel Pedro Rodr\'iguez Bol\'ivar</dc:creator>
    </item>
    <item>
      <title>Reducing Mid-Circuit Measurements via Probabilistic Circuits</title>
      <link>https://arxiv.org/abs/2405.13747</link>
      <description>arXiv:2405.13747v1 Announce Type: cross 
Abstract: Mid-circuit measurements and measurement-controlled gates are supported by an increasing number of quantum hardware platforms and will become more relevant as an essential building block for quantum error correction. However, mid-circuit measurements impose significant demands on the quantum hardware due to the required signal analysis and classical feedback loop. This work presents a static circuit optimization algorithm that can substitute some of these measurements with an equivalent circuit with randomized gate applications. Our method uses ideas from constant propagation to classically precompute measurement outcome probabilities. Our proposed optimization is efficient, as its runtime scales polynomially on the number of qubits and gates of the circuit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13747v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanbin Chen, Innocenzo Fulginiti, Christian B. Mendl</dc:creator>
    </item>
    <item>
      <title>Thermodynamic Natural Gradient Descent</title>
      <link>https://arxiv.org/abs/2405.13817</link>
      <description>arXiv:2405.13817v1 Announce Type: cross 
Abstract: Second-order training methods have better convergence properties than gradient descent but are rarely used in practice for large-scale training due to their computational overhead. This can be viewed as a hardware limitation (imposed by digital computers). Here we show that natural gradient descent (NGD), a second-order method, can have a similar computational complexity per iteration to a first-order method, when employing appropriate hardware. We present a new hybrid digital-analog algorithm for training neural networks that is equivalent to NGD in a certain parameter regime but avoids prohibitively costly linear system solves. Our algorithm exploits the thermodynamic properties of an analog system at equilibrium, and hence requires an analog thermodynamic computer. The training occurs in a hybrid digital-analog loop, where the gradient and Fisher information matrix (or any other positive semi-definite curvature matrix) are calculated at given time intervals while the analog dynamics take place. We numerically demonstrate the superiority of this approach over state-of-the-art digital first- and second-order training methods on classification tasks and language model fine-tuning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13817v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaelan Donatella, Samuel Duffield, Maxwell Aifer, Denis Melanson, Gavin Crooks, Patrick J. Coles</dc:creator>
    </item>
    <item>
      <title>Carbon Connect: An Ecosystem for Sustainable Computing</title>
      <link>https://arxiv.org/abs/2405.13858</link>
      <description>arXiv:2405.13858v1 Announce Type: cross 
Abstract: Computing is at a moment of profound opportunity. Emerging applications -- such as capable artificial intelligence, immersive virtual realities, and pervasive sensor systems -- drive unprecedented demand for computer. Despite recent advances toward net zero carbon emissions, the computing industry's gross energy usage continues to rise at an alarming rate, outpacing the growth of new energy installations and renewable energy deployments. A shift towards sustainability is needed to spark a transformation in how computer systems are manufactured, allocated, and consumed.
  Carbon Connect envisions coordinated research thrusts that produce design and management strategies for sustainable, next-generation computer systems. These strategies must flatten and then reverse growth trajectories for computing power and carbon for society's most rapidly growing applications such as artificial intelligence and virtual spaces. We will require accurate models for carbon accounting in computing technology. For embodied carbon, we must re-think conventional design strategies -- over-provisioned monolithic servers, frequent hardware refresh cycles, custom silicon -- and adopt life-cycle design strategies that more effectively reduce, reuse and recycle hardware at scale. For operational carbon, we must not only embrace renewable energy but also design systems to use that energy more efficiently. Finally, new hardware design and management strategies must be cognizant of economic policy and regulatory landscape, aligning private initiatives with societal goals. Many of these broader goals will require computer scientists to develop deep, enduring collaborations with researchers in economics, law, and industrial ecology to spark change in broader practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13858v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin C. Lee, David Brooks, Arthur van Benthem, Udit Gupta, Gage Hills, Vincent Liu, Benjamin Pierce, Christopher Stewart, Emma Strubell, Gu-Yeon Wei, Adam Wierman, Yuan Yao, Minlan Yu</dc:creator>
    </item>
    <item>
      <title>Implicit gaze research for XR systems</title>
      <link>https://arxiv.org/abs/2405.13878</link>
      <description>arXiv:2405.13878v1 Announce Type: cross 
Abstract: Although eye-tracking technology is being integrated into more VR and MR headsets, the true potential of eye tracking in enhancing user interactions within XR settings remains relatively untapped. Presently, one of the most prevalent gaze applications in XR is input control; for example, using gaze to control a cursor for pointing. However, our eyes evolved primarily for sensory input and understanding of the world around us, and yet few XR applications have leveraged natural gaze behavior to infer and support users' intent and cognitive states. Systems that can represent a user's context and interaction intent can better support the user by generating contextually relevant content, by making the user interface easier to use, by highlighting potential errors, and more. This mode of application is not fully taken advantage of in current commercially available XR systems and yet it is likely where we'll find paradigm-shifting use cases for eye tracking. In this paper, we elucidate the state-of-the-art applications for eye tracking and propose new research directions to harness its potential fully.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13878v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naveen Sendhilnathan, Ajoy S. Fernandes, Michael J. Proulx, Tanya R. Jonker</dc:creator>
    </item>
    <item>
      <title>Cognitive Internet of Vulnerable Road Users in Traffic: Predictive Neural Modulations of Road Crossing Intention</title>
      <link>https://arxiv.org/abs/2405.13955</link>
      <description>arXiv:2405.13955v1 Announce Type: cross 
Abstract: Vulnerable Road Users (VRUs) present a significant challenge for road safety due to the frequent unpredictability of their behaviors. In typical Intelligent Transportation Systems, vision-based approaches supported by networked cameras are often used to anticipate VRUs motion intentions and trajectories. However, several limitations posed by occlusions and distractions set a boundary for the efficacy of such methods. To address these challenges, this study introduces a framework that leverages data collected using wearable neurophysiological sensors on VRUs to integrate them seamlessly into the Vehicle-to-Everything communication framework. This integration empowers VRUs to autonomously broadcast their intended movements to other road agents, especially autonomous vehicles, thereby bridging a critical gap in current vehicular communication systems. To validate this concept, we conducted an experiment involving 12 participants, from whom EEG signals were collected as they engaged in road-crossing decisions within simulated environments. Employing Hidden Markov Models, we identified four cognitive stages intrinsic to a pedestrian's decision-making process. Our statistical analysis further revealed significant variations in EEG activities across these stages, shedding light on the neural correlates and cognitive dynamics underpinning pedestrian road-crossing behavior. We then developed a predictive cognitive model using dynamic time warping and K-nearest neighbors algorithms, optimized through a data-driven sliding window approach. This model demonstrated high predictive accuracy, evidenced by an Area Under the Curve of 0.91, indicating its capability to anticipate pedestrian road-crossing actions approximately 1 second in advance of any pedestrian movement. This research paves the way for a novel VRU-Vehicle interaction paradigm and signifies a shift towards a forward-thinking ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13955v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoshan Zhou, Carol C. Menassa, Vineet R. Kamat</dc:creator>
    </item>
    <item>
      <title>How Many Bytes Can You Take Out Of Brain-To-Text Decoding?</title>
      <link>https://arxiv.org/abs/2405.14055</link>
      <description>arXiv:2405.14055v1 Announce Type: cross 
Abstract: Brain-computer interfaces have promising medical and scientific applications for aiding speech and studying the brain. In this work, we propose an information-based evaluation metric for brain-to-text decoders. Using this metric, we examine two methods to augment existing state-of-the-art continuous text decoders. We show that these methods, in concert, can improve brain decoding performance by upwards of 40% when compared to a baseline model. We further examine the informatic properties of brain-to-text decoders and show empirically that they have Zipfian power law dynamics. Finally, we provide an estimate for the idealized performance of an fMRI-based text decoder. We compare this idealized model to our current model, and use our information-based metric to quantify the main sources of decoding error. We conclude that a practical brain-to-text decoder is likely possible given further algorithmic improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14055v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Antonello, Nihita Sarma, Jerry Tang, Jiaru Song, Alexander Huth</dc:creator>
    </item>
    <item>
      <title>Push and Pull: A Framework for Measuring Attentional Agency</title>
      <link>https://arxiv.org/abs/2405.14614</link>
      <description>arXiv:2405.14614v1 Announce Type: cross 
Abstract: We propose a framework for measuring attentional agency - the ability to allocate one's attention according to personal desires, goals, and intentions - on digital platforms. Platforms extend people's limited powers of attention by extrapolating their preferences to large collections of previously unconsidered informational objects. However, platforms typically also allow people to influence one another's attention. We introduce a formal framework for measuring how much a given platform empowers people to both pull information into their own attentional field and push information into the attentional fields of others. We also use these definitions to shed light on the implications of generative foundation models, which enable users to bypass the implicit "attentional bargain" that underlies embedded advertising and other methods for capturing economic value from informational goods. We conclude with a set of policy strategies that can be used to understand and reshape the distribution of attentional agency online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14614v1</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.IR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Wojtowicz, Shrey Jain, Nicholas Vincent</dc:creator>
    </item>
    <item>
      <title>I/O-efficient iterative matrix inversion with photonic integrated circuits</title>
      <link>https://arxiv.org/abs/2305.18548</link>
      <description>arXiv:2305.18548v3 Announce Type: replace 
Abstract: Photonic integrated circuits have been extensively explored for optical processing with the aim of breaking the speed bottleneck of digital electronics. However, the input/output (IO) bottleneck remains one of the key barriers. Here we report a novel photonic iterative processor (PIP) for matrix-inversion-intensive applications. The direct reuse of inputted data in the optical domain unlocks the potential to break the IO bottleneck. We demonstrate notable IO advantages with a lossless PIP for real-valued matrix inversion and integral-differential equation solving, as well as a coherent PIP with optical loops integrated on-chip, enabling complex-valued computation and a net inversion time of 1.2 ns. Furthermore, we estimate at least an order of magnitude enhancement in IO efficiency of a PIP over photonic single-pass processors and the state-of-the-art electronic processors for reservoir training tasks and MIMO precoding tasks, indicating the huge potential of PIP technology in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18548v3</guid>
      <category>cs.ET</category>
      <category>physics.optics</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minjia Chen, Yizhi Wang, Chunhui Yao, Adrian Wonfor, Shuai Yang, Richard Penty, Qixiang Cheng</dc:creator>
    </item>
    <item>
      <title>A scoping review of using Large Language Models (LLMs) to investigate Electronic Health Records (EHRs)</title>
      <link>https://arxiv.org/abs/2405.03066</link>
      <description>arXiv:2405.03066v2 Announce Type: replace 
Abstract: Electronic Health Records (EHRs) play an important role in the healthcare system. However, their complexity and vast volume pose significant challenges to data interpretation and analysis. Recent advancements in Artificial Intelligence (AI), particularly the development of Large Language Models (LLMs), open up new opportunities for researchers in this domain. Although prior studies have demonstrated their potential in language understanding and processing in the context of EHRs, a comprehensive scoping review is lacking. This study aims to bridge this research gap by conducting a scoping review based on 329 related papers collected from OpenAlex. We first performed a bibliometric analysis to examine paper trends, model applications, and collaboration networks. Next, we manually reviewed and categorized each paper into one of the seven identified topics: named entity recognition, information extraction, text similarity, text summarization, text classification, dialogue system, and diagnosis and prediction. For each topic, we discussed the unique capabilities of LLMs, such as their ability to understand context, capture semantic relations, and generate human-like text. Finally, we highlighted several implications for researchers from the perspectives of data resources, prompt engineering, fine-tuning, performance measures, and ethical concerns. In conclusion, this study provides valuable insights into the potential of LLMs to transform EHR research and discusses their applications and ethical considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03066v2</guid>
      <category>cs.ET</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingyao Li, Jiayan Zhou, Zhenxiang Gao, Wenyue Hua, Lizhou Fan, Huizi Yu, Loni Hagen, Yongfeng Zhang, Themistocles L. Assimes, Libby Hemphill, Siyuan Ma</dc:creator>
    </item>
    <item>
      <title>All-to-all reconfigurability with sparse and higher-order Ising machines</title>
      <link>https://arxiv.org/abs/2312.08748</link>
      <description>arXiv:2312.08748v2 Announce Type: replace-cross 
Abstract: Domain-specific hardware to solve computationally hard optimization problems has generated tremendous excitement recently. Here, we evaluate probabilistic bit (p-bit) based on Ising Machines (IM) or p-computers with a benchmark combinatorial optimization problem, namely the 3-regular 3-XOR Satisfiability (3R3X). The 3R3X problem has a glassy energy landscape, and it has recently been used to benchmark various IMs and other solvers. We introduce a multiplexed architecture where p-computers emulate all-to-all (complete) graph functionality despite being interconnected in sparse networks, enabling a highly parallelized chromatic Gibbs sampling. We implement this architecture in FPGAs and show that p-bit networks running an adaptive version of the powerful parallel tempering algorithm demonstrate competitive algorithmic and prefactor advantages over alternative IMs by D-Wave, Toshiba, and Fujitsu, except a greedy algorithm accelerated on a GPU. We further extend our APT results using higher-order interactions in FPGAs and show that while higher-order interactions lead to prefactor advantages, they do not show any algorithmic scaling advantages for the XORSAT problem, settling an open conjecture. Even though FPGA implementations of p-bits are still not quite as fast as the best possible greedy algorithms implemented in GPUs, scaled magnetic versions of p-computers could lead to orders of magnitude over such algorithms according to experimentally established projections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08748v2</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Srijan Nikhar, Sidharth Kannan, Navid Anjum Aadit, Shuvro Chowdhury, Kerem Y. Camsari</dc:creator>
    </item>
  </channel>
</rss>
