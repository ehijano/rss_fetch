<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Oct 2025 04:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dream2Image : An Open Multimodal EEG Dataset for Decoding and Visualizing Dreams with Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2510.06252</link>
      <description>arXiv:2510.06252v1 Announce Type: new 
Abstract: Dream2Image is the world's first dataset combining EEG signals, dream transcriptions, and AI-generated images. Based on 38 participants and more than 31 hours of dream EEG recordings, it contains 129 samples offering: the final seconds of brain activity preceding awakening (T-15, T-30, T-60, T-120), raw reports of dream experiences, and an approximate visual reconstruction of the dream. This dataset provides a novel resource for dream research, a unique resource to study the neural correlates of dreaming, to develop models for decoding dreams from brain activity, and to explore new approaches in neuroscience, psychology, and artificial intelligence. Available in open access on Hugging Face and GitHub, Dream2Image provides a multimodal resource designed to support research at the interface of artificial intelligence and neuroscience. It was designed to inspire researchers and extend the current approaches to brain activity decoding. Limitations include the relatively small sample size and the variability of dream recall, which may affect generalizability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06252v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yann Bellec</dc:creator>
    </item>
    <item>
      <title>Consciousness As Entropy Reduction (Short Version)</title>
      <link>https://arxiv.org/abs/2510.06297</link>
      <description>arXiv:2510.06297v1 Announce Type: new 
Abstract: A model of consciousness is proposed which, having a logical basis, lends itself to simulation using a simple mathematical model called Consciousness as Entropy Reduction (CER). The approach has been inspired by previous models such as GWT, IIT and an earlier less mainstream model called "Feature Map" in Psychology. CER considers the contents of consciousness and subconsciousness as \textit{scenarios}: a vector of patterns (or features) on various "channels" (or feature locations). In CER, a feature map itself is not consciousness but only the input \textit{scenario} into a world of possible subconscious \textit{scenarios} from which the conscious \textit{scenario} (i.e., conscious experience) is chosen. Essentially, it creates an internal simulation of the outside world. Solving problems in simulation internally as a "thought experiment" is obviously more economical than doing experiments in a real environment and lends itself to adaptability and hence is a major evolutionary advantage. CER also has connections with the Hopfield model in artificial neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06297v1</guid>
      <category>q-bio.NC</category>
      <category>math.LO</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifeng Chen, J. W. Sanders</dc:creator>
    </item>
    <item>
      <title>Retrieving the structure of probabilistic sequences from EEG data during the goalkeeper game</title>
      <link>https://arxiv.org/abs/2510.06344</link>
      <description>arXiv:2510.06344v1 Announce Type: new 
Abstract: This work draws on the conjecture that fingerprints of stochastic event sequences can be retrieved from electroencephalographic data (EEG) recorded during a behavioral task. To test this, we used the Goalkeeper Game (game.numec.prp.usp.br). Acting as a goalkeeper, the participant predicted each kick in a probabilistic sequence while EEG activity was recorded. At each trial, driven by a context tree, the kicker chose one of three options: left, center, or right. The goalkeeper then predicted the next kick by pressing a button. Tree estimation was performed by applying the Context Algorithm to EEG segments locked to the button press (-300 to 0 ms). We calculated the distance between the penalty taker's tree and the trees retrieved per participant and electrode. This metric was then correlated with the goalkeeper's success rates. We observed a clear reduction in the overall distance distribution over time for a subset of electrodes, indicating that EEG dependencies become more congruent with the penalty taker's tree as the goalkeeper learns the sequence. This distance is inversely proportional to the goalkeepers' success rates, indicating a clear relationship between performance and the neural signatures associated with the sequence structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06344v1</guid>
      <category>q-bio.NC</category>
      <category>math.PR</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>P. R. Cabral-Passos, P. S. Azevedo, V. H. Moraes, B. L. Ramalho, A. Duarte, C. D. Vargas</dc:creator>
    </item>
    <item>
      <title>Diffusion-Guided Renormalization of Neural Systems via Tensor Networks</title>
      <link>https://arxiv.org/abs/2510.06361</link>
      <description>arXiv:2510.06361v1 Announce Type: new 
Abstract: Far from equilibrium, neural systems self-organize across multiple scales. Exploiting multiscale self-organization in neuroscience and artificial intelligence requires a computational framework for modeling the effective non-equilibrium dynamics of stochastic neural trajectories. Non-equilibrium thermodynamics and representational geometry offer theoretical foundations, but we need scalable data-driven techniques for modeling collective properties of high-dimensional neural networks from partial subsampled observations. Renormalization is a coarse-graining technique central to studying emergent scaling properties of many-body and nonlinear dynamical systems. While widely applied in physics and machine learning, coarse-graining complex dynamical networks remains unsolved, affecting many computational sciences. Recent diffusion-based renormalization, inspired by quantum statistical mechanics, coarse-grains networks near entropy transitions marked by maximal changes in specific heat or information transmission. Here I explore diffusion-based renormalization of neural systems by generating symmetry-breaking representations across scales and offering scalable algorithms using tensor networks. Diffusion-guided renormalization bridges microscale and mesoscale dynamics of dissipative neural systems. For microscales, I developed a scalable graph inference algorithm for discovering community structure from subsampled neural activity. Using community-based node orderings, diffusion-guided renormalization generates renormalization group flow through metagraphs and joint probability functions. Towards mesoscales, diffusion-guided renormalization targets learning the effective non-equilibrium dynamics of dissipative neural trajectories occupying lower-dimensional subspaces, enabling coarse-to-fine control in systems neuroscience and artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06361v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan X. Kodama</dc:creator>
    </item>
    <item>
      <title>Utilizing Information Theoretic Approach to Study Cochlear Neural Degeneration</title>
      <link>https://arxiv.org/abs/2510.06671</link>
      <description>arXiv:2510.06671v1 Announce Type: new 
Abstract: Hidden hearing loss, or cochlear neural degeneration (CND), disrupts suprathreshold auditory coding without affecting clinical thresholds, making it difficult to diagnose. We present an information-theoretic framework to evaluate speech stimuli that maximally reveal CND by quantifying mutual information (MI) loss between inner hair cell (IHC) receptor potentials and auditory nerve fiber (ANF) responses and acoustic input and ANF responses. Using a phenomenological auditory model, we simulated responses to 50 CVC words under clean, time-compressed, reverberant, and combined conditions across different presentation levels, with systematically varied survival of low-, medium-, and high-spontaneous-rate fibers. MI was computed channel-wise between IHC and ANF responses and integrated across characteristic frequencies. Information loss was defined relative to a normal-hearing baseline. Results demonstrate progressive MI loss with increasing CND, most pronounced for time-compressed speech, while reverberation produced comparatively smaller effects. These findings identify rapid, temporally dense speech as optimal probes for CND, informing the design of objective clinical diagnostics while revealing problems associated with reverberation as a probe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06671v1</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>eess.AS</category>
      <category>math.IT</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahsan J. Cheema, Sunil Puria</dc:creator>
    </item>
    <item>
      <title>Gradient of White Matter Functional Variability via fALFF Differential Identifiability</title>
      <link>https://arxiv.org/abs/2510.06914</link>
      <description>arXiv:2510.06914v1 Announce Type: new 
Abstract: Functional variability in both gray matter (GM) and white matter (WM) is closely associated with human brain cognitive and developmental processes, and is commonly assessed using functional connectivity (FC). However, as a correlation-based approach, FC captures the co-fluctuation between brain regions rather than the intensity of neural activity in each region. Consequently, FC provides only a partial view of functional variability, and this limitation is particularly pronounced in WM, where functional signals are weaker and more susceptible to noise. To tackle this limitation, we introduce fractional amplitude of low-frequency fluctuation (fALFF) to measure the intensity of spontaneous neural activity and analyze functional variability in WM. Specifically, we propose a novel method to quantify WM functional variability by estimating the differential identifiability of fALFF. Higher differential identifiability is observed in WM fALFF compared to FC, which indicates that fALFF is more sensitive to WM functional variability. Through fALFF differential identifiability, we evaluate the functional variabilities of both WM and GM, and find the overall functional variability pattern is similar although WM shows slightly lower variability than GM. The regional functional variabilities of WM are associated with structural connectivity, where commissural fiber regions generally exhibit higher variability than projection fiber regions. Furthermore, we discover that WM functional variability demonstrates a spatial gradient ascending from the brainstem to the cortex by hypothesis testing, which aligns well with the evolutionary expansion. The gradient of functional variability in WM provides novel insights for understanding WM function. To the best of our knowledge, this is the first attempt to investigate WM functional variability via fALFF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06914v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinle Chang, Yang Yang, Yueran Li, Zhengcen Li, Haijin Zeng, Jingyong Su</dc:creator>
    </item>
    <item>
      <title>Quantifying spike train synchrony and directionality: Measures and Applications</title>
      <link>https://arxiv.org/abs/2510.07140</link>
      <description>arXiv:2510.07140v1 Announce Type: new 
Abstract: By introducing the twin concepts of reliability and precision along with the corresponding measures, Mainen and Sejnowski's seminal 1995 paper "Reliability of spike timing in neocortical neurons" (Mainen and Sejnowski, 1995) paved the way for a new kind of quantitative spike train analysis. In subsequent years a host of new methods was introduced that measured both the synchrony among neuronal spike trains and the directional component, e.g. how activity propogates between neurons. This development culminated with a new class of measures that are both time scale independent and time resolved. These include the two spike train distances ISI- and SPIKE-Distance as well as the coincidence detector SPIKE-Synchronization and its directional companion SPIKE-Order. This article will not only review all of these measures but also include two recently proposed algorithms for latency correction which build on SPIKE-order and aim to optimize the spike time alignment of sparse spike trains with well-defined global spiking events. For the sake of clarity, all these methods will be illustrated on artificially generated data but in each case exemplary applications to real neuronal data will be described as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07140v1</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Kreuz</dc:creator>
    </item>
    <item>
      <title>Stacked Regression using Off-the-shelf, Stimulus-tuned and Fine-tuned Neural Networks for Predicting fMRI Brain Responses to Movies (Algonauts 2025 Report)</title>
      <link>https://arxiv.org/abs/2510.06235</link>
      <description>arXiv:2510.06235v1 Announce Type: cross 
Abstract: We present our submission to the Algonauts 2025 Challenge, where the goal is to predict fMRI brain responses to movie stimuli. Our approach integrates multimodal representations from large language models, video encoders, audio models, and vision-language models, combining both off-the-shelf and fine-tuned variants. To improve performance, we enhanced textual inputs with detailed transcripts and summaries, and we explored stimulus-tuning and fine-tuning strategies for language and vision models. Predictions from individual models were combined using stacked regression, yielding solid results. Our submission, under the team name Seinfeld, ranked 10th. We make all code and resources publicly available, contributing to ongoing efforts in developing multimodal encoding models for brain activity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06235v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Scholz, Kunal Bagga, Christine Ahrends, Carlo Alberto Barbano</dc:creator>
    </item>
  </channel>
</rss>
