<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Nov 2024 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Minimal Conditions for Beneficial Neighbourhood Search and Local Descent</title>
      <link>https://arxiv.org/abs/2411.05263</link>
      <description>arXiv:2411.05263v1 Announce Type: cross 
Abstract: This paper investigates what properties a neighbourhood requires to support beneficial local search. We show that neighbourhood locality, and a reduction in cost probability towards the optimum, support a proof that search among neighbours is more likely to find an improving solution in a single search step than blind search. This is the first paper to introduce such a proof. The concepts underlying these properties are illustrated on a satisfiability problem class, and on travelling salesman problems. Secondly, for a given cost target t, we investigate a combination of blind search and local descent termed local blind descent, and present various conditions under which the expected number of steps to reach a cost better than t using local blind descent, is proven to be smaller than with blind search. Experiments indicate that local blind descent, given target cost t, should switch to local descent at a starting cost that reduces as t approaches the optimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05263v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark G. Wallace</dc:creator>
    </item>
    <item>
      <title>Towards computational methods for category theory</title>
      <link>https://arxiv.org/abs/2411.05511</link>
      <description>arXiv:2411.05511v1 Announce Type: cross 
Abstract: In this work, we describe a computational model for categories and functors. The categories that are handled by this model are locally finitely presentable categories which can be "sufficiently finitely" described to a computer. As an application of this model, we introduce a criterion to show whether a functor, as described in the model, is a left adjoint. The verification of this criterion can be partially automatised, if not fully in some cases, as witnessed by an implementation. While this work is focused on computational aspects, it is relevant to the broader categorical community, as it presents a new way to check whether functors are left adjoints and outlines a new computational methodology in category theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05511v1</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Forest</dc:creator>
    </item>
    <item>
      <title>Tachis: Higher-Order Separation Logic with Credits for Expected Costs</title>
      <link>https://arxiv.org/abs/2405.20083</link>
      <description>arXiv:2405.20083v2 Announce Type: replace 
Abstract: We present Tachis, a higher-order separation logic to reason about the expected cost of probabilistic programs. Inspired by the uses of time credits for reasoning about the running time of deterministic programs, we introduce a novel notion of probabilistic cost credit. Probabilistic cost credits are a separation logic resource that can be used to pay for the cost of operations in programs, and that can be distributed across all possible branches of sampling instructions according to their weight, thus enabling us to reason about expected cost. The representation of cost credits as separation logic resources gives Tachis a great deal of flexibility and expressivity. In particular, it permits reasoning about amortized expected cost by storing excess credits as potential into data structures to pay for future operations. Tachis further supports a range of cost models, including running time and entropy usage. We showcase the versatility of this approach by applying our techniques to prove upper bounds on the expected cost of a variety of probabilistic algorithms and data structures, including randomized quicksort, hash tables, and meldable heaps.
  All of our results have been mechanized using Coq, Iris, and the Coquelicot real analysis library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20083v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3689753</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Program. Lang. 8, OOPSLA2, Article 313 (October 2024), 30 pages</arxiv:journal_reference>
      <dc:creator>Philipp G. Haselwarter, Kwing Hei Li, Markus de Medeiros, Simon Oddershede Gregersen, Alejandro Aguirre, Joseph Tassarotti, Lars Birkedal</dc:creator>
    </item>
    <item>
      <title>Characterisation of Lawvere-Tierney Topologies on Simplicial Sets, Bicolored Graphs, and Fuzzy Sets</title>
      <link>https://arxiv.org/abs/2407.04535</link>
      <description>arXiv:2407.04535v2 Announce Type: replace 
Abstract: Simplicial sets generalise many categories of graphs. In this paper, we give a complete characterisation of the Lawvere-Tierney topologies on (semi-)simplicial sets, on bicolored graphs, and on fuzzy sets. We apply our results to establish that 'partially simple' simplicial sets and 'partially simple' graphs form quasitoposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04535v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alo\"is Rosset, Helle Hvid Hansen, J\"org Endrullis</dc:creator>
    </item>
    <item>
      <title>Interaction Equivalence</title>
      <link>https://arxiv.org/abs/2409.18709</link>
      <description>arXiv:2409.18709v2 Announce Type: replace 
Abstract: Contextual equivalence is the de facto standard notion of program equivalence. A key theorem is that contextual equivalence is an equational theory. Making contextual equivalence more intensional, for example taking into account the time cost of the computation, seems a natural refinement. Such a change, however, does not induce an equational theory, for an apparently essential reason: cost is not invariant under reduction.
  In the paradigmatic case of the untyped $\lambda$-calculus, we introduce interaction equivalence. Inspired by game semantics, we observe the number of interaction steps between terms and contexts but -- crucially -- ignore their own internal steps. We prove that interaction equivalence is an equational theory and we characterize it as $B$, the well-known theory induced by B\"ohm tree equality. Ours is the first observational characterization of $B$ obtained without enriching the discriminating power of contexts with extra features such as non-determinism. To prove our results, we develop interaction-based refinements of the B\"ohm-out technique and of intersection types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18709v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Beniamino Accattoli, Adrienne Lancelot, Giulio Manzonetto, Gabriele Vanoni</dc:creator>
    </item>
    <item>
      <title>Almost Surely Asymptotically Constant Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2403.03880</link>
      <description>arXiv:2403.03880v3 Announce Type: replace-cross 
Abstract: We present a new angle on the expressive power of graph neural networks (GNNs) by studying how the predictions of real-valued GNN classifiers, such as those classifying graphs probabilistically, evolve as we apply them on larger graphs drawn from some random graph model. We show that the output converges to a constant function, which upper-bounds what these classifiers can uniformly express. This strong convergence phenomenon applies to a very wide class of GNNs, including state of the art models, with aggregates including mean and the attention-based mechanism of graph transformers. Our results apply to a broad class of random graph models, including sparse and dense variants of the Erd\H{o}s-R\'enyi model, the stochastic block model, and the Barab\'asi-Albert model. We empirically validate these findings, observing that the convergence phenomenon appears not only on random graphs but also on some real-world graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03880v3</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sam Adam-Day, Michael Benedikt, \.Ismail \.Ilkan Ceylan, Ben Finkelshtein</dc:creator>
    </item>
    <item>
      <title>Learning Brave Assumption-Based Argumentation Frameworks via ASP</title>
      <link>https://arxiv.org/abs/2408.10126</link>
      <description>arXiv:2408.10126v2 Announce Type: replace-cross 
Abstract: Assumption-based Argumentation (ABA) is advocated as a unifying formalism for various forms of non-monotonic reasoning, including logic programming. It allows capturing defeasible knowledge, subject to argumentative debate. While, in much existing work, ABA frameworks are given up-front, in this paper we focus on the problem of automating their learning from background knowledge and positive/negative examples. Unlike prior work, we newly frame the problem in terms of brave reasoning under stable extensions for ABA. We present a novel algorithm based on transformation rules (such as Rote Learning, Folding, Assumption Introduction and Fact Subsumption) and an implementation thereof that makes use of Answer Set Programming. Finally, we compare our technique to state-of-the-art ILP systems that learn defeasible knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10126v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuele De Angelis (CNR-IASI, Rome, Italy), Maurizio Proietti (CNR-IASI, Rome, Italy), Francesca Toni (Imperial, London, UK)</dc:creator>
    </item>
  </channel>
</rss>
