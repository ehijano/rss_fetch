<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 05:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Evaluating LLMs in Open-Source Games</title>
      <link>https://arxiv.org/abs/2512.00371</link>
      <description>arXiv:2512.00371v1 Announce Type: new 
Abstract: Large Language Models' (LLMs) programming capabilities enable their participation in open-source games: a game-theoretic setting in which players submit computer programs in lieu of actions. These programs offer numerous advantages, including interpretability, inter-agent transparency, and formal verifiability; additionally, they enable program equilibria, solutions that leverage the transparency of code and are inaccessible within normal-form settings. We evaluate the capabilities of leading open- and closed-weight LLMs to predict and classify program strategies and evaluate features of the approximate program equilibria reached by LLM agents in dyadic and evolutionary settings. We identify the emergence of payoff-maximizing, cooperative, and deceptive strategies, characterize the adaptation of mechanisms within these programs over repeated open-source games, and analyze their comparative evolutionary fitness. We find that open-source games serve as a viable environment to study and steer the emergence of cooperative strategy in multi-agent dilemmas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00371v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Swadesh Sistla, Max Kleiman-Weiner</dc:creator>
    </item>
    <item>
      <title>Truthful Double Auctions under Approximate VCG: Immediate-Penalty Enforcement in P2P Energy Trading</title>
      <link>https://arxiv.org/abs/2512.00513</link>
      <description>arXiv:2512.00513v1 Announce Type: new 
Abstract: This paper examines truthful double auctions when exact VCG allocation is computationally infeasible and repeated-game punishments are impractical. We analyze an $\alpha$-approximate VCG mechanism and show that truthful reporting becomes a subgame-perfect equilibrium when the immediate penalty exceeds the incentive gap created by approximation, scaled by monitoring accuracy. To validate this result, we construct a PPO-based multi-agent reinforcement learning environment for P2P smart-grid trading, where prosumers incur penalties for bidding far from their true valuations. Across systematic experiments varying approximation accuracy, tolerance, penalty magnitude, and discounting, the learned behavior closely matches theoretical predictions. The findings demonstrate that immediate-penalty approximate VCG mechanisms provide a practical and transparent approach to sustaining truthful behavior in distributed market settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00513v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xun Shao, Ryuuto Shimizu</dc:creator>
    </item>
    <item>
      <title>Stable Voting and the Splitting of Cycles</title>
      <link>https://arxiv.org/abs/2512.00616</link>
      <description>arXiv:2512.00616v1 Announce Type: new 
Abstract: Algorithms for resolving majority cycles in preference aggregation have been studied extensively in computational social choice. Several sophisticated cycle-resolving methods, including Tideman's Ranked Pairs, Schulze's Beat Path, and Heitzig's River, are refinements of the Split Cycle (SC) method that resolves majority cycles by discarding the weakest majority victories in each cycle. Recently, Holliday and Pacuit proposed a new refinement of Split Cycle, dubbed Stable Voting, and a simplification thereof, called Simple Stable Voting (SSV). They conjectured that SSV is a refinement of SC whenever no two majority victories are of the same size. In this paper, we prove the conjecture up to 6 alternatives and refute it for more than 6 alternatives. While our proof of the conjecture for up to 5 alternatives uses traditional mathematical reasoning, our 6-alternative proof and 7-alternative counterexample were obtained with the use of SAT solving. The SAT encoding underlying this proof and counterexample is applicable far beyond SC and SSV: it can be used to test properties of any voting method whose choice of winners depends only on the ordering of margins of victory by size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00616v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Milan Moss\'e, Chase Norman, Eric Pacuit, Cynthia Wang</dc:creator>
    </item>
    <item>
      <title>Price of Anarchy of Multi-Stage Machine Scheduling Games</title>
      <link>https://arxiv.org/abs/2512.00733</link>
      <description>arXiv:2512.00733v1 Announce Type: new 
Abstract: In this paper, we extend the discussion of the price of anarchy of machine scheduling games to a multi-stage machine setting. The multi-stage setting arises naturally in manufacturing pipelines and distributed computing workflows, when each job must traverse a fixed sequence of processing stages. While the classical makespan price of anarchy of $2 - \frac{1}{m}$ has been established for sequential scheduling on identical machines, the efficiency loss in multi-stage scheduling has, to the best of our knowledge, not been previously analyzed. We assume that each task follows a greedy strategy and gets assigned to the least-loaded machine upon arrival at each stage. Notably, we observe that in multi-stage environments, greedy behavior generally does not coincide with a subgame perfect Nash equilibrium. We continue with analyzing the equilibrium under greedy choices, since it is logical for modeling selfish agents with limited computational power, and may also model a central scheduler performing the common least-load scheduling heuristics. Under this model, we first show that in single-stage scheduling, greedy choice again yields an exact price of anarchy of $2 - \frac{1}{m}$. In multi-stage scheduling, we show that the completion time from one stage to the next increases by at most two times the maximum job execution time. Using this relationship, we derived the price of anarchy of multistage scheduling under greedy choices to lie within $[2 - \frac{1}{m}, 3 - \frac{1}{m}]$, where $m$ denote the maximum number of machines in one stage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00733v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ho-Lin Chen, Pin-Ju Huang</dc:creator>
    </item>
    <item>
      <title>Mechanism Design with Spiteful Agents</title>
      <link>https://arxiv.org/abs/2512.01021</link>
      <description>arXiv:2512.01021v1 Announce Type: new 
Abstract: We study a mechanism-design problem in which spiteful agents strive to not only maximize their rewards but also, contingent upon their own payoff levels, seek to lower the opponents' rewards. We characterize all individually rational (IR) and incentive-compatible (IC) mechanisms that are immune to such spiteful behavior, showing that they take the form of threshold mechanisms with an ordering of the agents. Building on this characterization, we prove two impossibility results: under either anonymity or efficiency, any such IR and IC mechanism collapses to the null mechanism, which never allocates the item to any agent. Leveraging these findings, we partially extend our analysis to a multi-item setup. These results illuminate the challenges of auctioning items in the natural presence of other-regarding preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01021v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Aradhye, David Lagziel, Eilon Solan</dc:creator>
    </item>
    <item>
      <title>Autodeleveraging: Impossibilities and Optimization</title>
      <link>https://arxiv.org/abs/2512.01112</link>
      <description>arXiv:2512.01112v1 Announce Type: new 
Abstract: Autodeleveraging (ADL) is a last-resort loss socialization mechanism for perpetual futures venues. It is triggered when solvency-preserving liquidations fail. Despite the dominance of perpetual futures in the crypto derivatives market, with over \$60 trillion of volume in 2024, there has been no formal study of ADL. In this paper, we provide the first rigorous model of ADL. We prove that ADL mechanisms face a fundamental \emph{trilemma}: no policy can simultaneously satisfy exchange \emph{solvency}, \emph{revenue}, and \emph{fairness} to traders. This impossibility theorem implies that as participation scales, a novel form of \emph{moral hazard} grows asymptotically, rendering `zero-loss' socialization impossible. Constructively, we show that three classes of ADL mechanisms can optimally navigate this trilemma to provide fairness, robustness to price shocks, and maximal exchange revenue. We analyze these mechanisms on the Hyperliquid dataset from October 10, 2025, when ADL was used repeatedly to close \$2.1 billion of positions in 12 minutes. By comparing our ADL mechanisms to the standard approaches used in practice, we demonstrate empirically that Hyperliquid's production queue overutilized ADL by approximately $8\times$ relative to our optimal policy, imposing roughly \$630 million of unnecessary haircuts on winning traders. This comparison also suggests that Binance overutilized ADL far more than Hyperliquid. Our results both theoretically and empirically demonstrate that optimized ADL mechanisms can dramatically reduce the loss of trader profits while maintaining exchange solvency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01112v1</guid>
      <category>cs.GT</category>
      <category>q-fin.RM</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarun Chitra</dc:creator>
    </item>
    <item>
      <title>Guarding Against Malicious Biased Threats (GAMBiT): Experimental Design of Cognitive Sensors and Triggers with Behavioral Impact Analysis</title>
      <link>https://arxiv.org/abs/2512.00098</link>
      <description>arXiv:2512.00098v1 Announce Type: cross 
Abstract: This paper introduces GAMBiT (Guarding Against Malicious Biased Threats), a cognitive-informed cyber defense framework that leverages deviations from human rationality as a new defensive surface. Conventional cyber defenses assume rational, utility-maximizing attackers, yet real-world adversaries exhibit cognitive constraints and biases that shape their interactions with complex digital systems. GAMBiT embeds insights from cognitive science into cyber environments through cognitive triggers, which activate biases such as loss aversion, base-rate neglect, and sunk-cost fallacy, and through newly developed cognitive sensors that infer attackers' cognitive states from behavioral and network data. Three rounds of human-subject experiments (total n=61) in a simulated small business network demonstrate that these manipulations significantly disrupt attacker performance, reducing mission progress, diverting actions off the true attack path, and increasing detectability. These results demonstrate that cognitive biases can be systematically triggered to degrade the attacker's efficiency and enhance the defender's advantage. GAMBiT establishes a new paradigm in which the attacker's mind becomes part of the battlefield and cognitive manipulation becomes a proactive vector for cyber defense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00098v1</guid>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Beltz, Po-Yu Chen, James Doty, Yvonne Fonken, Nikolos Gurney, Hsiang-Wen Hsing, Sofia Hirschmann, Brett Israelsen, Nathan Lau, Mengyun Li, Stacy Marsella, Michael Murray, Jinwoo Oh, Amy Sliva, Kunal Srivastava, Stoney Trent, Peggy Wu, Ya-Ting Yang, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Solving Neural Min-Max Games: The Role of Architecture, Initialization &amp; Dynamics</title>
      <link>https://arxiv.org/abs/2512.00389</link>
      <description>arXiv:2512.00389v1 Announce Type: cross 
Abstract: Many emerging applications - such as adversarial training, AI alignment, and robust optimization - can be framed as zero-sum games between neural nets, with von Neumann-Nash equilibria (NE) capturing the desirable system behavior. While such games often involve non-convex non-concave objectives, empirical evidence shows that simple gradient methods frequently converge, suggesting a hidden geometric structure. In this paper, we provide a theoretical framework that explains this phenomenon through the lens of hidden convexity and overparameterization. We identify sufficient conditions - spanning initialization, training dynamics, and network width - that guarantee global convergence to a NE in a broad class of non-convex min-max games. To our knowledge, this is the first such result for games that involve two-layer neural networks. Technically, our approach is twofold: (a) we derive a novel path-length bound for the alternating gradient descent-ascent scheme in min-max games; and (b) we show that the reduction from a hidden convex-concave geometry to two-sided Polyak-{\L}ojasiewicz (P{\L}) min-max condition hold with high probability under overparameterization, using tools from random matrix theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00389v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deep Patel, Emmanouil-Vasileios Vlatakis-Gkaragkounis</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization for Non-Cooperative Game-Based Radio Resource Management</title>
      <link>https://arxiv.org/abs/2512.01245</link>
      <description>arXiv:2512.01245v1 Announce Type: cross 
Abstract: Radio resource management in modern cellular networks often calls for the optimization of complex utility functions that are potentially conflicting between different base stations (BSs). Coordinating the resource allocation strategies efficiently across BSs to ensure stable network service poses significant challenges, especially when each utility is accessible only via costly, black-box evaluations. This paper considers formulating the resource allocation among spectrum sharing BSs as a non-cooperative game, with the goal of aligning their allocation incentives toward a stable outcome. To address this challenge, we propose PPR-UCB, a novel Bayesian optimization (BO) strategy that learns from sequential decision-evaluation pairs to approximate pure Nash equilibrium (PNE) solutions. PPR-UCB applies martingale techniques to Gaussian process (GP) surrogates and constructs high probability confidence bounds for utilities uncertainty quantification. Experiments on downlink transmission power allocation in a multi-cell multi-antenna system demonstrate the efficiency of PPR-UCB in identifying effective equilibrium solutions within a few data samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01245v1</guid>
      <category>eess.SP</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunchuan Zhang, Jiechen Chen, Junshuo Liu, Robert C. Qiu</dc:creator>
    </item>
    <item>
      <title>Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation</title>
      <link>https://arxiv.org/abs/2512.01723</link>
      <description>arXiv:2512.01723v1 Announce Type: cross 
Abstract: Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N &lt;&lt; 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01723v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saba Kublashvili</dc:creator>
    </item>
    <item>
      <title>The Active and Noise-Tolerant Strategic Perceptron</title>
      <link>https://arxiv.org/abs/2512.01783</link>
      <description>arXiv:2512.01783v1 Announce Type: cross 
Abstract: We initiate the study of active learning algorithms for classifying strategic agents. Active learning is a well-established framework in machine learning in which the learner selectively queries labels, often achieving substantially higher accuracy and efficiency than classical supervised methods-especially in settings where labeling is costly or time-consuming, such as hiring, admissions, and loan decisions. Strategic classification, however, addresses scenarios where agents modify their features to obtain more favorable outcomes, resulting in observed data that is not truthful. Such manipulation introduces challenges beyond those in learning from clean data. Our goal is to design active and noise-tolerant algorithms that remain effective in strategic environments-algorithms that classify strategic agents accurately while issuing as few label requests as possible. The central difficulty is to simultaneously account for strategic manipulation and preserve the efficiency gains of active learning.
  Our main result is an algorithm for actively learning linear separators in the strategic setting that preserves the exponential improvement in label complexity over passive learning previously obtained only in the non-strategic case. Specifically, for data drawn uniformly from the unit sphere, we show that a modified version of the Active Perceptron algorithm [DKM05,YZ17] achieves excess error $\epsilon$ using only $\tilde{O}(d \ln \frac{1}{\epsilon})$ label queries and incurs at most $\tilde{O}(d \ln \frac{1}{\epsilon})$ additional mistakes relative to the optimal classifier, even in the nonrealizable case, when a $\tilde{\Omega}(\epsilon)$ fraction of inputs have inconsistent labels with the optimal classifier. The algorithm is computationally efficient and, under these distributional assumptions, requires substantially fewer label queries than prior work on strategic Perceptron [ABBN21].</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01783v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Florina Blacan, Hedyeh Beyhaghi</dc:creator>
    </item>
    <item>
      <title>The Condorcet Dimension of Metric Spaces</title>
      <link>https://arxiv.org/abs/2410.09201</link>
      <description>arXiv:2410.09201v4 Announce Type: replace 
Abstract: A Condorcet winning set is a set of candidates such that no other candidate is preferred by at least half the voters over all members of the set. The Condorcet dimension, which is the minimum cardinality of a Condorcet winning set, is known to be at most logarithmic in the number of candidates. We study the case of elections where voters and candidates are located in a $2$-dimensional space with preferences based upon proximity voting. Our main result is that the Condorcet dimension is at most $3$, under both the Manhattan norm and the infinity norm, natural measures in electoral systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09201v4</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandra Lassota, Adrian Vetta, Bernhard von Stengel</dc:creator>
    </item>
    <item>
      <title>Approximately Dominating Sets in Elections</title>
      <link>https://arxiv.org/abs/2504.20372</link>
      <description>arXiv:2504.20372v3 Announce Type: replace 
Abstract: Condorcet's paradox is a fundamental result in social choice theory which states that there exist elections in which, no matter which candidate wins, a majority of voters prefer a different candidate. In fact, even if we can select any $k$ winners, there still may exist another candidate that would beat each of the winners in a majority vote. That is, elections may require arbitrarily large dominating sets.
  We show that approximately dominating sets of constant size always exist. In particular, for every $\varepsilon &gt; 0$, every election (irrespective of the number of voters or candidates) can select $O(\frac{1}{\varepsilon ^2})$ winners such that no other candidate beats each of the winners by a margin of more than $\varepsilon$ fraction of voters.
  Our proof uses a simple probabilistic construction using samples from a maximal lottery, a well-studied distribution over candidates derived from the Nash equilibrium of a two-player game. In stark contrast to general approximate equilibria, which may require support logarithmic in the number of pure strategies, we show that maximal lotteries can be approximated with constant support size. These approximate maximal lotteries may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20372v3</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moses Charikar, Prasanna Ramakrishnan, Kangning Wang</dc:creator>
    </item>
    <item>
      <title>Temporal Cooperative Games</title>
      <link>https://arxiv.org/abs/2510.11255</link>
      <description>arXiv:2510.11255v3 Announce Type: replace 
Abstract: Classical cooperative game theory assumes that the worth of a coalition depends only on the set of agents involved, but in practice, it may also depend on the order in which agents arrive. Motivated by such scenarios, we introduce temporal cooperative games (TCG), where the worth $v$ becomes a function of the sequence of agents $\pi$ rather than just the set $S$. This shift calls for rethinking the underlying axioms. A key property in this temporal framework is the incentive for optimal arrival (I4OA), which encourages agents to join in the order maximizing total worth. Alongside, we define two additional properties: online individual rationality (OIR), incentivizing earlier agents to invite more participants, and sequential efficiency (SE), ensuring that the total worth of any sequence is fully distributed among its agents. We identify a class of reward-sharing mechanisms uniquely characterized by these three properties. The classical Shapley value does not directly apply here, so we construct its natural analogs in two variants: the sequential world, where rewards are defined for each sequence-player pair, and the extended world, where rewards are defined for each player alone. Properties of efficiency, additivity, and null player uniquely determine these Shapley analogs in both worlds. Importantly, the Shapley analogs are disjoint from mechanisms satisfying I4OA, OIR, and SE, and this conflict persists even for restricted classes such as convex and simple TCGs. Our findings thus uncover a fundamental tension: when players arrive sequentially, reward-sharing mechanisms satisfying desirable temporal properties must inherently differ from Shapley-inspired ones, opening new questions for defining fair and efficient solution concepts in TCGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11255v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ashwin Goyal, Drashthi Doshi, Swaprava Nath</dc:creator>
    </item>
    <item>
      <title>Computing Evolutionarily Stable Strategies in Multiplayer Games</title>
      <link>https://arxiv.org/abs/2511.20859</link>
      <description>arXiv:2511.20859v2 Announce Type: replace 
Abstract: We present an algorithm for computing all evolutionarily stable strategies in nondegenerate normal-form games with three or more players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20859v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sam Ganzfried</dc:creator>
    </item>
    <item>
      <title>A General Framework for a Class of Quarrels: The Quarrelling Paradox Revisited</title>
      <link>https://arxiv.org/abs/2205.08353</link>
      <description>arXiv:2205.08353v2 Announce Type: replace-cross 
Abstract: If a measure of voting power assigns players greater voting power because they no longer effectively cooperate, then it displays the quarrelling paradox and violates the quarrel postulate. However, we prove that certain types of quarrel increase some quarrellers' voting power on any proposed measure. On the one hand, such quarrels are politically significant because they incentivize players to strategically join coalitions in order to sabotage them from within; on the other, a postulate based on them cannot provide a reasonable normative criterion for evaluating measures of voting power. We therefore formalize a general framework of quarrels -- comprising twelve conceptions distinguished according to symmetry, reciprocality, and strength -- and provide criteria for whether a conception provides a suitable basis for a reasonable quarrel postulate. Although the two existing conceptions, proposed by Felsenthal and Machover and by Laruelle and Valenciano, do not, our framework's symmetric, weak conception does.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.08353v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Abizadeh, Adrian Vetta</dc:creator>
    </item>
    <item>
      <title>An AI Capability Threshold for Rent-Funded Universal Basic Income in an AI-Automated Economy</title>
      <link>https://arxiv.org/abs/2505.18687</link>
      <description>arXiv:2505.18687v3 Announce Type: replace-cross 
Abstract: We derive the first closed-form condition under which artificial intelligence (AI) capital profits could sustainably finance a universal basic income (UBI) without relying on new taxation or the creation of new jobs. In a Solow-Zeira task-automation economy with a CES aggregator $\sigma &lt; 1$, we introduce an AI capability parameter that scales the productivity of automatable tasks and obtain a tractable expression for the AI capability threshold -- the minimum productivity of AI relative to pre-AI automation required for a balanced transfer.
  Using current U.S. economic parameters, we find that even in the conservative scenario where no new tasks or jobs emerge, AI systems would only need to reach only 5-7 times today's automation productivity to fund an 11%-of-GDP UBI.
  Our analysis also reveals some specific policy levers: raising public revenue share (e.g. profit taxation) of AI capital from the current 15% to about 33% halves the required AI capability threshold to attain UBI to 3 times existing automation productivity, but gains diminish beyond 50% public revenue share, especially if regulatory costs increase. Market structure also strongly affects outcomes: monopolistic or concentrated oligopolistic markets reduce the threshold by increasing economic rents, whereas heightened competition significantly raises it.
  These results therefore offer a rigorous benchmark for assessing when advancing AI capabilities might sustainably finance social transfers in an increasingly automated economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18687v3</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aran Nayebi</dc:creator>
    </item>
    <item>
      <title>Matroids are Equitable</title>
      <link>https://arxiv.org/abs/2507.12100</link>
      <description>arXiv:2507.12100v2 Announce Type: replace-cross 
Abstract: We show that if the ground set of a matroid can be partitioned into $k\ge 2$ bases, then for any given subset $S$ of the ground set, there is a partition into $k$ bases such that the sizes of the intersections of the bases with $S$ may differ by at most one. This settles the matroid equitability conjecture by Fekete and Szab\'o (Electron. J. Comb. 2011) in the affirmative. We also investigate equitable splittings of two disjoint sets $S_1$ and $S_2$, and show that there is a partition into $k$ bases such that the sizes of the intersections with $S_1$ may differ by at most one and the sizes of the intersections with $S_2$ may differ by at most two; this is the best one can hope for arbitrary matroids.
  We also derive applications of this result into matroid constrained fair division problems. We show that there exists a matroid-constrained fair division that is envy-free up to one item if the valuations are identical and tri-valued additive. We also show that for bi-valued additive valuations, there exists a matroid-constrained allocation that provides everyone their maximin share.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12100v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Siyue Liu, Roshan Raj, L\'aszl\'o A. V\'egh</dc:creator>
    </item>
    <item>
      <title>Gaming and Cooperation in Federated Learning: What Can Happen and How to Monitor It</title>
      <link>https://arxiv.org/abs/2509.02391</link>
      <description>arXiv:2509.02391v2 Announce Type: replace-cross 
Abstract: The success of federated learning (FL) ultimately depends on how strategic participants behave under partial observability, yet most formulations still treat FL as a static optimization problem. We instead view FL deployments as governed strategic systems and develop an analytical framework that separates welfare-improving behavior from metric gaming. Within this framework, we introduce indices that quantify manipulability, the price of gaming, and the price of cooperation, and we use them to study how rules, information disclosure, evaluation metrics, and aggregator-switching policies reshape incentives and cooperation patterns. We derive threshold conditions for deterring harmful gaming while preserving benign cooperation, and for triggering auto-switch rules when early-warning indicators become critical. Building on these results, we construct a design toolkit including a governance checklist and a simple audit-budget allocation algorithm with a provable performance guarantee. Simulations across diverse stylized environments and a federated learning case study consistently match the qualitative and quantitative patterns predicted by our framework. Taken together, our results provide design principles and operational guidelines for reducing metric gaming while sustaining stable, high-welfare cooperation in FL platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02391v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongseok Kim, Hyoungsun Choi, Mohamed Jismy Aashik Rasool, Gisung Oh</dc:creator>
    </item>
    <item>
      <title>Learning the Value of Value Learning</title>
      <link>https://arxiv.org/abs/2511.17714</link>
      <description>arXiv:2511.17714v2 Announce Type: replace-cross 
Abstract: Standard decision frameworks addresses uncertainty about facts but assumes fixed values. We extend the Jeffrey-Bolker framework to model refinements in values and prove a value-of-information theorem for axiological refinement. In multi-agent settings, we establish that mutual refinement will characteristically transform zero-sum games into positive-sum interactions and yields Pareto-improving Nash bargains. These results show that a framework of rational choice can be extended to model value refinement and its associated benefits. By unifying epistemic and axiological refinement under a single formalism, we broaden the conceptual foundations of rational choice and illuminate the normative status of ethical deliberation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17714v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex John London, Aydin Mohseni</dc:creator>
    </item>
  </channel>
</rss>
