<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Jan 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Probabilistic WxChallenge Proposal</title>
      <link>https://arxiv.org/abs/2501.14139</link>
      <description>arXiv:2501.14139v1 Announce Type: new 
Abstract: The national forecasting competition WxChallenge, brainchild of Brad Illston at the University of Oklahoma in 2005, has become a cherished institution played across the United States each year. Participants include students, faculty, alumni, and industry professionals. However, forecasts are given as scalar values without expression of uncertainty, probabilities being a keystone of meteorological forecasting today, and previous attempts to add probabilistic elements to WxChallenge have failed partly due to challenges in making probability forecasting accessible to all, and inability to combine scores with different units while also appropriately rewarding forecasts using proper scoring rules. Much of the competition's maintenance relies on dedicated volunteers, highlighting need for more automation. Hence I propose three new features: (1) automated forecast problems based on morning ensemble guidance, forming prediction baselines, thresholds over which the players demonstrate skill in their later forecast; (2) a spread betting game, where the players allocate 100 confidence credits to the over-under for exceeding a percentile (e.g., 50pc) threshold of a variable (e.g., maximum temperature) derived from the ensemble baseline; and (3) a game where players distribute 100 confidence credits across bins of a continuous variable (e.g., accumulated precipitation) approximating a probability mass function. Forecasts are evaluated using Shannon information gained over the baseline forecast, yielding additive units of bits that allow score combinations of different variables and units. Information gain parallels the Brier Score and is likewise a sound measure of skill due its punishment of hedging. This proposal objective is to augment WxChallenge with two new probabilistic games that are accessible, scientifically sound, enjoyable, and optional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14139v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John R. Lawson</dc:creator>
    </item>
    <item>
      <title>K-Anonymous A/B Testing</title>
      <link>https://arxiv.org/abs/2501.14329</link>
      <description>arXiv:2501.14329v1 Announce Type: new 
Abstract: A core principle of Privacy by Design (PbD) is minimizing the data that is stored or shared about each individual respondent. PbD principles are mandated by the GDPR (see Article 5c and Article 25), as well as informing aspects of California Privacy Rights Act (CPRA). This paper describes a simple and effective approach that can be used in many a/b testing and similar contexts to help meet these PbD goals. Specifically, the method presented describes an approach to run OLS regression on k-anonymized data. To help illustrate the general utility of this approach, descriptions of two important use cases are offered: 1) calculating partial f-tests as a simple way to both check for a/b test interactions and to test for heterogeneity of treatment effects; and 2) regression adjustment using an approach similar to the popular CUPED method, as a variance reduction method for a/b tests. Using this method has advantages for privacy and compliance, as well as often reducing data storage and processing costs, by storing, sharing, or analyzing only aggregate level rather than individual level data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14329v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Gershoff</dc:creator>
    </item>
    <item>
      <title>Traffic noise assessment in urban Bulgaria using explainable machine learning</title>
      <link>https://arxiv.org/abs/2501.14437</link>
      <description>arXiv:2501.14437v1 Announce Type: new 
Abstract: Fine-grained noise maps are vital for epidemiological studies on traffic noise. However, detailed information on traffic noise is often limited, especially in Eastern Europe. Rigid linear noise land-use regressions are typically employed to estimate noise levels; however, machine learning likely offers more accurate noise predictions. We innovated by comparing the predictive accuracies of supervised machine learning models to estimate traffic noise levels across the five largest Bulgarian cities. In situ A-weighted equivalent continuous sound levels were obtained from 232 fixed-site monitors across these cities. We included transport- and land-use-related predictors using 50-1,000 m buffers. Extreme gradient boosting (XGB) had the highest ten-fold cross-validated fit (R2=0.680) and the lowest root mean square error (RMSE=4.739), insignificantly besting the random forest-based model (R2=0.667, RMSE=4.895). Support vector regression (R2=0.633, RMSE=5.358), elastic net (R2=0.568, RMSE=5.625), and linear regression (R2=0.548, RMSE=5.569) performed significantly worse. Shapley values for the XGB showed that the length of major roads within 100 m buffers, footways within 50 m buffers, residential roads within 50 m buffers, and the number of buildings within 50 m buffers were important non-linear predictors. Our spatially resolved noise maps revealed striking geographic noise variations and that, on average, 96.8% of the urban population experiences harmful noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14437v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Helbic, Julian Hagenauer, Angel Burov, Angel M. Dzhambov</dc:creator>
    </item>
    <item>
      <title>QuIP: Experimental design for expensive simulators with many Qualitative factors via Integer Programming</title>
      <link>https://arxiv.org/abs/2501.14616</link>
      <description>arXiv:2501.14616v1 Announce Type: new 
Abstract: The need to explore and/or optimize expensive simulators with many qualitative factors arises in broad scientific and engineering problems. Our motivating application lies in path planning - the exploration of feasible paths for navigation, which plays an important role in robotics, surgical planning and assembly planning. Here, the feasibility of a path is evaluated via expensive virtual experiments, and its parameter space is typically discrete and high-dimensional. A carefully selected experimental design is thus essential for timely decision-making. We propose here a novel framework, called QuIP, for experimental design of Qualitative factors via Integer Programming under a Gaussian process surrogate model with an exchangeable covariance function. For initial design, we show that its asymptotic D-optimal design can be formulated as a variant of the well-known assignment problem in operations research, which can be efficiently solved to global optimality using state-of-the-art integer programming solvers. For sequential design (specifically, for active learning or black-box optimization), we show that its design criterion can similarly be formulated as an assignment problem, thus enabling efficient and reliable optimization with existing solvers. We then demonstrate the effectiveness of QuIP over existing methods in a suite of path planning experiments and an application to rover trajectory optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14616v1</guid>
      <category>stat.AP</category>
      <category>cs.RO</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yen-Chun Liu, Simon Mak</dc:creator>
    </item>
    <item>
      <title>Understanding the Hamiltonian Monte Carlo through its Physics Fundamentals and Examples</title>
      <link>https://arxiv.org/abs/2501.13932</link>
      <description>arXiv:2501.13932v1 Announce Type: cross 
Abstract: The Hamiltonian Monte Carlo (HMC) algorithm is a powerful Markov Chain Monte Carlo (MCMC) method that uses Hamiltonian dynamics to generate samples from a target distribution. To fully exploit its potential, we must understand how Hamiltonian dynamics work and why they can be used in a MCMC algorithm. This work elucidates the Monte Carlo Hamiltonian, providing comprehensive explanations of the underlying physical concepts. It is intended for readers with a solid foundation in mathematics who may lack familiarity with specific physical concepts, such as those related to Hamiltonian dynamics. Additionally, we provide Python code for the HMC algorithm, examples and comparisons with the Random Walk Metropolis-Hastings (RWMH) and t-walk algorithms to highlight HMC's strengths and weaknesses when applied to Bayesian Inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13932v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abraham Granados, Isa\'ias Ba\~nales</dc:creator>
    </item>
    <item>
      <title>Assessing treatment efficacy for interval-censored endpoints using multistate semi-Markov models fit to multiple data streams</title>
      <link>https://arxiv.org/abs/2501.14097</link>
      <description>arXiv:2501.14097v1 Announce Type: cross 
Abstract: We introduce a computationally efficient and general approach for utilizing multiple, possibly interval-censored, data streams to study complex biomedical endpoints using multistate semi-Markov models. Our motivating application is the REGEN-2069 trial, which investigated the protective efficacy (PE) of the monoclonal antibody combination REGEN-COV against SARS-CoV-2 when administered prophylactically to individuals in households at high risk of secondary transmission. Using data on symptom onset, episodic RT-qPCR sampling, and serological testing, we estimate the PE of REGEN-COV for asymptomatic infection, its effect on seroconversion following infection, and the duration of viral shedding. We find that REGEN-COV reduced the risk of asymptomatic infection and the duration of viral shedding, and led to lower rates of seroconversion among asymptomatically infected participants. Our algorithm for fitting semi-Markov models to interval-censored data employs a Monte Carlo expectation maximization (MCEM) algorithm combined with importance sampling to efficiently address the intractability of the marginal likelihood when data are intermittently observed. Our algorithm provide substantial computational improvements over existing methods and allows us to fit semi-parametric models despite complex coarsening of the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14097v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raphael Morsomme, C. Jason Liang, Allyson Mateja, Dean A. Follmann, Meagan P. O'Brien, Chenguang Wang, Jonathan Fintzi</dc:creator>
    </item>
    <item>
      <title>Selecting Critical Scenarios of DER Adoption in Distribution Grids Using Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2501.14118</link>
      <description>arXiv:2501.14118v1 Announce Type: cross 
Abstract: We develop a new methodology to select scenarios of DER adoption most critical for distribution grids. Anticipating risks of future voltage and line flow violations due to additional PV adopters is central for utility investment planning but continues to rely on deterministic or ad hoc scenario selection. We propose a highly efficient search framework based on multi-objective Bayesian Optimization. We treat underlying grid stress metrics as computationally expensive black-box functions, approximated via Gaussian Process surrogates and design an acquisition function based on probability of scenarios being Pareto-critical across a collection of line- and bus-based violation objectives. Our approach provides a statistical guarantee and offers an order of magnitude speed-up relative to a conservative exhaustive search. Case studies on realistic feeders with 200-400 buses demonstrate the effectiveness and accuracy of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14118v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Mulkin, Miguel Heleno, Mike Ludkovski</dc:creator>
    </item>
    <item>
      <title>Facies Classification with Copula Entropy</title>
      <link>https://arxiv.org/abs/2501.14351</link>
      <description>arXiv:2501.14351v1 Announce Type: cross 
Abstract: In this paper we propose to apply copula entropy (CE) to facies classification. In our method, the correlations between geological variables and facies classes are measured with CE and then the variables associated with large negative CEs are selected for classification. We verified the proposed method on a typical facies dataset for facies classification and the experimental results show that the proposed method can select less geological variables for facies classification without sacrificing classification performance. The geological variables such selected are also interpretable to geologists with geological meanings due to the rigorous definition of CE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14351v1</guid>
      <category>cs.LG</category>
      <category>physics.geo-ph</category>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Ma</dc:creator>
    </item>
    <item>
      <title>Statistical Verification of Linear Classifiers</title>
      <link>https://arxiv.org/abs/2501.14430</link>
      <description>arXiv:2501.14430v1 Announce Type: cross 
Abstract: We propose a homogeneity test closely related to the concept of linear separability between two samples. Using the test one can answer the question whether a linear classifier is merely ``random'' or effectively captures differences between two classes. We focus on establishing upper bounds for the test's \emph{p}-value when applied to two-dimensional samples. Specifically, for normally distributed samples we experimentally demonstrate that the upper bound is highly accurate. Using this bound, we evaluate classifiers designed to detect ER-positive breast cancer recurrence based on gene pair expression. Our findings confirm significance of IGFBP6 and ELOVL5 genes in this process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14430v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Zhiyanov, Alexander Shklyaev, Alexey Galatenko, Vladimir Galatenko, Alexander Tonevitsky</dc:creator>
    </item>
    <item>
      <title>On Correlating Factors for Domain Adaptation Performance</title>
      <link>https://arxiv.org/abs/2501.14466</link>
      <description>arXiv:2501.14466v1 Announce Type: cross 
Abstract: Dense retrievers have demonstrated significant potential for neural information retrieval; however, they lack robustness to domain shifts, limiting their efficacy in zero-shot settings across diverse domains. In this paper, we set out to analyze the possible factors that lead to successful domain adaptation of dense retrievers. We include domain similarity proxies between generated queries to test and source domains. Furthermore, we conduct a case study comparing two powerful domain adaptation techniques. We find that generated query type distribution is an important factor, and generating queries that share a similar domain to the test documents improves the performance of domain adaptation methods. This study further emphasizes the importance of domain-tailored generated queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14466v1</guid>
      <category>cs.IR</category>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Goksenin Yuksel, Jaap Kamps</dc:creator>
    </item>
    <item>
      <title>Hierarchical Count Echo State Network Models with Application to Graduate Student Enrollments</title>
      <link>https://arxiv.org/abs/2501.14698</link>
      <description>arXiv:2501.14698v1 Announce Type: cross 
Abstract: Poisson autoregressive count models have evolved into a time series staple for correlated count data. This paper proposes an alternative to Poisson autoregressions: count echo state networks. Echo state networks can be statistically analyzed in frequentist manners via optimizing penalized likelihoods, or in Bayesian manners via MCMC sampling. This paper develops Poisson echo state techniques for count data and applies them to a massive count data set containing the number of graduate students from 1,758 United States universities during the years 1972-2021 inclusive. Negative binomial models are also implemented to better handle overdispersion in the counts. Performance of the proposed models are compared via their forecasting performance as judged by several methods. In the end, a hierarchical negative binomial based echo state network is judged as the superior model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14698v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Wang, Paul A. Parker, Robert B. Lund</dc:creator>
    </item>
    <item>
      <title>Latency correction in sparse neuronal spike trains with overlapping global events</title>
      <link>https://arxiv.org/abs/2410.15018</link>
      <description>arXiv:2410.15018v2 Announce Type: replace-cross 
Abstract: Background: In Kreuz et al., J Neurosci Methods 381, 109703 (2022) two methods were proposed that perform latency correction, i.e., optimize the spike time alignment of sparse neuronal spike trains with well defined global spiking events. The first one based on direct shifts is fast but uses only partial latency information, while the other one makes use of the full information but relies on the computationally costly simulated annealing. Both methods reach their limits and can become unreliable when successive global events are not sufficiently separated or even overlap.
  New Method: Here we propose an iterative scheme that combines the advantages of the two original methods by using in each step as much of the latency information as possible and by employing a very fast extrapolation direct shift method instead of the much slower simulated annealing.
  Results: We illustrate the effectiveness and the improved performance, measured in terms of the relative shift error, of the new iterative scheme not only on simulated data with known ground truths but also on single-unit recordings from two medial superior olive neurons of a gerbil.
  Comparison with Existing Method(s): The iterative scheme outperforms the existing approaches on both the simulated and the experimental data. Due to its low computational demands, and in contrast to simulated annealing, it can also be applied to very large datasets.
  Conclusions: The new method generalizes and improves on the original method both in terms of accuracy and speed. Importantly, it is the only method that allows to disentangle global events with overlap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15018v2</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <category>physics.data-an</category>
      <category>physics.med-ph</category>
      <category>stat.AP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arturo Mariani, Federico Senocrate, Jason Mikiel-Hunter, David McAlpine, Barbara Beiderbeck, Michael Pecka, Kevin Lin, Thomas Kreuz</dc:creator>
    </item>
  </channel>
</rss>
