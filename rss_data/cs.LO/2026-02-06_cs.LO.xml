<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Reachability Problem for One-Dimensional Thin Grammar Vector Addition Systems</title>
      <link>https://arxiv.org/abs/2602.05315</link>
      <description>arXiv:2602.05315v1 Announce Type: new 
Abstract: Vector addition systems with states (VASS) are a classic model in concurrency theory. Grammar vector addition systems (GVAS), equivalently, pushdown VASS, extend VASS by using a context-free grammar to control addition. In this paper, our main focus is on the reachability problem for one-dimensional thin GVAS (thin 1-GVAS), a structurally restricted yet expressive subclass. By adopting the index measure for complexity, and by generalizing the decomposition technique developed in the study of VASS reachability to grammar-generated derivation trees of GVAS, an effective integer programming system is established for a thin 1-GVAS. In this way, a nondeterministic algorithm with $\mathbf{F}_{2k}$ complexity is obtained for the reachability of thin 1-GVAS with index $k$, yielding a tighter upper bound than the previous one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05315v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengfeng Xue, Yuxi Fu</dc:creator>
    </item>
    <item>
      <title>Groups and Inverse Semigroups in Lambda Calculus</title>
      <link>https://arxiv.org/abs/2602.05654</link>
      <description>arXiv:2602.05654v1 Announce Type: new 
Abstract: We study invertibility of $\lambda$-terms modulo $\lambda$-theories. Here a fundamental role is played by a class of $\lambda$-terms called finite hereditary permutations (FHP) and by their infinite generalisations (HP). More precisely, FHPs are the invertible elements in the least extensional $\lambda$-theory $\lambda \eta$ and HPs are those in the greatest sensible $\lambda$-theory $H^*$. Our approach is based on inverse semigroups, algebraic structures that generalise groups and semilattices. We show that FHP modulo a $\lambda$-theory $T$ is always an inverse semigroup and that HP modulo $T$ is an inverse semigroup whenever $T$ contains the theory of B\"ohm trees. An inverse semigroup comes equipped with a natural order. We prove that the natural order corresponds to $\eta$-expansion in $\mathrm{FHP} /T$, and to infinite $\eta$-expansion in $\mathrm{HP}/T$. Building on these correspondences we obtain the two main contributions of this work: firstly, we recast in a broader framework the results cited at the beginning; secondly, we prove that the FHPs are the invertible $\lambda$-terms in all the $\lambda$-theories lying between $\lambda \eta$ and $H^+$. The latter is Morris' observational $\lambda$-theory, defined by using the $\beta$-normal forms as observables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05654v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Bucciarelli, Arturo De Faveri, Giulio Manzonetto, Antonino Salibra</dc:creator>
    </item>
    <item>
      <title>Strong Normalisation for Asynchronous Effects</title>
      <link>https://arxiv.org/abs/2602.05528</link>
      <description>arXiv:2602.05528v1 Announce Type: cross 
Abstract: Asynchronous effects of Ahman and Pretnar complement the conventional synchronous treatment of algebraic computational effects with asynchrony based on decoupling the execution of algebraic operation calls into signalling that an operation's implementation needs to be executed, and into interrupting a running computation with the operation's result, to which the computation can react by installing matching interrupt handlers. Beyond providing asynchrony for algebraic effects, the resulting core calculus also naturally models examples such as pre-emptive multi-threading, (cancellable) remote function calls, multi-party applications, and even a parallel variant of runners of algebraic effects. In this paper, we study the normalisation properties of this calculus. We prove that if one removes general recursion from the original calculus, then the remaining calculus is strongly normalising, including both its sequential and parallel parts. However, this only guarantees termination for very simple asynchronous examples. To improve on this result, we also prove that the sequential fragment of the calculus remains strongly normalising when a controlled amount of interrupt-driven recursive behaviour is reintroduced. Our strong normalisation proofs are structured compositionally as a natural extension of Lindley and Stark's $\top\top$-lifting based approach for proving strong normalisation of effectful languages. All our results are also formalised in Agda.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05528v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danel Ahman, Ilja Sobolev</dc:creator>
    </item>
    <item>
      <title>RocqSmith: Can Automatic Optimization Forge Better Proof Agents?</title>
      <link>https://arxiv.org/abs/2602.05762</link>
      <description>arXiv:2602.05762v1 Announce Type: cross 
Abstract: This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different automatic agent optimizers perform when applied to the task of optimizing a Rocq proof-generation agent, and assess whether parts of the fine-grained tuning of agentic systems, such as prompt design, contextual knowledge, and control strategies, can be automated. Our results show that while several optimizers yield measurable improvements, simple few-shot bootstrapping is the most consistently effective; however, none of the studied methods matches the performance of a carefully engineered state-of-the-art proof agent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05762v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Kozyrev, Nikita Khramov, Denis Lochmelis, Valerio Morelli, Gleb Solovev, Anton Podkopaev</dc:creator>
    </item>
    <item>
      <title>Compression for Coinductive Infinitary Rewriting: A Generic Approach, with Applications to Cut-Elimination for Non-Wellfounded Proofs</title>
      <link>https://arxiv.org/abs/2510.08420</link>
      <description>arXiv:2510.08420v2 Announce Type: replace 
Abstract: We introduce a generic presentation of 'syntactic objects built by mixed induction and coinduction' encompassing all standard kinds of infinitary terms, as well as derivation trees in non-wellfounded proof systems. We then define a notion of coinductive rewriting of such objects, which is equivalent to the original presentation of infinitary rewriting relying on metric convergence and ordinal-indexed sequences of rewriting steps. This provides a unified coinductive presentation of e.g. first-order infinitary rewriting, infinitary \lambda-calculi, and cut-elimination in non-wellfounded proofs.
  We then formulate and study the coinductive counterpart of compression, i.e. the property of an infinitary rewriting system such that all rewriting sequences of any ordinal length can be 'compressed' to equivalent sequences of length at most \omega (which ensures that they can be finitely approximated). We characterise compression in our generic setting for coinductive rewriting, 'factorising' the part of the proof that can be performed at this level of generality. Our proof is fully coinductive, avoiding any detour via rewriting sequences.
  Finally we focus on the non-wellfounded proof system \muMALL\infty for multiplicative-additive linear logic with fixed points, and we put our results to work in order to prove that compression holds for cut-elimination in this setting, which is a key lemma of several extension of cut-elimination to similar systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08420v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R\'emy Cerda, Alexis Saurin</dc:creator>
    </item>
    <item>
      <title>Morita Rigidity for Kleene Algebras</title>
      <link>https://arxiv.org/abs/2510.24993</link>
      <description>arXiv:2510.24993v2 Announce Type: replace 
Abstract: We introduce Morita equivalence to the study of Kleene algebras and modules. Classical characterizations of Morita-equivalent semirings such as having equivalent categories of modules and one semiring being a full matrix algebra over the other carry over. We also observe that Morita equivalence can be applied to extending and restricting scalars in Lindenbaum Tarski algebras of propositional dynamic logics. But the signature result which we obtain is a form of rigidity for Kleene algebras, which states that if the semiring reducts of two Kleene algebras are Morita-equivalent, then the Morita equivalence is in fact witnessed by Kleene bimodules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24993v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Serafin</dc:creator>
    </item>
    <item>
      <title>Cut-free Deductive System for Continuous Intuitionistic Logic</title>
      <link>https://arxiv.org/abs/2510.26849</link>
      <description>arXiv:2510.26849v4 Announce Type: replace 
Abstract: We introduce and develop propositional continuous intuitionistic logic and propositional continuous affine logic via complete algebraic semantics. Our approach centres on AC-algebras, which are algebras $USC(\mathcal{L})$ of sup-preserving functions from $[0,1]$ to an integral commutative residuated complete lattice $\mathcal{L}$ (in the intuitionistic case, $\mathcal{L}$ is a locale). We give an algebraic axiomatisation of AC-algebras in the language of continuous logic and prove, using the Macneille completion, that every Archimedean model embeds into some AC-algebra. We also show that (i) $USC(\mathcal{L})$ satisfies $v \dot + v = 2v$ exactly when $\mathcal{L}$ is a locale, (ii) involutiveness of negation in $USC(\mathcal{L})$ corresponds to that in $\mathcal{L} $, and that (iii) adding those conditions recovers classical continuous logic. For each variant -affine, intuitionistic, involutive, classical -we provide a sequent style deductive system and prove completeness and cut admissibility. This yields the first sequent style formulation of classical continuous logic enjoying cut admissibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26849v4</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Geoffroy (UCBL, ICJ, AGL)</dc:creator>
    </item>
    <item>
      <title>Abstract Framework for All-Path Reachability Analysis toward Safety and Liveness Verification (Full Version)</title>
      <link>https://arxiv.org/abs/2602.04641</link>
      <description>arXiv:2602.04641v2 Announce Type: replace 
Abstract: An all-path reachability (APR) predicate over an object set is a pair of a source set and a target set, which are subsets of the object set. APR predicates have been defined for abstract reduction systems (ARSs) and then extended to logically constrained term rewrite systems (LCTRSs) as pairs of constrained terms that represent sets of terms modeling configurations, states, etc. An APR predicate is said to be partially (or demonically) valid w.r.t. a rewrite system if every finite maximal reduction sequence of the system starting from any element in the source set includes an element in the target set. Partial validity of APR predicates w.r.t. ARSs is defined by means of two inference rules, which can be considered a proof system to construct (possibly infinite) derivation trees for partial validity. On the other hand, a proof system for LCTRSs consists of four inference rules, leaving a gap between the inference rules for ARSs and LCTRSs. In this paper, we revisit the framework for APR analysis and adapt it to verification of not only safety but also liveness properties. To this end, we first reformulate an abstract framework for partial validity w.r.t. ARSs so that there is a one-to-one correspondence between the inference rules for partial validity w.r.t. ARSs and LCTRSs. Secondly, we show how to apply APR analysis to safety verification. Thirdly, to apply APR analysis to liveness verification, we introduce a novel stronger validity of APR predicates, called total validity, which requires not only finite but also infinite execution paths to reach target sets. Finally, for a partially valid APR predicate with a cyclic-proof tree, we show a necessary and sufficient condition for the tree to ensure total validity. The condition implies that if there exists a cyclic-proof tree for an APR predicate, the proof graph of which is acyclic, then the APR predicate is totally valid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04641v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Misaki Kojima, Naoki Nishida</dc:creator>
    </item>
    <item>
      <title>Fine-tuned LLM-based Code Migration Framework</title>
      <link>https://arxiv.org/abs/2512.13515</link>
      <description>arXiv:2512.13515v3 Announce Type: replace-cross 
Abstract: The study presents the outcomes of research and experimental validation in the domain of automated codebase migration, with a focus on addressing challenges in transitioning SQL-based systems. The proposed method for migration essentially appears as a framework that leverages the best aspects of traditional software engineering techniques and provides an iterative, scalable, precise and efficient solution for modern database transformations. The central piece of the approach is the integration of a fine-tuned Large Language Model to address critical issues in SQL code conversion, such as syntax mapping, resolving discrepancies between Oracle PL/SQL and PostgreSQL, and optimising database elements such as stored procedures, triggers, views, and overall database logic. Thus, the method involves a trade-off between fine-tuning and prompt engineering. Special attention is given to a fine-tuning approach, which enhances the adaptability and compatibility with migration requirements across the entire database. According to the achieved results, fine-tuning plays a very important role. The study employs targeted evaluation methodologies along with computational metrics to measure the success of iterative conversion cycles. Core innovations include automated SQL feature detection, semi-supervised error analysis and integration of Subject Matter Experts feedback within a systematic migration workflow. The methodology achieves significant reductions in Syntax Error Rates, enhances feature alignment throughout migration iterations, and leverages dataset sampling to ensure continual improvement. By embedding GAI into the migration process, the framework facilitates precise feature mapping, semi-automated error resolution, and data-driven optimisation loops, improving workflow efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13515v3</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oleg Grynets, Vasyl Lyashkevych, Dmytro Baran, Maksym Orliansky, Taras Zelenyy, Markiian Leshchyshyn</dc:creator>
    </item>
  </channel>
</rss>
