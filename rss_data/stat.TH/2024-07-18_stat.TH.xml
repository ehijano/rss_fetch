<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jul 2024 04:01:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Estimating invertible processes in Hilbert spaces, with applications to functional ARMA processes</title>
      <link>https://arxiv.org/abs/2407.12221</link>
      <description>arXiv:2407.12221v1 Announce Type: new 
Abstract: Invertible processes naturally arise in many aspects of functional time series analysis, and consistent estimation of the infinite dimensional operators that define them are of interest. Asymptotic upper bounds for the estimation error of such operators for processes in the Hilbert space $L^2[0, 1]$ have been considered in recent years. This article adds to the theory in this area in several ways. We derive consistent estimates for the operators defining an invertible representation of a stationary process in a general separable Hilbert space under mild conditions that hold for many classes of functional time series. Moreover, based on these results, we derive consistency results with explicit rates for related operator estimates for Hilbert space-valued causal linear processes, as well as functional MA, AR and ARMA processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12221v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sebastian K\"uhnert, Gregory Rice, Alexander Aue</dc:creator>
    </item>
    <item>
      <title>Confidence Sets for $Z$-estimation Problems using Self-normalization</title>
      <link>https://arxiv.org/abs/2407.12278</link>
      <description>arXiv:2407.12278v1 Announce Type: new 
Abstract: Many commonly used statistical estimators are derived from optimization problems. This includes maximum likelihood estimation, empirical risk minimization, and so on. In many cases, the resulting estimators can be written as solutions to estimating equations, sometimes referred to as $Z$-estimators. Asymptotic normality for $Z$-estimators is a well-known result albeit when the dimension of the parameter is asymptotically smaller than the square root of the sample size. This hinders statistical inference when the dimension is "large." In this paper, we propose a self-normalization-based confidence set bypassing the asymptotic normality results. The proposed method is valid in the full range of dimensions growing smaller than the sample size (ignoring logarithmic factors) and asymptotically matches the asymptotic normality based confidence sets when asymptotic normality holds. Our proposal represents the first such general construction of confidence sets in the full range of consistency of $Z$-estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12278v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Woonyoung Chang, Arun Kumar Kuchibhotla</dc:creator>
    </item>
    <item>
      <title>A Point on Discrete versus Continuous State-Space Markov Chains</title>
      <link>https://arxiv.org/abs/2407.12308</link>
      <description>arXiv:2407.12308v1 Announce Type: new 
Abstract: This paper examines the impact of discrete marginal distributions on copula-based Markov chains. We present results on mixing and parameter estimation for a copula-based Markov chain model with Bernoulli($p$) marginal distribution and highlight the differences between continuous and discrete state-space Markov chains. We derive estimators for model parameters using the maximum likelihood approach and discuss other estimators of $p$ that are asymptotically equivalent to its maximum likelihood estimator. The asymptotic distributions of the parameter estimators are provided. A simulation study showcases the performance of the different estimators of $p$. Additionally, statistical tests for model parameters are included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12308v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathias N. Muia, Martial Longla</dc:creator>
    </item>
    <item>
      <title>Gaussian Approximation for Lag-Window Estimators and the Construction of Confidence bands for the Spectral Density</title>
      <link>https://arxiv.org/abs/2407.12316</link>
      <description>arXiv:2407.12316v1 Announce Type: new 
Abstract: In this paper we consider the construction of simultaneous confidence bands for the spectral density of a stationary time series using a Gaussian approximation for classical lag-window spectral density estimators evaluated at the set of all positive Fourier frequencies. The Gaussian approximation opens up the possibility to verify asymptotic validity of a multiplier bootstrap procedure and, even further, to derive the corresponding rate of convergence. A small simulation study sheds light on the finite sample properties of this bootstrap proposal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12316v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jens-Peter Kreiss, Anne Leucht, Efstathios Paparoditis</dc:creator>
    </item>
    <item>
      <title>On filter-type estimation of discretely sampled cyclic long-memory processes</title>
      <link>https://arxiv.org/abs/2407.12444</link>
      <description>arXiv:2407.12444v1 Announce Type: new 
Abstract: The generalized filtered method of moments was developed in the recent papers by Alomari et al., 2020, and Ayache et al., 2022. It used functional data obtained from continuously sampled cyclic long-memory stochastic processes to simultaneously estimate their parameters. However, the majority of applications deal with discretely sampled processes or time series. This paper extends the approach to accommodate discrete-time scenarios. It proves that the new discrete estimates exhibit analogous properties to the continuous case and are strongly consistent with the same rates of convergence. The numerical study results are presented to illustrate the theoretical findings and to indicate the sampling rates and resolution levels required for accurate estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12444v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Ayache, Serhii Kravchenko, Andriy Olenko</dc:creator>
    </item>
    <item>
      <title>Multigrid Monte Carlo Revisited: Theory and Bayesian Inference</title>
      <link>https://arxiv.org/abs/2407.12149</link>
      <description>arXiv:2407.12149v1 Announce Type: cross 
Abstract: Gaussian random fields play an important role in many areas of science and engineering. In practice, they are often simulated by sampling from a high-dimensional multivariate normal distribution which arises from the discretisation of a suitable precision operator on a finite grid. Existing methods such as Cholesky factorisation and Gibbs-sampling become prohibitively expensive on fine meshes due to their high computational cost or the fact that they do not explore the probability space efficiently. In this work we revisit the Multigrid Monte Carlo algorithm of Goodman &amp; Sokal (Physical Review D 40.6, 1989), which can overcome these issues. The novelty of our work consists in the application of the method to linear Bayesian settings where the prior is constrained by a finite set of observations. For this, we develop a bespoke random smoother which takes care of the low-rank updates that arise in Bayesian inference. We provide a rigorous analysis of the method based on the link between linear solvers and samplers for multivariate normal distributions, drawing on standard multigrid convergence theory in a finite element setting. In particular, we prove that Multigrid Monte Carlo is algorithmically near-optimal in the limit of the grid-size going to zero. These theoretical results are confirmed by numerical experiments which demonstrate that Multigrid Monte Carlo can be significantly more efficient than alternative methods when applied in a Bayesian setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12149v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoshihito Kazashi, Eike H. M\"uller, Robert Scheichl</dc:creator>
    </item>
    <item>
      <title>Information Compression in Dynamic Games</title>
      <link>https://arxiv.org/abs/2407.12318</link>
      <description>arXiv:2407.12318v1 Announce Type: cross 
Abstract: One of the reasons why stochastic dynamic games with an underlying dynamic system are challenging is since strategic players have access to enormous amount of information which leads to the use of extremely complex strategies at equilibrium. One approach to resolve this challenge is to simplify players' strategies by identifying appropriate compression of information maps so that the players can make decisions solely based on the compressed version of information, called the information state. For finite dynamic games with asymmetric information, inspired by the notion of information state for single-agent control problems, we propose two notions of information states, namely mutually sufficient information (MSI) and unilaterally sufficient information (USI). Both these information states are obtained with information compression maps independent of the strategy profile. We show that Bayes-Nash Equilibria (BNE) and Sequential Equilibria (SE) exist when all players use MSI-based strategies. We prove that when all players employ USI-based strategies the resulting sets of BNE and SE payoff profiles are the same as the sets of BNE and SE payoff profiles resulting when all players use full information-based strategies. We prove that when all players use USI-based strategies the resulting set of weak Perfect Bayesian Equilibrium (wPBE) payoff profiles can be a proper subset of all wPBE payoff profiles. We identify MSI and USI in specific models of dynamic games in the literature. We end by presenting an open problem: Do there exist strategy-dependent information compression maps that guarantee the existence of at least one equilibrium or maintain all equilibria that exist under perfect recall? We show, by a counterexample, that a well-known strategy-dependent information compression map used in the literature does not possess any of the properties of MSI or USI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12318v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dengwang Tang, Vijay Subramanian, Demosthenis Teneketzis</dc:creator>
    </item>
    <item>
      <title>Representation of Context-Specific Causal Models with Observational and Interventional Data</title>
      <link>https://arxiv.org/abs/2101.09271</link>
      <description>arXiv:2101.09271v4 Announce Type: replace 
Abstract: We address the problem of representing context-specific causal models based on both observational and experimental data collected under general (e.g. hard or soft) interventions by introducing a new family of context-specific conditional independence models called CStrees. This family is defined via a novel factorization criterion that allows for a generalization of the factorization property defining general interventional DAG models. We derive a graphical characterization of model equivalence for observational CStrees that extends the Verma and Pearl criterion for DAGs. This characterization is then extended to CStree models under general, context-specific interventions. To obtain these results, we formalize a notion of context-specific intervention that can be incorporated into concise graphical representations of CStree models. We relate CStrees to other context-specific models, showing that the families of DAGs, CStrees, labeled DAGs and staged trees form a strict chain of inclusions. We end with an application of interventional CStree models to a real data set, revealing the context-specific nature of the data dependence structure and the soft, interventional perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.09271v4</guid>
      <category>math.ST</category>
      <category>math.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eliana Duarte, Liam Solus</dc:creator>
    </item>
    <item>
      <title>Estimating a density near an unknown manifold: a Bayesian nonparametric approach</title>
      <link>https://arxiv.org/abs/2205.15717</link>
      <description>arXiv:2205.15717v3 Announce Type: replace 
Abstract: We study the Bayesian density estimation of data living in the offset of an unknown submanifold of the Euclidean space. In this perspective, we introduce a new notion of anisotropic H\"older for the underlying density and obtain posterior rates that are minimax optimal and adaptive to the regularity of the density, to the intrinsic dimension of the manifold, and to the size of the offset, provided that the latter is not too small -- while still allowed to go to zero. Our Bayesian procedure, based on location-scale mixtures of Gaussians, appears to be convenient to implement and yields good practical results, even for quite singular data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.15717v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Berenfeld, Paul Rosa, Judith Rousseau</dc:creator>
    </item>
    <item>
      <title>Universal Lower Bounds and Optimal Rates: Achieving Minimax Clustering Error in Sub-Exponential Mixture Models</title>
      <link>https://arxiv.org/abs/2402.15432</link>
      <description>arXiv:2402.15432v2 Announce Type: replace 
Abstract: Clustering is a pivotal challenge in unsupervised machine learning and is often investigated through the lens of mixture models. The optimal error rate for recovering cluster labels in Gaussian and sub-Gaussian mixture models involves ad hoc signal-to-noise ratios. Simple iterative algorithms, such as Lloyd's algorithm, attain this optimal error rate. In this paper, we first establish a universal lower bound for the error rate in clustering any mixture model, expressed through a Chernoff divergence, a more versatile measure of model information than signal-to-noise ratios. We then demonstrate that iterative algorithms attain this lower bound in mixture models with sub-exponential tails, notably emphasizing location-scale mixtures featuring Laplace-distributed errors. Additionally, for datasets better modelled by Poisson or Negative Binomial mixtures, we study mixture models whose distributions belong to an exponential family. In such mixtures, we establish that Bregman hard clustering, a variant of Lloyd's algorithm employing a Bregman divergence, is rate optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15432v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilien Dreveton, Alperen G\"ozeten, Matthias Grossglauser, Patrick Thiran</dc:creator>
    </item>
    <item>
      <title>Determine the Number of States in Hidden Markov Models via Marginal Likelihood</title>
      <link>https://arxiv.org/abs/2405.12343</link>
      <description>arXiv:2405.12343v2 Announce Type: replace 
Abstract: Hidden Markov models (HMM) have been widely used by scientists to model stochastic systems: the underlying process is a discrete Markov chain and the observations are noisy realizations of the underlying process. Determining the number of hidden states for an HMM is a model selection problem, which is yet to be satisfactorily solved, especially for the popular Gaussian HMM with heterogeneous covariance. In this paper, we propose a consistent method for determining the number of hidden states of HMM based on the marginal likelihood, which is obtained by integrating out both the parameters and hidden states. Moreover, we show that the model selection problem of HMM includes the order selection problem of finite mixture models as a special case. We give rigorous proof of the consistency of the proposed marginal likelihood method and provide an efficient computation method for practical implementation. We numerically compare the proposed method with the Bayesian information criterion (BIC), demonstrating the effectiveness of the proposed marginal likelihood method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12343v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yang Chen, Cheng-Der Fuh, Chu-Lan Michael Kao</dc:creator>
    </item>
    <item>
      <title>Parallel MCMC Algorithms: Theoretical Foundations, Algorithm Design, Case Studies</title>
      <link>https://arxiv.org/abs/2209.04750</link>
      <description>arXiv:2209.04750v2 Announce Type: replace-cross 
Abstract: Parallel Markov Chain Monte Carlo (pMCMC) algorithms generate clouds of proposals at each step to efficiently resolve a target probability distribution. We build a rigorous foundational framework for pMCMC algorithms that situates these methods within a unified 'extended phase space' measure-theoretic formalism. Drawing on our recent work that provides a comprehensive theory for reversible single proposal methods, we herein derive general criteria for multiproposal acceptance mechanisms which yield ergodic chains on general state spaces. Our formulation encompasses a variety of methodologies, including proposal cloud resampling and Hamiltonian methods, while providing a basis for the derivation of novel algorithms. In particular, we obtain a top-down picture for a class of methods arising from 'conditionally independent' proposal structures. As an immediate application, we identify several new algorithms including a multiproposal version of the popular preconditioned Crank-Nicolson (pCN) sampler suitable for high- and infinite-dimensional target measures which are absolutely continuous with respect to a Gaussian base measure. To supplement our theoretical results, we carry out a selection of numerical case studies that evaluate the efficacy of these novel algorithms. First, noting that the true potential of pMCMC algorithms arises from their natural parallelizability, we provide a limited parallelization study using TensorFlow and a graphics processing unit to scale pMCMC algorithms that leverage as many as 100k proposals at each step. Second, we use our multiproposal pCN algorithm (mpCN) to resolve a selection of problems in Bayesian statistical inversion for partial differential equations motivated by fluid measurement. These examples provide preliminary evidence of the efficacy of mpCN for high-dimensional target distributions featuring complex geometries and multimodal structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.04750v2</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan E. Glatt-Holtz, Andrew J. Holbrook, Justin A. Krometis, Cecilia F. Mondaini</dc:creator>
    </item>
    <item>
      <title>Causal inference under transportability assumptions for conditional relative effect measures</title>
      <link>https://arxiv.org/abs/2402.02702</link>
      <description>arXiv:2402.02702v2 Announce Type: replace-cross 
Abstract: When extending inferences from a randomized trial to a new target population, the transportability condition for conditional difference effect measures is invoked to identify the marginal causal mean difference in the target population. However, many clinical investigators believe that conditional relative effect measures are more likely to be "transportable" between populations. Here, we examine the identification and estimation of the marginal counterfactual mean difference and ratio under the transportability condition for conditional relative effect measures. We obtain identification results for two scenarios that often arise in practice when individuals in the target population (1) only have access to the control treatment, and (2) have access to the control and other treatments but not necessarily the experimental treatment evaluated in the trial. We then propose model and rate multiply robust and nonparametric efficient estimators that allow for the use of data-adaptive methods to model the nuisance functions. We examine the performance of the methods in simulation studies and illustrate their use with data from two trials of paliperidone for patients with schizophrenia. We conclude that the proposed methods are attractive when background knowledge suggests that the transportability condition for conditional relative effect measures is more plausible than alternative conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02702v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Guanbo Wang, Alexander Levis, Jon Steingrimsson, Issa Dahabreh</dc:creator>
    </item>
  </channel>
</rss>
