<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Variable selection via thresholding</title>
      <link>https://arxiv.org/abs/2503.21137</link>
      <description>arXiv:2503.21137v1 Announce Type: new 
Abstract: Variable selection comprises an important step in many modern statistical inference procedures. In the regression setting, when estimators cannot shrink irrelevant signals to zero, covariates without relationships to the response often manifest small but non-zero regression coefficients. The ad hoc procedure of discarding variables whose coefficients are smaller than some threshold is often employed in practice. We formally analyze a version of such thresholding procedures and develop a simple thresholding method that consistently estimates the set of relevant variables under mild regularity assumptions. Using this thresholding procedure, we propose a sparse, $\sqrt{n}$-consistent and asymptotically normal estimator whose non-zero elements do not exhibit shrinkage. The performance and applicability of our approach are examined via numerical studies of simulated and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21137v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ka Long Keith Ho, Hien Duy Nguyen</dc:creator>
    </item>
    <item>
      <title>Use of stochastic orders and statistical dependence in error analysis for multi-component system</title>
      <link>https://arxiv.org/abs/2503.21275</link>
      <description>arXiv:2503.21275v1 Announce Type: new 
Abstract: In this paper, we analyze the relative errors that crop up in the various reliability measures due to the tacit assumption that the components are independently working associated with a $n$-component series system or a parallel system where the components are dependent and follow a well-defined multivariate Weibull or exponential distribution. We also list some important observations which the previous authors have not noted in their earlier works. In this paper, we focus on the incurred error in multi-component series and parallel systems having multivariate Weibull distributions. In the upcoming sections, we establish that the present study has relevance with stochastic orders and statistical dependence which were not previously pointed out by previous authors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21275v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subarna Bhattacharjee, Aninda Kumar Nanda, Subhashree Patra</dc:creator>
    </item>
    <item>
      <title>Use of copula functions in error assessment due to deviation from dependence assumption</title>
      <link>https://arxiv.org/abs/2503.21286</link>
      <description>arXiv:2503.21286v1 Announce Type: new 
Abstract: In this paper, we analyze the relative errors in various reliability measures due to the tacit assumption that the components associated with a $n$-component series system or a parallel system are independently working where the components are dependent. We use Copula functions in said error analysis. This technique generalizes the existing work on error assessment for many wide class of distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21286v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subarna Bhattacharjee, Aninda Kumar Nanda, Subhashree Patra</dc:creator>
    </item>
    <item>
      <title>Safety of particle filters: Some first results on the time evolution of particle filter estimates</title>
      <link>https://arxiv.org/abs/2503.21334</link>
      <description>arXiv:2503.21334v1 Announce Type: new 
Abstract: Particle filters (PFs) is a class of Monte Carlo algorithms that propagate over time a set of $N\in\mathbb{N}$ particles which can be used to estimate, in an online fashion, the sequence of filtering distributions $(\hat{\eta}_t)_{t\geq 1}$ defined by a state-space model. Despite the popularity of PFs, the time evolution of their estimates does not appear to have been previously studied in the literature. Denoting by $(\hat{\eta}_t^N)_{t\geq 1}$ the PF estimate of $(\hat{\eta}_t)_{t\geq 1}$ and letting $\kappa\in (0,1)$, we first show that for any number of particles $N$ it holds that, with probability one, we have $\|\hat{\eta}_t^N- \hat{\eta}_t\|\geq \kappa$ for infinitely many $t\geq 1$, with $\|\cdot\|$ a measure of distance between probability distributions. Considering a simple filtering problem we then provide reassuring results concerning the ability of PFs to estimate jointly a finite set $\{\hat{\eta}_t\}_{t=1}^T$ of filtering distributions by studying $\P(\sup_{t\in\{1,\dots,T\}}\|\hat{\eta}_t^{N}-\hat{\eta}_t\|\geq \kappa)$. Finally, on the same toy filtering problem, we prove that sequential quasi-Monte Carlo, a randomized quasi-Monte Carlo version of PF algorithms, offers greater safety guarantees than PFs in the sense that, for this algorithm, it holds that $\lim_{N\rightarrow\infty}\sup_{t\geq 1}\|\hat{\eta}_t^N-\hat{\eta}_t\|=0$ with probability one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21334v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathieu Gerber</dc:creator>
    </item>
    <item>
      <title>Locally minimax optimal and dimension-agnostic discrete argmin inference</title>
      <link>https://arxiv.org/abs/2503.21639</link>
      <description>arXiv:2503.21639v1 Announce Type: new 
Abstract: We revisit the discrete argmin inference problem in high-dimensional settings. Given $n$ observations from a $d$ dimensional vector, the goal is to test whether the $r$th component of the mean vector is the smallest among all components. We propose dimension-agnostic tests that maintain validity regardless of how $d$ scales with $n$, and regardless of arbitrary ties in the mean vector. Notably, our validity holds under mild moment conditions, requiring little more than finiteness of a second moment, and permitting possibly strong dependence between coordinates. In addition, we establish the local minimax separation rate for this problem, which adapts to the cardinality of a confusion set, and show that the proposed tests attain this rate. Our method uses the sample splitting and self-normalization approach of Kim and Ramdas (2024). Our tests can be easily inverted to yield confidence sets for the argmin index. Empirical results illustrate the strong performance of our approach in terms of type I error control and power compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21639v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilmun Kim, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Wasserstein bounds for non-linear Gaussian filters</title>
      <link>https://arxiv.org/abs/2503.21643</link>
      <description>arXiv:2503.21643v1 Announce Type: new 
Abstract: Most Kalman filters for non-linear systems, such as the unscented Kalman filter, are based on Gaussian approximations. We use Poincar\'e inequalities to bound the Wasserstein distance between the true joint distribution of the prediction and measurement and its Gaussian approximation. The bounds can be used to assess the performance of non-linear Gaussian filters and determine those filtering approximations that are most likely to induce error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21643v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toni Karvonen, Simo S\"arkk\"a</dc:creator>
    </item>
    <item>
      <title>Teachable normal approximations to binomial and related probabilities or confidence bounds</title>
      <link>https://arxiv.org/abs/2503.20852</link>
      <description>arXiv:2503.20852v1 Announce Type: cross 
Abstract: This document is an extended version of an abstract for a talk, with approximately the same title, to be held at the 7th Joint Statistical Meeting of the Deutsche Arbeitsgemeinschaft Statistik, from 24 to 28 March 2025 in Berlin.
  Here ``teachable'' is meant to apply to people ranging from sufficiently advanced high school pupils to university students in mathematics or statistics: For understanding most of the proposed approximation results, it should suffice to know binomial laws, their means and variances, and the standard normal distribution function (but not necessarily the concept of a corresponding normal random variable).
  Of the proposed approximations, some are well-known (at least to experts), and some are based on teaching experience and research at Trier University.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20852v1</guid>
      <category>stat.OT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lutz Mattner</dc:creator>
    </item>
    <item>
      <title>A computational theory of evaluation for parameterisable subject</title>
      <link>https://arxiv.org/abs/2503.21138</link>
      <description>arXiv:2503.21138v1 Announce Type: cross 
Abstract: Evaluation is critical to advance decision making across domains, yet existing methodologies often struggle to balance theoretical rigor and practical scalability. In order to reduce the cost of experimental evaluation, we introduce a computational theory of evaluation for parameterisable subjects. We prove upper bounds of generalized evaluation error and generalized causal effect error of evaluation metric on subject. We also prove efficiency, and consistency to estimated causal effect of subject on metric by prediction. To optimize evaluation models, we propose a meta-learner to handle heterogeneous evaluation subjects space. Comparing with other computational approaches, our (conditional) evaluation model reduced 24.1%-99.0% evaluation errors across 12 scenes, including individual medicine, scientific simulation, business activities, and quantum trade. The evaluation time is reduced 3-7 order of magnitude comparing with experiments or simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21138v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hedong Yan</dc:creator>
    </item>
    <item>
      <title>G{\'e}n{\'e}ration de Matrices de Corr{\'e}lation avec des Structures de Graphe par Optimisation Convexe</title>
      <link>https://arxiv.org/abs/2503.21298</link>
      <description>arXiv:2503.21298v1 Announce Type: cross 
Abstract: This work deals with the generation of theoretical correlation matrices with specific sparsity patterns, associated to graph structures. We present a novel approach based on convex optimization, offering greater flexibility compared to existing techniques, notably by controlling the mean of the entry distribution in the generated correlation matrices. This allows for the generation of correlation matrices that better represent realistic data and can be used to benchmark statistical methods for graph inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21298v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Fahkar (STATIFY, LJK), K\'evin Polisano (SVH, LJK), Ir\`ene Gannaz (G-SCOP\_GROG, G-SCOP), Sophie Achard (STATIFY, LJK)</dc:creator>
    </item>
    <item>
      <title>Robust Mean Estimation for Optimization: The Impact of Heavy Tails</title>
      <link>https://arxiv.org/abs/2503.21421</link>
      <description>arXiv:2503.21421v1 Announce Type: cross 
Abstract: We consider the problem of constructing a least conservative estimator of the expected value $\mu$ of a non-negative heavy-tailed random variable. We require that the probability of overestimating the expected value $\mu$ is kept appropriately small; a natural requirement if its subsequent use in a decision process is anticipated. In this setting, we show it is optimal to estimate $\mu$ by solving a distributionally robust optimization (DRO) problem using the Kullback-Leibler (KL) divergence. We further show that the statistical properties of KL-DRO compare favorably with other estimators based on truncation, variance regularization, or Wasserstein DRO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21421v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bart P. G. van Parys, Bert Zwart</dc:creator>
    </item>
    <item>
      <title>Sparse Bayesian Learning for Label Efficiency in Cardiac Real-Time MRI</title>
      <link>https://arxiv.org/abs/2503.21443</link>
      <description>arXiv:2503.21443v1 Announce Type: cross 
Abstract: Cardiac real-time magnetic resonance imaging (MRI) is an emerging technology that images the heart at up to 50 frames per second, offering insight into the respiratory effects on the heartbeat. However, this method significantly increases the number of images that must be segmented to derive critical health indicators. Although neural networks perform well on inner slices, predictions on outer slices are often unreliable.
  This work proposes sparse Bayesian learning (SBL) to predict the ventricular volume on outer slices with minimal manual labeling to address this challenge. The ventricular volume over time is assumed to be dominated by sparse frequencies corresponding to the heart and respiratory rates. Moreover, SBL identifies these sparse frequencies on well-segmented inner slices by optimizing hyperparameters via type -II likelihood, automatically pruning irrelevant components. The identified sparse frequencies guide the selection of outer slice images for labeling, minimizing posterior variance.
  This work provides performance guarantees for the greedy algorithm. Testing on patient data demonstrates that only a few labeled images are necessary for accurate volume prediction. The labeling procedure effectively avoids selecting inefficient images. Furthermore, the Bayesian approach provides uncertainty estimates, highlighting unreliable predictions (e.g., when choosing suboptimal labels).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21443v1</guid>
      <category>stat.ME</category>
      <category>cs.CV</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Terhag, Philipp Knechtges, Achim Basermann, Anja Bach, Darius Gerlach, Jens Tank, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>Constraint-based causal discovery with tiered background knowledge and latent variables in single or overlapping datasets</title>
      <link>https://arxiv.org/abs/2503.21526</link>
      <description>arXiv:2503.21526v1 Announce Type: cross 
Abstract: In this paper we consider the use of tiered background knowledge within constraint based causal discovery. Our focus is on settings relaxing causal sufficiency, i.e. allowing for latent variables which may arise because relevant information could not be measured at all, or not jointly, as in the case of multiple overlapping datasets. We first present novel insights into the properties of the 'tiered FCI' (tFCI) algorithm. Building on this, we introduce a new extension of the IOD (integrating overlapping datasets) algorithm incorporating tiered background knowledge, the 'tiered IOD' (tIOD) algorithm. We show that under full usage of the tiered background knowledge tFCI and tIOD are sound, while simple versions of the tIOD and tFCI are sound and complete. We further show that the tIOD algorithm can often be expected to be considerably more efficient and informative than the IOD algorithm even beyond the obvious restriction of the Markov equivalence classes. We provide a formal result on the conditions for this gain in efficiency and informativeness. Our results are accompanied by a series of examples illustrating the exact role and usefulness of tiered background knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21526v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christine W. Bang, Vanessa Didelez</dc:creator>
    </item>
    <item>
      <title>Empirical Measures and Strong Laws of Large Numbers in Categorical Probability</title>
      <link>https://arxiv.org/abs/2503.21576</link>
      <description>arXiv:2503.21576v1 Announce Type: cross 
Abstract: The Glivenko-Cantelli theorem is a uniform version of the strong law of large numbers. It states that for every IID sequence of random variables, the empirical measure converges to the underlying distribution (in the sense of uniform convergence of the CDF). In this work, we provide tools to study such limits of empirical measures in categorical probability.
  We propose two axioms, permutation invariance and empirical adequacy, that a morphism of type $X^\mathbb{N} \to X$ should satisfy to be interpretable as taking an infinite sequence as input and producing a sample from its empirical measure as output. Since not all sequences have a well-defined empirical measure, ``such empirical sampling morphisms'' live in quasi-Markov categories, which, unlike Markov categories, allow partial morphisms. Given an empirical sampling morphism and a few other properties, we prove representability as well as abstract versions of the de Finetti theorem, the Glivenko-Cantelli theorem and the strong law of large numbers.
  We provide several concrete constructions of empirical sampling morphisms as partially defined Markov kernels on standard Borel spaces. Instantiating our abstract results then recovers the standard Glivenko-Cantelli theorem and the strong law of large numbers for random variables with finite first moment. Our work thus provides a joint proof of these two theorems in conjunction with the de Finetti theorem from first principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21576v1</guid>
      <category>math.PR</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Fritz, Tom\'a\v{s} Gonda, Antonio Lorenzin, Paolo Perrone, Areeb Shah Mohammed</dc:creator>
    </item>
    <item>
      <title>Clustered Switchback Designs for Experimentation Under Spatio-temporal Interference</title>
      <link>https://arxiv.org/abs/2312.15574</link>
      <description>arXiv:2312.15574v5 Announce Type: replace 
Abstract: We consider experimentation in the presence of non-stationarity, inter-unit (spatial) interference, and carry-over effects (temporal interference), where we wish to estimate the global average treatment effect (GATE), the difference between average outcomes having exposed all units at all times to treatment or to control. We suppose spatial interference is described by a graph, where a unit's outcome depends on its neighborhood's treatments, and that temporal interference is described by an MDP, where the transition kernel under either treatment (action) satisfies a rapid mixing condition. We propose a clustered switchback design, where units are grouped into clusters and time steps are grouped into blocks, and each whole cluster-block combination is assigned a single random treatment. Under this design, we show that for graphs that admit good clustering, a truncated Horvitz-Thompson estimator achieves a $\tilde O(1/NT)$ mean squared error (MSE), matching the lower bound up to logarithmic terms for sparse graphs. Our results simultaneously generalize the results from \citet{hu2022switchback,ugander2013graph} and \citet{leung2022rate}. Simulation studies validate the favorable performance of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15574v5</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Su Jia, Nathan Kallus, Christina Lee Yu</dc:creator>
    </item>
    <item>
      <title>Contraction rates and projection subspace estimation with Gaussian process priors in high dimension</title>
      <link>https://arxiv.org/abs/2403.03540</link>
      <description>arXiv:2403.03540v2 Announce Type: replace 
Abstract: This work explores the dimension reduction problem for Bayesian nonparametric regression and density estimation. More precisely, we are interested in estimating a functional parameter $f$ over the unit ball in $\mathbb{R}^d$, which depends only on a $d_0$-dimensional subspace of $\mathbb{R}^d$, with $d_0 &lt; d$. It is well-known that rescaled Gaussian process priors over the function space achieve smoothness adaptation and posterior contraction with near minimax-optimal rates. Moreover, hierarchical extensions of this approach, equipped with subspace projection, can also adapt to the intrinsic dimension $d_0$ ([Tok11]). When the ambient dimension $d$ does not vary with $n$, the minimax rate remains of the order $n^{-\beta/(2\beta +d_0)}$, where $\beta$ denotes the smoothness of $f$. However, this is up to multiplicative constants that can become prohibitively large when $d$ grows. The dependences between the contraction rate and the ambient dimension have not been fully explored yet and this work provides a first insight: we let the dimension $d$ grow with $n$ and, by combining the arguments of [Tok11] and [CR24], we derive a growth rate for $d$ that still leads to posterior consistency with minimax rate. The optimality of this growth rate is then discussed. Additionally, we provide a set of assumptions under which consistent estimation of $f$ leads to a correct estimation of the subspace projection, assuming that $d_0$ is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03540v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elie Odin (IMT), Fran\c{c}ois Bachoc (IMT), Agn\`es Lagnoux (IMT)</dc:creator>
    </item>
    <item>
      <title>Conditional uncorrelation equals independence</title>
      <link>https://arxiv.org/abs/2406.01849</link>
      <description>arXiv:2406.01849v3 Announce Type: replace 
Abstract: We express the independence of real-valued random variables in terms of the conditional uncorrelation, where the conditioning takes place over the cartesian products of intervals. Next, we express the mutual independence in terms of the conditional correlation matrix. While the previous studies on the subject are based on the copula functions, our approach uses the Radon-Nikodym derivative to reduce the general problem to the simple one-dimensional conditioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01849v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dawid Tar{\l}owski</dc:creator>
    </item>
    <item>
      <title>Asymptotic independence in higher dimensions and its implications on risk management</title>
      <link>https://arxiv.org/abs/2406.19186</link>
      <description>arXiv:2406.19186v2 Announce Type: replace 
Abstract: In the study of extremes, the presence of asymptotic independence signifies that extreme events across multiple variables are probably less likely to occur together. Although well-understood in a bivariate context, the concept remains relatively unexplored when addressing the nuances of joint occurrence of extremes in higher dimensions. In this paper, we propose a notion of mutual asymptotic independence to capture the behavior of joint extremes in dimensions larger than two and contrast it with the classical notion of (pairwise) asymptotic independence. Additionally, we define k-wise asymptotic independence, which captures the tail dependence between pairwise and mutual asymptotic independence. The concepts are compared using examples of Archimedean, Gaussian, and Marshall-Olkin copulas among others. Notably,for the popular Gaussian copula, we provide explicit conditions on the correlation matrix for mutual asymptotic independence and k-wise asymptotic independence to hold; moreover, we are able to compute exact tail orders for various tail events. Beside that, we compare and discuss the implications of these new notions of asymptotic independence on assessing the risk of complex systems under distributional ambiguity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19186v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bikramjit Das, Vicky Fasen-Hartmann</dc:creator>
    </item>
    <item>
      <title>Optimal e-value testing for properly constrained hypotheses</title>
      <link>https://arxiv.org/abs/2412.21125</link>
      <description>arXiv:2412.21125v2 Announce Type: replace 
Abstract: Hypothesis testing via e-variables can be framed as a sequential betting game, where a player each round picks an e-variable. A good player's strategy results in an effective statistical test that rejects the null hypothesis as soon as sufficient evidence arises. Building on recent advances, we address the question of restricting the pool of e-variables to simplify strategy design without compromising effectiveness. We extend the results of Clerico(2024), by characterising optimal sets of e-variables for a broad class of non-parametric hypothesis tests, defined by finitely many regular constraints. As an application, we discuss optimality in algorithmic mean estimation, including the case of heavy-tailed random variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21125v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenio Clerico</dc:creator>
    </item>
    <item>
      <title>On statistical and causal models associated with acyclic directed mixed graphs</title>
      <link>https://arxiv.org/abs/2501.03048</link>
      <description>arXiv:2501.03048v2 Announce Type: replace 
Abstract: Causal models in statistics are often described using acyclic directed mixed graphs (ADMGs), which contain directed and bidirected edges and no directed cycles. This article surveys various interpretations of ADMGs, discusses their relations in different sub-classes of ADMGs, and argues that one of them -- the noise expansion (NE) model -- should be used as the default interpretation. Our endorsement of the NE model is based on two observations. First, in a subclass of ADMGs called unconfounded graphs (which retain most of the good properties of directed acyclic graphs and bidirected graphs), the NE model is equivalent to many other interpretations including the global Markov and nested Markov models. Second, the NE model for an arbitrary ADMG is exactly the union of that for all unconfounded expansions of that graph. This property is referred to as completeness, as it shows that the model does not commit to any specific latent variable explanation. In proving that the NE model is nested Markov, we also develop an ADMG-based theory for causality. Finally, we compare the NE model with the closely related but different interpretation of ADMGs as directed acyclic graphs (DAGs) with latent variables that is commonly used in the literature. We argue that the "latent DAG" interpretation is mathematically unnecessary, makes obscure ontological assumptions, and discourages practitioners from deliberating over important structural assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03048v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyuan Zhao</dc:creator>
    </item>
    <item>
      <title>Spectral properties of kernel matrices in the flat limit</title>
      <link>https://arxiv.org/abs/1910.14067</link>
      <description>arXiv:1910.14067v3 Announce Type: replace-cross 
Abstract: Kernel matrices are of central importance to many applied fields. In this manuscript, we focus on spectral properties of kernel matrices in the so-called ``flat limit'', which occurs when points are close together relative to the scale of the kernel. We establish asymptotic expressions for the determinants of the kernel matrices, which we then leverage to obtain asymptotic expressions for the main terms of the eigenvalues. Analyticity of the eigenprojectors yields expressions for limiting eigenvectors, which are strongly tied to discrete orthogonal polynomials. Both smooth and finitely smooth kernels are covered, with stronger results available in the finite smoothness case.</description>
      <guid isPermaLink="false">oai:arXiv.org:1910.14067v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/19M129677X</arxiv:DOI>
      <arxiv:journal_reference>Siam J. Matrix Anal. Appl., 42(1):17-57, 2021</arxiv:journal_reference>
      <dc:creator>Simon Barthelm\'e, Konstantin Usevich</dc:creator>
    </item>
    <item>
      <title>The Population Resemblance Statistic: A Chi-Square Measure of Fit for Banking</title>
      <link>https://arxiv.org/abs/2307.11878</link>
      <description>arXiv:2307.11878v3 Announce Type: replace-cross 
Abstract: The Population Stability Index (PSI) is a widely used measure in credit risk modeling and monitoring within the banking industry. Its purpose is to monitor for changes in the population underlying a model, such as a scorecard, to ensure that the current population closely resembles the one used during model development. If substantial differences between populations are detected, model reconstruction may be necessary. Despite its widespread use, the origins and properties of the PSI are not well documented. Previous literature has suggested using arbitrary constants as a rule-of-thumb to assess resemblance (or "stability"), regardless of sample size. However, this approach too often calls for model reconstruction in small sample sizes while not detecting the need often enough in large sample sizes.
  This paper introduces an alternative discrepancy measure, the Population Resemblance statistic (PRS), based on the Pearson chi-square statistic. Properties of the PRS follow from the non-central chi-square distribution. Specifically, the PRS allows for critical values that are configured according to sample size and the number of risk categories. Implementation relies on the specification of a set of parameters, enabling practitioners to calibrate the procedure with their risk tolerance and sensitivity to population shifts. The PRS is demonstrated to be universally competent in a simulation study and with real-world examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11878v3</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nelis Potgieter, Corli van Zyl, WD Schutte, Fred Lombard</dc:creator>
    </item>
  </channel>
</rss>
