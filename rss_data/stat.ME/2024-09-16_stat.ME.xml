<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Sep 2024 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Cubature-based uncertainty estimation for nonlinear regression models</title>
      <link>https://arxiv.org/abs/2409.08756</link>
      <description>arXiv:2409.08756v1 Announce Type: new 
Abstract: Calibrating model parameters to measured data by minimizing loss functions is an important step in obtaining realistic predictions from model-based approaches, e.g., for process optimization. This is applicable to both knowledge-driven and data-driven model setups. Due to measurement errors, the calibrated model parameters also carry uncertainty. In this contribution, we use cubature formulas based on sparse grids to calculate the variance of the regression results. The number of cubature points is close to the theoretical minimum required for a given level of exactness. We present exact benchmark results, which we also compare to other cubatures. This scheme is then applied to estimate the prediction uncertainty of the NRTL model, calibrated to observations from different experimental designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08756v1</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bubel, Jochen Schmid, Maximilian Carmesin, Volodymyr Kozachynskyi, Erik Esche, Michael Bortz</dc:creator>
    </item>
    <item>
      <title>The underreported death toll of wars: a probabilistic reassessment from a structured expert elicitation</title>
      <link>https://arxiv.org/abs/2409.08779</link>
      <description>arXiv:2409.08779v1 Announce Type: new 
Abstract: Event datasets including those provided by Uppsala Conflict Data Program (UCDP) are based on reports from the media and international organizations, and are likely to suffer from reporting bias. Since the UCDP has strict inclusion criteria, they most likely under-estimate conflict-related deaths, but we do not know by how much. Here, we provide a generalizable, cross-national measure of uncertainty around UCDP reported fatalities that is more robust and realistic than UCDP's documented low and high estimates, and make available a dataset and R package accounting for the measurement uncertainty. We use a structured expert elicitation combined with statistical modelling to derive a distribution of plausible number of fatalities given the number of battle-related deaths and the type of violence documented by the UCDP. The results can help scholars understand the extent of bias affecting their empirical analyses of organized violence and contribute to improve the accuracy of conflict forecasting systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08779v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paola Vesco, David Randahl, H{\aa}vard Hegre, Stina H\"ogbladh, Mert Can Yilmaz</dc:creator>
    </item>
    <item>
      <title>High-dimensional regression with a count response</title>
      <link>https://arxiv.org/abs/2409.08821</link>
      <description>arXiv:2409.08821v1 Announce Type: new 
Abstract: We consider high-dimensional regression with a count response modeled by Poisson or negative binomial generalized linear model (GLM). We propose a penalized maximum likelihood estimator with a properly chosen complexity penalty and establish its adaptive minimaxity across models of various sparsity. To make the procedure computationally feasible for high-dimensional data we consider its LASSO and SLOPE convex surrogates. Their performance is illustrated through simulated and real-data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08821v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Or Zilberman, Felix Abramovich</dc:creator>
    </item>
    <item>
      <title>Angular Co-variance using intrinsic geometry of torus: Non-parametric change points detection in meteorological data</title>
      <link>https://arxiv.org/abs/2409.08838</link>
      <description>arXiv:2409.08838v1 Announce Type: new 
Abstract: In many temporal datasets, the parameters of the underlying distribution may change abruptly at unknown times. Detecting these changepoints is crucial for numerous applications. While this problem has been extensively studied for linear data, there has been remarkably less research on bivariate angular data. For the first time, we address the changepoint problem for the mean direction of toroidal and spherical data, which are types of bivariate angular data. By leveraging the intrinsic geometry of a curved torus, we introduce the concept of the ``square'' of an angle. This leads us to define the ``curved dispersion matrix'' for bivariate angular random variables, analogous to the dispersion matrix for bivariate linear random variables. Using this analogous measure of the ``Mahalanobis distance,'' we develop two new non-parametric tests to identify changes in the mean direction parameters for toroidal and spherical distributions. We derive the limiting distributions of the test statistics and evaluate their power surface and contours through extensive simulations. We also apply the proposed methods to detect changes in mean direction for hourly wind-wave direction measurements and the path of the cyclonic storm ``Biporjoy,'' which occurred between 6th and 19th June 2023 over the Arabian Sea, western coast of India.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08838v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Surojit Biswas, Buddhananda Banerjee, Arnab Kumar Laha</dc:creator>
    </item>
    <item>
      <title>Change point analysis with irregular signals</title>
      <link>https://arxiv.org/abs/2409.08863</link>
      <description>arXiv:2409.08863v1 Announce Type: new 
Abstract: This paper considers the problem of testing and estimation of change point where signals after the change point can be highly irregular, which departs from the existing literature that assumes signals after the change point to be piece-wise constant or vary smoothly. A two-step approach is proposed to effectively estimate the location of the change point. The first step consists of a preliminary estimation of the change point that allows us to obtain unknown parameters for the second step. In the second step we use a new procedure to determine the position of the change point. We show that, under suitable conditions, the desirable $\mathcal{O}_P(1)$ rate of convergence of the estimated change point can be obtained. We apply our method to analyze the Baidu search index of COVID-19 related symptoms and find 8~December 2019 to be the starting date of the COVID-19 pandemic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08863v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Kley, Yuhan Philip Liu, Hongyuan Cao, Wei Biao Wu</dc:creator>
    </item>
    <item>
      <title>Joint spatial modeling of mean and non-homogeneous variance combining semiparametric SAR and GAMLSS models for hedonic prices</title>
      <link>https://arxiv.org/abs/2409.08912</link>
      <description>arXiv:2409.08912v1 Announce Type: new 
Abstract: In the context of spatial econometrics, it is very useful to have methodologies that allow modeling the spatial dependence of the observed variables and obtaining more precise predictions of both the mean and the variability of the response variable, something very useful in territorial planning and public policies. This paper proposes a new methodology that jointly models the mean and the variance. Also, it allows to model the spatial dependence of the dependent variable as a function of covariates and to model the semiparametric effects in both models. The algorithms developed are based on generalized additive models that allow the inclusion of non-parametric terms in both the mean and the variance, maintaining the traditional theoretical framework of spatial regression. The theoretical developments of the estimation of this model are carried out, obtaining desirable statistical properties in the estimators. A simulation study is developed to verify that the proposed method has a remarkable predictive capacity in terms of the mean square error and shows a notable improvement in the estimation of the spatial autoregressive parameter, compared to other traditional methods and some recent developments. The model is also tested on data from the construction of a hedonic price model for the city of Bogota, highlighting as the main result the ability to model the variability of housing prices, and the wealth in the analysis obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08912v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J. D. Toloza-Delgado, O. O. Melo, N. A. Cruz</dc:creator>
    </item>
    <item>
      <title>Regression-based proximal causal inference for right-censored time-to-event data</title>
      <link>https://arxiv.org/abs/2409.08924</link>
      <description>arXiv:2409.08924v1 Announce Type: new 
Abstract: Unmeasured confounding is one of the major concerns in causal inference from observational data. Proximal causal inference (PCI) is an emerging methodological framework to detect and potentially account for confounding bias by carefully leveraging a pair of negative control exposure (NCE) and outcome (NCO) variables, also known as treatment and outcome confounding proxies. Although regression-based PCI is well developed for binary and continuous outcomes, analogous PCI regression methods for right-censored time-to-event outcomes are currently lacking. In this paper, we propose a novel two-stage regression PCI approach for right-censored survival data under an additive hazard structural model. We provide theoretical justification for the proposed approach tailored to different types of NCOs, including continuous, count, and right-censored time-to-event variables. We illustrate the approach with an evaluation of the effectiveness of right heart catheterization among critically ill patients using data from the SUPPORT study. Our method is implemented in the open-access R package 'pci2s'.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08924v1</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kendrick Li, George C. Linderman, Xu Shi, Eric J. Tchetgen Tchetgen</dc:creator>
    </item>
    <item>
      <title>Dynamic Bayesian Networks with Conditional Dynamics in Edge Addition and Deletion</title>
      <link>https://arxiv.org/abs/2409.08965</link>
      <description>arXiv:2409.08965v1 Announce Type: new 
Abstract: This study presents a dynamic Bayesian network framework that facilitates intuitive gradual edge changes. We use two conditional dynamics to model the edge addition and deletion, and edge selection separately. Unlike previous research that uses a mixture network approach, which restricts the number of possible edge changes, or structural priors to induce gradual changes, which can lead to unclear network evolution, our model induces more frequent and intuitive edge change dynamics. We employ Markov chain Monte Carlo (MCMC) sampling to estimate the model structures and parameters and demonstrate the model's effectiveness in a portfolio selection application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08965v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lupe S. H. Chan, Amanda M. Y. Chu, Mike K. P. So</dc:creator>
    </item>
    <item>
      <title>An efficient heuristic for approximate maximum flow computations</title>
      <link>https://arxiv.org/abs/2409.08350</link>
      <description>arXiv:2409.08350v1 Announce Type: cross 
Abstract: Several concepts borrowed from graph theory are routinely used to better understand the inner workings of the (human) brain. To this end, a connectivity network of the brain is built first, which then allows one to assess quantities such as information flow and information routing via shortest path and maximum flow computations. Since brain networks typically contain several thousand nodes and edges, computational scaling is a key research area. In this contribution, we focus on approximate maximum flow computations in large brain networks. By combining graph partitioning with maximum flow computations, we propose a new approximation algorithm for the computation of the maximum flow with runtime O(|V||E|^2/k^2) compared to the usual runtime of O(|V||E|^2) for the Edmonds-Karp algorithm, where $V$ is the set of vertices, $E$ is the set of edges, and $k$ is the number of partitions. We assess both accuracy and runtime of the proposed algorithm on simulated graphs as well as on graphs downloaded from the Brain Networks Data Repository (https://networkrepository.com).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08350v1</guid>
      <category>cs.DS</category>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyun Qian, Georg Hahn</dc:creator>
    </item>
    <item>
      <title>The Clustered Dose-Response Function Estimator for continuous treatment with heterogeneous treatment effects</title>
      <link>https://arxiv.org/abs/2409.08773</link>
      <description>arXiv:2409.08773v1 Announce Type: cross 
Abstract: Many treatments are non-randomly assigned, continuous in nature, and exhibit heterogeneous effects even at identical treatment intensities. Taken together, these characteristics pose significant challenges for identifying causal effects, as no existing estimator can provide an unbiased estimate of the average causal dose-response function. To address this gap, we introduce the Clustered Dose-Response Function (Cl-DRF), a novel estimator designed to discern the continuous causal relationships between treatment intensity and the dependent variable across different subgroups. This approach leverages both theoretical and data-driven sources of heterogeneity and operates under relaxed versions of the conditional independence and positivity assumptions, which are required to be met only within each identified subgroup. To demonstrate the capabilities of the Cl-DRF estimator, we present both simulation evidence and an empirical application examining the impact of European Cohesion funds on economic growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08773v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cerqua Augusto, Di Stefano Roberta, Mattera Raffaele</dc:creator>
    </item>
    <item>
      <title>Tracing the impacts of Mount Pinatubo eruption on global climate using spatially-varying changepoint detection</title>
      <link>https://arxiv.org/abs/2409.08908</link>
      <description>arXiv:2409.08908v1 Announce Type: cross 
Abstract: Significant events such as volcanic eruptions can have global and long lasting impacts on climate. These global impacts, however, are not uniform across space and time. Understanding how the Mt. Pinatubo eruption affects global and regional climate is of great interest for predicting impact on climate due to similar events. We propose a Bayesian framework to simultaneously detect and estimate spatially-varying temporal changepoints for regional climate impacts. Our approach takes into account the diffusing nature of the changes caused by the volcanic eruption and leverages spatial correlation. We illustrate our method on simulated datasets and compare it with an existing changepoint detection method. Finally, we apply our method on monthly stratospheric aerosol optical depth and surface temperature data from 1985 to 1995 to detect and estimate changepoints following the 1991 Mt. Pinatubo eruption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08908v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samantha Shi-Jun, Lyndsay Shand, Bo Li</dc:creator>
    </item>
    <item>
      <title>Multi forests: Variable importance for multi-class outcomes</title>
      <link>https://arxiv.org/abs/2409.08925</link>
      <description>arXiv:2409.08925v1 Announce Type: cross 
Abstract: In prediction tasks with multi-class outcomes, identifying covariates specifically associated with one or more outcome classes can be important. Conventional variable importance measures (VIMs) from random forests (RFs), like permutation and Gini importance, focus on overall predictive performance or node purity, without differentiating between the classes. Therefore, they can be expected to fail to distinguish class-associated covariates from covariates that only distinguish between groups of classes. We introduce a VIM called multi-class VIM, tailored for identifying exclusively class-associated covariates, via a novel RF variant called multi forests (MuFs). The trees in MuFs use both multi-way and binary splitting. The multi-way splits generate child nodes for each class, using a split criterion that evaluates how well these nodes represent their respective classes. This setup forms the basis of the multi-class VIM, which measures the discriminatory ability of the splits performed in the respective covariates with regard to this split criterion. Alongside the multi-class VIM, we introduce a second VIM, the discriminatory VIM. This measure, based on the binary splits, assesses the strength of the general influence of the covariates, irrespective of their class-associatedness. Simulation studies demonstrate that the multi-class VIM specifically ranks class-associated covariates highly, unlike conventional VIMs which also rank other types of covariates highly. Analyses of 121 datasets reveal that MuFs often have slightly lower predictive performance compared to conventional RFs. This is, however, not a limiting factor given the algorithm's primary purpose of calculating the multi-class VIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08925v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Roman Hornung (Institute for Medical Information Processing, Biometry and Epidemiology, LMU Munich, Munich, Germany, Munich Center for Machine Learning), Alexander Hapfelmeier (Institute of AI and Informatics in Medicine, TUM School of Medicine and Health, Technical University of Munich, Munich, Germany)</dc:creator>
    </item>
    <item>
      <title>Self-Organized State-Space Models with Artificial Dynamics</title>
      <link>https://arxiv.org/abs/2409.08928</link>
      <description>arXiv:2409.08928v1 Announce Type: cross 
Abstract: In this paper we consider a state-space model (SSM) parametrized by some parameter $\theta$, and our aim is to perform joint parameter and state inference. A simple idea to perform this task, which almost dates back to the origin of the Kalman filter, is to replace the static parameter $\theta$ by a Markov chain $(\theta_t)_{t\geq 0}$ on the parameter space and then to apply a standard filtering algorithm to the extended, or self-organized SSM. However, the practical implementation of this idea in a theoretically justified way has remained an open problem. In this paper we fill this gap by introducing various possible constructions of the Markov chain $(\theta_t)_{t\geq 0}$ that ensure the validity of the self-organized SSM (SO-SSM) for joint parameter and state inference. Notably, we show that theoretically valid SO-SSMs can be defined even if $\|\mathrm{Var}(\theta_{t}|\theta_{t-1})\|$ converges to 0 slowly as $t\rightarrow\infty$. This result is important since, as illustrated in our numerical experiments, such models can be efficiently approximated using standard particle filter algorithms. While the idea studied in this work was first introduced for online inference in SSMs, it has also been proved to be useful for computing the maximum likelihood estimator (MLE) of a given SSM, since iterated filtering algorithms can be seen as particle filters applied to SO-SSMs for which the target parameter value is the MLE of interest. Based on this observation, we also derive constructions of $(\theta_t)_{t\geq 0}$ and theoretical results tailored to these specific applications of SO-SSMs, and as a result, we introduce new iterated filtering algorithms. From a practical point of view, the algorithms introduced in this work have the merit of being simple to implement and only requiring minimal tuning to perform well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08928v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Chen, Mathieu Gerber, Christophe Andrieu, Randal Douc</dc:creator>
    </item>
    <item>
      <title>Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I: the compact case</title>
      <link>https://arxiv.org/abs/2208.14960</link>
      <description>arXiv:2208.14960v4 Announce Type: replace 
Abstract: Gaussian processes are arguably the most important class of spatiotemporal models within machine learning. They encode prior information about the modeled function and can be used for exact or approximate Bayesian learning. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process' covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is split into two parts, each involving different technical considerations: part I studies compact spaces, while part II studies non-compact spaces possessing certain structure. Our contributions make the non-Euclidean Gaussian process models we study compatible with well-understood computational techniques available in standard Gaussian process software packages, thereby making them accessible to practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.14960v4</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research, 2024</arxiv:journal_reference>
      <dc:creator>Iskander Azangulov, Andrei Smolensky, Alexander Terenin, Viacheslav Borovitskiy</dc:creator>
    </item>
    <item>
      <title>On the Wasserstein median of probability measures</title>
      <link>https://arxiv.org/abs/2209.03318</link>
      <description>arXiv:2209.03318v3 Announce Type: replace 
Abstract: The primary choice to summarize a finite collection of random objects is by using measures of central tendency, such as mean and median. In the field of optimal transport, the Wasserstein barycenter corresponds to the Fr\'{e}chet or geometric mean of a set of probability measures, which is defined as a minimizer of the sum of squared distances to each element in a given set with respect to the Wasserstein distance of order 2. We introduce the Wasserstein median as a robust alternative to the Wasserstein barycenter. The Wasserstein median corresponds to the Fr\'{e}chet median under the 2-Wasserstein metric. The existence and consistency of the Wasserstein median are first established, along with its robustness property. In addition, we present a general computational pipeline that employs any recognized algorithms for the Wasserstein barycenter in an iterative fashion and demonstrate its convergence. The utility of the Wasserstein median as a robust measure of central tendency is demonstrated using real and simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03318v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1080/10618600.2024.2374580</arxiv:DOI>
      <dc:creator>Kisung You, Dennis Shung, Mauro Giuffr\`e</dc:creator>
    </item>
    <item>
      <title>Inference in generalized linear models with robustness to misspecified variances</title>
      <link>https://arxiv.org/abs/2209.13918</link>
      <description>arXiv:2209.13918v3 Announce Type: replace 
Abstract: Generalized linear models usually assume a common dispersion parameter, an assumption that is seldom true in practice. Consequently, standard parametric methods may suffer appreciable loss of type I error control. As an alternative, we present a semi-parametric group-invariance method based on sign flipping of score contributions. Our method requires only the correct specification of the mean model, but is robust against any misspecification of the variance. We present tests for single as well as multiple regression coefficients. The test is asymptotically valid but shows excellent performance in small samples. We illustrate the method using RNA sequencing count data, for which it is difficult to model the overdispersion correctly. The method is available in the R library flipscores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13918v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo De Santis, Jelle J. Goeman, Jesse Hemerik, Samuel Davenport, Livio Finos</dc:creator>
    </item>
    <item>
      <title>A Tutorial on Asymptotic Properties for Biostatisticians with Applications to COVID-19 Data</title>
      <link>https://arxiv.org/abs/2211.07351</link>
      <description>arXiv:2211.07351v2 Announce Type: replace 
Abstract: Asymptotic properties of statistical estimators play a significant role both in practice and in theory. However, many asymptotic results in statistics rely heavily on the independent and identically distributed (iid) assumption, which is not realistic when we have fixed designs. In this article, we build a roadmap of general procedures for deriving asymptotic properties under fixed designs and the observations need not to be iid. We further provide their applications in many statistical applications. Finally, we apply our results to Poisson regression using a COVID-19 dataset as an illustration to demonstrate the power of these results in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07351v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elvis Han Cui</dc:creator>
    </item>
    <item>
      <title>Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces II: non-compact symmetric spaces</title>
      <link>https://arxiv.org/abs/2301.13088</link>
      <description>arXiv:2301.13088v4 Announce Type: replace 
Abstract: Gaussian processes are arguably the most important class of spatiotemporal models within machine learning. They encode prior information about the modeled function and can be used for exact or approximate Bayesian learning. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process' covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is split into two parts, each involving different technical considerations: part I studies compact spaces, while part II studies non-compact spaces possessing certain structure. Our contributions make the non-Euclidean Gaussian process models we study compatible with well-understood computational techniques available in standard Gaussian process software packages, thereby making them accessible to practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13088v4</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research, 2024</arxiv:journal_reference>
      <dc:creator>Iskander Azangulov, Andrei Smolensky, Alexander Terenin, Viacheslav Borovitskiy</dc:creator>
    </item>
    <item>
      <title>Correlated Bayesian Additive Regression Trees with Gaussian Process for Regression Analysis of Dependent Data</title>
      <link>https://arxiv.org/abs/2311.18699</link>
      <description>arXiv:2311.18699v2 Announce Type: replace 
Abstract: Bayesian Additive Regression Trees (BART) has gained widespread popularity, prompting the development of various extensions for different applications. However, limited attention has been given to analyzing dependent data. Based on a general correlated error assumption and an innovative dummy representation, we introduces a novel extension of BART, called Correlated BART (CBART), designed to handle correlated errors. By integrating CBART with a Gaussian process (GP), we propose the CBART-GP model, in which the CBART and GP components are loosely coupled, allowing them to be estimated and applied independently. CBART captures the covariate mean function E[y|x]=f(x), while the Gaussian process models the dependency structure in the response $y$. We also developed a computationally efficient approach, named two-stage analysis of variance with weighted residuals, for the estimation of CBART-GP. Simulation studies demonstrate the superiority of CBART-GP over other models, and a real-world application illustrates its practical applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18699v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuetao Lu a, Robert E. McCulloch</dc:creator>
    </item>
    <item>
      <title>Adjacency Matrix Decomposition Clustering for Human Activity Data</title>
      <link>https://arxiv.org/abs/2401.01949</link>
      <description>arXiv:2401.01949v2 Announce Type: replace 
Abstract: Mobile apps and wearable devices accurately and continuously measure human activity; patterns within this data can provide a wealth of information applicable to fields such as transportation and health. Despite the potential utility of this data, there has been limited development of analysis methods for sequences of daily activities. In this paper, we propose a novel clustering method and cluster evaluation metric for human activity data that leverages an adjacency matrix representation to cluster the data without the calculation of a distance matrix. Our technique is substantially faster than conventional methods based on computing pairwise distances via sequence alignment algorithms and also enhances interpretability of results. We compare our method to distance-based hierarchical clustering and nTreeClus through simulation studies and an application to data collected by Daynamica, an app that turns sensor data into a daily summary of a user's activities. Among days that contain a large portion of time spent at home, our method distinguishes days that also contain multiple hours of travel or other activities, while both comparison methods fail to identify these patterns. We further identify which day patterns classified by our method are associated with higher concern for contracting COVID-19 with implications for public health messaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01949v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martha Barnard, Yingling Fan, Julian Wolfson</dc:creator>
    </item>
    <item>
      <title>Bridging multiple worlds: multi-marginal optimal transport for causal partial-identification problem</title>
      <link>https://arxiv.org/abs/2406.07868</link>
      <description>arXiv:2406.07868v2 Announce Type: replace 
Abstract: Under the prevalent potential outcome model in causal inference, each unit is associated with multiple potential outcomes but at most one of which is observed, leading to many causal quantities being only partially identified. The inherent missing data issue echoes the multi-marginal optimal transport (MOT) problem, where marginal distributions are known, but how the marginals couple to form the joint distribution is unavailable. In this paper, we cast the causal partial identification problem in the framework of MOT with $K$ margins and $d$-dimensional outcomes and obtain the exact partial identified set. In order to estimate the partial identified set via MOT, statistically, we establish a convergence rate of the plug-in MOT estimator for the $\ell_2$ cost function stemming from the variance minimization problem and prove it is minimax optimal for arbitrary $K$ and $d \le 4$. We also extend the convergence result to general quadratic objective functions. Numerically, we demonstrate the efficacy of our method over synthetic datasets and several real-world datasets where our proposal consistently outperforms the baseline by a significant margin (over 70%). In addition, we provide efficient off-the-shelf implementations of MOT with general objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07868v2</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijun Gao, Shu Ge, Jian Qian</dc:creator>
    </item>
    <item>
      <title>Functional Clustering for Longitudinal Associations between Social Determinants of Health and Stroke Mortality in the US</title>
      <link>https://arxiv.org/abs/2406.10499</link>
      <description>arXiv:2406.10499v4 Announce Type: replace 
Abstract: Understanding the longitudinally changing associations between Social Determinants of Health (SDOH) and stroke mortality is essential for effective stroke management. Previous studies have uncovered significant regional disparities in the relationships between SDOH and stroke mortality. However, existing studies have not utilized longitudinal associations to develop data-driven methods for regional division in stroke control. To fill this gap, we propose a novel clustering method to analyze SDOH -- stroke mortality associations in US counties. To enhance the interpretability of the clustering outcomes, we introduce a novel regularized expectation-maximization algorithm equipped with various sparsity-and-smoothness-pursued penalties, aiming at simultaneous clustering and variable selection in longitudinal associations. As a result, we can identify crucial SDOH that contribute to longitudinal changes in stroke mortality. This facilitates the clustering of US counties into different regions based on the relationships between these SDOH and stroke mortality. The effectiveness of our proposed method is demonstrated through extensive numerical studies. By applying our method to longitudinal data on SDOH and stroke mortality at the county level, we identify 18 important SDOH for stroke mortality and divide the US counties into two clusters based on these selected SDOH. Our findings unveil complex regional heterogeneity in the longitudinal associations between SDOH and stroke mortality, providing valuable insights into region-specific SDOH adjustments for mitigating stroke mortality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10499v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fangzhi Luo, Jianbin Tan, Donglan Zhang, Hui Huang, Ye Shen</dc:creator>
    </item>
    <item>
      <title>Deep Learning of Multivariate Extremes via a Geometric Representation</title>
      <link>https://arxiv.org/abs/2406.19936</link>
      <description>arXiv:2406.19936v2 Announce Type: replace 
Abstract: The study of geometric extremes, where extremal dependence properties are inferred from the deterministic limiting shapes of scaled sample clouds, provides an exciting approach to modelling the extremes of multivariate data. These shapes, termed limit sets, link together several popular extremal dependence modelling frameworks. Although the geometric approach is becoming an increasingly popular modelling tool, current inference techniques are limited to a low dimensional setting (d &lt; 5), and generally require rigid modelling assumptions. In this work, we propose a range of novel theoretical results to aid with the implementation of the geometric extremes framework and introduce the first approach to modelling limit sets using deep learning. By leveraging neural networks, we construct asymptotically-justified yet flexible semi-parametric models for extremal dependence of high-dimensional data. We showcase the efficacy of our deep approach by modelling the complex extremal dependencies between meteorological and oceanographic variables in the North Sea off the coast of the UK.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19936v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Callum J. R. Murphy-Barltrop, Reetam Majumder, Jordan Richards</dc:creator>
    </item>
    <item>
      <title>A parameterization of anisotropic Gaussian fields with penalized complexity priors</title>
      <link>https://arxiv.org/abs/2409.02331</link>
      <description>arXiv:2409.02331v3 Announce Type: replace 
Abstract: Gaussian random fields (GFs) are fundamental tools in spatial modeling and can be represented flexibly and efficiently as solutions to stochastic partial differential equations (SPDEs). The SPDEs depend on specific parameters, which enforce various field behaviors and can be estimated using Bayesian inference. However, the likelihood typically only provides limited insights into the covariance structure under in-fill asymptotics. In response, it is essential to leverage priors to achieve appropriate, meaningful covariance structures in the posterior. This study introduces a smooth, invertible parameterization of the correlation length and diffusion matrix of an anisotropic GF and constructs penalized complexity (PC) priors for the model when the parameters are constant in space. The formulated prior is weakly informative, effectively penalizing complexity by pushing the correlation range toward infinity and the anisotropy to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02331v3</guid>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liam Llamazares-Elias, Jonas Latz, Finn Lindgren</dc:creator>
    </item>
    <item>
      <title>Efficient Estimation of the Central Mean Subspace via Smoothed Gradient Outer Products</title>
      <link>https://arxiv.org/abs/2312.15469</link>
      <description>arXiv:2312.15469v2 Announce Type: replace-cross 
Abstract: We consider the problem of sufficient dimension reduction (SDR) for multi-index models. The estimators of the central mean subspace in prior works either have slow (non-parametric) convergence rates, or rely on stringent distributional conditions (e.g., the covariate distribution $P_{\mathbf{X}}$ being elliptical symmetric). In this paper, we show that a fast parametric convergence rate of form $C_d \cdot n^{-1/2}$ is achievable via estimating the \emph{expected smoothed gradient outer product}, for a general class of distribution $P_{\mathbf{X}}$ admitting Gaussian or heavier distributions. When the link function is a polynomial with a degree of at most $r$ and $P_{\mathbf{X}}$ is the standard Gaussian, we show that the prefactor depends on the ambient dimension $d$ as $C_d \propto d^r$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15469v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gan Yuan, Mingyue Xu, Samory Kpotufe, Daniel Hsu</dc:creator>
    </item>
  </channel>
</rss>
