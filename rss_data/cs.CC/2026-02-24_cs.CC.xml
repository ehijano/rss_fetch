<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Feb 2026 02:45:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Computational Complexity of Edge Coverage Problem for Constrained Control Flow Graphs</title>
      <link>https://arxiv.org/abs/2602.18774</link>
      <description>arXiv:2602.18774v1 Announce Type: new 
Abstract: The article studies edge coverage for control flow graphs extended with explicit constraints. Achieving a given level of white-box coverage for a given code is a classic problem in software testing. We focus on designing test sets that achieve edge coverage \textit{while respecting additional constraints} between vertices. The paper analyzes how such constraints affect both the feasibility and computational complexity of edge coverage.
  The paper discusses five types of constraints. POSITIVE constraints require at least one test path where a given vertex precedes another. NEGATIVE constraints forbid any such test path. ONCE constraints require exactly one test path with a single occurrence of one vertex before another. MAX ONCE constraints allow such precedence in at most one test path. ALWAYS constraints require every test path containing a given vertex to also contain another vertex later on the same path. Each type models a different test requirement, such as mandatory flows, semantic exclusions, or execution cost limits.
  We investigate the computational complexity of finding a test set that achieves edge coverage and respects a given set of constraints. For POSITIVE constraints, the existence of an edge covering test set is decidable in polynomial time by extending standard edge coverage constructions with additional paths for each constraint. For NEGATIVE, MAX ONCE, ONCE, and ALWAYS constraints, the decision problem is NP-complete. The proofs rely on polynomial reductions from variants of SAT. The NP-completeness results hold even for restricted graph classes, including acyclic graphs, for all these four constraints.
  Finally, we study the fixed-parameter tractability of the NEGATIVE constraint. Although the general problem is NP-complete, the paper presents an FPT algorithm with respect to the number of constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18774v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.SE</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Ruszil, Artur Pola\'nski, Adam Roman, Jakub Zelek</dc:creator>
    </item>
    <item>
      <title>Embedding arbitrary Boolean circuits into fungal automata with arbitrary update sequences</title>
      <link>https://arxiv.org/abs/2602.19477</link>
      <description>arXiv:2602.19477v2 Announce Type: new 
Abstract: The sandpile automata of Bak, Tang, and Wiesenfeld (Phys. Rev. Lett., 1987) are a simple model for the diffusion of particles in space. A fundamental problem related to the complexity of the model is predicting its evolution in the parallel setting. Despite decades of effort, a classification of this problem for two-dimensional sandpile automata remains outstanding. Fungal automata were recently proposed by Goles et al. (Phys. Lett. A, 2020) as a spin-off of the model in which diffusion occurs either in horizontal $(H)$ or vertical $(V)$ directions according to a so-called update scheme. Goles et al. proved that the prediction problem for this model with the update scheme $H^4V^4$ is $\textbf{P}$-complete. This result was subsequently improved by Modanese and Worsch (Algorithmica, 2024), who showed the problem is $\textbf{P}$-complete also for the simpler updatenscheme $HV$. In this work, we fill in the gaps and prove that the prediction problem is $\textbf{P}$-complete for any update scheme that contains both $H$ and $V$ at least once.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19477v2</guid>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Goles, Augusto Modanese, Mart\'in R\'ios-Wilson, Domingo Ruiz-Tala, Thomas Worsch</dc:creator>
    </item>
    <item>
      <title>Parallelism and Adaptivity in Student-Teacher Witnessing</title>
      <link>https://arxiv.org/abs/2602.19934</link>
      <description>arXiv:2602.19934v1 Announce Type: new 
Abstract: Student-Teacher Games are a model of computation in which a computationally restricted Student attempts to produce a string satisfying a refutable property, while an all-powerful Teacher refutes incorrect candidates by providing counterexamples. By the classical result of Kraj\'i\v{c}ek, Pudl\'ak, and Takeuti [KPT90], such games capture the witnessing of $\forall\exists\forall$-formulas in bounded arithmetic. In this paper, we introduce subclasses of total search problems in the polynomial hierarchy, classified by the number of rounds and candidate answers per round required for a Student at the corresponding level to solve them. Assuming the polynomial hierarchy does not collapse, we separate these classes for different number of rounds and queries. As applications we obtain the following results:
  (a) We study theories of bounded arithmetic axiomatized by fine-grained variants of length induction and bounded collection. We prove a general witnessing theorem connecting their $\forall\exists\forall$-consequences to the appropriate classes of Student-Teacher Games. Under the non-collapse of the polynomial hierarchy, we separate these theories.
  (b) These conditional separations resolve two open problems in bounded arithmetic: one by Buss and Ressayre [Bus85, CK93] on the strength of bounded collection, and one by Pollett [Pol97] on the difference between strict and non-strict double length induction.
  (c) Finally, we extend the unprovability of circuit upper bounds due to Kraj\'i\v{c}ek and Oliveira [KO17] to the theory $PV_1+BB(\Sigma^b_1)$, and the unprovability of strong co-nondeterministic circuit lower bounds due to Pich and Santhanam [PS21] to the theory $PV_1+LLIND(s\Sigma^b_1)$. By the preceding separations, both theories strictly extend $PV_1$ assuming $NP\nsubseteq P/poly$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19934v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ond\v{r}ej Je\v{z}il, Dimitrios Tsintsilidas</dc:creator>
    </item>
    <item>
      <title>One Color Makes All the Difference in the Tractability of Partial Coloring in Semi-Streaming</title>
      <link>https://arxiv.org/abs/2602.18987</link>
      <description>arXiv:2602.18987v1 Announce Type: cross 
Abstract: This paper investigates the semi-streaming complexity of \textit{$k$-partial coloring}, a generalization of proper graph coloring. For $k \geq 1$, a $k$-partial coloring requires that each vertex $v$ in an $n$-node graph is assigned a color such that at least $\min\{k, \deg(v)\}$ of its neighbors are assigned colors different from its own. This framework naturally extends classical coloring problems: specifically, $k$-partial $(k+1)$-coloring and $k$-partial $k$-coloring generalize $(\Delta+1)$-proper coloring and $\Delta$-proper coloring, respectively.
  Prior works of Assadi, Chen, and Khanna [SODA~2019] and Assadi, Kumar, and Mittal [TheoretiCS~2023] show that both $(\Delta+1)$-proper coloring and $\Delta$-proper coloring admit one-pass randomized semi-streaming algorithms. We explore whether these efficiency gains extend to their partial coloring generalizations and reveal a sharp computational threshold : while $k$-partial $(k+1)$-coloring admits a one-pass randomized semi-streaming algorithm, the $k$-partial $k$-coloring remains semi-streaming intractable, effectively demonstrating a ``dichotomy of one color'' in the streaming model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18987v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avinandan Das</dc:creator>
    </item>
    <item>
      <title>Hypersequent Calculi Have Ackermannian Complexity</title>
      <link>https://arxiv.org/abs/2602.19229</link>
      <description>arXiv:2602.19229v1 Announce Type: cross 
Abstract: For substructural logics with contraction or weakening admitting cut-free sequent calculi, proof search was analyzed using well-quasi-orders on $\mathbb{N}^d$ (Dickson's lemma), yielding Ackermannian upper bounds via controlled bad-sequence arguments. For hypersequent calculi, that argument lifted the ordering to the powerset, since a hypersequent is a (multi)set of sequents. This induces a jump from Ackermannian to hyper-Ackermannian complexity in the fast-growing hierarchy, suggesting that cut-free hypersequent calculi for extensions of the commutative Full Lambek calculus with contraction or weakening ($\mathbf{FL_{ec}}$/$\mathbf{FL_{ew}}$) inherently entail hyper-Ackermannian upper bounds. We show that this intuition does not hold: every extension of $\mathbf{FL_{ec}}$ and $\mathbf{FL_{ew}}$ admitting a cut-free hypersequent calculus has an Ackermannian upper bound on provability.
  To avoid the powerset, we exploit novel dependencies between individual sequents within any hypersequent in backward proof search. The weakening case, in particular, introduces a Karp-Miller style acceleration, and it improves the upper bound for the fundamental fuzzy logic $\mathbf{MTL}$. Our Ackermannian upper bound is optimal for the contraction case (realized by the logic $\mathbf{FL_{ec}}$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19229v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. R. Balasubramanian, Vitor Greati, Revantha Ramanayake</dc:creator>
    </item>
    <item>
      <title>On Identifying Critical Network Edges via Analyzing Changes in Shapes (Curvatures)</title>
      <link>https://arxiv.org/abs/2602.19328</link>
      <description>arXiv:2602.19328v1 Announce Type: cross 
Abstract: In recent years extensions of manifold Ricci curvature to discrete combinatorial objects such as graphs and hypergraphs (popularly called as "network shapes"), have found a plethora of applications in a wide spectrum of research areas ranging over metabolic systems, transcriptional regulatory networks, protein-protein-interaction networks, social networks and brain networks to deep learning models and quantum computing but, in contrast, they have been looked at by relatively fewer researchers in the algorithms and computational complexity community. As an attempt to bring these network Ricci-curvature related problems under the lens of computational complexity and foster further inter-disciplinary interactions, we provide a formal framework for studying algorithmic and computational complexity issues for detecting critical edges in an undirected graph using Ollivier-Ricci curvatures and provide several algorithmic and inapproximability results for problems in this framework. Our results show some interesting connections between the exact perfect matching and perfect matching blocker problems for bipartite graphs and our problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19328v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhaskar DasGupta, Katie Kruzan</dc:creator>
    </item>
    <item>
      <title>Covering a Polyomino-Shaped Stain with Non-Overlapping Identical Stickers</title>
      <link>https://arxiv.org/abs/2602.19525</link>
      <description>arXiv:2602.19525v1 Announce Type: cross 
Abstract: You find a stain on the wall and decide to cover it with non-overlapping stickers of a single identical shape (rotation and reflection are allowed). Is it possible to find a sticker shape that fails to cover the stain? In this paper, we consider this problem under polyomino constraints and complete the classification of always-coverable stain shapes (polyominoes). We provide proofs for the maximal always-coverable polyominoes and construct concrete counterexamples for the minimal not always-coverable ones, demonstrating that such cases exist even among hole-free polyominoes. This classification consequently yields an algorithm to determine the always-coverability of any given stain. We also show that the problem of determining whether a given sticker can cover a given stain is $\NP$-complete, even though exact cover is not demanded. This result extends to the 1D case where the connectivity requirement is removed. As an illustration of the problem complexity, for a specific hexomino (6-cell) stain, the smallest sticker found in our search that avoids covering it has, although not proven minimum, a bounding box of $325 \times 325$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19525v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keigo Oka, Naoki Inaba, Akira Iino</dc:creator>
    </item>
    <item>
      <title>The Sample Complexity of Replicable Realizable PAC Learning</title>
      <link>https://arxiv.org/abs/2602.19552</link>
      <description>arXiv:2602.19552v1 Announce Type: cross 
Abstract: In this paper, we consider the problem of replicable realizable PAC learning. We construct a particularly hard learning problem and show a sample complexity lower bound with a close to $(\log|H|)^{3/2}$ dependence on the size of the hypothesis class $H$. Our proof uses several novel techniques and works by defining a particular Cayley graph associated with $H$ and analyzing a suitable random walk on this graph by examining the spectral properties of its adjacency matrix.
  Furthermore, we show an almost matching upper bound for the lower bound instance, meaning if a stronger lower bound exists, one would have to consider a different instance of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19552v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kasper Green Larsen, Markus Engelund Mathiasen, Chirag Pabbaraju, Clement Svendsen</dc:creator>
    </item>
    <item>
      <title>Analyzing and Leveraging the $k$-Sensitivity of LZ77</title>
      <link>https://arxiv.org/abs/2602.19649</link>
      <description>arXiv:2602.19649v1 Announce Type: cross 
Abstract: We study the sensitivity of the Lempel-Ziv 77 compression algorithm to edits, showing how modifying a string $w$ can deteriorate or improve its compression. Our first result is a tight upper bound for $k$ edits: $\forall w' \in B(w,k)$, we have $C_{\mathrm{LZ77}}(w') \leq 3 \cdot C_{\mathrm{LZ77}}(w) + 4k$. This result contrasts with Lempel-Ziv 78, where a single edit can significantly deteriorate compressibility, a phenomenon known as a *one-bit catastrophe*.
  We further refine this bound, focusing on the coefficient $3$ in front of $C_{\mathrm{LZ77}}(w)$, and establish a surprising trichotomy based on the compressibility of $w$. More precisely we prove the following bounds:
  - if $C_{\mathrm{LZ77}}(w) \lesssim k^{3/2}\sqrt{n}$, the compression may increase by up to a factor of $\approx 3$,
  - if $k^{3/2}\sqrt{n} \lesssim C_{\mathrm{LZ77}}(w) \lesssim k^{1/3}n^{2/3}$, this factor is at most $\approx 2$,
  - if $C_{\mathrm{LZ77}}(w) \gtrsim k^{1/3}n^{2/3}$, the factor is at most $\approx 1$.
  Finally, we present an $\varepsilon$-approximation algorithm to pre-edit a word $w$ with a budget of $k$ modifications to improve its compression. In favorable scenarios, this approach yields a total compressed size reduction by up to a factor of~$3$, accounting for both the LZ77 compression of the modified word and the cost of storing the edits, $C_{\mathrm{LZ77}}(w') + k \log |w|$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19649v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Bathie, Paul Huber, Guillaume Lagarde, Akka Zemmari</dc:creator>
    </item>
    <item>
      <title>Fast and simple multiplication of bounded twin-width matrices</title>
      <link>https://arxiv.org/abs/2602.20023</link>
      <description>arXiv:2602.20023v1 Announce Type: cross 
Abstract: Matrix multiplication is a fundamental task in almost all computational fields, including machine learning and optimization, computer graphics, signal processing, and graph algorithms (static and dynamic). Twin-width is a natural complexity measure of matrices (and more general structures) that has recently emerged as a unifying concept with important algorithmic applications. While the twin-width of a matrix is invariant to re-ordering rows and columns, most of its algorithmic applications to date assume that the input is given in a certain canonical ordering that yields a bounded twin-width contraction sequence. In general, efficiently finding such a sequence -- even for an approximate twin-width value -- remains a central and elusive open question.
  In this paper we show that a binary $n \times n$ matrix of twin-width $d$ can be preprocessed in $\widetilde{\mathcal{O}}_d(n^2)$ time, so that its product with any vector can be computed in $\widetilde{\mathcal{O}}_d(n)$ time. Notably, the twin-width of the input matrix need not be known and no particular ordering of its rows and columns is assumed. If a canonical ordering is available, i.e., if the input matrix is $d$-twin-ordered, then the runtime of preprocessing and matrix-vector products can be further reduced to $\mathcal{O}(n^2+dn)$ and $\mathcal{O}(dn)$.
  Consequently, we can multiply two $n \times n$ matrices in $\widetilde{\mathcal{O}}(n^2)$ time, when at least one of the matrices consists of 0/1 entries and has bounded twin-width. The results also extend to the case of bounded twin-width matrices with adversarial corruption. Our algorithms are significantly faster and simpler than earlier methods that involved first-order model checking and required both input matrices to be $d$-twin-ordered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20023v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'aszl\'o Kozma, Michal Opler</dc:creator>
    </item>
    <item>
      <title>Hierarchies of Minion Tests for PCSPs through Tensors</title>
      <link>https://arxiv.org/abs/2207.02277</link>
      <description>arXiv:2207.02277v4 Announce Type: replace 
Abstract: We provide a unified framework to study hierarchies of relaxations for Constraint Satisfaction Problems and their Promise variant. The idea is to split the description of a hierarchy into an algebraic part, depending on a minion capturing the "base level", and a geometric part - which we call tensorisation - inspired by multilinear algebra. We exploit the geometry of the tensor spaces arising from our construction to prove general properties of hierarchies. We identify certain classes of minions, which we call linear and conic, whose corresponding hierarchies have particularly fine features. We establish that the (combinatorial) bounded width, Sherali-Adams LP, affine IP, Sum-of-Squares SDP, and combined "LP + affine IP" hierarchies are all captured by this framework. In particular, in order to analyse the Sum-of-Squares SDP hierarchy, we also characterise the solvability of the standard SDP relaxation through a new minion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.02277v4</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Ciardo, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Graded Projection Recursion (GPR): A Framework for Controlling Bit-Complexity of Algebraic Packing</title>
      <link>https://arxiv.org/abs/2511.11988</link>
      <description>arXiv:2511.11988v4 Announce Type: replace 
Abstract: We present Graded Projection Recursion (GPR), a framework for converting certain blocked recursive algorithms into model-honest (i.e., reflects full bit complexity) near-quadratic procedures under bounded intermediate budgets. Part I gives a proof-complete {\em integral specification} of a three-band packing identity and a two-round middle-band extractor, and shows how per-node centering and sqrt-free dyadic l2 normalization (recursive invariant amplification) gives a sufficient packing base that grows linearly with the scaling depth (i.e., logarithmic bit-growth) in exact arithmetic.
  On fixed-width hardware, exact evaluation of the packed recursion generally requires either an extended-precision path or digit-band (slice) staging} that emulates b(n) bits of mantissa precision using w-bit words, incurring only polylogarithmic overhead; This leads to a soft-quadratic bit cost O(n^2) when b(n)=\Theta(\log n) in the basic 2x2 recursion). Part II introduces execution-format comparators (e.g., IEEE-754), a drift ledger, and a decision-invariance theorem that supports commensurate-accuracy claims in floating arithmetic (and that cleanly accounts for any staged/truncated auxiliary drift). Part III provides case-study reductions (LUP/solve/det/inv, LDL^T, blocked QR, SOI/SPD functions, GSEVP, dense LP/SDP IPM kernels, Gaussian process regression, and representative semiring problems) showing how to export the kernel advantage without reintroducing uncontrolled intermediate growth. Part IV abstracts admissible packings and extractors via a master condition and an easily checkable BWBM sufficient condition, and sketches extensions to multilinear/multigraded kernels and non-rounding extractors (e.g., CRT and semiring bucket projections).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11988v4</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Uhlmann</dc:creator>
    </item>
    <item>
      <title>On the Hardness of Approximation of the Fair k-Center Problem</title>
      <link>https://arxiv.org/abs/2602.16688</link>
      <description>arXiv:2602.16688v2 Announce Type: replace 
Abstract: In this work, we study the hardness of approximation of the fair $k$-center problem. In this problem, we are given a set of data points in a metric space that is partitioned into groups and the task is to choose a subset of $k$-data points, called centers, such that a prescribed number of data points from each group are chosen while minimizing the maximum distance from any point to its closest center. Although a polynomial-time $3$-approximation is known for fair $k$-center in general metrics, it has remained open whether this approximation guarantee is tight or could be further improved, especially since the classical unconstrained $k$-center problem admits a polynomial-time factor-$2$ approximation. We resolve this open question by proving that, assuming $\mathsf{P} \neq \mathsf{NP}$, for any $\epsilon&gt;0$, no polynomial-time algorithm can approximate fair $k$-center to $(3-\epsilon)$-factor.
  Our inapproximability results hold even when only two disjoint groups are present and at least one center must be chosen from each group. Further, it extends to the canonical one-per-group setting with $k$-groups (for arbitrary $k$), where exactly one center must be selected from each group. Consequently, the factor-$3$ barrier for fair $k$-center in general metric spaces is inherent, and existing $3$-approximation algorithms are optimal up to lower-order terms even in these restricted regimes. This result stands in sharp contrast to the $k$-supplier formulation, where both the unconstrained and fair variants admit factor-$3$ approximation in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16688v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suhas Thejaswi</dc:creator>
    </item>
    <item>
      <title>On Estimating the Quantum Tsallis Relative Entropy</title>
      <link>https://arxiv.org/abs/2510.00752</link>
      <description>arXiv:2510.00752v2 Announce Type: replace-cross 
Abstract: The relative entropy between quantum states quantifies their distinguishability. The estimation of certain relative entropies has been investigated in the literature, e.g., the von Neumann relative entropy and sandwiched R\'enyi relative entropy. In this paper, we present a comprehensive study of the estimation of the quantum Tsallis relative entropy. We show that for any constant $\alpha \in (0, 1)$, the $\alpha$-Tsallis relative entropy between two quantum states of rank $r$ can be estimated with sample complexity $\operatorname{poly}(r)$, which can be made more efficient if we know their state-preparation circuits. As an application, we obtain an approach to tolerant quantum state certification with respect to the quantum Hellinger distance with sample complexity $\widetilde{O}(r^{3.5})$, which exponentially outperforms the folklore approach based on quantum state tomography when $r$ is polynomial in the number of qubits. In addition, we show that the quantum state distinguishability problems with respect to the quantum $\alpha$-Tsallis relative entropy and quantum Hellinger distance are $\mathsf{QSZK}$-complete in a certain regime, and they are $\mathsf{BQP}$-complete in the low-rank case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00752v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinge Bao, Minbo Gao, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>HNN extensions of free groups with equal associated subgroups of finite index: polynomial time word problem</title>
      <link>https://arxiv.org/abs/2510.03801</link>
      <description>arXiv:2510.03801v2 Announce Type: replace-cross 
Abstract: Let $G=F\ast_\varphi t$ be an HNN extension of a free group $F$ with two equal associated normal subgroups $H_1 = H_2$ of finite index. We prove that the word problem in $G$ is decidable in polynomial time. This result extends to the case where the subgroups $H_1=H_2$ are not normal, provided that the isomorphism $\varphi:H_1\to H_2$ satisfies an additional condition described in Section 5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03801v2</guid>
      <category>math.GR</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanwen Shen, Alexander Ushakov</dc:creator>
    </item>
  </channel>
</rss>
