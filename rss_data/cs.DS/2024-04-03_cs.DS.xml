<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Apr 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A faster algorithm for the construction of optimal factoring automata</title>
      <link>https://arxiv.org/abs/2404.02354</link>
      <description>arXiv:2404.02354v1 Announce Type: new 
Abstract: The problem of constructing optimal factoring automata arises in the context of unification factoring for the efficient execution of logic programs. Given an ordered set of $n$ strings of length $m$, the problem is to construct a trie-like tree structure of minimum size in which the leaves in left-to-right order represent the input strings in the given order. Contrary to standard tries, the order in which the characters of a string are encountered can be different on different root-to-leaf paths. Dawson et al. [ACM Trans. Program. Lang. Syst. 18(5):528--563, 1996] gave an algorithm that solves the problem in time $O(n^2 m (n+m))$. In this paper, we present an improved algorithm with running-time $O(n^2m)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02354v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Erlebach, Kleitos Papadopoulos</dc:creator>
    </item>
    <item>
      <title>Learning Intersections of Halfspaces with Distribution Shift: Improved Algorithms and SQ Lower Bounds</title>
      <link>https://arxiv.org/abs/2404.02364</link>
      <description>arXiv:2404.02364v1 Announce Type: new 
Abstract: Recent work of Klivans, Stavropoulos, and Vasilyan initiated the study of testable learning with distribution shift (TDS learning), where a learner is given labeled samples from training distribution $\mathcal{D}$, unlabeled samples from test distribution $\mathcal{D}'$, and the goal is to output a classifier with low error on $\mathcal{D}'$ whenever the training samples pass a corresponding test. Their model deviates from all prior work in that no assumptions are made on $\mathcal{D}'$. Instead, the test must accept (with high probability) when the marginals of the training and test distributions are equal.
  Here we focus on the fundamental case of intersections of halfspaces with respect to Gaussian training distributions and prove a variety of new upper bounds including a $2^{(k/\epsilon)^{O(1)}} \mathsf{poly}(d)$-time algorithm for TDS learning intersections of $k$ homogeneous halfspaces to accuracy $\epsilon$ (prior work achieved $d^{(k/\epsilon)^{O(1)}}$). We work under the mild assumption that the Gaussian training distribution contains at least an $\epsilon$ fraction of both positive and negative examples ($\epsilon$-balanced). We also prove the first set of SQ lower-bounds for any TDS learning problem and show (1) the $\epsilon$-balanced assumption is necessary for $\mathsf{poly}(d,1/\epsilon)$-time TDS learning for a single halfspace and (2) a $d^{\tilde{\Omega}(\log 1/\epsilon)}$ lower bound for the intersection of two general halfspaces, even with the $\epsilon$-balanced assumption.
  Our techniques significantly expand the toolkit for TDS learning. We use dimension reduction and coverings to give efficient algorithms for computing a localized version of discrepancy distance, a key metric from the domain adaptation literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02364v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan</dc:creator>
    </item>
    <item>
      <title>Minimizing the Number of Tardy Jobs and Maximal Tardiness on a Single Machine is NP-hard</title>
      <link>https://arxiv.org/abs/2404.02784</link>
      <description>arXiv:2404.02784v1 Announce Type: new 
Abstract: This paper resolves a long-standing open question in bicriteria scheduling regarding the complexity of a single machine scheduling problem which combines the number of tardy jobs and the maximal tardiness criteria. We use the lexicographic approach with the maximal tardiness being the primary criterion. Accordingly, the objective is to find, among all solutions minimizing the maximal tardiness, the one which has the minimum number of tardy jobs. The complexity of this problem has been open for over thirty years, and has been known since then to be one of the most challenging open questions in multicriteria scheduling. We resolve this question by proving that the problem is strongly NP-hard. We also prove that the problem is at least weakly NP-hard when we switch roles between the two criteria (i.e., when the number of tardy jobs is the primary criterion). Finally, we provide hardness results for two other approaches (constraint and a priori approaches) to deal with these two criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02784v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Klaus Heeger, Danny Hermelin, Michael L. Pinedo, Dvir Shabtay</dc:creator>
    </item>
    <item>
      <title>On computing approximate Lewis weights</title>
      <link>https://arxiv.org/abs/2404.02881</link>
      <description>arXiv:2404.02881v1 Announce Type: new 
Abstract: In this note we provide and analyze a simple method that given an $n \times d$ matrix, outputs approximate $\ell_p$-Lewis weights, a natural measure of the importance of the rows with respect to the $\ell_p$ norm, for $p \geq 2$. More precisely, we provide a simple post-processing procedure that turns natural one-sided approximate $\ell_p$-Lewis weights into two-sided approximations. When combined with a simple one-sided approximation algorithm presented by Lee (PhD thesis, `16) this yields an algorithm for computing two-sided approximations of the $\ell_p$-Lewis weights of an $n \times d$-matrix using $\mathrm{poly}(d,p)$ approximate leverage score computations. While efficient high-accuracy algorithms for approximating $\ell_p$-Lewis had been established previously by Fazel, Lee, Padmanabhan and Sidford (SODA `22), the simple structure and approximation tolerance of our algorithm may make it of use for different applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02881v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Apers, Sander Gribling, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>A simple lower bound for the complexity of estimating partition functions on a quantum computer</title>
      <link>https://arxiv.org/abs/2404.02414</link>
      <description>arXiv:2404.02414v1 Announce Type: cross 
Abstract: We study the complexity of estimating the partition function ${\mathsf{Z}}(\beta)=\sum_{x\in\chi} e^{-\beta H(x)}$ for a Gibbs distribution characterized by the Hamiltonian $H(x)$. We provide a simple and natural lower bound for quantum algorithms that solve this task by relying on reflections through the coherent encoding of Gibbs states. Our primary contribution is a $\Omega(1/\epsilon)$ lower bound for the number of reflections needed to estimate the partition function with a quantum algorithm. We also prove a $\Omega(1/\epsilon^2)$ query lower bound for classical algorithms. The proofs are based on a reduction from the problem of estimating the Hamming weight of an unknown binary string.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02414v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherui Chen, Giacomo Nannicini</dc:creator>
    </item>
    <item>
      <title>Degree Sequence Optimization and Extremal Degree Enumerators</title>
      <link>https://arxiv.org/abs/2404.02551</link>
      <description>arXiv:2404.02551v1 Announce Type: cross 
Abstract: The degree sequence optimization problem is to find a subgraph of a given graph which maximizes the sum of given functions evaluated at the subgraph degrees. Here we study this problem by replacing degree sequences, via suitable nonlinear transformations, by suitable degree enumerators, and we introduce suitable degree enumerator polytopes.
  We characterize their vertices, that is, the extremal degree enumerators, for complete graphs and some complete bipartite graphs, and use these characterizations to obtain simpler and faster algorithms for optimization over degree sequences for such graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02551v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shmuel Onn</dc:creator>
    </item>
    <item>
      <title>History Trees and Their Applications</title>
      <link>https://arxiv.org/abs/2404.02673</link>
      <description>arXiv:2404.02673v1 Announce Type: cross 
Abstract: In the theoretical study of distributed communication networks, "history trees" are a discrete structure that naturally models the concept that anonymous agents become distinguishable upon receiving different sets of messages from neighboring agents. By conveniently organizing temporal information in a systematic manner, history trees have been instrumental in the development of optimal deterministic algorithms for networks that are both anonymous and dynamically evolving.
  This note provides an accessible introduction to history trees, drawing comparisons with more traditional structures found in existing literature and reviewing the latest advancements in the applications of history trees, especially within dynamic networks. Furthermore, it expands the theoretical framework of history trees in new directions, also highlighting several open problems for further investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02673v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Viglietta</dc:creator>
    </item>
    <item>
      <title>Forming Large Patterns with Local Robots in the OBLOT Model</title>
      <link>https://arxiv.org/abs/2404.02771</link>
      <description>arXiv:2404.02771v1 Announce Type: cross 
Abstract: In the arbitrary pattern formation problem, $n$ autonomous, mobile robots must form an arbitrary pattern $P \subseteq \mathbb{R}^2$. The (deterministic) robots are typically assumed to be indistinguishable, disoriented, and unable to communicate. An important distinction is whether robots have memory and/or a limited viewing range. Previous work managed to form $P$ under a natural symmetry condition if robots have no memory but an unlimited viewing range [22] or if robots have a limited viewing range but memory [25]. In the latter case, $P$ is only formed in a shrunk version that has constant diameter.
  Without memory and with limited viewing range, forming arbitrary patterns remains an open problem. We provide a partial solution by showing that $P$ can be formed under the same symmetry condition if the robots' initial diameter is $\leq 1$. Our protocol partitions $P$ into rotation-symmetric components and exploits the initial mutual visibility to form one cluster per component. Using a careful placement of the clusters and their robots, we show that a cluster can move in a coordinated way through its component while drawing $P$ by dropping one robot per pattern coordinate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02771v1</guid>
      <category>cs.RO</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Hahn, Jonas Harbig, Peter Kling</dc:creator>
    </item>
    <item>
      <title>Fast algorithms for Vizing's theorem on bounded degree graphs</title>
      <link>https://arxiv.org/abs/2303.05408</link>
      <description>arXiv:2303.05408v4 Announce Type: replace 
Abstract: Vizing's theorem states that every graph $G$ of maximum degree $\Delta$ can be properly edge-colored using $\Delta + 1$ colors. The fastest currently known $(\Delta+1)$-edge-coloring algorithm for general graphs is due to Sinnamon and runs in time $O(m\sqrt{n})$, where $n :=|V(G)|$ and $m :=|E(G)|$. We investigate the case when $\Delta$ is constant, i.e., $\Delta = O(1)$. In this regime, the runtime of Sinnamon's algorithm is $O(n^{3/2})$, which can be improved to $O(n \log n)$, as shown by Gabow, Nishizeki, Kariv, Leven, and Terada. Here we give an algorithm whose running time is only $O(n)$, which is obviously best possible. Prior to this work, no linear-time $(\Delta+1)$-edge-coloring algorithm was known for any $\Delta \geq 4$. Using some of the same ideas, we also develop new algorithms for $(\Delta+1)$-edge-coloring in the $\mathsf{LOCAL}$ model of distributed computation. Namely, when $\Delta$ is constant, we design a deterministic $\mathsf{LOCAL}$ algorithm with running time $\tilde{O}(\log^5 n)$ and a randomized $\mathsf{LOCAL}$ algorithm with running time $O(\log ^2 n)$. Although our focus is on the constant $\Delta$ regime, our results remain interesting for $\Delta$ up to $\log^{o(1)} n$, since the dependence of their running time on $\Delta$ is polynomial. The key new ingredient in our algorithms is a novel application of the entropy compression method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05408v4</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Bernshteyn, Abhishek Dhawan</dc:creator>
    </item>
    <item>
      <title>The Complexity of Cluster Vertex Splitting and Company</title>
      <link>https://arxiv.org/abs/2309.00504</link>
      <description>arXiv:2309.00504v3 Announce Type: replace 
Abstract: Clustering a graph when the clusters can overlap can be seen from three different angles: We may look for cliques that cover the edges of the graph with bounded overlap, we may look to add or delete few edges to uncover the cluster structure, or we may split vertices to separate the clusters from each other. Splitting a vertex $v$ means to remove it and to add two new copies of $v$ and to make each previous neighbor of $v$ adjacent with at least one of the copies. In this work, we study underlying computational problems regarding the three angles to overlapping clusterings, in particular when the overlap is small. We show that the above-mentioned covering problem is NP-complete. We then make structural observations that show that the covering viewpoint and the vertex-splitting viewpoint are equivalent, yielding NP-hardness for the vertex-splitting problem. On the positive side, we show that splitting at most $k$ vertices to obtain a cluster graph has a problem kernel with $O(k)$ vertices. Finally, we observe that combining our hardness results with the so-called critical-clique lemma yields NP-hardness for Cluster Editing with Vertex Splitting, which was previously open (Abu-Khzam et al. [ISCO 2018]) and independently shown to be NP-hard by Arrighi et al. [IPEC 2023]. We observe that a previous version of the critical-clique lemma was flawed; a corrected version has appeared in the meantime on which our hardness result is based.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00504v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Firbas, Alexander Dobler, Fabian Holzer, Jakob Schafellner, Manuel Sorge, Ana\"is Villedieu, Monika Wi{\ss}mann</dc:creator>
    </item>
    <item>
      <title>Nearly Optimal Fault Tolerant Distance Oracle</title>
      <link>https://arxiv.org/abs/2402.12832</link>
      <description>arXiv:2402.12832v5 Announce Type: replace 
Abstract: We present an $f$-fault tolerant distance oracle for an undirected weighted graph where each edge has an integral weight from $[1 \dots W]$. Given a set $F$ of $f$ edges, as well as a source node $s$ and a destination node $t$, our oracle returns the \emph{shortest path} from $s$ to $t$ avoiding $F$ in $O((cf \log (nW))^{O(f^2)})$ time, where $c &gt; 1$ is a constant. The space complexity of our oracle is $O(f^4n^2\log^2 (nW))$. For a constant $f$, our oracle is nearly optimal both in terms of space and time (barring some logarithmic factor).</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12832v5</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipan Dey, Manoj Gupta</dc:creator>
    </item>
    <item>
      <title>A Skip-based Algorithm for Weighted Reservoir Random Sampling with Replacement</title>
      <link>https://arxiv.org/abs/2403.20256</link>
      <description>arXiv:2403.20256v2 Announce Type: replace 
Abstract: Reservoir sampling techniques can be used to extract a sample from a population of unknown size. Most of attention has been put to sampling without replacement, with only a small number of studies focusing on sampling with replacement. Specifically, to the author's knowledge, no one has explored in detail how to deal with the weighted case in this setting. In this work, we demonstrate that the results shown in [1] can be further generalized using similar techniques to develop a fast skip-based algorithm for weighted reservoir sampling with replacement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20256v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adriano Meligrana</dc:creator>
    </item>
    <item>
      <title>A Quantum Algorithm Framework for Discrete Probability Distributions with Applications to R\'enyi Entropy Estimation</title>
      <link>https://arxiv.org/abs/2212.01571</link>
      <description>arXiv:2212.01571v2 Announce Type: replace-cross 
Abstract: Estimating statistical properties is fundamental in statistics and computer science. In this paper, we propose a unified quantum algorithm framework for estimating properties of discrete probability distributions, with estimating R\'enyi entropies as specific examples. In particular, given a quantum oracle that prepares an $n$-dimensional quantum state $\sum_{i=1}^{n}\sqrt{p_{i}}|i\rangle$, for $\alpha&gt;1$ and $0&lt;\alpha&lt;1$, our algorithm framework estimates $\alpha$-R\'enyi entropy $H_{\alpha}(p)$ to within additive error $\epsilon$ with probability at least $2/3$ using $\widetilde{\mathcal{O}}(n^{1-\frac{1}{2\alpha}}/\epsilon + \sqrt{n}/\epsilon^{1+\frac{1}{2\alpha}})$ and $\widetilde{\mathcal{O}}(n^{\frac{1}{2\alpha}}/\epsilon^{1+\frac{1}{2\alpha}})$ queries, respectively. This improves the best known dependence in $\epsilon$ as well as the joint dependence between $n$ and $1/\epsilon$. Technically, our quantum algorithms combine quantum singular value transformation, quantum annealing, and variable-time amplitude estimation. We believe that our algorithm framework is of general interest and has wide applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01571v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2024.3382037</arxiv:DOI>
      <dc:creator>Xinzhao Wang, Shengyu Zhang, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Budget Recycling Differential Privacy</title>
      <link>https://arxiv.org/abs/2403.11445</link>
      <description>arXiv:2403.11445v2 Announce Type: replace-cross 
Abstract: Differential Privacy (DP) mechanisms usually {force} reduction in data utility by producing "out-of-bound" noisy results for a tight privacy budget. We introduce the Budget Recycling Differential Privacy (BR-DP) framework, designed to provide soft-bounded noisy outputs for a broad range of existing DP mechanisms. By "soft-bounded," we refer to the mechanism's ability to release most outputs within a predefined error boundary, thereby improving utility and maintaining privacy simultaneously. The core of BR-DP consists of two components: a DP kernel responsible for generating a noisy answer per iteration, and a recycler that probabilistically recycles/regenerates or releases the noisy answer. We delve into the privacy accounting of BR-DP, culminating in the development of a budgeting principle that optimally sub-allocates the available budget between the DP kernel and the recycler. Furthermore, we introduce algorithms for tight BR-DP accounting in composition scenarios, and our findings indicate that BR-DP achieves reduced privacy leakage post-composition compared to DP. Additionally, we explore the concept of privacy amplification via subsampling within the BR-DP framework and propose optimal sampling rates for BR-DP across various queries. We experiment with real data, and the results demonstrate BR-DP's effectiveness in lifting the utility-privacy tradeoff provided by DP mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11445v2</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bo Jiang, Jian Du, Sagar Shamar, Qiang Yan</dc:creator>
    </item>
  </channel>
</rss>
