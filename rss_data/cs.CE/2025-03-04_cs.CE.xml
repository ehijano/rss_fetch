<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 03:02:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Condenser Pressure Influence on Ideal Steam Rankine Power Vapor Cycle using the Python Extension Package Cantera for Thermodynamics</title>
      <link>https://arxiv.org/abs/2503.00180</link>
      <description>arXiv:2503.00180v1 Announce Type: new 
Abstract: This study investigates the Rankine vapor power thermodynamic cycle using steam/water as the working fluid, which is common in commercial power plants for power generation as the source of the rotary shaft power needed to drive electric generators. The four-process cycle version, which comprises a water pump section, a boiler/superheater section, a steam turbine section, and a condenser section, was considered. The performance of this thermodynamic power cycle depends on several design parameters. This study varied a single independent variable, the absolute pressure of the condenser, by a factor of 256, from 0.78125 to 200 kPa. The peak pressure and peak temperature in the cycle were fixed at 50 bar (5,000 kPa) and 600{\deg}C, respectively, corresponding to a base case with a base value for the condenser's absolute pressure of 12.5 kPa (0.125 bar). The analysis was performed using the thermodynamics software package Cantera as an extension of the Python programming language. The results suggest that over the range of condenser pressures examined, a logarithmic function can be deployed to describe the dependence of input heat, the net output work, and cycle efficiency on the absolute pressure of the condenser. Each of these three performance metrics decreases as the absolute pressure of the condenser increases. However, a power function is a better choice to describe how the steam dryness (steam quality) at the end of the turbine section increases as the absolute pressure of the condenser rises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00180v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.48084/etasr.7277</arxiv:DOI>
      <arxiv:journal_reference>Condenser Pressure Influence on Ideal Steam Rankine Power Vapor Cycle using the Python Extension Package Cantera for Thermodynamics. Engineering, Technology &amp; Applied Science Research. 14(3), 14069-14078, 2024</arxiv:journal_reference>
      <dc:creator>Osama A. Marzouk</dc:creator>
    </item>
    <item>
      <title>Path Dependence in AMM-Based Markets: Mathematical Proof and Implications for Truth Discovery</title>
      <link>https://arxiv.org/abs/2503.00201</link>
      <description>arXiv:2503.00201v1 Announce Type: new 
Abstract: This paper demonstrates that Automated Market Maker (AMM) based markets, such as those using constant product formulas (e.g., Uniswap), are inherently path-dependent. We prove mathematically that the sequence of operations in AMMs determines the final state, challenging the notion that market prices solely reflect information. This property has profound implications for decentralized prediction markets that rely on AMMs for price discovery, as it demonstrates they cannot function as pure "truth machines." Using both mathematical proofs and empirical evidence from ETH/USDC pools, we show that AMM-based markets incorporate historical path information beyond the current market beliefs. Our findings contribute to the understanding of market efficiency, mechanism design, and the interpretation of prices in decentralized finance systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00201v1</guid>
      <category>cs.CE</category>
      <category>econ.TH</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Keroshan Pillay</dc:creator>
    </item>
    <item>
      <title>Surrogate Structure-Specific Probabilistic Dynamic Responses of Bridge Portfolios using Deep Learning with Partial Information</title>
      <link>https://arxiv.org/abs/2503.00335</link>
      <description>arXiv:2503.00335v1 Announce Type: new 
Abstract: Predicting region-wide structural responses under seismic shaking is essential for enhancing the effectiveness of earthquake engineering task forces such as earthquake early warning and regional seismic risk and resilience assessments. Existing domain-specific and data-driven approaches, however, lack the capability to provide high-fidelity, structure-specific dynamic response predictions for large-scale structural inventories in a timely manner. To address this gap, this study designed a novel deep learning framework, which integrates heterogeneous ground motion sequences and partial structural information as model inputs, to predict structure-specific, probabilistic dynamic responses of regional structural portfolios. Validation on a portfolio of highway bridges in California demonstrates the model's ability to capture inter-structure response variability by inputting critical and accessible bridge parameters while accounting for uncertainties due to the lack of other information. The results underscore the framework's efficiency and accuracy, paving the way for various advancements in performance-based earthquake engineering and regional-scale seismic decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00335v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chunxiao Ning, Yazhou Xie</dc:creator>
    </item>
    <item>
      <title>Polyconvex Physics-Augmented Neural Network Constitutive Models in Principal Stretches</title>
      <link>https://arxiv.org/abs/2503.00575</link>
      <description>arXiv:2503.00575v1 Announce Type: new 
Abstract: Accurate constitutive models of soft materials are crucial for understanding their mechanical behavior and ensuring reliable predictions in the design process. To this end, scientific machine learning research has produced flexible and general material model architectures that can capture the behavior of a wide range of materials, reducing the need for expert-constructed closed-form models. The focus has gradually shifted towards embedding physical constraints in the network architecture to regularize these over-parameterized models. Two popular approaches are input convex neural networks (ICNN) and neural ordinary differential equations (NODE). A related alternative has been the generalization of closed-form models, such as sparse regression from a large library. Remarkably, all prior work using ICNN or NODE uses the invariants of the Cauchy-Green tensor and none uses the principal stretches. In this work, we construct general polyconvex functions of the principal stretches in a physics-aware deep-learning framework and offer insights and comparisons to invariant-based formulations. The framework is based on recent developments to characterize polyconvex functions in terms of convex functions of the right stretch tensor $\mathbf{U}$, its cofactor $\text{cof}\mathbf{U}$, and its determinant $J$. Any convex function of a symmetric second-order tensor can be described with a convex and symmetric function of its eigenvalues. Thus, we first describe convex functions of $\mathbf{U}$ and $\text{cof}\mathbf{U}$ in terms of their respective eigenvalues using deep Holder sets composed with ICNN functions. A third ICNN takes as input $J$ and the two convex functions of $\mathbf{U}$ and $\text{cof}\mathbf{U}$, and returns the strain energy as output. The ability of the model to capture arbitrary materials is demonstrated using synthetic and experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00575v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Adrian Buganza Tepole, Asghar Jadoon, Manuel Rausch, Jan N. Fuhg</dc:creator>
    </item>
    <item>
      <title>Execution Welfare Across Solver-based DEXes</title>
      <link>https://arxiv.org/abs/2503.00738</link>
      <description>arXiv:2503.00738v1 Announce Type: new 
Abstract: Decentralized exchanges (DEXes) have evolved dramatically since the introduction of Automated Market Makers (AMMs). In recent years, solver-based protocols have emerged as an alternative venue aiming to introduce competition for routing, access to offchain liquidity, and thereby improve end-user execution. Currently, these solver auctions are hosted on opaque backends, and the extent of price improvement they provide to end users remains unclear.
  We conduct an empirical study of the execution welfare that these protocols bring to users by analyzing data across different asset profiles (USDC-WETH and PEPE-WETH). Our results indicate that, compared to vanilla routing through Uniswap V2 or V3, solver-based protocols effectively enhance execution welfare for end users on DEXes within certain trade size ranges. This effect is most pronounced with USDC-WETH, a short-tail asset, and somewhat less significant with PEPE-WETH, a long-tail asset.
  Additionally, we identify execution welfare discrepancies across solver-based platforms (e.g., CoWSwap, 1inchFusion, UniswapX), revealing potential inefficiencies due to solver market structure, variations in liquidity profile and inventory depth among solvers. These insights highlight both the advantages and challenges of solver-based trading, underscoring its role in improving execution outcomes while raising concerns about market concentration and competition dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00738v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuki Yuminaga, Dex Chen, Danning Sui</dc:creator>
    </item>
    <item>
      <title>PINN-MG: A physics-informed neural network for mesh generation</title>
      <link>https://arxiv.org/abs/2503.00814</link>
      <description>arXiv:2503.00814v1 Announce Type: new 
Abstract: In numerical simulation, structured mesh generation often requires a lot of time and manpower investment. The general scheme for structured quad mesh generation is to find a mapping between the computational domain and the physical domain. This mapping can be obtained by solving partial differential equations. However, existing structured mesh generation methods are difficult to ensure both efficiency and mesh quality. In this paper, we propose a structured mesh generation method based on physics-informed neural network, PINN-MG. It takes boundary curves as input and then utilizes an attention network to capture the potential mapping between computational and physical domains, generating structured meshes for the input physical domain. PINN-MG introduces the Navier-Lam\'e equation in linear elastic as a partial differential equation term in the loss function, ensuring that the neural network conforms to the law of elastic body deformation when optimizing the loss value. The training process of PINN-MG is completely unsupervised and does not require any prior knowledge or datasets, which greatly reduces the previous workload of producing structured mesh datasets. Experimental results show that PINN-MG can generate higher quality structured quad meshes than other methods, and has the advantages of traditional algebraic methods and differential methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00814v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Wang, Haisheng Li, Haoxuan Zhang, Xiaoqun Wu, Nan Li</dc:creator>
    </item>
    <item>
      <title>Personalizing the meshed SPL/NAC Brain Atlas for patient-specific scientific computing using SynthMorph</title>
      <link>https://arxiv.org/abs/2503.00931</link>
      <description>arXiv:2503.00931v1 Announce Type: new 
Abstract: Developing personalized computational models of the human brain remains a challenge for patient-specific clinical applications and neuroscience research. Efficient and accurate biophysical simulations rely on high-quality personalized computational meshes derived from patient's segmented anatomical MRI scans. However, both automatic and manual segmentation are particularly challenging for tissues with limited visibility or low contrast. In this work, we present a new method to create personalized computational meshes of the brain, streamlining the development of computational brain models for clinical applications and neuroscience research. Our method uses SynthMorph, a state-of-the-art anatomy-aware, learning-based medical image registration approach, to morph a comprehensive hexahedral mesh of the open-source SPL/NAC Brain Atlas to patient-specific MRI scans. Each patient-specific mesh includes over 300 labeled anatomical structures, more than any existing manual or automatic methods. Our registration-based method takes approximately 20 minutes, significantly faster than current state-of-the-art mesh generation pipelines, which can take up to two hours. We evaluated several state-of-the-art medical image registration methods, including SynthMorph, to determine the most optimal registration method to morph our meshed anatomical brain atlas to patient MRI scans. Our results demonstrate that SynthMorph achieved high DICE similarity coefficients and low Hausdorff Distance metrics between anatomical structures, while maintaining high mesh element quality. These findings demonstrate that our registration-based method efficiently and accurately produces high-quality, comprehensive personalized brain meshes, representing an important step toward clinical translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00931v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andy Huynh, Benjamin Zwick, Michael Halle, Adam Wittek, Karol Miller</dc:creator>
    </item>
    <item>
      <title>DCAMamba: Mamba-based Rapid Response DC Arc Fault Detection</title>
      <link>https://arxiv.org/abs/2503.01264</link>
      <description>arXiv:2503.01264v1 Announce Type: new 
Abstract: In electrical equipment, even minor contact issues can lead to arc faults. Traditional methods often struggle to balance the accuracy and rapid response required for effective arc fault detection. To address this challenge, we introduce DCAMamba, a novel framework for arc fault detection. Specifically, DCAMamba is built upon a state-space model (SSM) and utilizes a hardware-aware parallel algorithm, designed in a cyclic mode using the Mamba architecture. To meet the dual demands of high accuracy and fast response in arc fault detection, we have refined the original Mamba model and incorporated a Feature Amplification Strategy (FAS), a simple yet effective method that enhances the model's ability to interpret arc fault data. Experimental results show that DCAMamba, with FAS, achieves a 12$\%$ improvement in accuracy over the original Mamba, while maintaining an inference time of only 1.87 milliseconds. These results highlight the significant potential of DCAMamba as a future backbone for signal processing. Our code will be made open-source after peer review.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01264v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukun Wang, Ruxue Zhao, Wancheng Feng, Pu Sun, Chunpeng Tian</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Framework for Medium-Term Covariance Forecasting in Multi-Asset Portfolios</title>
      <link>https://arxiv.org/abs/2503.01581</link>
      <description>arXiv:2503.01581v1 Announce Type: new 
Abstract: Accurate covariance forecasting is central to portfolio allocation, risk management, and asset pricing, yet many existing methods struggle at medium-term horizons, where shifting market regimes and slower dynamics predominate. We propose a deep learning framework that combines three-dimensional convolutional neural networks, bidirectional long short-term memory layers, and multi-head attention to capture complex spatio-temporal dependencies. Using daily data on 14 exchange-traded funds from 2017 through 2023, we find that our model reduces Euclidean and Frobenius distance metrics by up to 20\% relative to classical benchmarks (e.g., shrinkage and GARCH approaches) and remains robust across distinct market regimes. Our portfolio experiments demonstrate significant economic value through lower volatility and moderate turnover. These findings highlight the potential of advanced deep learning architectures to improve medium-term covariance forecasts, offering practical benefits for institutional investors and risk managers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01581v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Reis, Ana Paula Serra, Jo\~ao Gama</dc:creator>
    </item>
    <item>
      <title>Camera Measurement of Blood Oxygen Saturation</title>
      <link>https://arxiv.org/abs/2503.01699</link>
      <description>arXiv:2503.01699v1 Announce Type: new 
Abstract: Blood oxygen saturation (SpO2) is a crucial vital sign routinely monitored in medical settings. Traditional methods require dedicated contact sensors, limiting accessibility and comfort. This study presents a deep learning framework for contactless SpO2 measurement using an off-the-shelf camera, addressing challenges related to lighting variations and skin tone diversity. We conducted two large-scale studies with diverse participants and evaluated our method against traditional signal processing approaches in intra- and inter-dataset scenarios. Our approach demonstrated consistent accuracy across demographic groups, highlighting the feasibility of camera-based SpO2 monitoring as a scalable and non-invasive tool for remote health assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01699v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiankai Tang, Xin Liu, Daniel McDuff, Zhang Jiang, Hongming Hu, Luxi Zhou, Nodoka Nagao, Haruta Suzuki, Yuki Nagahama, Wei Li, Linhong Ji, Yuanchun Shi, Izumi Nishidate, Yuntao Wang</dc:creator>
    </item>
    <item>
      <title>A COMSOL framework for predicting hydrogen embrittlement -- Part I: coupled hydrogen transport</title>
      <link>https://arxiv.org/abs/2503.01736</link>
      <description>arXiv:2503.01736v1 Announce Type: new 
Abstract: Hydrogen threatens the structural integrity of metals and thus predicting hydrogen-material interactions is key to unlocking the role of hydrogen in the energy transition. Quantifying the interplay between material deformation and hydrogen diffusion ahead of cracks and other stress concentrators is key to the prediction and prevention of hydrogen-assisted failures. In this work, a generalised theoretical and computational framework is presented that for the first time encompasses: (i) stress-assisted diffusion, (ii) hydrogen trapping due to multiple trap types, rigorously accounting for the rate of creation of dislocation trap sites, (iii) hydrogen transport through dislocations, (iv) equilibrium (Oriani) and non-equilibrium (McNabb-Foster) trapping kinetics, (v) hydrogen-induced softening, and (vi) hydrogen uptake, considering the role of hydrostatic stresses and local electrochemistry. Particular emphasis is placed on the numerical implementation in COMSOL Multiphysics, releasing the relevant models and discussing stability, discretisation and solver details. Each of the elements of the framework is independently benchmarked against results from the literature and implications for the prediction of hydrogen-assisted fractures are discussed. The second part of this work (Part II) shows how these crack tip predictions can be combined with crack growth simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01736v1</guid>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <category>physics.chem-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. D\'iaz, J. M. Alegre, I. I. Cuesta, E. Mart\'inez-Pa\~neda</dc:creator>
    </item>
    <item>
      <title>A COMSOL framework for predicting hydrogen embrittlement -- Part II: phase field fracture</title>
      <link>https://arxiv.org/abs/2503.01765</link>
      <description>arXiv:2503.01765v1 Announce Type: new 
Abstract: Prediction of hydrogen embrittlement requires a robust modelling approach and this will foster the safe adoption of hydrogen as a clean energy vector. A generalised computational model for hydrogen embrittlement is here presented, based on a phase field description of fracture. In combination with Part I of this work, which describes the process of hydrogen uptake and transport, this allows simulating a wide range of hydrogen transport and embrittlement phenomena. The material toughness is defined as a function of the hydrogen content and both elastic and elastic-plastic material behaviour are incorporated, enabling to capture both ductile and brittle fractures, and the transition from one to the other. The accumulation of hydrogen near a crack tip and subsequent embrittlement is numerically evaluated in a single-edge cracked plate, a boundary layer model and a 3D vessel case study, demonstrating the potential of the framework. Emphasis is placed on the numerical implementation, which is carried out in the finite element package COMSOL Multiphysics, and the models are made freely available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01765v1</guid>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <category>physics.chem-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. D\'iaz, J. M. Alegre, I. I. Cuesta, E. Mart\'inez-Pa\~neda</dc:creator>
    </item>
    <item>
      <title>Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice</title>
      <link>https://arxiv.org/abs/2503.00070</link>
      <description>arXiv:2503.00070v1 Announce Type: cross 
Abstract: Throughout the history from pre-industry 4.0 to post-industry 4.0, cybersecurity at banks has undergone significant changes. Pre-industry 4.0 cyber security at banks relied on individual security methods that were highly manual and had low accuracy. When moving to post-industry 4.0, cybersecurity at banks had a major turning point with security methods that combined different technologies such as Artificial Intelligence (AI), Blockchain, IoT, automating necessary processes and significantly increasing the defence layer for banks. However, along with the development of new technologies, the current challenge of cybersecurity at banks lies in scalability, high costs and resources in both money and time for R&amp;D of defence methods along with the threat of high-tech cybercriminals growing and expanding. This report goes from introducing the importance of cybersecurity at banks, analyzing their management, operational and business objectives, evaluating pre-industry 4.0 technologies used for cybersecurity at banks to assessing post-industry 4.0 technologies focusing on Artificial Intelligence and Blockchain, discussing current policies and practices and ending with discussing key advantages and challenges for 4.0 technologies and recommendations for further developing cybersecurity at banks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00070v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tue Nhi Tran</dc:creator>
    </item>
    <item>
      <title>Distributed Variational Quantum Algorithm with Many-qubit for Optimization Challenges</title>
      <link>https://arxiv.org/abs/2503.00221</link>
      <description>arXiv:2503.00221v1 Announce Type: cross 
Abstract: Optimization problems are critical across various domains, yet existing quantum algorithms, despite their great potential, struggle with scalability and accuracy due to excessive reliance on entanglement. To address these limitations, we propose variational quantum optimization algorithm (VQOA), which leverages many-qubit (MQ) operations in an ansatz solely employing quantum superposition, completely avoiding entanglement. This ansatz significantly reduces circuit complexity, enhances noise robustness, mitigates Barren Plateau issues, and enables efficient partitioning for highly complex large-scale optimization. Furthermore, we introduce distributed VQOA (DVQOA), which integrates high-performance computing with quantum computing to achieve superior performance across MQ systems and classical nodes. These features enable a significant acceleration of material optimization tasks (e.g., metamaterial design), achieving more than 50$\times$ speedup compared to state-of-the-art optimization algorithms. Additionally, DVQOA efficiently solves quantum chemistry problems and $\textit{N}$-ary $(N \geq 2)$ optimization problems involving higher-order interactions. These advantages establish DVQOA as a highly promising and versatile solver for real-world problems, demonstrating the practical utility of the quantum-classical approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00221v1</guid>
      <category>quant-ph</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seongmin Kim, In-Saeng Suh</dc:creator>
    </item>
    <item>
      <title>Input Specific Neural Networks</title>
      <link>https://arxiv.org/abs/2503.00268</link>
      <description>arXiv:2503.00268v1 Announce Type: cross 
Abstract: The black-box nature of neural networks limits the ability to encode or impose specific structural relationships between inputs and outputs. While various studies have introduced architectures that ensure the network's output adheres to a particular form in relation to certain inputs, the majority of these approaches impose constraints on only a single set of inputs. This paper introduces a novel neural network architecture, termed the Input Specific Neural Network (ISNN), which extends this concept by allowing scalar-valued outputs to be subject to multiple constraints. Specifically, the ISNN can enforce convexity in some inputs, non-decreasing monotonicity combined with convexity with respect to others, and simple non-decreasing monotonicity or arbitrary relationships with additional inputs. The paper presents two distinct ISNN architectures, along with equations for the first and second derivatives of the output with respect to the inputs. These networks are broadly applicable.
  In this work, we restrict their usage to solving problems in computational mechanics. In particular, we show how they can be effectively applied to fitting data-driven constitutive models. We then embed our trained data-driven constitutive laws into a finite element solver where significant time savings can be achieved by using explicit manual differentiation using the derived equations as opposed to automatic differentiation. We also show how ISNNs can be used to learn structural relationships between inputs and outputs via a binary gating mechanism. Particularly, ISNNs are employed to model an anisotropic free energy potential to get the homogenized macroscopic response in a decoupled multiscale setting, where the network learns whether or not the potential should be modeled as polyconvex, and retains only the relevant layers while using the minimum number of inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00268v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Asghar A. Jadoon, D. Thomas Seidl, Reese E. Jones, Jan N. Fuhg</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Surrogate Models for Efficient Estimation of Structural Response Distributions and Order Statistics</title>
      <link>https://arxiv.org/abs/2503.01242</link>
      <description>arXiv:2503.01242v1 Announce Type: cross 
Abstract: Engineering disciplines often rely on extensive simulations to ensure that structures are designed to withstand harsh conditions while avoiding over-engineering for unlikely scenarios. Assessments such as Serviceability Limit State (SLS) involve evaluating weather events, including estimating loads not expected to be exceeded more than a specified number of times (e.g., 100) throughout the structure's design lifetime. Although physics-based simulations provide robust and detailed insights, they are computationally expensive, making it challenging to generate statistically valid representations of a wide range of weather conditions.
  To address these challenges, we propose an approach using Gaussian Process (GP) surrogate models trained on a limited set of simulation outputs to directly generate the structural response distribution. We apply this method to an SLS assessment for estimating the order statistics \(Y_{100}\), representing the 100th highest response, of a structure exposed to 25 years of historical weather observations. Our results indicate that the GP surrogate models provide comparable results to full simulations but at a fraction of the computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01242v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vegard Flovik, Sebastian Winter, Christian Agrell</dc:creator>
    </item>
    <item>
      <title>The Role of Deep Learning in Financial Asset Management: A Systematic Review</title>
      <link>https://arxiv.org/abs/2503.01591</link>
      <description>arXiv:2503.01591v1 Announce Type: cross 
Abstract: This review systematically examines deep learning applications in financial asset management. Unlike prior reviews, this study focuses on identifying emerging trends, such as the integration of explainable artificial intelligence (XAI) and deep reinforcement learning (DRL), and their transformative potential. It highlights new developments, including hybrid models (e.g., transformer-based architectures) and the growing use of alternative data sources such as ESG indicators and sentiment analysis. These advancements challenge traditional financial paradigms and set the stage for a deeper understanding of the evolving landscape. We use the Scopus database to select the most relevant articles published from 2018 to 2023. The inclusion criteria encompassed articles that explicitly apply deep learning models within financial asset management. We excluded studies focused on physical assets. This review also outlines our methodology for evaluating the relevance and impact of the included studies, including data sources and analytical methods. Our search identified 934 articles, with 612 meeting the inclusion criteria based on their focus and methodology. The synthesis of results from these articles provides insights into the effectiveness of deep learning models in improving portfolio performance and price forecasting accuracy. The review highlights the broad applicability and potential enhancements deep learning offers to financial asset management. Despite some limitations due to the scope of model application and variation in methodological rigour, the overall evidence supports deep learning as a valuable tool in this field. Our systematic review underscores the progressive integration of deep learning in financial asset management, suggesting a trajectory towards more sophisticated and impactful applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01591v1</guid>
      <category>q-fin.GN</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Reis, Ana Paula Serra, Jo\~ao Gama</dc:creator>
    </item>
    <item>
      <title>Market-Derived Financial Sentiment Analysis: Context-Aware Language Models for Crypto Forecasting</title>
      <link>https://arxiv.org/abs/2502.14897</link>
      <description>arXiv:2502.14897v2 Announce Type: replace 
Abstract: Financial Sentiment Analysis (FSA) traditionally relies on human-annotated sentiment labels to infer investor sentiment and forecast market movements. However, inferring the potential market impact of words based on their human-perceived intentions is inherently challenging. We hypothesize that the historical market reactions to words, offer a more reliable indicator of their potential impact on markets than subjective sentiment interpretations by human annotators. To test this hypothesis, a market-derived labeling approach is proposed to assign tweet labels based on ensuing short-term price trends, enabling the language model to capture the relationship between textual signals and market dynamics directly. A domain-specific language model was fine-tuned on these labels, achieving up to an 11% improvement in short-term trend prediction accuracy over traditional sentiment-based benchmarks. Moreover, by incorporating market and temporal context through prompt-tuning, the proposed context-aware language model demonstrated an accuracy of 89.6% on a curated dataset of 227 impactful Bitcoin-related news events with significant market impacts. Aggregating daily tweet predictions into trading signals, our method outperformed traditional fusion models (which combine sentiment-based and price-based predictions). It challenged the assumption that sentiment-based signals are inferior to price-based predictions in forecasting market movements. Backtesting these signals across three distinct market regimes yielded robust Sharpe ratios of up to 5.07 in trending markets and 3.73 in neutral markets. Our findings demonstrate that language models can serve as effective short-term market predictors. This paradigm shift underscores the untapped capabilities of language models in financial decision-making and opens new avenues for market prediction applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14897v2</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamid Moradi-Kamali, Mohammad-Hossein Rajabi-Ghozlou, Mahdi Ghazavi, Ali Soltani, Amirreza Sattarzadeh, Reza Entezari-Maleki</dc:creator>
    </item>
    <item>
      <title>PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems</title>
      <link>https://arxiv.org/abs/2410.01337</link>
      <description>arXiv:2410.01337v3 Announce Type: replace-cross 
Abstract: Solving partial differential equations (PDEs) serves as a cornerstone for modeling complex dynamical systems. Recent progresses have demonstrated grand benefits of data-driven neural-based models for predicting spatiotemporal dynamics (e.g., tremendous speedup gain compared with classical numerical methods). However, most existing neural models rely on rich training data, have limited extrapolation and generalization abilities, and suffer to produce precise or reliable physical prediction under intricate conditions (e.g., irregular mesh or geometry, complex boundary conditions, diverse PDE parameters, etc.). To this end, we propose a new graph learning approach, namely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model spatiotemporal PDE systems on irregular meshes given small training datasets. Specifically, we incorporate a GNN into a numerical integrator to approximate the temporal marching of spatiotemporal dynamics for a given PDE system. Considering that many physical phenomena are governed by diffusion processes, we further design a learnable Laplace block, which encodes the discrete Laplace-Beltrami operator, to aid and guide the GNN learning in a physically feasible solution space. A boundary condition padding strategy is also designed to improve the model convergence and accuracy. Extensive experiments demonstrate that PhyMPGN is capable of accurately predicting various types of spatiotemporal dynamics on coarse unstructured meshes, consistently achieves the state-of-the-art results, and outperforms other baselines with considerable gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01337v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bocheng Zeng, Qi Wang, Mengtao Yan, Yang Liu, Ruizhi Chengze, Yi Zhang, Hongsheng Liu, Zidong Wang, Hao Sun</dc:creator>
    </item>
    <item>
      <title>ChemToolAgent: The Impact of Tools on Language Agents for Chemistry Problem Solving</title>
      <link>https://arxiv.org/abs/2411.07228</link>
      <description>arXiv:2411.07228v2 Announce Type: replace-cross 
Abstract: To enhance large language models (LLMs) for chemistry problem solving, several LLM-based agents augmented with tools have been proposed, such as ChemCrow and Coscientist. However, their evaluations are narrow in scope, leaving a large gap in understanding the benefits of tools across diverse chemistry tasks. To bridge this gap, we develop ChemToolAgent, an enhanced chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its performance on both specialized chemistry tasks and general chemistry questions. Surprisingly, ChemToolAgent does not consistently outperform its base LLMs without tools. Our error analysis with a chemistry expert suggests that: For specialized chemistry tasks, such as synthesis prediction, we should augment agents with specialized tools; however, for general chemistry questions like those in exams, agents' ability to reason correctly with chemistry knowledge matters more, and tool augmentation does not always help.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07228v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Botao Yu, Frazier N. Baker, Ziru Chen, Garrett Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, Huan Sun</dc:creator>
    </item>
    <item>
      <title>QPET: A Versatile and Portable Quantity-of-Interest-preservation Framework for Error-Bounded Lossy Compression</title>
      <link>https://arxiv.org/abs/2412.02799</link>
      <description>arXiv:2412.02799v2 Announce Type: replace-cross 
Abstract: Error-bounded lossy compression has been widely adopted in many scientific domains because it can address the challenges in storing, transferring, and analyzing unprecedented amounts of scientific data. Although error-bounded lossy compression offers general data distortion control by enforcing strict error bounds on raw data, it may fail to meet the quality requirements on the results of downstream analysis, a.k.a. Quantities of Interest (QoIs), derived from raw data. This may lead to uncertainties and even misinterpretations in scientific discoveries, significantly limiting the use of lossy compression in practice. In this paper, we propose QPET, a novel, versatile, and portable framework for QoI-preserving error-bounded lossy compression, which overcomes the challenges of modeling diverse QoIs by leveraging numerical strategies. QPET features (1) high portability to multiple existing lossy compressors, (2) versatile preservation to most differentiable univariate and multivariate QoIs, and (3) significant compression improvements in QoI-preservation tasks. Experiments with six real-world datasets demonstrate that integrating QPET into state-of-the-art error-bounded lossy compressors can gain 2x to 10x compression speedups of existing QoI-preserving error-bounded lossy compression solutions, up to 1000% compression ratio improvements to general-purpose compressors, and up to 133% compression ratio improvements to existing QoI-integrated scientific compressors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02799v2</guid>
      <category>cs.DB</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyang Liu, Pu Jiao, Kai Zhao, Xin Liang, Sheng Di, Franck Cappello</dc:creator>
    </item>
    <item>
      <title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title>
      <link>https://arxiv.org/abs/2412.20138</link>
      <description>arXiv:2412.20138v5 Announce Type: replace-cross 
Abstract: Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at https://github.com/PioneerFintech.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20138v5</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijia Xiao, Edward Sun, Di Luo, Wei Wang</dc:creator>
    </item>
    <item>
      <title>TFG-Flow: Training-free Guidance in Multimodal Generative Flow</title>
      <link>https://arxiv.org/abs/2501.14216</link>
      <description>arXiv:2501.14216v2 Announce Type: replace-cross 
Abstract: Given an unconditional generative model and a predictor for a target property (e.g., a classifier), the goal of training-free guidance is to generate samples with desirable target properties without additional training. As a highly efficient technique for steering generative models toward flexible outcomes, training-free guidance has gained increasing attention in diffusion models. However, existing methods only handle data in continuous spaces, while many scientific applications involve both continuous and discrete data (referred to as multimodality). Another emerging trend is the growing use of the simple and general flow matching framework in building generative foundation models, where guided generation remains under-explored. To address this, we introduce TFG-Flow, a novel training-free guidance method for multimodal generative flow. TFG-Flow addresses the curse-of-dimensionality while maintaining the property of unbiased sampling in guiding discrete variables. We validate TFG-Flow on four molecular design tasks and show that TFG-Flow has great potential in drug design by generating molecules with desired properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14216v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>ICLR 2025</arxiv:journal_reference>
      <dc:creator>Haowei Lin, Shanda Li, Haotian Ye, Yiming Yang, Stefano Ermon, Yitao Liang, Jianzhu Ma</dc:creator>
    </item>
  </channel>
</rss>
