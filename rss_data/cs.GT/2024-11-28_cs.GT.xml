<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 05:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Will an AI with Private Information Allow Itself to Be Switched Off?</title>
      <link>https://arxiv.org/abs/2411.17749</link>
      <description>arXiv:2411.17749v1 Announce Type: new 
Abstract: A wide variety of goals could cause an AI to disable its off switch because "you can't fetch the coffee if you're dead" (Russell 2019). Prior theoretical work on this shutdown problem assumes that humans know everything that AIs do. In practice, however, humans have only limited information. Moreover, in many of the settings where the shutdown problem is most concerning, AIs might have vast amounts of private information. To capture these differences in knowledge, we introduce the Partially Observable Off-Switch Game (POSG), a game-theoretic model of the shutdown problem with asymmetric information. Unlike when the human has full observability, we find that in optimal play, even AI agents assisting perfectly rational humans sometimes avoid shutdown. As expected, increasing the amount of communication or information available always increases (or leaves unchanged) the agents' expected common payoff. But counterintuitively, introducing bounded communication can make the AI defer to the human less in optimal play even though communication mitigates information asymmetry. In particular, communication sometimes enables new optimal behavior requiring strategic AI deference to achieve outcomes that were previously inaccessible. Thus, designing safe artificial agents in the presence of asymmetric information requires careful consideration of the tradeoffs between maximizing payoffs (potentially myopically) and maintaining AIs' incentives to defer to humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17749v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Garber, Rohan Subramani, Linus Luu, Mark Bedaywi, Stuart Russell, Scott Emmons</dc:creator>
    </item>
    <item>
      <title>PP-LEM: Efficient and Privacy-Preserving Clearance Mechanism for Local Energy Markets</title>
      <link>https://arxiv.org/abs/2411.17758</link>
      <description>arXiv:2411.17758v1 Announce Type: new 
Abstract: In this paper, we propose a novel Privacy-Preserving clearance mechanism for Local Energy Markets (PP-LEM), designed for computational efficiency and social welfare. PP-LEM incorporates a novel competitive game-theoretical clearance mechanism, modelled as a Stackelberg Game. Based on this mechanism, a privacy-preserving market model is developed using a partially homomorphic cryptosystem, allowing buyers' reaction function calculations to be executed over encrypted data without exposing sensitive information of both buyers and sellers. The comprehensive performance evaluation demonstrates that PP-LEM is highly effective in delivering an incentive clearance mechanism with computational efficiency, enabling it to clear the market for 200 users within the order of seconds while concurrently protecting user privacy. Compared to the state of the art, PP-LEM achieves improved computational efficiency without compromising social welfare while still providing user privacy protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17758v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.segan.2024.101477</arxiv:DOI>
      <arxiv:journal_reference>Sustainable Energy, Grids and Networks, Volume 39, 2024, 101477, ISSN 2352-4677</arxiv:journal_reference>
      <dc:creator>Kamil Erdayandi, Mustafa Asan Mustafa</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion by Large Language Models</title>
      <link>https://arxiv.org/abs/2404.00806</link>
      <description>arXiv:2404.00806v2 Announce Type: replace-cross 
Abstract: The rise of algorithmic pricing raises concerns of algorithmic collusion. We conduct experiments with algorithmic pricing agents based on Large Language Models (LLMs). We find that (1) LLM-based agents are adept at pricing tasks, (2) LLM-based pricing agents autonomously collude in oligopoly settings to the detriment of consumers, and (3) variation in seemingly innocuous phrases in LLM instructions ("prompts") may increase collusion. Novel off-path analysis techniques uncover price-war concerns as contributing to these phenomena. Our results extend to auction settings. Our findings uncover unique challenges to any future regulation of LLM-based pricing agents, and black-box pricing agents more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00806v2</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Yannai A. Gonczarowski, Ran I. Shorrer</dc:creator>
    </item>
  </channel>
</rss>
