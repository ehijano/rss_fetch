<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 01:50:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Outlier-free isogeometric discretizations for Laplace eigenvalue problems: closed-form eigenvalue and eigenvector expressions</title>
      <link>https://arxiv.org/abs/2505.01487</link>
      <description>arXiv:2505.01487v1 Announce Type: new 
Abstract: We derive explicit closed-form expressions for the eigenvalues and eigenvectors of the matrices resulting from isogeometric Galerkin discretizations based on outlier-free spline subspaces for the Laplace operator, under different types of homogeneous boundary conditions on bounded intervals. For optimal spline subspaces and specific reduced spline spaces, represented in terms of B-spline-like bases, we show that the corresponding mass and stiffness matrices exhibit a Toeplitz-minus-Hankel or Toeplitz-plus-Hankel structure. Such matrix structure holds for any degree p and implies that the eigenvalues are an explicitly known sampling of the spectral symbol of the Toeplitz part. Moreover, by employing tensor-product arguments, we extend the closed-form property of the eigenvalues and eigenvectors to a d-dimensional box. As a side result, we have an algebraic confirmation that the considered optimal and reduced spline spaces are indeed outlier-free.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01487v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.SP</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noureddine Lamsahel, Carla Manni, Ahmed Ratnani, Stefano Serra-Capizzano, Hendrik Speleers</dc:creator>
    </item>
    <item>
      <title>Schr\"odingerization based quantum algorithms for the fractional Poisson equation</title>
      <link>https://arxiv.org/abs/2505.01602</link>
      <description>arXiv:2505.01602v1 Announce Type: new 
Abstract: We develop a quantum algorithm for solving high-dimensional fractional Poisson equations. By applying the Caffarelli-Silvestre extension, the $d$-dimensional fractional equation is reformulated as a local partial differential equation in $d+1$ dimensions. We propose a quantum algorithm for the finite element discretization of this local problem, by capturing the steady-state of the corresponding differential equations using the Schr\"odingerization approach from \cite{JLY22SchrShort, JLY22SchrLong, analogPDE}. The Schr\"odingerization technique transforms general linear partial and ordinary differential equations into Schr\"odinger-type systems, making them suitable for quantum simulation. This is achieved through the warped phase transformation, which maps the equation into a higher-dimensional space. We provide detailed implementations of the method and conduct a comprehensive complexity analysis, which can show up to exponential advantage -- with respect to the inverse of the mesh size in high dimensions -- compared to its classical counterpart. Specifically, while the classical method requires $\widetilde{\mathcal{O}}(d^{1/2} 3^{3d/2} h^{-d-2})$ operations, the quantum counterpart requires $\widetilde{\mathcal{O}}(d 3^{3d/2} h^{-2.5})$ queries to the block-encoding input models, with the quantum complexity being independent of the dimension $d$ in terms of the inverse mesh size $h^{-1}$. Numerical experiments are conducted to verify the validity of our formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01602v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shi Jin, Nana Liu, Yue Yu</dc:creator>
    </item>
    <item>
      <title>Surrogate to Poincar\'e inequalities on manifolds for dimension reduction in nonlinear feature spaces</title>
      <link>https://arxiv.org/abs/2505.01807</link>
      <description>arXiv:2505.01807v1 Announce Type: new 
Abstract: We aim to approximate a continuously differentiable function $u:\mathbb{R}^d \rightarrow \mathbb{R}$ by a composition of functions $f\circ g$ where $g:\mathbb{R}^d \rightarrow \mathbb{R}^m$, $m\leq d$, and $f : \mathbb{R}^m \rightarrow \mathbb{R}$ are built in a two stage procedure. For a fixed $g$, we build $f$ using classical regression methods, involving evaluations of $u$. Recent works proposed to build a nonlinear $g$ by minimizing a loss function $\mathcal{J}(g)$ derived from Poincar\'e inequalities on manifolds, involving evaluations of the gradient of $u$. A problem is that minimizing $\mathcal{J}$ may be a challenging task. Hence in this work, we introduce new convex surrogates to $\mathcal{J}$. Leveraging concentration inequalities, we provide sub-optimality results for a class of functions $g$, including polynomials, and a wide class of input probability measures. We investigate performances on different benchmarks for various training sample sizes. We show that our approach outperforms standard iterative methods for minimizing the training Poincar\'e inequality based loss, often resulting in better approximation errors, especially for rather small training sets and $m=1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01807v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony Nouy, Alexandre Pasco</dc:creator>
    </item>
    <item>
      <title>Priorconditioned Sparsity-Promoting Projection Methods for Deterministic and Bayesian Linear Inverse Problems</title>
      <link>https://arxiv.org/abs/2505.01827</link>
      <description>arXiv:2505.01827v1 Announce Type: new 
Abstract: High-quality reconstructions of signals and images with sharp edges are needed in a wide range of applications. To overcome the large dimensionality of the parameter space and the complexity of the regularization functional, {sparisty-promoting} techniques for both deterministic and hierarchical Bayesian regularization rely on solving a sequence of high-dimensional iteratively reweighted least squares (IRLS) problems on a lower-dimensional subspace. Generalized Krylov subspace (GKS) methods are a particularly potent class of hybrid Krylov schemes that efficiently solve sequences of IRLS problems by projecting large-scale problems into a relatively small subspace and successively enlarging it. We refer to methods that promote sparsity and use GKS as S-GKS. A disadvantage of S-GKS methods is their slow convergence. In this work, we propose techniques that improve the convergence of S-GKS methods by combining them with priorconditioning, which we refer to as PS-GKS. Specifically, integrating the PS-GKS method into the IAS algorithm allows us to automatically select the shape/rate parameter of the involved generalized gamma hyper-prior, which is often fine-tuned otherwise. Furthermore, we proposed and investigated variations of the proposed PS-GKS method, including restarting and recycling (resPS-GKS and recPS-GKS). These respectively leverage restarted and recycled subspaces to overcome situations when memory limitations of storing the basis vectors are a concern. We provide a thorough theoretical analysis showing the benefits of priorconditioning for sparsity-promoting inverse problems. Numerical experiment are used to illustrate that the proposed PS-GKS method and its variants are competitive with or outperform other existing hybrid Krylov methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01827v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Lindbloom, Mirjeta Pasha, Jan Glaubitz, Youssef Marzouk</dc:creator>
    </item>
    <item>
      <title>A Unified Perspective on Orthogonalization and Diagonalization</title>
      <link>https://arxiv.org/abs/2505.02023</link>
      <description>arXiv:2505.02023v1 Announce Type: new 
Abstract: This paper makes a formal connection between two families of widely used matrix factorization algorithms in numerical linear algebra. One family consists of the Jacobi eigenvalue algorithm and its variants for computing the Hermitian eigendecomposition and singular value decomposition. The other consists of Gaussian elimination and the Gram-Schmidt procedure with various pivoting rules for computing the Cholesky decomposition and QR decomposition respectively.
  Both families are cast as special cases of a more general class of factorization algorithms. We provide a randomized pivoting rule that applies to this general class (which differs substantially from the usual pivoting rules for Gaussian elimination / Gram-Schmidt) which results in the same linear rate of convergence for each algorithm, irrespective of which factorization it computes.
  A second important consequence of this randomized pivoting rule is a provable, effective bound on the numerical stability of the Jacobi eigenvalue algorithm, which addresses a longstanding open problem of Demmel and Veseli\'c `92.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02023v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabel Detherage, Rikhav Shah</dc:creator>
    </item>
    <item>
      <title>High-order well-balanced methods for systems of balance laws: a control-based approach</title>
      <link>https://arxiv.org/abs/2505.02047</link>
      <description>arXiv:2505.02047v1 Announce Type: new 
Abstract: In some previous works, two of the authors have introduced a strategy to develop high-order numerical methods for systems of balance laws that preserve all the stationary solutions of the system. The key ingredient of these methods is a well-balanced reconstruction operator. A strategy has been also introduced to modify any standard reconstruction operator like MUSCL, ENO, CWENO, etc. in order to be well-balanced. This strategy involves a non-linear problem at every cell at every time step that consists in finding the stationary solution whose average is the given cell value. So far this strategy has been only applied to systems whose stationary solution are known either in explicit or implicit form. The goal of this paper is to present a general implementation of this technique that can be applied to any system of balance laws. To do this, the nonlinear problems to be solved in the reconstruction procedure are interpreted as control problems: they consist in finding a solution of an ODE system whose average at the computation interval is given. These problems are written in functional form and the gradient of the functional is computed on the basis of the adjoint problem. Newton's method is applied then to solve the problems. Special care is put to analyze the effects of computing the averages and the source terms using quadrature formulas. To test their efficiency and well-balancedness, the methods are applied to a number of systems of balance laws, ranging from easy academic systems consisting of Burgers equation with some nonlinear source terms to the shallow water equations or Euler equations of gas dynamics with gravity effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02047v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.amc.2020.125820</arxiv:DOI>
      <dc:creator>Irene G\'omez-Bueno, Manuel Jes\'us Castro D\'iaz, Carlos Par\'es</dc:creator>
    </item>
    <item>
      <title>Collocation Methods for High-Order Well-Balanced Methods for Systems of Balance Laws</title>
      <link>https://arxiv.org/abs/2505.02055</link>
      <description>arXiv:2505.02055v1 Announce Type: new 
Abstract: In some previous works, two of the authors introduced a technique to design high-order numerical methods for one-dimensional balance laws that preserve all their stationary solutions. The basis of these methods is a well-balanced reconstruction operator. Moreover, they introduced a procedure to modify any standard reconstruction operator, like MUSCL, ENO, CWENO, etc., in order to be well-balanced. This strategy involves a non-linear problem at every cell at every time step that consists in finding the stationary solution whose average is the given cell value. In a recent paper, a fully well-balanced method is presented where the non-linear problems to be solved in the reconstruction procedure are interpreted as control problems. The goal of this paper is to introduce a new technique to solve these local non-linear problems based on the application of the collocation RK methods. Special care is put to analyze the effects of computing the averages and the source terms using quadrature formulas. A general technique which allows us to deal with resonant problems is also introduced. To check the efficiency of the methods and their well-balance property, they have been applied to a number of tests, ranging from easy academic systems of balance laws consisting of Burgers equation with some non-linear source terms to the shallow water equations -- with and without Manning friction -- or Euler equations of gas dynamics with gravity effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02055v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/math9151799</arxiv:DOI>
      <dc:creator>Irene G\'omez-Bueno, Manuel Jes\'us Castro D\'iaz, Carlos Par\'es, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Compact difference method for Euler-Bernoulli beams and plates with nonlinear nonlocal strong damping</title>
      <link>https://arxiv.org/abs/2505.02132</link>
      <description>arXiv:2505.02132v1 Announce Type: new 
Abstract: We investigate the numerical approximation to the Euler-Bernoulli (E-B) beams and plates with nonlinear nonlocal strong damping, which describes the damped mechanical behavior of beams and plates in real applications. We discretize the damping term by the composite Simpson's rule and the six-point Simpson's formula in the beam and plate problems, respectively, and then construct the fully discrete compact difference scheme for these problems. To account for the nonlinear-nonlocal term, we design several novel discrete norms to facilitate the error estimates of the damping term and the numerical scheme. The stability, convergence, and energy dissipation properties of the proposed scheme are proved, and numerical experiments are carried out to substantiate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02132v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Guo, Yiqun Li, Wenlin Qiu</dc:creator>
    </item>
    <item>
      <title>Phantom Domain Finite Element Method: A novel approach for heterogeneous materials</title>
      <link>https://arxiv.org/abs/2505.02268</link>
      <description>arXiv:2505.02268v1 Announce Type: new 
Abstract: In this paper, we introduce the Phantom Domain Finite Element Method (PDFEM), a novel computational approach tailored for the efficient analysis of heterogeneous and composite materials. Inspired by fictitious domain methods, this method employs a structured mesh to discretize the entire material domain while utilizing separate, independent meshes for the inclusions. These inclusion meshes are coupled to the structured mesh via a substitution matrix, enabling them to act as phantom meshes that do not directly contribute to the final system of equations. This framework offers significant advantages, including enhanced flexibility in handling complex inclusion geometries and improved computational efficiency. To assess the accuracy and robustness of the proposed method, numerical experiments are conducted on structures containing inclusions of various geometries. In order to emphasize the efficiency of the PDFEM method, a numerical simulation is presented to highlight its advantages in the case of long natural fibers, such as flax and linen. These simulations are compared against FEM calculations, demonstrating the efficiency of PDFEM. Indeed, meshing such fine structures requires an extremely high number of elements, and in some cases, meshing becomes particularly challenging due to the complexity of the geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02268v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apples.2025.100218</arxiv:DOI>
      <dc:creator>Tianlong He, Philippe Karamian-Surville, Daniel Cho\"i</dc:creator>
    </item>
    <item>
      <title>Efficient Krylov methods for linear response in plane-wave electronic structure calculations</title>
      <link>https://arxiv.org/abs/2505.02319</link>
      <description>arXiv:2505.02319v1 Announce Type: new 
Abstract: We propose a novel algorithm based on inexact GMRES methods for linear response calculations in density functional theory. Such calculations require iteratively solving a nested linear problem $\mathcal{E} \delta\rho = b$ to obtain the variation of the electron density $\delta \rho$. Notably each application of the dielectric operator $\mathcal{E}$ in turn requires the iterative solution of multiple linear systems, the Sternheimer equations. We develop computable bounds to estimate the accuracy of the density variation given the tolerances to which the Sternheimer equations have been solved. Based on this result we suggest reliable strategies for adaptively selecting the convergence tolerances of the Sternheimer equations, such that each applications of $\mathcal{E}$ is no more accurate than needed. Experiments on challenging materials systems of practical relevance demonstrate our strategies to achieve superlinear convergence as well as a reduction of computational time by about 40% while preserving the accuracy of the returned response solution. Our algorithm seamlessly combines with standard preconditioning approaches known from the context of self-consistent field problems making it a promising framework for efficient response solvers based on Krylov subspace techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02319v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael F. Herbst, Bonan Sun</dc:creator>
    </item>
    <item>
      <title>On Trigonometric Interpolation and Its Applications</title>
      <link>https://arxiv.org/abs/2505.02330</link>
      <description>arXiv:2505.02330v1 Announce Type: new 
Abstract: In this paper, we propose a new trigonometric interpolation algorithm and establish relevant convergent properties. The method adjusts an existing trigonometric interpolation algorithm such that it can better leverage Fast Fourier Transform (FFT) to enhance efficiency. The algorithm can be formulated in a way such that certain cancellation effects can be effectively leveraged for error analysis, which enables us not only to obtain the desired uniform convergent rate of the approximation to a function, but desired uniform convergent rates for its derivatives as well.
  We further enhance the algorithm so it can be applied to non-periodic functions defined on bounded intervals. Numerical testing results confirm decent accurate performance of the algorithm. For its application, we demonstrate how it can be applied to estimate integrals and solve linear/non-linear ordinary differential equation (ODE). The test results show that it significantly outperforms Trapezoid/Simpson method on integral and standard Runge-Kutta algorithm on ODE. In addition, we show some numerical evidences that estimation error of the algorithm likely exhibits ``local property", i.e. error at a point tends not to propagate, which avoids significant compounding error at some other place, as a remarkable advantage compared to polynomial-based approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02330v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaorong Zou</dc:creator>
    </item>
    <item>
      <title>Optimal error estimates of a second-order temporally finite element method for electrohydrodynamic equations</title>
      <link>https://arxiv.org/abs/2505.02345</link>
      <description>arXiv:2505.02345v1 Announce Type: new 
Abstract: In this work, we mainly present the optimal convergence rates of the temporally second-order finite element scheme for solving the electrohydrodynamic equation. Suffering from the highly coupled nonlinearity, the convergence analysis of the numerical schemes for such a system is rather rare, not to mention the optimal error estimates for the high-order temporally scheme. To this end, we abandon the traditional error analysis method following the process of energy estimate, which may lead to the loss of accuracy. Instead, we note that the charge density also possesses the "energy" decaying property directly derived by its governing equation, although it does not appear in the energy stability analysis. This fact allows us to control the error terms of the charge density more conveniently, which finally leads to the optimal convergence rates. Several numerical examples are provided to demonstrate the theoretical results, including the energy stability, mass conservation, and convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02345v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shengfeng Wang, Zeyu Xia, Maojun Li</dc:creator>
    </item>
    <item>
      <title>Sampling Kantorovich operators for speckle noise reduction using a Down-Up scaling approach and gap filling in remote sensing images</title>
      <link>https://arxiv.org/abs/2505.02422</link>
      <description>arXiv:2505.02422v1 Announce Type: new 
Abstract: In the literature, several approaches have been proposed for restoring and enhancing remote sensing images, including methods based on interpolation, filtering, and deep learning. In this paper, we investigate the application of multivariate sampling Kantorovich (SK) operators for image reconstruction, with a particular focus on gap filling and speckle noise reduction. To understand the accuracy performances of the proposed algorithms, we first derive a quantitative estimate in $C(\R^n)$ for the error of approximation using the Euler-Maclaurin summation formula, which provides sharper error bounds under minimal regularity conditions. We also establish a convergence result and a quantitative estimate with respect to the dissimilarity index measured by the continuous SSIM for functions in Lebesgue spaces. Additionally, we prove a multidimensional linear prediction result, which is used to design a new SK-based reconstruction algorithm to handle missing data, that we call LP-SK algorithm. To address speckle noise, we integrate SK operators into a newly proposed Down-Up scaling approach. Numerical tests are presented on synthetic and real SAR images to validate the proposed methods. Performance is assessed using similarity metrics such as SSIM and PSNR, along with speckle-specific indexes. Comparative analysis with state-of-the-art techniques highlights the effectiveness of the proposed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02422v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Costarelli, Mariarosaria Natale</dc:creator>
    </item>
    <item>
      <title>Finite difference method for nonlinear damped viscoelastic Euler-Bernoulli beam model</title>
      <link>https://arxiv.org/abs/2505.02517</link>
      <description>arXiv:2505.02517v1 Announce Type: new 
Abstract: We propose and analyze the numerical approximation for a viscoelastic Euler-Bernoulli beam model containing a nonlinear strong damping coefficient. The finite difference method is used for spatial discretization, while the backward Euler method and the averaged PI rule are applied for temporal discretization. The long-time stability and the finite-time error estimate of the numerical solutions are derived for both the semi-discrete-in-space scheme and the fully-discrete scheme. Furthermore, the Leray-Schauder theorem is used to derive the existence and uniqueness of the fully-discrete numerical solutions. Finally, the numerical results verify the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02517v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlin Qiu, Xiangcheng Zheng, Tao Guo, Xu Xiao</dc:creator>
    </item>
    <item>
      <title>A posteriori error estimates for the finite element approximation of the convection-diffusion-reaction equation based on the variational multiscale concept</title>
      <link>https://arxiv.org/abs/2505.02531</link>
      <description>arXiv:2505.02531v1 Announce Type: new 
Abstract: In this study, we employ the variational multiscale (VMS) concept to develop a posteriori error estimates for the stationary convection-diffusion-reaction equation. The variational multiscale method is based on splitting the continuous part of the problem into a resolved scale (coarse scale) and an unresolved scale (fine scale). The unresolved scale (also known as the sub-grid scale) is modeled by choosing it proportional to the component of the residual orthogonal to the finite element space, leading to the orthogonal sub-grid scale (OSGS) method. The idea is then to use the modeled sub-grid scale as an error estimator, considering its contribution in the element interiors and on the edges. We present the results of the a priori analysis and two different strategies for the a posteriori error analysis for the OSGS method. Our proposal is to use a scaled norm of the sub-grid scales as an a posteriori error estimate in the so-called stabilized norm of the problem. This norm has control over the convective term, which is necessary for convection-dominated problems. Numerical examples show the reliable performance of the proposed error estimator compared to other error estimators belonging to the variational multiscale family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02531v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramon Codina, Hauke Gravenkamp, Sheraz Ahmed Khan</dc:creator>
    </item>
    <item>
      <title>Advances on the finite element discretization of fluid-structure interaction problems</title>
      <link>https://arxiv.org/abs/2505.02594</link>
      <description>arXiv:2505.02594v1 Announce Type: new 
Abstract: We review the main features of an unfitted finite element method for interface and fluid-structure interaction problems based on a distributed Lagrange multiplier in the spirit of the fictitious domain approach. We recall our theoretical findings concerning well-posedeness, stability, and convergence of the numerical schemes, and discuss the related computational challenges. In the case of elliptic interface problems, we also present a posteriori error estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02594v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Najwa Alshehri, Daniele Boffi, Fabio Credali, Lucia Gastaldi</dc:creator>
    </item>
    <item>
      <title>Nystr\"om Type Exponential Integrators for Strongly Magnetized Charged Particle Dynamics</title>
      <link>https://arxiv.org/abs/2505.01525</link>
      <description>arXiv:2505.01525v1 Announce Type: cross 
Abstract: Calculating the dynamics of charged particles in electromagnetic fields (i.e. the particle pushing problem) is one of the most computationally intensive components of particle-in-cell (PIC) methods for plasma physics simulations. This task is especially challenging when the plasma is strongly magnetized, since in this case the particle motion consists of a wide range of temporal scales from highly oscillatory fast gyromotion to slow macroscopic behavior and the resulting numerical model is very stiff. Current state-of-the-art time integrators used to simulate particle motion have limitations given the severe numerical stiffness of the problem and more efficient methods are of interest. Recently, exponential integrators have been proposed as a promising new approach for these simulations and shown to offer computational advantages over commonly used schemes. Exponential methods can solve linear problems exactly and are A-stable. In this paper, the standard exponential algorithms framework is extended to derive Nystr\"om-type exponential methods that integrate the Newtonian equations of motion as a second-order differential equation. Specific Nystr\"om-type schemes of second and third orders are derived and applied to strongly magnetized particle pushing problems. Numerical experiments are presented to demonstrate that the Nystr\"om-type exponential integrators can provide significant improvement in computational efficiency over the standard exponential methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01525v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.plasm-ph</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tri P. Nguyen, Ilon Joseph, Mayya Tokman</dc:creator>
    </item>
    <item>
      <title>3D neuron growth and neurodevelopmental disorder modeling based on truncated hierarchical B-splines with multi-level local refinements</title>
      <link>https://arxiv.org/abs/2505.01940</link>
      <description>arXiv:2505.01940v1 Announce Type: cross 
Abstract: 3D neuron growth and neurodevelopmental disorders (NDDs) deterioration exhibit complex morphological transformations as neurites differentiate into axons and dendrites, forming intricate networks driven by tubulin concentrations and neurotrophin signals. Conventional 2D models fall short of capturing such morphological complexity, prompting the need and development of advanced 3D computational approaches. In this paper, we present a complex 3D neuron growth model based on isogeometric analysis (IGA) and the phase field method, utilizing locally refined truncated hierarchical B-splines (THB-splines). IGA offers isoparametric representation and higher-order continuity, which are essential for simulating the smooth, evolving interfaces of phase field neurites. In contrast, the phase field method can automatically handle diffuse interfaces and complex topological changes without explicit boundary tracking. This IGA-based phase field method enables accurate and efficient simulation of neurite extensions, branching, and retraction in a fully 3D setting. The THB-spline implementation supports multi-level local refinement, focusing computational resources on regions of active growth, while dynamic domain expansion adapts the simulation domain to extend with growing neurites. KD-tree-based interpolation ensures that phase field variables are accurately transferred onto newly refined meshes. NDDs associated neurite deterioration is simulated by modulating the driving force term within the phase field model to induce interface retraction. This comprehensive 3D framework enhances the accuracy of neurite morphology simulations, advancing the study of complex neuron development, network formation and NDDs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01940v1</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuanren Qian, Yongjie Jessica Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient computation of soliton gas primitive potentials</title>
      <link>https://arxiv.org/abs/2505.02029</link>
      <description>arXiv:2505.02029v1 Announce Type: cross 
Abstract: We consider the problem of computing a class of soliton gas primitive potentials for the Korteweg--de Vries equation that arise from the accumulation of solitons on an infinite interval in the physical domain, extending to $-\infty$. This accumulation results in an associated Riemann--Hilbert problem on a number of disjoint intervals. In the case where the jump matrices have specific square-root behavior, we describe an efficient and accurate numerical method to solve this Riemann--Hilbert problem and extract the potential. The keys to the method are, first, the deformation of the Riemann--Hilbert problem, making numerical use of the so-called $g$-function, and, second, the incorporation of endpoint singularities into the chosen basis to discretize and solve the associated singular integral equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02029v1</guid>
      <category>nlin.SI</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>nlin.PS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cade Ballew, Deniz Bilman, Thomas Trogdon</dc:creator>
    </item>
    <item>
      <title>Boundary value problem of magnetically insulated diode: existence of solutions and complex bifurcation</title>
      <link>https://arxiv.org/abs/2505.02155</link>
      <description>arXiv:2505.02155v1 Announce Type: cross 
Abstract: The paper focuses on the stationary self-consistent problem of magnetic insulation for a vacuum diode with space-charge limitation, described by a singularly perturbed Vlasov-Maxwell system of dimension 1.5. The case of insulated diode when the electrons are deflected back towards the cathode at the point $x^{*}$ is considered. First, the initial VM system is reduced to the nonlinear singular limit system of ODEs for the potentials of electric and magnetic fields. The second step deals with the limit system's reduction to the new nonlinear singular ODE equation for effective potential $\Theta(x)$. The existence of non-negative solutions is proved for the last equation on the interval $[0, x^{*})$ where $\Theta(x)&gt;0$. The most interesting and unexplored case is when $\Theta(x)&lt;0$ on the interval $(x^{*}, 1]$ and corresponds to the case of an insulated diode. For the first time, a numerical analysis of complex bifurcation of solutions in insulated diode is considered for $\Theta(x)&lt;0$ depending on parameters and boundary conditions. Bifurcation diagrams of the dependence of solution $\Theta(x)$ on a free point (free boundary) $x^{*}$ were constructed. Insulated diode spacing is found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02155v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis Sidorov, Alexander Sinitsyn, David Leguizamon, Liguo Wang</dc:creator>
    </item>
    <item>
      <title>Minimisation of Quasar-Convex Functions Using Random Zeroth-Order Oracles</title>
      <link>https://arxiv.org/abs/2505.02281</link>
      <description>arXiv:2505.02281v1 Announce Type: cross 
Abstract: This study explores the performance of a random Gaussian smoothing zeroth-order (ZO) scheme for minimising quasar-convex (QC) and strongly quasar-convex (SQC) functions in both unconstrained and constrained settings. For the unconstrained problem, we establish the ZO algorithm's convergence to a global minimum along with its complexity when applied to both QC and SQC functions. For the constrained problem, we introduce the new notion of proximal-quasar-convexity and prove analogous results to the unconstrained case. Specifically, we show the complexity bounds and the convergence of the algorithm to a neighbourhood of a global minimum whose size can be controlled under a variance reduction scheme. Theoretical findings are illustrated through investigating the performance of the algorithm applied to a range of problems in machine learning and optimisation. Specifically, we observe scenarios where the ZO method outperforms gradient descent. We provide a possible explanation for this phenomenon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02281v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amir Ali Farzin, Yuen-Man Pun, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Enabling Local Neural Operators to perform Equation-Free System-Level Analysis</title>
      <link>https://arxiv.org/abs/2505.02308</link>
      <description>arXiv:2505.02308v1 Announce Type: cross 
Abstract: Neural Operators (NOs) provide a powerful framework for computations involving physical laws that can be modelled by (integro-) partial differential equations (PDEs), directly learning maps between infinite-dimensional function spaces that bypass both the explicit equation identification and their subsequent numerical solving. Still, NOs have so far primarily been employed to explore the dynamical behavior as surrogates of brute-force temporal simulations/predictions. Their potential for systematic rigorous numerical system-level tasks, such as fixed-point, stability, and bifurcation analysis - crucial for predicting irreversible transitions in real-world phenomena - remains largely unexplored. Toward this aim, inspired by the Equation-Free multiscale framework, we propose and implement a framework that integrates (local) NOs with advanced iterative numerical methods in the Krylov subspace, so as to perform efficient system-level stability and bifurcation analysis of large-scale dynamical systems. Beyond fixed point, stability, and bifurcation analysis enabled by local in time NOs, we also demonstrate the usefulness of local in space as well as in space-time ("patch") NOs in accelerating the computer-aided analysis of spatiotemporal dynamics. We illustrate our framework via three nonlinear PDE benchmarks: the 1D Allen-Cahn equation, which undergoes multiple concatenated pitchfork bifurcations; the Liouville-Bratu-Gelfand PDE, which features a saddle-node tipping point; and the FitzHugh-Nagumo (FHN) model, consisting of two coupled PDEs that exhibit both Hopf and saddle-node bifurcations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02308v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gianluca Fabiani, Hannes Vandecasteele, Somdatta Goswami, Constantinos Siettos, Ioannis G. Kevrekidis</dc:creator>
    </item>
    <item>
      <title>Optimally accurate operators for partial differential equations</title>
      <link>https://arxiv.org/abs/2505.02320</link>
      <description>arXiv:2505.02320v1 Announce Type: cross 
Abstract: In this contribution, we generalize the concept of \textit{optimally accurate operators} proposed and used in a series of studies on the simulation of seismic wave propagation, particularly based on Geller \&amp; Takeuchi (1995). Although these operators have been mathematically and numerically proven to be more accurate than conventional methods, the theory was specifically developed for the equations of motion in linear elastic continuous media. Furthermore, the original theory requires compensation for errors from each term due to truncation at low orders during the error estimation, which has limited its application to other types of physics described by partial differential equations.
  Here, we present a new method that can automatically derive numerical operators for arbitrary partial differential equations. These operators, which involve a small number of nodes in time and space (compact operators), are more accurate than conventional ones and do not require meshing. Our method evaluates the weak formulation of the equations of motion, developed with the aid of Taylor expansions.
  We establish the link between our new method and the classic optimally accurate operators, showing that they produce identical coefficients in homogeneous media. Finally, we perform a benchmark test for the 1D Poisson problem across various heterogeneous media. The benchmarks demonstrate the superiority of our method compared to conventional operators, even when using a set of linear B-spline test functions (three-point hat functions). However, the convergence rate can depend on the wavelength of the material property: when the material property has the same wavelength as that of the field, the convergence rate is O(4), whereas it can be less efficient O(2) for other models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02320v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nobuaki Fuji, Thibault Duretz</dc:creator>
    </item>
    <item>
      <title>dyGRASS: Dynamic Spectral Graph Sparsification via Localized Random Walks on GPUs</title>
      <link>https://arxiv.org/abs/2505.02741</link>
      <description>arXiv:2505.02741v2 Announce Type: cross 
Abstract: This work presents dyGRASS, an efficient dynamic algorithm for spectral sparsification of large undirected graphs that undergo streaming edge insertions and deletions. At its core, dyGRASS employs a random-walk-based method to efficiently estimate node-to-node distances in both the original graph (for decremental update) and its sparsifier (for incremental update). For incremental updates, dyGRASS enables the identification of spectrally critical edges among the updates to capture the latest structural changes. For decremental updates, dyGRASS facilitates the recovery of important edges from the original graph back into the sparsifier. To further enhance computational efficiency, dyGRASS employs a GPU-based non-backtracking random walk scheme that allows multiple walkers to operate simultaneously across various target updates. This parallelization significantly improves both the performance and scalability of the proposed dyGRASS framework. Our comprehensive experimental evaluations reveal that dyGRASS achieves approximately a 10x speedup compared to the state-of-the-art incremental sparsification (inGRASS) algorithm while eliminating the setup overhead and improving solution quality in incremental spectral sparsification tasks. Moreover, dyGRASS delivers high efficiency and superior solution quality for fully dynamic graph sparsification, accommodating both edge insertions and deletions across a diverse range of graph instances originating from integrated circuit simulations, finite element analysis, and social networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02741v2</guid>
      <category>cs.SI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yihang Yuan, Ali Aghdaei, Zhuo Feng</dc:creator>
    </item>
    <item>
      <title>Conjugate Direction Methods Under Inconsistent Systems</title>
      <link>https://arxiv.org/abs/2401.11714</link>
      <description>arXiv:2401.11714v4 Announce Type: replace 
Abstract: Since the development of the conjugate gradient (CG) method in 1952 by Hestenes and Stiefel, CG, has become an indispensable tool in computational mathematics for solving positive definite linear systems. On the other hand, the conjugate residual (CR) method, closely related CG and introduced by Stiefel in 1955 for the same settings, remains relatively less known outside the numerical linear algebra community. Since their inception, these methods -- henceforth collectively referred to as conjugate direction methods -- have been extended beyond positive definite to indefinite, albeit consistent, settings. Going one step further, in this paper, we investigate the theoretical and empirical properties of these methods under inconsistent systems. Among other things, we show that small modifications to the original algorithms allow for the pseudo-inverse solution. Furthermore, we show that CR is essentially equivalent to the minimum residual method, proposed by Paige and Saunders in 1975, in such contexts. Lastly, we conduct a series of numerical experiments to shed lights on their numerical stability (or lack thereof) and their performance for inconsistent systems. Surprisingly, we will demonstrate that, unlike CR and contrary to popular belief, CG can exhibit significant numerical instability, bordering on catastrophe in some instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11714v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Lim, Yang Liu, Fred Roosta</dc:creator>
    </item>
    <item>
      <title>Numerical Exploration of Nonlinear Dispersion Effects via a Strongly Coupled Two-scale System</title>
      <link>https://arxiv.org/abs/2402.09607</link>
      <description>arXiv:2402.09607v2 Announce Type: replace 
Abstract: The effective, fast transport of matter through porous media is often characterized by complex dispersion effects. To describe in mathematical terms such situations, instead of a simple macroscopic equation (as in the classical Darcy's law), one may need to consider two-scale boundary-value problems with full coupling between the scales where the macroscopic transport depends non-linearly on local (i.e. microscopic) drift interactions, which are again influenced by local concentrations. Such two-scale problems are computationally very expensive as numerous elliptic partial differential equations (cell problems) have to constantly be recomputed. In this work, we investigate such an effective two-scale model involving a suitable nonlinear dispersion term and explore numerically the behavior of its weak solutions. We introduce two distinct numerical schemes dealing with the same non-linear scale-coupling: (i) a Picard-type iteration and (ii) a time discretization decoupling. In addition, we propose a precomputing strategy where the calculations of cell problems are pushed into an offline phase. Our approach works for both schemes and significantly reduces computation times. We prove that the proposed precomputing strategy converges to the exact solution. Finally, we test our schemes via several numerical experiments that illustrate dispersion effects introduced by specific choices of microstructure and model ingredients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09607v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surendra Nepal, Vishnu Raveendran, Michael Eden, Rainey Lyons, Adrian Muntean</dc:creator>
    </item>
    <item>
      <title>Finite element schemes with tangential motion for fourth order geometric curve evolutions in arbitrary codimension</title>
      <link>https://arxiv.org/abs/2402.16799</link>
      <description>arXiv:2402.16799v3 Announce Type: replace 
Abstract: We introduce novel finite element schemes for curve diffusion and elastic flow in arbitrary codimension. The schemes are based on a variational form of a system that includes a specifically chosen tangential motion. We derive optimal $L^2$- and $H^1$-error bounds for continuous-in-time semidiscrete finite element approximations that use piecewise linear elements. In addition, we consider fully discrete schemes and, in the case of curve diffusion, prove unconditional stability for it. Finally, we present several numerical simulations, including some convergence experiments that confirm the derived error bounds. The presented simulations suggest that the tangential motion leads to equidistribution in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16799v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Klaus Deckelnick, Robert N\"urnberg</dc:creator>
    </item>
    <item>
      <title>An improved Shifted CholeskyQR based on columns</title>
      <link>https://arxiv.org/abs/2408.06311</link>
      <description>arXiv:2408.06311v5 Announce Type: replace 
Abstract: Among all the deterministic CholeskyQR-type algorithms, Shifted CholeskyQR3 is specifically designed to address the QR factorization of ill-conditioned matrices. This algorithm introduces a shift parameter $s$ to prevent failure during the initial Cholesky factorization step, making the choice of this parameter critical for the algorithm's effectiveness. Our goal is to identify a smaller $s$ compared to the traditional selection based on $\norm{X}_{2}$. In this research, we propose a new definition for the input matrix $X$ called $[X]_{g}$, which is based on the column properties of $X$. $[X]_{g}$ allows us to obtain a reduced shift parameter $s$ for the Shifted CholeskyQR3 algorithm, thereby improving the sufficient condition of $\kappa_{2}(X)$ for this method. We provide rigorous proofs of orthogonality and residuals for the improved algorithm using our proposed $s$. Numerical experiments confirm the enhanced numerical stability of orthogonality and residuals with the reduced $s$. We find that Shifted CholeskyQR3 can effectively handle ill-conditioned $X$ with a larger $\kappa_{2}(X)$ when using our reduced $s$ compared to the original $s$. Furthermore, we compare CPU times with other algorithms to assess performance improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06311v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwei Fan, Haoran Guan, Zhonghua Qiao</dc:creator>
    </item>
    <item>
      <title>Applications of multiscale hierarchical decomposition to blind deconvolution</title>
      <link>https://arxiv.org/abs/2409.08734</link>
      <description>arXiv:2409.08734v4 Announce Type: replace 
Abstract: The blind image deconvolution is a challenging, highly ill-posed nonlinear inverse problem. We introduce a Multiscale Hierarchical Decomposition Method (MHDM) that is iteratively solving variational problems with adaptive data and regularization parameters, towards obtaining finer and finer details of the unknown kernel and image. We establish convergence of the residual in the noise-free data case, and then in the noisy data case when the algorithm is stopped early by means of a discrepancy principle. Fractional Sobolev norms are employed as regularizers for both kernel and image, with the advantage of computing the minimizers explicitly in a pointwise manner. In order to break the notorious symmetry occurring during each minimization step, we enforce a positivity constraint on the Fourier transform of the kernels. Numerical comparisons with a single-step variational method and a non-blind MHDM show that our approach produces comparable results, while less laborious parameter tuning is necessary at the price of more computations. Additionally, the scale decomposition of both reconstructed kernel and image provides a meaningful interpretation of the involved iteration steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08734v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Wolf, Stefan Kindermann, Elena Resmerita, Luminita Vese</dc:creator>
    </item>
    <item>
      <title>Shifted CholeskyQR for sparse matrices</title>
      <link>https://arxiv.org/abs/2410.06525</link>
      <description>arXiv:2410.06525v3 Announce Type: replace 
Abstract: In this work, we focus on Shifted CholeskyQR for sparse matrices, which is widely used in real applications. We introduce a new model for sparse matrices, categorizing them into two types, $T_{1}$ matrices and $T_{2}$ matrices, based on the presence of dense columns. We provide an alternative choice of the shifted item $s$ for Shifted CholeskyQR3 \cite{Shifted} based on the structure and the key element of the input sparse $X$. We do rounding error analysis of Shifted CholeskyQR3 with such an $s$ and show that it is optimal compared to the original one in \cite{New} with proper element-norm conditions (ENCs) for $T_{1}$ matrices, improving the applicability while maintaining numerical stability. Our theoretical analysis utilizes the properties of $[\cdot]_{g}$ proposed in \cite{New}, which is the first to build connections between rounding error analysis and sparse matrices. Numerical experiments confirm our findings for $T_{1}$ matrices. Additionally, Shifted CholeskyQR3 with the alternative choice $s$ is applicable to $T_{2}$ matrices, which are more ill-conditioned than dense cases. Furthermore, Shifted CholeskyQR3 with our alternative $s$ shows good efficiency for both $T_{1}$ and $T_{2}$ matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06525v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Guan, Yuwei Fan</dc:creator>
    </item>
    <item>
      <title>Probabilistic error analysis of CholeskyQR based on columns</title>
      <link>https://arxiv.org/abs/2410.09389</link>
      <description>arXiv:2410.09389v3 Announce Type: replace 
Abstract: In this work, we utilize the randomized models presented in \cite{New} and do probabilistic error analysis of CholeskyQR2 and Shifted CholeskyQR3. We integrate the theoretical analysis with $[\cdot]_{g}$ defined in \cite{Columns}, providing sharper upper bounds of accuracy and better sufficient conditions for CholeskyQR2 and Shifted CholeskyQR3 along with the corresponding probabilities. Moreover, a probabilistic shifted item $s$ for Shifted CholeskyQR3 is received, improving the applicability of the algorithm while maintaining numerical stability. Numerical experiments confirm our findings and show that such a probabilistic $s$ has good robustness in ill-conditioned cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09389v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Guan, Yuwei Fan</dc:creator>
    </item>
    <item>
      <title>Mimetic Metrics for the DGSEM</title>
      <link>https://arxiv.org/abs/2410.14502</link>
      <description>arXiv:2410.14502v2 Announce Type: replace 
Abstract: Free-stream preservation is an essential property for numerical solvers on curvilinear grids. Key to this property is that the metric terms of the curvilinear mapping satisfy discrete metric identities, i.e., have zero divergence. Divergence-free metric terms are furthermore essential for entropy stability on curvilinear grids. We present a new way to compute the metric terms for discontinuous Galerkin spectral element methods (DGSEMs) that guarantees they are divergence-free. Our proposed mimetic approach uses projections that fit within the de Rham Cohomology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14502v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Bach, Andr\'es Rueda-Ram\'irez, David A. Kopriva, Gregor J. Gassner</dc:creator>
    </item>
    <item>
      <title>On the Robustness of the Successive Projection Algorithm</title>
      <link>https://arxiv.org/abs/2411.16195</link>
      <description>arXiv:2411.16195v2 Announce Type: replace 
Abstract: The successive projection algorithm (SPA) is a workhorse algorithm to learn the $r$ vertices of the convex hull of a set of $(r-1)$-dimensional data points, a.k.a. a latent simplex, which has numerous applications in data science. In this paper, we revisit the robustness to noise of SPA and several of its variants. In particular, when $r \geq 3$, we prove the tightness of the existing error bounds for SPA and for two more robust preconditioned variants of SPA. We also provide significantly improved error bounds for SPA, by a factor proportional to the conditioning of the $r$ vertices, in two special cases: for the first extracted vertex, and when $r \leq 2$. We then provide further improvements for the error bounds of a translated version of SPA proposed by Arora et al. (''A practical algorithm for topic modeling with provable guarantees'', ICML, 2013) in two special cases: for the first two extracted vertices, and when $r \leq 3$. Finally, we propose a new more robust variant of SPA that first shifts and lifts the data points in order to minimize the conditioning of the problem. We illustrate our results on synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16195v2</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Barbarino, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>Stabilizing and Solving Unique Continuation Problems by Parameterizing Data and Learning Finite Element Solution Operators</title>
      <link>https://arxiv.org/abs/2412.04409</link>
      <description>arXiv:2412.04409v3 Announce Type: replace 
Abstract: We consider an inverse problem involving the reconstruction of the solution to a nonlinear partial differential equation (PDE) with unknown boundary conditions. Instead of direct boundary data, we are provided with a large dataset of boundary observations for typical solutions (collective data) and a bulk measurement of a specific realization. To leverage this collective data, we first compress the boundary data using proper orthogonal decomposition (POD) in a linear expansion. Next, we identify a possible nonlinear low-dimensional structure in the expansion coefficients using an autoencoder, which provides a parametrization of the dataset in a lower-dimensional latent space. We then train an operator network to map the expansion coefficients representing the boundary data to the finite element (FE) solution of the PDE. Finally, we connect the autoencoder's decoder to the operator network which enables us to solve the inverse problem by optimizing a data-fitting term over the latent space. We analyze the underlying stabilized finite element method (FEM) in the linear setting and establish an optimal error estimate in the $H^1$-norm. The nonlinear problem is then studied numerically, demonstrating the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04409v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Burman, Mats G. Larson, Karl Larsson, Carl Lundholm</dc:creator>
    </item>
    <item>
      <title>A tensor-train reduced basis solver for parameterized partial differential equations on Cartesian grids</title>
      <link>https://arxiv.org/abs/2412.14460</link>
      <description>arXiv:2412.14460v2 Announce Type: replace 
Abstract: In this manuscript, we introduce the tensor-train reduced basis method, a novel projection-based reduced-order model designed for the efficient solution of parameterized partial differential equations. While reduced-order models are widely used for their computational efficiency compared to full-order models, they often involve significant offline computational costs. Our proposed approach mitigates this limitation by leveraging the tensor train format to efficiently represent high-dimensional finite element quantities. This method offers several advantages, including a reduced number of operations for constructing the reduced subspaces, a cost-effective hyper-reduction strategy for assembling the PDE residual and Jacobian, and a lower dimensionality of the projection subspaces for a given accuracy. We provide a posteriori error estimates to validate the accuracy of the method and evaluate its computational performance on benchmark problems, including the Poisson equation, heat equation, and transient linear elasticity in two- and three-dimensional domains. Although the current framework is restricted to problems defined on Cartesian grids, we anticipate that it can be extended to arbitrary shapes by integrating the tensor-train reduced basis method with unfitted finite element techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14460v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Mueller, Yiran Zhao, Santiago Badia, Tiangang Cui</dc:creator>
    </item>
    <item>
      <title>Deflation-based certified greedy algorithm and adaptivity for bifurcating nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2501.12361</link>
      <description>arXiv:2501.12361v2 Announce Type: replace 
Abstract: This work deals with tailored reduced order models for bifurcating nonlinear parametric partial differential equations, where multiple coexisting solutions arise for a given parametric instance. Approaches based on proper orthogonal decomposition have been widely investigated in the literature, but they usually rely on some \emph{a-priori} knowledge about the bifurcating model and lack any error estimation. On the other hand, standard certified reduced basis techniques fail to represent correctly the branching behavior, since the error estimator is no longer reliable. The main goal of the contribution is to overcome these limitations by introducing two novel algorithms: (i) the adaptive-greedy, detecting the bifurcation point starting from scarce information over the parametric space, and (ii) the deflated-greedy, certifying multiple coexisting branches simultaneously. The former approach takes advantage of the features of the reduced manifold to detect the bifurcation, while the latter exploits the deflation and continuation methods to discover the bifurcating solutions and enrich the reduced space. We test the two strategies for the Coanda effect held by the Navier-Stokes equations in a sudden-expansion channel. The accuracy of the approach and the error certification are compared with vanilla-greedy and proper orthogonal decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12361v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Federico Pichi, Maria Strazzullo</dc:creator>
    </item>
    <item>
      <title>Optimal sensor placement under model uncertainty in the weak-constraint 4D-Var framework</title>
      <link>https://arxiv.org/abs/2502.00150</link>
      <description>arXiv:2502.00150v2 Announce Type: replace 
Abstract: In data assimilation, the model may be subject to uncertainties and errors. The weak-constraint data assimilation framework enables incorporating model uncertainty in the dynamics of the governing equations. We propose a new framework for near-optimal sensor placement in the weak-constrained setting. This is achieved by first deriving a design criterion based on the expected information gain, which involves the Kullback-Leibler divergence from the forecast prior to the posterior distribution. An explicit formula for this criterion is provided, assuming that the model error and background are independent and Gaussian and the dynamics are linear. We discuss algorithmic approaches to efficiently evaluate this criterion through randomized approximations. To provide further insight and flexibility in computations, we also provide alternative expressions for the criteria. We provide an algorithm to find near-optimal experimental designs using column subset selection, including a randomized algorithm that avoids computing the adjoint of the forward operator. Through numerical experiments in one and two spatial dimensions, we show the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00150v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alen Alexanderian, Hugo D\'iaz, Vishwas Rao, Arvind K. Saibaba</dc:creator>
    </item>
    <item>
      <title>Analysis of a finite element method for PDEs in evolving domains with topological changes</title>
      <link>https://arxiv.org/abs/2504.14116</link>
      <description>arXiv:2504.14116v2 Announce Type: replace 
Abstract: The paper presents the first rigorous error analysis of an unfitted finite element method for a linear parabolic problem posed on an evolving domain $\Omega(t)$ that may undergo a topological change, such as, for example, a domain splitting. The domain evolution is assumed to be $C^2$-smooth away from a critical time $t_c$, at which the topology may change instantaneously. To accommodate such topological transitions in the error analysis, we introduce several structural assumptions on the evolution of $\Omega(t)$ in the vicinity of the critical time. These assumptions allow a specific stability estimate even across singularities. Based on this stability result we derive optimal-order discretization error bounds, provided the continuous solution is sufficiently smooth. We demonstrate the applicability of our assumptions with examples of level-set domains undergoing topological transitions and discuss cases where the analysis fails. The theoretical error estimate is confirmed by the results of a numerical experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14116v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxim A. Olshanskii, Arnold Reusken</dc:creator>
    </item>
    <item>
      <title>On Runge-Kutta methods of order 10</title>
      <link>https://arxiv.org/abs/2504.17329</link>
      <description>arXiv:2504.17329v2 Announce Type: replace 
Abstract: A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17329v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Misha Stepanov</dc:creator>
    </item>
    <item>
      <title>Affine matrix scrambling achieves smoothness-dependent convergence rates</title>
      <link>https://arxiv.org/abs/2505.00411</link>
      <description>arXiv:2505.00411v2 Announce Type: replace 
Abstract: We study the convergence rate of the median estimator for affine matrix scrambled digital nets applied to integrands over the unit hypercube $[0, 1]^s$. By taking the median of $(2r-1)$ independent randomized quasi-Monte Carlo (RQMC) samples, we demonstrate that the desired convergence rates can be achieved without increasing the number of randomizations $r$ as the quadrature size $N$ grows for both bounded and unbounded integrands. For unbounded integrands, our analysis assumes a boundary growth condition on the weak derivatives and also considers singularities such as kinks and jump discontinuities. Notably, when $r = 1$, the median estimator reduces to the standard RQMC estimator. By applying analytical techniques developed for median estimators, we prove that the affine matrix scrambled estimator achieves a convergence rate depending on the integrand's smoothness, and is therefore not limited by the canonical rate $\mathcal{O}(N^{-3/2})$. However, this smoothness-dependent theoretical rate is not observed empirically in numerical experiments when the affine matrix scrambling yields a heavy-tailed sampling distribution. In contrast, the median estimator consistently reveals the theoretical rates and yields smaller integration errors than mean estimators, further highlighting its advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00411v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Liu</dc:creator>
    </item>
    <item>
      <title>Bayesian Deep Learning with Multilevel Trace-class Neural Networks</title>
      <link>https://arxiv.org/abs/2203.12961</link>
      <description>arXiv:2203.12961v5 Announce Type: replace-cross 
Abstract: In this article we consider Bayesian inference associated to deep neural networks (DNNs) and in particular, trace-class neural network (TNN) priors which can be preferable to traditional DNNs as (a) they are identifiable and (b) they possess desirable convergence properties. TNN priors are defined on functions with infinitely many hidden units, and have strongly convergent Karhunen-Loeve-type approximations with finitely many hidden units. A practical hurdle is that the Bayesian solution is computationally demanding, requiring simulation methods, so approaches to drive down the complexity are needed. In this paper, we leverage the strong convergence of TNN in order to apply Multilevel Monte Carlo (MLMC) to these models. In particular, an MLMC method that was introduced is used to approximate posterior expectations of Bayesian TNN models with optimal computational complexity, and this is mathematically proved. The results are verified with several numerical experiments on model problems arising in machine learning, including regression, classification, and reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.12961v5</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil K. Chada, Ajay Jasra, Kody J. H. Law, Sumeetpal S. Singh</dc:creator>
    </item>
    <item>
      <title>Gauss-Southwell type descent methods for low-rank matrix optimization</title>
      <link>https://arxiv.org/abs/2306.00897</link>
      <description>arXiv:2306.00897v3 Announce Type: replace-cross 
Abstract: We consider gradient-related methods for low-rank matrix optimization with a smooth cost function. The methods operate on single factors of the low-rank factorization and share aspects of both alternating and Riemannian optimization. Two possible choices for the search directions based on Gauss-Southwell type selection rules are compared: one using the gradient of a factorized non-convex formulation, the other using the Riemannian gradient. While both methods provide gradient convergence guarantees that are similar to the unconstrained case, numerical experiments on a quadratic cost function indicate that the version based on the Riemannian gradient is significantly more robust with respect to small singular values and the condition number of the cost function. As a side result of our approach, we also obtain new convergence results for the alternating least squares method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.00897v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, Andr\'e Uschmajew, Bart Vandereycken</dc:creator>
    </item>
    <item>
      <title>Enhanced BPINN Training Convergence in Solving General and Multi-scale Elliptic PDEs with Noise</title>
      <link>https://arxiv.org/abs/2408.09340</link>
      <description>arXiv:2408.09340v2 Announce Type: replace-cross 
Abstract: Bayesian Physics Informed Neural Networks (BPINN) have attracted considerable attention for inferring the system states and physical parameters of differential equations according to noisy observations. However, in practice, Hamiltonian Monte Carlo (HMC) used to estimate the internal parameters of the solver for BPINN often encounters these troubles including poor performance and awful convergence for a given step size used to adjust the momentum of those parameters. To address the convergence of HMC for the BPINN method and extend its application scope to multi-scale partial differential equations (PDE), we develop a robust multi-scale BPINN (dubbed MBPINN) method by integrating multi-scale deep neural networks (MscaleDNN) and the BPINN framework. In this newly proposed MBPINN method, we reframe HMC with Stochastic Gradient Descent (SGD) to ensure the most ``likely'' estimation is always provided, and we configure its solver as a Fourier feature mapping-induced MscaleDNN. This novel method offers several key advantages: (1) it is more robust than HMC, (2) it incurs less computational cost than HMC, and (3) it is more flexible for complex problems. We demonstrate the applicability and performance of the proposed method through some general Poisson and multi-scale elliptic problems in one and two-dimensional Euclidean spaces. Our findings indicate that the proposed method can avoid HMC failures and provide valid results. Additionally, our method is capable of handling complex elliptic PDE and producing comparable results for general elliptic PDE under the case of lower signal-to-noise rate. These findings suggest that our proposed approach has great potential for physics-informed machine learning for parameter estimation and solution recovery in the case of ill-posed problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09340v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilong Hou, Xi'an Li, Jinran Wu, You-Gan Wang</dc:creator>
    </item>
  </channel>
</rss>
