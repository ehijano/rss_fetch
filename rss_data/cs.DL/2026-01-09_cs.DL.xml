<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>From Paper to Structured JSON: An Agentic Workflow for Compliant BMR Digital Transformation</title>
      <link>https://arxiv.org/abs/2601.04368</link>
      <description>arXiv:2601.04368v1 Announce Type: new 
Abstract: Pharmaceutical manufacturers generate thousands of batch manufacturing records (BMRs) each year under FDA 21 CFR Part 211 and EU GMP rules. These long documents combine tables, calculations, images, and handwritten notes, and are usually digitized by hand with hours of expert review per record. We present an AI workflow that converts unstructured BMRs into structured JSON using token based chunking, parallel large language model extraction, and a fixed schema that covers 11 content types while preserving the original Group-Phase-Step hierarchy. The system applies three layers of validation (JSON syntax, structural integrity of classes and references, and pharmaceutical compliance checks aligned with GMP) and reports coverage metrics for text, tables, images, and calculations. On three real BMRs between 15 and 66 pages, it achieves composite confidence scores in the low to high eighties while reducing processing time from hours to minutes on a single GPU. This enables practical, human in the loop BMR digitization at scale and unlocks historical manufacturing data for downstream analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04368v1</guid>
      <category>cs.DL</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhavik Agarwal, Nidhi Bendre, Viktoria Rojkova</dc:creator>
    </item>
    <item>
      <title>Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts</title>
      <link>https://arxiv.org/abs/2601.05099</link>
      <description>arXiv:2601.05099v1 Announce Type: new 
Abstract: Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword overlap, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-preserving entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05099v1</guid>
      <category>cs.DL</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JCDL67857.2025.00022</arxiv:DOI>
      <dc:creator>Zhiyin Tan, Changxu Duan</dc:creator>
    </item>
    <item>
      <title>Semantically Orthogonal Framework for Citation Classification: Disentangling Intent and Content</title>
      <link>https://arxiv.org/abs/2601.05103</link>
      <description>arXiv:2601.05103v1 Announce Type: new 
Abstract: Understanding the role of citations is essential for research assessment and citation-aware digital libraries. However, existing citation classification frameworks often conflate citation intent (why a work is cited) with cited content type (what part is cited), limiting their effectiveness in auto classification due to a dilemma between fine-grained type distinctions and practical classification reliability. We introduce SOFT, a Semantically Orthogonal Framework with Two dimensions that explicitly separates citation intent from cited content type, drawing inspiration from semantic role theory. We systematically re-annotate the ACL-ARC dataset using SOFT and release a cross-disciplinary test set sampled from ACT2. Evaluation with both zero-shot and fine-tuned Large Language Models demonstrates that SOFT enables higher agreement between human annotators and LLMs, and supports stronger classification performance and robust cross-domain generalization compared to ACL-ARC and SciCite annotation frameworks. These results confirm SOFT's value as a clear, reusable annotation standard, improving clarity, consistency, and generalizability for digital libraries and scholarly communication infrastructures. All code and data are publicly available on GitHub https://github.com/zhiyintan/SOFT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05103v1</guid>
      <category>cs.DL</category>
      <category>cs.CL</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-05409-8_12</arxiv:DOI>
      <dc:creator>Changxu Duan, Zhiyin Tan</dc:creator>
    </item>
    <item>
      <title>Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2601.05051</link>
      <description>arXiv:2601.05051v1 Announce Type: cross 
Abstract: Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05051v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jennifer D'Souza, Soren Auer, Eleni Poupaki, Alex Watkins, Anjana Devi, Riikka L. Puurunen, Bora Karasulu, Adrie Mackus, Erwin Kessels</dc:creator>
    </item>
    <item>
      <title>SciClaims: An End-to-End Generative System for Biomedical Claim Analysis</title>
      <link>https://arxiv.org/abs/2503.18526</link>
      <description>arXiv:2503.18526v2 Announce Type: replace-cross 
Abstract: We present SciClaims, an interactive web-based system for end-to-end scientific claim analysis in the biomedical domain. Designed for high-stakes use cases such as systematic literature reviews and patent validation, SciClaims extracts claims from text, retrieves relevant evidence from PubMed, and verifies their veracity. The system features a user-friendly interface where users can input scientific text and view extracted claims, predictions, supporting or refuting evidence, and justifications in natural language. Unlike prior approaches, SciClaims seamlessly integrates the entire scientific claim analysis process using a single large language model, without requiring additional fine-tuning. SciClaims is optimized to run efficiently on a single GPU and is publicly available for live interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18526v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.18653/v1/2025.emnlp-demos.11</arxiv:DOI>
      <dc:creator>Ra\'ul Ortega, Jos\'e Manuel G\'omez-P\'erez</dc:creator>
    </item>
  </channel>
</rss>
