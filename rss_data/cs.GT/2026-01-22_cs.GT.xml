<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Jan 2026 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Shapley Value on Uncertain Data</title>
      <link>https://arxiv.org/abs/2601.14543</link>
      <description>arXiv:2601.14543v1 Announce Type: new 
Abstract: The Shapley value provides a principled framework for fairly distributing rewards among participants according to their individual contributions. While prior work has applied this concept to data valuation in machine learning, existing formulations overwhelmingly assume that each participant contributes a fixed, deterministic dataset. In practice, however, data owners often provide samples drawn from underlying probabilistic distributions, introducing stochasticity into their marginal contributions and rendering the Shapley value itself a random variable. This work addresses this gap by proposing a framework for the Shapley value of probabilistic data distributions that quantifies both the expected contribution and the variance of each participant, thereby capturing uncertainty induced by random sampling. We develop theoretical and empirical methodologies for estimating these quantities: on the theoretical side, we derive unbiased estimators for the expectation and variance of the probabilistic Shapley value and analyze their statistical properties; on the empirical side, we introduce three Monte Carlo-based estimation algorithms - a baseline estimator using independent samples, a pooled estimator that improves efficiency through sample reuse, and a stratified pooled estimator that adaptively allocates sampling budget based on player-specific variability. Experiments on synthetic and real datasets demonstrate that these methods achieve strong accuracy-efficiency trade-offs, with the stratified pooled approach attaining substantial variance reduction at minimal additional cost. By extending Shapley value analysis from deterministic datasets to probabilistic data distributions, this work provides both theoretical rigor and practical tools for fair and reliable data valuation in modern stochastic data-sharing environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14543v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuofan Jia, Jian Pei</dc:creator>
    </item>
    <item>
      <title>Interval Scheduling Games</title>
      <link>https://arxiv.org/abs/2601.15148</link>
      <description>arXiv:2601.15148v1 Announce Type: new 
Abstract: We consider a game-theoretic variant of an interval scheduling problem. Every job is associated with a length, a weight, and a color. Each player controls all the jobs of a specific color, and needs to decide on a processing interval for each of its jobs. Jobs of the same color can be processed simultaneously by the machine. A job is covered if the machine is configured to its color during its whole processing interval. The goal of the machine is to maximize the sum of weights of all covered jobs, and the goal of each player is to place its jobs such that the sum of weights of covered jobs from its color is maximized. The study of this game is motivated by several applications like antenna scheduling for wireless networks.
  We first show that given a strategy profile of the players, the machine scheduling problem can be solved in polynomial time. We then study the game from the players' point of view. We analyze the existence of Nash equilibria, its computation, and inefficiency. We distinguish between instances of the classical interval scheduling problem, in which every player controls a single job, and instances in which color sets may include multiple jobs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15148v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vipin Ravindran Vijayalakshmi, Marc Schroder, Tami Tamir</dc:creator>
    </item>
    <item>
      <title>Real-time Facial Communication Restores Cooperation After Defection in Social Dilemmas</title>
      <link>https://arxiv.org/abs/2601.15211</link>
      <description>arXiv:2601.15211v1 Announce Type: new 
Abstract: Facial expressions are central to human interaction, yet their role in strategic decision-making has received limited attention. We investigate how real-time facial communication influences cooperation in repeated social dilemmas. In a laboratory experiment, participants play a repeated Prisoner's Dilemma game under two conditions: in one, they observe their counterpart's facial expressions via gender-neutral avatars, and in the other no facial cues are available. Using state-of-the-art biometric technology to capture and display emotions in real-time, we find that facial communication significantly increases overall cooperation and, notably, promotes cooperation following defection. This restorative effect suggests that facial expressions help participants interpret defections less harshly, fostering forgiveness and the resumption of cooperation. While past actions remain the strongest predictor of behavior, our findings highlight the communicative power of facial expressions in shaping strategic outcomes. These results offer practical insights for designing emotionally responsive virtual agents and digital platforms that sustain cooperation in the absence of physical presence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15211v1</guid>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mayada Oudah, John Wooders</dc:creator>
    </item>
    <item>
      <title>Distributed Agent-Constrained Truthful Facility Location</title>
      <link>https://arxiv.org/abs/2601.15258</link>
      <description>arXiv:2601.15258v1 Announce Type: new 
Abstract: We study a distributed facility location problem in which a set of agents, each with a private position on the real line, is partitioned into a collection of fixed, disjoint groups. The goal is to open $k$ facilities at locations chosen from the set of positions reported by the agents. This decision is made by mechanisms that operate in two phases. In Phase 1, each group selects the position of one of its agents to serve as the group's representative location. In Phase 2, $k$ representatives are chosen as facility locations. Once the facility locations are determined, each agent incurs an individual cost, defined either as the sum of its distances to all facilities (sum-variant) or as the distance to its farthest facility (max-variant). We focus on the class of strategyproof mechanisms, which preclude the agents from benefiting through strategic misreporting, and establish tight bounds on the approximation ratio with respect to the social cost (the total individual agent cost) in both variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15258v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Panagiotis Kanellopoulos, Alexandros A. Voudouris</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Scalable and Robust Paper Assignment</title>
      <link>https://arxiv.org/abs/2601.14402</link>
      <description>arXiv:2601.14402v1 Announce Type: cross 
Abstract: Assigning papers to reviewers is a central challenge in the peer-review process of large academic conferences. Program chairs must balance competing objectives, including maximizing reviewer expertise, promoting diversity, and enhancing robustness to strategic manipulation, but it is challenging to do so at the modern conference scale.
  Existing algorithmic paper assignment approaches either fail to address all of these goals simultaneously or suffer from poor scalability. To address the limitation, we propose Robust Assignment via Marginal Perturbation (RAMP), a unified framework for large-scale peer review. Our approach formulates a linearized perturbed-maximization objective with soft constraints that flexibly balance assignment quality, diversity, and robustness while maintaining runtime efficiency. We further introduce an attribute-aware sampling procedure that converts fractional solutions into integral assignments and improves the diversity and robustness of the final assignment. On datasets with over 20,000 papers and 20,000 reviewers, RAMP runs in under 20 minutes, demonstrating its suitability for real-world deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14402v1</guid>
      <category>cs.SI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Cui, Chenxin Dai, Yixuan Even Xu, Fei Fang</dc:creator>
    </item>
    <item>
      <title>How Wasteful is Signaling?</title>
      <link>https://arxiv.org/abs/2601.14454</link>
      <description>arXiv:2601.14454v1 Announce Type: cross 
Abstract: Signaling is wasteful. But how wasteful? We study the fraction of surplus dissipated in a separating equilibrium. For isoelastic environments, this waste ratio has a simple formula: $\beta/(\beta+\sigma)$, where $\beta$ is the benefit elasticity (reward to higher perception) and $\sigma$ is the elasticity of higher types' relative cost advantage. The ratio is constant across types and independent of other parameters, including convexity of cost in the signal. A constant waste ratio characterizes the isoelastic class. In winner-take-all signaling tournaments with $N$ candidates, exactly $(N-1)/N$ of the surplus dissipates -- the same as in Tullock contests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14454v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Frankel, Navin Kartik</dc:creator>
    </item>
    <item>
      <title>Proximal Policy Optimization with Evolutionary Mutations</title>
      <link>https://arxiv.org/abs/2601.14705</link>
      <description>arXiv:2601.14705v1 Announce Type: cross 
Abstract: Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm known for its stability and sample efficiency, but it often suffers from premature convergence due to limited exploration. In this paper, we propose POEM (Proximal Policy Optimization with Evolutionary Mutations), a novel modification to PPO that introduces an adaptive exploration mechanism inspired by evolutionary algorithms. POEM enhances policy diversity by monitoring the Kullback-Leibler (KL) divergence between the current policy and a moving average of previous policies. When policy changes become minimal, indicating stagnation, POEM triggers an adaptive mutation of policy parameters to promote exploration. We evaluate POEM on four OpenAI Gym environments: CarRacing, MountainCar, BipedalWalker, and LunarLander. Through extensive fine-tuning using Bayesian optimization techniques and statistical testing using Welch's t-test, we find that POEM significantly outperforms PPO on three of the four tasks (BipedalWalker: t=-2.0642, p=0.0495; CarRacing: t=-6.3987, p=0.0002; MountainCar: t=-6.2431, p&lt;0.0001), while performance on LunarLander is not statistically significant (t=-1.8707, p=0.0778). Our results highlight the potential of integrating evolutionary principles into policy gradient methods to overcome exploration-exploitation tradeoffs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14705v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Casimir Czworkowski, Stephen Hornish, Alhassan S. Yasin</dc:creator>
    </item>
    <item>
      <title>Game-Theoretic Lens on LLM-based Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2601.15047</link>
      <description>arXiv:2601.15047v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated strong reasoning, planning, and communication abilities, enabling them to operate as autonomous agents in open environments. While single-agent systems remain limited in adaptability and coordination, recent progress has shifted attention toward multi-agent systems (MAS) composed of interacting LLMs that pursue cooperative, competitive, or mixed objectives. This emerging paradigm provides a powerful testbed for studying social dynamics and strategic behaviors among intelligent agents. However, current research remains fragmented and lacks a unifying theoretical foundation. To address this gap, we present a comprehensive survey of LLM-based multi-agent systems through a game-theoretic lens. By organizing existing studies around the four key elements of game theory: players, strategies, payoffs, and information, we establish a systematic framework for understanding, comparing, and guiding future research on the design and analysis of LLM-based MAS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15047v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianing Hao, Han Ding, Yuanjian Xu, Tianze Sun, Ran Chen, Wanbo Zhang, Guang Zhang, Siguang Li</dc:creator>
    </item>
    <item>
      <title>Incentive-Tuning: Understanding and Designing Incentives for Empirical Human-AI Decision-Making Studies</title>
      <link>https://arxiv.org/abs/2601.15064</link>
      <description>arXiv:2601.15064v1 Announce Type: cross 
Abstract: AI has revolutionised decision-making across various fields. Yet human judgement remains paramount for high-stakes decision-making. This has fueled explorations of collaborative decision-making between humans and AI systems, aiming to leverage the strengths of both. To explore this dynamic, researchers conduct empirical studies, investigating how humans use AI assistance for decision-making and how this collaboration impacts results. A critical aspect of conducting these studies is the role of participants, often recruited through crowdsourcing platforms. The validity of these studies hinges on the behaviours of the participants, hence effective incentives that can potentially affect these behaviours are a key part of designing and executing these studies. In this work, we aim to address the critical role of incentive design for conducting empirical human-AI decision-making studies, focusing on understanding, designing, and documenting incentive schemes. Through a thematic review of existing research, we explored the current practices, challenges, and opportunities associated with incentive design for human-AI decision-making empirical studies. We identified recurring patterns, or themes, such as what comprises the components of an incentive scheme, how incentive schemes are manipulated by researchers, and the impact they can have on research outcomes. Leveraging the acquired understanding, we curated a set of guidelines to aid researchers in designing effective incentive schemes for their studies, called the Incentive-Tuning Framework, outlining how researchers can undertake, reflect on, and document the incentive design process. By advocating for a standardised yet flexible approach to incentive design and contributing valuable insights along with practical tools, we hope to pave the way for more reliable and generalizable knowledge in the field of human-AI decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15064v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simran Kaur, Sara Salimzadeh, Ujwal Gadiraju</dc:creator>
    </item>
    <item>
      <title>Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism</title>
      <link>https://arxiv.org/abs/2601.15249</link>
      <description>arXiv:2601.15249v1 Announce Type: cross 
Abstract: Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15249v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>stat.ME</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Garrett G. Wen, Buxin Su, Natalie Collina, Zhun Deng, Weijie Su</dc:creator>
    </item>
    <item>
      <title>Last-iterate Convergence for Symmetric, General-sum, $2 \times 2$ Games Under The Exponential Weights Dynamic</title>
      <link>https://arxiv.org/abs/2502.08063</link>
      <description>arXiv:2502.08063v3 Announce Type: replace 
Abstract: We conduct a comprehensive analysis of the discrete-time exponential-weights dynamic with a constant step size on all general-sum and symmetric $2 \times 2$ normal-form games, i.e. games with $2$ pure strategies per player, and where the ensuing payoff tuple is of the form $(A,A^\top)$ (where $A$ is the $2 \times 2$ payoff matrix corresponding to the first player). Such symmetric games commonly arise in real-world interactions between 'symmetric" agents who have identically defined utility functions -- such as Bertrand competition and multi-agent performative prediction, and display a rich multiplicity of equilibria despite the seemingly simple setting. Somewhat surprisingly, we show through a first-principles analysis that the exponential weights dynamic, which is popular in online learning, converges in the last iterate for such games regardless of initialization with an appropriately chosen step size. For certain games and/or initializations, we further show that the convergence rate is in fact exponential and holds for any step size.
  We illustrate our theory with extensive simulations and applications to the aforementioned game-theoretic interactions. In the case of multi-agent performative prediction, we formulate a new "mortgage competition" game between lenders (i.e. banks) who interact with a population of customers, and show that it fits into our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08063v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanghui Wang, Krishna Acharya, Lokranjan Lakshmikanthan, Juba Ziani, Vidya Muthukumar</dc:creator>
    </item>
    <item>
      <title>Sequential Causal Normal Form Games: Theory, Computation, and Strategic Signaling</title>
      <link>https://arxiv.org/abs/2511.06934</link>
      <description>arXiv:2511.06934v2 Announce Type: replace 
Abstract: Can classical game-theoretic frameworks be extended to capture the bounded rationality and causal reasoning of AI agents? We investigate this question by extending Causal Normal Form Games (CNFGs) to sequential settings, introducing Sequential Causal Multi-Agent Systems (S-CMAS) that incorporate Pearl's Causal Hierarchy across leader-follower interactions. While theoretically elegant -- we prove PSPACE-completeness, develop equilibrium refinements, and establish connections to signaling theory -- our comprehensive empirical investigation reveals a critical limitation: S-CNE provides zero welfare improvement over classical Stackelberg equilibrium across all tested scenarios. Through 50+ Monte Carlo simulations and hand-crafted synthetic examples, we demonstrate that backward induction with rational best-response eliminates any strategic advantage from causal layer distinctions. We construct a theoretical example illustrating conditions where benefits could emerge ($\epsilon$-rational satisficing followers), though implementation confirms that even relaxed rationality assumptions prove insufficient when good instincts align with optimal play. This negative result provides valuable insight: classical game-theoretic extensions grounded in rational choice are fundamentally incompatible with causal reasoning advantages, motivating new theoretical frameworks beyond standard Nash equilibrium for agentic AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06934v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>stat.OT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Thumm</dc:creator>
    </item>
    <item>
      <title>Polynomial-Time Algorithms for Computing the Nucleolus: An Assessment</title>
      <link>https://arxiv.org/abs/2511.16517</link>
      <description>arXiv:2511.16517v2 Announce Type: replace 
Abstract: Recently, Maggiorano et al. (2025) claimed that they have developed a strongly polynomial-time combinatorial algorithm for the nucleolus in convex games that is based on the reduced game approach and submodular function minimization method. Thereby, avoiding the ellipsoid method with its negative side effects in numerical computation completely. However, we shall argue that this is a fallacy based on an incorrect application of the Davis/Maschler reduced game property (RGP). Ignoring the fact that despite the pre-nucleolus, other solutions like the core, pre-kernel, and semi-reactive pre-bargaining set possess this property as well. This causes a severe selection issue, leading to the failure to compute the nucleolus of convex games using the reduced games approach. In order to assess this finding in its context, the ellipsoid method of Faigle et al. (2001) and the Fenchel-Moreau conjugation-based approach from convex analysis of Meinhardt (2013) to compute a pre-kernel element were resumed. In the latter case, it was exploited that for TU games with a single-valued pre-kernel, both solution concepts coincide. Implying that one has computed the pre-nucleolus if one has found the sole pre-kernel element of the game. Though it is a specialized and highly optimized algorithm for the pre-kernel, it assures runtime complexity of O(n^3) for computing the pre-nucleolus whenever the pre-kernel is a single point, which indicates a polynomial-time algorithm for this class of games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16517v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Holger I. Meinhardt</dc:creator>
    </item>
    <item>
      <title>Betting on Equilibrium: Monitoring Strategic Behavior in Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2601.05427</link>
      <description>arXiv:2601.05427v2 Announce Type: replace 
Abstract: In many multi-agent systems, agents interact repeatedly and are expected to settle into equilibrium behavior over time. Yet in practice, behavior often drifts, and detecting such deviations in real time remains an open challenge. We introduce a sequential testing framework that monitors whether observed play in repeated games is consistent with equilibrium, without assuming a fixed sample size. Our approach builds on the e-value framework for safe anytime-valid inference: by "betting" against equilibrium, we construct a test supermartingale that accumulates evidence whenever observed payoffs systematically violate equilibrium conditions. This yields a statistically sound, interpretable measure of departure from equilibrium that can be monitored online. We also leverage Benjamini-Hochberg-type procedures to increase detection power in large games while rigorously controlling the false discovery rate. Our framework unifies the treatment of Nash, correlated, and coarse correlated equilibria, offering finite-time guarantees and a detailed analysis of detection times. Moreover, we extend our method to stochastic games, broadening its applicability beyond repeated-play settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05427v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Etienne Gauthier, Francis Bach, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>BallotRank: A Condorcet Completion Method for Graphs</title>
      <link>https://arxiv.org/abs/2601.14015</link>
      <description>arXiv:2601.14015v2 Announce Type: replace 
Abstract: We introduce BallotRank, a ranked preference aggregation method derived from a modified PageRank algorithm. It is a Condorcet-consistent method without damping, and empirical examination of nearly 2,000 ranked choice elections and over 20,000 internet polls confirms that BallotRank always identifies the Condorcet winner at conventional values of the damping parameter. We also prove that the method satisfies many of the same social choice criteria as other well-known Condorcet completion methods, but it has the advantage of being a natural social welfare function that provides a full ranking of the candidates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14015v2</guid>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Douglas Todd, Ismar Volic</dc:creator>
    </item>
    <item>
      <title>Competition between service providers with strategic resource allocation: application to network slicing</title>
      <link>https://arxiv.org/abs/1912.04764</link>
      <description>arXiv:1912.04764v2 Announce Type: replace-cross 
Abstract: We propose and analyze a business model for 5G operators. Each operator is entitled to a share of a network operated by an Infrastructure Provider (InP) and use network slicing mechanisms to request network resources as needed for service provision. The network operators become Network Slice Tenants (NSTs). The InP performs the resource allocation based on a vector of weights chosen strategically by each NST. The weights distribute the NST's share of resources between its subscribers in each cell. We propose a strategy profile in which the NST chooses weights equal to the product of its share by the ratio between the total number of subscribers in the cell and the total number of subscribers in the network. We characterize the proposed solution in terms of subscription ratios and fractions of subscribers, for different cell capacities and user sensitivities. The proposed solution provides the exact values for the Nash equilibrium if the cells are homogeneous in terms of normalized capacity, which is a measure of the total amount of resources available in the cell. Otherwise, if the cells are heterogeneous, it provides an accurate approximation. We quantify the deviation from the equilibrium and conclude that it is highly accurate.</description>
      <guid isPermaLink="false">oai:arXiv.org:1912.04764v2</guid>
      <category>cs.NI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2021.3078562</arxiv:DOI>
      <dc:creator>Luis Guijarro, Jose R. Vidal, Vicent Pla</dc:creator>
    </item>
    <item>
      <title>Opinion Dynamics with Multiple Adversaries</title>
      <link>https://arxiv.org/abs/2502.15931</link>
      <description>arXiv:2502.15931v2 Announce Type: replace-cross 
Abstract: Opinion dynamics models how the publicly expressed opinions of users in a social network coevolve according to their neighbors as well as their own intrinsic opinion. Motivated by the real-world manipulation of social networks during the 2016 US elections and the 2019 Hong Kong protests, a growing body of work models the effects of a strategic actor who interferes with the network to induce disagreement or polarization. We lift the assumption of a single strategic actor by introducing a model in which any subset of network users can manipulate network outcomes. They do so by acting according to a fictitious intrinsic opinion. Strategic actors can have conflicting goals, and push competing narratives. We characterize the Nash Equilibrium of the resulting meta-game played by the strategic actors. Experiments on real-world social network datasets from Twitter, Reddit, and Political Blogs show that strategic agents can significantly increase polarization and disagreement, as well as increase the "cost" of the equilibrium. To this end, we give worst-case upper bounds on the Price of Misreporting (analogous to the Price of Anarchy). Finally, we give efficient learning algorithms for the platform to (i) detect whether strategic manipulation has occurred, and (ii) learn who the strategic actors are. Our algorithms are accurate on the same real-world datasets, suggesting how platforms can take steps to mitigate the effects of strategic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15931v2</guid>
      <category>cs.SI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3774904.3792080</arxiv:DOI>
      <dc:creator>Akhil Jalan, Marios Papachristou</dc:creator>
    </item>
    <item>
      <title>Tie-breaking in self interest cumulative subtraction games</title>
      <link>https://arxiv.org/abs/2510.24280</link>
      <description>arXiv:2510.24280v2 Announce Type: replace-cross 
Abstract: Subtraction games have a rich literature as normal-play combinatorial games (e.g., Berlekamp, Conway, and Guy, 1982). Recently, the theory has been extended to zero-sum scoring play (Cohensius et al. 2019). Here, we take the approach of cumulative self-interest games, as introduced in a recent framework preprint by Larsson, Meir, and Zick. By adapting standard Pure Subgame Perfect Equilibria (PSPE) from classical game theory, players must declare and commit to acting either ``friendly'' or ``antagonistic'' in case of indifference. Whenever the subtraction set has size two, we establish a tie-breaking rule monotonicity: a friendly player can never benefit by a deterministic deviation to antagonistic play. This type of terminology is new to both ``economic'' and ``combinatorial'' games, but it becomes essential in the self-interest cumulative setting. The main result is an immediate consequence of the tie-breaking rule's monotonicity; in the case of two-action subtraction sets, two antagonistic players are never better off than two friendly players, i.e., their PSPE utilities are never greater. For larger subtraction sets, we conjecture that the main result continues to hold, while tie-breaking monotonicity may fail, and we provide empirical evidence in support of both statements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24280v2</guid>
      <category>math.CO</category>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anjali Bhagat, Tanmay Kulkarni, Urban Larsson, Divya Murali</dc:creator>
    </item>
    <item>
      <title>Robust Verification of Concurrent Stochastic Games</title>
      <link>https://arxiv.org/abs/2601.12003</link>
      <description>arXiv:2601.12003v2 Announce Type: replace-cross 
Abstract: Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified - an unrealistic requirement in many real-world settings. We introduce *robust CSGs* and their subclass *interval CSGs* (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for *robust* verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12003v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angel Y. He, David Parker</dc:creator>
    </item>
  </channel>
</rss>
