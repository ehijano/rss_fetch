<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 04:02:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Residual Diffusion Models for Variable-Rate Joint Source Channel Coding of MIMO CSI</title>
      <link>https://arxiv.org/abs/2505.21681</link>
      <description>arXiv:2505.21681v1 Announce Type: new 
Abstract: Despite significant advancements in deep learning-based CSI compression, some key limitations remain unaddressed. Current approaches predominantly treat CSI compression as a source coding problem, neglecting transmission errors. In finite block length regimes, separate source and channel coding proves suboptimal, with reconstruction performance deteriorating significantly under challenging channel conditions. While existing autoencoder-based compression schemes can be readily extended to support joint source-channel coding, they struggle to capture complex channel distributions and exhibit poor scalability with increasing parameter count. To overcome these inherent limitations of autoencoder-based approaches, we propose Residual-Diffusion Joint Source-Channel Coding (RD-JSCC), a novel framework that integrates a lightweight autoencoder with a residual diffusion module to iteratively refine CSI reconstruction. Our flexible decoding strategy balances computational efficiency and performance by dynamically switching between low-complexity autoencoder decoding and sophisticated diffusion-based refinement based on channel conditions. Comprehensive simulations demonstrate that RD-JSCC significantly outperforms existing autoencoder-based approaches in challenging wireless environments. Furthermore, RD-JSCC offers several practical features, including a low-latency 2-step diffusion during inference, support for multiple compression rates with a single model, robustness to fixed-bit quantization, and adaptability to imperfect channel estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21681v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sravan Kumar Ankireddy, Heasung Kim, Hyeji Kim</dc:creator>
    </item>
    <item>
      <title>Ambient-aware continuous aid for mountain rescue activities</title>
      <link>https://arxiv.org/abs/2505.21751</link>
      <description>arXiv:2505.21751v1 Announce Type: new 
Abstract: Ambient-awareness in conjunction with pervasive computing is a significant challenge for system designers. It follows the necessity of gathering raw, massive and heterogeneous environmental data \newrrr{which we} obtained, while middleware processes must merge context modelling and reasoning seamlessly. We proposed a system supporting mountain rescuers which is demanding due to the large number of environmental objects interacting, as well as high data variability. We presented complex context processing embedded in the proposed context life cycle and implemented it \erarrr{following a proposed workflow for a demanding}\newrrr{in a difficult} mountain environment. We introduced five weather scenarios which are a basis for contextual and perceptual processing during the validation of our model. The system \erarrr{binds together} \newrrr{merges} a message streaming broker for massive data transport, low and high-level processing algorithms, repositories and a logical SAT solver. It constitutes a Context-Aware-as-a-Service (CAaaS) system, offering advanced support for mountain rescue operations. The provided software model defines middleware components which act on a predicted context and transform in situ sensor data into smart decisions, and which could operate as a platform-based cloud computing model. It is an enabler yielding a synergy effect with different software components orchestration when providing pro-activeness and non-intrusiveness concerning smart decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21751v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ins.2023.119772</arxiv:DOI>
      <dc:creator>Radoslaw Klimek</dc:creator>
    </item>
    <item>
      <title>When Feedback Empowers the Uplink: Integrating Adaptive Coding with Wireless Power Transfer</title>
      <link>https://arxiv.org/abs/2505.21951</link>
      <description>arXiv:2505.21951v1 Announce Type: new 
Abstract: Energy consumption and device lifetime are critical concerns for battery-constrained IoT devices. This paper introduces the Feedback-Aided Coding and Energy Transfer (FACET) framework, which synergistically combines adaptive feedback channel coding with wireless power transfer. FACET leverages the saturation effect of feedback coding, where increasing downlink power yields diminishing returns, to design a dual-purpose feedback mechanism that simultaneously guides uplink coding and replenishes device energy. We characterize the inherent tradeoff between feedback precision and harvested power, and formulate a fairness-constrained min-max optimization problem to minimize worst-case net energy consumption. An efficient algorithm based on alternating optimization and Lagrangian duality is developed, with each subproblem admitting a closed-form solution. Simulations show that FACET nearly triples device lifetime compared to conventional feedback coding architectures, and remains robust across a wide range of power regimes. These results suggest that FACET not only improves communication efficiency but also redefines the role of feedback in energy-constrained IoT systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21951v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Yang, Yulin Shao, Shaodan Ma</dc:creator>
    </item>
    <item>
      <title>The Tri-Hybrid MIMO Architecture</title>
      <link>https://arxiv.org/abs/2505.21971</link>
      <description>arXiv:2505.21971v1 Announce Type: new 
Abstract: We present an evolution of multiple-input multiple-output (MIMO) wireless communications known as the tri-hybrid MIMO architecture. In this framework, the traditional operations of linear precoding at the transmitter are distributed across digital beamforming, analog beamforming, and reconfigurable antennas. Compared with the hybrid MIMO architecture, which combines digital and analog beamforming, the tri-hybrid approach introduces a third layer of electromagnetic beamforming through antenna reconfigurability. This added layer offers a pathway to scale MIMO spatial dimensions, important for 6G systems operating in centimeter-wave bands, where the tension between larger bandwidths and infrastructure reuse necessitates ultra-large antenna arrays. We introduce the key features of the tri-hybrid architecture by (i)~reviewing the benefits and challenges of communicating with reconfigurable antennas, (ii)~examining tradeoffs between spectral and energy efficiency enabled by reconfigurability, and (iii)~exploring configuration challenges across the three layers. Overall, the tri-hybrid MIMO architecture offers a new approach for integrating emerging antenna technologies in the MIMO precoding framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21971v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert W. Heath, Jr., Joseph Carlson, Nitish Vikas Deshpande, Miguel Rodrigo Castellanos, Mohamed Akrout, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Wireless Communication for Low-Altitude Economy with UAV Swarm Enabled Two-Level Movable Antenna System</title>
      <link>https://arxiv.org/abs/2505.22286</link>
      <description>arXiv:2505.22286v1 Announce Type: new 
Abstract: Unmanned aerial vehicle (UAV) is regarded as a key enabling platform for low-altitude economy, due to its advantages such as 3D maneuverability, flexible deployment, and LoS air-to-air/ground communication links. In particular, the intrinsic high mobility renders UAV especially suitable for operating as a movable antenna (MA) from the sky. In this paper, by exploiting the flexible mobility of UAV swarm and antenna position adjustment of MA, we propose a novel UAV swarm enabled two-level MA system, where UAVs not only individually deploy a local MA array, but also form a larger-scale MA system with their individual MA arrays via swarm coordination. We formulate a general optimization problem to maximize the minimum achievable rate over all ground UEs, by jointly optimizing the 3D UAV swarm placement positions, their individual MAs' positions, and receive beamforming for different UEs. We first consider the special case where each UAV has only one antenna, under different scenarios of one single UE, two UEs, and arbitrary number of UEs. In particular, for the two-UE case, we derive the optimal UAV swarm placement positions in closed-form that achieves IUI-free communication, where the UAV swarm forms a uniform sparse array (USA) satisfying collision avoidance constraint. While for the general case with arbitrary number of UEs, we propose an efficient alternating optimization algorithm to solve the formulated non-convex optimization problem. Then, we extend the results to the case where each UAV is equipped with multiple antennas. Numerical results verify that the proposed low-altitude UAV swarm enabled MA system significantly outperforms various benchmark schemes, thanks to the exploitation of two-level mobility to create more favorable channel conditions for multi-UE communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22286v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiquan Lu, Yong Zeng, Shaodan Ma, Bin Li, Shi Jin, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Synonymous Variational Inference for Perceptual Image Compression</title>
      <link>https://arxiv.org/abs/2505.22438</link>
      <description>arXiv:2505.22438v1 Announce Type: new 
Abstract: Recent contributions of semantic information theory reveal the set-element relationship between semantic and syntactic information, represented as synonymous relationships. In this paper, we propose a synonymous variational inference (SVI) method based on this synonymity viewpoint to re-analyze the perceptual image compression problem. It takes perceptual similarity as a typical synonymous criterion to build an ideal synonymous set (Synset), and approximate the posterior of its latent synonymous representation with a parametric density by minimizing a partial semantic KL divergence. This analysis theoretically proves that the optimization direction of perception image compression follows a triple tradeoff that can cover the existing rate-distortion-perception schemes. Additionally, we introduce synonymous image compression (SIC), a new image compression scheme that corresponds to the analytical process of SVI, and implement a progressive SIC codec to fully leverage the model's capabilities. Experimental results demonstrate comparable rate-distortion-perception performance using a single progressive SIC codec, thus verifying the effectiveness of our proposed analysis method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22438v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liang, Kai Niu, Changshuo Wang, Jin Xu, Ping Zhang</dc:creator>
    </item>
    <item>
      <title>How Soft Skills Shape First-Year Success in Higher Education</title>
      <link>https://arxiv.org/abs/2505.21696</link>
      <description>arXiv:2505.21696v1 Announce Type: cross 
Abstract: Soft skills are critical for academic and professional success, but are often neglected in early-stage technical curricula. This paper presents a semi-isolated teaching intervention aimed at fostering study ability and key soft skills-communication, collaboration, and project management-among first-year computer science students. The elective seminar Soft Skills and Tools for Studies and Career in IT was alongside a mandatory team-based programming course. We analyze project outcomes and student experiences across three cohorts across three groups: students who attended the seminar, students who teamed up with a seminar attendee, and students with no exposure to the seminar.
  Results show that seminar participants performed significantly better in individual presentations and team projects. Qualitative feedback further indicates improved team dynamics and study preparedness. Although self-assessed collaboration and communication did not reach statistical significance, consistent trends suggest that early soft skills training enhances academic integration. We recommend embedding such interventions early in technical study programs to support the transition into university life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21696v1</guid>
      <category>cs.CY</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerstin Andree, Santiago Berrezueta-Guzman, Stephan Krusche, Luise Pufahl, Stefan Wagner</dc:creator>
    </item>
    <item>
      <title>A Provable Approach for End-to-End Safe Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.21852</link>
      <description>arXiv:2505.21852v1 Announce Type: cross 
Abstract: A longstanding goal in safe reinforcement learning (RL) is a method to ensure the safety of a policy throughout the entire process, from learning to operation. However, existing safe RL paradigms inherently struggle to achieve this objective. We propose a method, called Provably Lifetime Safe RL (PLS), that integrates offline safe RL with safe policy deployment to address this challenge. Our proposed method learns a policy offline using return-conditioned supervised learning and then deploys the resulting policy while cautiously optimizing a limited set of parameters, known as target returns, using Gaussian processes (GPs). Theoretically, we justify the use of GPs by analyzing the mathematical relationship between target and actual returns. We then prove that PLS finds near-optimal target returns while guaranteeing safety with high probability. Empirically, we demonstrate that PLS outperforms baselines both in safety and reward performance, thereby achieving the longstanding goal to obtain high rewards while ensuring the safety of a policy throughout the lifetime from learning to operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21852v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.RO</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akifumi Wachi, Kohei Miyaguchi, Takumi Tanabe, Rei Sato, Youhei Akimoto</dc:creator>
    </item>
    <item>
      <title>Interpolation of Quantum Polar Codes and Quantum Reed-Muller Codes</title>
      <link>https://arxiv.org/abs/2505.22142</link>
      <description>arXiv:2505.22142v1 Announce Type: cross 
Abstract: Good quantum error-correcting codes that fulfill practical considerations, such as simple encoding circuits and efficient decoders, are essential for functional quantum information processing systems. Quantum polar codes satisfy some of these requirements but lack certain critical features, thereby hindering their widespread use. Existing constructions either require entanglement assistance to produce valid quantum codes, suffer from poor finite-size performance, or fail to tailor polar codes to the underlying channel properties. Meanwhile, quantum Reed-Muller (RM) codes demonstrate strong performance, though no known efficient decoding algorithm exists for them. In this work, we propose strategies to interpolate between quantum polar codes and quantum RM codes, thus addressing the challenges of designing valid quantum polar codes without entanglement assistance and improving finite-size code performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22142v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Hidaka, Dina Abdelhadi, Ruediger Urbanke</dc:creator>
    </item>
    <item>
      <title>Attention-Enhanced Prompt Decision Transformers for UAV-Assisted Communications with AoI</title>
      <link>https://arxiv.org/abs/2505.22170</link>
      <description>arXiv:2505.22170v1 Announce Type: cross 
Abstract: Decision Transformer (DT) has recently demonstrated strong generalizability in dynamic resource allocation within unmanned aerial vehicle (UAV) networks, compared to conventional deep reinforcement learning (DRL). However, its performance is hindered due to zero-padding for varying state dimensions, inability to manage long-term energy constraint, and challenges in acquiring expert samples for few-shot fine-tuning in new scenarios. To overcome these limitations, we propose an attention-enhanced prompt Decision Transformer (APDT) framework to optimize trajectory planning and user scheduling, aiming to minimize the average age of information (AoI) under long-term energy constraint in UAV-assisted Internet of Things (IoT) networks. Specifically, we enhance the convenional DT framework by incorporating an attention mechanism to accommodate varying numbers of terrestrial users, introducing a prompt mechanism based on short trajectory demonstrations for rapid adaptation to new scenarios, and designing a token-assisted method to address the UAV's long-term energy constraint. The APDT framework is first pre-trained on offline datasets and then efficiently generalized to new scenarios. Simulations demonstrate that APDT achieves twice faster in terms of convergence rate and reduces average AoI by $8\%$ compared to conventional DT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22170v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi Lu, Yiyang Ni, Zhe Wang, Xiaoli Shi, Jun Li, Shi Jin</dc:creator>
    </item>
    <item>
      <title>The Ingleton inequality holds for metacyclic groups and fails for supersoluble groups</title>
      <link>https://arxiv.org/abs/2505.22565</link>
      <description>arXiv:2505.22565v1 Announce Type: cross 
Abstract: The Ingleton inequality first appeared in matroid theory, where Ingleton proved in 1971 that every rank function coming from a representable matroid on four subsets satisfies a particular inequality. Because this inequality is not implied by submodularity, Shannon-type axioms alone, it and various analogues play a central role in separately linear and non-linear phenomena in a variety of areas of mathematics. The Ingleton inequality for finite groups concerns the various intersections of four subgroups. It holds for many quadruples of subgroups of finite groups, but not all, the smallest example being four subgroups of $S_5$, of order 120. Open questions are whether the Inlgeton inequality always holds for metacycle and nilpotent groups. (There is a proof in the literature due to Oggier and Stancu, but there is an already known issue with their proof, which we address in this article.)
  In this paper we prove that the Ingleton inequality always holds for metacycle groups, but that it fails for supersoluble groups, a class of groups only a little larger than nilpotent groups. Although we do not resolve the nilpotent case here we do make some reductions, and also prove that there are no nilpotent violators of the Ingleton inequality of order less than 1024. We end with a list of Ingleton inequality violating groups of order at most 1023.
  The article comes with a Magma package that allows reproduction of all results in the paper and for the reader to check the Ingleton inequality for any given finite group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22565v1</guid>
      <category>math.GR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David A. Craven</dc:creator>
    </item>
    <item>
      <title>Edge-Spreading Raptor-Like LDPC Codes for 6G Wireless Systems</title>
      <link>https://arxiv.org/abs/2410.16875</link>
      <description>arXiv:2410.16875v2 Announce Type: replace 
Abstract: Next-generation channel coding has stringent demands on throughput, energy consumption, and error rate performance while maintaining key features of 5G New Radio (NR) standard codes such as rate compatibility, which is a significant challenge. Due to excellent capacity-achieving performance, spatially-coupled low-density parity-check (SC-LDPC) codes are considered a promising candidate for next-generation channel coding. In this paper, we propose an SC-LDPC code family called edge-spreading Raptor-like (ESRL) codes. Unlike other SC-LDPC codes that adopt the structure of existing rate-compatible LDPC block codes before coupling, ESRL codes maximize the possible locations of edge placement and focus on constructing an optimal coupled matrix. Moreover, a new graph representation called the unified graph is introduced. This graph offers a global perspective on ESRL codes and identifies the optimal edge reallocation to optimize the spreading strategy. We conduct comprehensive comparisons of ESRL codes and 5G-NR LDPC codes. Simulation results demonstrate that when all decoding parameters and complexity are the same, ESRL codes have obvious advantages in error rate performance and throughput compared to 5G-NR LDPC codes in some specific scenarios (low and high number of iterations), making them a promising solution towards next-generation channel coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16875v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Ren, Leyu Zhang, Yifei Shen, Wenqing Song, Emmanuel Boutillon, Alexios Balatsoukas-Stimming, Andreas Burg</dc:creator>
    </item>
    <item>
      <title>Bivariate Linear Operator Codes</title>
      <link>https://arxiv.org/abs/2411.16596</link>
      <description>arXiv:2411.16596v2 Announce Type: replace 
Abstract: In this work, we present a generalization of the linear operator family of codes that captures more codes that achieve list decoding capacity. Linear operator (LO) codes were introduced by Bhandari, Harsha, Kumar, and Sudan [BHKS24] as a way to capture capacity-achieving codes. In their framework, a code is specified by a collection of linear operators that are applied to a message polynomial and then evaluated at a specified set of evaluation points. We generalize this idea in a way that can be applied to bivariate message polynomials, getting what we call bivariate linear operator (B-LO) codes.
  We show that bivariate linear operator codes capture more capacity-achieving codes, including permuted product codes introduced by Berman, Shany, and Tamo [BST24]. These codes work with bivariate message polynomials, which is why our generalization is necessary to capture them as a part of the linear operator framework.
  Similarly to the initial paper on linear operator codes, we present sufficient conditions for a bivariate linear operator code to be list decodable. Using this characterization, we are able to derive the theorem characterizing list-decodability of LO codes as a specific case of our theorem for B-LO codes. We also apply this theorem to show that permuted product codes are list decodable up to capacity, thereby unifying this result with those of known list-decodable LO codes, including Folded Reed-Solomon, Multiplicity, and Affine Folded Reed-Solomon codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16596v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aaron L. Putterman, Vadim Zaripov</dc:creator>
    </item>
    <item>
      <title>Analog Computing for Signal Processing and Communications -- Part I: Computing with Microwave Networks</title>
      <link>https://arxiv.org/abs/2504.06790</link>
      <description>arXiv:2504.06790v2 Announce Type: replace 
Abstract: Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this two-part paper, we explore analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing and communications. In Part I of this paper, we model a MiLAC as a multiport microwave network with tunable impedance components, enabling the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator and matrix inversion, with remarkably low computational complexity. Specifically, a matrix can be inverted with complexity growing with the square of its size. We also show how a MiLAC can be used jointly with digital operations to implement sophisticated algorithms such as the Kalman filter. To enhance practicability, we propose a design of MiLAC based on lossless impedance components, reducing power consumption and eliminating the need for costly active components. In Part II of this paper, we investigate the applications of MiLACs in wireless communications, highlighting their potential to enable future wireless systems by executing computations and beamforming in the analog domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06790v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Analog Computing for Signal Processing and Communications -- Part II: Toward Gigantic MIMO Beamforming</title>
      <link>https://arxiv.org/abs/2504.07477</link>
      <description>arXiv:2504.07477v2 Announce Type: replace 
Abstract: Analog-domain operations offer a promising solution to accelerating signal processing and enabling future multiple-input multiple-output (MIMO) communications with thousands of antennas. In Part I of this paper, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In Part II of this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic MIMO beamforming entirely in the analog domain. MiLAC-aided beamforming enables the maximum flexibility and performance of digital beamforming, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of zero-forcing (ZF), which scales quadratically with the number of antennas instead of cubically. It also processes signals with fixed matrices, e.g., the discrete Fourier transform (DFT), directly in the analog domain. Numerical results show that it can perform ZF and DFT with a computational complexity reduction of up to $1.5\times 10^4$ and $4.0\times 10^7$ times, respectively, compared to digital beamforming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07477v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Rotatable Antenna Enabled Wireless Communication and Sensing: Opportunities and Challenges</title>
      <link>https://arxiv.org/abs/2505.16828</link>
      <description>arXiv:2505.16828v2 Announce Type: replace 
Abstract: Non-fixed flexible antenna architectures, such as fluid antenna system (FAS), movable antenna (MA), and pinching antenna, have garnered significant interest in recent years. Among them, rotatable antenna (RA) is an emerging technology that offers significant potential to enhance wireless communication and sensing performance by flexibly adjusting the boresight of directional antennas. Specifically, RA can flexibly reconfigure its boresight direction via mechanical or electronic means, thereby improving communication channel conditions and/or enhancing sensing resolution and range. In this article, we first provide an overview of RA, including its promising applications, hardware architectures, and radiation pattern characterization. We then illustrate how RA improves communication performance through interference mitigation, spatial multiplexing, and flexible beamforming, as well as sensing capabilities in terms of coverage, resolution, and multi-target/dimensional sensing. Furthermore, we discuss key design challenges in RA systems, including rotational scanning scheduling, channel estimation/sensing, boresight optimization, and RA configuration. Finally, both experimental and simulation results are provided to validate the performance gains achieved by RA for both communication and sensing. Leveraging its unique capabilities in flexible antenna/array rotation to adapt to various communication/sensing requirements and channel conditions, RA is poised to become a key enabler of future intelligent, resilient, and agile wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16828v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beixiong Zheng, Tiantian Ma, Changsheng You, Jie Tang, Robert Schober, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Decoupled Subgraph Federated Learning</title>
      <link>https://arxiv.org/abs/2402.19163</link>
      <description>arXiv:2402.19163v3 Announce Type: replace-cross 
Abstract: We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where interconnections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19163v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Learning Representations (ICLR), 2025</arxiv:journal_reference>
      <dc:creator>Javad Aliakbari, Johan \"Ostman, Alexandre Graell i Amat</dc:creator>
    </item>
    <item>
      <title>How Breakable Is Privacy: Probing and Resisting Model Inversion Attacks in Collaborative Inference</title>
      <link>https://arxiv.org/abs/2501.00824</link>
      <description>arXiv:2501.00824v5 Announce Type: replace-cross 
Abstract: Collaborative inference (CI) improves computational efficiency for edge devices by transmitting intermediate features to cloud models. However, this process inevitably exposes feature representations to model inversion attacks (MIAs), enabling unauthorized data reconstruction. Despite extensive research, there is no established criterion for assessing the difficulty of MIA implementation, leaving a fundamental question unanswered: \textit{What factors truly and verifiably determine the attack's success in CI?} Moreover, existing defenses lack the theoretical foundation described above, making it challenging to regulate feature information effectively while ensuring privacy and minimizing computational overhead. These shortcomings introduce three key challenges: theoretical gap, methodological limitation, and practical constraint.
  To overcome these challenges, we propose the first theoretical criterion to assess MIA difficulty in CI, identifying mutual information, entropy, and effective information volume as key influencing factors. The validity of this criterion is demonstrated by using the mutual information neural estimator. Building on this insight, we propose SiftFunnel, a privacy-preserving framework to resist MIA while maintaining usability. Specifically, we incorporate linear and non-linear correlation constraints alongside label smoothing to suppress redundant information transmission, effectively balancing privacy and usability. To enhance deployability, the edge model adopts a funnel-shaped structure with attention mechanisms, strengthening privacy while reducing computational and storage burdens. Experiments show that, compared to state-of-the-art defense, SiftFunnel increases reconstruction error by $\sim$30\%, lowers mutual and effective information metrics by $\geq$50\%, and reduces edge burdens by almost $20\times$, while maintaining comparable usability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00824v5</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rongke Liu</dc:creator>
    </item>
    <item>
      <title>Quantifying interdisciplinary synergy in higher STEM education</title>
      <link>https://arxiv.org/abs/2502.17841</link>
      <description>arXiv:2502.17841v2 Announce Type: replace-cross 
Abstract: We propose a framework to quantify and utilize interdisciplinarity in science and engineering curricula in the case of university-level higher education. We analyze interdisciplinary relations by standardizing large-scale official educational data in Korea using a cutting-edge large language model and constructing knowledge maps for disciplines of scientific education. We design and evaluate single-field and integrated dual-field curricula by adapting pedagogical theory and utilizing information theory-based metrics. We develop standard curricula for individual disciplines and integrated curricula combining two fields, with their interdisciplinarity quantified by the curriculum synergy score. The results indicate higher interdisciplinarity for combinations within or across closely related fields, especially in engineering fields. Based on the analysis, engineering fields constitute the core structure of our design for curriculum interdisciplinarity, while basic natural science fields are located at peripheral stems to provide fundamental concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17841v2</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.ed-ph</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gahyoun Gim, Jinhyuk Yun, Sang Hoon Lee</dc:creator>
    </item>
    <item>
      <title>ItDPDM: Information-Theoretic Discrete Poisson Diffusion Model</title>
      <link>https://arxiv.org/abs/2505.05082</link>
      <description>arXiv:2505.05082v3 Announce Type: replace-cross 
Abstract: Generative modeling of non-negative, discrete data, such as symbolic music, remains challenging due to two persistent limitations in existing methods. Firstly, many approaches rely on modeling continuous embeddings, which is suboptimal for inherently discrete data distributions. Secondly, most models optimize variational bounds rather than exact data likelihood, resulting in inaccurate likelihood estimates and degraded sampling quality. While recent diffusion-based models have addressed these issues separately, we tackle them jointly. In this work, we introduce the Information-Theoretic Discrete Poisson Diffusion Model (ItDPDM), inspired by photon arrival process, which combines exact likelihood estimation with fully discrete-state modeling. Central to our approach is an information-theoretic Poisson Reconstruction Loss (PRL) that has a provable exact relationship with the true data likelihood. ItDPDM achieves improved likelihood and sampling performance over prior discrete and continuous diffusion models on a variety of synthetic discrete datasets. Furthermore, on real-world datasets such as symbolic music and images, ItDPDM attains superior likelihood estimates and competitive generation quality-demonstrating a proof of concept for distribution-robust discrete generative modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05082v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sagnik Bhattacharya, Abhiram Gorle, Ahsan Bilal, Connor Ding, Amit Kumar Singh Yadav, Tsachy Weissman</dc:creator>
    </item>
    <item>
      <title>Sampling Strategies for Efficient Training of Deep Learning Object Detection Algorithms</title>
      <link>https://arxiv.org/abs/2505.18302</link>
      <description>arXiv:2505.18302v2 Announce Type: replace-cross 
Abstract: Two sampling strategies are investigated to enhance efficiency in training a deep learning object detection model. These sampling strategies are employed under the assumption of Lipschitz continuity of deep learning models. The first strategy is uniform sampling which seeks to obtain samples evenly yet randomly through the state space of the object dynamics. The second strategy of frame difference sampling is developed to explore the temporal redundancy among successive frames in a video. Experiment result indicates that these proposed sampling strategies provide a dataset that yields good training performance while requiring relatively few manually labelled samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18302v2</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gefei Shen, Yung-Hong Sun, Yu Hen Hu, Hongrui Jiang</dc:creator>
    </item>
  </channel>
</rss>
