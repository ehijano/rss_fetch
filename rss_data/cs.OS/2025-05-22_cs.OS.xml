<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.OS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.OS</link>
    <description>cs.OS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.OS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 May 2025 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>KernelOracle: Predicting the Linux Scheduler's Next Move with Deep Learning</title>
      <link>https://arxiv.org/abs/2505.15213</link>
      <description>arXiv:2505.15213v1 Announce Type: cross 
Abstract: Efficient task scheduling is paramount in the Linux kernel, where the Completely Fair Scheduler (CFS) meticulously manages CPU resources to balance high utilization with interactive responsiveness. This research pioneers the use of deep learning techniques to predict the sequence of tasks selected by CFS, aiming to evaluate the feasibility of a more generalized and potentially more adaptive task scheduler for diverse workloads. Our core contributions are twofold: first, the systematic generation and curation of a novel scheduling dataset from a running Linux kernel, capturing real-world CFS behavior; and second, the development, training, and evaluation of a Long Short-Term Memory (LSTM) network designed to accurately forecast the next task to be scheduled. This paper further discusses the practical pathways and implications of integrating such a predictive model into the kernel's scheduling framework. The findings and methodologies presented herein open avenues for data-driven advancements in kernel scheduling, with the full source code provided for reproducibility and further exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15213v1</guid>
      <category>cs.LG</category>
      <category>cs.OS</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sampanna Yashwant Kahu</dc:creator>
    </item>
    <item>
      <title>Data-driven Software-based Power Estimation for Embedded Devices</title>
      <link>https://arxiv.org/abs/2407.02764</link>
      <description>arXiv:2407.02764v2 Announce Type: replace 
Abstract: Energy measurement of computer devices, which are widely used in the Internet of Things (IoT), is an important yet challenging task. Most of these IoT devices lack ready-to-use hardware or software for power measurement. In this paper, we propose an easy-to-use approach to derive a software-based energy estimation model with external low-end power meters based on data-driven analysis. Our solution is demonstrated with a Jetson Nano board and Ruideng UM25C USB power meter. Various machine learning methods combined with our smart data collection &amp; profiling method and physical measurement are explored. Periodic Long-duration measurements are utilized in the experiments to derive and validate power models, allowing more accurate power readings from the low-end power meter. Benchmarks were used to evaluate the derived software-power model for the Jetson Nano board and Raspberry Pi. The results show that 92\% accuracy can be achieved by the software-based power estimation compared to measurement. A kernel module that can collect running traces of utilization and frequencies needed is developed, together with the power model derived, for power prediction for programs running in a real environment. Our cost-effective method facilitates accurate instantaneous power estimation, which low-end power meters cannot directly provide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02764v2</guid>
      <category>cs.OS</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Wang, Xinyi Li, Ti Zhou, Man Lin</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Computation with DVFS using Deep Reinforcement Learning for Multi-Task Systems in Edge Computing</title>
      <link>https://arxiv.org/abs/2409.19434</link>
      <description>arXiv:2409.19434v3 Announce Type: replace 
Abstract: Finding an optimal energy-efficient policy that is adaptable to underlying edge devices while meeting deadlines for tasks has always been challenging. This research studies generalized systems with multi-task, multi-deadline scenarios with reinforcement learning-based DVFS for energy saving for periodic soft real-time applications on edge devices. This work addresses the limitation of previous work that models a periodic system as a single task and single-deadline scenario, which is too simplified to cope with complex situations. The method encodes time series data in the Linux kernel into information that is easy to interpret for reinforcement learning, allowing the system to generate DVFS policies to adapt system patterns based on the general workload. For encoding, we present two different methods for comparison. Both methods use only one performance counter: system utilization, and the kernel only needs minimal information from the userspace. Our method is implemented on Jetson Nano Board (2GB) and is tested with three fixed multitask workloads, which are three, five, and eight tasks in the workload, respectively. For randomness and generalization, we also designed a random workload generator to build different multitask workloads to test. Based on the test results, our method could save 3%-10% power compared to Linux built-in governors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19434v3</guid>
      <category>cs.OS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyi Li, Ti Zhou, Haoyu Wang, Man Lin</dc:creator>
    </item>
  </channel>
</rss>
