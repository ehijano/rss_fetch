<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jul 2025 04:01:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A novel two-stage parameter estimation framework integrating Approximate Bayesian Computation and Machine Learning: The ABC-RF-rejection algorithm</title>
      <link>https://arxiv.org/abs/2507.02072</link>
      <description>arXiv:2507.02072v1 Announce Type: new 
Abstract: We introduce a novel two-stage parameter estimation framework designed to improve computational efficiency in settings involving complex, stochastic, or analytically intractable dynamic models. The proposed method, termed \textit{ABC-RF-rejection}, integrates Approximate Bayesian Computation (ABC) rejection sampling with Random Forest (RF) classification to efficiently screen parameter sets that produce simulations consistent with observed data. We evaluate the performance of this approach using both a deterministic Susceptible-Infected-Removed (SIR) epidemic model and a spatially explicit stochastic epidemic model. Results indicate that ABC-RF-rejection achieves substantial gains in computational efficiency while maintaining parameter inference accuracy comparable with standard ABC rejection methods. Finally, we apply the algorithm to estimate parameters governing the spatial spread of cassava brown streak disease (CBSD) in Nakasongola district, Uganda.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02072v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renata Retkute, Christopher A. Gilligan</dc:creator>
    </item>
    <item>
      <title>Dealing with separation problem in hidden Markov models with covariates based on a penalized maximum likelihood approach</title>
      <link>https://arxiv.org/abs/2507.02425</link>
      <description>arXiv:2507.02425v1 Announce Type: new 
Abstract: A penalized maximum likelihood estimation approach is proposed for discrete-time hidden Markov models where covariates affect the observed responses and serial dependence is considered. The proposed penalized maximum likelihood method addresses the issue of latent state separation that typically occurs when this model is applied to binary and categorical response variables with a limited number of categories, resulting in extremely large estimates of the support points of the latent variable assumed with a discrete, left unspecified distribution. We also propose a cross-validation approach for jointly selecting the number of hidden states and the roughness of the penalty term. The proposal is illustrated through a simulation study comparing parameter estimation accuracy and computational efficiency across different estimation procedures. We also demonstrate the potential of this class of models through the analysis of longitudinal data collected during spinal anesthesia to monitor the occurrence of hypotension in patients, and we compare the results with those obtained from other standard models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02425v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca Brusa, Fulvia Pennoni, Francesco Bartolucci, Romina Peruilh Bagolini</dc:creator>
    </item>
    <item>
      <title>DUST: A Duality-Based Pruning Method For Exact Multiple Change-Point Detection</title>
      <link>https://arxiv.org/abs/2507.02467</link>
      <description>arXiv:2507.02467v1 Announce Type: new 
Abstract: We tackle the challenge of detecting multiple change points in large time series by optimising a penalised likelihood derived from exponential family models. While dynamic programming algorithms can solve this task exactly with at most quadratic time complexity, recent years have seen the development of pruning strategies to improve their time efficiency. However, the two existing approaches have notable limitations: PELT struggles with pruning efficiency in sparse-change scenarios, while FPOP's structure is ill-suited for multi-parametric settings. To address these issues, we introduce the DUal Simple Test (DUST) framework, which prunes candidates by evaluating a dual function against a threshold. This approach is highly flexible and broadly applicable to parametric models of any dimension. Under mild assumptions, we establish strong duality for the underlying non-convex pruning problem. We demonstrate DUST's effectiveness across various change point regimes and models. In particular, for one-parametric models, DUST matches the simplicity of PELT with the efficiency of FPOP. Its use is especially advantageous for non-Gaussian models. Its use is especially advantageous for non-Gaussian models. Finally, we apply DUST to mouse monitoring time series under a change-in-variance model, illustrating its ability to recover the optimal change point structure efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02467v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Runge, Charles Truong, Simon Quern\'e</dc:creator>
    </item>
    <item>
      <title>On the analysis of sequential designs without a specified number of observations</title>
      <link>https://arxiv.org/abs/2507.02580</link>
      <description>arXiv:2507.02580v1 Announce Type: new 
Abstract: The paper focuses on sequential experiments for categorical responses in which whether or not a further observation is made depends on the outcome of a previous experiment. Examples include subsequent medical interventions being performed or not depending on the result of a previous intervention, data about offsprings, life tables, and repeated educational retraininig until a certain proficiency level is achieved. Such experiments do not lead to data with a full Cartesian product structure and, despite a prespecified initial sample size, the total number of observations, or interventions, made cannot be determined in advance. The paper investigates the distributional assumptions behind such data and describes a parameterization of the distribution that arises and the respective model class to analyze it. Both the data structure resulting from such an experiment and the model class are special examples of staged trees in algebraic statistics. The properties of the resulting parameter estimates and test statistics are obtained and illustrated using hypothetical and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02580v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Klimova, Tam\'as Rudas</dc:creator>
    </item>
    <item>
      <title>It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation</title>
      <link>https://arxiv.org/abs/2507.02275</link>
      <description>arXiv:2507.02275v1 Announce Type: cross 
Abstract: Structure-agnostic causal inference studies how well one can estimate a treatment effect given black-box machine learning estimates of nuisance functions (like the impact of confounders on treatment and outcomes). Here, we find that the answer depends in a surprising way on the distribution of the treatment noise. Focusing on the partially linear model of \citet{robinson1988root}, we first show that the widely adopted double machine learning (DML) estimator is minimax rate-optimal for Gaussian treatment noise, resolving an open problem of \citet{mackey2018orthogonal}. Meanwhile, for independent non-Gaussian treatment noise, we show that DML is always suboptimal by constructing new practical procedures with higher-order robustness to nuisance errors. These \emph{ACE} procedures use structure-agnostic cumulant estimators to achieve $r$-th order insensitivity to nuisance errors whenever the $(r+1)$-st treatment cumulant is non-zero. We complement these core results with novel minimax guarantees for binary treatments in the partially linear model. Finally, using synthetic demand estimation experiments, we demonstrate the practical benefits of our higher-order robust estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02275v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jikai Jin, Lester Mackey, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning</title>
      <link>https://arxiv.org/abs/2507.02442</link>
      <description>arXiv:2507.02442v1 Announce Type: cross 
Abstract: Enhancing the intelligibility and interpretability of machine learning is a crucial task in responding to the demand for Explicability as an AI principle, and in promoting the better social implementation of AI. The aim of our research is to contribute to this improvement by reformulating machine learning models through the lens of category theory, thereby developing a semantic framework for structuring and understanding AI systems. Our categorical modeling in this paper clarifies and formalizes the structural interplay between residuals and parameters in supervised learning. The present paper focuses on the multiple linear regression model, which represents the most basic form of supervised learning. By defining two concrete categories corresponding to parameters and data, along with an adjoint pair of functors between them, we introduce our categorical formulation of supervised learning. We show that the essential structure of this framework is captured by what we call the Gauss-Markov Adjunction. Within this setting, the dual flow of information can be explicitly described as a correspondence between variations in parameters and residuals. The ordinary least squares estimator for the parameters and the minimum residual are related via the preservation of limits by the right adjoint functor. Furthermore, we position this formulation as an instance of extended denotational semantics for supervised learning, and propose applying a semantic perspective developed in theoretical computer science as a formal foundation for Explicability in AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02442v1</guid>
      <category>cs.AI</category>
      <category>math.CT</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moto Kamiura</dc:creator>
    </item>
    <item>
      <title>Covariance scanning for adaptively optimal change point detection in high-dimensional linear models</title>
      <link>https://arxiv.org/abs/2507.02552</link>
      <description>arXiv:2507.02552v1 Announce Type: cross 
Abstract: This paper investigates the detection and estimation of a single change in high-dimensional linear models. We derive minimax lower bounds for the detection boundary and the estimation rate, which uncover a phase transition governed the sparsity of the covariance-weighted differential parameter. This form of "inherent sparsity" captures a delicate interplay between the covariance structure of the regressors and the change in regression coefficients on the detectability of a change point. Complementing the lower bounds, we introduce two covariance scanning-based methods, McScan and QcSan, which achieve minimax optimal performance (up to possible logarithmic factors) in the sparse and the dense regimes, respectively. In particular, QcScan is the first method shown to achieve consistency in the dense regime and further, we devise a combined procedure which is adaptively minimax optimal across sparse and dense regimes without the knowledge of the sparsity. Computationally, covariance scanning-based methods avoid costly computation of Lasso-type estimators and attain worst-case computation complexity that is linear in the dimension and sample size. Additionally, we consider the post-detection estimation of the differential parameter and the refinement of the change point estimator. Simulation studies support the theoretical findings and demonstrate the computational and statistical efficiency of the proposed covariance scanning methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02552v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Haeran Cho, Housen Li</dc:creator>
    </item>
    <item>
      <title>Conformal prediction after data-dependent model selection</title>
      <link>https://arxiv.org/abs/2408.07066</link>
      <description>arXiv:2408.07066v3 Announce Type: replace 
Abstract: Given a family of pretrained models and a hold-out set, how can we construct a valid conformal prediction set while selecting a model that minimizes the width of the set? If we use the same hold-out data set both to select a model (the model that yields the smallest conformal prediction sets) and then to construct a conformal prediction set based on that selected model, we suffer a loss of coverage due to selection bias. Alternatively, we could further splitting the data to perform selection and calibration separately, but this comes at a steep cost if the size of the dataset is limited. In this paper, we address the challenge of constructing a valid prediction set after data-dependent model selection -- commonly, selecting the model that minimizes the width of the resulting prediction sets. Our novel methods can be implemented efficiently and admit finite-sample validity guarantees without invoking additional sample-splitting. We show that our methods yield prediction sets with asymptotically optimal width under certain notion of regularity for the model class. The improvement in the width of the prediction sets constructed by our methods are further demonstrated through applications to synthetic datasets in various settings and a real data example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07066v3</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiting Liang, Wanrong Zhu, Rina Foygel Barber</dc:creator>
    </item>
    <item>
      <title>Generalized coarsened confounding for causal effects: a large-sample framework</title>
      <link>https://arxiv.org/abs/2501.03129</link>
      <description>arXiv:2501.03129v2 Announce Type: replace 
Abstract: There has been widespread use of causal inference methods for the rigorous analysis of observational studies and to identify policy evaluations. In this article, we consider a class of generalized coarsened procedures for confounding. At a high level, these procedures can be viewed as performing a clustering of confounding variables, followed by treatment effect and attendant variance estimation using the confounder strata. In addition, we propose two new algorithms for generalized coarsened confounding. While Iacus et al. (2011) developed some statistical properties for one special case in our class of procedures, we instead develop a general asymptotic framework. We provide asymptotic results for the average causal effect estimator as well as providing conditions for consistency. In addition, we provide an asymptotic justification for the variance formulae in Iacus et al. (2011). A bias correction technique is proposed, and we apply the proposed methodology to data from two well-known observational studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03129v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Debashis Ghosh, Lei Wang</dc:creator>
    </item>
    <item>
      <title>Interpreting the Win Ratio in Hierarchical Composite Endpoints: Challenges, Limitations, and Perspectives with Examples from Chronic Kidney Disease Trials</title>
      <link>https://arxiv.org/abs/2504.05909</link>
      <description>arXiv:2504.05909v2 Announce Type: replace 
Abstract: Win statistics based methods have gained traction as a method for analyzing Hierarchical Composite Endpoints (HCEs) in randomized clinical trials, particularly in cardiovascular and kidney disease research. HCEs offer several key advantages, including increased statistical power, the mitigation of competing risks, and hierarchical weighting of clinical importance for different outcome components. While, as summary measures, the win ratio (WR) along with the Net Benefit (NB) and the Win Odds (WO) provide a structured approach to analyzing HCEs, several concerns regarding their interpretability remain. In this paper, we explore critical aspects of WR interpretation that have received limited attention. Specifically, we discuss the challenge of defining an appropriate estimand in the context of HCEs using the WR, the difficulties in formulating a relevant causal question underlying the WR, and the dependency of the WR on the variance of its components, which complicates its role as an effect measure. Additionally, we highlight the non-collapsibility of the WR, akin to hazard and odds ratios, further complicating its interpretation. While the WR remains a valuable tool in clinical trials, its inherent limitations must be acknowledged to ensure its appropriate application and interpretation in regulatory and clinical decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05909v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrik F. Thomsen, Samvel B. Gasparyan, Julie F. Furberg, Christoph Tasto, Nicole Rethemeier, Patrick Schloemer, Tuo Wang, Niels Jongs, Yu Du, Tom Greene</dc:creator>
    </item>
    <item>
      <title>Post-treatment problems: What can we say about the effect of a treatment among sub-groups who (would) respond in some way?</title>
      <link>https://arxiv.org/abs/2505.06754</link>
      <description>arXiv:2505.06754v2 Announce Type: replace 
Abstract: Investigators are often interested in how a treatment affects an outcome for units responding to treatment in a certain way. We may wish to know the effect among units that, for example, meaningfully implemented the intervention or passed an attention check. Simply conditioning on the observed value of the post-treatment variable introduces problematic biases. Further, the identification assumptions required of several existing strategies are often indefensible. We propose the Treatment Reactive Average Causal Effect (TRACE), which we define as the total effect of treatment in the group that, if treated, would realize a particular value of the relevant post-treatment variable. By reasoning about the effect among the "non-reactive" group, we can identify and estimate the range of plausible values for the TRACE. We demonstrate the use of this approach with three examples: (i) using hypothetical data to illustrate how we can point identify the effect of police-perceived race on police violence during traffic stops, (ii) estimating effects of a community-policing intervention in Liberia, in locations where the project was meaningfully implemented, and (iii) studying how in-person canvassing affects support for transgender rights in the United States, among participants whose feelings towards transgender people become more positive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06754v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chad Hazlett, Nina McMurry, Tanvi Shinkre</dc:creator>
    </item>
    <item>
      <title>Filtrated Grouping in Multiple Functional Regression</title>
      <link>https://arxiv.org/abs/2506.11369</link>
      <description>arXiv:2506.11369v2 Announce Type: replace 
Abstract: To understand and communicate the risk of chronic joint disease associated with aging, it is essential to investigate how age is associated with gait patterns, particularly through gait angular kinematics. Motivated by this need, and by the critical role of joint coordination in gait, we propose a novel covariate grouping framework within the context of multiple functional regression, where a scalar response is linked to multiple functional covariates. We apply this approach to investigate the relationship between chronological age and gait angular kinematics, aiming to uncover biomechanical patterns that signal age-related gait pattern evolution. Specifically, we develop a forest-structured covariate grouping framework in which different functional covariates are aggregated hierarchically based on the level of coefficient homogeneity. This approach allows for the analysis of both common and idiosyncratic effects of covariates in a nuanced, multi-resolution manner. The identification of the forest structure is entirely data-driven and requires no prior knowledge, providing valuable insights into the interdependence among covariates. Compared to existing methods, the proposed regression framework demonstrates superior predictive power and offers more insightful interpretability on joint coordination. In addition, the proposed framework is broadly applicable and can be readily extended to analyze multivariate functional data in other scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11369v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhao Jiao, Hernando Ombao, Ian W. McKeague</dc:creator>
    </item>
    <item>
      <title>Tensor-product interactions in Markov-switching models</title>
      <link>https://arxiv.org/abs/2507.01555</link>
      <description>arXiv:2507.01555v2 Announce Type: replace 
Abstract: Markov-switching models are a powerful tool for modelling time series data that are driven by underlying latent states. As such, they are widely used in behavioural ecology, where discrete states can serve as proxies for behavioural modes and enable inference on latent behaviour driving e.g. observed movement. To understand drivers of behavioural changes, it is common to link model parameters to covariates. Over the last decade, nonparametric approaches have gained traction in this context to avoid unrealistic parametric assumptions. Nonetheless, existing methods are largely limited to univariate smooth functions of covariates, based on penalised splines, while real processes are typically complex requiring consideration of interaction effects. We address this gap by incorporating tensor-product interactions into Markov-switching models, enabling flexible modelling of multidimensional effects in a computationally efficient manner. Based on the extended Fellner-Schall method, we develop an efficient automatic smoothness selection procedure that is robust and scales well with the number of smooth functions in the model. The method builds on a random effects view of the spline coefficients and yields a recursive penalised likelihood procedure. As special cases, this general framework accommodates bivariate smoothing, function-valued random effects, and space-time interactions. We demonstrate its practical utility through three ecological case studies of an African elephant, common fruitflies, and Arctic muskoxen. The methodology is implemented in the LaMa R package, providing applied ecologists with an accessible and flexible tool for semiparametric inference in hidden-state models. The approach has the potential to drastically improve the level of detail in inference, allowing to fit HMMs with hundreds of parameters, 10-20 (potentially bivariate) smooths to thousands of observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01555v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan-Ole Koslik</dc:creator>
    </item>
    <item>
      <title>A Model-Consistent Data-Driven Computational Strategy for PDE Joint Inversion Problems</title>
      <link>https://arxiv.org/abs/2210.09228</link>
      <description>arXiv:2210.09228v3 Announce Type: replace-cross 
Abstract: The task of simultaneously reconstructing multiple physical coefficients in partial differential equations (PDEs) from observed data is ubiquitous in applications. In this work, we propose an integrated data-driven and model-based iterative reconstruction framework for such joint inversion problems where additional data on the unknown coefficients are supplemented for better reconstructions. Our method couples the supplementary data with the PDE model to make the data-driven modeling process consistent with the model-based reconstruction procedure. We characterize the impact of learning uncertainty on the joint inversion results for two typical inverse problems. Numerical evidence is provided to demonstrate the feasibility of using data-driven models to improve the joint inversion of multiple coefficients in PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.09228v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Ren, Lu Zhang</dc:creator>
    </item>
    <item>
      <title>The Choice of Normalization Influences Shrinkage in Regularized Regression</title>
      <link>https://arxiv.org/abs/2501.03821</link>
      <description>arXiv:2501.03821v3 Announce Type: replace-cross 
Abstract: Regularized models are often sensitive to the scales of the features in the data and it has therefore become standard practice to normalize (center and scale) the features before fitting the model. But there are many different ways to normalize the features and the choice may have dramatic effects on the resulting model. In spite of this, there has so far been no research on this topic. In this paper, we begin to bridge this knowledge gap by studying normalization in the context of lasso, ridge, and elastic net regression. We focus on binary features and show that their class balances (proportions of ones) directly influences the regression coefficients and that this effect depends on the combination of normalization and regularization methods used. We demonstrate that this effect can be mitigated by scaling binary features with their variance in the case of the lasso and standard deviation in the case of ridge regression, but that this comes at the cost of increased variance of the coefficient estimates. For the elastic net, we show that scaling the penalty weights, rather than the features, can achieve the same effect. Finally, we also tackle mixes of binary and normal features as well as interactions and provide some initial results on how to normalize features in these cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03821v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johan Larsson, Jonas Wallin</dc:creator>
    </item>
    <item>
      <title>Quantum-enhanced causal discovery for a small number of samples</title>
      <link>https://arxiv.org/abs/2501.05007</link>
      <description>arXiv:2501.05007v2 Announce Type: replace-cross 
Abstract: The discovery of causal relations from observed data has attracted significant interest from disciplines such as economics, social sciences, and biology. In practical applications, considerable knowledge of the underlying systems is often unavailable, and real data are usually associated with nonlinear causal structures, which makes the direct use of most conventional causality analysis methods difficult. This study proposes a novel quantum Peter-Clark (qPC) algorithm for causal discovery that does not require any assumptions about the underlying model structures. Based on conditional independence tests in a class of reproducing kernel Hilbert spaces characterized by quantum circuits, the proposed algorithm can explore causal relations from the observed data drawn from arbitrary distributions. We conducted systematic experiments on fundamental graphs of causal structures, demonstrating that the qPC algorithm exhibits better performance, particularly with smaller sample sizes compared to its classical counterpart. Furthermore, we proposed a novel optimization approach based on Kernel Target Alignment (KTA) for determining hyperparameters of quantum kernels. This method effectively reduced the risk of false positives in causal discovery, enabling more reliable inference. Our theoretical and experimental results demonstrate that the quantum algorithm can empower classical algorithms for accurate inference in causal discovery, supporting them in regimes where classical algorithms typically fail. In addition, the effectiveness of this method was validated using the datasets on Boston housing prices, heart disease, and biological signaling systems as real-world applications. These findings highlight the potential of quantum-based causal discovery methods in addressing practical challenges, particularly in small-sample scenarios, where traditional approaches have shown significant limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05007v2</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Terada, Ken Arai, Yu Tanaka, Yota Maeda, Hiroshi Ueno, Hiroyuki Tezuka</dc:creator>
    </item>
    <item>
      <title>The Poisson tensor completion non-parametric differential entropy estimator</title>
      <link>https://arxiv.org/abs/2505.04957</link>
      <description>arXiv:2505.04957v3 Announce Type: replace-cross 
Abstract: We introduce the Poisson tensor completion (PTC) estimator, a non-parametric differential entropy estimator. The PTC estimator leverages inter-sample relationships to compute a low-rank Poisson tensor decomposition of the frequency histogram. Our crucial observation is that the histogram bins are an instance of a space partitioning of counts and thus can be identified with a spatial Poisson process. The Poisson tensor decomposition leads to a completion of the intensity measure over all bins -- including those containing few to no samples -- and leads to our proposed PTC differential entropy estimator. A Poisson tensor decomposition models the underlying distribution of the count data and guarantees non-negative estimated values and so can be safely used directly in entropy estimation. Our estimator is the first tensor-based estimator that exploits the underlying spatial Poisson process related to the histogram explicitly when estimating the probability density with low-rank tensor decompositions for the purpose of tensor completion. Furthermore, we demonstrate that our PTC estimator is a substantial improvement over standard histogram-based estimators for sub-Gaussian probability distributions because of the concentration of norm phenomenon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04957v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel M. Dunlavy, Richard B. Lehoucq, Carolyn D. Mayer, Arvind Prasadan</dc:creator>
    </item>
  </channel>
</rss>
