<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 01:52:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Manifold Learning via Memory and Context</title>
      <link>https://arxiv.org/abs/2407.09488</link>
      <description>arXiv:2407.09488v1 Announce Type: new 
Abstract: Given a memory with infinite capacity, can we solve the learning problem? Apparently, nature has solved this problem as evidenced by the evolution of mammalian brains. Inspired by the organizational principles underlying hippocampal-neocortical systems, we present a navigation-based approach to manifold learning using memory and context. The key insight is to navigate on the manifold and memorize the positions of each route as inductive/design bias of direct-fit-to-nature. We name it navigation-based because our approach can be interpreted as navigating in the latent space of sensorimotor learning via memory (local maps) and context (global indexing). The indexing to the library of local maps within global coordinates is collected by an associative memory serving as the librarian, which mimics the coupling between the hippocampus and the neocortex. In addition to breaking from the notorious bias-variance dilemma and the curse of dimensionality, we discuss the biological implementation of our navigation-based learning by episodic and semantic memories in neural systems. The energy efficiency of navigation-based learning makes it suitable for hardware implementation on non-von Neumann architectures, such as the emerging in-memory computing paradigm, including spiking neural networks and memristor neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09488v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xin Li</dc:creator>
    </item>
    <item>
      <title>Brain Dialogue Interface (BDI): A User-Friendly fMRI Model for Interactive Brain Decoding</title>
      <link>https://arxiv.org/abs/2407.09509</link>
      <description>arXiv:2407.09509v1 Announce Type: new 
Abstract: Brain decoding techniques are essential for understanding the neurocognitive system. Although numerous methods have been introduced in this field, accurately aligning complex external stimuli with brain activities remains a formidable challenge. To alleviate alignment difficulties, many studies have simplified their models by employing single-task paradigms and establishing direct links between brain/world through classification strategies. Despite improvements in decoding accuracy, this strategy frequently encounters issues with generality when adapting these models to various task paradigms. To address this issue, this study introduces a user-friendly decoding model that enables dynamic communication with the brain, as opposed to the static decoding approaches utilized by traditional studies. The model functions as a brain simulator, allowing for interactive engagement with the brain and enabling the decoding of a subject's experiences through dialogue-like queries. Uniquely, our model is trained in a completely unsupervised and task-free manner. Our experiments demonstrate the feasibility and versatility of our proposed method. Notably, our model demonstrates exceptional capabilities in signal compression, successfully representing the entire brain signal of approximately 185,751 voxels with just 32 signals. Furthermore, we show how our model can integrate seamlessly with multimodal models, thus enhancing the potential for controlling brain decoding through textual or image inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09509v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heng Huang, Lin Zhao, Zihao Wu, Xiaowei Yu, Jing Zhang, Xintao Hu, Dajiang Zhu, Tianming Liu</dc:creator>
    </item>
    <item>
      <title>A Dynamic Systems Approach to Modelling Human-Machine Rhythm Interaction</title>
      <link>https://arxiv.org/abs/2407.09538</link>
      <description>arXiv:2407.09538v1 Announce Type: new 
Abstract: In exploring the simulation of human rhythmic perception and synchronization capabilities, this study introduces a computational model inspired by the physical and biological processes underlying rhythm processing. Utilizing a reservoir computing framework that simulates the function of cerebellum, the model features a dual-neuron classification and incorporates parameters to modulate information transfer, reflecting biological neural network characteristics. Our findings demonstrate the model's ability to accurately perceive and adapt to rhythmic patterns within the human perceptible range, exhibiting behavior closely aligned with human rhythm interaction. By incorporating fine-tuning mechanisms and delay-feedback, the model enables continuous learning and precise rhythm prediction. The introduction of customized settings further enhances its capacity to stimulate diverse human rhythmic behaviors, underscoring the potential of this architecture in temporal cognitive task modeling and the study of rhythm synchronization and prediction in artificial and biological systems. Therefore, our model is capable of transparently modelling cognitive theories that elucidate the dynamic processes by which the brain generates rhythm-related behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09538v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhongju Yuan, Wannes Van Ransbeeck, Geraint Wiggins, Dick Botteldooren</dc:creator>
    </item>
    <item>
      <title>Multi-object Data Integration in the Study of Primary Progressive Aphasia</title>
      <link>https://arxiv.org/abs/2407.09542</link>
      <description>arXiv:2407.09542v1 Announce Type: new 
Abstract: This article focuses on a multi-modal imaging data application where structural/anatomical information from gray matter (GM) and brain connectivity information in the form of a brain connectome network from functional magnetic resonance imaging (fMRI) are available for a number of subjects with different degrees of primary progressive aphasia (PPA), a neurodegenerative disorder (ND) measured through a speech rate measure on motor speech loss. The clinical/scientific goal in this study becomes the identification of brain regions of interest significantly related to the speech rate measure to gain insight into ND patterns. Viewing the brain connectome network and GM images as objects, we develop an integrated object response regression framework of network and GM images on the speech rate measure. A novel integrated prior formulation is proposed on network and structural image coefficients in order to exploit network information of the brain connectome while leveraging the interconnections among the two objects. The principled Bayesian framework allows the characterization of uncertainty in ascertaining a region being actively related to the speech rate measure. Our framework yields new insights into the relationship of brain regions associated with PPA, offering a deeper understanding of neuro-degenerative patterns of PPA. The supplementary file adds details about posterior computation and additional empirical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09542v1</guid>
      <category>q-bio.NC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rene Gutierrez, Rajarshi Guhaniyogi, Aaron Scheffler, Maria Luisa Gorno-Tempini, Maria Luisa Mandelli, Giovanni Battistella</dc:creator>
    </item>
    <item>
      <title>Psychology of Artificial Intelligence: Epistemological Markers of the Cognitive Analysis of Neural Networks</title>
      <link>https://arxiv.org/abs/2407.09563</link>
      <description>arXiv:2407.09563v1 Announce Type: new 
Abstract: What is the "nature" of the cognitive processes and contents of an artificial neural network? In other words, how does an artificial intelligence fundamentally "think," and in what form does its knowledge reside? The psychology of artificial intelligence, as predicted by Asimov (1950), aims to study this AI probing and explainability-sensitive matter. This study requires a neuronal level of cognitive granularity, so as not to be limited solely to the secondary macro-cognitive results (such as cognitive and cultural biases) of synthetic neural cognition. A prerequisite for examining the latter is to clarify some epistemological milestones regarding the cognitive status we can attribute to its phenomenology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09563v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Pichat (Neocognition)</dc:creator>
    </item>
    <item>
      <title>On the nature of information -- an evolutionary perspective</title>
      <link>https://arxiv.org/abs/2407.09567</link>
      <description>arXiv:2407.09567v1 Announce Type: new 
Abstract: This Perspective explores the origins and persistence of recurrent structures and patterns throughout the known Universe. We start with a first fundamental question: 1. Considering that all information consists of patterns in physical structure but not all physical patterns constitute information, what is the fundamental relation between these two? We first explore the materialistic nature of structures and information, detailing how they can form through spontaneous or templated processes and evolve into complex structures, including self-replicators. We posit that all recurring structures emerge either spontaneously de novo or based on underlying information. A main implication is that all information must be understood as both a product and a driver of evolution. We further observe that the three carriers of information underpin the emergence of three main layers of self-organisation: genes coded in DNA for the biological layer, ideas stored in neural structure for the cultural layer, and records written on innate objects for the civilisation layer. This gives rise to two additional questions, which we subsequently address: 2. What can we anticipate about the future development of self-organizing layers given the role of information in their emergence? 3. What is the universality of information and its evolution throughout the Universe? This manuscript aims to offer a fresh perspective and a universal framework for information and the origin of structures by extending and unifying concepts from physics, biology, and information theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09567v1</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.hist-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter van der Wijngaart</dc:creator>
    </item>
    <item>
      <title>Transcranial low-level laser stimulation in near infrared-II region for brain safety and protection</title>
      <link>https://arxiv.org/abs/2407.09922</link>
      <description>arXiv:2407.09922v1 Announce Type: new 
Abstract: Background: The use of near-infrared lasers for transcranial photobiomodulation (tPBM) offers a non-invasive method for influencing brain activity and is beneficial for various neurological conditions. Objective: To investigate the safety and neuroprotective properties of tPBM using near-infrared (NIR)-II laser stimulation. Methods: We conducted thirteen experiments involving multidimensional and quantitative methods and measured serum neurobiomarkers, performed electroencephalogram (EEG) and magnetic resonance imaging (MRI) scans, assessed executive functions, and collected a subjective questionnaire. Results: Significant reductions (n=15) in neuron specific enolase (NSE) levels were observed after treatment, indicating neuroprotective effects. No structural or functional brain abnormalities were observed, confirming the safety of tPBM. Additionally, cognitive and executive functions were not impaired, with participants' feedback indicating minimal discomfort. Conclusions: Our data indicate that NIR-II tPBM is safe with specific parameters, highlighting its potential for brain protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09922v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhilin Li, Yongheng Zhao, Yiqing Hu, Yang Li, Keyao Zhang, Zhibing Gao, Lirou Tan, Hanli Liu, Xiaoli Li, Aihua Cao, Zaixu Cui, Chenguang Zhao</dc:creator>
    </item>
    <item>
      <title>Time-Integrated Spike-Timing-Dependent-Plasticity</title>
      <link>https://arxiv.org/abs/2407.10028</link>
      <description>arXiv:2407.10028v1 Announce Type: new 
Abstract: In this work, we propose time-integrated spike-timing-dependent plasticity (TI-STDP), a mathematical model of synaptic plasticity that allows spiking neural networks to continuously adapt to sensory input streams in an unsupervised fashion. Notably, we theoretically establish and formally prove key properties related to the synaptic adjustment mechanics that underwrite TI-STDP. Empirically, we demonstrate the efficacy of TI-STDP in simulations of jointly learning deeper spiking neural networks that process input digit pixel patterns, at both full image and patch-levels, comparing to two powerful historical instantations of STDP; trace-based STDP (TR-STDP) and event-based post-synaptic STDP (EV-STDP). Usefully, we demonstrate that not only are all forms of STDP capable of meaningfully adapting the synaptic efficacies of a multi-layer biophysical architecture, but that TI-STDP is notably able to do so without requiring the tracking of a large window of pre- and post-synaptic spike timings, the maintenance of additional parameterized traces, or the restriction of synaptic plasticity changes to occur within very narrow windows of time. This means that our findings show that TI-STDP can efficiently embody the benefits of models such as canonical STDP, TR-STDP, and EV-STDP without their costs or drawbacks. Usefully, our results further demonstrate the promise of using a spike-correlation scheme such as TI-STDP in conducting credit assignment in discrete pulse-based neuromorphic models, particularly those than acquire a lower-level distributed representation jointly with an upper-level, more abstract representation that self-organizes to cluster based on inherent cross-pattern similarities. We further demonstrate TI-STDP's effectiveness in adapting a simple neuronal circuit that learns a simple bi-level, part-whole hierarchy from sensory input patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10028v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Gebhardt, Alexander G. Ororbia</dc:creator>
    </item>
    <item>
      <title>Large Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder</title>
      <link>https://arxiv.org/abs/2407.10376</link>
      <description>arXiv:2407.10376v1 Announce Type: new 
Abstract: Functional magnetic resonance imaging (fMRI) is essential for developing encoding models that identify functional changes in language-related brain areas of individuals with Neurocognitive Disorders (NCD). While large language model (LLM)-based fMRI encoding has shown promise, existing studies predominantly focus on healthy, young adults, overlooking older NCD populations and cognitive level correlations. This paper explores language-related functional changes in older NCD adults using LLM-based fMRI encoding and brain scores, addressing current limitations. We analyze the correlation between brain scores and cognitive scores at both whole-brain and language-related ROI levels. Our findings reveal that higher cognitive abilities correspond to better brain scores, with correlations peaking in the middle temporal gyrus. This study highlights the potential of fMRI encoding models and brain scores for detecting early functional changes in NCD patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10376v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuejiao Wang, Xianmin Gong, Lingwei Meng, Xixin Wu, Helen Meng</dc:creator>
    </item>
    <item>
      <title>MARVEL: MR Fingerprinting with Additional micRoVascular Estimates using bidirectional LSTMs</title>
      <link>https://arxiv.org/abs/2407.10512</link>
      <description>arXiv:2407.10512v1 Announce Type: new 
Abstract: The Magnetic Resonance Fingerprinting (MRF) approach aims to estimate multiple MR or physiological parameters simultaneously with a single fast acquisition sequence. Most of the MRF studies proposed so far have used simple MR sequence types to measure relaxation times (T1, T2). In that case, deep learning algorithms have been successfully used to speed up the reconstruction process. In theory, the MRF concept could be used with a variety of other MR sequence types and should be able to provide more information about the tissue microstructures. Yet, increasing the complexity of the numerical models often leads to prohibited simulation times, and estimating multiple parameters from one sequence implies new dictionary dimensions whose sizes become too large for standard computers and DL architectures.In this paper, we propose to analyze the MRF signal coming from a complex balance Steady-state free precession (bSSFP) type sequence to simultaneously estimate relaxometry maps (T1, T2), Field maps (B1, B0) as well as microvascular properties such as the local Cerebral Blood Volume (CBV) or the averaged vessel Radius (R).To bypass the curse of dimensionality, we propose an efficient way to simulate the MR signal coming from numerical voxels containing realistic microvascular networks as well as a Bidirectional Long Short-Term Memory network used for the matching process.On top of standard MRF maps, our results on 3 human volunteers suggest that our approach can quickly produce high-quality quantitative maps of microvascular parameters that are otherwise obtained using longer dedicated sequences and intravenous injection of a contrast agent. This approach could be used for the management of multiple pathologies and could be tuned to provide other types of microstructural information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10512v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Barrier (GIN), Thomas Coudert (GIN), Aur\'elien Delphin (IRMaGe), Benjamin Lemasson (GIN), Thomas Christen (GIN)</dc:creator>
    </item>
    <item>
      <title>Is GPT-4 conscious?</title>
      <link>https://arxiv.org/abs/2407.09517</link>
      <description>arXiv:2407.09517v1 Announce Type: cross 
Abstract: GPT-4 is often heralded as a leading commercial AI offering, sparking debates over its potential as a steppingstone toward artificial general intelligence. But does it possess consciousness? This paper investigates this key question using the nine qualitative measurements of the Building Blocks theory. GPT-4's design, architecture and implementation are compared to each of the building blocks of consciousness to determine whether it has achieved the requisite milestones to be classified as conscious or, if not, how close to consciousness GPT-4 is. Our assessment is that, while GPT-4 in its native configuration is not currently conscious, current technological research and development is sufficient to modify GPT-4 to have all the building blocks of consciousness. Consequently, we argue that the emergence of a conscious AI model is plausible in the near term. The paper concludes with a comprehensive discussion of the ethical implications and societal ramifications of engineering conscious AI entities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09517v1</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Izak Tait, Joshua Bensemann, Ziqi Wang</dc:creator>
    </item>
    <item>
      <title>Order parameters and phase transitions of continual learning in deep neural networks</title>
      <link>https://arxiv.org/abs/2407.10315</link>
      <description>arXiv:2407.10315v1 Announce Type: cross 
Abstract: Continual learning (CL) enables animals to learn new tasks without erasing prior knowledge. CL in artificial neural networks (NNs) is challenging due to catastrophic forgetting, where new learning degrades performance on older tasks. While various techniques exist to mitigate forgetting, theoretical insights into when and why CL fails in NNs are lacking. Here, we present a statistical-mechanics theory of CL in deep, wide NNs, which characterizes the network's input-output mapping as it learns a sequence of tasks. It gives rise to order parameters (OPs) that capture how task relations and network architecture influence forgetting and knowledge transfer, as verified by numerical evaluations. We found that the input and rule similarity between tasks have different effects on CL performance. In addition, the theory predicts that increasing the network depth can effectively reduce overlap between tasks, thereby lowering forgetting. For networks with task-specific readouts, the theory identifies a phase transition where CL performance shifts dramatically as tasks become less similar, as measured by the OPs. Sufficiently low similarity leads to catastrophic anterograde interference, where the network retains old tasks perfectly but completely fails to generalize new learning. Our results delineate important factors affecting CL performance and suggest strategies for mitigating forgetting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10315v1</guid>
      <category>cs.LG</category>
      <category>physics.app-ph</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haozhe Shan, Qianyi Li, Haim Sompolinsky</dc:creator>
    </item>
    <item>
      <title>Teaching CORnet Human fMRI Representations for Enhanced Model-Brain Alignment</title>
      <link>https://arxiv.org/abs/2407.10414</link>
      <description>arXiv:2407.10414v1 Announce Type: cross 
Abstract: Deep convolutional neural networks (DCNNs) have demonstrated excellent performance in object recognition and have been found to share some similarities with brain visual processing. However, the substantial gap between DCNNs and human visual perception still exists. Functional magnetic resonance imaging (fMRI) as a widely used technique in cognitive neuroscience can record neural activation in the human visual cortex during the process of visual perception. Can we teach DCNNs human fMRI signals to achieve a more brain-like model? To answer this question, this study proposed ReAlnet-fMRI, a model based on the SOTA vision model CORnet but optimized using human fMRI data through a multi-layer encoding-based alignment framework. This framework has been shown to effectively enable the model to learn human brain representations. The fMRI-optimized ReAlnet-fMRI exhibited higher similarity to the human brain than both CORnet and the control model in within-and across-subject as well as within- and across-modality model-brain (fMRI and EEG) alignment evaluations. Additionally, we conducted an in-depth analyses to investigate how the internal representations of ReAlnet-fMRI differ from CORnet in encoding various object dimensions. These findings provide the possibility of enhancing the brain-likeness of visual models by integrating human neural data, helping to bridge the gap between computer vision and visual neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10414v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zitong Lu, Yile Wang</dc:creator>
    </item>
    <item>
      <title>Contrastive Learning of Shared Spatiotemporal EEG Representations Across Individuals for Naturalistic Neuroscience</title>
      <link>https://arxiv.org/abs/2402.14213</link>
      <description>arXiv:2402.14213v2 Announce Type: replace 
Abstract: Neural representations induced by naturalistic stimuli offer insights into how humans respond to stimuli in daily life. Understanding neural mechanisms underlying naturalistic stimuli processing hinges on the precise identification and extraction of the shared neural patterns that are consistently present across individuals. Targeting the Electroencephalogram (EEG) technique, known for its rich spatial and temporal information, this study presents a framework for Contrastive Learning of Shared SpatioTemporal EEG Representations across individuals (CL-SSTER). CL-SSTER utilizes contrastive learning to maximize the similarity of EEG representations across individuals for identical stimuli, contrasting with those for varied stimuli. The network employed spatial and temporal convolutions to simultaneously learn the spatial and temporal patterns inherent in EEG. The versatility of CL-SSTER was demonstrated on three EEG datasets, including a synthetic dataset, a natural speech comprehension EEG dataset, and an emotional video watching EEG dataset. CL-SSTER attained the highest inter-subject correlation (ISC) values compared to the state-of-the-art ISC methods. The latent representations generated by CL-SSTER exhibited reliable spatiotemporal EEG patterns, which can be explained by properties of the naturalistic stimuli. CL-SSTER serves as an interpretable and scalable framework for the identification of inter-subject shared neural representations in naturalistic neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14213v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinke Shen, Lingyi Tao, Xuyang Chen, Sen Song, Quanying Liu, Dan Zhang</dc:creator>
    </item>
    <item>
      <title>Emergence and long-term maintenance of modularity in plastic networks of spiking neurons</title>
      <link>https://arxiv.org/abs/2405.18587</link>
      <description>arXiv:2405.18587v2 Announce Type: replace 
Abstract: In the last three decades it has become clear that cortical regions, interconnected via white-matter fibers, form a modular and hierarchical network. This organization, which has also been seen at the microscopic level in the form of interconnected neural assemblies, is believed to support the coexistence of segregation (specialization) and integration (binding) of information. A fundamental open question is to understand how this complex structure can emerge in the brain. Here, we made a first step to address this question and propose that adaptation to various inputs could be the key driving mechanism for the formation of structural assemblies. To test this idea, we develop a model of quadratic integrate-and-fire spiking neurons, trained to stimuli targetting distinct sub-populations. The model is designed to satisfy several biologically plausible constraints: (i) the network contains excitatory and inhibitory neurons with Hebbian and anti-Hebbian STDP; and (ii) neither the neuronal activity nor the synaptic weights are frozen after the learning phase. Instead, the network continues firing spontaneously while synaptic plasticity remains active. We find that only the combination of the two inhibitory STDP sub-populations allows for the formation of stable modular organization in the network, with each sub-population playing a distinct role. The Hebbian sub-population controls for the firing rate and the anti-Hebbian mediates pattern selectivity. After the learning phase, the network activity settles into an asynchronous irregular resting-state, resembling the behaviour typically observed in-vivo in the cortex. This post-learning activity also displays spontaneous memory recalls, which are fundamental for the long-term consolidation of the learned memory items. The model introduced represents a starting point for the joint investigation of neural dynamics, connectivity and plasticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18587v2</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rapha\"el Bergoin, Alessandro Torcini, Gustavo Deco, Mathias Quoy, Gorka Zamora-L\'opez</dc:creator>
    </item>
    <item>
      <title>Nonequilibrium dynamics and thermodynamics provide the underlying physical mechanism of the perceptual rivalry</title>
      <link>https://arxiv.org/abs/2407.00350</link>
      <description>arXiv:2407.00350v2 Announce Type: replace 
Abstract: Perceptual rivalry, where conflicting sensory information leads to alternating perceptions crucial for associated cognitive function, has attracted researcher's attention for long. Despite progresses being made, recent studies have revealed limitations and inconsistencies in our understanding across various rivalry contexts. We develop a unified physical framework, where perception undergoes a consecutive phase transition process encompassing different multi-state competitions. We reveal the underlying mechanisms of perceptual rivalry by identifying dominant switching paths among perceptual states and quantifying mean perceptual durations, switching frequencies, and proportions of different perceptions. We uncover the underlying nonequilibrium dynamics and thermodynamics by analyzing average nonequilibrium flux and entropy production rate, while associated time series irreversibility reflects the underlying nonequilibrium mechanism of perceptual rivalry and link thermodynamical results with neuro-electrophysiological experiments. Our framework provides a global and physical understanding of brain perception, which may go beyond cognitive science or psychology but embodies the connection with wider fields as decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00350v2</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuxuan Wu, Liufang Xu, Jin Wang</dc:creator>
    </item>
    <item>
      <title>Meta-Learning Strategies through Value Maximization in Neural Networks</title>
      <link>https://arxiv.org/abs/2310.19919</link>
      <description>arXiv:2310.19919v2 Announce Type: replace-cross 
Abstract: Biological and artificial learning agents face numerous choices about how to learn, ranging from hyperparameter selection to aspects of task distributions like curricula. Understanding how to make these meta-learning choices could offer normative accounts of cognitive control functions in biological learners and improve engineered systems. Yet optimal strategies remain challenging to compute in modern deep networks due to the complexity of optimizing through the entire learning process. Here we theoretically investigate optimal strategies in a tractable setting. We present a learning effort framework capable of efficiently optimizing control signals on a fully normative objective: discounted cumulative performance throughout learning. We obtain computational tractability by using average dynamical equations for gradient descent, available for simple neural network architectures. Our framework accommodates a range of meta-learning and automatic curriculum learning methods in a unified normative setting. We apply this framework to investigate the effect of approximations in common meta-learning algorithms; infer aspects of optimal curricula; and compute optimal neuronal resource allocation in a continual learning setting. Across settings, we find that control effort is most beneficial when applied to easier aspects of a task early in learning; followed by sustained effort on harder aspects. Overall, the learning effort framework provides a tractable theoretical test bed to study normative benefits of interventions in a variety of learning systems, as well as a formal account of optimal cognitive control strategies over learning trajectories posited by established theories in cognitive neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19919v2</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Carrasco-Davis, Javier Mas\'is, Andrew M. Saxe</dc:creator>
    </item>
  </channel>
</rss>
