<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Sep 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Incorporating Visual Cortical Lateral Connection Properties into CNN: Recurrent Activation and Excitatory-Inhibitory Separation</title>
      <link>https://arxiv.org/abs/2509.15460</link>
      <description>arXiv:2509.15460v1 Announce Type: new 
Abstract: The original Convolutional Neural Networks (CNNs) and their modern updates such as the ResNet are heavily inspired by the mammalian visual system. These models include afferent connections (retina and LGN to the visual cortex) and long-range projections (connections across different visual cortical areas). However, in the mammalian visual system, there are connections within each visual cortical area, known as lateral (or horizontal) connections. These would roughly correspond to connections within CNN feature maps, and this important architectural feature is missing in current CNN models. In this paper, we present how such lateral connections can be modeled within the standard CNN framework, and test its benefits and analyze its emergent properties in relation to the biological visual system. We will focus on two main architectural features of lateral connections: (1) recurrent activation and (2) separation of excitatory and inhibitory connections. We show that recurrent CNN using weight sharing is equivalent to lateral connections, and propose a custom loss function to separate excitatory and inhibitory weights. The addition of these two leads to increased classification accuracy, and importantly, the activation properties and connection properties of the resulting model show properties similar to those observed in the biological visual system. We expect our approach to help align CNN closer to its biological counterpart and better understand the principles of visual cortical computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15460v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jin Hyun Park, Cheng Zhang, Yoonsuck Choe</dc:creator>
    </item>
    <item>
      <title>Overcoming Output Dimension Collapse: How Sparsity Enables Zero-shot Brain-to-Image Reconstruction at Small Data Scales</title>
      <link>https://arxiv.org/abs/2509.15832</link>
      <description>arXiv:2509.15832v1 Announce Type: new 
Abstract: Advances in brain-to-image reconstruction are enabling us to externalize the subjective visual experiences encoded in the brain as images. Achieving such reconstruction with limited training data requires generalization beyond the training set, a task known as zero-shot prediction. Despite its importance, we still lack theoretical guidelines for achieving efficient and accurate reconstruction. In this paper, we provide a theoretical analysis of two widely used models for translating brain activity to latent image features. We define the data scale as the ratio of the number of training samples to the latent feature dimensionality and characterize how each model behaves across data scales. We first show that the naive linear regression model, which uses a shared set of input variables for all outputs, suffers from "output dimension collapse" at small data scales, restricting generalization beyond the training data. We then mathematically characterize the prediction error of the sparse linear regression model by deriving formulas linking prediction error with data scale and other problem parameters. Leveraging the sparsity of the brain-to-feature mapping, this approach enables accurate zero-shot prediction even at small data scales without trapping in output dimension collapse. Our results provide a theoretical guideline for achieving zero-shot reconstruction and highlight the benefits of variable selection in brain-to-image reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15832v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenya Otsuka, Yoshihiro Nagano, Yukiyasu Kamitani</dc:creator>
    </item>
    <item>
      <title>A Hypothesis-First Framework for Mechanistic Model Evaluation and Selection in Neuroimaging</title>
      <link>https://arxiv.org/abs/2509.16070</link>
      <description>arXiv:2509.16070v1 Announce Type: new 
Abstract: Neuroimaging provides rich measurements of brain structure and neural activity, but turning these data into mechanistic insight remains difficult. Statistical models quantify associations without much considerations for how they arise, whereas bio-realistic models directly embody candidate mechanisms but remain hard to deploy rigorously without specialized training. We present a framework that recasts modeling choices as testable mechanistic hypotheses and supplies a simple protocol for rejecting inappropriate model specifications, such as under-/over-parameterization or invalid simplifying assumptions, based on predefined criteria before any parameter inference. The key idea is expected model behavior under feature generalization constraints: instead of judging a model solely by how well it fits a specific target feature of interest Y at an optimal parameter set, we evaluate the model's expected Y output when the model is constrained to reproduce a broader, or distinct, feature Z over the entire parameter space. We then assess whether a mirror statistical model, derived from the model's expected Y outputs, to the empirical statistical model using standard statistics. In synthetic experiments with known ground truth (Wilson Cowan dynamics), the framework correctly rejects mis-specified hypotheses, penalizes unnecessary degrees of freedom, and preserves valid specifications. This provides a practical, hypothesis-first route to using mechanistic models for neuroimaging without requiring expert-level methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16070v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominic Boutet, Sylvain Baillet</dc:creator>
    </item>
    <item>
      <title>Kuramoto Orientation Diffusion Models</title>
      <link>https://arxiv.org/abs/2509.15328</link>
      <description>arXiv:2509.15328v1 Announce Type: cross 
Abstract: Orientation-rich images, such as fingerprints and textures, often exhibit coherent angular directional patterns that are challenging to model using standard generative approaches based on isotropic Euclidean diffusion. Motivated by the role of phase synchronization in biological systems, we propose a score-based generative model built on periodic domains by leveraging stochastic Kuramoto dynamics in the diffusion process. In neural and physical systems, Kuramoto models capture synchronization phenomena across coupled oscillators -- a behavior that we re-purpose here as an inductive bias for structured image generation. In our framework, the forward process performs \textit{synchronization} among phase variables through globally or locally coupled oscillator interactions and attraction to a global reference phase, gradually collapsing the data into a low-entropy von Mises distribution. The reverse process then performs \textit{desynchronization}, generating diverse patterns by reversing the dynamics with a learned score function. This approach enables structured destruction during forward diffusion and a hierarchical generation process that progressively refines global coherence into fine-scale details. We implement wrapped Gaussian transition kernels and periodicity-aware networks to account for the circular geometry. Our method achieves competitive results on general image benchmarks and significantly improves generation quality on orientation-dense datasets like fingerprints and textures. Ultimately, this work demonstrates the promise of biologically inspired synchronization dynamics as structured priors in generative modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15328v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yue Song, T. Anderson Keller, Sevan Brodjian, Takeru Miyato, Yisong Yue, Pietro Perona, Max Welling</dc:creator>
    </item>
    <item>
      <title>Modeling Adaptive Tracking of Predictable Stimuli in Electric Fish</title>
      <link>https://arxiv.org/abs/2509.15344</link>
      <description>arXiv:2509.15344v1 Announce Type: cross 
Abstract: The weakly electric fish \emph{Eigenmannia virescens} naturally swims back and forth to stay within a moving refuge, tracking its motion using visual and electrosensory feedback. Previous experiments show that when the refuge oscillates as a low-frequency sinusoid (below about 0.5 Hz), the tracking is nearly perfect, but phase lag increases and gain decreases at higher frequencies. Here, we model this nonlinear behavior as an adaptive internal model principle (IMP) system. Specifically, an adaptive state estimator identifies the \emph{a priori} unknown frequency, and feeds this parameter estimate into a closed-loop IMP-based system built around a lightly damped harmonic oscillator. We prove that the closed-loop tracking error of the IMP-based system, where the online adaptive frequency estimate is used as a surrogate for the unknown frequency, converges exponentially to that of an ideal control system with perfect information about the stimulus. Simulations further show that our model reproduces the fish refuge tracking Bode plot across a wide frequency range. These results establish the theoretical validity of combining the IMP with an adaptive identification process and provide a basic framework in adaptive sensorimotor control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15344v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yu Yang, Andreas Oliveira, Louis L. Whitcomb, Felipe Pait, Mario Sznaier, Noah J. Cowan</dc:creator>
    </item>
    <item>
      <title>Hybrid Lie semi-group and cascade structures for the generalized Gaussian derivative model for visual receptive fields</title>
      <link>https://arxiv.org/abs/2509.15748</link>
      <description>arXiv:2509.15748v1 Announce Type: cross 
Abstract: Because of the variabilities of real-world image structures under the natural image transformations that arise when observing similar objects or spatio-temporal events under different viewing conditions, the receptive field responses computed in the earliest layers of the visual hierarchy may be strongly influenced by such geometric image transformations. One way of handling this variability is by basing the vision system on covariant receptive field families, which expand the receptive field shapes over the degrees of freedom in the image transformations.
  This paper addresses the problem of deriving relationships between spatial and spatio-temporal receptive field responses obtained for different values of the shape parameters in the resulting multi-parameter families of receptive fields. For this purpose, we derive both (i) infinitesimal relationships, roughly corresponding to a combination of notions from semi-groups and Lie groups, as well as (ii) macroscopic cascade smoothing properties, which describe how receptive field responses at coarser spatial and temporal scales can be computed by applying smaller support incremental filters to the output from corresponding receptive fields at finer spatial and temporal scales, structurally related to the notion of Lie algebras, although with directional preferences.
  The presented results provide (i) a deeper understanding of the relationships between spatial and spatio-temporal receptive field responses for different values of the filter parameters, which can be used for both (ii) designing more efficient schemes for computing receptive field responses over populations of multi-parameter families of receptive fields, as well as (iii)~formulating idealized theoretical models of the computations of simple cells in biological vision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15748v1</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
  </channel>
</rss>
