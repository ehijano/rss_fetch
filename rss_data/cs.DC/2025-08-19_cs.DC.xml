<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Aug 2025 01:23:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Proceedings 18th Interaction and Concurrency Experience</title>
      <link>https://arxiv.org/abs/2508.12308</link>
      <description>arXiv:2508.12308v1 Announce Type: new 
Abstract: This volume contains the proceedings of ICE'25, the 18th Interaction and Concurrency Experience, which was held on Friday 20th June 2025 at the \'Ecole National Sup\'erieure des Arts et M\'etiers in Lille, France, as a satellite workshop of DisCoTec 2025. The ICE workshop series features a distinguishing review and selection procedure: PC members are encouraged to interact, anonymously, with authors. The 2025 edition of ICE received 7 submissions, each reviewed by three PC members, and about 75 comments were exchanged during the review process, witnessing very lively discussions. Four papers were accepted for publication plus 1 oral communication, which was accepted for presentation at the workshop. We were proud to host one invited talk, by Kirstin Peters. The abstract of her talk is included in this volume, together with the final versions of the research papers, which take into account the discussion at the workshop and during the review process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12308v1</guid>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.425</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 425, 2025</arxiv:journal_reference>
      <dc:creator>Cl\'ement Aubert (Augusta University), Cinzia Di Giusto (Universit\'e C\^ote d'Azur, CNRS, I3SSophia Antipolis), Simon Fowler (University of Glasgow School of Computing Science), Violet Ka I Pun (Western Norway University of Applied Sciences)</dc:creator>
    </item>
    <item>
      <title>Breaking the Aggregation Bottleneck in Federated Recommendation: A Personalized Model Merging Approach</title>
      <link>https://arxiv.org/abs/2508.12386</link>
      <description>arXiv:2508.12386v1 Announce Type: new 
Abstract: Federated recommendation (FR) facilitates collaborative training by aggregating local models from massive devices, enabling client-specific personalization while ensuring privacy. However, we empirically and theoretically demonstrate that server-side aggregation can undermine client-side personalization, leading to suboptimal performance, which we term the aggregation bottleneck. This issue stems from the inherent heterogeneity across numerous clients in FR, which drives the globally aggregated model to deviate from local optima. To this end, we propose FedEM, which elastically merges the global and local models to compensate for impaired personalization. Unlike existing personalized federated recommendation (pFR) methods, FedEM (1) investigates the aggregation bottleneck in FR through theoretical insights, rather than relying on heuristic analysis; (2) leverages off-the-shelf local models rather than designing additional mechanisms to boost personalization. Extensive experiments on real-world datasets demonstrate that our method preserves client personalization during collaborative training, outperforming state-of-the-art baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12386v1</guid>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jundong Chen, Honglei Zhang, Chunxu Zhang, Fangyuan Luo, Yidong Li</dc:creator>
    </item>
    <item>
      <title>DIT: Dimension Reduction View on Optimal NFT Rarity Meters</title>
      <link>https://arxiv.org/abs/2508.12671</link>
      <description>arXiv:2508.12671v1 Announce Type: new 
Abstract: Non-fungible tokens (NFTs) have become a significant digital asset class, each uniquely representing virtual entities such as artworks. These tokens are stored in collections within smart contracts and are actively traded across platforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is closely tied to their distinctive characteristics that define rarity, leading to a growing interest in quantifying rarity within both industry and academia. While there are existing rarity meters for assessing NFT rarity, comparing them can be challenging without direct access to the underlying collection data. The Rating over all Rarities (ROAR) benchmark addresses this challenge by providing a standardized framework for evaluating NFT rarity. This paper explores a dimension reduction approach to rarity design, introducing new performance measures and meters, and evaluates them using the ROAR benchmark. Our contributions to the rarity meter design issue include developing an optimal rarity meter design using non-metric weighted multidimensional scaling, introducing Dissimilarity in Trades (DIT) as a performance measure inspired by dimension reduction techniques, and unveiling the non-interpretable rarity meter DIT, which demonstrates superior performance compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12671v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitry Belousov, Yury Yanovich</dc:creator>
    </item>
    <item>
      <title>Dissecting CPU-GPU Unified Physical Memory on AMD MI300A APUs</title>
      <link>https://arxiv.org/abs/2508.12743</link>
      <description>arXiv:2508.12743v1 Announce Type: new 
Abstract: Discrete GPUs are a cornerstone of HPC and data center systems, requiring management of separate CPU and GPU memory spaces. Unified Virtual Memory (UVM) has been proposed to ease the burden of memory management; however, at a high cost in performance. The recent introduction of AMD's MI300A Accelerated Processing Units (APUs)--as deployed in the El Capitan supercomputer--enables HPC systems featuring integrated CPU and GPU with Unified Physical Memory (UPM) for the first time. This work presents the first comprehensive characterization of the UPM architecture on MI300A. We first analyze the UPM system properties, including memory latency, bandwidth, and coherence overhead. We then assess the efficiency of the system software in memory allocation, page fault handling, TLB management, and Infinity Cache utilization. We propose a set of porting strategies for transforming applications for the UPM architecture and evaluate six applications on the MI300A APU. Our results show that applications on UPM using the unified memory model can match or outperform those in the explicitly managed model--while reducing memory costs by up to 44%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12743v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Wahlgren, Gabin Schieffer, Ruimin Shi, Edgar A. Le\'on, Roger Pearce, Maya Gokhale, Ivy Peng</dc:creator>
    </item>
    <item>
      <title>Accelerating Edge Inference for Distributed MoE Models with Latency-Optimized Expert Placement</title>
      <link>https://arxiv.org/abs/2508.12851</link>
      <description>arXiv:2508.12851v1 Announce Type: new 
Abstract: Mixture-of-Experts (MoE) have become a cornerstone for training and scaling large language models (LLMs), offering substantial gains in model capacity and efficiency through sparse expert activation. However, serving these models remains challenging in practice, particularly in resource-constrained edge environments, due to their large memory footprint and complex communication demands. While centralized cloud inference is common, it incurs high infrastructure costs, along with latency and privacy concerns. A few recent edge MoE works propose memory-efficient strategies but typically focus on single-device or homogeneous setups. This paper presents DanceMoE, an efficient MoE inference framework that enables activation-aware expert placement across collaborative, heterogeneous, GPU-equipped edge servers. DanceMoE leverages the inherent sparsity of MoE models and workload locality to minimize cross-server communication and enable efficient expert placement under heterogeneous resource constraints. It introduces a data-driven, activation-aware placement algorithm that balances local coverage and memory usage across servers, alongside a lightweight migration mechanism that adapts expert assignments under evolving workloads. We evaluate DanceMoE on modern MoE models and widely used datasets, demonstrating up to 30.6\% lower inference latency, and substantial communication reduction compared to state-of-the-art baselines, showcasing the effectiveness of collaborative edge-based MoE inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12851v1</guid>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tian Wu, Liming Wang, Zijian Wen, Xiaoxi Zhang, Jingpu Duan, Xianwei Zhang, Jinhang Zuo</dc:creator>
    </item>
    <item>
      <title>WANify: Gauging and Balancing Runtime WAN Bandwidth for Geo-distributed Data Analytics</title>
      <link>https://arxiv.org/abs/2508.12961</link>
      <description>arXiv:2508.12961v1 Announce Type: new 
Abstract: Accurate wide area network (WAN) bandwidth (BW) is essential for geo-distributed data analytics (GDA) systems to make optimal decisions such as data and task placement to improve performance. Existing GDA systems, however, measure WAN BW statically and independently between data centers (DCs), while data transfer occurs dynamically and simultaneously among DCs during workload execution. Also, they use a single connection WAN BW that cannot capture actual WAN capacities between distant DCs. Such inaccurate WAN BWs yield sub-optimal decisions, inflating overall query latency and cost. In this paper, we present WANify, a new framework that precisely and dynamically gauges achievable runtime WAN BW using a machine learning prediction scheme, decision tree-based Random Forest. This helps GDA systems make better decisions yielding reduced latency and costs including WAN BW monitoring costs. Based on predicted runtime WAN BW, WANify determines the optimal number of heterogeneous parallel connections for data transfer among DCs. This approach improves performance without additional, or even at reduced cost, by fully exploiting available WAN capacities. In addition, WANify considers dynamics like network and workloads, and heterogeneity like skewed data, heterogeneous compute resources, and a varying number of DCs while making decisions. The WANify prototype running on state-of-the-art GDA systems is evaluated on AWS with 8 geo-distributed DCs. Results show that WANify enhances WAN throughput by balancing between the strongest and weakest WAN links, enabling GDA systems to reduce latency and cost by up to 26% and 16% respectively with minimal effort, all while handling dynamics and heterogeneity efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12961v1</guid>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anshuman Das Mohapatra, Kwangsung Oh</dc:creator>
    </item>
    <item>
      <title>Congested Clique Counting for Local Gibbs Distributions</title>
      <link>https://arxiv.org/abs/2508.13083</link>
      <description>arXiv:2508.13083v1 Announce Type: new 
Abstract: There are well established reductions between combinatorial sampling and counting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very recent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv 2024), we demonstrate the first approximate counting algorithm in the CongestedClique for a wide range of problems. Most interestingly, we present an algorithm for approximating the number of $q$-colorings of a graph within $\epsilon$-multiplicative error, when $q&gt;\alpha\Delta$ for any constant $\alpha&gt;2$, in $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds. More generally, we achieve a runtime of $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds for approximating the partition function of Gibbs distributions defined over graphs when simple locality and fast mixing conditions hold. Gibbs distributions are widely used in fields such as machine learning and statistical physics. We obtain our result by providing an algorithm to draw $n$ random samples from a distributed Markov chain in parallel, using similar ideas to triangle counting (Dolev, Lenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel, Kaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems, this result may be interesting for other applications requiring a large number of samples. In the special case of estimating the partition function of the hardcore model, also known as counting weighted independent sets, we can do even better and achieve an $\Tilde{O}\big(\frac{1}{\epsilon^2}\big)$ round algorithm, when the fugacity $\lambda \leq \frac{\alpha}{\Delta-1}$, where $\alpha$ is an arbitrary constant less than $1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13083v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Z. Sobel</dc:creator>
    </item>
    <item>
      <title>Team Formation and Applications</title>
      <link>https://arxiv.org/abs/2508.13084</link>
      <description>arXiv:2508.13084v1 Announce Type: new 
Abstract: A novel long-lived distributed problem, called Team Formation (TF), is introduced together with a message- and time-efficient randomized algorithm. The problem is defined over the asynchronous model with a complete communication graph, using bounded size messages, where a certain fraction of the nodes may experience a generalized, strictly stronger, version of initial failures. The goal of a TF algorithm is to assemble tokens injected by the environment, in a distributed manner, into teams of size $\sigma$, where $\sigma$ is a parameter of the problem.
  The usefulness of TF is demonstrated by using it to derive efficient algorithms for many distributed problems. Specifically, we show that various (one-shot as well as long-lived) distributed problems reduce to TF. This includes well-known (and extensively studied) distributed problems such as several versions of leader election and threshold detection. For example, we are the first to break the linear message complexity bound for asynchronous implicit leader election. We also improve the time complexity of message-optimal algorithms for asynchronous explicit leader election. Other distributed problems that reduce to TF are new ones, including matching players in online gaming platforms, a generalization of gathering, constructing a perfect matching in an induced subgraph of the complete graph, quorum sensing in message-passing networks, and more. To complement our positive contribution, we establish a tight lower bound on the message complexity of TF algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13084v1</guid>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuval Emek, Shay Kutten, Ido Rafael, Gadi Taubenfeld</dc:creator>
    </item>
    <item>
      <title>AegisBlock: A Privacy-Preserving Medical Research Framework using Blockchain</title>
      <link>https://arxiv.org/abs/2508.11797</link>
      <description>arXiv:2508.11797v1 Announce Type: cross 
Abstract: Due to HIPAA and other privacy regulations, it is imperative to maintain patient privacy while conducting research on patient health records. In this paper, we propose AegisBlock, a patient-centric access controlled framework to share medical records with researchers such that the anonymity of the patient is maintained while ensuring the trustworthiness of the data provided to researchers. AegisBlock allows for patients to provide access to their medical data, verified by miners. A researcher submits a time-based range query to request access to records from a certain patient, and upon patient approval, access will be granted. Our experimental evaluation results show that AegisBlock is scalable with respect to the number of patients and hospitals in the system, and efficient with up to 50% of malicious miners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11797v1</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Calkin Garg, Omar Rios Cruz, Tessa Andersen, Gaby G. Dagher, Donald Winiecki, Min Long</dc:creator>
    </item>
    <item>
      <title>FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing</title>
      <link>https://arxiv.org/abs/2508.12021</link>
      <description>arXiv:2508.12021v1 Announce Type: cross 
Abstract: Unsupervised federated learning (UFL) has gained attention as a privacy-preserving, decentralized machine learning approach that eliminates the need for labor-intensive data labeling. However, UFL faces several challenges in practical applications: (1) non-independent and identically distributed (non-iid) data distribution across devices, (2) expensive computational and communication costs at the edge, and (3) vulnerability to communication noise. Previous UFL approaches have relied on deep neural networks (NN), which introduce substantial overhead in both computation and communication. In this paper, we propose FedUHD, the first UFL framework based on Hyperdimensional Computing (HDC). HDC is a brain-inspired computing scheme with lightweight training and inference operations, much smaller model size, and robustness to communication noise. FedUHD introduces two novel HDC-based designs to improve UFL performance. On the client side, a kNN-based cluster hypervector removal method addresses non-iid data samples by eliminating detrimental outliers. On the server side, a weighted HDC aggregation technique balances the non-iid data distribution across clients. Our experiments demonstrate that FedUHD achieves up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in training, up to 271x lower communication cost, and 15.50% higher accuracy on average across diverse settings, along with superior robustness to various types of noise compared to state-of-the-art NN-based UFL approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12021v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>You Hak Lee, Xiaofan Yu, Quanling Zhao, Flavio Ponzina, Tajana Rosing</dc:creator>
    </item>
    <item>
      <title>Attack Graph Generation on HPC Clusters</title>
      <link>https://arxiv.org/abs/2508.12161</link>
      <description>arXiv:2508.12161v1 Announce Type: cross 
Abstract: Attack graphs (AGs) are graphical tools to analyze the security of computer networks. By connecting the exploitation of individual vulnerabilities, AGs expose possible multi-step attacks against target networks, allowing system administrators to take preventive measures to enhance their network's security. As powerful analytical tools, however, AGs are both time- and memory-consuming to be generated. As the numbers of network assets, interconnections between devices, as well as vulnerabilities increase, the size and volume of the resulting AGs grow at a much higher rate, leading to the well-known state-space explosion. In this paper, we propose the use of high performance computing (HPC) clusters to implement AG generators. We evaluate the performance through experiments and provide insights into how cluster environments can help resolve the issues of slow speed and high memory demands in AG generation in a balanced way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12161v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-85638-9_9</arxiv:DOI>
      <arxiv:journal_reference>Parallel and Distributed Processing Techniques. CSCE 2024. Communications in Computer and Information Science, vol 2256. Pages 120-129</arxiv:journal_reference>
      <dc:creator>Ming Li, John Hale</dc:creator>
    </item>
    <item>
      <title>A Large-Scale Web Search Dataset for Federated Online Learning to Rank</title>
      <link>https://arxiv.org/abs/2508.12353</link>
      <description>arXiv:2508.12353v1 Announce Type: cross 
Abstract: The centralized collection of search interaction logs for training ranking models raises significant privacy concerns. Federated Online Learning to Rank (FOLTR) offers a privacy-preserving alternative by enabling collaborative model training without sharing raw user data. However, benchmarks in FOLTR are largely based on random partitioning of classical learning-to-rank datasets, simulated user clicks, and the assumption of synchronous client participation. This oversimplifies real-world dynamics and undermines the realism of experimental results. We present AOL4FOLTR, a large-scale web search dataset with 2.6 million queries from 10,000 users. Our dataset addresses key limitations of existing benchmarks by including user identifiers, real click data, and query timestamps, enabling realistic user partitioning, behavior modeling, and asynchronous federated learning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12353v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3746252.3761651</arxiv:DOI>
      <dc:creator>Marcel Gregoriadis, Jingwei Kang, Johan Pouwelse</dc:creator>
    </item>
    <item>
      <title>Data-driven Trust Bootstrapping for Mobile Edge Computing-based Industrial IoT Services</title>
      <link>https://arxiv.org/abs/2508.12560</link>
      <description>arXiv:2508.12560v1 Announce Type: cross 
Abstract: We propose a data-driven and context-aware approach to bootstrap trustworthiness of homogeneous Internet of Things (IoT) services in Mobile Edge Computing (MEC) based industrial IoT (IIoT) systems. The proposed approach addresses key limitations in adapting existing trust bootstrapping approaches into MEC-based IIoT systems. These key limitations include, the lack of opportunity for a service consumer to interact with a lesser-known service over a prolonged period of time to get a robust measure of its trustworthiness, inability of service consumers to consistently interact with their peers to receive reliable recommendations of the trustworthiness of a lesser-known service as well as the impact of uneven context parameters in different MEC environments causing uneven trust environments for trust evaluation. In addition, the proposed approach also tackles the problem of data sparsity via enabling knowledge sharing among different MEC environments within a given MEC topology. To verify the effectiveness of the proposed approach, we carried out a comprehensive evaluation on two real-world datasets suitably adjusted to exhibit the context-dependent trust information accumulated in MEC environments within a given MEC topology. The experimental results affirmed the effectiveness of our approach and its suitability to bootstrap trustworthiness of services in MEC-based IIoT systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12560v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prabath Abeysekara, Hai Dong</dc:creator>
    </item>
    <item>
      <title>Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning</title>
      <link>https://arxiv.org/abs/2508.12978</link>
      <description>arXiv:2508.12978v1 Announce Type: cross 
Abstract: We propose Fed-DPRoC, a novel federated learning framework that simultaneously ensures differential privacy (DP), Byzantine robustness, and communication efficiency. We introduce the concept of robust-compatible compression, which enables users to compress DP-protected updates while maintaining the robustness of the aggregation rule. We instantiate our framework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for compression with robust averaging for robust aggregation. We theoretically prove the compatibility of JL transform with robust averaging and show that RobAJoL preserves robustness guarantees, ensures DP, and reduces communication cost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims and demonstrate that RobAJoL outperforms existing methods in terms of robustness and utility under different Byzantine attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12978v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Xia, Tayyebeh Jahani-Nezhad, Rawad Bitar</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Sparse Allreduce for Distributed Deep Learning</title>
      <link>https://arxiv.org/abs/2201.07598</link>
      <description>arXiv:2201.07598v3 Announce Type: replace 
Abstract: Communication overhead is one of the major obstacles to train large deep learning models at scale. Gradient sparsification is a promising technique to reduce the communication volume. However, it is very challenging to obtain real performance improvement because of (1) the difficulty of achieving an scalable and efficient sparse allreduce algorithm and (2) the sparsification overhead. This paper proposes O$k$-Top$k$, a scheme for distributed training with sparse gradients. O$k$-Top$k$ integrates a novel sparse allreduce algorithm (less than 6$k$ communication volume which is asymptotically optimal) with the decentralized parallel Stochastic Gradient Descent (SGD) optimizer, and its convergence is proved. To reduce the sparsification overhead, O$k$-Top$k$ efficiently selects the top-$k$ gradient values according to an estimated threshold. Evaluations are conducted on the Piz Daint supercomputer with neural network models from different deep learning domains. Empirical results show that O$k$-Top$k$ achieves similar model accuracy to dense allreduce. Compared with the optimized dense and the state-of-the-art sparse allreduces, O$k$-Top$k$ is more scalable and significantly improves training throughput (e.g., 3.29x-12.95x improvement for BERT on 256 GPUs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.07598v3</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3503221.3508399</arxiv:DOI>
      <dc:creator>Shigang Li, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>PhoenixOS: Concurrent OS-level GPU Checkpoint and Restore with Validated Speculation</title>
      <link>https://arxiv.org/abs/2405.12079</link>
      <description>arXiv:2405.12079v3 Announce Type: replace 
Abstract: PHOENIXOS (PHOS) is the first OS service that can concurrently checkpoint and restore (C/R) GPU processes -- a fundamental capability for critical tasks such as fault tolerance, process migration, and fast startup. While concurrent C/R is well-established on CPUs, it poses unique challenges on GPUs due to their lack of essential features for efficiently tracing concurrent memory reads and writes, such as specific hardware capabilities (e.g., dirty bits) and OS-mediated data paths (e.g., copy-on-write).
  To ensure correct concurrent C/R, PHOS proactively detects GPU memory reads and writes through a two-step process: first, it speculates about GPU memory accesses based on the arguments used when launching GPU kernels; then, it validates these accesses efficiently at runtime using binary instrumentation. With this validated speculation, PHOS retrofits CPU-based concurrent C/R for GPUs through software-based approaches, including soft copy-on-write, soft recopy, and soft on-demand restore. PHOS further proposes several GPU-aware techniques for efficient GPU C/R, including coordinated checkpoint data transfer and execution context pool. For downstream tasks that use C/R for tolerating failures, migrating processes between machines, and accelerating cold starts in serverless computing, PHOS achieves orders of magnitude higher performance than state-of-the-art OS-level GPU C/R systems like NVIDIA cuda-checkpoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12079v3</guid>
      <category>cs.DC</category>
      <category>cs.OS</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingda Wei, Zhuobin Huang, Tianle Sun, Yingyi Hao, Rong Chen, Mingcong Han, Jinyu Gu, Haibo Chen</dc:creator>
    </item>
    <item>
      <title>A Distributed Partitioning Software and its Applications</title>
      <link>https://arxiv.org/abs/2503.02185</link>
      <description>arXiv:2503.02185v2 Announce Type: replace 
Abstract: This article describes a geometric partitioning software that can be used for quick computation of data partitions on many-core HPC machines. It is most suited for dynamic applications with load distributions that vary with time. Partitioning costs were minimized with a lot of care, to tolerate frequent adjustments to the load distribution. The partitioning algorithm uses both geometry as well as statistics collected from the data distribution. The implementation is based on a hybrid programming model that is both distributed and multi-threaded. Partitions are computed by a hierarchical data decomposition, followed by data ordering using space-filling curves and greedy knapsack. This software was primarily used for partitioning 2 and 3 dimensional meshes in scientific computing. It was also used to solve point-location problems and for partitioning general graphs. The experiments described in this paper provide useful performance data for important parallel algorithms on a HPC machine built using a recent many-core processor designed for data-intensive applications by providing large on-chip memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02185v2</guid>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aparna Sasidharan</dc:creator>
    </item>
    <item>
      <title>An overview of the efficiency and censorship-resistance guarantees of widely-used consensus protocols</title>
      <link>https://arxiv.org/abs/2504.03588</link>
      <description>arXiv:2504.03588v2 Announce Type: replace 
Abstract: Censorship resistance with short-term inclusion guarantees is an important feature of decentralized systems, missing from many state-of-the-art and even deployed consensus protocols. In leader-based protocols the leader arbitrarily selects the transactions to be included in the new block, and so does a block builder in protocols such as Bitcoin and Ethereum.
  In a different line of work, since the redundancy of consensus for implementing distributed payments was formally proven, consensusless protocols have been described in theory and deployed in the real world. This has resulted in blockchains and payment systems that are more efficient, and at the same time avoid the centralized role of a leader or block builder.
  In this report we review existing consensus and consensusless protocols with regard to their censorship-resistance, efficiency, and other properties. Moreover, we present an approach for new constructions with these properties in mind, building on existing leader-based protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03588v2</guid>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Orestis Alpos, Bernardo David, Nikolas Kamarinakis, Dionysis Zindros</dc:creator>
    </item>
    <item>
      <title>Inter-APU Communication on AMD MI300A Systems via Infinity Fabric: a Deep Dive</title>
      <link>https://arxiv.org/abs/2508.11298</link>
      <description>arXiv:2508.11298v2 Announce Type: replace 
Abstract: The ever-increasing compute performance of GPU accelerators drives up the need for efficient data movements within HPC applications to sustain performance. Proposed as a solution to alleviate CPU-GPU data movement, AMD MI300A Accelerated Processing Unit (APU) combines CPU, GPU, and high-bandwidth memory (HBM) within a single physical package. Leadership supercomputers, such as El Capitan, group four APUs within a single compute node, using Infinity Fabric Interconnect. In this work, we design specific benchmarks to evaluate direct memory access from the GPU, explicit inter-APU data movement, and collective multi-APU communication. We also compare the efficiency of HIP APIs, MPI routines, and the GPU-specialized RCCL library. Our results highlight key design choices for optimizing inter-APU communication on multi-APU AMD MI300A systems with Infinity Fabric, including programming interfaces, allocators, and data movement. Finally, we optimize two real HPC applications, Quicksilver and CloverLeaf, and evaluate them on a four MI100A APU system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11298v2</guid>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabin Schieffer, Jacob Wahlgren, Ruimin Shi, Edgar A. Le\'on, Roger Pearce, Maya Gokhale, Ivy Peng</dc:creator>
    </item>
    <item>
      <title>Reputation-based PoS for the Restriction of Illicit Activities on Blockchain: Algorand Usecase</title>
      <link>https://arxiv.org/abs/2112.11024</link>
      <description>arXiv:2112.11024v4 Announce Type: replace-cross 
Abstract: In cryptocurrency-based permissionless blockchain networks, the decentralized structure enables any user to join and operate across different regions. The criminal entities exploit it by using cryptocurrency transactions on the blockchain to facilitate activities such as money laundering, gambling, and ransomware attacks. In recent times, different machine learning-based techniques can detect such criminal elements based on blockchain transaction data. However, there is no provision within the blockchain to deal with such elements. We propose a reputation-based methodology for response to the users detected carrying out the aforementioned illicit activities. We select Algorand blockchain to implement our methodology by incorporating it within the consensus protocol. The theoretical results obtained prove the restriction and exclusion of criminal elements through block proposal rejection and attenuation of the voting power as a validator for such entities. Further, we analyze the efficacy of our method and show that it puts no additional strain on the communication resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.11024v4</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mayank Pandey, Rachit Agarwal, Sandeep Kumar Shukla, Nishchal Kumar Verma</dc:creator>
    </item>
    <item>
      <title>Adversarially-Robust Gossip Algorithms for Approximate Quantile and Mean Computations</title>
      <link>https://arxiv.org/abs/2502.15320</link>
      <description>arXiv:2502.15320v3 Announce Type: replace-cross 
Abstract: This paper presents gossip algorithms for aggregation tasks that demonstrate both robustness to adversarial corruptions of any order of magnitude and optimality across a substantial range of these corruption levels. Gossip algorithms distribute information in a scalable and efficient way by having random pairs of nodes exchange small messages. Value aggregation problems are of particular interest in this setting, as they occur frequently in practice, and many elegant algorithms have been proposed for computing aggregates and statistics such as averages and quantiles. An important and well-studied advantage of gossip algorithms is their robustness to message delays, network churn, and unreliable message transmissions. However, these crucial robustness guarantees only hold if all nodes follow the protocol and no messages are corrupted. In this paper, we remedy this by providing a framework to model both adversarial participants and message corruptions in gossip-style communications by allowing an adversary to control a small fraction of the nodes or corrupt messages arbitrarily. Despite this very powerful and general corruption model, we show that robust gossip algorithms can be designed for many important aggregation problems. Our algorithms guarantee that almost all nodes converge to an approximately correct answer with optimal efficiency and essentially as fast as without corruptions. The design of adversarially-robust gossip algorithms poses completely new challenges. Despite this, our algorithms remain very simple variations of known non-robust algorithms with often only subtle changes to avoid non-compliant nodes gaining too much influence over outcomes. While our algorithms remain simple, their analysis is much more complex and often requires a completely different approach than the non-adversarial setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15320v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Haeupler, Marc Kaufmann, Raghu Raman Ravi, Ulysse Schaller</dc:creator>
    </item>
    <item>
      <title>The Panaceas for Improving Low-Rank Decomposition in Communication-Efficient Federated Learning</title>
      <link>https://arxiv.org/abs/2505.23176</link>
      <description>arXiv:2505.23176v2 Announce Type: replace-cross 
Abstract: To improve the training efficiency of federated learning (FL), previous research has employed low-rank decomposition techniques to reduce communication overhead. In this paper, we seek to enhance the performance of these low-rank decomposition methods. Specifically, we focus on three key issues related to decomposition in FL: what to decompose, how to decompose, and how to aggregate. Subsequently, we introduce three novel techniques: Model Update Decomposition (MUD), Block-wise Kronecker Decomposition (BKD), and Aggregation-Aware Decomposition (AAD), each targeting a specific issue. These techniques are complementary and can be applied simultaneously to achieve optimal performance. Additionally, we provide a rigorous theoretical analysis to ensure the convergence of the proposed MUD. Extensive experimental results show that our approach achieves faster convergence and superior accuracy compared to relevant baseline methods. The code is available at https://github.com/Leopold1423/fedmud-icml25.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23176v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiwei Li, Xiandi Luo, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li</dc:creator>
    </item>
    <item>
      <title>Novel Blockchain-based Protocols for Electronic Voting and Auctions</title>
      <link>https://arxiv.org/abs/2507.03258</link>
      <description>arXiv:2507.03258v2 Announce Type: replace-cross 
Abstract: Programmable blockchains have long been a hot research topic given their tremendous use in decentralized applications. Smart contracts, using blockchains as their underlying technology, inherit the desired properties such as verifiability, immutability, and transparency, which make it a great suit in trustless environments.
  In this thesis, we consider several decentralized protocols to be built on blockchains, specifically using smart contracts on Ethereum. We used algorithmic and cryptographic tools in our implementations to further improve the level of security and efficiency beyond the state-of-the-art works. We proposed a new approach called Blind Vote, which is an untraceable, secure, efficient, secrecy-preserving, and fully on-chain electronic voting protocol based on the well-known concept of Chaum's blind signatures. We illustrate that our approach achieves the same security guarantees as previous methods such as Tornado Vote [1], while consuming significantly less gas. Thus, we provide a cheaper and considerably more gas-efficient alternative for anonymous blockchain-based voting. On the other hand, we propose a new family of algorithms for private, trustless auctions that protect bidder identities and bid values while remaining practical for smart contract execution. We ensure trustlessness by running the auction logic in a smart contract, thereby eliminating reliance on any single trusted party. This approach prevents bid tampering, front-running, and collusion by enforcing immutability and decentralized verification of bids. The resulting protocol uniquely combines efficiency, trustlessness, and enduring bid privacy, offering a scalable and secure solution for blockchain-based marketplaces and other decentralized applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03258v2</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaorun Lin</dc:creator>
    </item>
    <item>
      <title>Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures</title>
      <link>https://arxiv.org/abs/2508.07423</link>
      <description>arXiv:2508.07423v2 Announce Type: replace-cross 
Abstract: As the particle physics community needs higher and higher precisions in order to test our current model of the subatomic world, larger and larger datasets are necessary. With upgrades scheduled for the detectors of colliding-beam experiments around the world, and specifically at the Large Hadron Collider at CERN, more collisions and more complex interactions are expected. This directly implies an increase in data produced and consequently in the computational resources needed to process them. At CERN, the amount of data produced is gargantuan. This is why the data have to be heavily filtered and selected in real time before being permanently stored. This data can then be used to perform physics analyses, in order to expand our current understanding of the universe and improve the Standard Model of physics. This real-time filtering, known as triggering, involves complex processing happening often at frequencies as high as 40 MHz. This thesis contributes to understanding how machine learning models can be efficiently deployed in such environments, in order to maximize throughput and minimize energy consumption. Inevitably, modern hardware designed for such tasks and contemporary algorithms are needed in order to meet the challenges posed by the stringent, high-frequency data rates. In this work, I present our graph neural network-based pipeline, developed for charged particle track reconstruction at the LHCb experiment at CERN. The pipeline was implemented end-to-end inside LHCb's first-level trigger, entirely on GPUs. Its performance was compared against the classical tracking algorithms currently in production at LHCb. The pipeline was also accelerated on the FPGA architecture, and its performance in terms of power consumption and processing speed was compared against the GPU implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07423v2</guid>
      <category>physics.data-an</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fotis I. Giasemis</dc:creator>
    </item>
  </channel>
</rss>
