<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2024 02:39:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Revisiting Human Information Foraging: Adaptations for LLM-based Chatbots</title>
      <link>https://arxiv.org/abs/2406.04452</link>
      <description>arXiv:2406.04452v1 Announce Type: new 
Abstract: Information Foraging Theory's (IFT) framing of human information seeking choices as decision-theoretic cost-value judgments has successfully explained how people seek information among linked patches of information (e.g., linked webpages). However, the theory has to be adopted and validated in non-patchy LLM-based chatbot environments, before its postulates can be reliably applied to the design of such chat-based information seeking environments. This paper is a thought experiment that applies the IFT cost-value proposition to LLM-based chatbots and presents a set of preliminary hypotheses to guide future theory-building efforts for how people seek information in such environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04452v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sruti Srinivasa Ragavan, Mohammad Amin Alipour</dc:creator>
    </item>
    <item>
      <title>Rough Set improved Therapy-Based Metaverse Assisting System</title>
      <link>https://arxiv.org/abs/2406.04465</link>
      <description>arXiv:2406.04465v2 Announce Type: new 
Abstract: Chronic neck and shoulder pain (CNSP) is a major global public health issue. Traditional treatments like physiotherapy and rehabilitation have drawbacks, including high costs, low precision, and user discomfort. This paper presents an interactive system based on Cognitive Therapy Theory (CBT) for CNSP treatment. The system includes a pain detection module using EMG and IMU to monitor pain and optimize data with Rough Set theory, and a cognitive therapy module that processes this data further for CBT-based interventions, including massage and heating therapy. An experimental plan is outlined to evaluate the system's effectiveness and performance. The goal is to create an accessible device for CNSP therapy. Additionally, the paper explores the system's application in a metaverse environment, enhancing treatment immersion and personalization. The metaverse platform simulates treatment environments and responds to real-time patient data, allowing for continuous monitoring and adjustment of treatment plans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04465v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Cao, Yanhui Jiang, Chang Yu, Feiwei Qin, Zekun Jiang</dc:creator>
    </item>
    <item>
      <title>Dog Heart Rate and Blood Oxygen Metaverse Interaction System</title>
      <link>https://arxiv.org/abs/2406.04466</link>
      <description>arXiv:2406.04466v2 Announce Type: new 
Abstract: This study developed an improved dog heart rate and blood oxygen sensor system using Arduino. Traditional methods face accuracy and reliability issues. Our system integrates advanced computational techniques with hardware-based sensing to enhance measurement precision. An Arduino microcontroller connected to a heart rate and blood oxygen sensor collects raw data, which is preprocessed and filtered to remove noise. Experimental plans include long-term monitoring of multiple dogs and comparative analysis with traditional methods to validate the system's effectiveness, aiming for widespread use in the home or veterinary clinics. Additionally, the system offers dog owners the possibility to interact with their virtual dogs in the metaverse using AR/VR, allowing them to better understand their real dogs' health conditions by observing their virtual health status.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04466v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanhui Jiang, Jin Cao, Chang Yu</dc:creator>
    </item>
    <item>
      <title>Accessible Adventures: Teaching Accessibility to High School Students Through Games</title>
      <link>https://arxiv.org/abs/2406.04637</link>
      <description>arXiv:2406.04637v1 Announce Type: new 
Abstract: Accessibility education has been rarely incorporated into the high school curricula. This is a missed opportunity to equip next-generation software designers and decision-makers with knowledge, awareness, and empathy regarding accessibility and disabilities. We taught accessibility to students (N=93) in a midwestern high school through empathy-driven games and interviewed three Computer Science high school teachers and one librarian who taught programming. Accessibility education is currently insufficient in high school, facing challenges such as teachers' knowledge and conflicted curriculum goals. The students exhibited increased knowledge and awareness of accessibility and empathy for people with disabilities after playing the games. With this education outreach, we aim to provide insights into teaching next-generation software designers about accessibility by leveraging games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04637v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyrie Zhixuan Zhou, Chunyu Liu, Jingwen Shan, Devorah Kletenik, Rachel F. Adler</dc:creator>
    </item>
    <item>
      <title>Children's expressed emotions during playful learning games</title>
      <link>https://arxiv.org/abs/2406.04794</link>
      <description>arXiv:2406.04794v1 Announce Type: new 
Abstract: Studies on software tutoring systems for complex learning have shown that confusion has a beneficial relationship with the learning experience and student engagement (Arguel et al., 2017). Causing confusion can prevent boredom while signs of confusion can serve as a signal of genuine learning and as a predecessor for frustration. There is little to no research on the role of confusion in early childhood education and playful learning, as these studies primarily focus on high school and university students during complex learning tasks. Despite that, the field acknowledges that confusion may be caused by inconsistency between information and a student's internal model referred to as cognitive disequilibrium known from the theory of cognitive development, which was originally theorized based on observational studies on young children (D'Mello and Graesser, 2012). Therefore, there is reason to expect that the virtues of confusion also apply to young children engaging in learning activities, such as playful learning. To investigate the role of confusion in playful learning, we conducted an observational study, in which the behavior and expressed emotions of young children were collected by familiar pedagogues, using a web app, while they engaged with playful learning games designed for kindergartens. The expressed emotions were analyzed using a likelihood metric to determine the likely transitions between emotions (D'Mello and Graesser, 2012). The preliminary results showed that during short play sessions, children express confusion, frustration, and boredom. Furthermore, the observed emotional transitions were matched with previously established models of affect dynamics during complex learning. We argue that games with a learning objective can benefit by purposely confusing the player and how the player's confusion may be managed to improve the learning experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04794v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thomas Vase Schultz Volden, Paolo Burelli</dc:creator>
    </item>
    <item>
      <title>Digital assistant in a point of sales</title>
      <link>https://arxiv.org/abs/2406.04851</link>
      <description>arXiv:2406.04851v2 Announce Type: new 
Abstract: This article investigates the deployment of a Voice User Interface (VUI)-powered digital assistant in a retail setting and assesses its impact on customer engagement and service efficiency. The study explores how digital assistants can enhance user interactions through advanced conversational capabilities with multilingual support. By integrating a digital assistant into a high-traffic retail environment, we evaluate its effectiveness in improving the quality of customer service and operational efficiency. Data collected during the experiment demonstrate varied impacts on customer interaction, revealing insights into the future optimizations of digital assistant technologies in customer-facing roles. This study contributes to the understanding of digital transformation strategies within the customer relations domain emphasizing the need for service flexibility and user-centric design in modern retail stores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04851v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emilia Lesiak, Grzegorz Wolny, Bartosz Przyby{\l}, Micha{\l} Szczerbak</dc:creator>
    </item>
    <item>
      <title>Mind Mansion: Exploring Metaphorical Interactions to Engage with Negative Thoughts in Virtual Reality</title>
      <link>https://arxiv.org/abs/2406.04871</link>
      <description>arXiv:2406.04871v1 Announce Type: new 
Abstract: Recurrent negative thoughts can significantly disrupt daily life and contribute to negative emotional states. Facing, confronting, and noticing such thoughts without support can be challenging. To provide a playful setting and leverage the technical maturation of Virtual Reality (VR), our VR experience, Mind Mansion, places the user in an initially cluttered virtual apartment. Here we utilize established concepts from traditional therapy and metaphors identified in prior works to let users engage metaphorically with representations of thoughts, gradually sorting the space, fostering awareness of thoughts, and supporting mental self-care. The results of our user study (n = 30) reveal that Mind Mansion encourages the exploration of alternative perspectives, fosters acceptance, and potentially offers new coping mechanisms. Our findings suggest that this VR intervention can reduce negative affect and improve overall emotional awareness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04871v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3661557</arxiv:DOI>
      <dc:creator>Julian Rasch, Michelle Johanna Zender, Sophia Sakel, Nadine Wagener</dc:creator>
    </item>
    <item>
      <title>Expansion of situations theory for exploring shared awareness in human-intelligent autonomous systems</title>
      <link>https://arxiv.org/abs/2406.04956</link>
      <description>arXiv:2406.04956v1 Announce Type: new 
Abstract: Intelligent autonomous systems are part of a system of systems that interact with other agents to accomplish tasks in complex environments. However, intelligent autonomous systems integrated system of systems add additional layers of complexity based on their limited cognitive processes, specifically shared situation awareness that allows a team to respond to novel tasks. Intelligent autonomous systems' lack of shared situation awareness adversely influences team effectiveness in complex task environments, such as military command-and-control. A complementary approach of shared situation awareness, called situations theory, is beneficial for understanding the relationship between system of systems shared situation awareness and effectiveness. The current study elucidates a conceptual discussion on situations theory to investigate the development of an system of systems shared situational awareness when humans team with intelligent autonomous system agents. To ground the discussion, the reviewed studies expanded situations theory within the context of a system of systems that result in three major conjectures that can be beneficial to the design and development of future systems of systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04956v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1504/IJSSE.2025.10058953</arxiv:DOI>
      <dc:creator>Scott A. Humr, Mustafa Canan, Mustafa Demir</dc:creator>
    </item>
    <item>
      <title>Categorizing Sources of Information for Explanations in Conversational AI Systems for Older Adults Aging in Place</title>
      <link>https://arxiv.org/abs/2406.05111</link>
      <description>arXiv:2406.05111v1 Announce Type: new 
Abstract: As the permeability of AI systems in interpersonal domains like the home expands, their technical capabilities of generating explanations are required to be aligned with user expectations for transparency and reasoning. This paper presents insights from our ongoing work in understanding the effectiveness of explanations in Conversational AI systems for older adults aging in place and their family caregivers. We argue that in collaborative and multi-user environments like the home, AI systems will make recommendations based on a host of information sources to generate explanations. These sources may be more or less salient based on user mental models of the system and the specific task. We highlight the need for cross technological collaboration between AI systems and other available sources of information in the home to generate multiple explanations for a single user query. Through example scenarios in a caregiving home setting, this paper provides an initial framework for categorizing these sources and informing a potential design space for AI explanations surrounding everyday tasks in the home.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05111v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niharika Mathur, Tamara Zubatiy, Elizabeth Mynatt</dc:creator>
    </item>
    <item>
      <title>Use of a Multiscale Vision Transformer to predict Nursing Activities Score from Low Resolution Thermal Videos in an Intensive Care Unit</title>
      <link>https://arxiv.org/abs/2406.04364</link>
      <description>arXiv:2406.04364v1 Announce Type: cross 
Abstract: Excessive caregiver workload in hospital nurses has been implicated in poorer patient care and increased worker burnout. Measurement of this workload in the Intensive Care Unit (ICU) is often done using the Nursing Activities Score (NAS), but this is usually recorded manually and sporadically. Previous work has made use of Ambient Intelligence (AmI) by using computer vision to passively derive caregiver-patient interaction times to monitor staff workload. In this letter, we propose using a Multiscale Vision Transformer (MViT) to passively predict the NAS from low-resolution thermal videos recorded in an ICU. 458 videos were obtained from an ICU in Melbourne, Australia and used to train a MViTv2 model using an indirect prediction and a direct prediction method. The indirect method predicted 1 of 8 potentially identifiable NAS activities from the video before inferring the NAS. The direct method predicted the NAS score immediately from the video. The indirect method yielded an average 5-fold accuracy of 57.21%, an area under the receiver operating characteristic curve (ROC AUC) of 0.865, a F1 score of 0.570 and a mean squared error (MSE) of 28.16. The direct method yielded a MSE of 18.16. We also showed that the MViTv2 outperforms similar models such as R(2+1)D and ResNet50-LSTM under identical settings.
  This study shows the feasibility of using a MViTv2 to passively predict the NAS in an ICU and monitor staff workload automatically. Our results above also show an increased accuracy in predicting NAS directly versus predicting NAS indirectly. We hope that our study can provide a direction for future work and further improve the accuracy of passive NAS monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04364v1</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Isaac YL Lee, Thanh Nguyen-Duc, Ryo Ueno, Jesse Smith, Peter Y Chan</dc:creator>
    </item>
    <item>
      <title>Automatic Bug Detection in LLM-Powered Text-Based Games Using LLMs</title>
      <link>https://arxiv.org/abs/2406.04482</link>
      <description>arXiv:2406.04482v1 Announce Type: cross 
Abstract: Advancements in large language models (LLMs) are revolutionizing interactive game design, enabling dynamic plotlines and interactions between players and non-player characters (NPCs). However, LLMs may exhibit flaws such as hallucinations, forgetfulness, or misinterpretations of prompts, causing logical inconsistencies and unexpected deviations from intended designs. Automated techniques for detecting such game bugs are still lacking. To address this, we propose a systematic LLM-based method for automatically identifying such bugs from player game logs, eliminating the need for collecting additional data such as post-play surveys. Applied to a text-based game DejaBoom!, our approach effectively identifies bugs inherent in LLM-powered interactive games, surpassing unstructured LLM-powered bug-catching methods and filling the gap in automated detection of logical and design flaws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04482v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claire Jin, Sudha Rao, Xiangyu Peng, Portia Botchway, Jessica Quaye, Chris Brockett, Bill Dolan</dc:creator>
    </item>
    <item>
      <title>Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations</title>
      <link>https://arxiv.org/abs/2406.04755</link>
      <description>arXiv:2406.04755v1 Announce Type: cross 
Abstract: Large language model (LLM) users might rely on others (e.g., prompting services), to write prompts. However, the risks of trusting prompts written by others remain unstudied. In this paper, we assess the risk of using such prompts on brand recommendation tasks when shopping. First, we found that paraphrasing prompts can result in LLMs mentioning given brands with drastically different probabilities, including a pair of prompts where the probability changes by 100%. Next, we developed an approach that can be used to perturb an original base prompt to increase the likelihood that an LLM mentions a given brand. We designed a human-inconspicuous algorithm that perturbs prompts, which empirically forces LLMs to mention strings related to a brand more often, by absolute improvements up to 78.3%. Our results suggest that our perturbed prompts, 1) are inconspicuous to humans, 2) force LLMs to recommend a target brand more often, and 3) increase the perceived chances of picking targeted brands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04755v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Weiran Lin, Anna Gerchanovsky, Omer Akgul, Lujo Bauer, Matt Fredrikson, Zifan Wang</dc:creator>
    </item>
    <item>
      <title>VERA: Generating Visual Explanations of Two-Dimensional Embeddings via Region Annotation</title>
      <link>https://arxiv.org/abs/2406.04808</link>
      <description>arXiv:2406.04808v1 Announce Type: cross 
Abstract: Two-dimensional embeddings obtained from dimensionality reduction techniques, such as MDS, t-SNE, and UMAP, are widely used across various disciplines to visualize high-dimensional data. These visualizations provide a valuable tool for exploratory data analysis, allowing researchers to visually identify clusters, outliers, and other interesting patterns in the data. However, interpreting the resulting visualizations can be challenging, as it often requires additional manual inspection to understand the differences between data points in different regions of the embedding space. To address this issue, we propose Visual Explanations via Region Annotation (VERA), an automatic embedding-annotation approach that generates visual explanations for any two-dimensional embedding. VERA produces informative explanations that characterize distinct regions in the embedding space, allowing users to gain an overview of the embedding landscape at a glance. Unlike most existing approaches, which typically require some degree of manual user intervention, VERA produces static explanations, automatically identifying and selecting the most informative visual explanations to show to the user. We illustrate the usage of VERA on a real-world data set and validate the utility of our approach with a comparative user study. Our results demonstrate that the explanations generated by VERA are as useful as fully-fledged interactive tools on typical exploratory data analysis tasks but require significantly less time and effort from the user.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04808v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavlin G. Poli\v{c}ar, Bla\v{z} Zupan</dc:creator>
    </item>
    <item>
      <title>Experiences from Integrating Large Language Model Chatbots into the Classroom</title>
      <link>https://arxiv.org/abs/2406.04817</link>
      <description>arXiv:2406.04817v1 Announce Type: cross 
Abstract: In the present study, we provided students an unfiltered access to a state-of-the-art large language model (LLM) chatbot. The chatbot was intentionally designed to mimic proprietary commercial chatbots such as ChatGPT where the chatbot has not been tailored for the educational context; the underlying engine was OpenAI GPT-4. The chatbot was integrated into online learning materials of three courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the LLM usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it was readily available and effectively provided a free access to the OpenAI GPT-4 model. We also observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes. These results suggest that the worst fears of educators -- all students overrelying on LLMs -- did not materialize even when the chatbot access was unfiltered. We finally discuss potential reasons for the low usage, suggesting the need for more tailored and scaffolded LLM experiences targeted for specific types of student use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04817v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arto Hellas, Juho Leinonen, Leo Lepp\"anen</dc:creator>
    </item>
    <item>
      <title>A Modular Framework for Flexible Planning in Human-Robot Collaboration</title>
      <link>https://arxiv.org/abs/2406.04907</link>
      <description>arXiv:2406.04907v1 Announce Type: cross 
Abstract: This paper presents a comprehensive framework to enhance Human-Robot Collaboration (HRC) in real-world scenarios. It introduces a formalism to model articulated tasks, requiring cooperation between two agents, through a smaller set of primitives. Our implementation leverages Hierarchical Task Networks (HTN) planning and a modular multisensory perception pipeline, which includes vision, human activity recognition, and tactile sensing. To showcase the system's scalability, we present an experimental scenario where two humans alternate in collaborating with a Baxter robot to assemble four pieces of furniture with variable components. This integration highlights promising advancements in HRC, suggesting a scalable approach for complex, cooperative tasks across diverse applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04907v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valerio Belcamino, Mariya Kilina, Linda Lastrico, Alessandro Carf\`i, Fulvio Mastrogiovanni</dc:creator>
    </item>
    <item>
      <title>Designs for Enabling Collaboration in Human-Machine Teaming via Interactive and Explainable Systems</title>
      <link>https://arxiv.org/abs/2406.05003</link>
      <description>arXiv:2406.05003v1 Announce Type: cross 
Abstract: Collaborative robots and machine learning-based virtual agents are increasingly entering the human workspace with the aim of increasing productivity and enhancing safety. Despite this, we show in a ubiquitous experimental domain, Overcooked-AI, that state-of-the-art techniques for human-machine teaming (HMT), which rely on imitation or reinforcement learning, are brittle and result in a machine agent that aims to decouple the machine and human's actions to act independently rather than in a synergistic fashion. To remedy this deficiency, we develop HMT approaches that enable iterative, mixed-initiative team development allowing end-users to interactively reprogram interpretable AI teammates. Our 50-subject study provides several findings that we summarize into guidelines. While all approaches underperform a simple collaborative heuristic (a critical, negative result for learning-based methods), we find that white-box approaches supported by interactive modification can lead to significant team development, outperforming white-box approaches alone, and black-box approaches are easier to train and result in better HMT performance highlighting a tradeoff between explainability and interactivity versus ease-of-training. Together, these findings present three important directions: 1) Improving the ability to generate collaborative agents with white-box models, 2) Better learning methods to facilitate collaboration rather than individualized coordination, and 3) Mixed-initiative interfaces that enable users, who may vary in ability, to improve collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05003v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Paleja, Michael Munje, Kimberlee Chang, Reed Jensen, Matthew Gombolay</dc:creator>
    </item>
    <item>
      <title>Classification Metrics for Image Explanations: Towards Building Reliable XAI-Evaluations</title>
      <link>https://arxiv.org/abs/2406.05068</link>
      <description>arXiv:2406.05068v1 Announce Type: cross 
Abstract: Decision processes of computer vision models - especially deep neural networks - are opaque in nature, meaning that these decisions cannot be understood by humans. Thus, over the last years, many methods to provide human-understandable explanations have been proposed. For image classification, the most common group are saliency methods, which provide (super-)pixelwise feature attribution scores for input images. But their evaluation still poses a problem, as their results cannot be simply compared to the unknown ground truth. To overcome this, a slew of different proxy metrics have been defined, which are - as the explainability methods themselves - often built on intuition and thus, are possibly unreliable. In this paper, new evaluation metrics for saliency methods are developed and common saliency methods are benchmarked on ImageNet. In addition, a scheme for reliability evaluation of such metrics is proposed that is based on concepts from psychometric testing. The used code can be found at https://github.com/lelo204/ClassificationMetricsForImageExplanations .</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05068v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3658537</arxiv:DOI>
      <arxiv:journal_reference>FAccT'24: The 2024 ACM Conference on Fairness, Accountability, and Transparency, June 2024, Pages 1-19</arxiv:journal_reference>
      <dc:creator>Benjamin Fresz, Lena L\"orcher, Marco Huber</dc:creator>
    </item>
    <item>
      <title>WonderFlow: Narration-Centric Design of Animated Data Videos</title>
      <link>https://arxiv.org/abs/2308.04040</link>
      <description>arXiv:2308.04040v2 Announce Type: replace 
Abstract: Creating an animated data video enriched with audio narration takes a significant amount of time and effort and requires expertise. Users not only need to design complex animations, but also turn written text scripts into audio narrations and synchronize visual changes with the narrations. This paper presents WonderFlow, an interactive authoring tool, that facilitates narration-centric design of animated data videos. WonderFlow allows authors to easily specify a semantic link between text and the corresponding chart elements. Then it automatically generates audio narration by leveraging text-to-speech techniques and aligns the narration with an animation. WonderFlow provides a visualization structure-aware animation library designed to ease chart animation creation, enabling authors to apply pre-designed animation effects to common visualization components. It also allows authors to preview and iteratively refine their data videos in a unified system, without having to switch between different creation tools. To evaluate WonderFlow's effectiveness and usability, we created an example gallery and conducted a user study and expert interviews. The results demonstrated that WonderFlow is easy to use and simplifies the creation of data videos with narration-animation interplay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.04040v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun Wang, Leixian Shen, Zhengxin You, Xinhuan Shu, Bongshin Lee, John Thompson, Haidong Zhang, Dongmei Zhang</dc:creator>
    </item>
    <item>
      <title>Opportunities for Adaptive Experiments to Enable Continuous Improvement in Computer Science Education</title>
      <link>https://arxiv.org/abs/2310.12324</link>
      <description>arXiv:2310.12324v2 Announce Type: replace 
Abstract: Randomized A/B comparisons of alternative pedagogical strategies or other course improvements could provide useful empirical evidence for instructor decision-making. However, traditional experiments do not provide a straightforward pathway to rapidly utilize data, increasing the chances that students in an experiment experience the best conditions. Drawing inspiration from the use of machine learning and experimentation in product development at leading technology companies, we explore how adaptive experimentation might aid continuous course improvement. In adaptive experiments, data is analyzed and utilized as different conditions are deployed to students. This can be achieved using machine learning algorithms to identify which actions are more beneficial in improving students' learning experiences and outcomes. These algorithms can then dynamically deploy the most effective conditions in subsequent interactions with students, resulting in better support for students' needs. We illustrate this approach with a case study that provides a side-by-side comparison of traditional and adaptive experiments on adding self-explanation prompts in online homework problems in a CS1 course. This work paves the way for exploring the importance of adaptive experiments in bridging research and practice to achieve continuous improvement in educational settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12324v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3660650.3660659</arxiv:DOI>
      <arxiv:journal_reference>In The 26th Western Canadian Conference on Computing Education (WCCCE '24). ACM, New York, NY, USA, 7 pages (2024)</arxiv:journal_reference>
      <dc:creator>Ilya Musabirov, Angela Zavaleta-Bernuy, Pan Chen, Michael Liut, Joseph Jay Williams</dc:creator>
    </item>
    <item>
      <title>Human-Centered AI Product Prototyping with No-Code AutoML: Conceptual Framework, Potentials and Limitations</title>
      <link>https://arxiv.org/abs/2402.07933</link>
      <description>arXiv:2402.07933v2 Announce Type: replace 
Abstract: This paper addresses the complexities inherent in AI product prototyping, focusing on the challenges posed by the probabilistic nature of AI behavior and the limited accessibility of prototyping tools to non-experts. A Design Science Research (DSR) approach is presented which culminates in a conceptual framework aimed at improving the AI prototyping process. Through a comprehensive literature review, key challenges were identified and no-code AutoML was analyzed as a solution. The framework describes the seamless incorporation of non-expert input and evaluation during prototyping, leveraging the potential of no-code AutoML to enhance accessibility and interpretability. A hybrid approach of combining naturalistic (case study) and artificial evaluation methods (criteria-based analysis) validated the utility of our approach, highlighting its efficacy in supporting AI non-experts and streamlining decision-making and its limitations. Implications for academia and industry, emphasizing the strategic integration of no-code AutoML to enhance AI product development processes, mitigate risks, and foster innovation, are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07933v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Truss, Marc Schmitt</dc:creator>
    </item>
    <item>
      <title>The Influencer Next Door: How Misinformation Creators Use GenAI</title>
      <link>https://arxiv.org/abs/2405.13554</link>
      <description>arXiv:2405.13554v2 Announce Type: replace 
Abstract: Advances in generative AI (GenAI) have raised concerns about detecting and discerning AI-generated content from human-generated content. Most existing literature assumes a paradigm where 'expert' organized disinformation creators and flawed AI models deceive 'ordinary' users. Based on longitudinal ethnographic research with misinformation creators and consumers between 2022-2023, we instead find that GenAI supports bricolage work, where non-experts increasingly use GenAI to remix, repackage, and (re)produce content to meet their personal needs and desires. This research yielded four key findings: First, participants primarily used GenAI for creation, rather than truth-seeking. Second, a spreading 'influencer millionaire' narrative drove participants to become content creators, using GenAI as a productivity tool to generate a volume of (often misinformative) content. Third, GenAI lowered the barrier to entry for content creation across modalities, enticing consumers to become creators and significantly increasing existing creators' output. Finally, participants used Gen AI to learn and deploy marketing tactics to expand engagement and monetize their content. We argue for shifting analysis from the public as consumers of AI content to bricoleurs who use GenAI creatively, often without a detailed understanding of its underlying technology. We analyze how these understudied emergent uses of GenAI produce new or accelerated misinformation harms, and their implications for AI products, platforms and policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13554v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amelia Hassoun, Ariel Abonizio, Katy Osborn, Cameron Wu, Beth Goldberg</dc:creator>
    </item>
    <item>
      <title>"Generate" the Future of Work through AI: Empirical Evidence from Online Labor Markets</title>
      <link>https://arxiv.org/abs/2308.05201</link>
      <description>arXiv:2308.05201v2 Announce Type: replace-cross 
Abstract: Large Language Model (LLM) based generative AI, such as ChatGPT, is considered the first generation of Artificial General Intelligence (AGI), exhibiting zero-shot learning abilities for a wide variety of downstream tasks. Due to its general-purpose and emergent nature, its impact on labor dynamics becomes complex and difficult to anticipate. Leveraging an extensive dataset from a prominent online labor market, we uncover a post-ChatGPT decline in labor demand, supply, and transactions for submarkets pertaining to text-related and programming-related jobs, in comparison to those not directly exposed to ChatGPT's core functionalities. Meanwhile, these affected submarkets exhibit a discernible increase in the complexity of the remaining jobs and a heightened level of competition among freelancers. Intriguingly, our findings indicate that the diminution in the labor supply pertaining to programming is comparatively less pronounced, a phenomenon ascribed to the transition of freelancers previously engaged in text-related tasks now bidding for programming-related opportunities. Although the per-period job diversity freelancers apply for tends to be more limited, those who successfully navigate skill transitions from text to programming demonstrate greater resilience to ChatGPT's overall market contraction impact. As AI becomes increasingly versatile and potent, our paper offers crucial insights into AI's influence on labor markets and individuals' reactions, underscoring the necessity for proactive interventions to address the challenges and opportunities presented by this transformative technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05201v2</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Liu (University of Science and Technology of China), Xingchen Xu (University of Washington), Xi Nan (University of Washington), Yongjun Li (University of Science and Technology of China), Yong Tan (University of Washington)</dc:creator>
    </item>
    <item>
      <title>You Only Look at Screens: Multimodal Chain-of-Action Agents</title>
      <link>https://arxiv.org/abs/2309.11436</link>
      <description>arXiv:2309.11436v4 Announce Type: replace-cross 
Abstract: Autonomous graphical user interface (GUI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, most existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-GUI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -- leveraging a series of intermediate previous action histories and future action plans -- to help the agent decide what action to execute. We evaluate our approach on a new device-control benchmark AITW with 30$K$ unique instructions, spanning multi-step tasks such as application operation, web searching, and web shopping. Experimental results show that Auto-GUI achieves state-of-the-art performance with an action type prediction accuracy of 90\% and an overall action success rate of 74\%. Code is publicly available at https://github.com/cooelf/Auto-GUI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11436v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuosheng Zhang, Aston Zhang</dc:creator>
    </item>
    <item>
      <title>CompeteAI: Understanding the Competition Dynamics in Large Language Model-based Agents</title>
      <link>https://arxiv.org/abs/2310.17512</link>
      <description>arXiv:2310.17512v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have been widely used as agents to complete different tasks, such as personal assistance or event planning. While most of the work has focused on cooperation and collaboration between agents, little work explores competition, another important mechanism that promotes the development of society and economy. In this paper, we seek to examine the competition dynamics in LLM-based agents. We first propose a general framework for studying the competition between agents. Then, we implement a practical competitive environment using GPT-4 to simulate a virtual town with two types of agents, restaurant agents and customer agents. Specifically, the restaurant agents compete with each other to attract more customers, where competition encourages them to transform, such as cultivating new operating strategies. Simulation experiments reveal several interesting findings at the micro and macro levels, which align well with existing market and sociological theories. We hope that the framework and environment can be a promising testbed to study competition that fosters understanding of society. Code is available at: https://github.com/microsoft/competeai.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17512v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie Zhu, Hao Chen, Xing Xie</dc:creator>
    </item>
    <item>
      <title>The Good, The Bad, and Why: Unveiling Emotions in Generative AI</title>
      <link>https://arxiv.org/abs/2312.11111</link>
      <description>arXiv:2312.11111v3 Announce Type: replace-cross 
Abstract: Emotion significantly impacts our daily behaviors and interactions. While recent generative AI models, such as large language models, have shown impressive performance in various tasks, it remains unclear whether they truly comprehend emotions. This paper aims to address this gap by incorporating psychological theories to gain a holistic understanding of emotions in generative AI models. Specifically, we propose three approaches: 1) EmotionPrompt to enhance AI model performance, 2) EmotionAttack to impair AI model performance, and 3) EmotionDecode to explain the effects of emotional stimuli, both benign and malignant. Through extensive experiments involving language and multi-modal models on semantic understanding, logical reasoning, and generation tasks, we demonstrate that both textual and visual EmotionPrompt can boost the performance of AI models while EmotionAttack can hinder it. Additionally, EmotionDecode reveals that AI models can comprehend emotional stimuli akin to the mechanism of dopamine in the human brain. Our work heralds a novel avenue for exploring psychology to enhance our understanding of generative AI models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11111v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Xinyi Wang, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, Xing Xie</dc:creator>
    </item>
    <item>
      <title>Cognitively Biased Users Interacting with Algorithmically Biased Results in Whole-Session Search on Debated Topics</title>
      <link>https://arxiv.org/abs/2403.17286</link>
      <description>arXiv:2403.17286v2 Announce Type: replace-cross 
Abstract: When interacting with information retrieval (IR) systems, users, affected by confirmation biases, tend to select search results that confirm their existing beliefs on socially significant contentious issues. To understand the judgments and attitude changes of users searching online, our study examined how cognitively biased users interact with algorithmically biased search engine result pages (SERPs). We designed three-query search sessions on debated topics under various bias conditions. We recruited 1,321 crowdsourcing participants and explored their attitude changes, search interactions, and the effects of confirmation bias. Three key findings emerged: 1) most attitude changes occur in the initial query of a search session; 2) Confirmation bias and result presentation on SERPs affect the number and depth of clicks in the current query and perceived familiarity with clicked results in subsequent queries; 3) The bias position also affects attitude changes of users with lower perceived openness to conflicting opinions. Our study goes beyond traditional simulation-based evaluation settings and simulated rational users, sheds light on the mixed effects of human biases and algorithmic biases in information retrieval tasks on debated topics, and can inform the design of bias-aware user models, human-centered bias mitigation techniques, and socially responsible intelligent IR systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17286v2</guid>
      <category>cs.IR</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Wang, Jiqun Liu</dc:creator>
    </item>
  </channel>
</rss>
