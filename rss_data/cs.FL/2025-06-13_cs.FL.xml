<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jun 2025 04:01:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Chance and Mass Interpretations of Probabilities in Markov Decision Processes (Extended Version)</title>
      <link>https://arxiv.org/abs/2506.10377</link>
      <description>arXiv:2506.10377v1 Announce Type: new 
Abstract: Markov decision processes (MDPs) are a popular model for decision-making in the presence of uncertainty. The conventional view of MDPs in verification treats them as state transformers with probabilities defined over sequences of states and with schedulers making random choices. An alternative view, especially well-suited for modeling dynamical systems, defines MDPs as distribution transformers with schedulers distributing probability masses. Our main contribution is a unified semantical framework that accommodates these two views and two new ones. These four semantics of MDPs arise naturally through identifying different sources of randomness in an MDP (namely schedulers, configurations, and transitions) and providing different ways of interpreting these probabilities (called the chance and mass interpretations). These semantics are systematically unified through a mathematical construct called chance-mass (CM) classifier. As another main contribution, we study a reachability problem in each of the two new semantics, demonstrating their hardness and providing two algorithms for solving them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10377v1</guid>
      <category>cs.FL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yun Chen Tsai, Kittiphon Phalakarn, S. Akshay, Ichiro Hasuo</dc:creator>
    </item>
    <item>
      <title>Minimality and computability of languages of G-shifts</title>
      <link>https://arxiv.org/abs/2506.10610</link>
      <description>arXiv:2506.10610v1 Announce Type: new 
Abstract: Motivated by the notion of strong computable type for sets in computable analysis, we define the notion of strong computable type for $G$-shifts, where $G$ is a finitely generated group with decidable word problem. A $G$-shift has strong computable type if one can compute its language from the complement of its language. We obtain a characterization of $G$-shifts with strong computable type in terms of a notion of minimality with respect to properties with a bounded computational complexity. We provide a self-contained direct proof, and also explain how this characterization can be obtained from an existing similar characterization for sets by Amir and Hoyrup, and discuss its connexions with results by Jeandel on closure spaces. We apply this characterization to several classes of shifts that are minimal with respect to specific properties. This provides a unifying approach that not only generalizes many existing results but also has the potential to yield new findings effortlessly. In contrast to the case of sets, we prove that strong computable type for G-shifts is preserved under products. We conclude by discussing some generalizations and future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10610v1</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.DS</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Djamel Eddine Amir, Benjamin Hellouin de Menibus</dc:creator>
    </item>
    <item>
      <title>Landauer Principle and Thermodynamics of Computation</title>
      <link>https://arxiv.org/abs/2506.10876</link>
      <description>arXiv:2506.10876v1 Announce Type: cross 
Abstract: According to the Landauer principle, any logically irreversible process accompanies entropy production, which results in heat dissipation in the environment. Erasing of information, one of the primary logically irreversible processes, has a lower bound on heat dissipated into the environment, called the Landauer bound (LB). However, the practical erasure processes dissipate much more heat than the LB. Recently, there have been a few experimental investigations to reach this bound both in the classical and quantum domains. There has also been a spate of activities to enquire about this LB in finite time, with finite-size heat baths, non-Markovian and nonequilibrium environment in the quantum regime where the effects of fluctuations and correlation of the systems with the bath can no longer be ignored. This article provides a comprehensive review of the recent progress on the Landauer bound, which serves as a fundamental principle in the thermodynamics of computation. We also provide a perspective for future endeavors in these directions. Furthermore, we review the recent exploration toward establishing energetic bounds of a computational process. We also review the thermodynamic aspects of error correction, which is an indispensable part of information processing and computations. In doing so, we briefly discuss the basics of these fields to provide a complete picture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10876v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pritam Chattopadhyay, Avijit Misra, Tanmoy Pandit, Goutam Paul</dc:creator>
    </item>
    <item>
      <title>New Fault Domains for Conformance Testing of Finite State Machines</title>
      <link>https://arxiv.org/abs/2410.19405</link>
      <description>arXiv:2410.19405v2 Announce Type: replace 
Abstract: A fault domain reflects a tester's assumptions about faults that may occur in an implementation and that need to be detected during testing. A fault domain that has been widely studied in the literature on black-box conformance testing is the class of finite state machines (FSMs) with at most $m$ states. Numerous strategies for generating test suites have been proposed that guarantee fault coverage for this class. These so-called $m$-complete test suites grow exponentially in $m-n$, where $n$ is the number of states of the specification, so one can only run them for small values of $m-n$. But the assumption that $m-n$ is small is not realistic in practice. In his seminal paper from 1964, Hennie raised the challenge to design checking experiments in which the number of states may increase appreciably. In order to solve this long-standing open problem, we propose (much larger) fault domains that capture the assumption that all states in an implementation can be reached by first performing a sequence from some set $A$ (typically a state cover for the specification), followed by $k$ arbitrary inputs, for some small $k$. The number of states of FSMs in these fault domains grows exponentially in $k$. We present a sufficient condition for $k$-$A$-completeness of test suites with respect to these fault domains. Our condition implies $k$-$A$-completeness of two prominent $m$-complete test suite generation strategies, the Wp and HSI methods. Thus these strategies are complete for much larger fault domains than those for which they were originally designed, and thereby solve Hennie's challenge. We show that three other prominent $m$-complete methods (H, SPY and SPYH) do not always generate $k$-$A$-complete test suites.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19405v2</guid>
      <category>cs.FL</category>
      <category>cs.SE</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frits Vaandrager, Ivo Melse</dc:creator>
    </item>
    <item>
      <title>Formalizing zeta and L-functions in Lean</title>
      <link>https://arxiv.org/abs/2503.00959</link>
      <description>arXiv:2503.00959v3 Announce Type: replace-cross 
Abstract: The Riemann zeta function, and more generally the L-functions of Dirichlet characters, are among the central objects of study in number theory. We report on a project to formalize the theory of these objects in Lean's "Mathlib" library, including a proof of Dirichlet's theorem on primes in arithmetic progressions and a formal statement of the Riemann hypothesis</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00959v3</guid>
      <category>math.NT</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Loeffler, Michael Stoll</dc:creator>
    </item>
    <item>
      <title>Extending AALpy with Passive Learning: A Generalized State-Merging Approach</title>
      <link>https://arxiv.org/abs/2506.06333</link>
      <description>arXiv:2506.06333v2 Announce Type: replace-cross 
Abstract: AALpy is a well-established open-source automata learning library written in Python with a focus on active learning of systems with IO behavior. It provides a wide range of state-of-the-art algorithms for different automaton types ranging from fully deterministic to probabilistic automata. In this work, we present the recent addition of a generalized implementation of an important method from the domain of passive automata learning: state-merging in the red-blue framework. Using a common internal representation for different automaton types allows for a general and highly configurable implementation of the red-blue framework. We describe how to define and execute state-merging algorithms using AALpy, which reduces the implementation effort for state-merging algorithms mainly to the definition of compatibility criteria and scoring. This aids the implementation of both existing and novel algorithms. In particular, defining some existing state-merging algorithms from the literature with AALpy only takes a few lines of code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06333v2</guid>
      <category>cs.LG</category>
      <category>cs.FL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin von Berg, Bernhard K. Aichernig</dc:creator>
    </item>
  </channel>
</rss>
