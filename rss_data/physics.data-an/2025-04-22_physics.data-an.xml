<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Apr 2025 01:46:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unbinned Inference with Correlated Events</title>
      <link>https://arxiv.org/abs/2504.14072</link>
      <description>arXiv:2504.14072v1 Announce Type: new 
Abstract: Modern machine learning has enabled parameter inference from event-level data without the need to first summarize all events with a histogram. All of these unbinned inference methods make use of the fact that the events are statistically independent so that the log likelihood is a sum over events. However, this assumption is not valid for unbinned inference on unfolded data, where the deconvolution process induces a correlation between events. We explore the impact of event correlations on downstream inference tasks in the context of the OmniFold unbinned unfolding method. We find that uncertainties may be significantly underestimated when event correlations are excluded from uncertainty quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14072v1</guid>
      <category>physics.data-an</category>
      <category>hep-ex</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krish Desai, Owen Long, Benjamin Nachman</dc:creator>
    </item>
    <item>
      <title>Probability of collision in nonlinear dynamics by moment propagation</title>
      <link>https://arxiv.org/abs/2504.13935</link>
      <description>arXiv:2504.13935v1 Announce Type: cross 
Abstract: Estimating the probability of collision between spacecraft is crucial for risk management and collision-avoidance strategies. Current methods often rely on Gaussian assumptions and simplifications, which can be inaccurate in highly nonlinear scenarios. This paper presents a general and efficient approach for computing collision probabilities without relying on such assumptions. Using high-order multivariate Taylor polynomials, we propagate statistical moments of initial uncertainties to the point of closest approach between the spacecraft. To compute the probability of collision, we derive a semi-analytical expression for the probability density function (PDF) of the closest approach distance, inferred from the propagated moments using orthogonal polynomials. Tested on various short-term and long-term encounters in low-Earth orbit, our method accurately handles nonlinear dynamics, non-Gaussian uncertainties, and irregular distributions. This versatile framework advances space situational awareness by providing precise collision probability estimates in complex dynamical environments. Moreover, our methodology applies to any dynamical system with uncertainty in its initial state and is therefore not restricted to collision probability estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13935v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>physics.data-an</category>
      <category>physics.space-ph</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Th\'eo Verhelst, Giacomo Acciarini, Dario Izzo, Francesco Biscani</dc:creator>
    </item>
    <item>
      <title>Learning the nature of viscoelasticity in geologic materials with MCMC</title>
      <link>https://arxiv.org/abs/2504.14028</link>
      <description>arXiv:2504.14028v1 Announce Type: cross 
Abstract: Rock and ice are ubiquitous geologic materials. While apparently solid, they also exhibit fluid behavior under stress - a property termed viscoelasticity. Viscoelastic convection of Earth's mantle drives tectonic plate motion with consequences for earthquakes and sea-level rise, while viscoelastic deformation of ice controls glacier flow and the flexure of icy moons. For crystalline materials, "flow laws" describing bulk rheology can be derived from understanding microstructural dynamics such as crystal-defect migration. Common geologic materials like ice and olivine have grain sizes and crystal orientations that evolve with strain; this complexity precludes a first principles approach. Here we use a Bayesian inference method to learn the connection between microstructure and flow in ice and olivine, from fits to experimental data of these materials undergoing steady-state deformation and forced oscillations. We demonstrate that this method can constrain a nonlinear viscoelastic model for each material, that is capable of capturing both steady and transient dynamics and can also predict dynamics for data it was not trained on. Our results may improve geodynamic models that rely on parameterized constitutive equations, while our approach will be useful for experimental design and hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14028v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ron Maor, Lars Hansen, Douglas Jerolmack, David Goldsby</dc:creator>
    </item>
    <item>
      <title>Invariance-embedded Machine Learning Sub-grid-scale Stress Models for Meso-scale Hurricane Boundary Layer Flow Simulation I: Model Development and $\textit{a priori}$ Studies</title>
      <link>https://arxiv.org/abs/2504.14473</link>
      <description>arXiv:2504.14473v1 Announce Type: cross 
Abstract: This study develops invariance-embedded machine learning sub-grid-scale (SGS) stress models admitting turbulence kinetic energy (TKE) backscatter towards more accurate large eddy simulation (LES) of meso-scale turbulent hurricane boundary layer flows. The new machine learning SGS model consists of two parts: a classification model used to distinguish regions with either strong energy cascade or energy backscatter from those with mild TKE transfer and a regression model used to calculate SGS stresses in regions with strong TKE transfer. To ease model implementation in computational fluid dynamics (CFD) solvers, the Smagorinsky model with a signed coefficient $C_s$, where a positive value indicates energy cascade while a negative one indicates energy backscatter, is employed as the carrier of the machine learning model. To improve its robustness and generality, both physical invariance and geometric invariance features of turbulent flows are embedded into the model input for classification and regression, and the signed Smagorinsky model coefficient is used as the output of the regression model. Different machine-learning methods and input setups have been used to test the classification model's performance. The F1-scores, which measure balanced precision and recall of a model, of the classification models with physical and geometric invariance embedded can be improved by about $17\%$ over those without considering geometric invariance. Regression models based on ensemble neural networks have demonstrated superior performance in predicting the signed Smagorinsky model coefficient, exceeding that of the dynamic Smagorinsky model in $\textit{a priori}$ tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14473v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.ao-ph</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Badrul Hasan, Meilin Yu, Tim Oates</dc:creator>
    </item>
    <item>
      <title>Solving All Seismic Tomographic Problems using Deep Learning</title>
      <link>https://arxiv.org/abs/2504.14830</link>
      <description>arXiv:2504.14830v1 Announce Type: cross 
Abstract: In a variety of geoscientific applications scientists often need to image properties of the Earth's interior in order to understand the heterogeneity and processes taking place within the Earth. Seismic tomography is one such method which has been used widely to study properties of the subsurface. In order to solve tomographic problems efficiently, neural network-based methods have been introduced to geophysics. However, these methods can only be applied to certain types of problems with fixed acquisition geometry at a specific site. In this study we extend neural network-based methods to problems with various scales and acquisition geometries by using graph mixture density networks (MDNs). We train a graph MDN for 2D tomographic problems using simulated velocity models and travel time data, and apply the trained network to both synthetic and real data problems that have various scales and station distributions at different sites. The results demonstrate that graph MDNs can provide comparable solutions to those obtained using traditional Bayesian methods in seconds, and therefore provide the possibility to use graph MDNs to produce rapid solutions for all kinds of seismic tomographic problems over the world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14830v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xin Zhang, Kaiwen Xia</dc:creator>
    </item>
    <item>
      <title>Machine learning-powered data cleaning for LEGEND: a semi-supervised approach using affinity propagation and support vector machines</title>
      <link>https://arxiv.org/abs/2410.14701</link>
      <description>arXiv:2410.14701v2 Announce Type: replace 
Abstract: Neutrinoless double-beta decay ($0\nu\beta\beta$) is a rare nuclear process that, if observed, will provide insight into the nature of neutrinos and help explain the matter-antimatter asymmetry in the universe. The Large Enriched Germanium Experiment for Neutrinoless Double-Beta Decay (LEGEND) will operate in two phases to search for $0\nu\beta\beta$. The first (second) stage will employ 200 (1000) kg of High-Purity Germanium (HPGe) enriched in $^{76}$Ge to achieve a half-life sensitivity of 10$^{27}$ (10$^{28}$) years. In this study, we present a semi-supervised data-driven approach to remove non-physical events captured by HPGe detectors powered by a novel artificial intelligence model. We utilize Affinity Propagation to cluster waveform signals based on their shape and a Support Vector Machine to classify them into different categories. We train, optimize, test our model on data taken from a natural abundance HPGe detector installed in the Full Chain Test experimental stand at the University of North Carolina at Chapel Hill. We demonstrate that our model yields a maximum sacrifice of physics events of $0.024 ^{+0.004}_{-0.003} \%$. Our model is being used to accelerate data cleaning development for LEGEND-200 and will serve to improve data cleaning procedures for LEGEND-1000.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14701v2</guid>
      <category>physics.data-an</category>
      <category>nucl-ex</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/2632-2153/adbb37</arxiv:DOI>
      <arxiv:journal_reference>2025 Mach. Learn.: Sci. Technol. 6 015064</arxiv:journal_reference>
      <dc:creator>E. Le\'on, A. Li, M. A. Bahena Schott, B. Bos, M. Busch, J. R. Chapman, G. L. Duran, J. Gruszko, R. Henning, E. L. Martin, J. F. Wilkerson</dc:creator>
    </item>
  </channel>
</rss>
