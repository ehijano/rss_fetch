<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 05:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Counting Unit Circular Arc Intersections</title>
      <link>https://arxiv.org/abs/2602.01074</link>
      <description>arXiv:2602.01074v1 Announce Type: new 
Abstract: Given a set of $n$ circular arcs of the same radius in the plane, we consider the problem of computing the number of intersections among the arcs. The problem was studied before and the previously best algorithm solves the problem in $O(n^{4/3+\epsilon})$ time [Agarwal, Pellegrini, and Sharir, SIAM J. Comput., 1993], for any constant $\epsilon&gt;0$. No progress has been made on the problem for more than 30 years. We present a new algorithm of $O(n^{4/3}\log^{16/3}n)$ time and improve it to $O(n^{1+\epsilon}+K^{1/3}n^{2/3}(\frac{n^2}{n+K})^{\epsilon}\log^{16/3}n)$ time for small $K$, where $K$ is the number of intersections of all arcs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01074v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haitao Wang</dc:creator>
    </item>
    <item>
      <title>On Saxe's theorems about the complexity of the Distance Geometry Problem</title>
      <link>https://arxiv.org/abs/2602.00001</link>
      <description>arXiv:2602.00001v1 Announce Type: cross 
Abstract: In 1979, James B.~Saxe published an extended summary on the complexity of the Distance Geometry Problem in the proceedings of the 17th Allerton Conference. Many of the proofs in his paper are sketches, and even the whole proofs do not have all the details. In this paper we provide a commentary to Saxe's results and hopefully more understandable versions thereof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00001v1</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>math.MG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ma\"el Kupperschmitt, Leo Liberti</dc:creator>
    </item>
    <item>
      <title>An Algorithm for Fast and Correct Computation of Reeb Spaces for PL Bivariate Fields</title>
      <link>https://arxiv.org/abs/2403.06564</link>
      <description>arXiv:2403.06564v4 Announce Type: replace 
Abstract: The Reeb space is a fundamental data structure in computational topology that represents the fiber topology of a multi-field (or multiple scalar fields), extending the level set topology of a scalar field. Efficient algorithms have been designed for computing Reeb graphs, however, computing correct Reeb spaces for PL bivariate fields, is a challenging open problem. There are only a few implementable algorithms in the literature for computing Reeb space or its approximation, via range quantization or by computing a Jacobi fiber surface, which are computationally expensive or have correctness issues, i.e., the computed Reeb space may not be topologically equivalent or homeomorphic to the actual Reeb space. In the current paper, we propose a novel algorithm for fast and correct computation of the Reeb space corresponding to a generic PL bivariate field defined on a triangulation $\mathbb{M}$ of a $3$-manifold without boundary, leveraging the fast algorithms for computing Reeb graphs in the literature.
  Our algorithm is based on the computation of a Multi-Dimensional Reeb Graph (MDRG) which is first proved to be homeomorphic with the Reeb space. For the correct computation of the MDRG, we compute the Jacobi set of the PL bivariate field and its projection into the Reeb space, called the Jacobi structure. Finally, the correct Reeb space is obtained by computing a net-like structure embedded in the Reeb space and then computing its $2$-sheets in the net-like structure. The time complexity of our algorithm is $\mathcal{O}(n^2 + n\, c_{int}\, \log n + nc_L^2)$, where $n$ is the total number of simplices in $\mathbb{M}$, $c_{int}$ is the number of intersection points of the projections of the non-adjacent Jacobi set edges on the range of the bivariate field and $c_L$ is the upper bound on the number of simplices in the link of an edge of $\mathbb{M}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06564v4</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amit Chattopadhyay, Yashwanth Ramamurthi, Osamu Saeki</dc:creator>
    </item>
    <item>
      <title>The Flood Complex: Large-Scale Persistent Homology on Millions of Points</title>
      <link>https://arxiv.org/abs/2509.22432</link>
      <description>arXiv:2509.22432v2 Announce Type: replace-cross 
Abstract: We consider the problem of computing persistent homology (PH) for large-scale Euclidean point cloud data, aimed at downstream machine learning tasks, where the exponential growth of the most widely-used Vietoris-Rips complex imposes serious computational limitations. Although more scalable alternatives such as the Alpha complex or sparse Rips approximations exist, they often still result in a prohibitively large number of simplices. This poses challenges in the complex construction and in the subsequent PH computation, prohibiting their use on large-scale point clouds. To mitigate these issues, we introduce the Flood complex, inspired by the advantages of the Alpha and Witness complex constructions. Informally, at a given filtration value $r\geq 0$, the Flood complex contains all simplices from a Delaunay triangulation of a small subset of the point cloud $X$ that are fully covered by balls of radius $r$ emanating from $X$, a process we call flooding. Our construction allows for efficient PH computation, possesses several desirable theoretical properties, and is amenable to GPU parallelization. Scaling experiments on 3D point cloud data show that we can compute PH of up to dimension 2 on several millions of points. Importantly, when evaluating object classification performance on real-world and synthetic data, we provide evidence that this scaling capability is needed, especially if objects are geometrically or topologically complex, yielding performance superior to other PH-based methods and neural networks for point cloud data. Source code and datasets are available on https://github.com/plus-rkwitt/flooder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22432v2</guid>
      <category>cs.LG</category>
      <category>cs.CG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Graf, Paolo Pellizzoni, Martin Uray, Stefan Huber, Roland Kwitt</dc:creator>
    </item>
    <item>
      <title>Algorithms for orthogonal partitioning into four parts</title>
      <link>https://arxiv.org/abs/2511.20866</link>
      <description>arXiv:2511.20866v2 Announce Type: replace-cross 
Abstract: The famous pancake theorem states that for every finite set $X$ in the plane, there exist two orthogonal lines that divide $X$ into four equal parts. We propose an algorithm whose running time is linear in the number of points in $X$ and prove that this complexity is optimal. We also consider generalizations of the pancake theorem and show that orthogonal hyperplanes can be found in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20866v2</guid>
      <category>math.CO</category>
      <category>cs.CG</category>
      <category>math.MG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Fakhrutdinov, Oleg R. Musin</dc:creator>
    </item>
  </channel>
</rss>
