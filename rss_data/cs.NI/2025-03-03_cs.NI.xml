<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Mar 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalable Coordinated Learning for H2M/R Applications over Optical Access Networks (Invited)</title>
      <link>https://arxiv.org/abs/2502.20598</link>
      <description>arXiv:2502.20598v1 Announce Type: new 
Abstract: One of the primary research interests adhering to next-generation fiber-wireless access networks is human-to-machine/robot (H2M/R) collaborative communications facilitating Industry 5.0. This paper discusses scalable H2M/R communications across large geographical distances that also allow rapid onboarding of new machines/robots as $\sim72\%$ training time is saved through global-local coordinated learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20598v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sourav Mondal, Elaine Wong</dc:creator>
    </item>
    <item>
      <title>Towards Specialized Wireless Networks Using an ML-Driven Radio Interface</title>
      <link>https://arxiv.org/abs/2502.20996</link>
      <description>arXiv:2502.20996v1 Announce Type: new 
Abstract: Future wireless networks will need to support diverse applications (such as extended reality), scenarios (such as fully automated industries), and technological advances (such as terahertz communications). Current wireless networks are designed to perform adequately across multiple scenarios so they lack the adaptability needed for specific use cases. Therefore, meeting the stringent requirements of next-generation applications incorporating technology advances and operating in novel scenarios will necessitate wireless specialized networks which we refer to as SpecNets. These networks, equipped with cognitive capabilities, dynamically adapt to the unique demands of each application, e.g., by automatically selecting and configuring network mechanisms. An enabler of SpecNets are the recent advances in artificial intelligence and machine learning (AI/ML), which allow to continuously learn and react to changing requirements and scenarios. By integrating AI/ML functionalities, SpecNets will fully leverage the concept of AI/ML-defined radios (MLDRs) that are able to autonomously establish their own communication protocols by acquiring contextual information and dynamically adapting to it. In this paper, we introduce SpecNets and explain how MLDR interfaces enable this concept. We present three illustrative use cases for wireless local area networks (WLANs): bespoke industrial networks, traffic-aware robust THz links, and coexisting networks. Finally, we showcase SpecNets' benefits in the industrial use case by introducing a lightweight, fast-converging ML agent based on multi-armed bandits (MABs). This agent dynamically optimizes channel access to meet varying performance needs: high throughput, low delay, or fair access. Results demonstrate significant gains over IEEE 802.11, highlighting the system's autonomous adaptability across diverse scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20996v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kamil Szczech, Maksymilian Wojnar, Katarzyna Kosek-Szott, Krzysztof Rusek, Szymon Szott, Dileepa Marasinghe, Nandana Rajatheva, Richard Combes, Francesc Wilhelmi, Anders Jonsson, Boris Bellalta</dc:creator>
    </item>
    <item>
      <title>Including Follower Dynamics in Beaconing for Platooning Safety</title>
      <link>https://arxiv.org/abs/2502.21039</link>
      <description>arXiv:2502.21039v1 Announce Type: new 
Abstract: In this paper, we propose procedures to address platoon follower dynamics within adaptive beaconing. We implement them in a known adaptive beaconing scheme which is Jerk Beaconing (JB) to improve its safety. We evaluate our proposed approach in terms of safety, string stability and the channel busy ratio (CBR) overhead. The results reveal that our proposal significantly enhances safety without imposing substantial CBR overhead and maintains the string stability of the PATH CACC controller under normal conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21039v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hassan Laghbi, Nigel Thomas</dc:creator>
    </item>
    <item>
      <title>Resource Allocation and Sharing in URLLC for IoT Applications using Shareability Graphs</title>
      <link>https://arxiv.org/abs/2502.21080</link>
      <description>arXiv:2502.21080v1 Announce Type: new 
Abstract: The current development trend of wireless communications aims at coping with the very stringent reliability and latency requirements posed by several emerging Internet of Things (IoT) application scenarios. Since the problem of realizing Ultra Reliable Low-Latency Communications (URLLC) is becoming more and more important, it has attracted the attention of researchers, and new efficient resource allocation algorithms are necessary. In this paper, we consider a challenging scenario where the available spectrum might be fragmented across non-adjacent portions of the band, and channels are differently affected by interference coming from surrounding networks. Furthermore, Channel State Information (CSI) is assumed to be unavailable, thus requiring an allocation of resources based only on topology information and channel statistics. To address this challenge in a dense smart factory scenario where devices periodically transmit their data to a common receiver, we present a novel resource allocation methodology based on a graph-theoretical approach originally designed to allocate mobility resources in on-demand, shared transportation. The proposed methodology is compared with two benchmark allocation strategies, showing its ability of increasing spectral efficiency of as much as 50% with respect to the best performing benchmark. Contrary to what happens in many resource allocation settings, this increase in spectrum efficiency does not come at the expense of fairness, which is also increased as compared to benchmark algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21080v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2020.2999645</arxiv:DOI>
      <arxiv:journal_reference>IEEE Internet of Things Journal, vol. 7, no. 10, pp. 10511-10526, Oct. 2020</arxiv:journal_reference>
      <dc:creator>Federico Librino, Paolo Santi</dc:creator>
    </item>
    <item>
      <title>Distributed Data Access in Industrial Edge Networks</title>
      <link>https://arxiv.org/abs/2502.21117</link>
      <description>arXiv:2502.21117v1 Announce Type: new 
Abstract: Wireless edge networks in smart industrial environments increasingly operate using advanced sensors and autonomous machines interacting with each other and generating huge amounts of data. Those huge amounts of data are bound to make data management (e.g., for processing, storing, computing) a big challenge. Current data management approaches, relying primarily on centralized data storage, might not be able to cope with the scalability and real time requirements of Industry 4.0 environments, while distributed solutions are increasingly being explored. In this paper, we introduce the problem of distributed data access in multi-hop wireless industrial edge deployments, whereby a set of consumer nodes needs to access data stored in a set of data cache nodes, satisfying the industrial data access delay requirements and at the same time maximizing the network lifetime. We prove that the introduced problem is computationally intractable and, after formulating the objective function, we design a two-step algorithm in order to address it. We use an open testbed with real devices for conducting an experimental investigation on the performance of the algorithm. Then, we provide two online improvements, so that the data distribution can dynamically change before the first node in the network runs out of energy. We compare the performance of the methods via simulations for different numbers of network nodes and data consumers, and we show significant lifetime prolongation and increased energy efficiency when employing the method which is using only decentralized low-power wireless communication instead of the method which is using also centralized local area wireless communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21117v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JSAC.2020.2980917</arxiv:DOI>
      <arxiv:journal_reference>IEEE Journal on Selected Areas in Communications, vol. 38, no. 5, pp. 915-927, May 2020</arxiv:journal_reference>
      <dc:creator>Theofanis P. Raptis, Andrea Passarella, Marco Conti</dc:creator>
    </item>
    <item>
      <title>The Complexity-Performance Tradeoff in Resource Allocation for URLLC Exploiting Dynamic CSI</title>
      <link>https://arxiv.org/abs/2502.21121</link>
      <description>arXiv:2502.21121v1 Announce Type: new 
Abstract: The challenging applications envisioned for the future Internet of Things networks are making it urgent to develop fast and scalable resource allocation algorithms able to meet the stringent reliability and latency constraints typical of the Ultra Reliable, Low Latency Communications (URLLC).
  However, there is an inherent tradeoff between complexity and performance to be addressed: sophisticated resource allocation methods providing optimized spectrum utilization are challenged by the scale of applications and the concomitant stringent latency constraints. Whether non-trivial resource allocation approaches can be successfully applied in large-scale network instances is still an open question that this paper aims to address. More specifically, we consider a scenario in which Channel State Information (CSI) is used to improve spectrum allocation in a radio environment that experiences channel time correlation.
  Channel correlation allows the usage of CSI for longer time before an update, thus lowering the overhead burden. Following this intuition, we propose a dynamic pilot transmission allocation scheme in order to adaptively tune the CSI age.
  We systematically analyze the improvement of this approach applied to a sophisticated, recently introduced graph-based resource allocation method that we extend here to account for CSI.
  The results show that, even in very dense networks and accounting for the higher computational time of the graph-based approach, this algorithm is able to improve spectrum efficiency by over 12% as compared to a greedy heuristic, and that dynamic pilot transmissions allocation can further boost its performance in terms of fairness, while concomitantly further increase spectrum efficiency of 3-5%. \</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21121v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2021.3066104</arxiv:DOI>
      <arxiv:journal_reference>IEEE Internet of Things Journal, vol. 8, no. 17, pp. 13266-13277, 1 Sept.1, 2021</arxiv:journal_reference>
      <dc:creator>Federico Librino, Paolo Santi</dc:creator>
    </item>
    <item>
      <title>Channel, Mode and Power Optimization for non-Orthogonal D2D Communications: a Hybrid Approach</title>
      <link>https://arxiv.org/abs/2502.21255</link>
      <description>arXiv:2502.21255v1 Announce Type: new 
Abstract: The increasing traffic demand in cellular networks has recently led to the investigation of new strategies to save precious resources like spectrum and energy. Direct device-to-device (D2D) communication becomes a promising solution if the two terminals are located in close proximity. In this case, the D2D communications should coexist with cellular transmissions, so they must be carefully scheduled in order to avoid harmful interference impacts. In this paper, we outline a novel framework encompassing channel allocation, mode selection and power control for D2D communications. Power allocation is done in a distributed and cognitive fashion at the beginning of each time slot, based on local information, while channel/mode selection is performed in a centralized manner only at the beginning of an epoch, a time interval including a series of subsequent time slots. This hybrid approach guarantees an effective tradeoff between overhead and adaptivity. We analyze in depth the distributed power allocation mechanism, and we state a theorem which allows to derive the optimal power allocation strategy and to compute the corresponding throughput. Extensive simulations confirm the benefits granted by our approach, when compared with state-of-the-art distributed schemes, in terms of throughput and fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21255v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCCN.2019.2961651</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Cognitive Communications and Networking, vol. 6, no. 2, pp. 657-668, June 2020</arxiv:journal_reference>
      <dc:creator>Federico Librino, Giorgio Quer</dc:creator>
    </item>
    <item>
      <title>Robust Multicast Origin Authentication in MACsec and CANsec for Automotive Scenarios</title>
      <link>https://arxiv.org/abs/2502.20555</link>
      <description>arXiv:2502.20555v1 Announce Type: cross 
Abstract: Having everything interconnected through the Internet, including vehicle onboard systems, is making security a primary concern in the automotive domain as well. Although Ethernet and CAN XL provide link-level security based on symmetric cryptography, they do not support origin authentication for multicast transmissions. Asymmetric cryptography is unsuitable for networked embedded control systems with real-time constraints and limited computational resources. In these cases, solutions derived from the TESLA broadcast authentication protocol may constitute a more suitable option.
  In this paper, some such strategies are presented and analyzed that allow for multicast origin authentication, also improving robustness to frame losses by means of interleaved keychains. A flexible authentication mechanism that relies on a unified receiver is then proposed, which enables transmitters to select strategies at runtime, to achieve the best compromise among security, reliability, and resource consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20555v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gianluca Cena, Lucia Seno, Stefano Scanzio</dc:creator>
    </item>
    <item>
      <title>Towards Zero Touch Networks: Cross-Layer Automated Security Solutions for 6G Wireless Networks</title>
      <link>https://arxiv.org/abs/2502.20627</link>
      <description>arXiv:2502.20627v1 Announce Type: cross 
Abstract: The transition from 5G to 6G mobile networks necessitates network automation to meet the escalating demands for high data rates, ultra-low latency, and integrated technology. Recently, Zero-Touch Networks (ZTNs), driven by Artificial Intelligence (AI) and Machine Learning (ML), are designed to automate the entire lifecycle of network operations with minimal human intervention, presenting a promising solution for enhancing automation in 5G/6G networks. However, the implementation of ZTNs brings forth the need for autonomous and robust cybersecurity solutions, as ZTNs rely heavily on automation. AI/ML algorithms are widely used to develop cybersecurity mechanisms, but require substantial specialized expertise and encounter model drift issues, posing significant challenges in developing autonomous cybersecurity measures. Therefore, this paper proposes an automated security framework targeting Physical Layer Authentication (PLA) and Cross-Layer Intrusion Detection Systems (CLIDS) to address security concerns at multiple Internet protocol layers. The proposed framework employs drift-adaptive online learning techniques and a novel enhanced Successive Halving (SH)-based Automated ML (AutoML) method to automatically generate optimized ML models for dynamic networking environments. Experimental results illustrate that the proposed framework achieves high performance on the public Radio Frequency (RF) fingerprinting and the Canadian Institute for CICIDS2017 datasets, showcasing its effectiveness in addressing PLA and CLIDS tasks within dynamic and complex networking environments. Furthermore, the paper explores open challenges and research directions in the 5G/6G cybersecurity domain. This framework represents a significant advancement towards fully autonomous and secure 6G networks, paving the way for future innovations in network automation and cybersecurity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20627v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Yang, Shimaa Naser, Abdallah Shami, Sami Muhaidat, Lyndon Ong, M\'erouane Debbah</dc:creator>
    </item>
    <item>
      <title>The Effect of Hop-count Modification Attack on Random Walk-based SLP Schemes Developed forWSNs: a Study</title>
      <link>https://arxiv.org/abs/2502.20902</link>
      <description>arXiv:2502.20902v1 Announce Type: cross 
Abstract: Source location privacy (SLP) has been of great concern in WSNs when deployed for habitat monitoring applications. The issue is taken care of by employing privacy-preserving routing schemes. In the existing works, the attacker is assumed to be passive in nature and backtracks to the source of information by eavesdropping the message signals. In this work, we try to understand the impact of active attacks by proposing a new hybrid attack model consisting of both active and passive attacks. The proposed model is then applied to three existing TTL-based random walk SLP solutions: phantom routing scheme (PRS), source location privacy using randomized routes (SLP-R), and position-independent section-based scheme (PSSLP). The performance of the algorithms in terms of privacy metrics is compared in the case of pure passive attack and hybrid attack of varying intensity. The results indicate a significant degradation in the privacy protection performance of the reference algorithms in the face of the proposed hybrid attack model indicating the importance and relevance of such attacks. It is further observed that the hybrid attack can be optimized to increase the vulnerability of the existing solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20902v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Manjula Rajaa, Anirban Ghoshb, Chukkapalli Praveen Kumarc, Suleiman Samba, C N Shariff</dc:creator>
    </item>
    <item>
      <title>Enabling AutoML for Zero-Touch Network Security: Use-Case Driven Analysis</title>
      <link>https://arxiv.org/abs/2502.21286</link>
      <description>arXiv:2502.21286v1 Announce Type: cross 
Abstract: Zero-Touch Networks (ZTNs) represent a state-of-the-art paradigm shift towards fully automated and intelligent network management, enabling the automation and intelligence required to manage the complexity, scale, and dynamic nature of next-generation (6G) networks. ZTNs leverage Artificial Intelligence (AI) and Machine Learning (ML) to enhance operational efficiency, support intelligent decision-making, and ensure effective resource allocation. However, the implementation of ZTNs is subject to security challenges that need to be resolved to achieve their full potential. In particular, two critical challenges arise: the need for human expertise in developing AI/ML-based security mechanisms, and the threat of adversarial attacks targeting AI/ML models. In this survey paper, we provide a comprehensive review of current security issues in ZTNs, emphasizing the need for advanced AI/ML-based security mechanisms that require minimal human intervention and protect AI/ML models themselves. Furthermore, we explore the potential of Automated ML (AutoML) technologies in developing robust security solutions for ZTNs. Through case studies, we illustrate practical approaches to securing ZTNs against both conventional and AI/ML-specific threats, including the development of autonomous intrusion detection systems and strategies to combat Adversarial ML (AML) attacks. The paper concludes with a discussion of the future research directions for the development of ZTN security approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21286v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNSM.2024.3376631</arxiv:DOI>
      <arxiv:journal_reference>in IEEE Transactions on Network and Service Management, vol. 21, no. 3, pp. 3555-3582, June 2024</arxiv:journal_reference>
      <dc:creator>Li Yang, Mirna El Rajab, Abdallah Shami, Sami Muhaidat</dc:creator>
    </item>
    <item>
      <title>WHALE-FL: Wireless and Heterogeneity Aware Latency Efficient Federated Learning over Mobile Devices via Adaptive Subnetwork Scheduling</title>
      <link>https://arxiv.org/abs/2405.00885</link>
      <description>arXiv:2405.00885v3 Announce Type: replace-cross 
Abstract: As a popular distributed learning paradigm, federated learning (FL) over mobile devices fosters numerous applications, while their practical deployment is hindered by participating devices' computing and communication heterogeneity. Some pioneering research efforts proposed to extract subnetworks from the global model, and assign as large a subnetwork as possible to the device for local training based on its full computing and communications capacity. Although such fixed size subnetwork assignment enables FL training over heterogeneous mobile devices, it is unaware of (i) the dynamic changes of devices' communication and computing conditions and (ii) FL training progress and its dynamic requirements of local training contributions, both of which may cause very long FL training delay. Motivated by those dynamics, in this paper, we develop a wireless and heterogeneity aware latency efficient FL (WHALE-FL) approach to accelerate FL training through adaptive subnetwork scheduling. Instead of sticking to the fixed size subnetwork, WHALE-FL introduces a novel subnetwork selection utility function to capture device and FL training dynamics, and guides the mobile device to adaptively select the subnetwork size for local training based on (a) its computing and communication capacity, (b) its dynamic computing and/or communication conditions, and (c) FL training status and its corresponding requirements for local training contributions. Our evaluation shows that, compared with peer designs, WHALE-FL effectively accelerates FL training without sacrificing learning accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00885v3</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.IV</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huai-an Su, Jiaxiang Geng, Liang Li, Xiaoqi Qin, Yanzhao Hou, Hao Wang, Xin Fu, Miao Pan</dc:creator>
    </item>
    <item>
      <title>Scaling Large-Language-Model-based Multi-Agent Collaboration</title>
      <link>https://arxiv.org/abs/2406.07155</link>
      <description>arXiv:2406.07155v2 Announce Type: replace-cross 
Abstract: Recent breakthroughs in large language model-driven autonomous agents have revealed that multi-agent collaboration often surpasses each individual through collective reasoning. Inspired by the neural scaling law--increasing neurons enhances performance, this study explores whether the continuous addition of collaborative agents can yield similar benefits. Technically, we utilize directed acyclic graphs to organize agents into a multi-agent collaboration network (MacNet), upon which their interactive reasoning is topologically orchestrated for autonomous task solving. Extensive evaluations reveal that it effectively supports collaboration among over a thousand agents, with irregular topologies outperforming regular ones. We also identify a collaborative scaling law--the overall performance follows a logistic growth pattern as agents scale, with collaborative emergence occurring earlier than traditional neural emergence. We speculate this may be because scaling agents catalyzes their multidimensional considerations during interactive reflection and refinement, thereby producing more comprehensive artifacts. The code is available at https://github.com/OpenBMB/ChatDev/tree/macnet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07155v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Qian, Zihao Xie, YiFei Wang, Wei Liu, Kunlun Zhu, Hanchen Xia, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun</dc:creator>
    </item>
    <item>
      <title>Task-Driven Semantic Quantization and Imitation Learning for Goal-Oriented Communications</title>
      <link>https://arxiv.org/abs/2502.17842</link>
      <description>arXiv:2502.17842v2 Announce Type: replace-cross 
Abstract: Semantic communication marks a new paradigm shift from bit-wise data transmission to semantic information delivery for the purpose of bandwidth reduction. To more effectively carry out specialized downstream tasks at the receiver end, it is crucial to define the most critical semantic message in the data based on the task or goal-oriented features. In this work, we propose a novel goal-oriented communication (GO-COM) framework, namely Goal-Oriented Semantic Variational Autoencoder (GOS-VAE), by focusing on the extraction of the semantics vital to the downstream tasks. Specifically, we adopt a Vector Quantized Variational Autoencoder (VQ-VAE) to compress media data at the transmitter side. Instead of targeting the pixel-wise image data reconstruction, we measure the quality-of-service at the receiver end based on a pre-defined task-incentivized model. Moreover, to capture the relevant semantic features in the data reconstruction, imitation learning is adopted to measure the data regeneration quality in terms of goal-oriented semantics. Our experimental results demonstrate the power of imitation learning in characterizing goal-oriented semantics and bandwidth efficiency of our proposed GOS-VAE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17842v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>2025 International Conference on Communications (IEEE ICC)</arxiv:journal_reference>
      <dc:creator>Yu-Chieh Chao, Yubei Chen, Weiwei Wang, Achintha Wijesinghe, Suchinthaka Wanninayaka, Songyang Zhang, Zhi Ding</dc:creator>
    </item>
  </channel>
</rss>
