<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Apr 2024 04:02:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Zak-OTFS for Integration of Sensing and Communication</title>
      <link>https://arxiv.org/abs/2404.04182</link>
      <description>arXiv:2404.04182v1 Announce Type: new 
Abstract: The Zak-OTFS input/output (I/O) relation is predictable and non-fading when the delay and Doppler periods are greater than the effective channel delay and Doppler spreads, a condition which we refer to as the crystallization condition. The filter taps can simply be read off from the response to a single Zak-OTFS point (impulse) pulsone waveform, and the I/O relation can be reconstructed for a sampled system that operates under finite duration and bandwidth constraints. Predictability opens up the possibility of a model-free mode of operation. The time-domain realization of a Zak-OTFS point pulsone is a pulse train modulated by a tone, hence the name, pulsone. The Peak-to-Average Power Ratio (PAPR) of a pulsone is about $15$ dB, and we describe a general method for constructing a spread pulsone for which the time-domain realization has a PAPR of about 6dB. We construct the spread pulsone by applying a type of discrete spreading filter to a Zak-OTFS point pulsone. The self-ambiguity function of the point pulsone is supported on the period lattice ${\Lambda}_{p}$, and by applying a discrete chirp filter, we obtain a spread pulsone with a self-ambiguity function that is supported on a rotated lattice ${\Lambda^*}$. We show that if the channel satisfies the crystallization conditions with respect to ${\Lambda^*}$ then the effective DD domain filter taps can simply be read off from the cross-ambiguity between the channel response to the spread pulsone and the transmitted spread pulsone. If, in addition, the channel satisfies the crystallization conditions with respect to the period lattice ${\Lambda}_{p}$, then in an OTFS frame consisting of a spread pilot pulsone and point data pulsones, after cancelling the received signal corresponding to the spread pulsone, we can recover the channel response to any data pulsone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04182v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ubadah, Saif Khan Mohammed, Ronny Hadani, Shachar Kons, Ananthanarayanan Chockalingam, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>Improvement of Performance in Freezing of Gait detection in Parkinsons Disease using Transformer networks and a single waist worn triaxial accelerometer</title>
      <link>https://arxiv.org/abs/2404.03704</link>
      <description>arXiv:2404.03704v1 Announce Type: cross 
Abstract: Freezing of gait (FOG) is one of the most incapacitating symptoms in Parkinsons disease, affecting more than 50 percent of patients in advanced stages of the disease. The presence of FOG may lead to falls and a loss of independence with a consequent reduction in the quality of life. Wearable technology and artificial intelligence have been used for automatic FOG detection to optimize monitoring. However, differences between laboratory and daily-life conditions present challenges for the implementation of reliable detection systems. Consequently, improvement of FOG detection methods remains important to provide accurate monitoring mechanisms intended for free-living and real-time use. This paper presents advances in automatic FOG detection using a single body-worn triaxial accelerometer and a novel classification algorithm based on Transformers and convolutional networks. This study was performed with data from 21 patients who manifested FOG episodes while performing activities of daily living in a home setting. Results indicate that the proposed FOG-Transformer can bring a significant improvement in FOG detection using leave-one-subject-out cross-validation (LOSO CV). These results bring opportunities for the implementation of accurate monitoring systems for use in ambulatory or home settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03704v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2022.105482</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence Volume 116, November 2022, 105482</arxiv:journal_reference>
      <dc:creator>Luis Sigcha, Luigi Borz\`i, Ignacio Pav\'on, N\'elson Costa, Susana Costa, Pedro Arezes, Juan-Manuel L\'opez, Guillermo De Arcas</dc:creator>
    </item>
    <item>
      <title>Randomized Greedy Methods for Weak Submodular Sensor Selection with Robustness Considerations</title>
      <link>https://arxiv.org/abs/2404.03740</link>
      <description>arXiv:2404.03740v1 Announce Type: cross 
Abstract: We study a pair of budget- and performance-constrained weak submodular maximization problems. For computational efficiency, we explore the use of stochastic greedy algorithms which limit the search space via random sampling instead of the standard greedy procedure which explores the entire feasible search space. We propose a pair of stochastic greedy algorithms, namely, Modified Randomized Greedy (MRG) and Dual Randomized Greedy (DRG) to approximately solve the budget- and performance-constrained problems, respectively. For both algorithms, we derive approximation guarantees that hold with high probability. We then examine the use of DRG in robust optimization problems wherein the objective is to maximize the worst-case of a number of weak submodular objectives and propose the Randomized Weak Submodular Saturation Algorithm (Random-WSSA). We further derive a high-probability guarantee for when Random-WSSA successfully constructs a robust solution. Finally, we showcase the effectiveness of these algorithms in a variety of relevant uses within the context of Earth-observing LEO constellations which estimate atmospheric weather conditions and provide Earth coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03740v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ege C. Kaya, Michael Hibbard, Takashi Tanaka, Ufuk Topcu, Abolfazl Hashemi</dc:creator>
    </item>
    <item>
      <title>Localized Distributional Robustness in Submodular Multi-Task Subset Selection</title>
      <link>https://arxiv.org/abs/2404.03759</link>
      <description>arXiv:2404.03759v1 Announce Type: cross 
Abstract: In this work, we approach the problem of multi-task submodular optimization with the perspective of local distributional robustness, within the neighborhood of a reference distribution which assigns an importance score to each task. We initially propose to introduce a regularization term which makes use of the relative entropy to the standard multi-task objective. We then demonstrate through duality that this novel formulation itself is equivalent to the maximization of a submodular function, which may be efficiently carried out through standard greedy selection methods. This approach bridges the existing gap in the optimization of performance-robustness trade-offs in multi-task subset selection. To numerically validate our theoretical results, we test the proposed method in two different setting, one involving the selection of satellites in low Earth orbit constellations in the context of a sensor selection problem, and the other involving an image summarization task using neural networks. Our method is compared with two other algorithms focused on optimizing the performance of the worst-case task, and on directly optimizing the performance on the reference distribution itself. We conclude that our novel formulation produces a solution that is locally distributional robust, and computationally inexpensive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03759v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ege C. Kaya, Abolfazl Hashemi</dc:creator>
    </item>
    <item>
      <title>The ESPRIT algorithm under high noise: Optimal error scaling and noisy super-resolution</title>
      <link>https://arxiv.org/abs/2404.03885</link>
      <description>arXiv:2404.03885v1 Announce Type: cross 
Abstract: Subspace-based signal processing techniques, such as the Estimation of Signal Parameters via Rotational Invariant Techniques (ESPRIT) algorithm, are popular methods for spectral estimation. These algorithms can achieve the so-called super-resolution scaling under low noise conditions, surpassing the well-known Nyquist limit. However, the performance of these algorithms under high-noise conditions is not as well understood. Existing state-of-the-art analysis indicates that ESPRIT and related algorithms can be resilient even for signals where each observation is corrupted by statistically independent, mean-zero noise of size $\mathcal{O}(1)$, but these analyses only show that the error $\epsilon$ decays at a slow rate $\epsilon=\mathcal{\tilde{O}}(n^{-1/2})$ with respect to the cutoff frequency $n$. In this work, we prove that under certain assumptions of bias and high noise, the ESPRIT algorithm can attain a significantly improved error scaling $\epsilon = \mathcal{\tilde{O}}(n^{-3/2})$, exhibiting noisy super-resolution scaling beyond the Nyquist limit. We further establish a theoretical lower bound and show that this scaling is optimal. Our analysis introduces novel matrix perturbation results, which could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03885v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyan Ding, Ethan N. Epperly, Lin Lin, Ruizhe Zhang</dc:creator>
    </item>
    <item>
      <title>Approximate UMAP allows for high-rate online visualization of high-dimensional data streams</title>
      <link>https://arxiv.org/abs/2404.04001</link>
      <description>arXiv:2404.04001v1 Announce Type: cross 
Abstract: In the BCI field, introspection and interpretation of brain signals are desired for providing feedback or to guide rapid paradigm prototyping but are challenging due to the high noise level and dimensionality of the signals. Deep neural networks are often introspected by transforming their learned feature representations into 2- or 3-dimensional subspace visualizations using projection algorithms like Uniform Manifold Approximation and Projection (UMAP). Unfortunately, these methods are computationally expensive, making the projection of data streams in real-time a non-trivial task. In this study, we introduce a novel variant of UMAP, called approximate UMAP (aUMAP). It aims at generating rapid projections for real-time introspection. To study its suitability for real-time projecting, we benchmark the methods against standard UMAP and its neural network counterpart parametric UMAP. Our results show that approximate UMAP delivers projections that replicate the projection space of standard UMAP while decreasing projection speed by an order of magnitude and maintaining the same training time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04001v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Wassenaar, Pierre Guetschel, Michael Tangermann</dc:creator>
    </item>
    <item>
      <title>Next Generation Multiple Access for IMT Towards 2030 and Beyond</title>
      <link>https://arxiv.org/abs/2404.04012</link>
      <description>arXiv:2404.04012v1 Announce Type: cross 
Abstract: Multiple access techniques are fundamental to the design of wireless communication systems, since many crucial components of such systems depend on the choice of the multiple access technique. Because of the importance of multiple access, there has been an ongoing quest during the past decade to develop next generation multiple access (NGMA). Among those potential candidates for NGMA, non-orthogonal multiple access (NOMA) has received significant attention from both the industrial and academic research communities, and has been highlighted in the recently published International Mobile Telecommunications (IMT)-2030 Framework. However, there is still no consensus in the research community about how exactly NOMA assisted NGMA should be designed. This perspective is to outline three important features of NOMA assisted NGMA, namely multi-domain utilization, multi-mode compatibility, and multi-dimensional optimality, where important directions for future research into the design of NOMA assisted NGMA are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04012v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiguo Ding, Robert Schober, Pingzhi Fan, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>PASO -- Astronomy and Space Situational Awareness in a Dark Sky Destination</title>
      <link>https://arxiv.org/abs/2404.04090</link>
      <description>arXiv:2404.04090v1 Announce Type: cross 
Abstract: The Pampilhosa da Serra Space Observatory (PASO) is located in the center of the continental Portuguese territory, in the heart of a certified Dark Sky destination by the Starlight Foundation (Aldeias do Xisto) and has been an instrumental asset to advance science, education and astrotourism certifications. PASO hosts astronomy and Space Situational Awareness (SSA) activities including a node of the Portuguese Space Surveillance \&amp; Tracking (SST) infrastructure network, such as a space radar currently in test phase using GEM radiotelescope, a double Wide Field of View Telescope system, a EUSST optical sensor telescope. These instruments allow surveillance of satellite and space debris in LEO, MEO and GEO orbits. The WFOV telescope offers spectroscopy capabilities enabling light curve analysis and cosmic sources monitoring. Instruments for Space Weather are being considered for installation to monitor solar activities and expand the range of SSA services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04090v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.HE</category>
      <category>eess.SP</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Domingos Barbosa, Bruno Coelho, Miguel Bergano, Constan\c{c}a Alves, Alexandre C. M. Correia, Lu\'is Cupido, Jos\'e Freitas, Lu\'is Gon\c{c}alves, Bruce Grossan, Anna Guerman, Allan K. de Almeida Jr., Dalmiro Maia, Bruno Morgado, Jo\~ao Pandeirada, Val\'erio Ribeiro, Gon\c{c}alo Rosa, George Smoot, Timoth\'ee Vaillant, Thyrso Villela, Carlos Alexandre Wuensche</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Aided Cooperative Localization under Dense Urban Environment</title>
      <link>https://arxiv.org/abs/2404.04096</link>
      <description>arXiv:2404.04096v1 Announce Type: cross 
Abstract: Future wireless network technology provides automobiles with the connectivity feature to consolidate the concept of vehicular networks that collaborate on conducting cooperative driving tasks. The full potential of connected vehicles, which promises road safety and quality driving experience, can be leveraged if machine learning models guarantee the robustness in performing core functions including localization and controls. Location awareness, in particular, lends itself to the deployment of location-specific services and the improvement of the operation performance. The localization entails direct communication to the network infrastructure, and the resulting centralized positioning solutions readily become intractable as the network scales up. As an alternative to the centralized solutions, this article addresses decentralized principle of vehicular localization reinforced by machine learning techniques in dense urban environments with frequent inaccessibility to reliable measurement. As such, the collaboration of multiple vehicles enhances the positioning performance of machine learning approaches. A virtual testbed is developed to validate this machine learning model for real-map vehicular networks. Numerical results demonstrate universal feasibility of cooperative localization, in particular, for dense urban area configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04096v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoon Lee, Hong Ki Kim, Seung Hyun Oh, Sang Hyun Lee</dc:creator>
    </item>
    <item>
      <title>Mode Selection in Cognitive Radar Networks</title>
      <link>https://arxiv.org/abs/2312.09428</link>
      <description>arXiv:2312.09428v2 Announce Type: replace 
Abstract: Cognitive Radar Networks, which were popularized by Simon Haykin in 2006, have been proposed to address limitations with legacy radar installations. These limitations include large physical size, power consumption, fixed operating parameters, and single point vulnerabilities. Cognitive radar solves part of this problem through adaptability, using biologically inspired techniques to observe the environment and adjust operation accordingly. Cognitive radar networks (CRNs) extend the capabilities of cognitive radar spatially, providing the opportunity to observe targets from multiple angles to mitigate stealth effects; distribute resources over space and in time; obtain better tracking performance; and gain more information from a scene. Often, problems of cognition in CRNs are viewed through the lens of iterative learning problems - one or multiple cognitive processes are implemented in the network, where each process first observes the environment, then selects operating parameters (from discrete or continuous options) using the history of observations and previous rewards, then repeats the cycle. Further, cognitive radar networks often are modeled with a flexible architecture and wide-bandwidth front-ends, enabling the addition of electronic support measures such as passive signal estimation. In this work we consider questions of the form "How should a cognitive radar network choose when to observe targets?" and "How can a cognitive radar network reduce the amount of energy it uses?". We implement tools from the multi-armed bandit and age of information literature to select modes for the network, choosing either an active radar mode or a passive signal estimation mode. We show that through the use of target classes, the network can determine how often each target should be observed to optimize tracking performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09428v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William W. Howard, Samuel R. Shebert, Anthony F. Martone, R. Michael Buehrer</dc:creator>
    </item>
    <item>
      <title>DeepAlloc: CNN-Based Approach to Efficient Spectrum Allocation in Shared Spectrum Systems</title>
      <link>https://arxiv.org/abs/2201.07762</link>
      <description>arXiv:2201.07762v3 Announce Type: replace-cross 
Abstract: Shared spectrum systems facilitate spectrum allocation to unlicensed users without harming the licensed users; they offer great promise in optimizing spectrum utility, but their management (in particular, efficient spectrum allocation to unlicensed users) is challenging. A significant shortcoming of current allocation methods is that they are either done very conservatively to ensure correctness, or are based on imperfect propagation models and/or spectrum sensing with poor spatial granularity. This leads to poor spectrum utilization, the fundamental objective of shared spectrum systems.
  To allocate spectrum near-optimally to secondary users in general scenarios, we fundamentally need to have knowledge of the signal path-loss function. In practice, however, even the best known path-loss models have unsatisfactory accuracy, and conducting extensive surveys to gather path-loss values is infeasible. To circumvent this challenge, we propose to learn the spectrum allocation function directly using supervised learning techniques. We particularly address the scenarios when the primary users' information may not be available; for such settings, we make use of a crowdsourced sensing architecture and use the spectrum sensor readings as features. We develop an efficient CNN-based approach (called DeepAlloc) and address various challenges that arise in its application to the learning the spectrum allocation function. Via extensive large-scale simulation and a small testbed, we demonstrate the effectiveness of our developed techniques; in particular, we observe that our approach improves the accuracy of standard learning techniques and prior work by up to 60%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.07762v3</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2024.3352034</arxiv:DOI>
      <dc:creator>Mohammad Ghaderibaneh, Caitao Zhan, Himanshu Gupta</dc:creator>
    </item>
    <item>
      <title>Visual Decoding and Reconstruction via EEG Embeddings with Guided Diffusion</title>
      <link>https://arxiv.org/abs/2403.07721</link>
      <description>arXiv:2403.07721v5 Announce Type: replace-cross 
Abstract: How to decode human vision through neural signals has attracted a long-standing interest in neuroscience and machine learning. Modern contrastive learning and generative models improved the performance of fMRI-based visual decoding and reconstruction. However, the high cost and low temporal resolution of fMRI limit their applications in brain-computer interfaces (BCIs), prompting a high need for EEG-based visual reconstruction. In this study, we present an EEG-based visual reconstruction framework. It consists of a plug-and-play EEG encoder called the Adaptive Thinking Mapper (ATM), which is aligned with image embeddings, and a two-stage EEG guidance image generator that first transforms EEG features into image priors and then reconstructs the visual stimuli with a pre-trained image generator. Our approach allows EEG embeddings to achieve superior performance in image classification and retrieval tasks. Our two-stage image generation strategy vividly reconstructs images seen by humans. Furthermore, we analyzed the impact of signals from different time windows and brain regions on decoding and reconstruction. The versatility of our framework is demonstrated in the magnetoencephalogram (MEG) data modality. We report that EEG-based visual decoding achieves SOTA performance, highlighting the portability, low cost, and high temporal resolution of EEG, enabling a wide range of BCI applications. The code of ATM is available at https://github.com/dongyangli-del/EEG_Image_decode.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07721v5</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyang Li, Chen Wei, Shiying Li, Jiachen Zou, Quanying Liu</dc:creator>
    </item>
  </channel>
</rss>
