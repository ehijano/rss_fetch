<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Jul 2024 01:38:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 24 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Modelling brain connectomes networks: Solv is a worthy competitor to hyperbolic geometry!</title>
      <link>https://arxiv.org/abs/2407.16077</link>
      <description>arXiv:2407.16077v1 Announce Type: new 
Abstract: Finding suitable embeddings for connectomes (spatially embedded complex networks that map neural connections in the brain) is crucial for analyzing and understanding cognitive processes. Recent studies have found two-dimensional hyperbolic embeddings superior to Euclidean embeddings in modeling connectomes across species, especially human connectomes. However, those studies had limitations: geometries other than Euclidean, hyperbolic, or spherical were not considered. Following William Thurston's suggestion that the networks of neurons in the brain could be successfully represented in Solv geometry, we study the goodness-of-fit of the embeddings for 21 connectome networks (8 species). To this end, we suggest an embedding algorithm based on Simulating Annealing that allows us to embed connectomes to Euclidean, Spherical, Hyperbolic, Solv, Nil, and product geometries. Our algorithm tends to find better embeddings than the state-of-the-art, even in the hyperbolic case. Our findings suggest that while three-dimensional hyperbolic embeddings yield the best results in many cases, Solv embeddings perform reasonably well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16077v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>math.MG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dorota Celi\'nska-Kopczy\'nska, Eryk Kopczy\'nski</dc:creator>
    </item>
    <item>
      <title>Energy-information trade-off makes the cortical critical power law the optimal coding</title>
      <link>https://arxiv.org/abs/2407.16215</link>
      <description>arXiv:2407.16215v1 Announce Type: new 
Abstract: Stimulus responses of cortical neurons exhibit the critical power law, where the covariance eigenspectrum follows the power law with the exponent just at the edge of differentiability of the neural manifold. This criticality is conjectured to balance the expressivity and robustness of neural codes, because a non-differential fractal manifold spoils coding reliability. However, contrary to the conjecture, here we prove that the neural coding is not degraded even on the non-differentiable fractal manifold, where the coding is extremely sensitive to perturbations. Rather, we show that the trade-off between energetic cost and information always makes this critical power-law response the optimal neural coding. Direct construction of a maximum likelihood decoder of the power-law coding validates the theoretical prediction. By revealing the non-trivial nature of high-dimensional coding, the theory developed here will contribute to a deeper understanding of criticality and power laws in computation in biological and artificial neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16215v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tsuyoshi Tatsukawa, Jun-nosuke Teramae</dc:creator>
    </item>
    <item>
      <title>How Does a Single EEG Channel Tell Us About Brain States in Brain-Computer Interfaces ?</title>
      <link>https://arxiv.org/abs/2407.16249</link>
      <description>arXiv:2407.16249v1 Announce Type: new 
Abstract: Over recent decades, neuroimaging tools, particularly electroencephalography (EEG), have revolutionized our understanding of the brain and its functions. EEG is extensively used in traditional brain-computer interface (BCI) systems due to its low cost, non-invasiveness, and high temporal resolution. This makes it invaluable for identifying different brain states relevant to both medical and non-medical applications. Although this practice is widely recognized, current methods are mainly confined to lab or clinical environments because they rely on data from multiple EEG electrodes covering the entire head. Nonetheless, a significant advancement for these applications would be their adaptation for "real-world" use, using portable devices with a single-channel. In this study, we tackle this challenge through two distinct strategies: the first approach involves training models with data from multiple channels and then testing new trials on data from a single channel individually. The second method focuses on training with data from a single channel and then testing the performances of the models on data from all the other channels individually. To efficiently classify cognitive tasks from EEG data, we propose Convolutional Neural Networks (CNNs) with only a few parameters and fast learnable spectral-temporal features. We demonstrated the feasibility of these approaches on EEG data recorded during mental arithmetic and motor imagery tasks from three datasets. We achieved the highest accuracies of 100%, 91.55% and 73.45% in binary and 3-class classification on specific channels across three datasets. This study can contribute to the development of single-channel BCI and provides a robust EEG biomarker for brain states classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16249v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zaineb Ajra, Binbin Xu, G\'erard Dray, Jacky Montmain, St\'ephane Perrey</dc:creator>
    </item>
    <item>
      <title>Hyperbolic embedding of brain networks detects regions disrupted by neurodegeneration</title>
      <link>https://arxiv.org/abs/2407.16589</link>
      <description>arXiv:2407.16589v1 Announce Type: new 
Abstract: Graph theoretical methods have proven valuable for investigating alterations in both anatomical and functional brain connectivity networks during Alzheimer's disease (AD). Recent studies suggest that representing brain networks in a suitable geometric space can better capture their connectivity structure. This study introduces a novel approach to characterize brain connectivity changes using low-dimensional, informative representations of networks in a latent geometric space. Specifically, the networks are embedded in the Poincar\'e disk model of hyperbolic geometry. Here, we define a local measure of distortion of the geometric neighborhood of a node following a perturbation. The method is applied to a brain networks dataset of patients with AD and healthy participants, derived from DWI and fMRI scans. We show that, compared with standard graph measures, our method identifies more accurately the brain regions most affected by neurodegeneration. Notably, the abnormality detection in memory-related and frontal areas are robust across multiple brain parcellation scales. Finally, our findings suggest that the geometric perturbation score could serve as a potential biomarker for characterizing disease progression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16589v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alice Longhena, Martin Guillemaud, Fabrizio De Vico Fallani, Raffaella Lara Migliaccio, Mario Chavez</dc:creator>
    </item>
    <item>
      <title>A statistical significance test for spatio-temporal receptive field estimates obtained using spike-triggered averaging of binary pseudo-random sequences</title>
      <link>https://arxiv.org/abs/2407.16013</link>
      <description>arXiv:2407.16013v1 Announce Type: cross 
Abstract: Spatio-temporal receptive fields (STRF) of visual neurons are often estimated using spike-triggered averaging of binary pseudo-random stimulus sequences. The spike train of a visual neuron is recorded simultaneously with the stimulus presentation. The neuron's STRF is estimated by averaging the stimulus frames that coincide with spikes at fixed latencies. Although this is a widely used technique, an analytical method for determining the statistical significance of the estimated value of the STRF pixels seems to be lacking. Such a significance test would be useful for identifying the significant features of the STRF and investigating their relationship with experimental variables. Here, the distribution of the estimated STRF pixel values is derived for given spike trains, under the null hypothesis that spike occurrences and stimulus values are statistically independent. This distribution is then used for computing amplitude thresholds to determine the STRF pixels where the null hypothesis can be rejected at a desired two-tailed significance level. It is also proposed that the size of the receptive field may be inferred from the significant pixels. The application of the proposed method is illustrated on spike trains collected from individual mouse retinal ganglion cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16013v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11760-023-02603-1</arxiv:DOI>
      <arxiv:journal_reference>SIViP 17, 3759-3766 (2023)</arxiv:journal_reference>
      <dc:creator>Murat Okatan</dc:creator>
    </item>
    <item>
      <title>Hierarchical Machine Learning Classification of Parkinsonian Disorders using Saccadic Eye Movements: A Development and Validation Study</title>
      <link>https://arxiv.org/abs/2407.16063</link>
      <description>arXiv:2407.16063v2 Announce Type: cross 
Abstract: Discriminating between Parkinson's Disease (PD) and Progressive Supranuclear Palsy (PSP) is difficult due to overlapping symptoms, especially early on. Saccades (rapid conjugate eye movements between fixation points) are affected by both diseases but conventional saccade analyses exhibit group level differences only. We hypothesized analyzing entire saccade raw time series waveforms would permit superior individual level discrimination between PD, PSP, and healthy controls (HC). 13,309 saccadic eye movements from 127 participants were analyzed using a novel, calibration-free waveform analysis and hierarchical machine learning framework. Individual saccades were classified based on which trained model could reconstruct each waveform with minimum error, indicating the most likely condition. A hierarchical classifier then predicted overall status (recently diagnosed and medication-naive 'de novo' PD, 'established' PD on antiparkinsonian medication, PSP, and healthy controls) by combining each participant's saccade results. This approach substantially outperformed conventional metrics, achieving high AUROCs distinguishing de novo PD from PSP (0.92-0.97), de novo PD from HC (0.72-0.89), and PSP from HC (0.90-0.95), while the conventional model showed limited performance (AUROC range: 0.45-0.75). This calibration-free waveform analysis sets a new standard for precise saccadic classification of PD, PSP, and HC, increasing potential for clinical adoption, remote monitoring, and screening.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16063v2</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Salil B Patel, Oliver B Bredemeyer, James J FitzGerald, Chrystalina A Antoniades</dc:creator>
    </item>
    <item>
      <title>Early Recognition of Parkinson's Disease Through Acoustic Analysis and Machine Learning</title>
      <link>https://arxiv.org/abs/2407.16091</link>
      <description>arXiv:2407.16091v1 Announce Type: cross 
Abstract: Parkinson's Disease (PD) is a progressive neurodegenerative disorder that significantly impacts both motor and non-motor functions, including speech. Early and accurate recognition of PD through speech analysis can greatly enhance patient outcomes by enabling timely intervention. This paper provides a comprehensive review of methods for PD recognition using speech data, highlighting advances in machine learning and data-driven approaches. We discuss the process of data wrangling, including data collection, cleaning, transformation, and exploratory data analysis, to prepare the dataset for machine learning applications. Various classification algorithms are explored, including logistic regression, SVM, and neural networks, with and without feature selection. Each method is evaluated based on accuracy, precision, and training time. Our findings indicate that specific acoustic features and advanced machine-learning techniques can effectively differentiate between individuals with PD and healthy controls. The study concludes with a comparison of the different models, identifying the most effective approaches for PD recognition, and suggesting potential directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16091v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niloofar Fadavi, Nazanin Fadavi</dc:creator>
    </item>
    <item>
      <title>Considering dynamical synergy and integrated information; the unusual case of minimum mutual information</title>
      <link>https://arxiv.org/abs/2407.16601</link>
      <description>arXiv:2407.16601v1 Announce Type: cross 
Abstract: This brief note considers the problem of estimating temporal synergy and integrated information in dyadic dynamical processes. One of the standard estimators of dynamic synergy is based on the minimal mutual information between sets of elements, however, despite it's increasingly widespread use, the mathematical features of this redundancy function have largely gone unexplored. Here, we show that it has two previously unrecognized limitations: it cannot disambiguate between truly integrated systems and disintegrated systems with first-order autocorrelation. Second, paradoxically, there are some systems that become more synergistic when dis-integrated (as long as first-order autocorrelations are preserved). In these systems, integrated information can decrease while synergy simultaneously increases. We derive conditions under which this occurs and discuss the implications of these findings for past and future work in applied fields such as neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16601v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thomas F. Varley</dc:creator>
    </item>
    <item>
      <title>AutoRG-Brain: Grounded Report Generation for Brain MRI</title>
      <link>https://arxiv.org/abs/2407.16684</link>
      <description>arXiv:2407.16684v1 Announce Type: cross 
Abstract: Radiologists are tasked with interpreting a large number of images in a daily base, with the responsibility of generating corresponding reports. This demanding workload elevates the risk of human error, potentially leading to treatment delays, increased healthcare costs, revenue loss, and operational inefficiencies. To address these challenges, we initiate a series of work on grounded Automatic Report Generation (AutoRG), starting from the brain MRI interpretation system, which supports the delineation of brain structures, the localization of anomalies, and the generation of well-organized findings. We make contributions from the following aspects, first, on dataset construction, we release a comprehensive dataset encompassing segmentation masks of anomaly regions and manually authored reports, termed as RadGenome-Brain MRI. This data resource is intended to catalyze ongoing research and development in the field of AI-assisted report generation systems. Second, on system design, we propose AutoRG-Brain, the first brain MRI report generation system with pixel-level grounded visual clues. Third, for evaluation, we conduct quantitative assessments and human evaluations of brain structure segmentation, anomaly localization, and report generation tasks to provide evidence of its reliability and accuracy. This system has been integrated into real clinical scenarios, where radiologists were instructed to write reports based on our generated findings and anomaly segmentation masks. The results demonstrate that our system enhances the report-writing skills of junior doctors, aligning their performance more closely with senior doctors, thereby boosting overall productivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16684v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayu Lei, Xiaoman Zhang, Chaoyi Wu, Lisong Dai, Ya Zhang, Yanyong Zhang, Yanfeng Wang, Weidi Xie, Yuehua Li</dc:creator>
    </item>
    <item>
      <title>Neuron-Astrocyte Associative Memory</title>
      <link>https://arxiv.org/abs/2311.08135</link>
      <description>arXiv:2311.08135v2 Announce Type: replace 
Abstract: Astrocytes, the most abundant type of glial cell, play a fundamental role in memory. Despite most hippocampal synapses being contacted by an astrocyte, there are no current theories that explain how neurons, synapses, and astrocytes might collectively contribute to memory function. We demonstrate that fundamental aspects of astrocyte morphology and physiology naturally lead to a dynamic, high-capacity associative memory system. The neuron-astrocyte networks generated by our framework are closely related to popular machine learning architectures known as Dense Associative Memories or Modern Hopfield Networks. In their known biological implementations the ratio of stored memories to the number of neurons remains constant, despite the growth of the network size. Our work demonstrates that neuron-astrocyte networks follow superior, supralinear memory scaling laws, outperforming all known biological implementations of Dense Associative Memory. This theoretical link suggests the exciting and previously unnoticed possibility that memories could be stored, at least in part, within astrocytes rather than solely in the synaptic weights between neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08135v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo Kozachkov, Jean-Jacques Slotine, Dmitry Krotov</dc:creator>
    </item>
    <item>
      <title>Towards a "universal translator" for neural dynamics at single-cell, single-spike resolution</title>
      <link>https://arxiv.org/abs/2407.14668</link>
      <description>arXiv:2407.14668v2 Announce Type: replace 
Abstract: Neuroscience research has made immense progress over the last decade, but our understanding of the brain remains fragmented and piecemeal: the dream of probing an arbitrary brain region and automatically reading out the information encoded in its neural activity remains out of reach. In this work, we build towards a first foundation model for neural spiking data that can solve a diverse set of tasks across multiple brain areas. We introduce a novel self-supervised modeling approach for population activity in which the model alternates between masking out and reconstructing neural activity across different time steps, neurons, and brain regions. To evaluate our approach, we design unsupervised and supervised prediction tasks using the International Brain Laboratory repeated site dataset, which is comprised of Neuropixels recordings targeting the same brain locations across 48 animals and experimental sessions. The prediction tasks include single-neuron and region-level activity prediction, forward prediction, and behavior decoding. We demonstrate that our multi-task-masking (MtM) approach significantly improves the performance of current state-of-the-art population models and enables multi-task learning. We also show that by training on multiple animals, we can improve the generalization ability of the model to unseen animals, paving the way for a foundation model of the brain at single-cell, single-spike resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14668v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizi Zhang, Yanchen Wang, Donato Jimenez-Beneto, Zixuan Wang, Mehdi Azabou, Blake Richards, Olivier Winter, International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz</dc:creator>
    </item>
  </channel>
</rss>
