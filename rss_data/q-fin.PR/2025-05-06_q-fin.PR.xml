<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.PR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.PR</link>
    <description>q-fin.PR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.PR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 04:04:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multilayer Perceptron Neural Network Models in Asset Pricing: An Empirical Study on Large-Cap US Stocks</title>
      <link>https://arxiv.org/abs/2505.01921</link>
      <description>arXiv:2505.01921v2 Announce Type: replace 
Abstract: In this study, MLP models with dynamic structure are applied to factor models for asset pricing tasks. Concretely, the MLP pyramid model structure was employed on firm-characteristic-sorted portfolio factors for modelling the large-capital US stocks. It was further developed as a practicable factor investing strategy based on the predictions. The main findings in this chapter were evaluated from two angles: model performance and investing performance, which were compared from the periods with and without COVID-19. The empirical results indicated that with the restrictions of the data size, the MLP models no longer perform "deeper, better", while the proposed MLP models with two and three hidden layers have higher flexibility to model the factors in this case. This study also verified the idea of previous works that MLP models for factor investing have more meaning in the downside risk control than in pursuing the absolute annual returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01921v2</guid>
      <category>q-fin.PR</category>
      <category>q-fin.CP</category>
      <category>q-fin.RM</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.15333718</arxiv:DOI>
      <dc:creator>Shanyan Lai</dc:creator>
    </item>
    <item>
      <title>Why do financial prices exhibit Brownian motion despite predictable order flow?</title>
      <link>https://arxiv.org/abs/2502.17906</link>
      <description>arXiv:2502.17906v3 Announce Type: replace-cross 
Abstract: In financial market microstructure, there are two enigmatic empirical laws: (i) the market-order flow has predictable persistence due to metaorder splitters by institutional investors, well formulated as the Lillo-Mike-Farmer model. However, this phenomenon seems paradoxical given the diffusive and unpredictable price dynamics; (ii) the price impact $I(Q)$ of a large metaorder $Q$ follows the square-root law, $I(Q)\propto \sqrt{Q}$. Here we theoretically reveal why price dynamics follows Brownian motion despite predictable order flow by unifying these enigmas. We generalize the Lillo-Mike-Farmer model to nonlinear price-impact dynamics, which is mapped to an exactly solvable L\'evy-walk model. Our exact solution shows that the price dynamics remains diffusive under the square-root law, even under persistent order flow. This work illustrates the crucial role of the square-root law in mitigating large price movements by large metaorders, thereby leading to the Brownian price dynamics, consistently with the efficient market hypothesis over long timescales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17906v3</guid>
      <category>q-fin.TR</category>
      <category>cond-mat.stat-mech</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Sato, Kiyoshi Kanazawa</dc:creator>
    </item>
    <item>
      <title>Asset Pricing in Pre-trained Transformer</title>
      <link>https://arxiv.org/abs/2505.01575</link>
      <description>arXiv:2505.01575v2 Announce Type: replace-cross 
Abstract: This paper proposes an innovative Transformer model, Single-directional representative from Transformer (SERT), for US large capital stock pricing. It also innovatively applies the pre-trained Transformer models under the stock pricing and factor investment context. They are compared with standard Transformer models and encoder-only Transformer models in three periods covering the entire COVID-19 pandemic to examine the model adaptivity and suitability during the extreme market fluctuations. Namely, pre-COVID-19 period (mild up-trend), COVID-19 period (sharp up-trend with deep down shock) and 1-year post-COVID-19 (high fluctuation sideways movement). The best proposed SERT model achieves the highest out-of-sample R2, 11.2% and 10.91% respectively, when extreme market fluctuation takes place followed by pre-trained Transformer models (10.38% and 9.15%). Their Trend-following-based strategy wise performance also proves their excellent capability for hedging downside risks during market shocks. The proposed SERT model achieves a Sortino ratio 47% higher than the buy-and-hold benchmark in the equal-weighted portfolio and 28% higher in the value-weighted portfolio when the pandemic period is attended. It proves that Transformer models have a great capability to capture patterns of temporal sparsity data in the asset pricing factor model, especially with considerable volatilities. We also find the softmax signal filter as the common configuration of Transformer models in alternative contexts, which only eliminates differences between models, but does not improve strategy-wise performance, while increasing attention heads improve the model performance insignificantly and applying the 'layer norm first' method do not boost the model performance in our case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01575v2</guid>
      <category>q-fin.CP</category>
      <category>econ.EM</category>
      <category>q-fin.PR</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.15327831</arxiv:DOI>
      <dc:creator>Shanyan Lai</dc:creator>
    </item>
  </channel>
</rss>
