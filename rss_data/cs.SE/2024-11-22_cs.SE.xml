<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Nov 2024 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DSTC: Direct Preference Learning with Only Self-Generated Tests and Code to Improve Code LMs</title>
      <link>https://arxiv.org/abs/2411.13611</link>
      <description>arXiv:2411.13611v1 Announce Type: new 
Abstract: Direct preference learning offers a promising and computation-efficient beyond supervised fine-tuning (SFT) for improving code generation in coding large language models (LMs). However, the scarcity of reliable preference data is a bottleneck for the performance of direct preference learning to improve the coding accuracy of code LMs. In this paper, we introduce \underline{\textbf{D}}irect Preference Learning with Only \underline{\textbf{S}}elf-Generated \underline{\textbf{T}}ests and \underline{\textbf{C}}ode (DSTC), a framework that leverages only self-generated code snippets and tests to construct reliable preference pairs such that direct preference learning can improve LM coding accuracy without external annotations. DSTC combines a minimax selection process and test-code concatenation to improve preference pair quality, reducing the influence of incorrect self-generated tests and enhancing model performance without the need for costly reward models. When applied with direct preference learning methods such as Direct Preference Optimization (DPO) and Kahneman-Tversky Optimization (KTO), DSTC yields stable improvements in coding accuracy (pass@1 score) across diverse coding benchmarks, including HumanEval, MBPP, and BigCodeBench, demonstrating both its effectiveness and scalability for models of various sizes. This approach autonomously enhances code generation accuracy across LLMs of varying sizes, reducing reliance on expensive annotated coding datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13611v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Liu, Shenao Zhang, Yongfei Liu, Boyi Liu, Yingxiang Yang, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Verification and Validation of Autonomous Systems</title>
      <link>https://arxiv.org/abs/2411.13614</link>
      <description>arXiv:2411.13614v1 Announce Type: new 
Abstract: This paper describes how to proficiently prevent software defects in autonomous vehicles, discover and correct defects if they are encountered, and create a higher level of assurance in the software product development phase. It also describes how to ensure high assurance on software reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13614v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sneha Sudhir Shetiya, Vikas Vyas, Shreyas Renukuntla</dc:creator>
    </item>
    <item>
      <title>A Systematic Literature Review on a Decade of Industrial TLA+ Practice</title>
      <link>https://arxiv.org/abs/2411.13722</link>
      <description>arXiv:2411.13722v1 Announce Type: new 
Abstract: TLA+ is a formal specification language used for designing, modeling, documenting, and verifying systems through model checking. Despite significant interest from the research community, knowledge about usage of the TLA+ ecosystem in practice remains scarce. Industry reports suggest that software engineers could benefit from insights, innovations, and solutions to the practical challenges of TLA+. This paper explores this development by conducting a systematic literature review of TLA+'s industrial usage over the past decade. We analyze the trend in industrial application, characterize its use, examine whether its promised benefits resonate with practitioners, and identify challenges that may hinder further adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13722v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-76554-4_2</arxiv:DOI>
      <arxiv:journal_reference>Integrated Formal Methods, IFM 2024, LNCS 15234 (2025), pp 24-34</arxiv:journal_reference>
      <dc:creator>Roman B\"ogli, Leandro Lerena, Christos Tsigkanos, Timo Kehrer</dc:creator>
    </item>
    <item>
      <title>An Evaluation-Driven Approach to Designing LLM Agents: Process and Architecture</title>
      <link>https://arxiv.org/abs/2411.13768</link>
      <description>arXiv:2411.13768v1 Announce Type: new 
Abstract: The advent of Large Language Models (LLMs) has enabled the development of LLM agents capable of autonomously achieving under-specified goals and continuously evolving through post-deployment improvement, sometimes without requiring code or model updates. Conventional approaches, such as pre-defined test cases and code/model redevelopment pipelines, are inadequate for addressing the unique challenges of LLM agent development, particularly in terms of quality and risk control. This paper introduces an evaluation-driven design approach, inspired by test-driven development, to address these challenges. Through a multivocal literature review (MLR), we synthesize existing LLM evaluation methods and propose a novel process model and reference architecture specifically designed for LLM agents. The proposed approach integrates online and offline evaluations to support adaptive runtime adjustments and systematic offline redevelopment, improving runtime pipelines, artifacts, system architecture, and LLMs by continuously incorporating evaluation results, including fine-grained feedback from human and AI evaluators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13768v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boming Xia, Qinghua Lu, Liming Zhu, Zhenchang Xing, Dehai Zhao, Hao Zhang</dc:creator>
    </item>
    <item>
      <title>Evidence is All We Need: Do Self-Admitted Technical Debts Impact Method-Level Maintenance?</title>
      <link>https://arxiv.org/abs/2411.13777</link>
      <description>arXiv:2411.13777v1 Announce Type: new 
Abstract: Self-Admitted Technical Debt (SATD) refers to the phenomenon where developers explicitly acknowledge technical debt through comments in the source code. While considerable research has focused on detecting and addressing SATD, its true impact on software maintenance remains underexplored. The few studies that have examined this critical aspect have not provided concrete evidence linking SATD to negative effects on software maintenance. These studies, however, focused only on file- or class-level code granularity. This paper aims to empirically investigate the influence of SATD on various facets of software maintenance at the method level. We assess SATD's effects on code quality, bug susceptibility, change frequency, and the time practitioners typically take to resolve SATD.
  By analyzing a dataset of 774,051 methods from 49 open-source projects, we discovered that methods containing SATD are not only larger and more complex but also exhibit lower readability and a higher tendency for bugs and changes. We also found that SATD often remains unresolved for extended periods, adversely affecting code quality and maintainability. Our results provide empirical evidence highlighting the necessity of early identification, resource allocation, and proactive management of SATD to mitigate its long-term impacts on software quality and maintenance costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13777v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaiful Chowdhury, Hisham Kidwai, Muhammad Asaduzzaman</dc:creator>
    </item>
    <item>
      <title>LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues</title>
      <link>https://arxiv.org/abs/2411.13941</link>
      <description>arXiv:2411.13941v1 Announce Type: new 
Abstract: Reproducing buggy code is the first and crucially important step in issue resolving, as it aids in identifying the underlying problems and validating that generated patches resolve the problem. While numerous approaches have been proposed for this task, they primarily address common, widespread errors and struggle to adapt to unique, evolving errors specific to individual code repositories. To fill this gap, we propose EvoCoder, a multi-agent continuous learning framework for issue code reproduction. EvoCoder adopts a reflection mechanism that allows the LLM to continuously learn from previously resolved problems and dynamically refine its strategies to new emerging challenges. To prevent experience bloating, EvoCoder introduces a novel hierarchical experience pool that enables the model to adaptively update common and repo-specific experiences. Our experimental results show a 20\% improvement in issue reproduction rates over existing SOTA methods. Furthermore, integrating our reproduction mechanism significantly boosts the overall accuracy of the existing issue-resolving pipeline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13941v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yalan Lin, Yingwei Ma, Rongyu Cao, Binhua Li, Fei Huang, Xiaodong Gu, Yongbin Li</dc:creator>
    </item>
    <item>
      <title>A Socio-Technical Grounded Theory on the Effect of Cognitive Dysfunctions in the Performance of Software Developers with ADHD and Autism</title>
      <link>https://arxiv.org/abs/2411.13950</link>
      <description>arXiv:2411.13950v1 Announce Type: new 
Abstract: The concept of neurodiversity, encompassing conditions such as Autism Spectrum Disorder (ASD), Attention-Deficit/Hyperactivity Disorder (ADHD), dyslexia, and dyspraxia, challenges traditional views of these neurodevelopmental variations as disorders and instead frames them as natural cognitive differences that contribute to unique ways of thinking and problem-solving. Within the software development industry, known for its emphasis on innovation, there is growing recognition of the value neurodivergent individuals bring to technical teams. Despite this, research on the contributions of neurodivergent individuals in Software Engineering (SE) remains limited. This interdisciplinary Socio-Technical Grounded Theory study addresses this gap by exploring the experiences of neurodivergent software engineers with ASD and ADHD, examining the cognitive and emotional challenges they face in software teams. Based on interviews and a survey with 25 neurodivergent and 5 neurotypical individuals, our theory describes how neurodivergent cognitive dysfunctions affect SE performance, and how the individuals' individual journey and various accommodations can regulate this effect. We conclude our paper with a list of inclusive Agile practices, allowing organizations to better support neurodivergent employees and fully leverage their capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13950v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiev Gama, Grischa Liebel, Miguel Goul\~ao, Aline Lacerda, Cristiana Lacerda</dc:creator>
    </item>
    <item>
      <title>Repository-level Code Translation Benchmark Targeting Rust</title>
      <link>https://arxiv.org/abs/2411.13990</link>
      <description>arXiv:2411.13990v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have shown significant capabilities in code translation, often evaluated using benchmarks like CodeTransOcean. However, these evaluations typically focus on simple, function-level translations without considering dependencies, which does not reflect the complexities of real-world software development. Further, their effectiveness in translating to newer, lower-resource languages like Rust in realistic scenarios is still under-explored. To address this gap, we introduce first repository-level code translation benchmark comprising 375 tasks targeting Rust, complete with relevant dependencies. Using this benchmark, we study four state-of-the-art LLMs, analyzing their erroneous outputs to understand their performance in more complex translation scenarios. Our findings reveal that LLMs exhibit substantially worse performance (41.5%-56.2% Pass@1 drop of GPT-4) on repository-level translations compared to simpler tasks, highlighting limitations in existing evaluation methods. The model that performed the best is Claude-3.5, demonstrating the strongest translation capabilities in both basic functionality accuracy and several relevant additional abilities. Additionally, we discover that LLMs struggle with identifying language differences in complex tasks, and that increased dependencies correlate with greater translation difficulty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13990v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangsheng Ou, Mingwei Liu, Yuxuan Chen, Xing Peng, Zibin Zheng</dc:creator>
    </item>
    <item>
      <title>Translating C To Rust: Lessons from a User Study</title>
      <link>https://arxiv.org/abs/2411.14174</link>
      <description>arXiv:2411.14174v1 Announce Type: new 
Abstract: Rust aims to offer full memory safety for programs, a guarantee that untamed C programs do not enjoy. How difficult is it to translate existing C code to Rust? To get a complementary view from that of automatic C to Rust translators, we report on a user study asking humans to translate real-world C programs to Rust. Our participants are able to produce safe Rust translations, whereas state-of-the-art automatic tools are not able to do so. Our analysis highlights that the high-level strategy taken by users departs significantly from those of automatic tools we study. We also find that users often choose zero-cost (static) abstractions for temporal safety, which addresses a predominant component of runtime costs in other full memory safety defenses. User-provided translations showcase a rich landscape of specialized strategies to translate the same C program in different ways to safe Rust, which future automatic translators can consider.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14174v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.14722/ndss.2025.241407</arxiv:DOI>
      <dc:creator>Ruishi Li, Bo Wang, Tianyu Li, Prateek Saxena, Ashish Kundu</dc:creator>
    </item>
    <item>
      <title>Automated Generation of Code Debugging Exercises</title>
      <link>https://arxiv.org/abs/2411.14303</link>
      <description>arXiv:2411.14303v1 Announce Type: new 
Abstract: Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14303v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor-Alexandru P\u{a}durean, Paul Denny, Adish Singla</dc:creator>
    </item>
    <item>
      <title>ROSMonitoring 2.0: Extending ROS Runtime Verification to Services and Ordered Topics</title>
      <link>https://arxiv.org/abs/2411.14367</link>
      <description>arXiv:2411.14367v1 Announce Type: new 
Abstract: Formal verification of robotic applications presents challenges due to their hybrid nature and distributed architecture. This paper introduces ROSMonitoring 2.0, an extension of ROSMonitoring designed to facilitate the monitoring of both topics and services while considering the order in which messages are published and received. The framework has been enhanced to support these novel features for ROS1 -- and partially ROS2 environments -- offering improved real-time support, security, scalability, and interoperability. We discuss the modifications made to accommodate these advancements and present results obtained from a case study involving the runtime monitoring of specific components of a fire-fighting Uncrewed Aerial Vehicle (UAV).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14367v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.411.3</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 411, 2024, pp. 38-55</arxiv:journal_reference>
      <dc:creator>Maryam Ghaffari Saadat (University of Manchester), Angelo Ferrando (University of Modena,Reggio Emilia), Louise A. Dennis (University of Manchester), Michael Fisher (University of Manchester)</dc:creator>
    </item>
    <item>
      <title>A Case Study on Numerical Analysis of a Path Computation Algorithm</title>
      <link>https://arxiv.org/abs/2411.14372</link>
      <description>arXiv:2411.14372v1 Announce Type: new 
Abstract: Lack of numerical precision in control software -- in particular, related to trajectory computation -- can lead to incorrect results with costly or even catastrophic consequences. Various tools have been proposed to analyze the precision of program computations. This paper presents a case study on numerical analysis of an industrial implementation of the fast marching algorithm, a popular path computation algorithm frequently used for trajectory computation. We briefly describe the selected tools, present the applied methodology, highlight some attention points, summarize the results and outline future work directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14372v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.411.8</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 411, 2024, pp. 126-142</arxiv:journal_reference>
      <dc:creator>Gr\'egoire Boussu (Thales Research,Technology), Nikolai Kosmatov (Thales Research,Technology), Franck V\'edrine (Universit\'e Paris-Saclay, CEA, List)</dc:creator>
    </item>
    <item>
      <title>RV4Chatbot: Are Chatbots Allowed to Dream of Electric Sheep?</title>
      <link>https://arxiv.org/abs/2411.14368</link>
      <description>arXiv:2411.14368v1 Announce Type: cross 
Abstract: Chatbots have become integral to various application domains, including those with safety-critical considerations. As a result, there is a pressing need for methods that ensure chatbots consistently adhere to expected, safe behaviours. In this paper, we introduce RV4Chatbot, a Runtime Verification framework designed to monitor deviations in chatbot behaviour. We formalise expected behaviours as interaction protocols between the user and the chatbot. We present the RV4Chatbot design and describe two implementations that instantiate it: RV4Rasa, for monitoring chatbots created with the Rasa framework, and RV4Dialogflow, for monitoring Dialogflow chatbots. Additionally, we detail experiments conducted in a factory automation scenario using both RV4Rasa and RV4Dialogflow. </description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14368v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.411.5</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 411, 2024, pp. 73-90</arxiv:journal_reference>
      <dc:creator>Andrea Gatti (University of Genoa), Viviana Mascardi (University of Genoa), Angelo Ferrando (University of Modena,Reggio Emilia)</dc:creator>
    </item>
    <item>
      <title>Model Checking and Verification of Synchronisation Properties of Cobot Welding</title>
      <link>https://arxiv.org/abs/2411.14369</link>
      <description>arXiv:2411.14369v1 Announce Type: cross 
Abstract: This paper describes use of model checking to verify synchronisation properties of an industrial welding system consisting of a cobot arm and an external turntable. The robots must move synchronously, but sometimes get out of synchronisation, giving rise to unsatisfactory weld qualities in problem areas, such as around corners. These mistakes are costly, since time is lost both in the robotic welding and in manual repairs needed to improve the weld. Verification of the synchronisation properties has shown that they are fulfilled as long as assumptions of correctness made about parts outside the scope of the model hold, indicating limitations in the hardware. These results have indicated the source of the problem, and motivated a re-calibration of the real-life system. This has drastically improved the welding results, and is a demonstration of how formal methods can be useful in an industrial setting.  </description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14369v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.411.6</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 411, 2024, pp. 91-108</arxiv:journal_reference>
      <dc:creator>Yvonne Murray, Henrik Nordlie, David A. Anisi, Pedro Ribeiro, Ana Cavalcanti</dc:creator>
    </item>
    <item>
      <title>"I Don't Use AI for Everything": Exploring Utility, Attitude, and Responsibility of AI-empowered Tools in Software Development</title>
      <link>https://arxiv.org/abs/2409.13343</link>
      <description>arXiv:2409.13343v2 Announce Type: replace 
Abstract: AI-empowered tools have emerged as a transformative force, fundamentally reshaping the software development industry and promising far-reaching impacts across diverse sectors. This study investigates the adoption, impact, and security considerations of AI-empowered tools in the software development process. Through semi-structured interviews with 19 software practitioners from diverse backgrounds, we explore three key aspects: the utility of AI tools, developers' attitudes towards them, and security and privacy responsibilities. Our findings reveal widespread adoption of AI tools across various stages of software development. Developers generally express positive attitudes towards AI, viewing it as an efficiency-enhancing assistant rather than a job replacement threat. However, they also recognized limitations in AI's ability to handle complex, unfamiliar, or highly specialized tasks in software development. Regarding security and privacy, we found varying levels of risk awareness among developers, with larger companies implementing more comprehensive risk management strategies. Our study provides insights into the current state of AI adoption in software development and offers recommendations for practitioners, organizations, AI providers, and regulatory bodies to effectively navigate the integration of AI in the software industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13343v2</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shidong Pan, Litian Wang, Tianyi Zhang, Zhenchang Xing, Yanjie Zhao, Qinghua Lu, Xiaoyu Sun</dc:creator>
    </item>
    <item>
      <title>Systematic Mapping Study on Requirements Engineering for Regulatory Compliance of Software Systems</title>
      <link>https://arxiv.org/abs/2411.01940</link>
      <description>arXiv:2411.01940v2 Announce Type: replace 
Abstract: Context: As the diversity and complexity of regulations affecting Software-Intensive Products and Services (SIPS) is increasing, software engineers need to address the growing regulatory scrutiny. As with any other non-negotiable requirements, SIPS compliance should be addressed early in SIPS engineering - i.e., during requirements engineering (RE). Objectives: In the conditions of the expanding regulatory landscape, existing research offers scattered insights into regulatory compliance of SIPS. This study addresses the pressing need for a structured overview of the state of the art in software RE and its contribution to regulatory compliance of SIPS. Method: We conducted a systematic mapping study to provide an overview of the current state of research regarding challenges, principles and practices for regulatory compliance of SIPS related to RE. We focused on the role of RE and its contribution to other SIPS lifecycle phases. We retrieved 6914 studies published from 2017 until 2023 from four academic databases, which we filtered down to 280 relevant primary studies. Results: We identified and categorized the RE-related challenges in regulatory compliance of SIPS and their potential connection to six types of principles and practices. We found that about 13.6% of the primary studies considered the involvement of both software engineers and legal experts. About 20.7% of primary studies considered RE in connection to other process areas. Most primary studies focused on a few popular regulation fields and application domains. Our results suggest that there can be differences in terms of challenges and involvement of stakeholders across different fields of regulation. Conclusion: Our findings highlight the need for an in-depth investigation of stakeholders' roles, relationships between process areas, and specific challenges for distinct regulatory fields to guide research and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01940v2</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Oleksandr Kosenkov, Parisa Elahidoost, Tony Gorschek, Jannik Fischbach, Daniel Mendez, Michael Unterkalmsteiner, Davide Fucci, Rahul Mohanani</dc:creator>
    </item>
    <item>
      <title>Collaborative Distributed Machine Learning</title>
      <link>https://arxiv.org/abs/2309.16584</link>
      <description>arXiv:2309.16584v4 Announce Type: replace-cross 
Abstract: Various collaborative distributed machine learning (CDML) systems, including federated learning systems and swarm learning systems, with diferent key traits were developed to leverage resources for the development and use of machine learning(ML) models in a conidentiality-preserving way. To meet use case requirements, suitable CDML systems need to be selected. However, comparison between CDML systems to assess their suitability for use cases is often diicult. To support comparison of CDML systems and introduce scientiic and practical audiences to the principal functioning and key traits of CDML systems, this work presents a CDML system conceptualization and CDML archetypes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16584v4</guid>
      <category>cs.MA</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3704807</arxiv:DOI>
      <dc:creator>David Jin, Niclas Kannengie{\ss}er, Sascha Rank, Ali Sunyaev</dc:creator>
    </item>
    <item>
      <title>Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines</title>
      <link>https://arxiv.org/abs/2403.11585</link>
      <description>arXiv:2403.11585v3 Announce Type: replace-cross 
Abstract: In the ever-evolving landscape of machine learning, seamless translation of natural language descriptions into executable code remains a formidable challenge. This paper introduces Linguacodus, an innovative framework designed to tackle this challenge by deploying a dynamic pipeline that iteratively transforms natural language task descriptions into code through high-level data-shaping instructions. The core of Linguacodus is a fine-tuned large language model (LLM), empowered to evaluate diverse solutions for various problems and select the most fitting one for a given task. This paper details the fine-tuning process, and sheds light on how natural language descriptions can be translated into functional code. Linguacodus represents a substantial leap towards automated code generation, effectively bridging the gap between task descriptions and executable code. It holds great promise for advancing machine learning applications across diverse domains. Additionally, we propose an algorithm capable of transforming a natural description of an ML task into code with minimal human interaction. In extensive experiments on a vast machine learning code dataset originating from Kaggle, we showcase the effectiveness of Linguacodus. The investigations highlight its potential applications across diverse domains, emphasizing its impact on applied machine learning in various scientific fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11585v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.7717/peerj-cs.2328</arxiv:DOI>
      <dc:creator>Ekaterina Trofimova, Emil Sataev, Andrey E. Ustyuzhanin</dc:creator>
    </item>
    <item>
      <title>Fixing Security Vulnerabilities with AI in OSS-Fuzz</title>
      <link>https://arxiv.org/abs/2411.03346</link>
      <description>arXiv:2411.03346v2 Announce Type: replace-cross 
Abstract: Critical open source software systems undergo significant validation in the form of lengthy fuzz campaigns. The fuzz campaigns typically conduct a biased random search over the domain of program inputs, to find inputs which crash the software system. Such fuzzing is useful to enhance the security of software systems in general since even closed source software may use open source components. Hence testing open source software is of paramount importance. Currently OSS-Fuzz is the most significant and widely used infrastructure for continuous validation of open source systems. Unfortunately even though OSS-Fuzz has identified more than 10,000 vulnerabilities across 1000 or more software projects, the detected vulnerabilities may remain unpatched, as vulnerability fixing is often manual in practice. In this work, we rely on the recent progress in Large Language Model (LLM) agents for autonomous program improvement including bug fixing. We customise the well-known AutoCodeRover agent for fixing security vulnerabilities. This is because LLM agents like AutoCodeRover fix bugs from issue descriptions via code search. Instead for security patching, we rely on the test execution of the exploit input to extract code elements relevant to the fix. Our experience with OSS-Fuzz vulnerability data shows that LLM agent autonomy is useful for successful security patching, as opposed to approaches like Agentless where the control flow is fixed. More importantly our findings show that we cannot measure quality of patches by code similarity of the patch with reference codes (as in CodeBLEU scores used in VulMaster), since patches with high CodeBLEU scores still fail to pass given the given exploit input. Our findings indicate that security patch correctness needs to consider dynamic attributes like test executions as opposed to relying of standard text/code similarity metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03346v2</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuntong Zhang, Jiawei Wang, Dominic Berzin, Martin Mirchev, Dongge Liu, Abhishek Arya, Oliver Chang, Abhik Roychoudhury</dc:creator>
    </item>
  </channel>
</rss>
