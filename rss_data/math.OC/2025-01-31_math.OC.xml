<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Solving Large Multicommodity Network Flow Problems on GPUs</title>
      <link>https://arxiv.org/abs/2501.17996</link>
      <description>arXiv:2501.17996v1 Announce Type: new 
Abstract: We consider the all-pairs multicommodity network flow problem on a network with capacitated edges. The usual treatment keeps track of a separate flow for each source-destination pair on each edge; we rely on a more efficient formulation in which flows with the same destination are aggregated, reducing the number of variables by a factor equal to the size of the network. Problems with hundreds of nodes, with a total number of variables on the order of a million, can be solved using standard generic interior-point methods on CPUs; we focus on GPU-compatible algorithms that can solve such problems much faster, and in addition scale to much larger problems, with up to a billion variables. Our method relies on the primal-dual hybrid gradient algorithm, and exploits several specific features of the problem for efficient GPU computation. Numerical experiments show that our primal-dual multicommodity network flow method accelerates state of the art generic commercial solvers by $100\times$ to $1000\times$, and scales to problems that are much larger. We provide an open source implementation of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17996v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangzhao Zhang, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Learning Prosumer Behavior in Energy Communities: Integrating Bilevel Programming and Online Learning</title>
      <link>https://arxiv.org/abs/2501.18017</link>
      <description>arXiv:2501.18017v1 Announce Type: new 
Abstract: Dynamic pricing through bilevel programming is widely used for demand response but often assumes perfect knowledge of prosumer behavior, which is unrealistic in practical applications. This paper presents a novel framework that integrates bilevel programming with online learning, specifically Thompson sampling, to overcome this limitation. The approach dynamically sets optimal prices while simultaneously learning prosumer behaviors through observed responses, eliminating the need for extensive pre-existing datasets. Applied to an energy community providing capacity limitation services to a distribution system operator, the framework allows the community manager to infer individual prosumer characteristics, including usage patterns for photovoltaic systems, electric vehicles, home batteries, and heat pumps. Numerical simulations with 25 prosumers, each represented by 10 potential signatures, demonstrate rapid learning with low regret, with most prosumer characteristics learned within five days and full convergence achieved in 100 days.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18017v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bennevis Crowley, Jalal Kazempour, Lesia Mitridati, Mahnoosh Alizadeh</dc:creator>
    </item>
    <item>
      <title>Online Nonstochastic Control with Convex Safety Constraints</title>
      <link>https://arxiv.org/abs/2501.18039</link>
      <description>arXiv:2501.18039v1 Announce Type: new 
Abstract: This paper considers the online nonstochastic control problem of a linear time-invariant system under convex state and input constraints that need to be satisfied at all times. We propose an algorithm called Online Gradient Descent with Buffer Zone for Convex Constraints (OGD-BZC), designed to handle scenarios where the system operates within general convex safety constraints. We demonstrate that OGD-BZC, with appropriate parameter selection, satisfies all the safety constraints under bounded adversarial disturbances. Additionally, to evaluate the performance of OGD-BZC, we define the regret with respect to the best safe linear policy in hindsight. We prove that OGD-BZC achieves $\tilde{O} (\sqrt{T})$ regret given proper parameter choices. Our numerical results highlight the efficacy and robustness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18039v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nanfei Jiang, Spencer Hutchinson, Mahnoosh Alizadeh</dc:creator>
    </item>
    <item>
      <title>An optimal level of Stubbornness to win a soccer match</title>
      <link>https://arxiv.org/abs/2501.18050</link>
      <description>arXiv:2501.18050v1 Announce Type: new 
Abstract: This study conceptualizes stubbornness as an optimal feedback Nash equilibrium within a dynamic setting. To assess a soccer player's performance, we analyze a payoff function that incorporates key factors such as injury risk, assist rate, passing accuracy, and dribbling ability. The evolution of goal-related dynamics is represented through a backward parabolic partial stochastic differential equation (BPPSDE), chosen for its theoretical connection to the Feynman-Kac formula, which links stochastic differential equations (SDEs) to partial differential equations (PDEs). This relationship allows stochastic problems to be reformulated as PDEs, facilitating both analytical and numerical solutions for complex systems. We construct a stochastic Lagrangian and utilize a path integral control framework to derive an optimal measure of stubbornness. Furthermore, we introduce a modified Ornstein-Uhlenbeck BPPSDE to obtain an explicit solution for a player's optimal level of stubbornness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18050v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paramahansa Pramanik</dc:creator>
    </item>
    <item>
      <title>A Framework for Stochastic Fairness in Dominant Resource Allocation with Cloud Computing Applications</title>
      <link>https://arxiv.org/abs/2501.18051</link>
      <description>arXiv:2501.18051v1 Announce Type: new 
Abstract: Allocation of limited resources under uncertain requirements often necessitates fairness considerations, with applications in computer systems, health systems, and humanitarian logistics. This paper introduces a stochastic fairness framework for multi-resource allocation, leveraging rough mean and variance estimates of resource requirement distributions. The framework employs a distributionally robust (DR) model to develop the concept of stochastic fairness, satisfying key properties such as Stochastic Pareto efficiency, Stochastic sharing incentive, and Stochastic envy-freeness under suitable conditions. We propose a finitely convergent algorithm to solve the DR model and empirically evaluate its performance against alternative resource allocation models under varying levels of information about requirement distributions. Our findings reveal that the variance in resource requirements and the chance probability of resource constraint significantly influence allocation decisions. Furthermore, we show that the DR-based partial-information model can achieve performance closer to the full-information setting compared to the worst-case information model. Convergence of the sample average model and comparisons across models are illustrated using data from cloud computing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18051v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Lei, Akhil Singla, Sanjay Mehrotra</dc:creator>
    </item>
    <item>
      <title>DCatalyst: A Unified Accelerated Framework for Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2501.18114</link>
      <description>arXiv:2501.18114v1 Announce Type: new 
Abstract: We study decentralized optimization over a network of agents, modeled as graphs, with no central server. The goal is to minimize $f+r$, where $f$ represents a (strongly) convex function averaging the local agents' losses, and $r$ is a convex, extended-value function.
  We introduce DCatalyst, a unified black-box framework that integrates Nesterov acceleration into decentralized optimization algorithms. %, enhancing their performance. At its core, DCatalyst operates as an \textit{inexact}, \textit{momentum-accelerated} proximal method (forming the outer loop) that seamlessly incorporates any selected decentralized algorithm (as the inner loop). We demonstrate that DCatalyst achieves optimal communication and computational complexity (up to log-factors) across various decentralized algorithms and problem instances. Notably, it extends acceleration capabilities to problem classes previously lacking accelerated solution methods, thereby broadening the effectiveness of decentralized methods.
  On the technical side, our framework introduce the {\it inexact estimating sequences}--a novel extension of the well-known Nesterov's estimating sequences, tailored for the minimization of composite losses in decentralized settings. This method adeptly handles consensus errors and inexact solutions of agents' subproblems, challenges not addressed by existing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18114v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Cao, Xiaokai Chen, Gesualdo Scutari</dc:creator>
    </item>
    <item>
      <title>Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization</title>
      <link>https://arxiv.org/abs/2501.18183</link>
      <description>arXiv:2501.18183v1 Announce Type: new 
Abstract: We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\theta/2})$ with communication complexity of $O(T^{\theta})$ and number of linear optimization oracle calls of $O(T^{2\theta})$ for decentralized upper-linearizable function optimization, for any $0\le \theta \le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18183v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyang Lu, Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Power of $(L_0,L_1)$-Smoothness in Stochastic Convex Optimization: First- and Zero-Order Algorithms</title>
      <link>https://arxiv.org/abs/2501.18198</link>
      <description>arXiv:2501.18198v1 Announce Type: new 
Abstract: This paper is devoted to the study of stochastic optimization problems under the generalized smoothness assumption. By considering the unbiased gradient oracle in Stochastic Gradient Descent, we provide strategies to achieve the desired accuracy with linear rate. Moreover, in the case of the strong growth condition for smoothness $\left(L_0 = 0\right)$, we obtain in the convex setup the iteration complexity: $N = \mathcal{O}\left(L_1R \log\frac{1}{\varepsilon} + \frac{L_1 c R^2}{\varepsilon}\right)$ for Clipped Stochastic Gradient Descent and $N = \mathcal{O}\left(L_1R \log\frac{1}{\varepsilon}\right)$ for Normalized Stochastic Gradient Descent. Furthermore, we generalize the convergence results to the case with a biased gradient oracle, and show that the power of $(L_0,L_1)$-smoothness extends to zero-order algorithms. Finally, we validate our theoretical results with a numerical experiment, which has aroused some interest in the machine learning community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18198v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Lobanov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Joint Design and Pricing of Extended Warranties for Multiple Automobiles with Different Price Bands</title>
      <link>https://arxiv.org/abs/2501.18203</link>
      <description>arXiv:2501.18203v1 Announce Type: new 
Abstract: Extended warranties (EWs) are significant source of revenue for capital-intensive products like automobiles. Such products consist of multiple subsystems, providing flexibility in EW customization, for example, bundling a tailored set of subsystems in an EW contract. This, in turn, enables the creation of a service menu with different EW contract options. From the perspective of a third-party EW provider servicing a fleet of automobile brands, we develop a novel model to jointly optimize the design and pricing of EWs in order to maximize the profit. Specifically, the problem is to determine which contracts should be included in the EW menu and identify the appropriate price for each contract. As the complexity of the joint optimization problem increases exponentially with the number of subsystems, two solution approaches are devised to solve the problem. The first approach is based on a mixed-integer second-order cone programming reformulation, which guarantees optimality but is applicable only for a small number of subsystems. The second approach utilizes a two-step iteration process, offering enhanced computational efficiency in scenarios with a large number of subsystems. Through numerical experiments, the effectiveness of our model is validated, particularly in scenarios characterized by high failure rates and a large number of subsystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18203v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yajing Chen, Yanrong Li, Xiao-Lin Wang, Zhi-Sheng Ye</dc:creator>
    </item>
    <item>
      <title>Wavelet-Based Multiscale Flow For Realistic Image Deformation in the Large Diffeomorphic Deformation Model Framework</title>
      <link>https://arxiv.org/abs/2501.18211</link>
      <description>arXiv:2501.18211v1 Announce Type: new 
Abstract: Estimating accurate high-dimensional transformations remains very challenging, especially in a clinical setting. In this paper, we introduce a multiscale parameterization of deformations to enhance registration and atlas estimation in the Large Deformation Diffeomorphic Metric Mapping framework. Using the Haar wavelet transform, a multiscale representation of the initial velocity fields is computed to optimize transformations in a coarse-to-fine fashion. This additional layer of spatial regularization does not modify the underlying model of deformations. As such, it preserves the original kernel Hilbert space structure of the velocity fields, enabling the algorithm to perform efficient gradient descent. Numerical experiments on several datasets, including abnormal fetal brain images, show that compared to the original algorithm, the coarse-to-fine strategy reaches higher performance and yields template images that preserve important details while avoiding unrealistic features. This highly versatile strategy can easily be applied to other mathematical frameworks for almost no additional computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18211v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10851-024-01219-5</arxiv:DOI>
      <arxiv:journal_reference>Journal of Mathematical Imaging and Vision, 2025, 67 (2), pp.10</arxiv:journal_reference>
      <dc:creator>Fleur Gaudfernau (HeKA), El\'eonore Blondiaux (HeKA), St\'ephanie Allassonni\`ere (HeKA), Erwan Le Pennec (CMAP)</dc:creator>
    </item>
    <item>
      <title>Revisiting $\Psi$DONet: microlocally inspired filters for incomplete-data tomographic reconstructions</title>
      <link>https://arxiv.org/abs/2501.18219</link>
      <description>arXiv:2501.18219v1 Announce Type: new 
Abstract: In this paper, we revisit a supervised learning approach based on unrolling, known as $\Psi$DONet, by providing a deeper microlocal interpretation for its theoretical analysis, and extending its study to the case of sparse-angle tomography. Furthermore, we refine the implementation of the original $\Psi$DONet considering special filters whose structure is specifically inspired by the streak artifact singularities characterizing tomographic reconstructions from incomplete data. This allows to considerably lower the number of (learnable) parameters while preserving (or even slightly improving) the same quality for the reconstructions from limited-angle data and providing a proof-of-concept for the case of sparse-angle tomographic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18219v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatiana A. Bubba, Luca Ratti, Andrea Sebastiani</dc:creator>
    </item>
    <item>
      <title>Decentralised convex optimisation with probability-proportional-to-size quantization</title>
      <link>https://arxiv.org/abs/2501.18312</link>
      <description>arXiv:2501.18312v1 Announce Type: new 
Abstract: Communication is one of the bottlenecks of distributed optimisation and learning. To overcome this bottleneck, we propose a novel quantization method that transforms a vector into a sample of components' indices drawn from a categorical distribution with probabilities proportional to values at those components. Then, we propose a primal and a primal-dual accelerated stochastic gradient methods that use our proposed quantization, and derive their convergence rates in terms of probabilities of large deviations. We focus on affine-constrained convex optimisation and its application to decentralised distributed optimisation problems. To illustrate the work of our algorithm, we apply it to the decentralised computation of semi-discrete entropy regularized Wasserstein barycenters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18312v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitrii Pasechniuk, Pavel Dvurechensky, C\'esar A. Uribe, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Synthesis of Dissipative Systems Using Input-State Data</title>
      <link>https://arxiv.org/abs/2501.18330</link>
      <description>arXiv:2501.18330v1 Announce Type: new 
Abstract: This paper deals with the data-driven synthesis of dissipative linear systems in discrete time. We collect finitely many noisy data samples with which we synthesise a controller that makes all systems that explain the data dissipative with respect to a given quadratic supply rate. By adopting the informativity approach, we introduce the notion of informativity for closed-loop dissipativity. Under certain assumptions on the noise and the system, with the help of tools for quadratic matrix inequalities, we provide necessary and sufficient conditions for informativity for closed-loop dissipativity. We also provide a recipe to design suitable controllers by means of data-based linear matrix inequalities. This main result comprises two parts, to account for both the cases that the output matrices are known or unknown. Lastly, we illustrate our findings with an example, for which we want to design a data-driven controller achieving (strict) passivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18330v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Encho T. Nguyen, Henk J. van Waarde</dc:creator>
    </item>
    <item>
      <title>Implicit Riemannian Optimism with Applications to Min-Max Problems</title>
      <link>https://arxiv.org/abs/2501.18381</link>
      <description>arXiv:2501.18381v1 Announce Type: new 
Abstract: We introduce a Riemannian optimistic online learning algorithm for Hadamard manifolds based on inexact implicit updates. Unlike prior work, our method can handle in-manifold constraints, and matches the best known regret bounds in the Euclidean setting with no dependence on geometric constants, like the minimum curvature. Building on this, we develop algorithms for g-convex, g-concave smooth min-max problems on Hadamard manifolds. Notably, one method nearly matches the gradient oracle complexity of the lower bound for Euclidean problems, for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18381v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christophe Roux, David Mart\'inez-Rubio, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Performance guarantees for optimization-based state estimation using turnpike properties</title>
      <link>https://arxiv.org/abs/2501.18385</link>
      <description>arXiv:2501.18385v1 Announce Type: new 
Abstract: In this paper, we develop novel accuracy and performance guarantees for optimal state estimation of general nonlinear systems (in particular, moving horizon estimation, MHE). Our results rely on a turnpike property of the optimal state estimation problem, which essentially states that the omniscient infinite-horizon solution involving all past and future data serves as turnpike for the solutions of finite-horizon estimation problems involving a subset of the data. This leads to the surprising observation that MHE problems naturally exhibit a leaving arc, which may have a strong negative impact on the estimation accuracy. To address this, we propose a delayed MHE scheme, and we show that the resulting performance (both averaged and non-averaged) is approximately optimal and achieves bounded dynamic regret with respect to the infinite-horizon solution, with error terms that can be made arbitrarily small by an appropriate choice of the delay. In various simulation examples, we observe that already a very small delay in the MHE scheme is sufficient to significantly improve the overall estimation error by 20-25 % compared to standard MHE (without delay). This finding is of great importance for practical applications (especially for monitoring, fault detection, and parameter estimation) where a small delay in the estimation is rather irrelevant but may significantly improve the estimation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18385v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Julian D. Schiller, Lars Gr\"une, and Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>Generator Sets for the Minkowski Sum Problem -- Theory and Insights</title>
      <link>https://arxiv.org/abs/2501.18420</link>
      <description>arXiv:2501.18420v1 Announce Type: new 
Abstract: This paper considers a class of multi-objective optimization problems known as Minkowski sum problems. Minkowski sum problems have a decomposable structure, where the global nondominated (Pareto) set corresponds to the Minkowski sum of several local nondominated sets. In some cases, the vectors of local sets does not contribute to the generation of the global nondominated set, and may therefore lead to wasted computational efforts. Therefore, we investigate theoretical properties of both necessary and redundant vectors, and propose an algorithm based on bounding sets for identifying unnecessary local vectors. We conduct extensive numerical experiments to test the the impact of varying characteristics of the instances on the resulting global nondominated set and the number of redundant vectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18420v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mark Lyngesen, Sune Lauth Gadegaard, Lars Relund Nielsen</dc:creator>
    </item>
    <item>
      <title>High-precision linear minimization is no slower than projection</title>
      <link>https://arxiv.org/abs/2501.18454</link>
      <description>arXiv:2501.18454v1 Announce Type: new 
Abstract: This note demonstrates that, for all compact convex sets, high-precision linear minimization can be performed via a single evaluation of the projection and a scalar-vector multiplication. In consequence, if $\varepsilon$-approximate linear minimization takes at least $L(\varepsilon)$ vector-arithmetic operations and projection requires $P$ operations, then $\mathcal{O}(P)\geq \mathcal{O}(L(\varepsilon))$ is guaranteed. This concept is expounded with examples, an explicit error bound, and an exact linear minimization result for polyhedral sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18454v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zev Woodstock</dc:creator>
    </item>
    <item>
      <title>Computing AD-compatible subgradients of convex relaxations of implicit functions</title>
      <link>https://arxiv.org/abs/2501.18471</link>
      <description>arXiv:2501.18471v1 Announce Type: new 
Abstract: Automatic generation of convex relaxations and subgradients is critical in global optimization, and is typically carried out using variants of automatic/algorithmic differentiation (AD). At previous AD conferences, variants of the forward and reverse AD modes were presented to evaluate accurate subgradients for convex relaxations of supplied composite functions. In a recent approach for generating convex relaxations of implicit functions, these relaxations are constructed as optimal-value functions; this formulation is versatile but complicates sensitivity analysis. We present the first subgradient propagation rules for these implicit function relaxations, based on supplied AD-like knowledge of the residual function. Our new subgradient rules allow implicit function relaxations to be added to the elemental function libraries for the forward AD modes for subgradient propagation of convex relaxations. Proof-of-concept numerical results in Julia are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18471v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingkai Song, Kamil A. Khan</dc:creator>
    </item>
    <item>
      <title>New complementarity formulations for root-finding and optimization of piecewise-affine functions in abs-normal form</title>
      <link>https://arxiv.org/abs/2501.18503</link>
      <description>arXiv:2501.18503v1 Announce Type: new 
Abstract: Nonsmooth functions have been used to model discrete-continuous phenomena such as contact mechanics, and are also prevalent in neural network formulations via activation functions such as ReLU. At previous AD conferences, Griewank et al. showed that nonsmooth functions may be approximated well by piecewise-affine functions constructed using an AD-like procedure. Moreover, such a piecewise-affine function may always be represented in an "abs-normal form", encoding it as a collection of four matrices and two vectors. We present new general complementarity formulations for root-finding and optimization of piecewise-affine functions in abs-normal form, with significantly fewer restrictions than previous approaches. In particular, piecewise-affine root-finding may always be represented as a mixed-linear complementarity problem (MLCP), which may often be simplified to a linear complementarity problem (LCP). We also present approaches for verifying existence of solutions to these problems. A proof-of-concept implementation in Julia is discussed and applied to several numerical examples, using the PATH solver to solve complementarity problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18503v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulan Zhang, Kamil A. Khan</dc:creator>
    </item>
    <item>
      <title>Reducing Simulation Effort for RIS Optimization using an Efficient Far-Field Approximation</title>
      <link>https://arxiv.org/abs/2501.18583</link>
      <description>arXiv:2501.18583v1 Announce Type: new 
Abstract: Optimization of Reconfigurable Intelligent Surfaces (RIS) via a previously introduced method is effective, but time-consuming, because multiport impedance or scatter matrices are required for each transmitter and receiver position, which generally must be obtained through full-wave simulation. Herein, a simple and efficient far-field approximation is introduced, to extrapolate scatter matrices for arbitrary receiver and transmitter positions from only a single simulation while still maintaining high accuracy suitable for optimization purposes. This is demonstrated through comparisons of the optimized capacitance values and further supported by empirical measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18583v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/AP-S/INC-USNC-URSI52054.2024.10687003</arxiv:DOI>
      <dc:creator>Hans-Dieter Lang, Michel A. Nyffenegger, Heinz Mathis, Xingqi Zhang</dc:creator>
    </item>
    <item>
      <title>Low-Thrust Many-Revolution Trajectory Design Under Operational Uncertainties for DESTINY+ Mission</title>
      <link>https://arxiv.org/abs/2501.17867</link>
      <description>arXiv:2501.17867v1 Announce Type: cross 
Abstract: DESTINY+ is a planned JAXA medium-class Epsilon mission from Earth to deep space using a low-thrust, many-revolution orbit. Such a trajectory design is a challenging problem not only for trajectory design but also for flight operations, and in particular, it is essential to evaluate the impact of operational uncertainties to ensure mission success. In this study, we design the low-thrust trajectory from Earth orbit to a lunar transfer orbit by differential dynamic programming using the Sundman transformation. The results of Monte Carlo simulations with operational uncertainties confirm that the spacecraft can be successfully guided to the lunar transfer orbit by using the feedback control law of differential dynamic programming in the angular domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17867v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naoya Ozaki, Yuki Akiyama, Akira Hatakeyama, Shota Ito, Takuya Chikazawa, Takayuki Yamamoto</dc:creator>
    </item>
    <item>
      <title>Investigating the Monte-Carlo Tree Search Approach for the Job Shop Scheduling Problem</title>
      <link>https://arxiv.org/abs/2501.17991</link>
      <description>arXiv:2501.17991v1 Announce Type: cross 
Abstract: The Job Shop Scheduling Problem (JSSP) is a well-known optimization problem in manufacturing, where the goal is to determine the optimal sequence of jobs across different machines to minimize a given objective. In this work, we focus on minimising the weighted sum of job completion times. We explore the potential of Monte Carlo Tree Search (MCTS), a heuristic-based reinforcement learning technique, to solve large-scale JSSPs, especially those with recirculation. We propose several Markov Decision Process (MDP) formulations to model the JSSP for the MCTS algorithm. In addition, we introduce a new synthetic benchmark derived from real manufacturing data, which captures the complexity of large, non-rectangular instances often encountered in practice. Our experimental results show that MCTS effectively produces good-quality solutions for large-scale JSSP instances, outperforming our constraint programming approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17991v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Laurie Boveroux, Damien Ernst, Quentin Louveaux</dc:creator>
    </item>
    <item>
      <title>Joint Pricing and Resource Allocation: An Optimal Online-Learning Approach</title>
      <link>https://arxiv.org/abs/2501.18049</link>
      <description>arXiv:2501.18049v1 Announce Type: cross 
Abstract: We study an online learning problem on dynamic pricing and resource allocation, where we make joint pricing and inventory decisions to maximize the overall net profit. We consider the stochastic dependence of demands on the price, which complicates the resource allocation process and introduces significant non-convexity and non-smoothness to the problem. To solve this problem, we develop an efficient algorithm that utilizes a "Lower-Confidence Bound (LCB)" meta-strategy over multiple OCO agents. Our algorithm achieves $\tilde{O}(\sqrt{Tmn})$ regret (for $m$ suppliers and $n$ consumers), which is optimal with respect to the time horizon $T$. Our results illustrate an effective integration of statistical learning methodologies with complex operations research problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18049v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianyu Xu, Xuan Wang, Yu-Xiang Wang, Jiashuo Jiang</dc:creator>
    </item>
    <item>
      <title>Stochastic scattering control of spider diffusion governed by an optimal diffraction probability measure selected from its own local-time</title>
      <link>https://arxiv.org/abs/2501.18057</link>
      <description>arXiv:2501.18057v1 Announce Type: cross 
Abstract: The purpose of this article is to study a new problem of stochastic control, related to Walsh's spider diffusion, named: stochastic optimal scattering control. The optimal scattering control of the spider diffusion at the junction point is governed by an appropriate and highly non-trivial condition of the Kirchhoff Law type, involving an optimal diffraction probability measure selected from the own local time of the spider process at the vertex. In this work, we prove first the weak dynamic programming principle in the spirit of [32], adapted to the new class of spider diffusion introduced recently in [37]-[38]. Thereafter, we show that the value function of the problem is characterized uniquely in terms of a Hamilton Jacobi Bellman (HJB) system posed on a star-shaped network, having a new boundary condition at the vertex called : non linear local-time Kirchhoff's transmission. The key main point is to use the recent comparison theorem obtained in [40], that has significantly unlocked the study of this type of problem. We conclude by discussing the formulation of stochastic scattering control problems, where there is no dependency w.r.t. the local-time variable, for which their well-posedness appear as a simpler consequence of the results of this work and the advances contained in [40].</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18057v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isaac Ohavi</dc:creator>
    </item>
    <item>
      <title>Input layer regularization and automated regularization hyperparameter tuning for myelin water estimation using deep learning</title>
      <link>https://arxiv.org/abs/2501.18074</link>
      <description>arXiv:2501.18074v1 Announce Type: cross 
Abstract: We propose a novel deep learning method which combines classical regularization with data augmentation for estimating myelin water fraction (MWF) in the brain via biexponential analysis. Our aim is to design an accurate deep learning technique for analysis of signals arising in magnetic resonance relaxometry. In particular, we study the biexponential model, one of the signal models used for MWF estimation. We greatly extend our previous work on \emph{input layer regularization (ILR)} in several ways. We now incorporate optimal regularization parameter selection via a dedicated neural network or generalized cross validation (GCV) on a signal-by-signal, or pixel-by-pixel, basis to form the augmented input signal, and now incorporate estimation of MWF, rather than just exponential time constants, into the analysis. On synthetically generated data, our proposed deep learning architecture outperformed both classical methods and a conventional multi-layer perceptron. On in vivo brain data, our architecture again outperformed other comparison methods, with GCV proving to be somewhat superior to a NN for regularization parameter selection. Thus, ILR improves estimation of MWF within the biexponential model. In addition, classical methods such as GCV may be combined with deep learning to optimize MWF imaging in the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18074v1</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirage Modi, Shashank Sule, Jonathan Palumbo, Michael Rozowski, Mustapha Bouhrara, Wojciech Czaja, Richard G. Spencer</dc:creator>
    </item>
    <item>
      <title>Learning Provablely Improves the Convergence of Gradient Descent</title>
      <link>https://arxiv.org/abs/2501.18092</link>
      <description>arXiv:2501.18092v1 Announce Type: cross 
Abstract: As a specialized branch of deep learning, Learning to Optimize (L2O) tackles optimization problems by training DNN-based solvers. Despite achieving significant success in various scenarios, such as faster convergence in solving convex optimizations and improved optimality in addressing non-convex cases, there remains a deficiency in theoretical support. Current research heavily relies on stringent assumptions that do not align with the intricacies of the training process. To address this gap, our study aims to establish L2O's convergence through its training methodology. We demonstrate that learning an algorithm's hyperparameters significantly enhances its convergence. Focusing on the gradient descent (GD) algorithm for quadratic programming, we prove the convergence of L2O's training using the neural tangent kernel theory. Moreover, we conduct empirical evaluations using synthetic datasets. Our findings indicate exceeding 50\% outperformance over the GD methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18092v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingyu Song, Wei Lin, Hong Xu</dc:creator>
    </item>
    <item>
      <title>Faster Convergence of Riemannian Stochastic Gradient Descent with Increasing Batch Size</title>
      <link>https://arxiv.org/abs/2501.18164</link>
      <description>arXiv:2501.18164v1 Announce Type: cross 
Abstract: Many models used in machine learning have become so large that even computer computation of the full gradient of the loss function is impractical. This has made it necessary to efficiently train models using limited available information, such as batch size and learning rate. We have theoretically analyzed the use of Riemannian stochastic gradient descent (RSGD) and found that using an increasing batch size leads to faster RSGD convergence than using a constant batch size not only with a constant learning rate but also with a decaying learning rate, such as cosine annealing decay and polynomial decay. In particular, RSGD has a better convergence rate $O(\frac{1}{\sqrt{T}})$ than the existing rate $O(\frac{\sqrt{\log T}}{\sqrt[4]{T}})$ with a diminishing learning rate, where $T$ is the number of iterations. The results of experiments on principal component analysis and low-rank matrix completion problems confirmed that, except for the MovieLens dataset and a constant learning rate, using a polynomial growth batch size or an exponential growth batch size results in better performance than using a constant batch size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18164v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanata Oowada, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>A conditional gradient homotopy method with applications to Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2207.03101</link>
      <description>arXiv:2207.03101v3 Announce Type: replace 
Abstract: We propose a new homotopy-based conditional gradient method for solving convex optimization problems with a large number of simple conic constraints. Instances of this template naturally appear in semidefinite programming problems arising as convex relaxations of combinatorial optimization problems. Our method is a double-loop algorithm in which the conic constraint is treated via a self-concordant barrier, and the inner loop employs a conditional gradient algorithm to approximate the analytic central path, while the outer loop updates the accuracy imposed on the temporal solution and the homotopy parameter. Our theoretical iteration complexity is competitive when confronted to state-of-the-art SDP solvers, with the decisive advantage of cheap projection-free subroutines. Preliminary numerical experiments are provided for illustrating the practical performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.03101v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pavel Dvurechensky, Gabriele Iommazzo, Shimrit Shtern, Mathias Staudigl</dc:creator>
    </item>
    <item>
      <title>An optimally fast objective-function-free minimization algorithm using random subspaces</title>
      <link>https://arxiv.org/abs/2310.16580</link>
      <description>arXiv:2310.16580v2 Announce Type: replace 
Abstract: An algorithm for unconstrained non-convex optimization is described, which does not evaluate the objective function and in which minimization is carried out, at each iteration, within a randomly selected subspace. It is shown that this random approximation technique does not affect the method's convergence nor its evaluation complexity for the search of an $\epsilon$-approximate first-order critical point, which is $\mathcal{O}(\epsilon^{-(p+1)/p})$, where $p$ is the order of derivatives used. A variant of the algorithm using approximate Hessian matrices is also analysed and shown to require at most $\mathcal{O}(\epsilon^{-2})$ evaluations. Preliminary numerical tests show that the random-subspace technique can significantly improve performance when used with $p=2$ in the correct context, making it very competitive when compared to standard first-order algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16580v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Bellavia, S. Gratton, B. Morini, Ph. L. Toint</dc:creator>
    </item>
    <item>
      <title>Chebyshev centers and radii for sets induced by quadratic matrix inequalities</title>
      <link>https://arxiv.org/abs/2403.05315</link>
      <description>arXiv:2403.05315v3 Announce Type: replace 
Abstract: This paper studies sets of matrices induced by quadratic inequalities. In particular, the center and radius of a smallest ball containing the set, called a Chebyshev center and the Chebyshev radius, are studied. In addition, this work studies the diameter of the set, which is the farthest distance between any two elements of the set. Closed-form solutions are provided for a Chebyshev center, the Chebyshev radius, and the diameter of sets induced by quadratic matrix inequalities (QMIs) with respect to arbitrary unitarily invariant norms. Examples of these norms include the Frobenius norm, spectral norm, nuclear norm, Schatten p-norms, and Ky Fan k-norms. In addition, closed-form solutions are presented for the radius of the largest ball within a QMI-induced set. Finally, the paper discusses applications of the presented results in data-driven modeling and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05315v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Shakouri, Henk J. van Waarde, M. Kanat Camlibel</dc:creator>
    </item>
    <item>
      <title>Clipped SGD Algorithms for Performative Prediction: Tight Bounds for Clipping Bias and Remedies</title>
      <link>https://arxiv.org/abs/2404.10995</link>
      <description>arXiv:2404.10995v2 Announce Type: replace 
Abstract: This paper studies the convergence of clipped stochastic gradient descent (SGD) algorithms with decision-dependent data distribution. Our setting is motivated by privacy preserving optimization algorithms that interact with performative data where the prediction models can influence future outcomes. This challenging setting involves the non-smooth clipping operator and non-gradient dynamics due to distribution shifts. We make two contributions in pursuit for a performative stable solution using clipped SGD algorithms. First, we characterize the clipping bias with projected clipped SGD (PCSGD) algorithm which is caused by the clipping operator that prevents PCSGD from reaching a stable solution. When the loss function is strongly convex, we quantify the lower and upper bounds for this clipping bias and demonstrate a bias amplification phenomenon with the sensitivity of data distribution. When the loss function is non-convex, we bound the magnitude of stationarity bias. Second, we propose remedies to mitigate the bias either by utilizing an optimal step size design for PCSGD, or to apply the recent DiceSGD algorithm [Zhang et al., 2024]. Our analysis is also extended to show that the latter algorithm is free from clipping bias in the performative setting. Numerical experiments verify our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10995v2</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Michal Yemini, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>A tactical time slot management problem under mixed logit demand</title>
      <link>https://arxiv.org/abs/2407.02308</link>
      <description>arXiv:2407.02308v2 Announce Type: replace 
Abstract: The growth of e-commerce has led to an increase in home delivery requests, including those for attended home deliveries on subscription-based platforms. To accommodate customer availability, many online retailers offer various delivery time slots. This paper introduces a tactical time slot management problem for subscription-based e-retailers, focusing on slot assortment and price discounts. The novelty of our model lies in incorporating customers' heterogeneous preferences regarding delivery slots, captured through a mixed logit choice model. The resulting stochastic problem is formulated as a mixed-integer linear programming relying on simulations. We utilize a simulation-based adaptive large neighborhood search to solve this problem efficiently for large instances. Numerical experiments demonstrate the effectiveness of our approach, particularly in addressing uncertain heterogeneous customer behavior when optimizing assortment and pricing strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02308v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dorsa Abdolhamidi, Virginie Lurkin</dc:creator>
    </item>
    <item>
      <title>Global Optimization Algorithm through High-Resolution Sampling</title>
      <link>https://arxiv.org/abs/2410.13737</link>
      <description>arXiv:2410.13737v2 Announce Type: replace 
Abstract: We present an optimization algorithm that can identify a global minimum of a potentially nonconvex smooth function with high probability, assuming the Gibbs measure of the potential satisfies a logarithmic Sobolev inequality. Our contribution is twofold: on the one hand we propose a global optimization method, which is built on an oracle sampling algorithm producing arbitrarily accurate samples from a given Gibbs measure. On the other hand, we propose a new sampling algorithm, drawing inspiration from both overdamped and underdamped Langevin dynamics, as well as from the high-resolution differential equation known for its acceleration in deterministic settings. While the focus of the paper is primarily theoretical, we demonstrate the effectiveness of our algorithms on the Rastrigin function, where it outperforms recent approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13737v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Cortild, Claire Delplancke, Nadia Oudjane, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>A Block Coordinate and Variance-Reduced Method for Generalized Variational Inequalities of Minty Type</title>
      <link>https://arxiv.org/abs/2411.00979</link>
      <description>arXiv:2411.00979v2 Announce Type: replace 
Abstract: Block coordinate methods have been extensively studied for minimization problems, where they come with significant complexity improvements whenever the considered problems are compatible with block decomposition and, moreover, block Lipschitz parameters are highly nonuniform. For the more general class of variational inequalities with monotone operators, essentially none of the existing methods transparently shows potential complexity benefits of using block coordinate updates in such settings. Motivated by this gap, we develop a new randomized block coordinate method and study its oracle complexity and runtime. We prove that in the setting where block Lipschitz parameters are highly nonuniform -- the main setting in which block coordinate methods lead to high complexity improvements in any of the previously studied settings -- our method can lead to complexity improvements by a factor order-$m$, where $m$ is the number of coordinate blocks. The same method further applies to the more general problem with a finite-sum operator with $m$ components, where it can be interpreted as performing variance reduction. Compared to the state of the art, the method leads to complexity improvements up to a factor $\sqrt{m},$ obtained when the component Lipschitz parameters are highly nonuniform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00979v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Optimal Decentralized Smoothed Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2411.08355</link>
      <description>arXiv:2411.08355v2 Announce Type: replace 
Abstract: We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem, where $N$ agents interact through a communication graph. In each round, each agent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online fashion and selects an action $x^i_t \in \mathbb{R}^d$. The objective is to minimize the global cumulative cost, which includes the sum of individual hitting costs $f^i_t(x^i_t)$, a temporal "switching cost" for changing decisions, and a spatial "dissimilarity cost" that penalizes deviations in decisions among neighboring agents. We propose the first truly decentralized algorithm ACORD for multi-agent SOCO that provably exhibits asymptotic optimality. Our approach allows each agent to operate using only local information from its immediate neighbors in the graph. For finite-time performance, we establish that the optimality gap in the competitive ratio decreases with time horizon $T$ and can be conveniently tuned based on the per-round computation available to each agent. Our algorithm benefits from a provably scalable computational complexity that depends only logarithmically on the number of agents and almost linearly on their degree within the graph. Moreover, our results hold even when the communication graph changes arbitrarily and adaptively over time. Finally, ACORD, by virtue of its asymptotic-optimality, is shown to be provably superior to the state-of-the-art LPC algorithm, while exhibiting much lower computational complexity. Extensive numerical experiments across various network topologies further corroborate our theoretical claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08355v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neelkamal Bhuyan, Debankur Mukherjee, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>Assessing How Ride-hailing Rebalancing Strategies Improve the Resilience of Multi-modal Transportation Systems</title>
      <link>https://arxiv.org/abs/2412.00276</link>
      <description>arXiv:2412.00276v2 Announce Type: replace 
Abstract: The global ride-hailing (RH) industry plays an essential role in multi-modal transportation systems by improving user mobility, particularly as first- and last-mile solutions. However, the flexibility of on-demand mobility services can lead to local supply-demand imbalances. While many RH rebalancing studies focus on nominal scenarios with regular demand patterns, it is crucial to consider disruptions - such as train line interruptions - that negatively impact operational efficiency, resulting in longer travel times, higher costs, increased transfers, and service delays. This study examines how RH rebalancing strategies can strengthen the resilience of multi-modal transportation systems against such disruptions. We incorporate RH services into systems where users choose and switch transportation modes based on their preferences, accounting for uncertainties in demand predictions that reflect discrepancies between forecasts and actual conditions. To address the stochastic supply-demand dynamics in large-scale networks, we propose a multi-agent reinforcement learning (MARL) strategy, specifically utilizing a multi-agent deep deterministic policy gradient (MADDPG) approach. The proposed framework is particularly well-suited for this problem due to its ability to handle continuous action spaces, which are prevalent in real-world transportation systems, and its capacity to enable effective coordination among multiple agents operating in dynamic and decentralized environments. Through a 900 km2 multi-modal traffic simulation, we evaluate the proposed model's performance against four existing RH rebalancing strategies, focusing on its ability to enhance system resilience. The results demonstrate significant improvements in key performance indicators, including user waiting time, resilience metrics, total travel time, and travel distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00276v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Euntak Lee, Rim Slama, Ludovic Leclercq</dc:creator>
    </item>
    <item>
      <title>Revisiting LocalSGD and SCAFFOLD: Improved Rates and Missing Analysis</title>
      <link>https://arxiv.org/abs/2501.04443</link>
      <description>arXiv:2501.04443v2 Announce Type: replace 
Abstract: LocalSGD and SCAFFOLD are widely used methods in distributed stochastic optimization, with numerous applications in machine learning, large-scale data processing, and federated learning. However, rigorously establishing their theoretical advantages over simpler methods, such as minibatch SGD (MbSGD), has proven challenging, as existing analyses often rely on strong assumptions, unrealistic premises, or overly restrictive scenarios.
  In this work, we revisit the convergence properties of LocalSGD and SCAFFOLD under a variety of existing or weaker conditions, including gradient similarity, Hessian similarity, weak convexity, and Lipschitz continuity of the Hessian. Our analysis shows that (i) LocalSGD achieves faster convergence compared to MbSGD for weakly convex functions without requiring stronger gradient similarity assumptions; (ii) LocalSGD benefits significantly from higher-order similarity and smoothness; and (iii) SCAFFOLD demonstrates faster convergence than MbSGD for a broader class of non-quadratic functions. These theoretical insights provide a clearer understanding of the conditions under which LocalSGD and SCAFFOLD outperform MbSGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04443v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruichen Luo, Sebastian U Stich, Samuel Horv\'ath, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>On a Lemma by Br\'ezis and Haraux</title>
      <link>https://arxiv.org/abs/2501.11662</link>
      <description>arXiv:2501.11662v2 Announce Type: replace 
Abstract: We propose several applications of an often overlooked part of the 1976 paper by Br\'ezis and Haraux, in which the Br\'ezis--Haraux theorem was established. Our results unify and extend various existing ones on the range of a composite monotone operator and provide new insight into their seminal paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11662v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh N. B\`ui</dc:creator>
    </item>
    <item>
      <title>Active Learning For Contextual Linear Optimization: A Margin-Based Approach</title>
      <link>https://arxiv.org/abs/2305.06584</link>
      <description>arXiv:2305.06584v2 Announce Type: replace-cross 
Abstract: We develop the first active learning method for contextual linear optimization. Specifically, we introduce a label acquisition algorithm that sequentially decides whether to request the ``labels'' of feature samples from an unlabeled data stream, where the labels correspond to the coefficients of the objective in the linear optimization. Our method is the first to be directly informed by the decision loss induced by the predicted coefficients, referred to as the Smart Predict-then-Optimize (SPO) loss. Motivated by the structure of the SPO loss, our algorithm adopts a margin-based criterion utilizing the concept of distance to degeneracy. In particular, we design an efficient active learning algorithm with theoretical excess risk (i.e., generalization) guarantees. We derive upper bounds on the label complexity, defined as the number of samples whose labels are acquired to achieve a desired small level of SPO risk. These bounds show that our algorithm has a much smaller label complexity than the naive supervised learning approach that labels all samples, particularly when the SPO loss is minimized directly on the collected data. To address the discontinuity and nonconvexity of the SPO loss, we derive label complexity bounds under tractable surrogate loss functions. Under natural margin conditions, these bounds also outperform naive supervised learning. Using the SPO+ loss, a specialized surrogate of the SPO loss, we establish even tighter bounds under separability conditions. Finally, we present numerical evidence showing the practical value of our algorithms in settings such as personalized pricing and the shortest path problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.06584v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo Liu, Paul Grigas, Heyuan Liu, Zuo-Jun Max Shen</dc:creator>
    </item>
    <item>
      <title>Layered Models can "Automatically" Regularize and Discover Low-Dimensional Structures via Feature Learning</title>
      <link>https://arxiv.org/abs/2310.11736</link>
      <description>arXiv:2310.11736v3 Announce Type: replace-cross 
Abstract: Layered models like neural networks appear to extract key features from data through empirical risk minimization, yet the theoretical understanding for this process remains unclear. Motivated by these observations, we study a two-layer nonparametric regression model where the input undergoes a linear transformation followed by a nonlinear mapping to predict the output, mirroring the structure of two-layer neural networks. In our model, both layers are optimized jointly through empirical risk minimization, with the nonlinear layer modeled by a reproducing kernel Hilbert space induced by a rotation and translation invariant kernel, regularized by a ridge penalty.
  Our main result shows that the two-layer model can "automatically" induce regularization and facilitate feature learning. Specifically, the two-layer model promotes dimensionality reduction in the linear layer and identifies a parsimonious subspace of relevant features -- even without applying any norm penalty on the linear layer. Notably, this regularization effect arises directly from the model's layered structure, independent of optimization dynamics.
  More precisely, assuming the covariates have nonzero explanatory power for the response only through a low dimensional subspace (central mean subspace), the linear layer consistently estimates both the subspace and its dimension. This demonstrates that layered models can inherently discover low-complexity solutions relevant for prediction, without relying on conventional regularization methods. Real-world data experiments further demonstrate the persistence of this phenomenon in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11736v3</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunlu Chen, Yang Li, Keli Liu, Feng Ruan</dc:creator>
    </item>
    <item>
      <title>Multi-Player Resource-Sharing Games with Fair Reward Allocation</title>
      <link>https://arxiv.org/abs/2402.05300</link>
      <description>arXiv:2402.05300v3 Announce Type: replace-cross 
Abstract: This paper considers a multi-player resource-sharing game with a fair reward allocation model. Multiple players choose from a collection of resources. Each resource brings a random reward equally divided among the players who choose it. We consider two settings. The first setting is a one-slot game where the mean rewards of the resources are known to all the players, and the objective of player 1 is to maximize their worst-case expected utility. Certain special cases of this setting have explicit solutions. These cases provide interesting yet non-intuitive insights into the problem. The second setting is an online setting, where the game is played over a finite time horizon, where the mean rewards are unknown to the first player. Instead, the first player receives, as feedback, the rewards of the resources they chose after the action. We develop a novel Upper Confidence Bound (UCB) algorithm that minimizes the worst-case regret of the first player using the feedback received.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05300v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mevan Wijewardena, Michael. J Neely</dc:creator>
    </item>
    <item>
      <title>Scaling Robust Optimization for Multi-Agent Robotic Systems: A Distributed Perspective</title>
      <link>https://arxiv.org/abs/2402.16227</link>
      <description>arXiv:2402.16227v2 Announce Type: replace-cross 
Abstract: This paper presents a novel distributed robust optimization scheme for steering distributions of multi-agent systems under stochastic and deterministic uncertainty. Robust optimization is a subfield of optimization which aims to discover an optimal solution that remains robustly feasible for all possible realizations of the problem parameters within a given uncertainty set. Such approaches would naturally constitute an ideal candidate for multi-robot control, where in addition to stochastic noise, there might be exogenous deterministic disturbances. Nevertheless, as these methods are usually associated with significantly high computational demands, their application to multi-agent robotics has remained limited. The scope of this work is to propose a scalable robust optimization framework that effectively addresses both types of uncertainties, while retaining computational efficiency and scalability. In this direction, we provide tractable approximations for robust constraints that are relevant in multi-robot settings. Subsequently, we demonstrate how computations can be distributed through an Alternating Direction Method of Multipliers (ADMM) approach towards achieving scalability and communication efficiency. All improvements are also theoretically justified by establishing and comparing the resulting computational complexities. Simulation results highlight the performance of the proposed algorithm in effectively handling both stochastic and deterministic uncertainty in multi-robot systems. The scalability of the method is also emphasized by showcasing tasks with up to hundreds of agents. The results of this work indicate the promise of blending robust optimization, distribution steering and distributed optimization towards achieving scalable, safe and robust multi-robot control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16227v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arshiya Taj Abdul, Augustinos D. Saravanos, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Regularized Nonnegative Scale-invariant Low-rank Approximation Models</title>
      <link>https://arxiv.org/abs/2403.18517</link>
      <description>arXiv:2403.18517v4 Announce Type: replace-cross 
Abstract: Regularized nonnegative low-rank approximations, such as sparse Nonnegative Matrix Factorization or sparse Nonnegative Tucker Decomposition, form an important branch of dimensionality reduction models known for their enhanced interpretability. From a practical perspective, however, selecting appropriate regularizers and regularization coefficients, as well as designing efficient algorithms, remains challenging due to the multifactor nature of these models and the limited theoretical guidance available. This paper addresses these challenges by studying a more general model, the Homogeneous Regularized Scale-Invariant model. We prove that the scale-invariance inherent to low-rank approximation models induces an implicit regularization effect that balances solutions. This insight provides a deeper understanding of the role of regularization functions in low-rank approximation models, informs the selection of regularization hyperparameters, and enables the design of balancing strategies to accelerate the empirical convergence of optimization algorithms.
  Additionally, we propose a generic Majorization-Minimization (MM) algorithm capable of handling $\ell_p^p$-regularized nonnegative low-rank approximations with non-Euclidean loss functions, with convergence guarantees. Our contributions are demonstrated on sparse Nonnegative Matrix Factorization, ridge-regularized Nonnegative Canonical Polyadic Decomposition, and sparse Nonnegative Tucker Decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18517v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy E. Cohen, Valentin Leplat</dc:creator>
    </item>
    <item>
      <title>Predictive control for nonlinear stochastic systems: Closed-loop guarantees with unbounded noise</title>
      <link>https://arxiv.org/abs/2407.13257</link>
      <description>arXiv:2407.13257v3 Announce Type: replace-cross 
Abstract: We present a stochastic model predictive control framework for nonlinear systems subject to unbounded process noise with closed-loop guarantees. First, we provide a conceptual shrinking-horizon framework that utilizes general probabilistic reachable sets and minimizes the expected cost. Then, we provide a tractable receding-horizon formulation that uses a nominal state to minimize a deterministic quadratic cost and satisfy tightened constraints. Our theoretical analysis demonstrates recursive feasibility, satisfaction of chance constraints, and bounds on the expected cost for the resulting closed-loop system. We provide a constructive design for probabilistic reachable sets of nonlinear continuously differentiable systems using stochastic contraction metrics. Numerical simulations highlight the computational efficiency and theoretical guarantees of the proposed method. Overall, this paper provides a framework for computationally tractable stochastic predictive control with closed-loop guarantees for nonlinear systems with unbounded noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13257v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes K\"ohler, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>End-to-end metasurface design for temperature imaging via broadband Planck-radiation regression</title>
      <link>https://arxiv.org/abs/2409.08456</link>
      <description>arXiv:2409.08456v2 Announce Type: replace-cross 
Abstract: We present a theoretical framework for temperature imaging from long-wavelength infrared thermal radiation (e.g. 8-12 $\mu$m) through the end-to-end design of a metasurface-optics frontend and a computational-reconstruction backend. We introduce a new nonlinear reconstruction algorithm, ``Planck regression," that reconstructs the temperature map from a grayscale sensor image, even in the presence of severe chromatic aberration, by exploiting blackbody and optical physics particular to thermal imaging. We combine this algorithm with an end-to-end approach that optimizes a manufacturable, single-layer metasurface to yield the most accurate reconstruction. Our designs demonstrate high-quality, noise-robust reconstructions of arbitrary temperature maps (including completely random images) in simulations of an ultra-compact thermal-imaging device. We also show that Planck regression is much more generalizable to arbitrary images than a straightforward neural-network reconstruction, which requires a large training set of domain-specific images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08456v2</guid>
      <category>physics.optics</category>
      <category>eess.IV</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sophie Fisher, Gaurav Arya, Arka Majumdar, Zin Lin, Steven G. Johnson</dc:creator>
    </item>
    <item>
      <title>Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2412.00661</link>
      <description>arXiv:2412.00661v2 Announce Type: replace-cross 
Abstract: Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging because the size of the joint state and action spaces grows exponentially in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm $\texttt{SUBSAMPLE-MFQ}$ ($\textbf{Subsample}$-$\textbf{M}$ean-$\textbf{F}$ield-$\textbf{Q}$-learning) and a decentralized randomized policy for a system with $n$ agents. For $k\leq n$, our algorithm learns a policy for the system in time polynomial in $k$. We show that this learned policy converges to the optimal policy on the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. We empirically validate our method in Gaussian squeeze and global exploration settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00661v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emile Anand, Ishani Karmarkar, Guannan Qu</dc:creator>
    </item>
    <item>
      <title>On stochastic control problems with higher-order moments</title>
      <link>https://arxiv.org/abs/2412.13521</link>
      <description>arXiv:2412.13521v2 Announce Type: replace-cross 
Abstract: In this paper, we focus on a class of time-inconsistent stochastic control problems, where the objective function includes the mean and several higher-order central moments of the terminal value of state. To tackle the time-inconsistency, we seek both the closed-loop and the open-loop Nash equilibrium controls as time-consistent solutions. We establish a partial differential equation (PDE) system for deriving a closed-loop Nash equilibrium control, which does not include the equilibrium value function and is different from the extended Hamilton-Jacobi-Bellman (HJB) equations as in Bj\"ork et al. (Finance Stoch. 21: 331-360, 2017). We show that our PDE system is equivalent to the extended HJB equations that seems difficult to be solved for our higher-order moment problems. In deriving an open-loop Nash equilibrium control, due to the non-separable higher-order moments in the objective function, we make some moment estimates in addition to the standard perturbation argument for developing a maximum principle. Then, the problem is reduced to solving a flow of forward-backward stochastic differential equations. In particular, we investigate linear controlled dynamics and some objective functions affine in the mean. The closed-loop and the open-loop Nash equilibrium controls are identical, which are independent of the state value, random path and the preference on the odd-order central moments. By sending the highest order of central moments to infinity, we obtain the time-consistent solutions to some control problems whose objective functions include some penalty functions for deviation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13521v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yike Wang, Jingzhen Liu, Alain Bensoussan, Ka-Fai Cedric Yiu, Jiaqin Wei</dc:creator>
    </item>
    <item>
      <title>An Efficient Numerical Function Optimization Framework for Constrained Nonlinear Robotic Problems</title>
      <link>https://arxiv.org/abs/2501.17349</link>
      <description>arXiv:2501.17349v2 Announce Type: replace-cross 
Abstract: This paper presents a numerical function optimization framework designed for constrained optimization problems in robotics. The tool is designed with real-time considerations and is suitable for online trajectory and control input optimization problems. The proposed framework does not require any analytical representation of the problem and works with constrained block-box optimization functions. The method combines first-order gradient-based line search algorithms with constraint prioritization through nullspace projections onto constraint Jacobian space. The tool is implemented in C++ and provided online for community use, along with some numerical and robotic example implementations presented in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17349v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sait Sovukluk, Christian Ott</dc:creator>
    </item>
  </channel>
</rss>
