<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Nov 2025 03:48:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Shaping manifolds in equivariant recurrent neural networks</title>
      <link>https://arxiv.org/abs/2511.04802</link>
      <description>arXiv:2511.04802v1 Announce Type: new 
Abstract: Recordings of increasingly large neural populations have revealed that the firing of individual neurons is highly coordinated. When viewed in the space of all possible patterns, the collective activity forms non-linear structures called neural manifolds. Because such structures are observed even at rest or during sleep, an important hypothesis is that activity manifolds may correspond to continuous attractors shaped by recurrent connectivity between neurons. Classical models of recurrent networks have shown that continuous attractors can be generated by specific symmetries in the connectivity. Although a variety of attractor network models have been studied, general principles linking network connectivity and the geometry of attractors remain to be formulated. Here, we address this question by using group representation theory to formalize the relationship between the symmetries in recurrent connectivity and the resulting fixed-point manifolds. We start by revisiting the classical ring model, a continuous attractor network generating a circular manifold. Interpreting its connectivity as a circular convolution, we draw a parallel with feed-forward CNNs. Building on principles of geometric deep learning, we then generalize this architecture to a broad range of symmetries using group representation theory. Specifically, we introduce a new class of equivariant RNNs, where the connectivity is based on group convolution. Using the group Fourier transform, we reduce such networks to low-rank models, giving us a low-dimensional description that can be fully analyzed to determine the symmetry, dimensionality and stability of fixed-point manifolds. Our results underline the importance of stability considerations: for a connectivity with a given symmetry, depending on parameters, several manifolds with different symmetry subgroups can coexist, some stable and others consisting of saddle points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04802v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arianna Di Bernardo, Adrian Valente, Francesca Mastrogiuseppe, Srdjan Ostojic</dc:creator>
    </item>
    <item>
      <title>Duration-modulated neural population dynamics in humans during BMI controls</title>
      <link>https://arxiv.org/abs/2511.04887</link>
      <description>arXiv:2511.04887v1 Announce Type: new 
Abstract: The motor cortex (MC) is often described as an autonomous dynamical system during movement execution. In an autonomous dynamical system, flexible movement generation depends on reconfiguring the initial conditions, which then unwind along known dynamics. An open question is whether these dynamics govern MC activity during brain-machine interface (BMI) control. We investigated MC activity during BMI cursor movements of multiple durations, ranging from hundreds of milliseconds to sustained over seconds. These durations were chosen to cover the range of movement durations necessary to control modern BMIs under varying precision levels. Movements shared their MC initial condition with movements of different durations in the same direction. Long-duration movements sustained MC activity, effectively pausing the neural population dynamics until each movement goal was reached. The difference across durations in MC population dynamics may be attributed to external inputs. Our results highlight the role of sustained inputs to MC during movement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04887v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fei Yin, Charles Guan, Tyson Aflalo, Jorge Gamez, Kelsie Pejsa, Emily Rosario, Charles Liu, Ausaf Bari, Richard Andersen</dc:creator>
    </item>
    <item>
      <title>Predicting Cognitive Assessment Scores in Older Adults with Cognitive Impairment Using Wearable Sensors</title>
      <link>https://arxiv.org/abs/2511.04983</link>
      <description>arXiv:2511.04983v1 Announce Type: new 
Abstract: Background and Objectives: This paper focuses on using AI to assess the cognitive function of older adults with mild cognitive impairment or mild dementia using physiological data provided by a wearable device. Cognitive screening tools are disruptive, time-consuming, and only capture brief snapshots of activity. Wearable sensors offer an attractive alternative by continuously monitoring physiological signals. This study investigated whether physiological data can accurately predict scores on established cognitive tests. Research Design and Methods: We recorded physiological signals from 23 older adults completing three NIH Toolbox Cognitive Battery tests, which assess working memory, processing speed, and attention. The Empatica EmbracePlus, a wearable device, measured blood volume pulse, skin conductance, temperature, and movement. Statistical features were extracted using wavelet-based and segmentation methods. We then applied supervised learning and validated predictions via cross-validation, hold-out testing, and bootstrapping. Results: Our models showed strong performance with Spearman's \rho of 0.73-0.82 and mean absolute errors of 0.14-0.16, significantly outperforming a naive mean predictor. Sensor roles varied: heart-related signals combined with movement and temperature best predicted working memory, movement paired with skin conductance was most informative for processing speed, and heart in tandem with skin conductance worked best for attention. Discussion and Implications: These findings suggest that wearable sensors paired with AI tools such as supervised learning and feature engineering can noninvasively track specific cognitive functions in older adults, enabling continuous monitoring. Our study demonstrates how AI can be leveraged when the data sample is small. This approach may support remote assessments and facilitate clinical interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04983v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Assma Habadi, Milos Zefran, Lijuan Yin, Woojin Song, Maria Caceres, Elise Hu, Naoko Muramatsu</dc:creator>
    </item>
    <item>
      <title>Travelling waves modulated by subthreshold oscillations in networks of integrate-and-fire neurons</title>
      <link>https://arxiv.org/abs/2511.05232</link>
      <description>arXiv:2511.05232v1 Announce Type: new 
Abstract: Travelling waves of neural firing activity are observed in brain tissue as a part of various sensory, motor and cognitive processes. They represent an object of major interest in the study of excitable networks, with analysis conducted in both neural field models and spiking neuronal networks. The latter class exposes the single-neuron dynamics directly, allowing us to study the details of their influence upon network-scale behaviour. Here we present a study of a laterally-inhibited network of leaky integrate-and-fire neurons modulated by a slow voltage-gated ion channel that acts as a linear adaptation variable. As the strength of the ion channel increases, we find that its interaction with the lateral inhibition increases wave speeds. The ion channel can enable subthreshold oscillations, with the intervals between the firing events of loosely-coupled travelling wave solutions structured around the neuron's natural period. These subthreshold oscillations also enable the occurrence of codimension-2 grazing bifurcations; along with the emergence of fold bifurcations along wave solution branches, the slow ion channel introduces a variety of intermediate structures in the solution space. These point towards further investigation of the role neighbouring solution branches play in the behaviour of waves forced across bifurcations, which we illustrate with the aid of simulations using a novel root-finding algorithm designed to handle uncertainty over the existence of firing solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05232v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry D. J. Kerr, Peter Ashwin, Kyle C. A. Wedgwood</dc:creator>
    </item>
    <item>
      <title>A Penny for Your Thoughts: Decoding Speech from Inexpensive Brain Signals</title>
      <link>https://arxiv.org/abs/2511.04691</link>
      <description>arXiv:2511.04691v1 Announce Type: cross 
Abstract: We explore whether neural networks can decode brain activity into speech by mapping EEG recordings to audio representations. Using EEG data recorded as subjects listened to natural speech, we train a model with a contrastive CLIP loss to align EEG-derived embeddings with embeddings from a pre-trained transformer-based speech model. Building on the state-of-the-art EEG decoder from Meta, we introduce three architectural modifications: (i) subject-specific attention layers (+0.15% WER improvement), (ii) personalized spatial attention (+0.45%), and (iii) a dual-path RNN with attention (-1.87%). Two of the three modifications improved performance, highlighting the promise of personalized architectures for brain-to-speech decoding and applications in brain-computer interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04691v1</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>eess.AS</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quentin Auster, Kateryna Shapovalenko, Chuang Ma, Demaio Sun</dc:creator>
    </item>
    <item>
      <title>ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy</title>
      <link>https://arxiv.org/abs/2511.05221</link>
      <description>arXiv:2511.05221v1 Announce Type: cross 
Abstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major prodromal marker of $\alpha$-synucleinopathies, often preceding the clinical onset of Parkinson's disease, dementia with Lewy bodies, or multiple system atrophy. While wrist-worn actimeters hold significant potential for detecting RBD in large-scale screening efforts by capturing abnormal nocturnal movements, they become inoperable without a reliable and efficient analysis pipeline. This study presents ActiTect, a fully automated, open-source machine learning tool to identify RBD from actigraphy recordings. To ensure generalizability across heterogeneous acquisition settings, our pipeline includes robust preprocessing and automated sleep-wake detection to harmonize multi-device data and extract physiologically interpretable motion features characterizing activity patterns. Model development was conducted on a cohort of 78 individuals, yielding strong discrimination under nested cross-validation (AUROC = 0.95). Generalization was confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To assess real-world robustness, leave-one-dataset-out cross-validation across the internal and external cohorts demonstrated consistent performance (AUROC range = 0.84-0.89). A complementary stability analysis showed that key predictive features remained reproducible across datasets, supporting the final pooled multi-center model as a robust pre-trained resource for broader deployment. By being open-source and easy to use, our tool promotes widespread adoption and facilitates independent validation and collaborative improvements, thereby advancing the field toward a unified and generalizable RBD detection model using wearable devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05221v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>David Bertram, Anja Ophey, Sinah R\"ottgen, Konstantin Kuffer, Gereon R. Fink, Elke Kalbe, Clint Hansen, Walter Maetzler, Maximilian Kapsecker, Lara M. Reimer, Stephan Jonas, Andreas T. Damgaard, Natasha B. Bertelsen, Casper Skjaerbaek, Per Borghammer, Karolien Groenewald, Pietro-Luca Ratti, Michele T. Hu, No\'emie Moreau, Michael Sommerauer, Katarzyna Bozek</dc:creator>
    </item>
    <item>
      <title>TRACE: Contrastive learning for multi-trial time-series data in neuroscience</title>
      <link>https://arxiv.org/abs/2506.04906</link>
      <description>arXiv:2506.04906v2 Announce Type: replace 
Abstract: Modern neural recording techniques such as two-photon imaging or Neuropixel probes allow to acquire vast time-series datasets with responses of hundreds or thousands of neurons. Contrastive learning is a powerful self-supervised framework for learning representations of complex datasets. Existing applications for neural time series rely on generic data augmentations and do not exploit the multi-trial data structure inherent in many neural datasets. Here we present TRACE, a new contrastive learning framework that averages across different subsets of trials to generate positive pairs. TRACE allows to directly learn a two-dimensional embedding, combining ideas from contrastive learning and neighbor embeddings. We show that TRACE outperforms other methods, resolving fine response differences in simulated data. Further, using in vivo recordings, we show that the representations learned by TRACE capture both biologically relevant continuous variation, cell-type-related cluster structure, and can assist data quality control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04906v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lisa Schmors, Dominic Gonschorek, Jan Niklas B\"ohm, Yongrong Qiu, Na Zhou, Dmitry Kobak, Andreas Tolias, Fabian Sinz, Jacob Reimer, Katrin Franke, Sebastian Damrich, Philipp Berens</dc:creator>
    </item>
    <item>
      <title>Generalizable, real-time neural decoding with hybrid state-space models</title>
      <link>https://arxiv.org/abs/2506.05320</link>
      <description>arXiv:2506.05320v2 Announce Type: replace 
Abstract: Real-time decoding of neural activity is central to neuroscience and neurotechnology applications, from closed-loop experiments to brain-computer interfaces, where models are subject to strict latency constraints. Traditional methods, including simple recurrent neural networks, are fast and lightweight but often struggle to generalize to unseen data. In contrast, recent Transformer-based approaches leverage large-scale pretraining for strong generalization performance, but typically have much larger computational requirements and are not always suitable for low-resource or real-time settings. To address these shortcomings, we present POSSM, a novel hybrid architecture that combines individual spike tokenization via a cross-attention module with a recurrent state-space model (SSM) backbone to enable (1) fast and causal online prediction on neural activity and (2) efficient generalization to new sessions, individuals, and tasks through multi-dataset pretraining. We evaluate POSSM's decoding performance and inference speed on intracortical decoding of monkey motor tasks, and show that it extends to clinical applications, namely handwriting and speech decoding in human subjects. Notably, we demonstrate that pretraining on monkey motor-cortical recordings improves decoding performance on the human handwriting task, highlighting the exciting potential for cross-species transfer. In all of these tasks, we find that POSSM achieves decoding accuracy comparable to state-of-the-art Transformers, at a fraction of the inference cost (up to 9x faster on GPU). These results suggest that hybrid SSMs are a promising approach to bridging the gap between accuracy, inference speed, and generalization when training neural decoders for real-time, closed-loop applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05320v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025</arxiv:journal_reference>
      <dc:creator>Avery Hee-Woon Ryoo, Nanda H. Krishna, Ximeng Mao, Mehdi Azabou, Eva L. Dyer, Matthew G. Perich, Guillaume Lajoie</dc:creator>
    </item>
    <item>
      <title>Quantifying Uncertainty in Error Consistency: Towards Reliable Behavioral Comparison of Classifiers</title>
      <link>https://arxiv.org/abs/2507.06645</link>
      <description>arXiv:2507.06645v2 Announce Type: replace 
Abstract: Benchmarking models is a key factor for the rapid progress in machine learning (ML) research. Thus, further progress depends on improving benchmarking metrics. A standard metric to measure the behavioral alignment between ML models and human observers is error consistency (EC). EC allows for more fine-grained comparisons of behavior than other metrics such as accuracy, and has been used in the influential Brain-Score benchmark to rank different DNNs by their behavioral consistency with humans. Previously, EC values have been reported without confidence intervals. However, empirically measured EC values are typically noisy -- thus, without confidence intervals, valid benchmarking conclusions are problematic. Here we improve on standard EC in two ways: First, we show how to obtain confidence intervals for EC using a bootstrapping technique, allowing us to derive significance tests for EC. Second, we propose a new computational model relating the EC between two classifiers to the implicit probability that one of them copies responses from the other. This view of EC allows us to give practical guidance to scientists regarding the number of trials required for sufficiently powerful, conclusive experiments. Finally, we use our methodology to revisit popular NeuroAI-results. We find that while the general trend of behavioral differences between humans and machines holds up to scrutiny, many reported differences between deep vision models are statistically insignificant. Our methodology enables researchers to design adequately powered experiments that can reliably detect behavioral differences between models, providing a foundation for more rigorous benchmarking of behavioral alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06645v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Klein, Sascha Meyen, Wieland Brendel, Felix A. Wichmann, Kristof Meding</dc:creator>
    </item>
    <item>
      <title>Internal World Models as Imagination Networks in Cognitive Agents</title>
      <link>https://arxiv.org/abs/2510.04391</link>
      <description>arXiv:2510.04391v2 Announce Type: replace-cross 
Abstract: What is the computational objective of imagination? While classical interpretations suggest imagination is useful for maximizing rewards, recent findings challenge this view. In this study, we propose that imagination serves to access an internal world model (IWM) and use psychological network analysis to explore IWMs in humans and large language models (LLMs). Specifically, we assessed imagination vividness ratings using two questionnaires and constructed imagination networks from these reports. Imagination networks from human groups showed correlations between different centrality measures, including expected influence, strength, and closeness. However, imagination networks from LLMs showed a lack of clustering and lower correlations between centrality measures under different prompts and conversational memory conditions. Together, these results indicate a lack of similarity between IWMs in human and LLM agents. Overall, our study offers a novel method for comparing internally-generated representations in humans and AI, providing insights for developing human-like imagination in artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04391v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 10 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saurabh Ranjan, Brian Odegaard</dc:creator>
    </item>
  </channel>
</rss>
