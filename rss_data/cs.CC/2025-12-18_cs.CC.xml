<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Dec 2025 02:45:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Algorithmizing the Multiplicity Schwartz-Zippel Lemma</title>
      <link>https://arxiv.org/abs/2111.11072</link>
      <description>arXiv:2111.11072v3 Announce Type: replace 
Abstract: The multiplicity Schwartz-Zippel lemma asserts that over a field, a low-degree polynomial cannot vanish with high multiplicity very often on a sufficiently large product set. Since its discovery in a work of Dvir, Kopparty, Saraf and Sudan [SIAM J. Comput., 2013], the lemma has found numerous applications in both math and computer science; in particular, in the definition and properties of multiplicity codes by Kopparty, Saraf and Yekhanin [J. ACM, 2014].
  In this work, we show how to algorithmize the multiplicity Schwartz-Zippel lemma for arbitrary product sets over any field. In other words, we give an efficient algorithm for unique decoding of multivariate multiplicity codes from half their minimum distance on arbitrary product sets over all fields. Previously, such an algorithm was known either when the underlying product set had a nice algebraic structure: for instance, was a subfield (by Kopparty [ToC, 2015]) or when the underlying field had large (or zero) characteristic, the multiplicity parameter was sufficiently large and the multiplicity code had distance bounded away from $1$ (Bhandari, Harsha, Kumar and Sudan [STOC 2021]). In particular, even unique decoding of bivariate multiplicity codes with multiplicity two from half their minimum distance was not known over arbitrary product sets over any field.
  Our algorithm builds upon a result of Kim and Kopparty [ToC, 2017] who gave an algorithmic version of the Schwartz-Zippel lemma (without multiplicities) or equivalently, an efficient algorithm for unique decoding of Reed-Muller codes over arbitrary product sets. We introduce a refined notion of distance based on the multiplicity Schwartz-Zippel lemma and design a unique decoding algorithm for this distance measure. On the way, we give an alternate analysis of Forney's classical generalized minimum distance decoder that might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.11072v3</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.29</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 29, 1-53</arxiv:journal_reference>
      <dc:creator>Siddharth Bhandari, Prahladh Harsha, Mrinal Kumar, Ashutosh Shankar</dc:creator>
    </item>
    <item>
      <title>Toward P != NP: An Observer-Theoretic Separation via SPDP Rank and a ZFC-Equivalent Foundation within the N-Frame Model</title>
      <link>https://arxiv.org/abs/2512.11820</link>
      <description>arXiv:2512.11820v2 Announce Type: replace 
Abstract: We present a self-contained separation framework for P vs NP developed entirely within ZFC. The approach consists of: (i) a deterministic, radius-1 compilation from uniform polynomial-time Turing computation to local sum-of-squares (SoS) polynomials with polylogarithmic contextual entanglement width (CEW); (ii) a formal Width-to-Rank upper bound for the resulting SPDP matrices at matching parameters; (iii) an NP-side identity-minor lower bound in the same encoding; and (iv) a rank-monotone, instance-uniform extraction map from the compiled P-side polynomials to the NP family. Together these yield a contradiction under the assumption P = NP, establishing a separation.
  We develop a correspondence between CEW, viewed as a quantitative measure of computational contextuality, and SPDP rank, yielding a unified criterion for complexity separation. We prove that bounded-CEW observers correspond to polynomial-rank computations (the class P), while unbounded CEW characterizes the class NP. This implies that exponential SPDP rank for #3SAT and related hard families forces P != NP within the standard framework of complexity theory.
  Key technical components include: (1) constructive lower bounds on SPDP rank via Ramanujan-Tseitin expander families; (2) a non-circular reduction from Turing-machine computation to low-rank polynomial evaluation; (3) a codimension-collapse lemma ensuring that rank amplification cannot occur within polynomial resources; and (4) proofs of barrier immunity against relativization, natural proofs, and algebrization. The result is a complete ZFC proof architecture whose primitives and compositions are fully derived, with community verification and machine-checked formalization left as future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11820v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Darren J. Edwards</dc:creator>
    </item>
    <item>
      <title>Robust and optimal loading of general classical data into quantum computers</title>
      <link>https://arxiv.org/abs/2411.02782</link>
      <description>arXiv:2411.02782v3 Announce Type: replace-cross 
Abstract: As standard data loading processes, quantum state preparation and block-encoding are critical and necessary processes for quantum computing applications, including quantum machine learning, Hamiltonian simulation, and many others. Yet, existing protocols suffer from poor robustness under device imperfection, thus limiting their practicality for real-world applications. Here, this limitation is overcome based on a fanin process designed in a tree-like bucket-brigade architecture. It suppresses the error propagation between different branches, thus exponentially improving the robustness compared to existing depth-optimal methods. Moreover, the approach here simultaneously achieves the state-of-the-art fault-tolerant circuit depth, gate count, and STA. As an example of application, we show that for quantum simulation of geometrically local Hamiltonian, the code distance of each logic qubit can potentially be reduced exponentially using our technique. We believe that our technique can significantly enhance the power of quantum computing in the near-term and fault-tolerant regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02782v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCAD.2025.3600368</arxiv:DOI>
      <dc:creator>Xiao-Ming Zhang</dc:creator>
    </item>
    <item>
      <title>The NPA hierarchy does not always attain the commuting operator value</title>
      <link>https://arxiv.org/abs/2510.04943</link>
      <description>arXiv:2510.04943v4 Announce Type: replace-cross 
Abstract: We show that it is undecidable to determine whether the commuting operator value of a nonlocal game is strictly greater than 1/2. Specifically, there is a computable mapping from Turing machines to /boolean constraint system (BCS) nonlocal games in which the halting property of the machine is encoded as a decision problem for the commuting operator value of the game. As a corollary, there is a BCS game for which the value of the Navascu\'es-Pironio-Ac\'in (NPA) hierarchy does not attain the commuting operator value at any finite level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04943v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Fanizza, Larissa Kroell, Arthur Mehta, Connor Paddock, Denis Rochette, William Slofstra, Yuming Zhao</dc:creator>
    </item>
    <item>
      <title>Algebra in Algorithmic Coding Theory</title>
      <link>https://arxiv.org/abs/2512.06478</link>
      <description>arXiv:2512.06478v2 Announce Type: replace-cross 
Abstract: We survey the notion and history of error-correcting codes and the algorithms needed to make them effective in information transmission. We then give some basic as well as more modern constructions of, and algorithms for, error-correcting codes that depend on relatively simple elements of applied algebra. While the role of algebra in the constructions of codes has been widely acknowledged in texts and other writings, the role in the design of algorithms is often less widely understood, and this survey hopes to reduce this difference to some extent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06478v2</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Madhu Sudan</dc:creator>
    </item>
  </channel>
</rss>
