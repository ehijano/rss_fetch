<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 01:49:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Deep Unrolled Meta-Learning for Multi-Coil and Multi-Modality MRI with Adaptive Optimization</title>
      <link>https://arxiv.org/abs/2505.11518</link>
      <description>arXiv:2505.11518v1 Announce Type: new 
Abstract: We propose a unified deep meta-learning framework for accelerated magnetic resonance imaging (MRI) that jointly addresses multi-coil reconstruction and cross-modality synthesis. Motivated by the limitations of conventional methods in handling undersampled data and missing modalities, our approach unrolls a provably convergent optimization algorithm into a structured neural network architecture. Each phase of the network mimics a step of an adaptive forward-backward scheme with extrapolation, enabling the model to incorporate both data fidelity and nonconvex regularization in a principled manner. To enhance generalization across different acquisition settings, we integrate meta-learning, which enables the model to rapidly adapt to unseen sampling patterns and modality combinations using task-specific meta-knowledge. The proposed method is evaluated on the open source datasets, showing significant improvements in PSNR and SSIM over conventional supervised learning, especially under aggressive undersampling and domain shifts. Our results demonstrate the synergy of unrolled optimization, task-aware meta-learning, and modality fusion, offering a scalable and generalizable solution for real-world clinical MRI reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11518v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Merham Fouladvand, Peuroly Batra</dc:creator>
    </item>
    <item>
      <title>Code Retrieval for MILP Instance Generation</title>
      <link>https://arxiv.org/abs/2505.11526</link>
      <description>arXiv:2505.11526v1 Announce Type: new 
Abstract: Mixed-Integer Linear Programming (MILP) is widely used in fields such as scheduling, logistics, and planning. Enhancing the performance of MILP solvers, particularly learning-based solvers, requires substantial amounts of high-quality data. However, existing methods for MILP instance generation typically necessitate training a separate model for each problem class and are computationally intensive when generating new instances. To address these limitations, we reformulate the MILP Instance Generation task as MILP Code Generation task, enabling efficient, flexible, and interpretable instance generation through code. Since MILP instances generated from code can vary significantly in scale, we introduce MILP-EmbedSim, a new similarity metric that accurately measures the similarity between instances of varying sizes within the same problem class. Leveraging this metric, we propose MILP-Retrieval, a pipeline that retrieves generation code from library to produce MILP instances highly similar to target instance. MILP-Retrieval outperforms baselines in both MILP Code Generation and Instance Generation tasks, provides a novel perspective on MILP instance generation and opens new possibilities for learning-based solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11526v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tianxing Yang, Huigen Ye, Hua Xu</dc:creator>
    </item>
    <item>
      <title>CASL-HJX: A Comprehensive Guide to Solving Deterministic and Stochastic Hamilton-Jacobi Equations</title>
      <link>https://arxiv.org/abs/2505.11527</link>
      <description>arXiv:2505.11527v2 Announce Type: new 
Abstract: CASL-HJX is a computational framework designed for solving deterministic and stochastic Hamilton-Jacobi equations in two spatial dimensions. It provides a flexible and efficient approach to modeling front propagation problems, optimal control problems, and stochastic Hamilton-Jacobi Bellman equations. The framework integrates numerical methods for hyperbolic PDEs with operator splitting techniques and implements implicit methods for second-order derivative terms, ensuring convergence to viscosity solutions while achieving global rather than local optimization. Built with a high-performance C++ core, CASL-HJX efficiently handles mixed-order derivative systems with time-varying dynamics, making it suitable for real-world applications across multiple domains. We demonstrate the solver's versatility through tutorial examples covering various PDEs and through applications in neuroscience, where it enables the design of energy-efficient controllers for regulating neural populations to mitigate pathological synchrony. While our examples focus on these applications, the mathematical foundation of the solver makes it applicable to problems in finance, engineering, and machine learning. The modular architecture allows researchers to define computational domains, configure problems, and execute simulations with high numerical accuracy. CASL-HJX bridges the gap between deterministic control methods and stochastic models, providing a robust tool for managing uncertainty in complex dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11527v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faranak Rajabi, Jacob Fingerman, Andrew Wang, Jeff Moehlis, Frederic Gibou</dc:creator>
    </item>
    <item>
      <title>Control of semilinear differential equations with moving singularities</title>
      <link>https://arxiv.org/abs/2505.11531</link>
      <description>arXiv:2505.11531v1 Announce Type: new 
Abstract: In this paper, we present a control problem related to a semilinear differential equation with a moving singularity, i.e., the singular point depends on a parameter. The particularity of the controllability condition resides in the fact that it depends on the singular point which in turn depends on the control variable. We provide sufficient conditions to ensure that the functional determining the control is continuous over the entire domain of the parameter. Lower and upper solutions technique combined with a bisection algorithm is used to prove the controllability of the equation and to approximate the control. An example is given together with some numerical simulations. The results naturally extend to fractional differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11531v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/fractalfract9040198</arxiv:DOI>
      <dc:creator>Radu Precup, Andrei Stan, Wei-Shih Du</dc:creator>
    </item>
    <item>
      <title>Generalized Bregman Projection Algorithms for Solving Nonlinear Split Feasibility Problems in Infinite-Dimensional Spaces</title>
      <link>https://arxiv.org/abs/2505.11537</link>
      <description>arXiv:2505.11537v1 Announce Type: new 
Abstract: This paper introduces generalized Bregman projection algorithms for solving nonlinear split feasibility problems (SF P s) in infinitedimensional Hilbert spaces. The methods integrate Bregman projections, proximal gradient steps, and adaptive inertial terms to enhance convergence. Strong convergence is established under mild assumptions, and numerical experiments demonstrate the efficiency and robustness of the proposed algorithms in comparison to classical methods. These results contribute to advancing optimization techniques for nonlinear and high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11537v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saeed Hashemi Sababe, Ehsan Lotfali Ghasab</dc:creator>
    </item>
    <item>
      <title>Multi-Objective Memory Bandwidth Regulation and Cache Partitioning for Multicore Real-Time Systems</title>
      <link>https://arxiv.org/abs/2505.11554</link>
      <description>arXiv:2505.11554v1 Announce Type: new 
Abstract: Memory bandwidth regulation and cache partitioning are widely used techniques for achieving predictable timing in real-time computing systems. Combined with partitioned scheduling, these methods require careful co-allocation of tasks and resources to cores, as task execution times strongly depend on available allocated resources. To address this challenge, this paper presents a 0-1 linear program for task-resource co-allocation, along with a multi-objective heuristic designed to minimize resource usage while guaranteeing schedulability under a preemptive EDF scheduling policy. Our heuristic employs a multi-layer framework, where an outer layer explores resource allocations using Pareto-pruned search, and an inner layer optimizes task allocation by solving a knapsack problem using dynamic programming. To evaluate the performance of the proposed optimization algorithm, we profile real-world benchmarks on an embedded AMD UltraScale+ ZCU102 platform, with fine-grained resource partitioning enabled by the Jailhouse hypervisor, leveraging cache set partitioning and MemGuard for memory bandwidth regulation. Experiments based on the benchmarking results show that the proposed 0-1 linear program outperforms existing mixed-integer programs by finding more optimal solutions within the same time limit. Moreover, the proposed multi-objective multi-layer heuristic performs consistently better than the state-of-the-art multi-resource-task co-allocation algorithm in terms of schedulability, resource usage, number of non-dominated solutions, and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11554v1</guid>
      <category>math.OC</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.OS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ECRTS.2025.7</arxiv:DOI>
      <dc:creator>Binqi Sun, Zhihang Wei, Andrea Bastoni, Debayan Roy, Mirco Theile, Tomasz Kloda, Rodolfo Pellizzoni, Marco Caccamo</dc:creator>
    </item>
    <item>
      <title>Challenges in Model Agnostic Controller Learning for Unstable Systems</title>
      <link>https://arxiv.org/abs/2505.11641</link>
      <description>arXiv:2505.11641v1 Announce Type: new 
Abstract: Model agnostic controller learning, for instance by direct policy optimization, has been the object of renewed attention lately, since it avoids a computationally expensive system identification step. Indeed, direct policy search has been empirically shown to lead to optimal controllers in a number of cases of practical importance. However, to date, these empirical results have not been backed up with a comprehensive theoretical analysis for general problems. In this paper we use a simple example to show that direct policy optimization is not directly generalizable to other seemingly simple problems. In such cases, direct optimization of a performance index can lead to unstable pole/zero cancellations, resulting in the loss of internal stability and unbounded outputs in response to arbitrarily small perturbations. We conclude the paper by analyzing several alternatives to avoid this phenomenon, suggesting some new directions in direct control policy optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11641v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mario Sznaier, Mustafa Bozdag</dc:creator>
    </item>
    <item>
      <title>Advancing Averaged Primer Vector Theory with Bang-Bang Control and Eclipsing</title>
      <link>https://arxiv.org/abs/2505.11660</link>
      <description>arXiv:2505.11660v1 Announce Type: new 
Abstract: Low-thrust, many-revolution spacecraft trajectories are increasingly required for mission design due to the efficiency and reliability of electric propulsion technology. Primer vector theory using averaged dynamics is well suited for such applications, but is difficult to implement in a way that maintains both optimality and computational efficiency. An improved model is presented that combines advances from several past works into a general and practical formulation for minimum-fuel, perturbed Keplerian dynamics. The model maintains computational efficiency of dynamics averaging with optimal handling of the eclipsing constraint and bang-bang control through the use of the Leibniz integral rule for multi-arc averaging. A subtle, but important singularity arising from the averaged eclipsing constraint is identified and fixed. A maximum number of six switching function roots per revolution is established within the averaged dynamics. This new theoretical insight provides a practical upper-bound on the number of thrusting arcs required for any low-thrust optimization problem. Variational equations are provided for fast and accurate calculation of the state transition matrix for use in targeting and optimization. The dynamics include generic two-body perturbations and an expanded state to allow for sensitivity calculations with respect to launch date and flight time. A 48-revolution GTO to GEO transfer is used to directly compare optimal averaged and unaveraged trajectories. The capabilities of averaged dynamics are then demonstrated with an optimal 486-revolution GTO to GEO minimum fuel transfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11660v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Lifset, Ryan P. Russell</dc:creator>
    </item>
    <item>
      <title>An Adaptive and Parameter-Free Nesterov's Accelerated Gradient Method for Convex Optimization</title>
      <link>https://arxiv.org/abs/2505.11670</link>
      <description>arXiv:2505.11670v1 Announce Type: new 
Abstract: We propose AdaNAG, an adaptive accelerated gradient method based on Nesterov's accelerated gradient method. AdaNAG is line-search-free, parameter-free, and achieves the accelerated convergence rates $f(x_k) - f_\star = \mathcal{O}\left(1/k^2\right)$ and $\min_{i\in\left\{1,\dots, k\right\}} \|\nabla f(x_i)\|^2 = \mathcal{O}\left(1/k^3\right)$ for $L$-smooth convex function $f$. We provide a Lyapunov analysis for the convergence proof of AdaNAG, which additionally enables us to propose a novel adaptive gradient descent (GD) method, AdaGD. AdaGD achieves the non-ergodic convergence rate $f(x_k) - f_\star = \mathcal{O}\left(1/k\right)$, like the original GD. The analysis of AdaGD also motivated us to propose a generalized AdaNAG that includes practically useful variants of AdaNAG. Numerical results demonstrate that our methods outperform some other recent adaptive methods for representative applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11670v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaewook J. Suh, Shiqian Ma</dc:creator>
    </item>
    <item>
      <title>On the Sharp Input-Output Analysis of Nonlinear Systems under Adversarial Attacks</title>
      <link>https://arxiv.org/abs/2505.11688</link>
      <description>arXiv:2505.11688v1 Announce Type: new 
Abstract: This paper is concerned with learning the input-output mapping of general nonlinear dynamical systems. While the existing literature focuses on Gaussian inputs and benign disturbances, we significantly broaden the scope of admissible control inputs and allow correlated, nonzero-mean, adversarial disturbances. With our reformulation as a linear combination of basis functions, we prove that the $l_1$-norm estimator overcomes the challenges as long as the probability that the system is under adversarial attack at a given time is smaller than a certain threshold. We provide an estimation error bound that decays with the input memory length and prove its optimality by constructing a problem instance that suffers from the same bound under adversarial attacks. Our work provides a sharp input-output analysis for a generic nonlinear and partially observed system under significantly generalized assumptions compared to existing works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11688v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Yuchen Fang, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Cubic Regularization Technique of the Newton Method for Vector Optimization</title>
      <link>https://arxiv.org/abs/2505.11911</link>
      <description>arXiv:2505.11911v1 Announce Type: new 
Abstract: This study proposes a cubic regularization of the Newton method for generating weakly efficient points of unconstrained vector optimization problems under no convexity assumption on the objective function. It is observed that at a given iterate, the cubic regularized Newton direction is not necessarily a descent direction. In generating the sequence of iterates, no line search is utilized to find a suitable step length to move along the cubic regularized Newton direction. Yet, the proposed method exhibits a global convergence property with $O(k^{-2/3})$ rate of convergence. Further, the local q-quadratic convergence of the Newton method is also retained in the cubic regularization. A new stopping condition is used, which enforces the proposed method to enter in close neighborhood of non-weakly efficient points that are stationary. Thus, the studied technique ends up generating weakly efficient points, not just Pareto critical points. In addition, conditions on the choice of regularization parameter value under which the full cubic regularized Newton step becomes descent are derived. Performance profiles and comparison of the derived method with the existing methods on several test examples are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11911v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debdas Ghosh</dc:creator>
    </item>
    <item>
      <title>A preconditioned difference of convex functions algorithm with extrapolation and line search</title>
      <link>https://arxiv.org/abs/2505.11914</link>
      <description>arXiv:2505.11914v1 Announce Type: new 
Abstract: This paper proposes a novel proximal difference-of-convex (DC) algorithm enhanced with extrapolation and aggressive non-monotone line search for solving non-convex optimization problems. We introduce an adaptive conservative update strategy of the extrapolation parameter determined by a computationally efficient non-monotone line search. The core of our algorithm is to unite the update of the extrapolation parameter with the step size of the non-monotone line search interactively. The global convergence of the two proposed algorithms is established through the Kurdyka-{\L}ojasiewicz properties, ensuring convergence within a preconditioned framework for linear equations. Numerical experiments on two general non-convex problems: SCAD-penalized binary classification and graph-based Ginzburg-Landau image segmentation models, demonstrate the proposed method's high efficiency compared to existing DC algorithms both in convergence rate and solution accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11914v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ran Zhang, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>An alternative definition for c-convex functions and another synthetic statement of MTW condition</title>
      <link>https://arxiv.org/abs/2505.12063</link>
      <description>arXiv:2505.12063v1 Announce Type: new 
Abstract: The main theorem of this paper states that the c-convexity and the alternative c-convexity are equivalent if and only if the cost function c satisfies MTW condition. The alternative c-convex function is an analogy of the definition of the convex function that is using the inequality phi(t x1 + (1 - t) x0) &lt;= t phi(x1) + (1 - t) phi(x0). We study properties of the alternative c-convex functions and MTW condition, then prove the main theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12063v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonghyeon Jeong</dc:creator>
    </item>
    <item>
      <title>GPU-Accelerated SPOCK for Scenario-Based Risk-Averse Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2505.12078</link>
      <description>arXiv:2505.12078v1 Announce Type: new 
Abstract: This paper presents a GPU-accelerated implementation of the SPOCK algorithm, a proximal method designed for solving scenario-based risk-averse optimal control problems. The proposed implementation leverages the massive parallelization of the SPOCK algorithm, and benchmarking against state-of-the-art interior-point solvers demonstrates GPU-accelerated SPOCK's competitive execution time and memory footprint for large-scale problems. We further investigate the effect of the scenario tree structure on parallelizability, and so on solve time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12078v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruairi Moran, Pantelis Sopasakis</dc:creator>
    </item>
    <item>
      <title>Proximal optimal transport divergences</title>
      <link>https://arxiv.org/abs/2505.12097</link>
      <description>arXiv:2505.12097v1 Announce Type: new 
Abstract: We introduce proximal optimal transport divergence, a novel discrepancy measure that interpolates between information divergences and optimal transport distances via an infimal convolution formulation. This divergence provides a principled foundation for optimal transport proximals and proximal optimization methods frequently used in generative modeling. We explore its mathematical properties, including smoothness, boundedness, and computational tractability, and establish connections to primal-dual formulation and adversarial learning. Building on the Benamou-Brenier dynamic formulation of optimal transport cost, we also establish a dynamic formulation for proximal OT divergences. The resulting dynamic formulation is a first order mean-field game whose optimality conditions are governed by a pair of nonlinear partial differential equations, a backward Hamilton-Jacobi and a forward continuity partial differential equations. Our framework generalizes existing approaches while offering new insights and computational tools for generative modeling, distributional optimization, and gradient-based learning in probability spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12097v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ricardo Baptista, Panagiota Birmpa, Markos A. Katsoulakis, Luc Rey-Bellet, Benjamin J. Zhang</dc:creator>
    </item>
    <item>
      <title>Inexact Regularized Quasi-Newton Algorithm for Solving Monotone Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2505.12263</link>
      <description>arXiv:2505.12263v1 Announce Type: new 
Abstract: Newton's method has been an important approach for solving variational inequalities, quasi-Newton method is a good alternative choice to save computational cost. In this paper, we propose a new method for solving monotone variational inequalities where we introduce a merit function based on the merit function. With the help of the merit function, we can locally accepts unit step size. And a globalization technique based on the hyperplane is applied to the method. The proposed method applied to monotone variational inequality problems is globally convergent in the sense that subproblems always have unique solutions, and the whole sequence of iterates converges to a solution of the problem without any regularity assumptions. We also provide extensive numerical results to demonstrate the efficiency of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12263v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuge Ye, Qingna Li, Deren Han</dc:creator>
    </item>
    <item>
      <title>Finite-time stabilization of ladder multi-level quantum systems</title>
      <link>https://arxiv.org/abs/2505.12303</link>
      <description>arXiv:2505.12303v1 Announce Type: new 
Abstract: In this paper, a novel continuous non-smooth control strategy is proposed to achieve finite-time stabilization of ladder quantum systems. We first design a universal fractional-order control law for a ladder n-level quantum system using a distance-based Lyapunov function, and then apply the Filippov solution in the sense of differential inclusions and the LaSalle's invariance principle to prove the existence and uniqueness of the solution of the ladder system under the continuous non-smooth control law. Both asymptotic stability and finite-time stability for the ladder system is rigorously established by applying Lyapunov stability theory and finite-time stability criteria. We also derive an upper bound of the time required for convergence to an eigenstate of the intrinsic Hamiltonian. Numerical simulations on a rubidium ladder three-level atomic system validate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12303v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>quant-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeping Su, Sen Kuang, Daoyi Dong</dc:creator>
    </item>
    <item>
      <title>A smoothing moving balls approximation method for a class of conic-constrained difference-of-convex optimization problems</title>
      <link>https://arxiv.org/abs/2505.12314</link>
      <description>arXiv:2505.12314v1 Announce Type: new 
Abstract: In this paper, we consider the problem of minimizing a difference-of-convex objective over a nonlinear conic constraint, where the cone is closed, convex, pointed and has a nonempty interior. We assume that the support function of a compact base of the polar cone exhibits a majorizing smoothing approximation, a condition that is satisfied by widely studied cones such as $\mathbb{R}^m_-$ and ${\cal S}^m_-$. Leveraging this condition, we reformulate the conic constraint equivalently as a single constraint involving the aforementioned support function, and adapt the moving balls approximation (MBA) method for its solution. In essence, in each iteration of our algorithm, we approximate the support function by a smooth approximation function and apply one MBA step. The subproblems that arise in our algorithm always involve only one single inequality constraint, and can thus be solved efficiently via one-dimensional root-finding procedures. We design explicit rules to evolve the smooth approximation functions from iteration to iteration and establish the corresponding iteration complexity for obtaining an $\epsilon$-Karush-Kuhn-Tucker point. In addition, in the convex setting, we establish convergence of the sequence generated, and study its local convergence rate under a standard H\"olderian growth condition. Finally, we illustrate numerically the effects of different rules of evolving the smooth approximation functions on the rate of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12314v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiefeng Xu, Ting Kei Pong, Nung-sing Sze</dc:creator>
    </item>
    <item>
      <title>Stochastic Production Planning: Optimal Control and Analytical Insights</title>
      <link>https://arxiv.org/abs/2505.12341</link>
      <description>arXiv:2505.12341v1 Announce Type: new 
Abstract: This study investigates a stochastic production planning problem with a running cost composed of quadratic production costs and inventory-dependent costs. The objective is to minimize the expected cost until production stops when inventory reaches a specified level, subject to a boundary condition. Using probability space and Brownian motion, the Hamilton-Jacobi-Bellman (HJB) equation is derived, and optimal feedback control is obtained. The solution demonstrates desirable monotonicity and convexity properties under specific assumptions. An illustrative example further confirms these results with explicit function properties and a practical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12341v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dragos-Patru Covei</dc:creator>
    </item>
    <item>
      <title>Efficient Optimization with Orthogonality Constraint: a Randomized Riemannian Submanifold Method</title>
      <link>https://arxiv.org/abs/2505.12378</link>
      <description>arXiv:2505.12378v1 Announce Type: new 
Abstract: Optimization with orthogonality constraints frequently arises in various fields such as machine learning. Riemannian optimization offers a powerful framework for solving these problems by equipping the constraint set with a Riemannian manifold structure and performing optimization intrinsically on the manifold. This approach typically involves computing a search direction in the tangent space and updating variables via a retraction operation. However, as the size of the variables increases, the computational cost of the retraction can become prohibitively high, limiting the applicability of Riemannian optimization to large-scale problems. To address this challenge and enhance scalability, we propose a novel approach that restricts each update on a random submanifold, thereby significantly reducing the per-iteration complexity. We introduce two sampling strategies for selecting the random submanifolds and theoretically analyze the convergence of the proposed methods. We provide convergence results for general nonconvex functions and functions that satisfy Riemannian Polyak-Lojasiewicz condition as well as for stochastic optimization settings. Additionally, we demonstrate how our approach can be generalized to quotient manifolds derived from the orthogonal manifold. Extensive experiments verify the benefits of the proposed method, across a wide variety of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12378v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andi Han, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>High-dimensional Optimization with Low Rank Tensor Sampling and Local Search</title>
      <link>https://arxiv.org/abs/2505.12383</link>
      <description>arXiv:2505.12383v1 Announce Type: new 
Abstract: We present a novel method called TESALOCS (TEnsor SAmpling and LOCal Search) for multidimensional optimization, combining the strengths of gradient-free discrete methods and gradient-based approaches. The discrete optimization in our method is based on low-rank tensor techniques, which, thanks to their low-parameter representation, enable efficient optimization of high-dimensional problems. For the second part, i.e., local search, any effective gradient-based method can be used, whether existing (such as quasi-Newton methods) or any other developed in the future. Our approach addresses the limitations of gradient-based methods, such as getting stuck in local optima; the limitations of discrete methods, which cannot be directly applied to continuous functions; and limitations of gradient-free methods that require large computational budgets. Note that we are not limited to a single type of low-rank tensor decomposition for discrete optimization, but for illustrative purposes, we consider a specific efficient low-rank tensor train decomposition. For 20 challenging 100-dimensional functions, we demonstrate that our method can significantly outperform results obtained with gradient-based methods like Conjugate Gradient, BFGS, SLSQP, and other methods, improving them by orders of magnitude with the same computing budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12383v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Sozykin, Andrei Chertkov, Anh-Huy Phan, Ivan Oseledets, Gleb Ryzhakov</dc:creator>
    </item>
    <item>
      <title>The regulator problem for the wave equation with high internal damping controlled on the boundary: a new look via systems with memory</title>
      <link>https://arxiv.org/abs/2505.12401</link>
      <description>arXiv:2505.12401v1 Announce Type: new 
Abstract: We study the quadratic regulator problem on a finite time horizon for the wave equation with high internal damping controlled on the boundary by square integrable controls. The approach in this paper transforms the wave equation with high internal damping to an equation with persistent memory controlled on the boundary.
  One of the results of this paper is the introduction of a state space which is an extended Hilbert space, so a time dependent Hilbert space. We prove that the unique optimal control can be represented as a feedback control via a Riccati operator which solves a suitable version of the Riccati equation. Both the feedback operator and the Riccati equation acts on such time dependent space. The derivation of these main results requires a very precise analysis of the properties of the derivatives of the value function and we find an explicit form for the derivative of the Riccati operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12401v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. Pandolfi</dc:creator>
    </item>
    <item>
      <title>The Stochastic Multi-Proximal Method for Nonsmooth Optimization</title>
      <link>https://arxiv.org/abs/2505.12409</link>
      <description>arXiv:2505.12409v1 Announce Type: new 
Abstract: Stochastic gradient descent type methods are ubiquitous in machine learning, but they are only applicable to the optimization of differentiable functions. Proximal algorithms are more general and applicable to nonsmooth functions. We propose a new stochastic and variance-reduced algorithm, the Stochastic Multi-Proximal Method (SMPM), in which the proximity operators of a (possibly empty) random subset of functions are called at every iteration, according to an arbitrary sampling distribution. Several existing algorithms, including Point-SAGA (2016), Proxskip (2022) and RandProx-Minibatch (2023) are recovered as particular cases. We derive linear convergence results in presence of strong convexity and smoothness or similarity of the functions. We prove convergence in the general convex case and accelerated O(1/t2) convergence with varying stepsizes in presence of strong convexity solely. Our results are new even for the above special cases. Moreover, we show an application to distributed optimization with compressed communication, outperforming existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12409v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Condat, Elnur Gasanov, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>$\mathcal{H}_\infty$ model order reduction for quadratic output systems</title>
      <link>https://arxiv.org/abs/2505.12529</link>
      <description>arXiv:2505.12529v1 Announce Type: new 
Abstract: Linear time-invariant quadratic output (LTIQO) systems generalize linear time-invariant systems to nonlinear regimes. Problems of this class occur in multiple applications naturally, such as port-Hamiltonian systems, optimal control, and stochastical problems. We introduce an $\mathcal{H}_\infty$-norm for LTIQO systems with one or multiple outputs and propose an algorithm to optimize a reduced order model (ROM) to be close in the $\mathcal{H}_\infty$-norm to a given full order model. We illustrate the applicability and the performance with an established numerical example and compare the resulting ROMs with results from balanced truncation and $\mathcal{H}_2$-focussed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12529v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Birgit Hillebrecht, Benjamin Unger</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Descent Algorithms for Optimization: Accelerated Rates via Randomized Integration Time</title>
      <link>https://arxiv.org/abs/2505.12553</link>
      <description>arXiv:2505.12553v1 Announce Type: new 
Abstract: We study the Hamiltonian flow for optimization (HF-opt), which simulates the Hamiltonian dynamics for some integration time and resets the velocity to $0$ to decrease the objective function; this is the optimization analogue of the Hamiltonian Monte Carlo algorithm for sampling. For short integration time, HF-opt has the same convergence rates as gradient descent for minimizing strongly and weakly convex functions. We show that by randomizing the integration time in HF-opt, the resulting randomized Hamiltonian flow (RHF) achieves accelerated convergence rates in continuous time, similar to the rates for the accelerated gradient flow. We study a discrete-time implementation of RHF as the randomized Hamiltonian gradient descent (RHGD) algorithm. We prove that RHGD achieves the same accelerated convergence rates as Nesterov's accelerated gradient descent (AGD) for minimizing smooth strongly and weakly convex functions. We provide numerical experiments to demonstrate that RHGD is competitive with classical accelerated methods such as AGD across all settings and outperforms them in certain regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12553v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Fu, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Accelerated Markov Chain Monte Carlo Algorithms on Discrete States</title>
      <link>https://arxiv.org/abs/2505.12599</link>
      <description>arXiv:2505.12599v1 Announce Type: new 
Abstract: We propose a class of discrete state sampling algorithms based on Nesterov's accelerated gradient method, which extends the classical Metropolis-Hastings (MH) algorithm. The evolution of the discrete states probability distribution governed by MH can be interpreted as a gradient descent direction of the Kullback--Leibler (KL) divergence, via a mobility function and a score function. Specifically, this gradient is defined on a probability simplex equipped with a discrete Wasserstein-2 metric with a mobility function. This motivates us to study a momentum-based acceleration framework using damped Hamiltonian flows on the simplex set, whose stationary distribution matches the discrete target distribution. Furthermore, we design an interacting particle system to approximate the proposed accelerated sampling dynamics. The extension of the algorithm with a general choice of potentials and mobilities is also discussed. In particular, we choose the accelerated gradient flow of the relative Fisher information, demonstrating the advantages of the algorithm in estimating discrete score functions without requiring the normalizing constant and keeping positive probabilities. Numerical examples, including sampling on a Gaussian mixture supported on lattices or a distribution on a hypercube, demonstrate the effectiveness of the proposed discrete-state sampling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12599v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bohan Zhou, Shu Liu, Xinzhe Zuo, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Dynamic programming and dimensionality in convex stochastic optimization and control</title>
      <link>https://arxiv.org/abs/2505.12787</link>
      <description>arXiv:2505.12787v1 Announce Type: new 
Abstract: This paper studies stochastic optimization problems and associated Bellman equations in formats that allow for reduced dimensionality of the cost-to-go functions. In particular, we study stochastic control problems in the ``decision-hazard-decision'' form where at each stage, the system state is controlled both by predictable as well as adapted controls. Such an information structure may result in a lower dimensional system state than what is required in more traditional ``decision-hazard'' or ``hazard-decision'' formulations. The dimension is critical for the complexity of numerical dynamic programming algorithms and, in particular, for cutting plane schemes such as the stochastic dual dynamic programming algorithm. Our main result characterizes optimal solutions and optimum values in terms of solutions to generalized Bellman equations. Existence of solutions to the Bellman equations is established under general conditions that do not require compactness. We allow for general randomness but show that, in the Markovian case, the dimensionality of the Bellman equations reduces with respect to randomness just like in more traditional control formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12787v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teemu Pennanen, Ari-Pekka Perkki\"o</dc:creator>
    </item>
    <item>
      <title>Mode-Prefix-Based Control of Switched Linear Systems with Applications to Fault Tolerance</title>
      <link>https://arxiv.org/abs/2505.13105</link>
      <description>arXiv:2505.13105v1 Announce Type: new 
Abstract: In this paper, we consider the problem of designing prefix-based optimal controllers for switched linear systems over finite horizons. This problem arises in fault-tolerant control, when system faults result in abrupt changes in dynamics. We consider a class of mode-prefix-based linear controllers that depend only on the history of the switching signal. The proposed optimal control problems seek to minimize both expected performance and worst-case performance over switching signals. We show that this problem can be reduced to a convex optimization problem. To this end, we synthesize one controller for each switching signal under a prefix constraint that ensures consistency between controllers. Then, system level synthesis is used to obtain a convex program in terms of the system-level parameters. In particular, it is shown that the prefix constraints are linear in terms of the system-level parameters. Finally, we apply this framework for optimal control of a fighter jet model suffering from system faults, illustrating how fault tolerance is ensured.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13105v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Antoine Aspeel, Necmiye Ozay, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>How to optimise tournament draws: The case of the 2022 FIFA World Cup</title>
      <link>https://arxiv.org/abs/2505.13106</link>
      <description>arXiv:2505.13106v1 Announce Type: new 
Abstract: The organisers of major sports competitions use different policies with respect to constraints in the group draw. Our paper aims to rationalise these choices by analysing the trade-off between attractiveness (the number of games played by teams from the same geographic zone) and fairness (the departure of the draw mechanism from a uniform distribution). A parametric optimisation model is formulated and applied to the 2022 FIFA World Cup draw. A flaw of the draw procedure is identified: the pre-assignment of the host to a group implies additional but unnecessary distortions. All Pareto efficient sets of draw constraints are determined via simulations. The proposed framework can be used to find the optimal draw rules of a tournament and justify the distortion of the draw procedure for the stakeholders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13106v1</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Group Symmetry Enables Faster Optimization in Inverse Problems</title>
      <link>https://arxiv.org/abs/2505.13223</link>
      <description>arXiv:2505.13223v2 Announce Type: new 
Abstract: We prove for the first time that, if a linear inverse problem exhibits a group symmetry structure, gradient-based optimizers can be designed to exploit this structure for faster convergence rates. This theoretical finding demonstrates the existence of a special class of structure-adaptive optimization algorithms which are tailored for symmetry-structured inverse problems such as CT/MRI/PET, compressed sensing, and image processing applications such as inpainting/deconvolution, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13223v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junqi Tang, Guixian Xu</dc:creator>
    </item>
    <item>
      <title>Policy Gradient with Second Order Momentum</title>
      <link>https://arxiv.org/abs/2505.11561</link>
      <description>arXiv:2505.11561v1 Announce Type: cross 
Abstract: We develop Policy Gradient with Second-Order Momentum (PG-SOM), a lightweight second-order optimisation scheme for reinforcement-learning policies. PG-SOM augments the classical REINFORCE update with two exponentially weighted statistics: a first-order gradient average and a diagonal approximation of the Hessian. By preconditioning the gradient with this curvature estimate, the method adaptively rescales each parameter, yielding faster and more stable ascent of the expected return. We provide a concise derivation, establish that the diagonal Hessian estimator is unbiased and positive-definite under mild regularity assumptions, and prove that the resulting update is a descent direction in expectation. Numerical experiments on standard control benchmarks show up to a 2.1x increase in sample efficiency and a substantial reduction in variance compared to first-order and Fisher-matrix baselines. These results indicate that even coarse second-order information can deliver significant practical gains while incurring only D memory overhead for a D-parameter policy. All code and reproducibility scripts will be made publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11561v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Sun</dc:creator>
    </item>
    <item>
      <title>Regularity and Stability Properties of Selective SSMs with Discontinuous Gating</title>
      <link>https://arxiv.org/abs/2505.11602</link>
      <description>arXiv:2505.11602v1 Announce Type: cross 
Abstract: Deep Selective State-Space Models (SSMs), characterized by input-dependent, time-varying parameters, offer significant expressive power but pose challenges for stability analysis, especially with discontinuous gating signals. In this paper, we investigate the stability and regularity properties of continuous-time selective SSMs through the lens of passivity and Input-to-State Stability (ISS). We establish that intrinsic energy dissipation guarantees exponential forgetting of past states. Crucially, we prove that the unforced system dynamics possess an underlying minimal quadratic energy function whose defining matrix exhibits robust $\text{AUC}_{\text{loc}}$ regularity, accommodating discontinuous gating. Furthermore, assuming a universal quadratic storage function ensures passivity across all inputs, we derive parametric LMI conditions and kernel constraints that limit gating mechanisms, formalizing "irreversible forgetting" of recurrent models. Finally, we provide sufficient conditions for global ISS, linking uniform local dissipativity to overall system robustness. Our findings offer a rigorous framework for understanding and designing stable and reliable deep selective SSMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11602v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikola Zubi\'c, Davide Scaramuzza</dc:creator>
    </item>
    <item>
      <title>Generalization Guarantees for Learning Branch-and-Cut Policies in Integer Programming</title>
      <link>https://arxiv.org/abs/2505.11636</link>
      <description>arXiv:2505.11636v1 Announce Type: cross 
Abstract: Mixed-integer programming (MIP) provides a powerful framework for optimization problems, with Branch-and-Cut (B&amp;C) being the predominant algorithm in state-of-the-art solvers. The efficiency of B&amp;C critically depends on heuristic policies for making sequential decisions, including node selection, cut selection, and branching variable selection. While traditional solvers often employ heuristics with manually tuned parameters, recent approaches increasingly leverage machine learning, especially neural networks, to learn these policies directly from data. A key challenge is to understand the theoretical underpinnings of these learned policies, particularly their generalization performance from finite data. This paper establishes rigorous sample complexity bounds for learning B&amp;C policies where the scoring functions guiding each decision step (node, cut, branch) have a certain piecewise polynomial structure. This structure generalizes the linear models that form the most commonly deployed policies in practice and investigated recently in a foundational series of theoretical works by Balcan et al. Such piecewise polynomial policies also cover the neural network architectures (e.g., using ReLU activations) that have been the focal point of contemporary practical studies. Consequently, our theoretical framework closely reflects the models utilized by practitioners investigating machine learning within B&amp;C, offering a unifying perspective relevant to both established theory and modern empirical research in this area. Furthermore, our theory applies to quite general sequential decision making problems beyond B&amp;C.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11636v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyu Cheng, Amitabh Basu</dc:creator>
    </item>
    <item>
      <title>A Local Polyak-Lojasiewicz and Descent Lemma of Gradient Descent For Overparametrized Linear Models</title>
      <link>https://arxiv.org/abs/2505.11664</link>
      <description>arXiv:2505.11664v1 Announce Type: cross 
Abstract: Most prior work on the convergence of gradient descent (GD) for overparameterized neural networks relies on strong assumptions on the step size (infinitesimal), the hidden-layer width (infinite), or the initialization (large, spectral, balanced). Recent efforts to relax these assumptions focus on two-layer linear networks trained with the squared loss. In this work, we derive a linear convergence rate for training two-layer linear neural networks with GD for general losses and under relaxed assumptions on the step size, width, and initialization. A key challenge in deriving this result is that classical ingredients for deriving convergence rates for nonconvex problems, such as the Polyak-{\L}ojasiewicz (PL) condition and Descent Lemma, do not hold globally for overparameterized neural networks. Here, we prove that these two conditions hold locally with local constants that depend on the weights. Then, we provide bounds on these local constants, which depend on the initialization of the weights, the current loss, and the global PL and smoothness constants of the non-overparameterized model. Based on these bounds, we derive a linear convergence rate for GD. Our convergence analysis not only improves upon prior results but also suggests a better choice for the step size, as verified through our numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11664v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziqing Xu, Hancheng Min, Salma Tarmoun, Enrique Mallada, Rene Vidal</dc:creator>
    </item>
    <item>
      <title>Qronos: Correcting the Past by Shaping the Future... in Post-Training Quantization</title>
      <link>https://arxiv.org/abs/2505.11695</link>
      <description>arXiv:2505.11695v1 Announce Type: cross 
Abstract: We introduce Qronos -- a new state-of-the-art post-training quantization algorithm that sequentially rounds and updates neural network weights. Qronos not only explicitly corrects errors due to both weight and activation quantization, but also errors resulting from quantizing previous layers. Our iterative algorithm is based on an interpretable and disciplined optimization framework that subsumes and surpasses existing data-driven approaches. At each step, Qronos alternates between error correction and diffusion via optimal update rules. Importantly, we prove that Qronos admits an efficient implementation that uses the Cholesky decomposition for solving least-squares problems. We also demonstrate that Qronos is compatible with existing transformation techniques such as Hadamard-based incoherence processing and weight-activation scaling equalization, among others. We evaluate Qronos using recent autoregressive language generation models in the Llama3 family; Qronos consistently outperforms previous state-of-the-art adaptive rounding methods when quantizing the weights, activations, and/or KV caches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11695v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shihao Zhang, Haoyu Zhang, Ian Colbert, Rayan Saab</dc:creator>
    </item>
    <item>
      <title>Variational Regularized Unbalanced Optimal Transport: Single Network, Least Action</title>
      <link>https://arxiv.org/abs/2505.11823</link>
      <description>arXiv:2505.11823v1 Announce Type: cross 
Abstract: Recovering the dynamics from a few snapshots of a high-dimensional system is a challenging task in statistical physics and machine learning, with important applications in computational biology. Many algorithms have been developed to tackle this problem, based on frameworks such as optimal transport and the Schr\"odinger bridge. A notable recent framework is Regularized Unbalanced Optimal Transport (RUOT), which integrates both stochastic dynamics and unnormalized distributions. However, since many existing methods do not explicitly enforce optimality conditions, their solutions often struggle to satisfy the principle of least action and meet challenges to converge in a stable and reliable way. To address these issues, we propose Variational RUOT (Var-RUOT), a new framework to solve the RUOT problem. By incorporating the optimal necessary conditions for the RUOT problem into both the parameterization of the search space and the loss function design, Var-RUOT only needs to learn a scalar field to solve the RUOT problem and can search for solutions with lower action. We also examined the challenge of selecting a growth penalty function in the widely used Wasserstein-Fisher-Rao metric and proposed a solution that better aligns with biological priors in Var-RUOT. We validated the effectiveness of Var-RUOT on both simulated data and real single-cell datasets. Compared with existing algorithms, Var-RUOT can find solutions with lower action while exhibiting faster convergence and improved training stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11823v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuhao Sun, Zhenyi Zhang, Zihan Wang, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>On the $O(\frac{\sqrt{d}}{K^{1/4}})$ Convergence Rate of AdamW Measured by $\ell_1$ Norm</title>
      <link>https://arxiv.org/abs/2505.11840</link>
      <description>arXiv:2505.11840v1 Announce Type: cross 
Abstract: As the default optimizer for training large language models, AdamW has achieved remarkable success in deep learning. However, its convergence behavior is not theoretically well-understood. This paper establishes the convergence rate $\frac{1}{K}\sum_{k=1}^KE\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}C}{K^{1/4}})$ for AdamW measured by $\ell_1$ norm, where $K$ represents the iteration number, $d$ denotes the model dimension, and $C$ matches the constant in the optimal convergence rate of SGD. Theoretically, we have $E\left[\|\nabla f(x)\|_1\right]\geq\sqrt{\frac{2d}{\pi}}E\left[\|\nabla f(x)\|_2\right]$ when each element of $\nabla f(x)$ is generated from Gaussian distribution $\mathcal N(0,1)$. Empirically, our experimental results on real-world deep learning tasks reveal $\|\nabla f(x)\|_1=\varTheta(\sqrt{d})\|\nabla f(x)\|_2$. Both support that our convergence rate can be considered to be analogous to the optimal $\frac{1}{K}\sum_{k=1}^KE\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{C}{K^{1/4}})$ convergence rate of SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11840v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huan Li, Yiming Dong, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>Model-free Dynamic Mode Adaptive Control using Matrix RLS</title>
      <link>https://arxiv.org/abs/2505.11844</link>
      <description>arXiv:2505.11844v1 Announce Type: cross 
Abstract: This paper presents a novel, model-free, data-driven control synthesis technique known as dynamic mode adaptive control (DMAC) for synthesizing controllers for complex systems whose mathematical models are not suitable for classical control design. DMAC consists of a dynamics approximation module and a controller module. The dynamics approximation module is motivated by data-driven reduced-order modeling techniques and directly approximates the system's dynamics in state-space form using a matrix version of the recursive least squares algorithm. The controller module includes an output tracking controller that utilizes sparse measurements from the system to generate the control signal. The DMAC controller design technique is demonstrated through various dynamic systems commonly found in engineering applications. A systematic sensitivity study demonstrates the robustness of DMAC with respect to its own hyperparameters and the system's parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11844v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parham Oveissi, Ankit Goel</dc:creator>
    </item>
    <item>
      <title>T-Rex: Fitting a Robust Factor Model via Expectation-Maximization</title>
      <link>https://arxiv.org/abs/2505.12117</link>
      <description>arXiv:2505.12117v1 Announce Type: cross 
Abstract: Over the past decades, there has been a surge of interest in studying low-dimensional structures within high-dimensional data. Statistical factor models $-$ i.e., low-rank plus diagonal covariance structures $-$ offer a powerful framework for modeling such structures. However, traditional methods for fitting statistical factor models, such as principal component analysis (PCA) or maximum likelihood estimation assuming the data is Gaussian, are highly sensitive to heavy tails and outliers in the observed data. In this paper, we propose a novel expectation-maximization (EM) algorithm for robustly fitting statistical factor models. Our approach is based on Tyler's M-estimator of the scatter matrix for an elliptical distribution, and consists of solving Tyler's maximum likelihood estimation problem while imposing a structural constraint that enforces the low-rank plus diagonal covariance structure. We present numerical experiments on both synthetic and real examples, demonstrating the robustness of our method for direction-of-arrival estimation in nonuniform noise and subspace recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12117v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Cederberg</dc:creator>
    </item>
    <item>
      <title>Multi-CALF: A Policy Combination Approach with Statistical Guarantees</title>
      <link>https://arxiv.org/abs/2505.12350</link>
      <description>arXiv:2505.12350v1 Announce Type: cross 
Abstract: We introduce Multi-CALF, an algorithm that intelligently combines reinforcement learning policies based on their relative value improvements. Our approach integrates a standard RL policy with a theoretically-backed alternative policy, inheriting formal stability guarantees while often achieving better performance than either policy individually. We prove that our combined policy converges to a specified goal set with known probability and provide precise bounds on maximum deviation and convergence time. Empirical validation on control tasks demonstrates enhanced performance while maintaining stability guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12350v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgiy Malaniya, Anton Bolychev, Grigory Yaremenko, Anastasia Krasnaya, Pavel Osinenko</dc:creator>
    </item>
    <item>
      <title>A universal policy wrapper with guarantees</title>
      <link>https://arxiv.org/abs/2505.12354</link>
      <description>arXiv:2505.12354v1 Announce Type: cross 
Abstract: We introduce a universal policy wrapper for reinforcement learning agents that ensures formal goal-reaching guarantees. In contrast to standard reinforcement learning algorithms that excel in performance but lack rigorous safety assurances, our wrapper selectively switches between a high-performing base policy -- derived from any existing RL method -- and a fallback policy with known convergence properties. Base policy's value function supervises this switching process, determining when the fallback policy should override the base policy to ensure the system remains on a stable path. The analysis proves that our wrapper inherits the fallback policy's goal-reaching guarantees while preserving or improving upon the performance of the base policy. Notably, it operates without needing additional system knowledge or online constrained optimization, making it readily deployable across diverse reinforcement learning architectures and tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12354v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Bolychev, Georgiy Malaniya, Grigory Yaremenko, Anastasia Krasnaya, Pavel Osinenko</dc:creator>
    </item>
    <item>
      <title>Wasserstein Barycenter Gaussian Process based Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2505.12471</link>
      <description>arXiv:2505.12471v1 Announce Type: cross 
Abstract: Gaussian Process based Bayesian Optimization is a widely applied algorithm to learn and optimize under uncertainty, well-known for its sample efficiency. However, recently -- and more frequently -- research studies have empirically demonstrated that the Gaussian Process fitting procedure at its core could be its most relevant weakness. Fitting a Gaussian Process means tuning its kernel's hyperparameters to a set of observations, but the common Maximum Likelihood Estimation technique, usually appropriate for learning tasks, has shown different criticalities in Bayesian Optimization, making theoretical analysis of this algorithm an open challenge. Exploiting the analogy between Gaussian Processes and Gaussian Distributions, we present a new approach which uses a prefixed set of hyperparameters values to fit as many Gaussian Processes and then combines them into a unique model as a Wasserstein Barycenter of Gaussian Processes. We considered both "easy" test problems and others known to undermine the \textit{vanilla} Bayesian Optimization algorithm. The new method, namely Wasserstein Barycenter Gausssian Process based Bayesian Optimization (WBGP-BO), resulted promising and able to converge to the optimum, contrary to vanilla Bayesian Optimization, also on the most "tricky" test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12471v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Candelieri, Andrea Ponti, Francesco Archetti</dc:creator>
    </item>
    <item>
      <title>Enforcing Fairness Where It Matters: An Approach Based on Difference-of-Convex Constraints</title>
      <link>https://arxiv.org/abs/2505.12530</link>
      <description>arXiv:2505.12530v1 Announce Type: cross 
Abstract: Fairness in machine learning has become a critical concern, particularly in high-stakes applications. Existing approaches often focus on achieving full fairness across all score ranges generated by predictive models, ensuring fairness in both high and low-scoring populations. However, this stringent requirement can compromise predictive performance and may not align with the practical fairness concerns of stakeholders. In this work, we propose a novel framework for building partially fair machine learning models, which enforce fairness within a specific score range of interest, such as the middle range where decisions are most contested, while maintaining flexibility in other regions. We introduce two statistical metrics to rigorously evaluate partial fairness within a given score range, such as the top 20%-40% of scores. To achieve partial fairness, we propose an in-processing method by formulating the model training problem as constrained optimization with difference-of-convex constraints, which can be solved by an inexact difference-of-convex algorithm (IDCA). We provide the complexity analysis of IDCA for finding a nearly KKT point. Through numerical experiments on real-world datasets, we demonstrate that our framework achieves high predictive performance while enforcing partial fairness where it matters most.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12530v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yutian He, Yankun Huang, Yao Yao, Qihang Lin</dc:creator>
    </item>
    <item>
      <title>On long-duration storage, weather uncertainty and limited foresight</title>
      <link>https://arxiv.org/abs/2505.12538</link>
      <description>arXiv:2505.12538v1 Announce Type: cross 
Abstract: Long-duration energy storage (LDES) is a key component for fully renewable, sector-coupled energy systems based on wind and solar. While capacity expansion planning has begun to take into account interannual weather variability, it often ignores weather uncertainty and limited foresight in capacity and operational decisions. We build a stochastic capacity expansion model for fully decarbonized energy systems with LDES in Europe accounting for weather uncertainty - isolating the effect of limited foresight by comparing it to a perfect foresight benchmark. Under limited foresight, LDES acts as a hedge against extreme system states operating defensively and exhibiting a stockpiling effect absent under perfect foresight. Solar PV gains in system value for its higher predictability with up to 29\% higher capacities versus the benchmark while onshore wind capacities are lower. We shed light on the underlying mechanisms by deriving implicit LDES bidding curves. We show that LDES bids reflect the costs and the weather-dependent probability of extreme system states conditional on the current system state. This has important implications for the price formation on renewable electricity markets, as a wide and continuous range of probabilistic LDES bids alleviates concerns of extreme price disparity at high renewable shares.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12538v1</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Schmidt</dc:creator>
    </item>
    <item>
      <title>Transmission Neural Networks: Approximation and Optimal Control</title>
      <link>https://arxiv.org/abs/2505.12657</link>
      <description>arXiv:2505.12657v1 Announce Type: cross 
Abstract: Transmission Neural Networks (TransNNs) introduced by Gao and Caines (2022) connect virus spread models over networks and neural networks with tuneable activation functions. This paper presents the approximation technique and the underlying assumptions employed by TransNNs in relation to the corresponding Markovian Susceptible-Infected-Susceptible (SIS) model with 2^n states, where n is the number of nodes in the network. The underlying infection paths are assumed to be stochastic with heterogeneous and time-varying transmission probabilities. We obtain the conditional probability of infection in the stochastic 2^n-state SIS epidemic model corresponding to each state configuration under mild assumptions, which enables control solutions based on Markov decision processes (MDP). Finally, MDP control with 2^n-state SIS epidemic models and optimal control with TransNNs are compared in terms of mitigating virus spread over networks through vaccination, and it is shown that TranNNs enable the generation of control laws with significant computational savings, albeit with more conservative control actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12657v1</guid>
      <category>eess.SY</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IFAC Conference on Networked Systems, 2025</arxiv:journal_reference>
      <dc:creator>Shuang Gao, Peter E. Caines</dc:creator>
    </item>
    <item>
      <title>Connecting the Equinoctial Elements and Rodrigues Parameters: A New Set of Elements</title>
      <link>https://arxiv.org/abs/2505.12812</link>
      <description>arXiv:2505.12812v1 Announce Type: cross 
Abstract: A geometric interpretation of the equinoctial elements is given with a connection to orthogonal rotations and attitude dynamics in Euclidean 3-space. An identification is made between the equinoctial elements and classic Rodrigues parameters. A new set of equinoctial elements are developed using the modified Rodrigues parameters, thereby removing the coordinate singularity for retrograde equatorial orbits present in previous versions of these elements. A low-thrust trajectory optimization problem is set up using the new elements to numerically verify convergence for the two-point boundary problem, as compared to their predecessors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12812v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>physics.class-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G007347</arxiv:DOI>
      <arxiv:journal_reference>Journal of Guidance, Control, and Dynamics, 46(9), 1726-1744 (2023)</arxiv:journal_reference>
      <dc:creator>Joseph T. A. Peterson, Vishala Arya, John L. Junkins</dc:creator>
    </item>
    <item>
      <title>RGNMR: A Gauss-Newton method for robust matrix completion with theoretical guarantees</title>
      <link>https://arxiv.org/abs/2505.12919</link>
      <description>arXiv:2505.12919v1 Announce Type: cross 
Abstract: Recovering a low rank matrix from a subset of its entries, some of which may be corrupted, is known as the robust matrix completion (RMC) problem. Existing RMC methods have several limitations: they require a relatively large number of observed entries; they may fail under overparametrization, when their assumed rank is higher than the correct one; and many of them fail to recover even mildly ill-conditioned matrices. In this paper we propose a novel RMC method, denoted $\texttt{RGNMR}$, which overcomes these limitations. $\texttt{RGNMR}$ is a simple factorization-based iterative algorithm, which combines a Gauss-Newton linearization with removal of entries suspected to be outliers. On the theoretical front, we prove that under suitable assumptions, $\texttt{RGNMR}$ is guaranteed exact recovery of the underlying low rank matrix. Our theoretical results improve upon the best currently known for factorization-based methods. On the empirical front, we show via several simulations the advantages of $\texttt{RGNMR}$ over existing RMC methods, and in particular its ability to handle a small number of observed entries, overparameterization of the rank and ill-conditioned matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12919v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eilon Vaknin Laufer, Boaz Nadler</dc:creator>
    </item>
    <item>
      <title>A Faster Parametric Search for the Integral Quickest Transshipment Problem</title>
      <link>https://arxiv.org/abs/2505.12975</link>
      <description>arXiv:2505.12975v1 Announce Type: cross 
Abstract: Algorithms for computing fractional solutions to the quickest transshipment problem have been significantly improved since Hoppe and Tardos first solved the problem in strongly polynomial time. For integral solutions, runtime improvements are limited to general progress on submodular function minimization, which is an integral part of Hoppe and Tardos' algorithm. Yet, no structural improvements on their algorithm itself have been proposed. We replace two central subroutines in the algorithm with methods that require vastly fewer minimizations of submodular functions. This improves the state-of-the-art runtime from $ \tilde{O}(m^4 k^{15}) $ down to $ \tilde{O}(m^2 k^5 + m^4 k^2) $, where $ k $ is the number of terminals and $ m $ is the number of arcs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12975v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mariia Anapolska, Dario van den Boom, Christina B\"using, Timo Gersing</dc:creator>
    </item>
    <item>
      <title>Algorithms for Nonlinear Mixed-Integer Location Estimation</title>
      <link>https://arxiv.org/abs/2505.12980</link>
      <description>arXiv:2505.12980v1 Announce Type: cross 
Abstract: For three decades, carrier-phase observations have been used to obtain the most accurate location estimates using global navigation satellite systems (GNSS). These estimates are computed by minimizing a nonlinear mixed-integer least-squares problem. Existing algorithms linearize the problem, orthogonally project it to eliminate real variables, and then solve the integer least-square problem. There is now considerable interest in developing similar localization techniques for terrestrial and indoor settings. We show that algorithms that linearize first fail in these settings and we propose several algorithms for computing the estimates. Some of our algorithms are elimination algorithms that start by eliminating the non-linear terms in the constraints; others construct a geometric arrangement that allows us to efficiently enumerate integer solutions (in polynomial time). We focus on simplified localization problems in which the measurements are range (distance) measurements and carrier phase range measurements, with no nuisance parameters. The simplified problem allows us to focus on the core question of untangling the nonlinearity and the integer nature of some parameters. We show using simulations that the new algorithms are effective at close ranges at which the linearize-first approach fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12980v1</guid>
      <category>eess.SP</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ophir Uziel, Efi Fogel, Dan Halperin, Sivan Toledo</dc:creator>
    </item>
    <item>
      <title>Lexicographic Preferences over Random Availability Functions</title>
      <link>https://arxiv.org/abs/2505.12997</link>
      <description>arXiv:2505.12997v1 Announce Type: cross 
Abstract: We provide an axiomatic characterization of lexicographic preferences over the set of all random availability functions using two assumptions. The first assumption is strong monotonicity, which in our framework is equivalent to the strong dominance property in microeconomics. The second assumption is independence of worse alternatives and we show that a weaker version of the same suffices for our purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12997v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>Stochastic Orthogonal Regularization for deep projective priors</title>
      <link>https://arxiv.org/abs/2505.13078</link>
      <description>arXiv:2505.13078v1 Announce Type: cross 
Abstract: Many crucial tasks of image processing and computer vision are formulated as inverse problems. Thus, it is of great importance to design fast and robust algorithms to solve these problems. In this paper, we focus on generalized projected gradient descent (GPGD) algorithms where generalized projections are realized with learned neural networks and provide state-of-the-art results for imaging inverse problems. Indeed, neural networks allow for projections onto unknown low-dimensional sets that model complex data, such as images. We call these projections deep projective priors. In generic settings, when the orthogonal projection onto a lowdimensional model set is used, it has been shown, under a restricted isometry assumption, that the corresponding orthogonal PGD converges with a linear rate, yielding near-optimal convergence (within the class of GPGD methods) in the classical case of sparse recovery. However, for deep projective priors trained with classical mean squared error losses, there is little guarantee that the hypotheses for linear convergence are satisfied. In this paper, we propose a stochastic orthogonal regularization of the training loss for deep projective priors. This regularization is motivated by our theoretical results: a sufficiently good approximation of the orthogonal projection guarantees linear stable recovery with performance close to orthogonal PGD. We show experimentally, using two different deep projective priors (based on autoencoders and on denoising networks), that our stochastic orthogonal regularization yields projections that improve convergence speed and robustness of GPGD in challenging inverse problem settings, in accordance with our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13078v1</guid>
      <category>eess.IV</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Joundi (UB), Yann Traonmilin (UB), Alasdair Newson (ISIR)</dc:creator>
    </item>
    <item>
      <title>When majority rules, minority loses: bias amplification of gradient descent</title>
      <link>https://arxiv.org/abs/2505.13122</link>
      <description>arXiv:2505.13122v1 Announce Type: cross 
Abstract: Despite growing empirical evidence of bias amplification in machine learning, its theoretical foundations remain poorly understood. We develop a formal framework for majority-minority learning tasks, showing how standard training can favor majority groups and produce stereotypical predictors that neglect minority-specific features. Assuming population and variance imbalance, our analysis reveals three key findings: (i) the close proximity between ``full-data'' and stereotypical predictors, (ii) the dominance of a region where training the entire model tends to merely learn the majority traits, and (iii) a lower bound on the additional training required. Our results are illustrated through experiments in deep learning for tabular and image classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13122v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bachoc (IMT), J\'er\^ome Bolte (TSE-R), Ryan Boustany (TSE-R), Jean-Michel Loubes (IMT)</dc:creator>
    </item>
    <item>
      <title>It\^o-Wentzell-Lions formulae for flows of full and conditional measures on semimartingales</title>
      <link>https://arxiv.org/abs/2505.13155</link>
      <description>arXiv:2505.13155v1 Announce Type: cross 
Abstract: In this paper, we establish the It\^o-Wentzell-Lions formulae for flows of both full and conditional measures on general semimartingales. This generalizes the existing works on flows of measures on It\^o processes. The key technical components involve an appropriate approximation of random fields by cylindrical functions and localization techniques. Moreover, we present the specific formulae in two special cases, including It\^o-Wentzell-Lions formulae for time-space-measure-dependent functions and for functions driven by Poisson random measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13155v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liu Jisheng, Zhang Jing</dc:creator>
    </item>
    <item>
      <title>Null-adjusted persistence function for high-resolution community detection</title>
      <link>https://arxiv.org/abs/2505.13272</link>
      <description>arXiv:2505.13272v1 Announce Type: cross 
Abstract: Modularity and persistence probability are two widely used quality functions for detecting communities in complex networks. In this paper, we introduce a new objective function called null-adjusted persistence, which incorporates features from both modularity and persistence probability, as it implies a comparison of persistence probability with the same null model of modularity. We prove key analytic properties of this new function. We show that the null-adjusted persistence overcomes the limitations of modularity, such as scaling behavior and resolution limits, and the limitation of the persistence probability, which is an increasing function with respect to the cluster size. We propose to find the partition that maximizes the null-adjusted persistence with a variation of the Louvain method and we tested its effectiveness on benchmark and real networks. We found out that maximizing null-adjusted persistence outperforms modularity maximization, as it detects higher resolution partitions in dense and large networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13272v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Avellone, Paolo Bartesaghi, Stefano Benati, Christos Charalambous, Rosanna Grassi</dc:creator>
    </item>
    <item>
      <title>Gluon: Making Muon &amp; Scion Great Again! (Bridging Theory and Practice of LMO-based Optimizers for LLMs)</title>
      <link>https://arxiv.org/abs/2505.13416</link>
      <description>arXiv:2505.13416v1 Announce Type: cross 
Abstract: Recent developments in deep learning optimization have brought about radically new algorithms based on the Linear Minimization Oracle (LMO) framework, such as $\sf Muon$ and $\sf Scion$. After over a decade of $\sf Adam$'s dominance, these LMO-based methods are emerging as viable replacements, offering several practical advantages such as improved memory efficiency, better hyperparameter transferability, and most importantly, superior empirical performance on large-scale tasks, including LLM training. However, a significant gap remains between their practical use and our current theoretical understanding: prior analyses (1) overlook the layer-wise LMO application of these optimizers in practice, and (2) rely on an unrealistic smoothness assumption, leading to impractically small stepsizes. To address both, we propose a new LMO-based method called $\sf Gluon$, capturing prior theoretically analyzed methods as special cases, and introduce a new refined generalized smoothness model that captures the layer-wise geometry of neural networks, matches the layer-wise practical implementation of $\sf Muon$ and $\sf Scion$, and leads to convergence guarantees with strong practical predictive power. Unlike prior results, our theoretical stepsizes closely match the fine-tuned values reported by Pethick et al. (2025). Our experiments with NanoGPT and CNN confirm that our assumption holds along the optimization trajectory, ultimately closing the gap between theory and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13416v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artem Riabinin, Egor Shulgin, Kaja Gruntkowska, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Robust Path Recommendations During Public Transit Disruptions Under Demand Uncertainty</title>
      <link>https://arxiv.org/abs/2201.01437</link>
      <description>arXiv:2201.01437v2 Announce Type: replace 
Abstract: When there are significant service disruptions in public transit systems, passengers usually need guidance to find alternative paths. This paper proposes a path recommendation model to mitigate congestion during public transit disruptions. Passengers with different origins, destinations, and departure times are recommended with different paths such that the system travel time is minimized. We model the path recommendation problem as an optimal flow problem with uncertain demand information. To tackle the lack of analytical formulation of travel times due to capacity constraints, we propose a simulation-based first-order approximation to transform the original problem into a linear program. Uncertainties in demand are modeled using robust optimization to protect the path recommendation strategies against inaccurate estimates. A real-world rail disruption scenario in the Chicago Transit Authority (CTA) system is used as a case study. Results show that even without considering uncertainty, the nominal model can reduce the system travel time by 9.1% (compared to the status quo), and outperforms the benchmark capacity-based path recommendation. The average travel time of passengers in the incident line (i.e., passengers receiving recommendations) is reduced more (-20.6% compared to the status quo). After incorporating the demand uncertainty, the robust model can further reduce system travel times. The best robust model can decrease the average travel time of incident-line passengers by 2.91% compared to the nominal model. The improvement of robust models is more prominent when the actual demand pattern is close to the worst-case demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.01437v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.trb.2023.02.004</arxiv:DOI>
      <arxiv:journal_reference>Transportation Research Part B: Methodological, 169, 82-107 (2023)</arxiv:journal_reference>
      <dc:creator>Baichuan Mo, Haris N. Koutsopoulos, Max Zuo-Jun Shen, Jinhua Zhao</dc:creator>
    </item>
    <item>
      <title>P-split formulations: A class of intermediate formulations between big-M and convex hull for disjunctive constraints</title>
      <link>https://arxiv.org/abs/2202.05198</link>
      <description>arXiv:2202.05198v3 Announce Type: replace 
Abstract: We develop a class of mixed-integer formulations for disjunctive constraints intermediate to the big-M and convex hull formulations in terms of relaxation strength. The main idea is to capture the best of both the big-M and convex hull formulations: a computationally light formulation with a tight relaxation. The "P-split" formulations are based on a lifted transformation that splits convex additively separable constraints into P partitions and forms the convex hull of the linearized and partitioned disjunction. The "P-split" formulations are derived for disjunctive constraints with convex constraints within each disjunct, and we generalize the results for the case with nonconvex constraints within the disjuncts. We analyze the continuous relaxation of the P-split formulations and show that, under certain assumptions, the formulations form a hierarchy starting from a big-M equivalent and converging to the convex hull. We computationally compare the P-split formulations against big-M and convex hull formulations on 344 test instances. The test problems include K-means clustering, semi-supervised clustering, P_ball problems, and optimization over trained ReLU neural networks. The computational results show promising potential of the P-split formulations. For many of the test problems, P-split formulations are solved with a similar number of explored nodes as the convex hull formulation, while reducing the solution time by an order of magnitude and outperforming big-M both in time and number of explored nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.05198v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Kronqvist, Ruth Misener, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>Tight Mixed-Integer Optimization Formulations for Prescriptive Trees</title>
      <link>https://arxiv.org/abs/2302.14744</link>
      <description>arXiv:2302.14744v2 Announce Type: replace 
Abstract: We focus on modeling the relationship between an input feature vector and the predicted outcome of a trained decision tree using mixed-integer optimization. This can be used in many practical applications where a decision tree or tree ensemble is incorporated into an optimization problem to model the predicted outcomes of a decision. We propose tighter mixed-integer optimization formulations than those previously introduced. Existing formulations can be shown to have linear relaxations that have fractional extreme points, even for the simple case of modeling a single decision tree. A formulation we propose, based on a projected union of polyhedra approach, is ideal for a single decision tree. While the formulation is generally not ideal for tree ensembles or if additional constraints are added, it generally has fewer extreme points, leading to a faster time to solve, particularly if the formulation has relatively few trees. However, previous work has shown that formulations based on a binary representation of the feature vector perform well computationally and hence are attractive for use in practical applications. We present multiple approaches to tighten existing formulations with binary vectors, and show that fractional extreme points are removed when there are multiple splits on the same feature. At an extreme, we prove that this results in ideal formulations for tree ensembles modeling a one-dimensional feature vector. Building on this result, we also show via numerical simulations that these additional constraints result in significantly tighter linear relaxations when the feature vector is low dimensional. We also present instances where the time to solve to optimality is significantly improved using these formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14744v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Biggs, Georgia Perakis</dc:creator>
    </item>
    <item>
      <title>Distorted optimal transport</title>
      <link>https://arxiv.org/abs/2308.11238</link>
      <description>arXiv:2308.11238v2 Announce Type: replace 
Abstract: Classic optimal transport theory is formulated through minimizing the expected transport cost between two given distributions. We propose the framework of distorted optimal transport by minimizing a distorted expected cost, which is the cost under a non-linear expectation. This new formulation is motivated by concrete problems in decision theory, robust optimization, and risk management, and it has many distinct features compared to the classic theory. We choose simple cost functions and study different distortion functions and their implications on the optimal transport plan. We show that on the real line, the comonotonic coupling is optimal for the distorted optimal transport problem when the distortion function is convex and the cost function is submodular and monotone. Some forms of duality and uniqueness results are provided. For inverse-S-shaped distortion functions and linear cost, we obtain the unique form of optimal coupling for all marginal distributions, which turns out to have an interesting ``first comonotonic, then counter-monotonic" dependence structure; for S-shaped distortion functions a similar structure is obtained. Our results highlight several challenges and features in distorted optimal transport, offering a new mathematical bridge between the fields of probability, decision theory, and risk management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11238v2</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <category>math.PR</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyan Liu, Bin Wang, Ruodu Wang, Sheng Chao Zhuang</dc:creator>
    </item>
    <item>
      <title>Generalized open-loop Nash equilibria in linear-quadratic difference games with coupled-affine inequality constraints</title>
      <link>https://arxiv.org/abs/2310.01895</link>
      <description>arXiv:2310.01895v5 Announce Type: replace 
Abstract: In this note, we study a class of deterministic finite-horizon linear-quadratic difference games with coupled affine inequality constraints involving both state and control variables. We show that the necessary conditions for the existence of generalized open-loop Nash equilibria in this game class lead to two strongly coupled discrete-time linear complementarity systems. Subsequently, we derive sufficient conditions by establishing an equivalence between the solutions of these systems and convexity of the players' objective functions. These conditions are then reformulated as a solution to a linear complementarity problem, providing a numerical method to compute these equilibria. We illustrate our results using a network flow game with constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01895v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Partha Sarathi Mohapatra, Puduru Viswanadha Reddy</dc:creator>
    </item>
    <item>
      <title>A deep learning algorithm for computing mean field control problems via forward-backward score dynamics</title>
      <link>https://arxiv.org/abs/2401.09547</link>
      <description>arXiv:2401.09547v2 Announce Type: replace 
Abstract: We propose a deep learning approach to compute mean field control problems with individual noises. The problem consists of the Fokker-Planck (FP) equation and the Hamilton-Jacobi-Bellman (HJB) equation. Using the differential of the entropy, namely the score function, we first formulate the deterministic forward-backward characteristics for the mean field control system, which is different from the classical forward-backward stochastic differential equations (FBSDEs). We further apply the neural network approximation to fit the proposed deterministic characteristic lines. Numerical examples, including the control problem with entropy potential energy, the linear quadratic regulator, and the systemic risks, demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09547v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo Zhou, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Hybrid optimal control with mixed-integer Lagrangian methods</title>
      <link>https://arxiv.org/abs/2403.06842</link>
      <description>arXiv:2403.06842v3 Announce Type: replace 
Abstract: Models involving hybrid systems are versatile in their application but difficult to optimize efficiently due to their combinatorial nature. This work presents a method to cope with hybrid optimal control problems which, in contrast to decomposition techniques, does not require relaxing the integrality constraints. Based on the discretize-then-optimize approach, our scheme addresses mixed-integer nonlinear problems under mild assumptions. The proposed numerical algorithm builds upon the augmented Lagrangian framework, whose subproblems are handled using successive mixed-integer linearizations with trust regions. We validate the performance of the numerical routine with extensive investigations using hybrid optimal control problems from different fields of application. Promising preliminary results are presented for a motion planning task with hysteresis and a Lotka-Volterra fishing problem with total variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06842v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktoriya Nikitina, Alberto De Marchi, Matthias Gerdts</dc:creator>
    </item>
    <item>
      <title>Nonlinear integral extension of PID control with improved convergence of perturbed second-order dynamic systems</title>
      <link>https://arxiv.org/abs/2404.02502</link>
      <description>arXiv:2404.02502v3 Announce Type: replace 
Abstract: Nonlinear extension of the integral part of a standard proportional-integral-derivative (PID) feedback control is proposed for perturbed second-order systems. The approach is model-free and requires solely the Lipschitz boundedness of the unknown matched perturbations. For constant disturbances, the global asymptotic stability is shown based on the circle criterion. For Lipschitz perturbations, an ultimately bounded output error is provided based on the steady-state behavior in frequency domain. Also the transient response to the stepwise disturbances is analyzed for the control tuning. Based on the developed analysis, the design recommendations are formulated as a step by step procedure. It is also discussed how the proposed control is applicable to second-order systems extended by additional (parasitic) actuator dynamics with low-pass characteristics. The proposed nonlinear control is proven to outperform its linear PID counterpart during the settling phase, i.e. at convergence of the residual output error. An experimental case study of the second-order system with an additional actuator dynamics and considerable perturbations is demonstrated to confirm and benchmark the control performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02502v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman</dc:creator>
    </item>
    <item>
      <title>Flexible-step MPC for Switched Linear Systems with No Quadratic Common Lyapunov Function</title>
      <link>https://arxiv.org/abs/2404.07870</link>
      <description>arXiv:2404.07870v2 Announce Type: replace 
Abstract: In this paper, we develop a systematic method for constructing a generalized discrete-time control Lyapunov function for the flexible-step Model Predictive Control (MPC) scheme, recently introduced in [2], when restricted to the class of linear systems. Specifically, we show that a set of Linear Matrix Inequalities (LMIs) can be used for this purpose, demonstrating its tractability. The main consequence of this LMI formulation is that, when combined with flexible-step MPC, we can effectively stabilize switched control systems, for which no quadratic common Lyapunov function exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07870v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annika F\"urnsinn, Christian Ebenbauer, Bahman Gharesifard</dc:creator>
    </item>
    <item>
      <title>A Symplectic Analysis of Alternating Mirror Descent</title>
      <link>https://arxiv.org/abs/2405.03472</link>
      <description>arXiv:2405.03472v3 Announce Type: replace 
Abstract: Motivated by understanding the behavior of the Alternating Mirror Descent (AMD) algorithm for bilinear zero-sum games, we study the discretization of continuous-time Hamiltonian flow via the symplectic Euler method. We provide a framework for analysis using results from Hamiltonian dynamics, Lie algebra, and symplectic numerical integrators, with an emphasis on the existence and properties of a conserved quantity, the modified Hamiltonian (MH), for the symplectic Euler method. We compute the MH in closed-form when the original Hamiltonian is a quadratic function, and show that it generally differs from the other conserved quantity known previously in that case. We derive new error bounds on the MH when truncated at orders in the stepsize in terms of the number of iterations, $K$, and use these bounds to show an improved $\mathcal{O}(K^{1/5})$ total regret bound and an $\mathcal{O}(K^{-4/5})$ duality gap of the average iterates for AMD. Finally, we propose a conjecture which, if true, would imply that the total regret for AMD scales as $\mathcal{O}\left(K^{\varepsilon}\right)$ and the duality gap of the average iterates as $\mathcal{O}\left(K^{-1+\varepsilon}\right)$ for any $\varepsilon&gt;0$, and we can take $\varepsilon=0$ upon certain convergence conditions for the MH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03472v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Katona, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Extended mean-field control problems with Poissonian common noise: Stochastic maximum principle and Hamiltonian-Jacobi-Bellman equation</title>
      <link>https://arxiv.org/abs/2407.05356</link>
      <description>arXiv:2407.05356v2 Announce Type: replace 
Abstract: This paper studies mean-field control problems with state-control joint law dependence and Poissonian common noise. We develop the stochastic maximum principle (SMP) and establish its connection to the Hamiltonian-Jacobi-Bellman (HJB) equation on the Wasserstein space. The presence of the conditional joint law in the McKean-Vlasov dynamics and its discontinuity caused by the Poissonian common noise bring new technical challenges. To develop the SMP when the control domain is not necessarily convex, we first consider a strong relaxed control formulation that allows us to perform the first-order variation. We propose the technique of extension transformation to overcome the compatibility issues arising from the joint law in the relaxed control formulation. By further establishing the equivalence between the relaxed control and the strict control formulations, we obtain the SMP for the original problem with strict controls. In the part to investigate the HJB equation, we formulate an auxiliary control problem subjecting to a controlled measure-valued dynamics with Poisson jumps, which allows us to derive the HJB equation of the original problem under the open-loop strict control by some newly established equivalence formulations. We also establish the connection between the SMP and the HJB equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05356v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiaoli Wei, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Two-Player Zero-Sum Hybrid Games</title>
      <link>https://arxiv.org/abs/2407.10107</link>
      <description>arXiv:2407.10107v3 Announce Type: replace 
Abstract: In this paper, we formulate a two-player zero-sum game under dynamic constraints defined by hybrid dynamical equations. The game consists of a min-max problem involving a cost functional that depends on the actions and resulting solutions to the hybrid system, defined as functions of hybrid time and, hence, can flow or jump. A terminal set conveniently defined allows to recast both finite and infinite horizon problems. We present sufficient conditions given in terms of Hamilton-Jacobi-Bellman-Isaacs-like equations to guarantee to attain a solution to the game. It is shown that when the players select the optimal strategy, the value function can be evaluated without computing solutions to the hybrid system. Under additional conditions, we show that the optimal state-feedback laws render a set of interest asymptotically stable for the resulting hybrid closed-loop system. Applications of these games, presented here as robust control problems, include disturbance rejection and security problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10107v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Santiago J. Leudo, Ricardo G. Sanfelice</dc:creator>
    </item>
    <item>
      <title>Recursive Optimal Stopping with Poisson Stopping Constraints</title>
      <link>https://arxiv.org/abs/2407.17975</link>
      <description>arXiv:2407.17975v2 Announce Type: replace 
Abstract: This paper solves a recursive optimal stopping problem with Poisson stopping constraints using the penalized backward stochastic differential equation (PBSDE) with jumps. Stopping in this problem is only allowed at Poisson random intervention times, and jumps play a significant role not only through the stopping times but also in the recursive objective functional and model coefficients. To solve the problem, we propose a decomposition method based on Jacod-Pham that allows us to separate the problem into a series of sub-problems between each pair of consecutive Poisson stopping times. To represent the value function of the recursive optimal stopping problem when the initial time falls between two consecutive Poisson stopping times and the generator is concave/convex, we leverage the comparison theorem of BSDEs with jumps. We then apply the representation result to American option pricing in a nonlinear market with Poisson stopping constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17975v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gechun Liang, Wei Wei, Zhen Wu, Zhenda Xu</dc:creator>
    </item>
    <item>
      <title>Characterization of input-to-output stability for infinite-dimensional systems</title>
      <link>https://arxiv.org/abs/2410.06013</link>
      <description>arXiv:2410.06013v2 Announce Type: replace 
Abstract: We prove a superposition theorem for input-to-output stability (IOS) of a broad class of nonlinear infinite-dimensional systems with outputs including both continuous-time and discrete-time systems. It contains, as a special case, the superposition theorem for input-to-state stability (ISS) of infinite-dimensional systems and the IOS superposition theorem for systems of ordinary differential equations known from the literature.
  To achieve this result, we introduce and examine several novel stability and attractivity concepts for infinite-dimensional systems with outputs: We prove criteria for the uniform limit property for systems with outputs, several of which are new already for systems with full-state output, we provide superposition theorems for systems which satisfy both the output Lagrange stability (OL) and IOS, give a sufficient condition for OL and characterize ISS in terms of IOS and input/output-to-state stability. Finally, by means of counterexamples, we illustrate the challenges appearing on the way of extension of the superposition theorems from the literature to infinite-dimensional systems with outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06013v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Bachmann, Sergey Dashkovskiy, Andrii Mironchenko</dc:creator>
    </item>
    <item>
      <title>Nesterov Acceleration for Ensemble Kalman Inversion and Variants</title>
      <link>https://arxiv.org/abs/2501.08779</link>
      <description>arXiv:2501.08779v2 Announce Type: replace 
Abstract: Ensemble Kalman inversion (EKI) is a derivative-free, particle-based optimization method for solving inverse problems. It can be shown that EKI approximates a gradient flow, which allows the application of methods for accelerating gradient descent. Here, we show that Nesterov acceleration is effective in speeding up the reduction of the EKI cost function on a variety of inverse problems. We also implement Nesterov acceleration for two EKI variants, unscented Kalman inversion and ensemble transform Kalman inversion. Our specific implementation takes the form of a particle-level nudge that is demonstrably simple to couple in a black-box fashion with any existing EKI variant algorithms, comes with no additional computational expense, and with no additional tuning hyperparameters. This work shows a pathway for future research to translate advances in gradient-based optimization into advances in gradient-free Kalman optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08779v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sydney Vernon, Eviatar Bach, Oliver R. A. Dunbar</dc:creator>
    </item>
    <item>
      <title>A note on the Cucker-Smale model with time delay and communication failures</title>
      <link>https://arxiv.org/abs/2501.17743</link>
      <description>arXiv:2501.17743v2 Announce Type: replace 
Abstract: In this paper, we deal with a Cucker-Smale model with time-dependent time delay and communication failures. Namely, we investigate the situation in which the agents involved in a flocking process can possibly suspend the exchange of information among themselves at some times. Under a so-called Persistence Excitation Condition, we establish the exponential flocking for the considered model. The exponential decay estimates on the velocity diameters we obtain are independent of the number of agents, which is convenient especially when the number of agents becomes too large. Exponential decay estimates with decay rate depending on the number of agents appear instead in the case of pair-dependent time delays and non-universal interaction, i.e. not all the agents are able to exchange information among themselves. In this paper, we rather consider a universal interaction and the time delay functions do not depend on the pair of agents. The analysis is then extended to a model with distributed time delay, namely the time delay is not pointwise but the agents are influenced by the information received from the other components of the system in a certain time interval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17743v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisa Continelli</dc:creator>
    </item>
    <item>
      <title>Adaptive Extrapolated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization</title>
      <link>https://arxiv.org/abs/2502.21099</link>
      <description>arXiv:2502.21099v2 Announce Type: replace 
Abstract: This paper proposes {\sf AEPG-SPIDER}, an Adaptive Extrapolated Proximal Gradient (AEPG) method with variance reduction for minimizing composite nonconvex finite-sum functions. It integrates three acceleration techniques: adaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic path-integrated estimator SPIDER. Unlike existing methods that adjust the stepsize factor using historical gradients, {\sf AEPG-SPIDER} relies on past iterate differences for its update. While targeting stochastic finite-sum problems, {\sf AEPG-SPIDER} simplifies to {\sf AEPG} in the full-batch, non-stochastic setting, which is also of independent interest. To our knowledge, {\sf AEPG-SPIDER} and {\sf AEPG} are the first Lipschitz-free methods to achieve optimal iteration complexity for this class of \textit{composite} minimization problems. Specifically, {\sf AEPG} achieves the optimal iteration complexity of $\mathcal{O}(N \epsilon^{-2})$, while {\sf AEPG-SPIDER} achieves $\mathcal{O}(N + \sqrt{N} \epsilon^{-2})$ for finding $\epsilon$-approximate stationary points, where $N$ is the number of component functions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish non-ergodic convergence rates for both methods. Preliminary experiments on sparse phase retrieval and linear eigenvalue problems demonstrate the superior performance of {\sf AEPG-SPIDER} and {\sf AEPG} compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21099v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Value-Oriented Forecast Combinations for Unit Commitment</title>
      <link>https://arxiv.org/abs/2503.13677</link>
      <description>arXiv:2503.13677v2 Announce Type: replace 
Abstract: Value-oriented forecasts for two-stage power system operational problems have been demonstrated to reduce cost, but prove to be computationally challenging for large-scale systems because the underlying optimization problem must be internalized into the forecast model training. Therefore, existing approaches typically scale poorly in the usable training data or require relaxations of the underlying optimization. This paper presents a method for value-oriented forecast combinations using progressive hedging, which unlocks high-fidelity, at-scale models and large-scale datasets in training. We also derive one-shot training model for reference and study how different modifications of the training model impact the solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13677v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehrnoush Ghazanfariharandi, Robert Mieth</dc:creator>
    </item>
    <item>
      <title>Approximation of diffeomorphisms for quantum state transfers</title>
      <link>https://arxiv.org/abs/2503.14450</link>
      <description>arXiv:2503.14450v3 Announce Type: replace 
Abstract: In this paper, we seek to combine two emerging standpoints in control theory. On the one hand, recent advances in infinite-dimensional geometric control have unlocked a method for controlling (with arbitrary precision and in arbitrarily small times) state transfers for bilinear Schr\"odinger PDEs posed on a Riemannian manifold $M$. In particular, these arguments rely on controllability results in the group of the diffeomorphisms of $M$. On the other hand, using tools of $\Gamma$-convergence, it has been proved that we can phrase the retrieval of a diffeomorphism of $M$ as an ensemble optimal control problem. More precisely, this is done by employing a control-affine system for \emph{simultaneously} steering a finite swarm of points towards the respective targets. Here we blend these two theoretical approaches and numerically find control laws driving state transitions (such as eigenstate transfers) in small time in a bilinear Schr\"odinger PDE posed on the torus. Such systems have experimental relevance and are currently used to model rotational dynamics of molecules, and cold atoms trapped in periodic optical lattices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14450v3</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenio Pozzoli, Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>DualMS: Implicit Dual-Channel Minimal Surface Optimization for Heat Exchanger Design</title>
      <link>https://arxiv.org/abs/2504.02830</link>
      <description>arXiv:2504.02830v2 Announce Type: replace 
Abstract: Heat exchangers are critical components in a wide range of engineering applications, from energy systems to chemical processing, where efficient thermal management is essential. The design objectives for heat exchangers include maximizing the heat exchange rate while minimizing the pressure drop, requiring both a large interface area and a smooth internal structure. State-of-the-art designs, such as triply periodic minimal surfaces (TPMS), have proven effective in optimizing heat exchange efficiency. However, TPMS designs are constrained by predefined mathematical equations, limiting their adaptability to freeform boundary shapes. Additionally, TPMS structures do not inherently control flow directions, which can lead to flow stagnation and undesirable pressure drops.
  This paper presents DualMS, a novel computational framework for optimizing dual-channel minimal surfaces specifically for heat exchanger designs in freeform shapes. To the best of our knowledge, this is the first attempt to directly optimize minimal surfaces for two-fluid heat exchangers, rather than relying on TPMS. Our approach formulates the heat exchange maximization problem as a constrained connected maximum cut problem on a graph, with flow constraints guiding the optimization process. To address undesirable pressure drops, we model the minimal surface as a classification boundary separating the two fluids, incorporating an additional regularization term for area minimization. We employ a neural network that maps spatial points to binary flow types, enabling it to classify flow skeletons and automatically determine the surface boundary. DualMS demonstrates greater flexibility in surface topology compared to TPMS and achieves superior thermal performance, with lower pressure drops while maintaining a similar heat exchange rate under the same material cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02830v2</guid>
      <category>math.OC</category>
      <category>cs.GR</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3721238.3730700</arxiv:DOI>
      <dc:creator>Weizheng Zhang, Hao Pan, Lin Lu, Xiaowei Duan, Xin Yan, Ruonan Wang, Qiang Du</dc:creator>
    </item>
    <item>
      <title>Distributed Solving of Linear Quadratic Optimal Controller with Terminal State Constraint</title>
      <link>https://arxiv.org/abs/2504.05631</link>
      <description>arXiv:2504.05631v3 Announce Type: replace 
Abstract: This paper is concerned with the linear quadratic (LQ) optimal control of continuous-time system with terminal state constraint. In particular, multiple agents exist in the system which can only access partial information of the matrix parameters. This makes the classical solving method based on Riccati equation with global information suffering. The main contribution is to present a distributed algorithm to derive the optimal controller which is consisting of the distributed iterations for the Riccati equation, a backward differential equation driven by the optimal Lagrange multiplier and the optimal state. The effectiveness of the proposed algorithm is verified by two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05631v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjing Yang, Juanjuan Xu</dc:creator>
    </item>
    <item>
      <title>Null controllability of damped nonlinear wave equation</title>
      <link>https://arxiv.org/abs/2211.15449</link>
      <description>arXiv:2211.15449v3 Announce Type: replace-cross 
Abstract: In this paper, we investigate the null controllability of nonlinear wave systems. Initially, we employ a combination of the Galerkin method and a fixed point theorem to establish the null controllability for semi-linear wave equations with nonlinear functions that are dependent on velocities, under the geometric control condition. Subsequently, utilizing a novel iterative method, we demonstrate the null controllability for a class of quasi-linear wave systems in a constructive manner. Lastly, we present a control result for a class of fully nonlinear wave systems, serving as an application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.15449v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yan Cui, Peng Lu, Yi Zhou</dc:creator>
    </item>
    <item>
      <title>Symmetric Solutions to Symmetric Partial Difference Equations</title>
      <link>https://arxiv.org/abs/2310.00903</link>
      <description>arXiv:2310.00903v3 Announce Type: replace-cross 
Abstract: This paper studies systems of linear difference equations on the lattice $\Z^n$ that are invariant under a finite group of symmetries, and shows that there exist solutions to such systems that are also invariant under this group of symmetries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00903v3</guid>
      <category>math.CA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/10236198.2024.2428380</arxiv:DOI>
      <arxiv:journal_reference>Symmetric Solutions to Symmetric Partial Difference Equations, Journal of Dfference Equations and Applications, 31:3, 406-417, 2025</arxiv:journal_reference>
      <dc:creator>Shiva Shankar</dc:creator>
    </item>
    <item>
      <title>A Cyclic Small Phase Theorem</title>
      <link>https://arxiv.org/abs/2312.00956</link>
      <description>arXiv:2312.00956v2 Announce Type: replace-cross 
Abstract: This paper introduces a brand-new phase definition called the segmental phase for multi-input multi-output linear time-invariant systems. The underpinning of the definition lies in the matrix segmental phase which, as its name implies, is graphically based on the smallest circular segment covering the matrix normalized numerical range in the unit disk. The matrix segmental phase has the crucial product eigen-phase bound, which makes itself stand out from several existing phase notions in the literature. The proposed bound paves the way for stability analysis of a single-loop cyclic feedback system consisting of multiple subsystems. A cyclic small phase theorem is then established as our main result, which requires the loop system phase to lie between $-\pi$ and $\pi$. The proposed theorem complements a cyclic version of the celebrated small gain theorem. In addition, a generalization of the proposed theorem is made via the use of angular scaling techniques for reducing conservatism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00956v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Chen, Wei Chen, Di Zhao, Jianqi Chen, Li Qiu</dc:creator>
    </item>
    <item>
      <title>ATE-SG: Alternate Through the Epochs Stochastic Gradient for Multi-Task Neural Networks</title>
      <link>https://arxiv.org/abs/2312.16340</link>
      <description>arXiv:2312.16340v2 Announce Type: replace-cross 
Abstract: This paper introduces novel alternate training procedures for hard-parameter sharing Multi-Task Neural Networks (MTNNs). Traditional MTNN training faces challenges in managing conflicting loss gradients, often yielding sub-optimal performance. The proposed alternate training method updates shared and task-specific weights alternately through the epochs, exploiting the multi-head architecture of the model. This approach reduces computational costs per epoch and memory requirements. Convergence properties similar to those of the classical stochastic gradient method are established. Empirical experiments demonstrate enhanced training regularization and reduced computational demands. In summary, our alternate training procedures offer a promising advancement for the training of hard-parameter sharing MTNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16340v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Francesco Della Santa, Alessandra Papini</dc:creator>
    </item>
    <item>
      <title>Economic Capacity Withholding Bounds of Competitive Energy Storage Bidders</title>
      <link>https://arxiv.org/abs/2403.05705</link>
      <description>arXiv:2403.05705v2 Announce Type: replace-cross 
Abstract: Economic withholding in electricity markets refers to generators bidding higher than their true marginal fuel cost, and is a typical approach to exercising market power. However, existing market designs require storage to design bids strategically based on their own future price predictions, motivating storage to conduct economic withholding without assuming market power. As energy storage takes up more significant roles in wholesale electricity markets, understanding its motivations for economic withholding and the consequent effects on social welfare becomes increasingly vital. This paper derives a theoretical framework to study the economic capacity withholding behavior of storage participating in competitive electricity markets and validate our results in simulations based on the ISO New England system. We demonstrate that storage bids can reach unbounded high levels under conditions where future price predictions show bounded expectations but unbounded deviations. Conversely, in scenarios with peak price limitations, we show the upper bounds of storage bids are grounded in bounded price expectations. Most importantly, we show that storage capacity withholding can potentially lower the overall system cost when price models account for system uncertainties. Our paper reveals energy storage is not a market manipulator but an honest player contributing to the social welfare. It helps electricity market researchers and operators better understand the economic withholding behavior of storage and reform market policies to maximize storage contributing to a cost-efficient decolonization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05705v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Qin, Ioannis Lestas, Bolun Xu</dc:creator>
    </item>
    <item>
      <title>Learning to Cover: Online Learning and Optimization with Irreversible Decisions</title>
      <link>https://arxiv.org/abs/2406.14777</link>
      <description>arXiv:2406.14777v2 Announce Type: replace-cross 
Abstract: We define an online learning and optimization problem with discrete and irreversible decisions contributing toward a coverage target. In each period, a decision-maker selects facilities to open, receives information on the success of each one, and updates a classification model to guide future decisions. The goal is to minimize facility openings under a chance constraint reflecting the coverage target, in an asymptotic regime characterized by a large target number of facilities $m\to\infty$ but a finite horizon $T \in \mathcal{Z}_+$. We prove that, under statistical conditions, the online classifier converges to the Bayes-optimal classifier at a rate of at best $\mathcal{O}(1/\sqrt n)$. Thus, we formulate our online learning and optimization problem, with a generalized learning rate $r&gt;0$ and a residual error $1-p$. We derive an asymptotically optimal algorithm and an asymptotically tight lower bound. The regret grows in $\Theta\left(m^{\frac{1-r}{1-r^T}}\right)$ if $p=1$ (perfect learning) or in $\Theta\left(\max\left\{m^{\frac{1-r}{1-r^T}},\sqrt{m}\right\}\right)$ otherwise; in particular, the regret rate is sub-linear and converges exponentially fast to its infinite-horizon limit. We extend this result to a more complicated facility location setting in a bipartite facility-customer graph with a target on customer coverage. Throughout, constructive proofs identify a policy featuring limited exploration initially and fast exploitation later on once uncertainty gets mitigated. These results uncover the benefits of limited online learning and optimization through pilot programs prior to full-fledged expansion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14777v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Jacquillat, Michael Lingzhi Li</dc:creator>
    </item>
    <item>
      <title>Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies</title>
      <link>https://arxiv.org/abs/2410.03968</link>
      <description>arXiv:2410.03968v3 Announce Type: replace-cross 
Abstract: Decoding strategies play a pivotal role in text generation for modern language models, yet a puzzling gap divides theory and practice. Surprisingly, strategies that should intuitively be optimal, such as Maximum a Posteriori (MAP), often perform poorly in practice. Meanwhile, popular heuristic approaches like Top-$k$ and Nucleus sampling, which employ truncation and normalization of the conditional next-token probabilities, have achieved great empirical success but lack theoretical justifications. In this paper, we propose Decoding Game, a comprehensive theoretical framework which reimagines text generation as a two-player zero-sum game between Strategist, who seeks to produce text credible in the true distribution, and Nature, who distorts the true distribution adversarially. After discussing the decomposibility of multi-step generation, we derive the optimal strategy in closed form for one-step Decoding Game. It is shown that the adversarial Nature imposes an implicit regularization on likelihood maximization, and truncation-normalization methods are first-order approximations to the optimal strategy under this regularization. Additionally, by generalizing the objective and parameters of Decoding Game, near-optimal strategies encompass diverse methods such as greedy search, temperature scaling, and hybrids thereof. Numerical experiments are conducted to complement our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03968v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sijin Chen, Omar Hagrass, Jason M. Klusowski</dc:creator>
    </item>
    <item>
      <title>Learning Provably Improves the Convergence of Gradient Descent</title>
      <link>https://arxiv.org/abs/2501.18092</link>
      <description>arXiv:2501.18092v3 Announce Type: replace-cross 
Abstract: Learn to Optimize (L2O) trains deep neural network based solvers for optimization, achieving success in accelerating convex problems and improving non-convex solutions. However, L2O lacks rigorous theoretical backing for its own training convergence, as existing analyses often use unrealistic assumptions -- a gap this work highlights empirically. We bridge this gap by proving the training convergence of L2O models that learn Gradient Descent (GD) hyperparameters for quadratic programming, leveraging the Neural Tangent Kernel (NTK) theory. We propose a deterministic initialization strategy to support our theoretical results and promote stable training over extended optimization horizons by mitigating gradient explosion. Our L2O framework demonstrates over 50\% better optimality against GD and superior robustness over state-of-the-art L2O methods on synthetic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18092v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingyu Song, Wei Lin, Hong Xu</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Spectral Descent and Muon on Multiclass Separable Data</title>
      <link>https://arxiv.org/abs/2502.04664</link>
      <description>arXiv:2502.04664v3 Announce Type: replace-cross 
Abstract: Different gradient-based methods for optimizing overparameterized models can all achieve zero training error yet converge to distinctly different solutions inducing different generalization properties. We provide the first complete characterization of implicit optimization bias for p-norm normalized steepest descent (NSD) and momentum steepest descent (NMD) algorithms in multi-class linear classification with cross-entropy loss. Our key theoretical contribution is proving that these algorithms converge to solutions maximizing the margin with respect to the classifier matrix's p-norm, with established convergence rates. These results encompass important special cases including Spectral Descent and Muon, which we show converge to max-margin solutions with respect to the spectral norm. A key insight of our contribution is that the analysis of general entry-wise and Schatten p-norms can be reduced to the analysis of NSD/NMD with max-norm by exploiting a natural ordering property between all p-norms relative to the max-norm and its dual sum-norm. For the specific case of descent with respect to the max-norm, we further extend our analysis to include preconditioning, showing that Adam converges to the matrix's max-norm solution. Our results demonstrate that the multi-class linear setting, which is inherently richer than the binary counterpart, provides the most transparent framework for studying implicit biases of matrix-parameter optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04664v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Fan, Mark Schmidt, Christos Thrampoulidis</dc:creator>
    </item>
    <item>
      <title>Projection-based Lyapunov method for fully heterogeneous weakly-coupled MDPs</title>
      <link>https://arxiv.org/abs/2502.06072</link>
      <description>arXiv:2502.06072v3 Announce Type: replace-cross 
Abstract: Heterogeneity poses a fundamental challenge for many real-world large-scale decision-making problems but remains largely understudied. In this paper, we study the fully heterogeneous setting of a prominent class of such problems, known as weakly-coupled Markov decision processes (WCMDPs). Each WCMDP consists of $N$ arms (or subproblems), which have distinct model parameters in the fully heterogeneous setting, leading to the curse of dimensionality when $N$ is large. We show that, under mild assumptions, an efficiently computable policy achieves an $O(1/\sqrt{N})$ optimality gap in the long-run average reward per arm for fully heterogeneous WCMDPs as $N$ becomes large. This is the first asymptotic optimality result for fully heterogeneous average-reward WCMDPs. Our main technical innovation is the construction of projection-based Lyapunov functions that certify the convergence of rewards and costs to an optimal region, even under full heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06072v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangcheng Zhang, Yige Hong, Weina Wang</dc:creator>
    </item>
    <item>
      <title>Locational Energy Storage Bid Bounds for Facilitating Social Welfare Convergence</title>
      <link>https://arxiv.org/abs/2502.18598</link>
      <description>arXiv:2502.18598v2 Announce Type: replace-cross 
Abstract: This paper proposes a novel method to generate bid bounds that can serve as offer caps for energy storage in electricity markets to help reduce system costs and regulate potential market power exercises. We derive the bid bounds based on a tractable multi-period economic dispatch chance-constrained formulation that systematically incorporates the uncertainty and risk preference of the system operator. The key analytical results verify that the bounds effectively cap storage bids across all uncertainty scenarios with a guaranteed confidence level. We show that bid bounds decrease as the state of charge increases but rise with greater netload uncertainty and risk preference. We test the effectiveness of the proposed pricing mechanism based on the 8-bus ISO-NE test system, including agent-based storage bidding models. Simulation results demonstrate that the proposed bid bounds effectively align storage bids with the social welfare objective and outperform existing deterministic bid bounds. Under 30% renewable capacity and 20% storage capacity, the bid bounds contribute to an average reduction of 0.17\% in system cost, while increasing storage profit by an average of 10.16% across various system uncertainty scenarios and bidding strategies. These benefits scale up with increased storage economic withholding and storage capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18598v2</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ning Qi, Bolun Xu</dc:creator>
    </item>
    <item>
      <title>Control, Optimal Transport and Neural Differential Equations in Supervised Learning</title>
      <link>https://arxiv.org/abs/2503.15105</link>
      <description>arXiv:2503.15105v3 Announce Type: replace-cross 
Abstract: We study the fundamental computational problem of approximating optimal transport (OT) equations using neural differential equations (Neural ODEs). More specifically, we develop a novel framework for approximating unbalanced optimal transport (UOT) in the continuum using Neural ODEs. By generalizing a discrete UOT problem with Pearson divergence, we constructively design vector fields for Neural ODEs that converge to the true UOT dynamics, thereby advancing the mathematical foundations of computational transport and machine learning. To this end, we design a numerical scheme inspired by the Sinkhorn algorithm to solve the corresponding minimization problem and rigorously prove its convergence, providing explicit error estimates. From the obtained numerical solutions, we derive vector fields defining the transport dynamics and construct the corresponding transport equation.
  Finally, from the numerically obtained transport equation, we construct a neural differential equation whose flow converges to the true transport dynamics in an appropriate limiting regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15105v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh-Nhat Phung, Minh-Binh Tran</dc:creator>
    </item>
    <item>
      <title>Stochastic Multigrid Minimization for Ptychographic Phase Retrieval</title>
      <link>https://arxiv.org/abs/2504.10118</link>
      <description>arXiv:2504.10118v2 Announce Type: replace-cross 
Abstract: We propose a novel stochastic multigrid minimization method for ptychographic phase retrieval. In our formulation, the challenging nonconvex and ill-posed inverse problem is recast as the iterative minimization of a quadratic surrogate model that majorizes the original objective function. Our general framework encompasses the Ptychographic Iterative Engine (PIE) family of algorithms. By efficiently solving the surrogate problem using a multigrid method, our approach delivers significant improvements in both convergence speed and reconstruction quality compared with conventional PIE techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10118v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borong Zhang, Qin Li, Zichao Wendy Di</dc:creator>
    </item>
    <item>
      <title>Certifying Stability of Reinforcement Learning Policies using Generalized Lyapunov Functions</title>
      <link>https://arxiv.org/abs/2505.10947</link>
      <description>arXiv:2505.10947v2 Announce Type: replace-cross 
Abstract: We study the problem of certifying the stability of closed-loop systems under control policies derived from optimal control or reinforcement learning (RL). Classical Lyapunov methods require a strict step-wise decrease in the Lyapunov function but such a certificate is difficult to construct for a learned control policy. The value function associated with an RL policy is a natural Lyapunov function candidate but it is not clear how it should be modified. To gain intuition, we first study the linear quadratic regulator (LQR) problem and make two key observations. First, a Lyapunov function can be obtained from the value function of an LQR policy by augmenting it with a residual term related to the system dynamics and stage cost. Second, the classical Lyapunov decrease requirement can be relaxed to a generalized Lyapunov condition requiring only decrease on average over multiple time steps. Using this intuition, we consider the nonlinear setting and formulate an approach to learn generalized Lyapunov functions by augmenting RL value functions with neural network residual terms. Our approach successfully certifies the stability of RL policies trained on Gymnasium and DeepMind Control benchmarks. We also extend our method to jointly train neural controllers and stability certificates using a multi-step Lyapunov loss, resulting in larger certified inner approximations of the region of attraction compared to the classical Lyapunov approach. Overall, our formulation enables stability certification for a broad class of systems with learned policies by making certificates easier to construct, thereby bridging classical control theory and modern learning-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10947v2</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehan Long, Jorge Cort\'es, Nikolay Atanasov</dc:creator>
    </item>
  </channel>
</rss>
