<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Low Dimensional Dynamics of Globally Coupled Complex Riccati Equations: Exact Firing-rate Equations for Spiking Neurons with Clustered Substructure</title>
      <link>https://arxiv.org/abs/2503.15537</link>
      <description>arXiv:2503.15537v1 Announce Type: new 
Abstract: We report on an exact theory for ensembles of globally coupled, heterogeneous complex Riccati equations. A drastic dimensionality reduction to a few ordinary differential equations is achieved for Lorentzian heterogeneity. By applying this technique, we obtain low-dimensional firing-rate equations for populations of spiking neurons with a clustered substructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15537v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.SI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Paz\'o, Rok Cestnik</dc:creator>
    </item>
    <item>
      <title>There must be encapsulated nonconceptual content in vision</title>
      <link>https://arxiv.org/abs/2503.15538</link>
      <description>arXiv:2503.15538v1 Announce Type: new 
Abstract: In this paper I want to propose an argument to support Jerry Fodor's thesis (Fodor 1983) that input systems are modular and thus informationally encapsulated. The argument starts with the suggestion that there is a "grounding problem" in perception, i. e. that there is a problem in explaining how perception that can yield a visual experience is possible, how sensation can become meaningful perception of something for the subject. Given that visual experience is actually possible, this invites a transcendental argument that explains the conditions of its possibility. I propose that one of these conditions is the existence of a visual module in Fodor's sense that allows the step from sensation to object-identifying perception, thus enabling visual experience. It seems to follow that there is informationally encapsulated nonconceptual content in visual perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15538v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>(2005) in Athanassios Raftopoulos (ed.), Cognitive penetrability of perception: Attention, action, attention and bottom-up constraints (Huntington: Nova Science), 157-70</arxiv:journal_reference>
      <dc:creator>Vincent C. M\"uller</dc:creator>
    </item>
    <item>
      <title>Implantable CMOS probes for high resolution Electrical Imaging of Local Field Potentials Across the Rat Barrel Cortex in vivo</title>
      <link>https://arxiv.org/abs/2503.15663</link>
      <description>arXiv:2503.15663v1 Announce Type: new 
Abstract: High-resolution recordings of extracellular potentials are fundamental for the study of neuronal networks, the basis of neuronal coding and transmission. Here we present an innovative method for an in vivo electrical imaging of Local Field Potentials using novel implantable neural interfaces with a high-density array of 256 recording sites and a spatial resolution of 15 {\mu}m. Thanks to this technology, we analyze the propagation of whisker-evoked activity in a single barrel-column of the rat somatosensory cortex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15663v1</guid>
      <category>q-bio.NC</category>
      <category>physics.ins-det</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudia Cecchetto, Mufti Mahmud, Vincenzo Sorrenti, Marta Maschietto, Enrico Chiarello, Mathias Schulz, Roland Thewes, Stefano Vassanelli</dc:creator>
    </item>
    <item>
      <title>Allostatic Control of Persistent States in Spiking Neural Networks for perception and computation</title>
      <link>https://arxiv.org/abs/2503.16085</link>
      <description>arXiv:2503.16085v1 Announce Type: new 
Abstract: We introduce a novel model for updating perceptual beliefs about the environment by extending the concept of Allostasis to the control of internal representations. Allostasis is a fundamental regulatory mechanism observed in animal physiology that orchestrates responses to maintain a dynamic equilibrium in bodily needs and internal states. In this paper, we focus on an application in numerical cognition, where a bump of activity in an attractor network is used as a spatial numerical representation. While existing neural networks can maintain persistent states, to date, there is no unified framework for dynamically controlling spatial changes in neuronal activity in response to environmental changes. To address this, we couple a well known allostatic microcircuit, the Hammel model, with a ring attractor, resulting in a Spiking Neural Network architecture that can modulate the location of the bump as a function of some reference input. This localized activity in turn is used as a perceptual belief in a simulated subitization task a quick enumeration process without counting. We provide a general procedure to fine-tune the model and demonstrate the successful control of the bump location. We also study the response time in the model with respect to changes in parameters and compare it with biological data. Finally, we analyze the dynamics of the network to understand the selectivity and specificity of different neurons to distinct categories present in the input. The results of this paper, particularly the mechanism for moving persistent states, are not limited to numerical cognition but can be applied to a wide range of tasks involving similar representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16085v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aung Htet, Alejandro Rodriguez Jimenez, Sarah Hamburg, Alessandro Di Nuovo</dc:creator>
    </item>
    <item>
      <title>Representational Similarity via Interpretable Visual Concepts</title>
      <link>https://arxiv.org/abs/2503.15699</link>
      <description>arXiv:2503.15699v1 Announce Type: cross 
Abstract: How do two deep neural networks differ in how they arrive at a decision? Measuring the similarity of deep networks has been a long-standing open question. Most existing methods provide a single number to measure the similarity of two networks at a given layer, but give no insight into what makes them similar or dissimilar. We introduce an interpretable representational similarity method (RSVC) to compare two networks. We use RSVC to discover shared and unique visual concepts between two models. We show that some aspects of model differences can be attributed to unique concepts discovered by one model that are not well represented in the other. Finally, we conduct extensive evaluation across different vision model architectures and training protocols to demonstrate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15699v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Neehar Kondapaneni, Oisin Mac Aodha, Pietro Perona</dc:creator>
    </item>
    <item>
      <title>Resource-rational reinforcement learning and sensorimotor causal states, and resource-rational maximiners</title>
      <link>https://arxiv.org/abs/2404.18775</link>
      <description>arXiv:2404.18775v4 Announce Type: replace 
Abstract: We propose a new computational-level objective function for theoretical biology and theoretical neuroscience that combines: reinforcement learning, the study of learning with feedback via rewards; rate-distortion theory, a branch of information theory that deals with compressing signals to retain relevant information; and computational mechanics, the study of minimal sufficient statistics of prediction also known as causal states. We highlight why this proposal is likely only an approximation, but is likely to be an interesting one, and propose a new algorithm for evaluating it to obtain the newly-coined ``reward-rate manifold''. The performance of real and artificial agents in partially observable environments can be newly benchmarked using these reward-rate manifolds. Finally, we describe experiments that can probe whether or not biological organisms are resource-rational reinforcement learners, using as an example maximin strategies, as bacteria have been shown to be approximate maximiners -- doing their best in the worst-case environment, regardless of what is actually happening.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18775v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Marzen</dc:creator>
    </item>
    <item>
      <title>Hierarchical feature extraction on functional brain networks for autism spectrum disorder identification with resting-state fMRI data</title>
      <link>https://arxiv.org/abs/2412.02424</link>
      <description>arXiv:2412.02424v2 Announce Type: replace 
Abstract: Autism Spectrum Disorder (ASD) is a pervasive developmental disorder of the central nervous system, primarily manifesting in childhood. It is characterized by atypical and repetitive behaviors. Currently, diagnostic methods mainly rely on questionnaire surveys and behavioral observations, which are prone to misdiagnosis due to their subjective nature. With advancements in medical imaging, MR imaging-based diagnostics have emerged as a more objective alternative. In this paper, we propose a Hierarchical Neural Network model for ASD identification, termed ASD-HNet, which hierarchically extracts features from functional brain networks based on resting-state functional magnetic resonance imaging (rs-fMRI) data. This hierarchical approach enhances the extraction of brain representations, improving diagnostic accuracy and aiding in the identification of brain regions associated with ASD. Specifically, features are extracted at three levels: (1) the local region of interest (ROI) scale, (2) the community scale, and (3) the global representation scale. At the ROI scale, graph convolution is employed to transfer features between ROIs. At the community scale, functional gradients are introduced, and a K-Means clustering algorithm is applied to group ROIs with similar functional gradients into communities. Features from ROIs within the same community are then extracted to characterize the communities. At the global representation scale, we extract global features from the whole community-scale brain networks to represent the entire brain. We validate the effectiveness of our method using the publicly available Autism Brain Imaging Data Exchange I (ABIDE-I) dataset. Experimental results demonstrate that ASD-HNet outperforms existing methods. The code is available at https://github.com/LYQbyte/ASD-HNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02424v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqian Luo, Qiurong Chen, Fali Li, Liang Yi, Peng Xu, Yangsong Zhang</dc:creator>
    </item>
    <item>
      <title>A comprehensive and reliable protocol for manual segmentation of the human claustrum using high-resolution MRI</title>
      <link>https://arxiv.org/abs/2503.01761</link>
      <description>arXiv:2503.01761v2 Announce Type: replace 
Abstract: The claustrum is a thin gray matter structure in each brain hemisphere, characterized by exceptionally high connectivity with nearly all brain regions. Despite extensive animal studies on its anatomy and function and growing evidence of claustral deficits in neuropsychiatric disorders, its specific roles in normal and abnormal human brain function remain largely unknown. This is primarily due to its thin and complex morphology, which limits accurate anatomical delineation and neural activity isolation in conventional in vivo neuroimaging. To facilitate future neuroimaging studies, we developed a comprehensive and reliable manual segmentation protocol based on a cellular-resolution brain atlas and high-resolution (0.7^3 mm) MRI data. The protocols involve detailed guidelines to delineate the entire claustrum, including the inferior parts that have not been clearly described in earlier MRI studies. Additionally, we propose a geometric method to parcellate the claustrum into three subregions (the dorsal, ventral, and temporal claustrum) along the superior-to-inferior axis. The mean bilateral claustrum volume in 10 young adults was 3307.5 mm^3, approximately 0.21% of total intracranial volume. Our segmentation protocol demonstrated high inter- and intra-rater reliability (ICC &gt; 0.89, DSC &gt; 0.85), confirming its replicability. This comprehensive and reliable claustrum segmentation protocols will provide a cornerstone for future neuroimaging studies of systematic, large-scale investigations of the anatomy and the functions of the human claustrum in normal and pathological populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01761v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Seung-Suk Kang, Joseph Bodenheimer, Kayley Morris, Tracey Butler</dc:creator>
    </item>
    <item>
      <title>Functional Correspondences in the Human and Marmoset Visual Cortex During Movie Watching: Insights from Correlation, Redundancy, and Synergy</title>
      <link>https://arxiv.org/abs/2503.15218</link>
      <description>arXiv:2503.15218v2 Announce Type: replace 
Abstract: The world of beauty is deeply connected to the visual cortex, as perception often begins with vision in both humans and marmosets. Quantifying functional correspondences in the visual cortex across species can help us understand how information is processed in the primate visual cortex, while also providing deeper insights into human visual cortex functions through the study of marmosets. In this study, we measured pairwise and beyond pairwise correlation, redundancy, and synergy in movie-driven fMRI data across species. Our first key finding was that humans and marmosets exhibited significant overlaps in functional synergy. Second, we observed that the strongest functional correspondences between the human peri-entorhinal and entorhinal cortex (PeEc) and the occipitotemporal higher-level visual regions in the marmoset during movie watching reflected a functional synergistic relationship. These regions are known to correspond to face-selective areas in both species. Third, redundancy measures maintained stable high-order hubs, indicating a steady core of shared information processing, while synergy measures revealed a dynamic shift from low- to high-level visual regions as interaction increased, reflecting adaptive integration. This highlights distinct patterns of information processing across the visual hierarchy. Ultimately, our results reveal the marmoset as a compelling model for investigating visual perception, distinguished by its remarkable functional parallels to the human visual cortex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15218v2</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Ting Xu, Vince D. Calhoun</dc:creator>
    </item>
    <item>
      <title>Toward Neuronal Implementations of Delayed Optimal Control</title>
      <link>https://arxiv.org/abs/2410.02555</link>
      <description>arXiv:2410.02555v2 Announce Type: replace-cross 
Abstract: Animal sensorimotor behavior is frequently modeled using optimal controllers. However, it is unclear how the neural circuits within the animal's nervous system implement optimal controller-like behavior. In this work, we study the question of implementing a delayed linear quadratic regulator with linear dynamical "neurons" on a muscle model. We show that for any second-order controller, there are three minimal neural circuit configurations that implement the same controller. Furthermore, the firing rate characteristics of each circuit can vary drastically, even as the overall controller behavior is preserved. Along the way, we introduce concepts that bridge controller realizations to neural implementations that are compatible with known neuronal delay structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02555v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Shuang Li</dc:creator>
    </item>
    <item>
      <title>Training Large Neural Networks With Low-Dimensional Error Feedback</title>
      <link>https://arxiv.org/abs/2502.20580</link>
      <description>arXiv:2502.20580v3 Announce Type: replace-cross 
Abstract: Training deep neural networks typically relies on backpropagating high dimensional error signals a computationally intensive process with little evidence supporting its implementation in the brain. However, since most tasks involve low-dimensional outputs, we propose that low-dimensional error signals may suffice for effective learning. To test this hypothesis, we introduce a novel local learning rule based on Feedback Alignment that leverages indirect, low-dimensional error feedback to train large networks. Our method decouples the backward pass from the forward pass, enabling precise control over error signal dimensionality while maintaining high-dimensional representations. We begin with a detailed theoretical derivation for linear networks, which forms the foundation of our learning framework, and extend our approach to nonlinear, convolutional, and transformer architectures. Remarkably, we demonstrate that even minimal error dimensionality on the order of the task dimensionality can achieve performance matching that of traditional backpropagation. Furthermore, our rule enables efficient training of convolutional networks, which have previously been resistant to Feedback Alignment methods, with minimal error. This breakthrough not only paves the way toward more biologically accurate models of learning but also challenges the conventional reliance on high-dimensional gradient signals in neural network training. Our findings suggest that low-dimensional error signals can be as effective as high-dimensional ones, prompting a reevaluation of gradient-based learning in high-dimensional systems. Ultimately, our work offers a fresh perspective on neural network optimization and contributes to understanding learning mechanisms in both artificial and biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20580v3</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maher Hanut, Jonathan Kadmon</dc:creator>
    </item>
  </channel>
</rss>
