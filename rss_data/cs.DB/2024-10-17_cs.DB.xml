<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 02:16:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>GeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Dataset</title>
      <link>https://arxiv.org/abs/2410.11853</link>
      <description>arXiv:2410.11853v1 Announce Type: new 
Abstract: Analyzing individual human trajectory data helps our understanding of human mobility and finds many commercial and academic applications. There are two main approaches to accessing trajectory data for research: one involves using real-world datasets like GeoLife, while the other employs simulations to synthesize data. Real-world data provides insights from real human activities, but such data is generally sparse due to voluntary participation. Conversely, simulated data can be more comprehensive but may capture unrealistic human behavior. In this Data and Resource paper, we combine the benefit of both by leveraging the statistical features of real-world data and the comprehensiveness of simulated data. Specifically, we extract features from the real-world GeoLife dataset such as the average number of individual daily trips, average radius of gyration, and maximum and minimum trip distances. We calibrate the Pattern of Life Simulation, a realistic simulation of human mobility, to reproduce these features. Therefore, we use a genetic algorithm to calibrate the parameters of the simulation to mimic the GeoLife features. For this calibration, we simulated numerous random simulation settings, measured the similarity of generated trajectories to GeoLife, and iteratively (over many generations) combined parameter settings of trajectory datasets most similar to GeoLife. Using the calibrated simulation, we simulate large trajectory datasets that we call GeoLife+, where + denotes the Kleene Plus, indicating unlimited replication with at least one occurrence. We provide simulated GeoLife+ data with 182, 1k, and 5k over 5 years, 10k, and 50k over a year and 100k users over 6 months of simulation lifetime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11853v1</guid>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hossein Amiri, Richard Yang, Andreas Zufle</dc:creator>
    </item>
    <item>
      <title>Utilizing Spatiotemporal Data Analytics to Pinpoint Outage Location</title>
      <link>https://arxiv.org/abs/2410.12056</link>
      <description>arXiv:2410.12056v1 Announce Type: new 
Abstract: Understanding the exact fault location in the post-event analysis is the key to improving the accuracy of outage management. Unfortunately, the fault location is not generally well documented during the restoration process, creating a big challenge for post-event analysis. By utilizing various data source systems, including outage management system (OMS) data, asset geospatial information system (GIS) data, and vehicle location data, this paper creates a novel method to pinpoint the outage location accurately to create additional insights for distribution operations and performance teams during the post-event analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12056v1</guid>
      <category>cs.DB</category>
      <category>cs.CY</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Reddy Mandati, Po-Chen Chen, Vladyslav Anderson, Bishwa Sapkota, Michael Jarrell Warren, Bobby Besharati, Ankush Agarwal, Samuel Johnston III</dc:creator>
    </item>
    <item>
      <title>DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing</title>
      <link>https://arxiv.org/abs/2410.12189</link>
      <description>arXiv:2410.12189v1 Announce Type: new 
Abstract: Analyzing unstructured data, such as complex documents, has been a persistent challenge in data processing. Large Language Models (LLMs) have shown promise in this regard, leading to recent proposals for declarative frameworks for LLM-powered unstructured data processing. However, these frameworks focus on reducing cost when executing user-specified operations using LLMs, rather than improving accuracy, executing most operations as-is. This is problematic for complex tasks and data, where LLM outputs for user-defined operations are often inaccurate, even with optimized prompts.
  We present DocETL, a system that optimizes complex document processing pipelines, while accounting for LLM shortcomings. DocETL offers a declarative interface for users to define such pipelines and uses an agent-based framework to automatically optimize them, leveraging novel agent-based rewrites (that we call {\em rewrite directives}) and an optimization and evaluation framework that we introduce. We introduce {\em (i)} logical rewriting of pipelines, tailored for LLM-based tasks, {\em (ii)} an agent-guided plan evaluation mechanism that synthesizes and orchestrates task-specific validation prompts, and {\em (iii)} an optimization algorithm that efficiently finds promising plans, considering the time constraints of LLM-based plan generation and evaluation. Our evaluation on three different unstructured document analysis tasks demonstrates that DocETL finds plans with outputs that are $1.34$ to $4.6\times$ higher quality (e.g., more accurate, comprehensive) than well-engineered baselines, addressing a critical gap in existing declarative frameworks for unstructured data analysis. DocETL is open-source at \ttt{docetl.org}, and as of October 2024, has amassed over 800 GitHub Stars, with users spanning a variety of domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12189v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreya Shankar, Aditya G. Parameswaran, Eugene Wu</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility</title>
      <link>https://arxiv.org/abs/2410.12418</link>
      <description>arXiv:2410.12418v1 Announce Type: new 
Abstract: Knowledge Graphs (KGs) have recently gained relevant attention in many application domains, from healthcare to biotechnology, from logistics to finance. Financial organisations, central banks, economic research entities, and national supervision authorities apply ontological reasoning on KGs to address crucial business tasks, such as economic policymaking, banking supervision, anti-money laundering, and economic research. Reasoning allows for the generation of derived knowledge capturing complex business semantics and the set up of effective business processes. A major obstacle in KGs sharing is represented by privacy considerations since the identity of the data subjects and their sensitive or company-confidential information may be improperly exposed.
  In this paper, we propose a novel framework to enable KGs sharing while ensuring that information that should remain private is not directly released nor indirectly exposed via derived knowledge, while maintaining the embedded knowledge of the KGs to support business downstream tasks. Our approach produces a privacy-preserving synthetic KG as an augmentation of the input one via the introduction of structural anonymisation. We introduce a novel privacy measure for KGs, which considers derived knowledge and a new utility metric that captures the business semantics we want to preserve, and propose two novel anonymization algorithms. Our extensive experimental evaluation, with both synthetic graphs and real-world datasets, confirms the effectiveness of our approach achieving up to a 70% improvement in the privacy of entities compared to existing methods not specifically designed for KGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12418v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luigi Bellomarini, Costanza Catalano, Andrea Coletta, Michela Iezzi, Pierangela Samarati</dc:creator>
    </item>
    <item>
      <title>Finding Logic Bugs in Spatial Database Engines via Affine Equivalent Inputs</title>
      <link>https://arxiv.org/abs/2410.12496</link>
      <description>arXiv:2410.12496v1 Announce Type: new 
Abstract: Spatial Database Management Systems (SDBMSs) aim to store, manipulate, and retrieve spatial data. SDBMSs are employed in various modern applications, such as geographic information systems, computer-aided design tools, and location-based services. However, the presence of logic bugs in SDBMSs can lead to incorrect results, substantially undermining the reliability of these applications. Detecting logic bugs in SDBMSs is challenging due to the lack of ground truth for identifying incorrect results. In this paper, we propose an automated geometry-aware generator to generate high-quality SQL statements for SDBMSs and a novel concept named Affine Equivalent Inputs (AEI) to validate the results of SDBMSs. We implemented them as a tool named Spatter (Spatial DBMS Tester) for finding logic bugs in four popular SDBMSs: PostGIS, DuckDB Spatial, MySQL, and SQL Server. Our testing campaign detected 34 previously unknown and unique bugs in these SDBMSs, of which 30 have been confirmed, and 18 have already been fixed. Our testing efforts have been well appreciated by the developers. Experimental results demonstrate that the geometry-aware generator significantly outperforms a naive random-shape generator in detecting unique bugs, and AEI can identify 14 logic bugs in SDBMSs that were totally overlooked by previous methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12496v1</guid>
      <category>cs.DB</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3698810</arxiv:DOI>
      <dc:creator>Wenjing Deng, Qiuyang Mang, Chengyu Zhang, Manuel Rigger</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Augmented Ontology-Based Data Access for Renewable Energy Data</title>
      <link>https://arxiv.org/abs/2410.12734</link>
      <description>arXiv:2410.12734v1 Announce Type: new 
Abstract: Managing the growing data from renewable energy production plants for effective decision-making often involves leveraging Ontology-based Data Access (OBDA), a well-established approach that facilitates querying diverse data through a shared vocabulary, presented in the form of an ontology. Our work addresses one of the common problems in this context, deriving from feeding complex class hierarchies defined by such ontologies from fragmented and imbalanced (w.r.t. class labels) data sources. We introduce an innovative framework that enhances existing OBDA systems. This framework incorporates a dynamic class management approach to address hierarchical classification, leveraging machine learning. The primary objectives are to enhance system performance, extract richer insights from underrepresented data, and automate data classification beyond the typical capabilities of basic deductive reasoning at the ontological level. We experimentally validate our methodology via real-world, industrial case studies from the renewable energy sector, demonstrating the practical applicability and effectiveness of the proposed solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12734v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Calautti, Damiano Duranti, Paolo Giorgini</dc:creator>
    </item>
    <item>
      <title>From Commands to Prompts: LLM-based Semantic File System for AIOS</title>
      <link>https://arxiv.org/abs/2410.11843</link>
      <description>arXiv:2410.11843v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated significant potential in the development of intelligent applications and systems such as LLM-based agents and agent operating systems (AIOS). However, when these applications and systems interact with the underlying file system, the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based semantic file system ( LSFS ) for prompt-driven file management. Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating semantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update monitoring and summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations (e.g., CRUD, group by, join) powered by vector database. Our experiments show that LSFS offers significant improvements over traditional file systems in terms of user convenience, the diversity of supported functions, and the accuracy and efficiency of file operations. Additionally, with the integration of LLM, our system enables more intelligent file management tasks, such as content summarization and version comparison, further enhancing its capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11843v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeru Shi, Kai Mei, Mingyu Jin, Yongye Su, Chaoji Zuo, Wenyue Hua, Wujiang Xu, Yujie Ren, Zirui Liu, Mengnan Du, Dong Deng, Yongfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Table-LLM-Specialist: Language Model Specialists for Tables using Iterative Generator-Validator Fine-tuning</title>
      <link>https://arxiv.org/abs/2410.12164</link>
      <description>arXiv:2410.12164v1 Announce Type: cross 
Abstract: In this work, we propose Table-LLM-Specialist, or Table-Specialist for short, as a new self-trained fine-tuning paradigm specifically designed for table tasks. Our insight is that for each table task, there often exist two dual versions of the same task, one generative and one classification in nature. Leveraging their duality, we propose a Generator-Validator paradigm, to iteratively generate-then-validate training data from language-models, to fine-tune stronger \sys models that can specialize in a given task, without requiring manually-labeled data.
  Our extensive evaluations suggest that our Table-Specialist has (1) \textit{strong performance} on diverse table tasks over vanilla language-models -- for example, Table-Specialist fine-tuned on GPT-3.5 not only outperforms vanilla GPT-3.5, but can often match or surpass GPT-4 level quality, (2) \textit{lower cost} to deploy, because when Table-Specialist fine-tuned on GPT-3.5 achieve GPT-4 level quality, it becomes possible to deploy smaller models with lower latency and inference cost, with comparable quality, and (3) \textit{better generalizability} when evaluated across multiple benchmarks, since \sys is fine-tuned on a broad range of training data systematically generated from diverse real tables. Our code and data will be available at https://github.com/microsoft/Table-LLM-Specialist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12164v1</guid>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junjie Xing, Yeye He, Mengyu Zhou, Haoyu Dong, Shi Han, Dongmei Zhang, Surajit Chaudhuri</dc:creator>
    </item>
    <item>
      <title>KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs</title>
      <link>https://arxiv.org/abs/2410.12480</link>
      <description>arXiv:2410.12480v1 Announce Type: cross 
Abstract: Schema and entity matching tasks are crucial for data integration and management. While large language models (LLMs) have shown promising results in these tasks, they suffer from hallucinations and confusion about task instructions. In this paper, we present the Knowledge-Compliant Matching Framework (KcMF), an LLM-based approach that addresses these issues without the need for domain-specific fine-tuning. KcMF employs a pseudo-code-based task decomposition strategy to adopt task-specific natural language statements that guide LLM reasoning and reduce confusion. We also propose two mechanisms, Dataset as Knowledge (DaK) and Example as Knowledge (EaK), to build domain knowledge sets when unstructured domain knowledge is lacking. Additionally, we introduce a result-ensembling strategy to leverage multiple knowledge sources and suppress poorly formatted outputs. Comprehensive evaluations on schema and entity matching tasks demonstrate that KcMF outperforms previous non-LLM state-of-the-art (SOTA) methods by an average F1 score of 22.9% and competes effectively with SOTA fine-tuned LLMs. Moreover, KcMF generalizes well across different LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12480v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongqin Xu, Huan Li, Ke Chen, Lidan Shou</dc:creator>
    </item>
    <item>
      <title>Optimization and Application of Cloud-based Deep Learning Architecture for Multi-Source Data Prediction</title>
      <link>https://arxiv.org/abs/2410.12642</link>
      <description>arXiv:2410.12642v1 Announce Type: cross 
Abstract: This study develops a cloud-based deep learning system for early prediction of diabetes, leveraging the distributed computing capabilities of the AWS cloud platform and deep learning technologies to achieve efficient and accurate risk assessment. The system utilizes EC2 p3.8xlarge GPU instances to accelerate model training, reducing training time by 93.2% while maintaining a prediction accuracy of 94.2%. With an automated data processing and model training pipeline built using Apache Airflow, the system can complete end-to-end updates within 18.7 hours. In clinical applications, the system demonstrates a prediction accuracy of 89.8%, sensitivity of 92.3%, and specificity of 95.1%. Early interventions based on predictions lead to a 37.5% reduction in diabetes incidence among the target population. The system's high performance and scalability provide strong support for large-scale diabetes prevention and management, showcasing significant public health value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12642v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Zhang, Fa Wang, Xin Huang, Xintao Li, Sibei Liu, Hansong Zhang</dc:creator>
    </item>
    <item>
      <title>TorchQL: A Programming Framework for Integrity Constraints in Machine Learning</title>
      <link>https://arxiv.org/abs/2308.06686</link>
      <description>arXiv:2308.06686v4 Announce Type: replace 
Abstract: Finding errors in machine learning applications requires a thorough exploration of their behavior over data. Existing approaches used by practitioners are often ad-hoc and lack the abstractions needed to scale this process. We present TorchQL, a programming framework to evaluate and improve the correctness of machine learning applications. TorchQL allows users to write queries to specify and check integrity constraints over machine learning models and datasets. It seamlessly integrates relational algebra with functional programming to allow for highly expressive queries using only eight intuitive operators. We evaluate TorchQL on diverse use-cases including finding critical temporal inconsistencies in objects detected across video frames in autonomous driving, finding data imputation errors in time-series medical records, finding data labeling errors in real-world images, and evaluating biases and constraining outputs of language models. Our experiments show that TorchQL enables up to 13x faster query executions than baselines like Pandas and MongoDB, and up to 40% shorter queries than native Python. We also conduct a user study and find that TorchQL is natural enough for developers familiar with Python to specify complex integrity constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06686v4</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaditya Naik, Adam Stein, Yinjun Wu, Mayur Naik, Eric Wong</dc:creator>
    </item>
  </channel>
</rss>
