<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Robust Market Design with Opaque Announcements</title>
      <link>https://arxiv.org/abs/2408.04509</link>
      <description>arXiv:2408.04509v1 Announce Type: new 
Abstract: We introduce a framework where the announcements of a clearinghouse about the allocation process are opaque in the sense that there can be more than one outcome compatible with a realization of type reports. We ask whether desirable properties can be ensured under opacity in a robust sense. A property can be guaranteed under an opaque announcement if every mechanism compatible with it satisfies the property. We find an impossibility result: strategy-proofness cannot be guaranteed under any level of opacity. In contrast, in some environments, weak Maskin monotonicity and non-bossiness can be guaranteed under opacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04509v1</guid>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aram Grigoryan, Markus M\"oller</dc:creator>
    </item>
    <item>
      <title>Revealed Invariant Preference</title>
      <link>https://arxiv.org/abs/2408.04573</link>
      <description>arXiv:2408.04573v1 Announce Type: new 
Abstract: We consider the problem of rationalizing choice data by a preference satisfying an arbitrary collection of invariance axioms. Examples of such axioms include quasilinearity, homotheticity, independence-type axioms for mixture spaces, constant relative/absolute risk and ambiguity aversion axioms, stationarity for dated rewards or consumption streams, separability, and many others. We provide necessary and sufficient conditions for invariant rationalizability via a novel approach which relies on tools from the theoretical computer science literature on automated theorem proving. We also establish a generalization of the Dushnik-Miller theorem, which we use to give a complete description of the out-of-sample predictions generated by the data under any such collection of axioms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04573v1</guid>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Caradonna, Christopher P. Chambers</dc:creator>
    </item>
    <item>
      <title>Non-maximizing policies that fulfill multi-criterion aspirations in expectation</title>
      <link>https://arxiv.org/abs/2408.04385</link>
      <description>arXiv:2408.04385v1 Announce Type: cross 
Abstract: In dynamic programming and reinforcement learning, the policy for the sequential decision making of an agent in a stochastic environment is usually determined by expressing the goal as a scalar reward function and seeking a policy that maximizes the expected total reward. However, many goals that humans care about naturally concern multiple aspects of the world, and it may not be obvious how to condense those into a single reward function. Furthermore, maximization suffers from specification gaming, where the obtained policy achieves a high expected total reward in an unintended way, often taking extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple distinct evaluation metrics, which do not necessarily represent quantities that the user wants to be maximized. We assume the task of the agent is to ensure that the vector of expected totals of the evaluation metrics falls into some given convex set, called the aspiration set. Our algorithm guarantees that this task is fulfilled by using simplices to approximate feasibility sets and propagate aspirations forward while ensuring they remain feasible. It has complexity linear in the number of possible state-action-successor triples and polynomial in the number of evaluation metrics. Moreover, the explicitly non-maximizing nature of the chosen policy and goals yields additional degrees of freedom, which can be used to apply heuristic safety criteria to the choice of actions. We discuss several such safety criteria that aim to steer the agent towards more conservative behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04385v1</guid>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Dima, Simon Fischer, Jobst Heitzig, Joss Oliver</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence for Multi-Unit Auction design</title>
      <link>https://arxiv.org/abs/2404.15633</link>
      <description>arXiv:2404.15633v3 Announce Type: replace-cross 
Abstract: Understanding bidding behavior in multi-unit auctions remains an ongoing challenge for researchers. Despite their widespread use, theoretical insights into the bidding behavior, revenue ranking, and efficiency of commonly used multi-unit auctions are limited. This paper utilizes artificial intelligence, specifically reinforcement learning, as a model free learning approach to simulate bidding in three prominent multi-unit auctions employed in practice. We introduce six algorithms that are suitable for learning and bidding in multi-unit auctions and compare them using an illustrative example. This paper underscores the significance of using artificial intelligence in auction design, particularly in enhancing the design of multi-unit auctions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15633v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peyman Khezr, Kendall Taylor</dc:creator>
    </item>
  </channel>
</rss>
