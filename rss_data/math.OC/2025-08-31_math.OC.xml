<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Sep 2025 04:01:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Impulse control in a spectrally negative L\'evy model with a level-dependent intensity of bankruptcy</title>
      <link>https://arxiv.org/abs/2508.21133</link>
      <description>arXiv:2508.21133v1 Announce Type: new 
Abstract: We consider an optimal dividend problem with transaction costs where the surplus is modelled by a spectrally negative L\'evy process in an Omega model. n this model, the surplus is allowed to spend time below the critical ruin level, but is penalised by a state-dependent intensity of bankruptcy. We show that under the spectrally negative model an optimal strategy is such that the surplus is reduced to a level $c_1$ whenever they are above another level $c_2$, and that such levels are unique under the additional assumption that the L\'evy measure has a log-convex tail. We describe a numerical method to compute the optimal values $c_1$ and $c_2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21133v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Mata</dc:creator>
    </item>
    <item>
      <title>Verifying Probabilistic Regions of Attraction with Neural Lyapunov Functions for Stochastic Systems</title>
      <link>https://arxiv.org/abs/2508.21213</link>
      <description>arXiv:2508.21213v1 Announce Type: new 
Abstract: Leveraging a stochastic extension of Zubov's equation, we develop a physics-informed neural network (PINN) approach for learning a neural Lyapunov function that captures the largest probabilistic region of attraction (ROA) for stochastic systems. We then provide sufficient conditions for the learned neural Lyapunov functions that can be readily verified by satisfiability modulo theories (SMT) solvers, enabling formal verification of both local stability analysis and probabilistic ROA estimates. By solving Zubov's equation for the maximal Lyapunov function, our method provides more accurate and larger probabilistic ROA estimates than traditional sum-of-squares (SOS) methods. Numerical experiments on nonlinear stochastic systems validate the effectiveness of our approach in training and verifying neural Lyapunov functions for probabilistic stability analysis and ROA estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21213v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun Su, Hans De Sterck, Jun Liu</dc:creator>
    </item>
    <item>
      <title>A Fundamental Convergence Rate Bound for Gradient Based Online Optimization Algorithms with Exact Tracking</title>
      <link>https://arxiv.org/abs/2508.21335</link>
      <description>arXiv:2508.21335v1 Announce Type: new 
Abstract: In this paper, we consider algorithms with integral action for solving online optimization problems characterized by quadratic cost functions with a time-varying optimal point described by an $(n-1)$th order polynomial. Using a version of the internal model principle, the optimization algorithms under consideration are required to incorporate a discrete time $n$-th order integrator in order to achieve exact tracking. By using results on an optimal gain margin problem, we obtain a fundamental convergence rate bound for the class of linear gradient based algorithms exactly tracking a time-varying optimal point. This convergence rate bound is given by $ \left(\frac{\sqrt{\kappa} - 1 }{\sqrt{\kappa} + 1}\right)^{\frac{1}{n}}$, where $\kappa$ is the condition number for the set of cost functions under consideration. Using our approach, we also construct algorithms which achieve the optimal convergence rate as well as zero steady-state error when tracking a time-varying optimal point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21335v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alex Xinting Wu, Ian R. Petersen, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Incremental Policy Iteration for Unknown Nonlinear Systems with Stability and Performance Guarantees</title>
      <link>https://arxiv.org/abs/2508.21367</link>
      <description>arXiv:2508.21367v1 Announce Type: new 
Abstract: This paper proposes a general incremental policy iteration adaptive dynamic programming (ADP) algorithm for model-free robust optimal control of unknown nonlinear systems. The approach integrates recursive least squares estimation with linear ADP principles, which greatly simplifies the implementation while preserving adaptive learning capabilities. In particular, we develop a sufficient condition for selecting a discount factor such that it allows learning the optimal policy starting with an initial policy that is not necessarily stabilizing. Moreover, we characterize the robust stability of the closed-loop system and the near-optimality of iterative policies. Finally, we perform numerical simulations to demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21367v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingkai Meng, Fenglan Wang, Lin Zhao</dc:creator>
    </item>
    <item>
      <title>Stochastic Online Feedback Optimization for Networks of Non-Compliant Agents</title>
      <link>https://arxiv.org/abs/2508.21414</link>
      <description>arXiv:2508.21414v1 Announce Type: new 
Abstract: In several applications of online optimization to networked systems such as power grids and robotic networks, information about the system model and its disturbances is not generally available. Within the optimization community, increasing interest has been devoted to the framework of online feedback optimization (OFO), which aims to address these challenges by leveraging real-time input-output measurements to empower online optimization. We extend the OFO framework to a stochastic setting, allowing the subsystems comprising the network (the $\textit{agents}$) to be $\textit{non-compliant}$. This means that the actual control input implemented by the agents is a random variable depending upon the control setpoint generated by the OFO algorithm. Mean-square error bounds are obtained for the general algorithm and the theory is illustrated in application to power systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21414v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caio Kalil Lauand, Andrey Bernstein</dc:creator>
    </item>
    <item>
      <title>A Passivity Analysis for Nonlinear Consensus on Digraphs</title>
      <link>https://arxiv.org/abs/2508.21428</link>
      <description>arXiv:2508.21428v1 Announce Type: new 
Abstract: This work presents a passivity-based analysis for the nonlinear output agreement problem in network systems over directed graphs. We reformulate the problem as a convergence analysis on the agreement submanifold. First, we establish how passivity properties of individual agents and controllers determine the passivity of their associated system relations. Building on this, we introduce the concept of submanifold-constrained passivity and develop a novel compensation theorem that ensures output convergence to the agreement submanifold. Unlike previous approaches, our approach can analyze the network system with arbitrary digraphs and any passive agents. We apply this framework to analyze the output agreement problem for network systems consisting of nonlinear and passive agents. Numerical examples support our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21428v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng-Yu Yue, Daniel Zelazo</dc:creator>
    </item>
    <item>
      <title>An Optimistic Gradient Tracking Method for Distributed Minimax Optimization</title>
      <link>https://arxiv.org/abs/2508.21431</link>
      <description>arXiv:2508.21431v1 Announce Type: new 
Abstract: This paper studies the distributed minimax optimization problem over networks. To enhance convergence performance, we propose a distributed optimistic gradient tracking method, termed DOGT, which solves a surrogate function that captures the similarity between local objective functions to approximate a centralized optimistic approach locally. Leveraging a Lyapunov-based analysis, we prove that DOGT achieves linear convergence to the optimal solution for strongly convex-strongly concave objective functions while remaining robust to the heterogeneity among them. Moreover, by integrating an accelerated consensus protocol, the accelerated DOGT (ADOGT) algorithm achieves an optimal convergence rate of $\mathcal{O} \left( \kappa \log \left( \epsilon ^{-1} \right) \right)$ and communication complexity of $\mathcal{O} \left( \kappa \log \left( \epsilon ^{-1} \right) /\sqrt{1-\sqrt{\rho _W}} \right)$ for a suboptimality level of $\epsilon&gt;0$, where $\kappa$ is the condition number of the objective function and $\rho_W$ is the spectrum gap of the network. Numerical experiments illustrate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21431v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Huang, Jinming Xu, Jiming Chen, Karl Henrik Johansson</dc:creator>
    </item>
    <item>
      <title>Sensor placement via large deviations in the Eikonal equation</title>
      <link>https://arxiv.org/abs/2508.21469</link>
      <description>arXiv:2508.21469v1 Announce Type: new 
Abstract: In this work, we address the problem of optimally placing a finite number of sensors within a given region so as to minimize the mean or maximal distance to the points of the domain. To tackle this natural geometric performance criterion, formulated in terms of distance functions, we combine tools from geometric analysis with a classical result of Varadhan, which provides an efficient approximation of the distance function via the solution of a simple elliptic PDE. The effectiveness of the proposed approach is demonstrated through illustrative numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21469v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ilias Ftouhi, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>A Stochastic-Optimization-Based Adaptive-Sampling Scheme for Data-Driven Stability Analysis of Switched Linear Systems</title>
      <link>https://arxiv.org/abs/2508.21617</link>
      <description>arXiv:2508.21617v1 Announce Type: new 
Abstract: We introduce a novel approach based on stochastic optimization to find the optimal sampling distribution for the data-driven stability analysis of switched linear systems. Our goal is to address limitations of existing approaches, in particular, the fact that these methods suffer from illconditioning of the optimal Lyapunov function, which was shown in recent work to be a direct consequence of the way the data is collected by sampling uniformly the state space. In this work, we formalize the notion of optimal sampling distribution, using the perspective of stochastic optimization. This allows us to leverage tools from stochastic optimization to estimate the optimal sampling distribution, and then use it to collect samples for the data-driven stability analysis of the system. We show in numerical experiments (on challenging systems of dimension up to five) that the overall procedure is highly favorable in terms of data usage compared to existing methods using fixed sampling distributions. Finally, we introduce a heuristic that combines data points from previous samples, and show empirically that this allows an additional substantial reduction in the number of samples required to achieve the same stability guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21617v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis Vuille, Guillaume O. Berger, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>Hull Clustering with Blended Representative Periods for Energy System Optimization Models</title>
      <link>https://arxiv.org/abs/2508.21641</link>
      <description>arXiv:2508.21641v1 Announce Type: new 
Abstract: The growing integration of renewable energy sources into power systems requires planning models to account for not only demand variability but also fluctuations in renewable availability during operational periods. Capturing this temporal detail over long planning horizons can be computationally demanding or even intractable. A common approach to address this challenge is to approximate the problem using a reduced set of selected time periods, known as representative periods (RPs). However, using too few RPs can significantly degrade solution quality. In this paper, we propose a novel method -- hull clustering with blended RPs -- that enhances traditional clustering-based RP approaches in two key ways. First, instead of selecting typical cluster centers (e.g., centroids or medoids) as RPs, our method is based on extreme points, which are more likely to be constraint-binding. Second, it represents base periods as weighted combinations of RPs (e.g., convex or conic blends), enabling a more accurate approximation of the full time horizon with fewer RPs. Through two case studies based on data from the European network operators, we demonstrate that hull clustering with blended RPs outperforms traditional RP techniques in both regret and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21641v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigory Neustroev, Diego A. Tejada-Arango, German Morales-Espana, Mathijs M. de Weerdt</dc:creator>
    </item>
    <item>
      <title>Mean Field Games of Controls with Dirichlet \&amp; Neumann Boundary Conditions</title>
      <link>https://arxiv.org/abs/2508.21642</link>
      <description>arXiv:2508.21642v1 Announce Type: new 
Abstract: In a mean field game of controls, a large population of identical players seek to minimize a cost that depends on the joint distribution of the states of the players and their controls. We consider the classes of mean field games of controls in which the value function and the distribution of player states satisfy either Dirichlet or Neumann boundary conditions. We prove that such systems are well-posed either with sufficient smallness conditions or in the case of monotone couplings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21642v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Jameson Graber, Kyle Rosengartner</dc:creator>
    </item>
    <item>
      <title>PDE-constrained optimal control of a leader-follower opinion formation model</title>
      <link>https://arxiv.org/abs/2508.21674</link>
      <description>arXiv:2508.21674v1 Announce Type: new 
Abstract: We consider the PDE-constrained optimal control of a leader-follower kinetic opinion formation model, with a Fokker-Planck-type system of partial differential equations as a state constraint. We derive the Boltzmann-type and Fokker-Planck-type systems of equations associated with the controlled leader-follower opinion formation model. In a function space setting we derive first-order optimality conditions associated with the PDE-constrained optimal control problem, yielding an optimality system of coupled nonlinear partial differential equations. We employ a gradient-type sweeping algorithm to numerically attack the optimality system obtained from the first-order optimality conditions. We present the results from a finite elements based simulation for different types of interactions and cost functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21674v1</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bertram D\"uring, Oliver Wright</dc:creator>
    </item>
    <item>
      <title>A Dual Ensemble Kalman Filter Approach to Robust Control of Nonlinear Systems: An Application to Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2508.21684</link>
      <description>arXiv:2508.21684v1 Announce Type: new 
Abstract: This paper considers the problem of data-driven robust control design for nonlinear systems, for instance, obtained when discretizing nonlinear partial differential equations (PDEs). A robust learning control approach is developed for nonlinear affine in control systems based on Lyapunov redesign technique. The robust control is developed as a sum of an optimal learning control which stabilizes the system in absence of disturbances, and an additive Lyapunov-based robustification term which handles the effects of disturbances. The dual ensemble Kalman filter (dual EnKF) algorithm is utilized in the optimal control design methodology. A simulation study is done on the heat equation and Burgers partial differential equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21684v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anant A. Joshi, Saviz Mowlavi, Mouhacine Benosman</dc:creator>
    </item>
    <item>
      <title>Globally Coupled Particle Swarm Optimization</title>
      <link>https://arxiv.org/abs/2508.21721</link>
      <description>arXiv:2508.21721v1 Announce Type: new 
Abstract: All things in the world are interconnected, the only difference is the strength of their connections.Particle swarm optimization(PSO) simulates the foraging behavior of a flock of birds, information is transmitted to quickly find the location of food. This is a process of information exchange, where birds influence each other, constantly adjusting their position and speed values,and updating the optimal position information.In this paper, we propose a globally coupled particle swarm ptimization(GCPSO) that combines the globally coupled map lattices(GCML) with the PSO to enhance its optimization capabilities.The information of the $i$-th lattice point is influenced by the information of all lattice points in GCML.The information between lattice points is interdependent.Inspired by this, we will integrate GCML into PSO and propose a new improved particle swarm optimization, namely GCPSO.Here, the speed update formula has been modified and improved.The next flight speed of each bird is influenced by its current speed, its historical best position, the historical global best position, its current position, and the positions of all birds.Each bird(particle) is influenced by all birds. The strength of the impact will be distinguished by the size of the weight. This is the essential difference and key improvement from PSO.Through extensive experiments, it has been found that compared to PSO, GCPSO has a stronger ability to search for solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21721v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liguo Yuan</dc:creator>
    </item>
    <item>
      <title>Learning from the past in an irreversible investment problem</title>
      <link>https://arxiv.org/abs/2508.21731</link>
      <description>arXiv:2508.21731v1 Announce Type: new 
Abstract: We consider an irreversible investment problem under incomplete information, where the investor is able to exercise multiple investment rights to a project. The investor does not observe the project value directly and instead only a noisy observation process is observed. Upon each investment, the investor acquires previously hidden information from the project's past (''learning from the past''), and so the learning rate of the problem is controlled by investing. The acquisition of additional information is modeled by letting each investment affect the elapsed time of the observation process. We set up the problem as a recursively defined multiple stopping problem under incomplete information and present the optimal investment strategy as a sequence of stopping boundaries, where the boundaries are solved from equations derived from smooth fit conditions. Examples of optimal boundaries are then solved numerically, and we provide numerical comparative statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21731v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Topias Tolonen-Weckstr\"om</dc:creator>
    </item>
    <item>
      <title>Sequential Fair Allocation With Replenishments: A Little Envy Goes An Exponentially Long Way</title>
      <link>https://arxiv.org/abs/2508.21753</link>
      <description>arXiv:2508.21753v1 Announce Type: new 
Abstract: We study the trade-off between envy and inefficiency in repeated resource allocation settings with stochastic replenishments, motivated by real-world systems such as food banks and medical supply chains. Specifically, we consider a model in which a decision-maker faced with stochastic demand and resource donations must trade off between an equitable and efficient allocation of resources over an infinite horizon. The decision-maker has access to storage with fixed capacity $M$, and incurs efficiency losses when storage is empty (stockouts) or full (overflows). We provide a nearly tight (up to constant factors) characterization of achievable envy-inefficiency pairs. Namely, we introduce a class of Bang-Bang control policies whose inefficiency exhibits a sharp phase transition, dropping from $\Theta(1/M)$ when $\Delta = 0$ to $e^{-\Omega(\Delta M)}$ when $\Delta &gt; 0$, where $\Delta$ is used to denote the target envy of the policy. We complement this with matching lower bounds, demonstrating that the trade-off is driven by supply, as opposed to demand uncertainty. Our results demonstrate that envy-inefficiency trade-offs not only persist in settings with dynamic replenishment, but are shaped by the decision-maker's available capacity, and are therefore qualitatively different compared to previously studied settings with fixed supply.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21753v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chido Onyeze, Sean R. Sinclair, Chamsi Hssaine, Siddhartha Banerjee</dc:creator>
    </item>
    <item>
      <title>Toward real-time optimization through model reduction and model discrepancy sensitivities</title>
      <link>https://arxiv.org/abs/2508.21792</link>
      <description>arXiv:2508.21792v1 Announce Type: new 
Abstract: Optimization problems arise in a range of scenarios, from optimal control to model parameter estimation. In many applications, such as the development of digital twins, it is essential to solve these optimization problems within wall-clock-time limitations. However, this is often unattainable for complex systems, such as those modeled by nonlinear partial differential equations. One strategy for mitigating this issue is to construct a reduced-order model (ROM) that enables more rapid optimization. In particular, the use of nonintrusive ROMs -- those that do not require access to the full-order model at evaluation time -- is popular because they facilitate optimization solutions can be computed within the wall-clock-time requirements. However, the optimization solution will be unreliable if the iterates move outside the ROM training data. This article proposes the use of hyper-differential sensitivity analysis with respect to model discrepancy (HDSA-MD) as a computationally efficient tool to augment ROM-constrained optimization and improve its reliability. The proposed approach consists of two phases: (i) an offline phase where several full-order model evaluations are computed to train the ROM, and (ii) an online phase where a ROM-constrained optimization problem is solved, $N=\mathcal{O}(1)$ full-order model evaluations are computed, and HDSA-MD is used to enhance the optimization solution using the full-order model data. Numerical results are demonstrated for two examples, atmospheric contaminant control and wildfire ignition location estimation, in which a ROM is trained offline using inaccurate atmospheric data. The HDSA-MD update yields a significant improvement in the ROM-constrained optimization solution using only one full-order model evaluation online with corrected atmospheric data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21792v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Hart, Shane A. McQuarrie, Zachary Morrow, Bart van Bloemen Waanders</dc:creator>
    </item>
    <item>
      <title>Adaptive Dead-Zone Dual Sliding Mode Observer for Reliable Electrochemical Model-Based SOC Estimation</title>
      <link>https://arxiv.org/abs/2508.21610</link>
      <description>arXiv:2508.21610v1 Announce Type: cross 
Abstract: Accurate state of charge (SOC) estimation is critical for ensuring the safety, reliability, and efficiency of lithium-ion batteries in electric vehicles and energy storage systems. Electrochemical models provide high fidelity for SOC estimation but introduce challenges due to parameter variations, nonlinearities, and computational complexity. To address these issues, this paper proposes an adaptive dead-zone dual sliding mode observer(SMO) based on an improved electrochemical single-particle model. The algorithm integrates a state observer for SOC estimation and a parameter observer for online parameter adaptation. A Lyapunov-derived adaptive dead-zone is introduced to ensure stability, activating parameter updates only when the terminal voltage error lies within a rigorously defined bound. The proposed method was validated under constant-current and UDDS dynamic conditions. Results demonstrate that the adaptive dead-zone dual SMO achieves superior accuracy compared with conventional dual SMO and equivalent circuit model-based EKF methods, maintaining SOC estimation errors within 0.2% under correct initialization and below 1% under a 30% initial SOC error, with rapid convergence. Computational efficiency analysis further shows that the adaptive dead-zone dual sliding mode observer reduces execution time compared with the conventional dual SMO by limiting unnecessary parameter updates, highlighting its suitability for real-time battery management applications. Moreover, robustness under battery aging was confirmed using a cycle-aging model, where the adaptive dead-zone dual SMO maintained stable SOC estimation despite parameter drift. These findings indicate that the proposed method offers a reliable, accurate, and computationally efficient solution for SOC estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21610v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Guangdi Hu, Keyi Liao, Jian Ye, Feng Guo</dc:creator>
    </item>
    <item>
      <title>A Soft Inducement Framework for Incentive-Aided Steering of No-Regret Players</title>
      <link>https://arxiv.org/abs/2508.21672</link>
      <description>arXiv:2508.21672v1 Announce Type: cross 
Abstract: In this work, we investigate a steering problem in a mediator-augmented two-player normal-form game, where the mediator aims to guide players toward a specific action profile through information and incentive design. We first characterize the games for which successful steering is possible. Moreover, we establish that steering players to any desired action profile is not always achievable with information design alone, nor when accompanied with sublinear payment schemes. Consequently, we derive a lower bound on the constant payments required per round to achieve this goal. To address these limitations incurred with information design, we introduce an augmented approach that involves a one-shot information design phase before the start of the repeated game, transforming the prior interaction into a Stackelberg game. Finally, we theoretically demonstrate that this approach improves the convergence rate of players' action profiles to the target point by a constant factor with high probability, and support it with empirical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21672v1</guid>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asrin Efe Yorulmaz, Raj Kiriti Velicheti, Melih Bastopcu, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained DC Optimal Power Flow Using Constraint-Informed Statistical Estimation</title>
      <link>https://arxiv.org/abs/2508.21687</link>
      <description>arXiv:2508.21687v1 Announce Type: cross 
Abstract: Chance-constrained optimization has emerged as a promising framework for managing uncertainties in power systems. This work advances its application to the DC Optimal Power Flow (DC-OPF) model, developing a novel approach to uncertainty modeling and estimation. Current methods typically tackle these problems by first modeling random nodal injections using high-dimensional statistical distributions that scale with the number of buses, followed by deriving deterministic reformulations of the probabilistic constraints. We propose an alternative methodology that exploits the constraint structure to inform the uncertainties to be estimated, enabling significant dimensionality reduction. Rather than learning joint distributions of net-load forecast errors across units, we instead directly model the one-dimensional aggregate system forecast error and two-dimensional line errors weighted by power transfer distribution factors. We evaluate our approach under both Gaussian and non-Gaussian distributions on synthetic and real-world datasets, demonstrating significant improvements in statistical accuracy and optimization performance compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21687v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyang Yi, D. Adrian Maldonado, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>Convergence to good non-optimal critical points in the training of neural networks: Gradient descent optimization with one random initialization overcomes all bad non-global local minima with high probability</title>
      <link>https://arxiv.org/abs/2212.13111</link>
      <description>arXiv:2212.13111v2 Announce Type: replace 
Abstract: Gradient descent (GD) methods for the training of artificial neural networks (ANNs) belong nowadays to the most heavily employed computational schemes in the digital world. Despite the compelling success of such methods, it remains an open problem to provide a rigorous theoretical justification for the success of GD methods in the training of ANNs. The main difficulty is that the optimization risk landscapes associated to ANNs usually admit many non-optimal critical points (saddle points as well as non-global local minima) whose risk values are strictly larger than the optimal risk value. It is a key contribution of this article to overcome this obstacle in certain simplified shallow ANN training situations. In such simplified ANN training scenarios we prove that the gradient flow (GF) dynamics with only one random initialization overcomes with high probability all bad non-global local minima (all non-global local minima whose risk values are much larger than the risk value of the global minima) and converges with high probability to a good critical point (a critical point whose risk value is very close to the optimal risk value of the global minima). This analysis allows us to establish convergence in probability to zero of the risk value of the GF trajectories with convergence rates as the ANN training time and the width of the ANN increase to infinity. We complement the analytical findings of this work with extensive numerical simulations for shallow and deep ANNs: All these numerical simulations strongly suggest that with high probability the considered GD method (stochastic GD or Adam) overcomes all bad non-global local minima, does not converge to a global minimum, but does converge to a good non-optimal critical point whose risk value is very close to the optimal risk value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.13111v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shokhrukh Ibragimov, Arnulf Jentzen, Adrian Riekert</dc:creator>
    </item>
    <item>
      <title>A novel switched systems approach to nonconvex optimisation</title>
      <link>https://arxiv.org/abs/2410.21570</link>
      <description>arXiv:2410.21570v2 Announce Type: replace 
Abstract: We develop a novel switching dynamics that converges to the Karush-Kuhn-Tucker (KKT) point of a nonlinear optimisation problem. This new approach is particularly notable for its lower dimensionality compared to conventional primal-dual dynamics, as it focuses exclusively on estimating the primal variable. Our method is successfully illustrated on general quadratic optimisation problems, the minimisation of the classical Rosenbrock function, and a nonconvex optimisation problem stemming from the control of energy-efficient buildings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21570v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Ferguson, Saeed Ahmed, Juan E. Machado, Michele Cucuzzella, Jacquelien M. A. Scherpen</dc:creator>
    </item>
    <item>
      <title>A Bayesian Composite Risk Approach for Stochastic Optimal Control and Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2412.16488</link>
      <description>arXiv:2412.16488v3 Announce Type: replace 
Abstract: Inspired by Shapiro et al.~\cite{shapiro2023episodic}, we consider a stochastic optimal control (SOC) and Markov decision process (MDP) where the risks arising from epistemic and aleatoric uncertainties are assessed using Bayesian composite risk (BCR) measures (Qian et al.~\cite{qian2019composite}). The time dependence of the risk measures allows us to capture the decision maker's (DM) dynamic risk preferences opportunely as increasing information about both uncertainties is obtained. This makes the new BCR-SOC/MDP model more flexible than conventional risk-averse SOC/MDP models. Unlike \cite{shapiro2023episodic} where the control/action at each episode is based on the current state alone, the new model allows the control to depend on the probability distribution of the epistemic uncertainty, which reflects the fact that in many practical instances the cumulative information about epistemic uncertainty often affects the DM's belief about the future aleatoric uncertainty and hence the DM's action \cite{strens2000bayesian}. The new modeling paradigm incorporates several existing SOC/MDP models including distributionally robust SOC/MDP models and Bayes-adaptive MDP models and generates so-called preference robust SOC/MDP models. Moreover, we derive conditions under which the BCR-SOC/MDP model is well-defined, demonstrate that finite-horizon BCR-SOC/MDP models can be solved using dynamic programming techniques, and extend the discussion to the infinite-horizon case. By using Bellman equations, we show that under some standard conditions, asymptotic convergence of the optimal values and optimal actions as the episodic variable goes to infinity is achieved. Finally, we carry out numerical tests on a finite horizon spread betting problem and an inventory control problem and show the effectiveness of the proposed model and numerical schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16488v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wentao Ma, Zhiping Chen, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Algebraic Control: Complete Stable Inversion with Necessary and Sufficient Conditions</title>
      <link>https://arxiv.org/abs/2501.00172</link>
      <description>arXiv:2501.00172v4 Announce Type: replace 
Abstract: In this paper, we establish necessary and sufficient conditions for stable inversion, addressing challenges in non-minimum phase, non-square, and singular systems. An H-Infinity based algebraic approximation is introduced for near-perfect tracking without preview. Additionally, we propose a novel robust control strategy combining the nominal model with dual feedforward control to form a feedback structure. Numerical comparison demonstrates the approach's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00172v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Burak K\"urk\c{c}\"u, Masayoshi Tomizuka</dc:creator>
    </item>
    <item>
      <title>A control-oriented approach to optimal sensor placement</title>
      <link>https://arxiv.org/abs/2502.15062</link>
      <description>arXiv:2502.15062v2 Announce Type: replace 
Abstract: We propose a control-oriented optimal experimental design (cOED) approach for linear PDE-constrained Bayesian inverse problems. In particular, we consider optimal control problems with uncertain parameters that need to be estimated by solving an inverse problem, which in turn requires measurement data. We consider the case where data is collected at a set of sensors. While classical Bayesian OED techniques provide experimental designs (sensor placements) that minimize the posterior uncertainty in the inversion parameter, these designs are not tailored to the demands of the optimal control problem. In the present control-oriented setting, we prioritize the designs that minimize the uncertainty in the state variable being controlled or the control objective. We propose a mathematical framework for uncertainty quantification and cOED for parameterized PDE-constrained optimal control problems with linear dependence to the control variable and the inversion parameter. We also present scalable computational methods for computing control-oriented sensor placements and for quantifying the uncertainty in the control objective. Additionally, we present illustrative numerical results in the context of a model problem motivated by heat transfer applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15062v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madhusudan Madhavan, Alen Alexanderian, Arvind K. Saibaba, Bart van Bloemen Waanders, Rebekah D. White</dc:creator>
    </item>
    <item>
      <title>Constrained Optimization From a Control Perspective via Feedback Linearization</title>
      <link>https://arxiv.org/abs/2503.12665</link>
      <description>arXiv:2503.12665v2 Announce Type: replace 
Abstract: Tools from control and dynamical systems have proven valuable for analyzing and developing optimization methods. In this paper, we establish rigorous theoretical foundations for using feedback linearization -- a well-established nonlinear control technique -- to solve constrained optimization problems. For equality-constrained optimization, we establish global convergence rates to first-order Karush-Kuhn-Tucker (KKT) points and uncover the close connection between the FL method and the Sequential Quadratic Programming (SQP) algorithm. Building on this relationship, we extend the FL approach to handle inequality-constrained problems. Furthermore, we introduce a momentum-accelerated feedback linearization algorithm that achieves faster convergence, and provides a rigorous convergence guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12665v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Arvind Raghunathan, Jeff Shamma, Na Li</dc:creator>
    </item>
    <item>
      <title>Distributed Constrained Online Nonconvex Optimization with Compressed Communication</title>
      <link>https://arxiv.org/abs/2503.22410</link>
      <description>arXiv:2503.22410v2 Announce Type: replace 
Abstract: This paper considers distributed online nonconvex optimization with time-varying inequality constraints over a network of agents. For a time-varying graph, we propose a distributed online primal-dual algorithm with compressed communication to efficiently utilize communication resources. We show that the proposed algorithm establishes an $\mathcal{O}( {{T^{\max \{ {1 - {\theta_1},{\theta_1}} \}}}} )$ network regret bound and an $\mathcal{O}( {T^{1 - {\theta_1}/2}} )$ network cumulative constraint violation bound, where $T$ is the number of iterations and ${\theta_1} \in ( {0,1} )$ is a user-defined trade-off parameter. When Slater's condition holds (i.e, there is a point that strictly satisfies the inequality constraints at all iterations), the network cumulative constraint violation bound is reduced to $\mathcal{O}( {T^{1 - {\theta_1}}} )$. These bounds are comparable to the state-of-the-art results established by existing distributed online algorithms with perfect communication for distributed online convex optimization with (time-varying) inequality constraints. Finally, a simulation example is presented to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22410v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunpeng Zhang, Lei Xu, Xinlei Yi, Ming Cao, Karl H. Johansson, Tianyou Chai, Tao Yang</dc:creator>
    </item>
    <item>
      <title>Compressed Zeroth-Order Algorithm for Stochastic Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2503.23426</link>
      <description>arXiv:2503.23426v4 Announce Type: replace 
Abstract: This paper studies the stochastic distributed nonconvex optimization problem over a network of agents, where agents only access stochastic zeroth-order information about their local cost functions and collaboratively optimize the global objective over bandwidth-limited communication networks. To mitigate communication overhead and handle the unavailability of explicit gradient information, we propose a communication compressed zeroth-order stochastic distributed (CZSD) algorithm. By integrating a generalized contractive compressor and a stochastic two-point zeroth-order oracle, CZSD achieves convergence rates comparable to its exact communication counterpart while reducing both communication overhead and sampling complexity. Specifically, to the best of our knowledge, CZSD is the first compressed zeroth-order algorithm achieving linear speedup, with convergence rates of $\mathcal{O}(\sqrt{p}/\sqrt{nT})$ and $\mathcal{O}(p/(nT))$ under general nonconvex settings and the Polyak--{\L}ojasiewicz condition, respectively. Numerical experiments validate the algorithm's effectiveness and communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23426v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haonan Wang, Xinlei Yi, Yiguang Hong</dc:creator>
    </item>
    <item>
      <title>Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization</title>
      <link>https://arxiv.org/abs/2507.09823</link>
      <description>arXiv:2507.09823v2 Announce Type: replace 
Abstract: In this paper, we focus on the problem of minimizing a continuously differentiable convex objective function, $\min_x f(x)$. Recently, Malitsky (2020); Alacaoglu et al.(2023) developed an adaptive first-order method, GRAAL. This algorithm computes stepsizes by estimating the local curvature of the objective function without any line search procedures or hyperparameter tuning, and attains the standard iteration complexity $\mathcal{O}(L\lVert x_0-x^*\rVert^2/\epsilon)$ of fixed-stepsize gradient descent for $L$-smooth functions. However, a natural question arises: is it possible to accelerate the convergence of GRAAL to match the optimal complexity $\mathcal{O}(\sqrt{L\lVert x_0-x^*\rVert^2/\epsilon})$ of the accelerated gradient descent of Nesterov (1983)? Although some attempts have been made by Li and Lan (2025); Suh and Ma (2025), the ability of existing accelerated algorithms to adapt to the local curvature of the objective function is highly limited. We resolve this issue and develop GRAAL with Nesterov acceleration, which can adapt its stepsize to the local curvature at a geometric, or linear, rate just like non-accelerated GRAAL. We demonstrate the adaptive capabilities of our algorithm by proving that it achieves near-optimal iteration complexities for $L$-smooth functions, as well as under a more general $(L_0,L_1)$-smoothness assumption (Zhang et al., 2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09823v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ekaterina Borodich, Dmitry Kovalev</dc:creator>
    </item>
    <item>
      <title>The Ellipsoidal Separation Machine</title>
      <link>https://arxiv.org/abs/2507.20698</link>
      <description>arXiv:2507.20698v2 Announce Type: replace 
Abstract: We propose the -- to the best of our knowledge -- first fully functional implementation of the ``Separation by a Convex Body'' (SCB) approach first outlined in Grzybowski et al. [1] for classification, separating two data sets using an ellipsoid. A training problem is defined that is structurally similar to the Support Vector Machine (SVM) one, thus leading to call our method the Ellipsoidal Separation Machine (ESM). Like SVM, the training problem is convex, and can in particular be formulated as a Semidefinite Program (SDP); however, solving it by means of standard SDP approaches does not scale to the size required by practical classification task. As an alternative, a nonconvex formulation is proposed that is amenable to a Block-Gauss-Seidel approach alternating between a much smaller SDP and a simple separable Second-Order Cone Program (SOCP). For the purpose of the classification approach the reduced SDP can even be solved approximately by relaxing it in a Lagrangian way and updating the multipliers by fast subgradient-type approaches. A characteristic of ESM is that it necessarily defines ``indeterminate points'', i.e., those that cannot be reliably classified as belonging to one of the two sets. This makes it particularly suitable for Classification with Rejection (CwR) tasks, whereby the system explicitly indicates that classification of some points as belonging to one of the two sets is too doubtful to be reliable. We show that, in many datasets, ESM is competitive with SVM -- with the kernel chosen among the three standard ones and endowed with CwR capabilities using the margin of the classifier -- and in general behaves differently; thus, ESM provides another arrow in the quiver when designing CwR approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20698v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonio Frangioni, Enrico Gorgone, Benedetto Manca</dc:creator>
    </item>
    <item>
      <title>Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery</title>
      <link>https://arxiv.org/abs/2401.02592</link>
      <description>arXiv:2401.02592v3 Announce Type: replace-cross 
Abstract: In this paper, we provide the first convergence guarantee for the factorization approach. Specifically, to avoid the scaling ambiguity and to facilitate theoretical analysis, we optimize over the so-called left-orthogonal TT format which enforces orthonormality among most of the factors. To ensure the orthonormal structure, we utilize the Riemannian gradient descent (RGD) for optimizing those factors over the Stiefel manifold. We first delve into the TT factorization problem and establish the local linear convergence of RGD. Notably, the rate of convergence only experiences a linear decline as the tensor order increases. We then study the sensing problem that aims to recover a TT format tensor from linear measurements. Assuming the sensing operator satisfies the restricted isometry property (RIP), we show that with a proper initialization, which could be obtained through spectral initialization, RGD also converges to the ground-truth tensor at a linear rate. Furthermore, we expand our analysis to encompass scenarios involving Gaussian noise in the measurements. We prove that RGD can reliably recover the ground truth at a linear rate, with the recovery error exhibiting only polynomial growth in relation to the tensor order. We conduct various experiments to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02592v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research (December 2024)</arxiv:journal_reference>
      <dc:creator>Zhen Qin, Michael B. Wakin, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Long time behaviour of generalised gradient flows via occupational measures</title>
      <link>https://arxiv.org/abs/2410.20943</link>
      <description>arXiv:2410.20943v2 Announce Type: replace-cross 
Abstract: This paper introduces new methods to study the long time behaviour of the generalised gradient flow associated with a solution of the critical equation for mechanical Hamiltonian system posed on the flat torus $\mathbb{T}^d$. For this analysis it is necessary to look at the critical set of $u$ consisting of all the points on $\mathbb{T}^d$ such that zero belongs to the super-differential of such a solution. Indeed, such a set turns out to be an attractor for the generalised gradient flow. Moreover, being the critical set the union of two subsets of rather different nature, namely the regular critical set and the singular set, we are interested in establishing whether the generalised gradient flow approaches the former or the latter as $t\to \infty$. One crucial tool of our analysis is provided by limiting occupational measures, a family of measures that are invariant under the generalized flow. Indeed, we show that by integrating the potential with respect to such measures, one can deduce whether the generalised gradient flow enters the singular set in finite time, or it approaches the regular critical set as time tends to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20943v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Albano, Piermarco Cannarsa, Wei Cheng, Cristian Mendico</dc:creator>
    </item>
    <item>
      <title>Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence</title>
      <link>https://arxiv.org/abs/2412.18164</link>
      <description>arXiv:2412.18164v4 Announce Type: replace-cross 
Abstract: Diffusion models have emerged as powerful tools for generative modeling, demonstrating exceptional capability in capturing target data distributions from large datasets. However, fine-tuning these massive models for specific downstream tasks, constraints, and human preferences remains a critical challenge. While recent advances have leveraged reinforcement learning algorithms to tackle this problem, much of the progress has been empirical, with limited theoretical understanding. To bridge this gap, we propose a stochastic control framework for fine-tuning diffusion models. Building on denoising diffusion probabilistic models as the pre-trained reference dynamics, our approach integrates linear dynamics control with Kullback-Leibler regularization. We establish the well-posedness and regularity of the stochastic control problem and develop a policy iteration algorithm (PI-FT) for numerical solution. We show that PI-FT achieves global convergence at a linear rate. Unlike existing work that assumes regularities throughout training, we prove that the control and value sequences generated by the algorithm maintain the regularity. Additionally, we explore extensions of our framework to parametric settings and continuous-time formulations, and demonstrate the practical effectiveness of the proposed PI-FT algorithm through numerical experiments. Our code is available at https://github.com/yinbinhan/fine-tuning-of-diffusion-models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18164v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Forty-Second International Conference on Machine Learning 2025</arxiv:journal_reference>
      <dc:creator>Yinbin Han, Meisam Razaviyayn, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Matrix Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2508.11795</link>
      <description>arXiv:2508.11795v2 Announce Type: replace-cross 
Abstract: This paper generalizes the control barrier function framework by replacing scalar-valued functions with matrix-valued ones. Specifically, we develop barrier conditions for safe sets defined by matrix inequalities -- both semidefinite and indefinite. Matrix inequalities can be used to describe a richer class of safe sets, including nonsmooth ones. The safety filters constructed from our proposed matrix control barrier functions via semidefinite programming (CBF-SDP) are shown to be continuous. Our matrix formulation naturally provides a continuous safety filter for Boolean-based control barrier functions, notably for disjunctions (OR), without relaxing the safe set. We illustrate the effectiveness of the proposed framework with applications in drone network connectivity maintenance and nonsmooth obstacle avoidance, both in simulations and hardware experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11795v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pio Ong, Yicheng Xu, Ryan M. Bena, Faryar Jabbari, Aaron D. Ames</dc:creator>
    </item>
  </channel>
</rss>
