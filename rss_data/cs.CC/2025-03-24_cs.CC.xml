<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Mar 2025 03:03:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Graph Colouring Is Hard on Average for Polynomial Calculus and Nullstellensatz</title>
      <link>https://arxiv.org/abs/2503.17022</link>
      <description>arXiv:2503.17022v1 Announce Type: new 
Abstract: We prove that polynomial calculus (and hence also Nullstellensatz) over any field requires linear degree to refute that sparse random regular graphs, as well as sparse Erd\H{o}s-R\'{e}nyi random graphs, are $3$-colourable. Using the known relation between size and degree for polynomial calculus proofs, this implies strongly exponential lower bounds on proof size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17022v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Conneryd, Susanna F. de Rezende, Jakob Nordstr\"om, Shuo Pang, Kilian Risse</dc:creator>
    </item>
    <item>
      <title>Range Avoidance in Boolean Circuits via Turan-type Bounds</title>
      <link>https://arxiv.org/abs/2503.17114</link>
      <description>arXiv:2503.17114v1 Announce Type: new 
Abstract: Given a circuit $C : \{0,1\}^n \to \{0,1\}^m$ from a circuit class $F$, with $m &gt; n$, finding a $y \in \{0,1\}^m$ such that $\forall x \in \{0,1\}^n$, $C(x) \ne y$, is the range avoidance problem (denoted by $F$-$avoid$). Deterministic polynomial time algorithms (even with access to $NP$ oracles) solving this problem is known to imply explicit constructions of various pseudorandom objects like hard Boolean functions, linear codes, PRGs etc. Deterministic polynomial time algorithms are known for $NC^0_2$-$avoid$ when $m &gt; n$, and for $NC^0_3$-$avoid$ when $m \ge \frac{n^2}{\log n}$, where $NC^0_k$ is the class of circuits with bounded fan-in which have constant depth and the output depends on at most $k$ of the input bits. On the other hand, it is also known that $NC^0_3$-$avoid$ when $m = n+O\left(n^{2/3}\right)$ is at least as hard as explicit construction of rigid matrices.
  In this paper, we propose a new approach to solving range avoidance problem via hypergraphs. We formulate the problem in terms of Turan-type problems in hypergraphs of the following kind - for a fixed $k$-uniform hypergraph $H'$, what is the maximum number of edges that can exist in a $k$-uniform hypergraph $H$ which does not have a sub-hypergraph isomorphic to $H'$? We use our approach to show (using known Turan-type bounds) that there is a constant $c$ such that $mon$-$NC^0_3$-$avoid$ can be solved in deterministic polynomial time when $m &gt; cn^2$. To improve the stretch constraint to linear, we show a new Turan-type theorem for a hypergraph structure (which we call the the loose $chi$-cycles) and use it to show that $mon$-$NC^0_3$-$avoid$ can be solved in deterministic polynomial time when $m &gt; n$, thus improving the known bounds of $NC^0_3$-avoid for the case of monotone circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17114v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neha Kuntewar, Jayalal Sarma</dc:creator>
    </item>
    <item>
      <title>OnDev-LCT: On-Device Lightweight Convolutional Transformers towards federated learning</title>
      <link>https://arxiv.org/abs/2401.11652</link>
      <description>arXiv:2401.11652v1 Announce Type: cross 
Abstract: Federated learning (FL) has emerged as a promising approach to collaboratively train machine learning models across multiple edge devices while preserving privacy. The success of FL hinges on the efficiency of participating models and their ability to handle the unique challenges of distributed learning. While several variants of Vision Transformer (ViT) have shown great potential as alternatives to modern convolutional neural networks (CNNs) for centralized training, the unprecedented size and higher computational demands hinder their deployment on resource-constrained edge devices, challenging their widespread application in FL. Since client devices in FL typically have limited computing resources and communication bandwidth, models intended for such devices must strike a balance between model size, computational efficiency, and the ability to adapt to the diverse and non-IID data distributions encountered in FL. To address these challenges, we propose OnDev-LCT: Lightweight Convolutional Transformers for On-Device vision tasks with limited training data and resources. Our models incorporate image-specific inductive biases through the LCT tokenizer by leveraging efficient depthwise separable convolutions in residual linear bottleneck blocks to extract local features, while the multi-head self-attention (MHSA) mechanism in the LCT encoder implicitly facilitates capturing global representations of images. Extensive experiments on benchmark image datasets indicate that our models outperform existing lightweight vision models while having fewer parameters and lower computational demands, making them suitable for FL scenarios with data heterogeneity and communication bottlenecks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11652v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.neunet.2023.11.044</arxiv:DOI>
      <dc:creator>Chu Myaet Thwal, Minh N. H. Nguyen, Ye Lin Tun, Seong Tae Kim, My T. Thai, Choong Seon Hong</dc:creator>
    </item>
    <item>
      <title>Subgradient Method for System Identification with Non-Smooth Objectives</title>
      <link>https://arxiv.org/abs/2503.16673</link>
      <description>arXiv:2503.16673v1 Announce Type: cross 
Abstract: This paper investigates a subgradient-based algorithm to solve the system identification problem for linear time-invariant systems with non-smooth objectives. This is essential for robust system identification in safety-critical applications. While existing work provides theoretical exact recovery guarantees using optimization solvers, the design of fast learning algorithms with convergence guarantees for practical use remains unexplored. We analyze the subgradient method in this setting where the optimization problems to be solved change over time as new measurements are taken, and we establish linear convergence results for both the best and Polyak step sizes after a burn-in period. Additionally, we characterize the asymptotic convergence of the best average sub-optimality gap under diminishing and constant step sizes. Finally, we compare the time complexity of standard solvers with the subgradient algorithm and support our findings with experimental results. This is the first work to analyze subgradient algorithms for system identification with non-smooth objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16673v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Baturalp Yalcin, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>On the Importance of Error Mitigation for Quantum Computation</title>
      <link>https://arxiv.org/abs/2503.17243</link>
      <description>arXiv:2503.17243v1 Announce Type: cross 
Abstract: Quantum error mitigation (EM) is a family of hybrid quantum-classical methods for eliminating or reducing the effect of noise and decoherence on quantum algorithms run on quantum hardware, without applying quantum error correction (EC). While EM has many benefits compared to EC, specifically that it requires no (or little) qubit overhead, this benefit comes with a painful price: EM seems to necessitate an overhead in quantum run time which grows as a (mild) exponent. Accordingly, recent results show that EM alone cannot enable exponential quantum advantages (QAs), for an average variant of the expectation value estimation problem. These works raised concerns regarding the role of EM in the road map towards QAs.
  We aim to demystify the discussion and provide a clear picture of the role of EM in achieving QAs, both in the near and long term. We first propose a clear distinction between finite QA and asymptotic QA, which is crucial to the understanding of the question, and present the notion of circuit volume boost, which we claim is an adequate way to quantify the benefits of EM. Using these notions, we can argue straightforwardly that EM is expected to have a significant role in achieving QAs. Specifically, that EM is likely to be the first error reduction method for useful finite QAs, before EC; that the first such QAs are expected to be achieved using EM in the very near future; and that EM is expected to maintain its important role in quantum computation even when EC will be routinely used - for as long as high-quality qubits remain a scarce resource.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17243v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>cs.CC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dorit Aharonov, Ori Alberton, Itai Arad, Yosi Atia, Eyal Bairey, Zvika Brakerski, Itsik Cohen, Omri Golan, Ilya Gurwich, Oded Kenneth, Eyal Leviatan, Netanel H. Lindner, Ron Aharon Melcer, Adiel Meyer, Gili Schul, Maor Shutman</dc:creator>
    </item>
    <item>
      <title>Blended Conditional Gradients: the unconditioning of conditional gradients</title>
      <link>https://arxiv.org/abs/1805.07311</link>
      <description>arXiv:1805.07311v4 Announce Type: replace-cross 
Abstract: We present a blended conditional gradient approach for minimizing a smooth convex function over a polytope P, combining the Frank--Wolfe algorithm (also called conditional gradient) with gradient-based steps, different from away steps and pairwise steps, but still achieving linear convergence for strongly convex functions, along with good practical performance. Our approach retains all favorable properties of conditional gradient algorithms, notably avoidance of projections onto P and maintenance of iterates as sparse convex combinations of a limited number of extreme points of P. The algorithm is lazy, making use of inexpensive inexact solutions of the linear programming subproblem that characterizes the conditional gradient approach. It decreases measures of optimality (primal and dual gaps) rapidly, both in the number of iterations and in wall-clock time, outperforming even the lazy conditional gradient algorithms of [arXiv:1410.8816]. We also present a streamlined version of the algorithm for the probability simplex.</description>
      <guid isPermaLink="false">oai:arXiv.org:1805.07311v4</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\'abor Braun, Sebastian Pokutta, Dan Tu, Stephen Wright</dc:creator>
    </item>
    <item>
      <title>Parameterized Max Min Feedback Vertex Set</title>
      <link>https://arxiv.org/abs/2302.09604</link>
      <description>arXiv:2302.09604v3 Announce Type: replace-cross 
Abstract: Given a graph $G$ and an integer $k$, Max Min FVS asks whether there exists a minimal set of vertices of size at least $k$ whose deletion destroys all cycles. We present several results that improve upon the state of the art of the parameterized complexity of this problem with respect to both structural and natural parameters.
  Using standard DP techniques, we first present an algorithm of time $\textrm{tw}^{O(\textrm{tw})}n^{O(1)}$, significantly generalizing a recent algorithm of Gaikwad et al. of time $\textrm{vc}^{O(\textrm{vc})}n^{O(1)}$, where $\textrm{tw}, \textrm{vc}$ denote the input graph's treewidth and vertex cover respectively. Subsequently, we show that both of these algorithms are essentially optimal, since a $\textrm{vc}^{o(\textrm{vc})}n^{O(1)}$ algorithm would refute the ETH.
  With respect to the natural parameter $k$, the aforementioned recent work by Gaikwad et al. claimed an FPT branching algorithm with complexity $10^k n^{O(1)}$. We point out that this algorithm is incorrect and present a branching algorithm of complexity $9.34^k n^{O(1)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09604v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis, Nikolaos Melissinos, Manolis Vasilakis</dc:creator>
    </item>
    <item>
      <title>Algorithmic causal structure emerging through compression</title>
      <link>https://arxiv.org/abs/2502.04210</link>
      <description>arXiv:2502.04210v3 Announce Type: replace-cross 
Abstract: We explore the relationship between causality, symmetry, and compression. We build on and generalize the known connection between learning and compression to a setting where causal models are not identifiable. We propose a framework where causality emerges as a consequence of compressing data across multiple environments. We define algorithmic causality as an alternative definition of causality when traditional assumptions for causal identifiability do not hold. We demonstrate how algorithmic causal and symmetric structures can emerge from minimizing upper bounds on Kolmogorov complexity, without knowledge of intervention targets. We hypothesize that these insights may also provide a novel perspective on the emergence of causality in machine learning models, such as large language models, where causal relationships may not be explicitly identifiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04210v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Wendong, Simon Buchholz, Bernhard Sch\"olkopf</dc:creator>
    </item>
    <item>
      <title>Word problems and embedding-obstructions in cellular automata groups on groups</title>
      <link>https://arxiv.org/abs/2503.05572</link>
      <description>arXiv:2503.05572v2 Announce Type: replace-cross 
Abstract: We study groups of reversible cellular automata, or CA groups, on groups. More generally, we consider automorphism groups of subshifts of finite type on groups. It is known that word problems of CA groups on virtually nilpotent groups are in co-NP, and can be co-NP-hard. We show that under the Gap Conjecture of Grigorchuk, their word problems are PSPACE-hard on all other groups. On free and surface groups, we show that they are indeed always in PSPACE. On a group with co-NEXPTIME word problem, CA groups themselves have co-NEXPTIME word problem, and on the lamplighter group (which itself has polynomial-time word problem) we show they can be co-NEXPTIME-hard. We show also two nonembeddability results: the group of cellular automata on a non-cyclic free group does not embed in the group of cellular automata on the integers (this solves a question of Barbieri, Carrasco-Vargas and Rivera-Burgos); and the group of cellular automata in dimension $D$ does not embed in a group of cellular automata in dimension $d$ if $D \geq 3d+2$ (this solves a question of Hochman).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05572v2</guid>
      <category>math.GR</category>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>math.DS</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ville Salo</dc:creator>
    </item>
  </channel>
</rss>
