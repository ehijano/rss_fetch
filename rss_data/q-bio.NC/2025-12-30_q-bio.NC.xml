<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Dec 2025 05:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>JParc: Joint cortical surface parcellation with registration</title>
      <link>https://arxiv.org/abs/2512.22485</link>
      <description>arXiv:2512.22485v1 Announce Type: new 
Abstract: Cortical surface parcellation is a fundamental task in both basic neuroscience research and clinical applications, enabling more accurate mapping of brain regions. Model-based and learning-based approaches for automated parcellation alleviate the need for manual labeling. Despite the advancement in parcellation performance, learning-based methods shift away from registration and atlas propagation without exploring the reason for the improvement compared to traditional methods. In this study, we present JParc, a joint cortical registration and parcellation framework, that outperforms existing state-of-the-art parcellation methods. In rigorous experiments, we demonstrate that the enhanced performance of JParc is primarily attributable to accurate cortical registration and a learned parcellation atlas. By leveraging a shallow subnetwork to fine-tune the propagated atlas labels, JParc achieves a Dice score greater than 90% on the Mindboggle dataset, using only basic geometric features (sulcal depth, curvature) that describe cortical folding patterns. The superior accuracy of JParc can significantly increase the statistical power in brain mapping studies as well as support applications in surgical planning and many other downstream neuroscientific and clinical tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22485v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jian Li, Karthik Gopinath, Brian L. Edlow, Adrian V. Dalca, Bruce Fischl</dc:creator>
    </item>
    <item>
      <title>Nonlinear Dynamical Modeling of Human Intracranial Brain Activity with Flexible Inference</title>
      <link>https://arxiv.org/abs/2512.22785</link>
      <description>arXiv:2512.22785v1 Announce Type: new 
Abstract: Dynamical modeling of multisite human intracranial neural recordings is essential for developing neurotechnologies such as brain-computer interfaces (BCIs). Linear dynamical models are widely used for this purpose due to their interpretability and their suitability for BCIs. In particular, these models enable flexible real-time inference, even in the presence of missing neural samples, which often occur in wireless BCIs. However, neural activity can exhibit nonlinear structure that is not captured by linear models. Furthermore, while recurrent neural network models can capture nonlinearity, their inference does not directly address handling missing observations. To address this gap, recent work introduced DFINE, a deep learning framework that integrates neural networks with linear state-space models to capture nonlinearities while enabling flexible inference. However, DFINE was developed for intracortical recordings that measure localized neuronal populations. Here we extend DFINE to modeling of multisite human intracranial electroencephalography (iEEG) recordings. We find that DFINE significantly outperforms linear state-space models (LSSMs) in forecasting future neural activity. Furthermore, DFINE matches or exceeds the accuracy of a gated recurrent unit (GRU) model in neural forecasting, indicating that a linear dynamical backbone, when paired and jointly trained with nonlinear neural networks, can effectively describe the dynamics of iEEG signals while also enabling flexible inference. Additionally, DFINE handles missing observations more robustly than the baselines, demonstrating its flexible inference and utility for BCIs. Finally, DFINE's advantage over LSSM is more pronounced in high gamma spectral bands. Taken together, these findings highlight DFINE as a strong and flexible framework for modeling human iEEG dynamics, with potential applications in next-generation BCIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22785v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiarash Vaziri, Lucine L. Oganesian, HyeongChan Jo, Roberto M. C. Vera, Charles Y. Liu, Brian Lee, Maryam M. Shanechi</dc:creator>
    </item>
    <item>
      <title>An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making</title>
      <link>https://arxiv.org/abs/2512.23144</link>
      <description>arXiv:2512.23144v1 Announce Type: new 
Abstract: Decision paralysis, i.e. hesitation, freezing, or failure to act despite full knowledge and motivation, poses a challenge for choice models that assume options are already specified and readily comparable. Drawing on qualitative reports in autism research that are especially salient, we propose a computational account in which paralysis arises from convergence failure in a hierarchical decision process. We separate intent selection (what to pursue) from affordance selection (how to pursue the goal) and formalize commitment as inference under a mixture of reverse- and forward-Kullback-Leibler (KL) objectives. Reverse KL is mode-seeking and promotes rapid commitment, whereas forward KL is mode-covering and preserves multiple plausible goals or actions. In static and dynamic (drift-diffusion) models, forward-KL-biased inference yields slow, heavy-tailed response times and two distinct failure modes, intent saturation and affordance saturation, when values are similar. Simulations in multi-option tasks reproduce key features of decision inertia and shutdown, treating autism as an extreme regime of a general, inference-based, decision-making continuum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23144v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wendyam Eric Lionel Ilboudo, Saori C Tanaka</dc:creator>
    </item>
    <item>
      <title>A Network of Biologically Inspired Rectified Spectral Units (ReSUs) Learns Hierarchical Features Without Error Backpropagation</title>
      <link>https://arxiv.org/abs/2512.23146</link>
      <description>arXiv:2512.23146v1 Announce Type: new 
Abstract: We introduce a biologically inspired, multilayer neural architecture composed of Rectified Spectral Units (ReSUs). Each ReSU projects a recent window of its input history onto a canonical direction obtained via canonical correlation analysis (CCA) of previously observed past-future input pairs, and then rectifies either its positive or negative component. By encoding canonical directions in synaptic weights and temporal filters, ReSUs implement a local, self-supervised algorithm for progressively constructing increasingly complex features.
  To evaluate both computational power and biological fidelity, we trained a two-layer ReSU network in a self-supervised regime on translating natural scenes. First-layer units, each driven by a single pixel, developed temporal filters resembling those of Drosophila post-photoreceptor neurons (L1/L2 and L3), including their empirically observed adaptation to signal-to-noise ratio (SNR). Second-layer units, which pooled spatially over the first layer, became direction-selective -- analogous to T4 motion-detecting cells -- with learned synaptic weight patterns approximating those derived from connectomic reconstructions.
  Together, these results suggest that ReSUs offer (i) a principled framework for modeling sensory circuits and (ii) a biologically grounded, backpropagation-free paradigm for constructing deep self-supervised neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23146v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shanshan Qin, Joshua L. Pughe-Sanford, Alexander Genkin, Pembe Gizem Ozdil, Philip Greengard, Anirvan M. Sengupta, Dmitri B. Chklovskii</dc:creator>
    </item>
    <item>
      <title>Somatosensory prediction in premature neonates: iatrogenic pain experience increases repetition suppression and deviance detection of innocuous stimuli in a tactile oddball protocol</title>
      <link>https://arxiv.org/abs/2512.23301</link>
      <description>arXiv:2512.23301v1 Announce Type: new 
Abstract: Sensory prediction (SP) is a fundamental mechanism of perception that supports cognitive development. Atypical SP has been reported across multiple neurodevelopmental disorders (ND), suggesting it may constitute an early cross-syndromic marker. Premature birth is a major risk factor for ND, with risk increasing as gestational age (GA) at birth decreases. However, how perinatal risk factors shape the development of SP remains poorly understood. We do not know if untimely birth itself, or exposure to iatrogenic pain during neonatal intensive care, cause neurodevelopmental impairments. In this study, we first assessed whether SP can be detected in the brains of premature neonates at 35 weeks corrected GA using a tactile oddballomission paradigm with EEG. We then examined the effects of the degree of prematurity and of the exposure to painful care procedures on neural indices of SP. Results demonstrate the presence of repetition suppression (RS) and a mismatch response (MMR) to deviant stimuli in the contralateral somatosensory cortex of premature neonates. The amplitude of these SP proxies was significantly affected by the number of painful procedures experienced since birth, independently of the effect of GA at birth. Contrary to our initial hypothesis that greater neurodevelopmental risk would be associated with less mature SP, infants with higher exposure to pain exhibited more robust indices of SP. These findings suggest that increased ex utero experience, even painful, is associated with accelerated maturation of predictive somatosensory processing. Longitudinal follow-up of participants at age 2 will explore how these early markers relate to developmental outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23301v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anne-Lise Marais (COMETE), Victoria Dumont (COMETE), Marie Anquetil (LPCN), Arnaud Mortier (LMNO), Anne-Sophie Trentesaux (CHU Caen Normandie), Nadege Roche-Labarbe (COMETE)</dc:creator>
    </item>
    <item>
      <title>Dynamical incompatibilities in paced finger tapping experiments</title>
      <link>https://arxiv.org/abs/2512.23661</link>
      <description>arXiv:2512.23661v1 Announce Type: new 
Abstract: The behavioral description of the sensorimotor synchronization phenomenon in humans is exhaustive, mostly by using variations of the traditional paced finger-tapping task. This task helps unveil the inner workings of the error-correction mechanism responsible for the resynchronization after a perturbation to the period of the stimuli sequence. Yet, fundamental contradictions still exist among different works in the literature. One of such contradictions only emerges after comparing the two most-common period perturbation types: step changes and phase shifts. The stimulus sequence is exactly the same in both perturbation types up to and including the (unexpected) perturbed stimulus. Why then would the timing of the next response be different between perturbation types, as observed? The explanation lies in the buildup of different temporal contexts during the experiments that recalibrate the error-correction mechanism. Here we show, both experimentally and theoretically, that responses to different perturbation types are dynamically incompatible when they occur in separate experiments. That is, they can't be represented by the same underlying dynamical system, thus explaining many contradictory results and the difficulty in reproducing both types of perturbations with a single mathematical model. On the other hand, if both perturbation types are presented at random during the same experiment then the responses are compatible with each other and can be construed as produced by a unique underlying mechanism. We conclude that a single underlying dynamical system can represent the response to all perturbation types, signs, and sizes, which is nevertheless recalibrated by temporal context. Our results offer a ground for performing better comparisons in paced finger tapping and extend the usable range of data beyond the perturbed stimulus and into the information-rich resynchronization phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23661v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ariel D. Silva, Claudia R. Gonz\'alez, Rodrigo Laje</dc:creator>
    </item>
    <item>
      <title>Lessons from Neuroscience for AI: How integrating Actions, Compositional Structure and Episodic Memory could enable Safe, Interpretable and Human-Like AI</title>
      <link>https://arxiv.org/abs/2512.22568</link>
      <description>arXiv:2512.22568v1 Announce Type: cross 
Abstract: The phenomenal advances in large language models (LLMs) and other foundation models over the past few years have been based on optimizing large-scale transformer models on the surprisingly simple objective of minimizing next-token prediction loss, a form of predictive coding that is also the backbone of an increasingly popular model of brain function in neuroscience and cognitive science. However, current foundation models ignore three other important components of state-of-the-art predictive coding models: tight integration of actions with generative models, hierarchical compositional structure, and episodic memory. We propose that to achieve safe, interpretable, energy-efficient, and human-like AI, foundation models should integrate actions, at multiple scales of abstraction, with a compositional generative architecture and episodic memory. We present recent evidence from neuroscience and cognitive science on the importance of each of these components. We describe how the addition of these missing components to foundation models could help address some of their current deficiencies: hallucinations and superficial understanding of concepts due to lack of grounding, a missing sense of agency/responsibility due to lack of control, threats to safety and trustworthiness due to lack of interpretability, and energy inefficiency. We compare our proposal to current trends, such as adding chain-of-thought (CoT) reasoning and retrieval-augmented generation (RAG) to foundation models, and discuss new ways of augmenting these models with brain-inspired components. We conclude by arguing that a rekindling of the historically fruitful exchange of ideas between brain science and AI will help pave the way towards safe and interpretable human-centered AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22568v1</guid>
      <category>cs.AI</category>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajesh P. N. Rao, Vishwas Sathish, Linxing Preston Jiang, Matthew Bryan, Prashant Rangarajan</dc:creator>
    </item>
    <item>
      <title>The body is not there to compute: Comment on "Informational embodiment: Computational role of information structure in codes and robots" by Pitti et al</title>
      <link>https://arxiv.org/abs/2512.22868</link>
      <description>arXiv:2512.22868v1 Announce Type: cross 
Abstract: Applying the lens of computation and information has been instrumental in driving the technological progress of our civilization as well as in empowering our understanding of the world around us. The digital computer was and for many still is the leading metaphor for how our mind operates. Information theory (IT) has also been important in our understanding of how nervous systems encode and process information. The target article deploys information and computation to bodies: to understand why they have evolved in particular ways (animal bodies) and to design optimal bodies (robots). In this commentary, I argue that the main role of bodies is not to compute.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22868v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.plrev.2025.11.003</arxiv:DOI>
      <arxiv:journal_reference>Physics of Life Reviews 55, 250-252 (2025)</arxiv:journal_reference>
      <dc:creator>Matej Hoffmann</dc:creator>
    </item>
    <item>
      <title>Graph Neural Networks with Transformer Fusion of Brain Connectivity Dynamics and Tabular Data for Forecasting Future Tobacco Use</title>
      <link>https://arxiv.org/abs/2512.23137</link>
      <description>arXiv:2512.23137v1 Announce Type: cross 
Abstract: Integrating non-Euclidean brain imaging data with Euclidean tabular data, such as clinical and demographic information, poses a substantial challenge for medical imaging analysis, particularly in forecasting future outcomes. While machine learning and deep learning techniques have been applied successfully to cross-sectional classification and prediction tasks, effectively forecasting outcomes in longitudinal imaging studies remains challenging. To address this challenge, we introduce a time-aware graph neural network model with transformer fusion (GNN-TF). This model flexibly integrates both tabular data and dynamic brain connectivity data, leveraging the temporal order of these variables within a coherent framework. By incorporating non-Euclidean and Euclidean sources of information from a longitudinal resting-state fMRI dataset from the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA), the GNN-TF enables a comprehensive analysis that captures critical aspects of longitudinal imaging data. Comparative analyses against a variety of established machine learning and deep learning models demonstrate that GNN-TF outperforms these state-of-the-art methods, delivering superior predictive accuracy for predicting future tobacco usage. The end-to-end, time-aware transformer fusion structure of the proposed GNN-TF model successfully integrates multiple data modalities and leverages temporal dynamics, making it a valuable analytic tool for functional brain imaging studies focused on clinical outcome prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23137v1</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runzhi Zhou, Xi Luo</dc:creator>
    </item>
    <item>
      <title>A Paradigm Shift in Human Neuroscience Research: Progress, Prospects, and a Proof of Concept for Population Neuroscience</title>
      <link>https://arxiv.org/abs/2212.04195</link>
      <description>arXiv:2212.04195v3 Announce Type: replace 
Abstract: Recent advances and reflections on reproducible human neuroscience, especially brain-wide association studies (BWAS) leveraging large datasets, have led to divergent and sometimes opposing views on research practices and priorities. The debates span multiple dimensions. Shifts along these axes have fractured consensus and further fragmented an already heterogeneous field of cognitive neuroscience. Here, we sketch a holistic and integrative response grounded in population neuroscience, organized around a closed-loop "design-analysis-interpretation" research cycle that aims to build consensus while bridging these divides. Our central claim is that population neuroscience offers a unique population-level vantage point for identifying general principles, characterizing inter-individual variabilities, and benchmarking intra-individual changes, thereby providing a supportive framework for small-scale, mechanism-focused studies at the individual level and allowing them to co-evolve with population-level studies. Population neuroscience is not simply about providing larger N for BWAS; its deeper goal is to accumulate a family of cross-scale priors and shared infrastructures that can support design, analysis, and interpretation of human neuroscience for decades to come. In this sense, we outline a "third-generation" view of population neuroscience that reorients the field from amassing isolated associations toward building integrative reference frameworks for future mechanistic and translational work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04195v3</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zi-Xuan Zhou, Xi-Nian Zuo</dc:creator>
    </item>
    <item>
      <title>EM and XRM Connectomics Imaging and Experimental Metadata Standards</title>
      <link>https://arxiv.org/abs/2401.15251</link>
      <description>arXiv:2401.15251v2 Announce Type: replace 
Abstract: High resolution volumetric neuroimaging datasets from electron microscopy (EM) and x-ray micro and holographic-nano tomography (XRM/XHN) are being generated at an increasing rate and by a growing number of research teams. These datasets are derived from an increasing number of species, in an increasing number of brain regions, and with an increasing number of techniques. Each of these large-scale datasets, often surpassing petascale levels, is typically accompanied by a unique and varied set of metadata. These datasets can be used to derive connectomes, or neuron-synapse level connectivity diagrams, to investigate the fundamental organization of neural circuitry, neuronal development, and neurodegenerative disease. Standardization is essential to facilitate comparative connectomics analysis and enhance data utilization. Although the neuroinformatics community has successfully established and adopted data standards for many modalities, this effort has not yet encompassed EM and XRM/ XHN connectomics data. This lack of standardization isolates these datasets, hindering their integration and comparison with other research performed in the field. Towards this end, our team formed a working group consisting of community stakeholders to develop Image and Experimental Metadata Standards for EM and XRM/XHN data to ensure the scientific impact and further motivate the generation and sharing of these data. This document addresses version 1.1 of these standards, aiming to support metadata services and future software designs for community collaboration. Standards for derived annotations are described in a companion document. Standards definitions are available on a community github page. We hope these standards will enable comparative analysis, improve interoperability between connectomics software tools, and continue to be refined and improved by the neuroinformatics community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15251v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miguel E. Wimbish, Nicole K. Guittari, Victoria A. Rose, Jorge L. Rivera Jr, Patricia K. Rivlin, Mark A. Hinton, Jordan K. Matelsky, Nicole E. Stock, Brock A. Wester, Erik C. Johnson, William R. Gray-Roncal</dc:creator>
    </item>
    <item>
      <title>Linton Stereo Illusion</title>
      <link>https://arxiv.org/abs/2408.00770</link>
      <description>arXiv:2408.00770v3 Announce Type: replace 
Abstract: We present a new illusion that challenges our understanding of stereo vision. The illusion consists of a larger circle at 50cm, and smaller circle in front of it at 40cm, with constant angular sizes throughout. We move the larger circle forward by 10cm (to 40cm) and then back again (to 50cm). The question is, what distance should we move the smaller circle forward and back to maintain a constant perceived separation in depth between the circles? Constant physical distance (10cm) or constant retinal disparity (6.7cm)? Observers choose constant disparity. We therefore argue the 'Linton Stereo Illusion' appears to suggest that perceived stereo depth reflects retinal disparities rather than 3D geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00770v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Linton</dc:creator>
    </item>
    <item>
      <title>DCHO: A Decomposition-Composition Framework for Predicting Higher-Order Brain Connectivity to Enhance Diverse Downstream Applications</title>
      <link>https://arxiv.org/abs/2509.09696</link>
      <description>arXiv:2509.09696v2 Announce Type: replace 
Abstract: Higher-order brain connectivity (HOBC), which captures interactions among three or more brain regions, provides richer organizational information than traditional pairwise functional connectivity (FC). Recent studies have begun to infer latent HOBC from noninvasive imaging data, but they mainly focus on static analyses, limiting their applicability in dynamic prediction tasks. To address this gap, we propose DCHO, a unified approach for modeling and forecasting the temporal evolution of HOBC based on a Decomposition-Composition framework, which is applicable to both non-predictive tasks (state classification) and predictive tasks (brain dynamics forecasting). DCHO adopts a decomposition-composition strategy that reformulates the prediction task into two manageable subproblems: HOBC inference and latent trajectory prediction. In the inference stage, we propose a dual-view encoder to extract multiscale topological features and a latent combinatorial learner to capture high-level HOBC information. In the forecasting stage, we introduce a latent-space prediction loss to enhance the modeling of temporal trajectories. Extensive experiments on multiple neuroimaging datasets demonstrate that DCHO achieves superior performance in both non-predictive tasks (state classification) and predictive tasks (brain dynamics forecasting), significantly outperforming existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09696v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weibin Li, Wendu Li, Quanying Liu</dc:creator>
    </item>
    <item>
      <title>Identifying Autism-Related Neurobiomarkers Using Hybrid Deep Learning Models</title>
      <link>https://arxiv.org/abs/2510.13841</link>
      <description>arXiv:2510.13841v2 Announce Type: replace 
Abstract: Autism spectrum disorder (ASD) has been associated with structural alterations across cortical and subcortical regions. Quantitative neuroimaging enables large-scale analysis of these neuroanatomical patterns. This project used structural MRI (T1-weighted) data from the publicly available ABIDE I dataset (n = 1,112) to classify ASD and control participants using a hybrid model. A 3D convolutional neural network (CNN) was trained to learn neuroanatomical feature representations, which were then passed to a support vector machine (SVM) for final classification. Gradient-weighted class activation mapping (Grad-CAM) was applied to the CNN to visualize the brain regions that contributed most to the model predictions. The Grad-CAM difference maps showed strongest relevance along cortical boundary regions, with additional emphasis in midline frontal-temporal-parietal areas, which is broadly consistent with prior ASD neuroimaging findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13841v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Chen</dc:creator>
    </item>
    <item>
      <title>Topologically Invariant Permutation Test</title>
      <link>https://arxiv.org/abs/2511.06153</link>
      <description>arXiv:2511.06153v2 Announce Type: replace 
Abstract: Functional brain networks exhibit topological structures that reflect neural organization; however, statistical comparison of these networks is challenging for several reasons. This paper introduces a topologically invariant permutation test for detecting topological inequivalence. Under topological equivalence, topological features can be permuted separately between groups without distorting individual network structures. The test statistic uses $2$-Wasserstein distances on persistent diagrams, computed in closed form. To reduce variability in brain connectivities while preserving topology, heat kernel expansion on the Hodge Laplacian is applied with bandwidth $t$ controlling diffusion intensity. Theoretical results guarantee variance reduction through optimal Hilbert space projection. Simulations across diverse network topologies show superior performance compared to conventional two-sample tests and alternative metrics. Applied to resting-state fMRI data from the Multimodal Treatment of ADHD study, the method detects significant topological differences between cannabis users and non-users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06153v2</guid>
      <category>q-bio.NC</category>
      <category>math.AT</category>
      <category>stat.ME</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sixtus Dakurah</dc:creator>
    </item>
    <item>
      <title>Cross-Population Amplitude Coupling in High-Dimensional Oscillatory Neural Time Series</title>
      <link>https://arxiv.org/abs/2105.03508</link>
      <description>arXiv:2105.03508v4 Announce Type: replace-cross 
Abstract: Neural oscillations have long been considered important markers of interaction across brain regions, yet identifying coordinated oscillatory activity from high-dimensional multiple-electrode recordings remains challenging. We sought to quantify time-varying covariation of oscillatory amplitudes across two brain regions, during a memory task, based on local field potentials recorded from 96 electrodes in each region. We extended Canonical Correlation Analysis (CCA) to multiple time series through the cross-correlation of latent time series. This, however, introduces a large number of possible lead-lag cross-correlations across the two regions. To manage that high dimensionality we developed rigorous statistical procedures aimed at finding a small number of dominant lead-lag effects. The method correctly identified ground truth structure in realistic simulation-based settings. When we used it to analyze local field potentials recorded from prefrontal cortex and visual area V4 we obtained highly plausible results. The new statistical methodology could also be applied to other slowly-varying high-dimensional time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.03508v4</guid>
      <category>stat.ME</category>
      <category>q-bio.NC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heejong Bong, Val\'erie Ventura, Eric A. Yttri, Matthew A. Smith, Robert E. Kass</dc:creator>
    </item>
  </channel>
</rss>
