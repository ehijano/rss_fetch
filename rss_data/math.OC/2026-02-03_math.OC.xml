<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 03:02:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dual Quaternion SE(3) Synchronization with Recovery Guarantees</title>
      <link>https://arxiv.org/abs/2602.00324</link>
      <description>arXiv:2602.00324v1 Announce Type: new 
Abstract: Synchronization over the special Euclidean group SE(3) aims to recover absolute poses from noisy pairwise relative transformations and is a core primitive in robotics and 3D vision. Standard approaches often require multi-step heuristic procedures to recover valid poses, which are difficult to analyze and typically lack theoretical guarantees. This paper adopts a dual quaternion representation and formulates SE(3) synchronization directly over the unit dual quaternion. A two-stage algorithm is developed: A spectral initializer computed via the power method on a Hermitian dual quaternion measurement matrix, followed by a dual quaternion generalized power method (DQGPM) that enforces feasibility through per-iteration projection. The estimation error bounds are established for spectral estimators, and DQGPM is shown to admit a finite-iteration error bound and achieves linear error contraction up to an explicit noise-dependent threshold. Experiments on synthetic benchmarks and real-world multi-scan point-set registration demonstrate that the proposed pipeline improves both accuracy and efficiency over representative matrix-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00324v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianing Zhao, Linglingzhi Zhu, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Efficiency-Reward Trade-Off in Queues with Dynamic Arrivals</title>
      <link>https://arxiv.org/abs/2602.00351</link>
      <description>arXiv:2602.00351v1 Announce Type: new 
Abstract: Motivated by applications in online marketplaces such as ride-hailing platforms and payment channel networks, we study a single-server queue with state-dependent arrival control. The service operator dynamically chooses the arrival rate as a function of the current queue length and receives a reward determined by the induced rate, capturing objectives such as throughput, revenue, or social welfare. The goal is to design control policies that simultaneously achieve high long-run operating reward and low congestion, measured by the expected steady-state queue length.
  We adopt a regret-based framework relative to an optimal benchmark and characterize the efficiency--reward trade-off under an $\varepsilon$-optimal reward constraint. Our results reveal a sharp dichotomy between small-market and large-market regimes. In small markets, including state-independent policies, any admissible control incurs poor efficiency, with the expected queue length growing on the order of $1/\varepsilon$. In contrast, in large markets, state-dependent policies can achieve substantially better performance. When the reward function exhibits sufficient curvature, the optimal queue length scales as $\Theta(1/\sqrt{\varepsilon})$; otherwise, it scales as $\Theta(\log(1/\varepsilon))$.
  For each regime, we establish universal lower bounds on the achievable efficiency and construct simple state-dependent policies that attain these bounds. Our results provide a non-asymptotic heavy-traffic characterization for queues with dynamic arrivals and offer structural insights into the design of efficient pricing and admission control policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00351v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianze Qu, Sushil Mahavir Varma</dc:creator>
    </item>
    <item>
      <title>Learning Safety-Guaranteed, Non-Greedy Control Barrier Functions Using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2602.00366</link>
      <description>arXiv:2602.00366v1 Announce Type: new 
Abstract: Spacecraft rendezvous and proximity operations (RPO) pose safety risks to high-value assets, so formal safety guarantees are critical. Yet conservative safety controllers can reduce mission efficiency. We propose a unified two-stage reinforcement learning (RL) framework that addresses two complementary limitations of Input-Constrained Control Barrier Functions (ICCBFs) for safety-critical, fuel-limited spacecraft control. Given a certified safe set S, ICCBFs guarantee forward invariance of an inner set C* under input bounds, but the resulting per-step quadratic programme (QP) is greedy and fuel-inefficient within C*, and recoverable states outside C* are conservatively discarded. Stage 1 learns state-dependent class-K-infinity parameters that adapt ICCBF/CLF decay rates, embedding long-horizon cost awareness while preserving invariance in C*. Stage 2 learns a residual barrier h_RL(x) that certifies recoverability for a subset of S minus C*. At run time, the controller selects the appropriate barrier formulation (Stage 1 or Stage 2) and solves a lightweight ZOH QP. Both stages are trained with PPO using rewards that penalise constraint violations, control effort, and task metrics. We evaluate three benchmarks: cruise control, spacecraft rendezvous with a rotating target, and inspection that maximises observability subject to keep-in and keep-out zone constraints. Across test cases, the method reduces median fuel relative to ICCBF baselines by 12 to 25 percent and increases the fraction of trajectories that remain in S by 7 to 8 percent, while retaining real-time QP complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00366v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minduli Wijayatunga, Nathan Wallace, Salah Sukkarieh, Roberto Armellin</dc:creator>
    </item>
    <item>
      <title>A Hybrid Relaxation-Heuristic Framework for Solving MIP with Binary Variables</title>
      <link>https://arxiv.org/abs/2602.00429</link>
      <description>arXiv:2602.00429v1 Announce Type: new 
Abstract: Mixed-Integer Programming (MIP), particularly Mixed-Integer Linear Programming (MILP) and Mixed-Integer Quadratic Programming (MIQP), has found extensive applications in domains such as portfolio optimization and network flow control, which inclusion of integer variables or cardinality constraints renders these problems NP-hard, posing significant computational challenges. While traditional approaches have explored approximation methods like heuristics and relaxation techniques (e.g. Lagrangian dual relaxation), the integration of these strategies within a unified hybrid framework remains underexplored. In this paper, we propose a generalized hybrid framework to address MIQP problems with binary variables, which consists of two phases: (1) a Mixed Relaxation Phase, which employs Linear Relaxation, Duality Relaxation, and Augmented Relaxation with randomized sampling to generate a diverse pre-solution pool, and (2) a Heuristic Optimization Phase, which refines the pool using Genetic Algorithms and Variable Neighborhood Search (VNS) to approximate binary solutions effectively. Becuase of the page limit, we will only detailedly evaluate the proposed framework on portfolio optimization problems using benchmark datasets from the OR Library, where the experimental results demonstrate state-of-the-art performance, highlighting the framework's ability to solve larger and more complex MIP problems efficiently. This study offers a robust and flexible methodology that bridges relaxation techniques and heuristic optimization, advancing the practical solvability of challenging MIP problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00429v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zayn Wang</dc:creator>
    </item>
    <item>
      <title>Exact Instance Compression for Convex Empirical Risk Minimization via Color Refinement</title>
      <link>https://arxiv.org/abs/2602.00437</link>
      <description>arXiv:2602.00437v1 Announce Type: new 
Abstract: Empirical risk minimization (ERM) can be computationally expensive, with standard solvers scaling poorly even in the convex setting. We propose a novel lossless compression framework for convex ERM based on color refinement, extending prior work from linear programs and convex quadratic programs to a broad class of differentiable convex optimization problems. We develop concrete algorithms for a range of models, including linear and polynomial regression, binary and multiclass logistic regression, regression with elastic-net regularization, and kernel methods such as kernel ridge regression and kernel logistic regression. Numerical experiments on representative datasets demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00437v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bryan Zhu, Ziang Chen</dc:creator>
    </item>
    <item>
      <title>On the Analysis of Misspecified Variational Inequalities with Nonlinear Constraints</title>
      <link>https://arxiv.org/abs/2602.00448</link>
      <description>arXiv:2602.00448v1 Announce Type: new 
Abstract: In this paper, we study a class of misspecified variational inequalities (VIs) where both the monotone operator and nonlinear convex constraints depend on an unknown parameter learned via a secondary VI. Existing data-driven VI methods typically follow a decoupled learn-then-optimize scheme, causing the approximation error from the learning to propagate the main decision-making problem and hinder convergence. We instead consider a simultaneous approach that jointly solves the main and secondary VIs. To efficiently handle nonlinear constraints with parameter misspecification, we propose a single-loop inexact Augmented Lagrangian method that simultaneously updates the primal decision variables, dual multipliers, and the misspecified parameter. The method combines a forward-reflected-backward step with an Augmented Lagrangian penalty, and explicitly handles misspecification on both the operator and constraint functions. Moreover, we introduce a relaxed performance metric based on the Minty VI gap combined with an aggregated infeasibility metric. By proving boundedness of the dual iterates, we establish $\mathcal{O}(1/K)$ ergodic convergence rates for these metrics. Numerical Experiments are provided to showcase the superior performance of our algorithm compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00448v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Novel Kumar Dey, Mohammad Mahdi Ahmadi, Erfan Yazdandoost Hamedani, Afrooz Jalilzadeh</dc:creator>
    </item>
    <item>
      <title>Extending Meshulam's result on the boundedness of orbits of relaxed projections onto affine subspaces from finite to infinite-dimensional Hilbert spaces</title>
      <link>https://arxiv.org/abs/2602.00544</link>
      <description>arXiv:2602.00544v1 Announce Type: new 
Abstract: In 1996, Meshulam proved that any sequence generated in Euclidean space by randomly projecting onto affine subspaces drawn from a finite collection stays bounded even if the intersection of the subspaces is empty. His proof, which works even for relaxed projections, relies on an ingenious induction on the dimension of the Euclidean space.
  In this paper, we extend Meshulam's result to the general Hilbert space setting by an induction proof of the number of affine subspaces in the given collection. We require that the corresponding parallel linear subspaces are innately regular -- this assumption always holds in Euclidean space. We also discuss the sharpness of our result and make a connection to randomized block Kaczmarz methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00544v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heinz H. Bauschke, Tran Thanh Tung</dc:creator>
    </item>
    <item>
      <title>Deterministic Zeroth-Order Mirror Descent via Vector Fields with A Posteriori Certification</title>
      <link>https://arxiv.org/abs/2602.00634</link>
      <description>arXiv:2602.00634v1 Announce Type: new 
Abstract: We develop a deterministic zeroth-order mirror descent framework by replacing gradients with a general vector field, yielding a vector-field-driven mirror update that preserves Bregman geometry while accommodating derivative-free oracles. Our analysis provides a unified evaluation template for last-iterate function values under a relative-smoothness-type inequality, with an emphasis on trajectory-wise (a posteriori) certification: whenever a verifiable inequality holds along the realized iterates, we obtain explicit last-iterate guarantees. The framework subsumes a broad class of information-geometric algorithms, including generalized Blahut-Arimoto-type updates, by expressing their dynamics through suitable choices of the vector field. We then instantiate the theory with deterministic central finite differences in moderate dimension, where constructing the vector field via deterministic central finite differences requires 2d off-center function values (and one reusable center value), i.e., 2d+1 evaluations in total, where d is the number of input real numbers. In this deterministic finite-difference setting, the key interface property is not classical convexity alone but a punctured-neighborhood generalized star-convexity condition that isolates an explicit resolution-dependent error floor. Establishing this property for the finite-difference vector field reduces to a robust conic dominance design problem; we give an explicit scaling rule ensuring the required uniform dominance on a circular cone. Together, these results expose a hidden geometric structure linking Bregman telescoping identities, deterministic certification, and robust conic geometry in zeroth-order mirror descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00634v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahito Hayashi</dc:creator>
    </item>
    <item>
      <title>Properties of Measure Controls and Their Trajectories</title>
      <link>https://arxiv.org/abs/2602.00752</link>
      <description>arXiv:2602.00752v1 Announce Type: new 
Abstract: This paper deals with the concepts of measure controls and of measure vector fields, within the mathematical framework of measure differential equations (MDEs), recently proposed in~\cite{piccoli_measure_2019}. Measure controls can be seen as a generalization of relaxed control. Moreover, they are particularly suitable for studying dynamics with uncertainty.
  The main results of this paper include establishing the existence and well-posedness of control systems with measure controls and proving the equivalence between measure controls and measure vector fields. The stability and closure properties of the trajectory set are also studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00752v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mauro Garavello, Xiaoqian Gong, Benedetto Piccoli</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Jacobian-Free Backpropagation for Optimal Control Problems with Implicit Hamiltonians</title>
      <link>https://arxiv.org/abs/2602.00921</link>
      <description>arXiv:2602.00921v1 Announce Type: new 
Abstract: Optimal feedback control with implicit Hamiltonians poses a fundamental challenge for learning-based value function methods due to the absence of closed-form optimal control laws. Recent work~\cite{gelphman2025end} introduced an implicit deep learning approach using Jacobian-Free Backpropagation (JFB) to address this setting, but only established sample-wise descent guarantees. In this paper, we establish convergence guarantees for JFB in the stochastic minibatch setting, showing that the resulting updates converge to stationary points of the expected optimal control objective. We further demonstrate scalability on substantially higher-dimensional problems, including multi-agent optimal consumption and swarm-based quadrotor and bicycle control. Together, our results provide both theoretical justification and empirical evidence for using JFB in high-dimensional optimal control with implicit Hamiltonians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00921v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Gelphman, Deepanshu Verma, Nicole Tianjiao Yang, Stanley Osher, Samy Wu Fung</dc:creator>
    </item>
    <item>
      <title>An Efficient Memory Gradient Method for Extreme M-Eigenvalues of Elastic type Tensors</title>
      <link>https://arxiv.org/abs/2602.01152</link>
      <description>arXiv:2602.01152v1 Announce Type: new 
Abstract: M-eigenvalues of fourth order hierarchically symmetric tensors play a significant role in nonlinear elastic material analysis and quantum entanglement problems. This paper focuses on computing extreme M-eigenvalues for such tensors. To achieve this, we first reformulate the M-eigenvalue problem as a sequence of unconstrained optimization problems by introducing a shift parameter. Subsequently, we develop a memory gradient method specifically designed to approximate these extreme M-eigenvalues. Under this framework, we establish the global convergence of the proposed method. Finally, comprehensive numerical experiments demonstrate the efficacy and stability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01152v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuolin Du, Yisheng Song</dc:creator>
    </item>
    <item>
      <title>Computationally Tractable Robust Nonlinear Model Predictive Control using DC Programming</title>
      <link>https://arxiv.org/abs/2602.01164</link>
      <description>arXiv:2602.01164v1 Announce Type: new 
Abstract: We propose a computationally tractable, tube-based robust nonlinear model predictive control (MPC) framework using difference-of-convex (DC) functions and sequential convex programming. For systems with differentiable discrete time dynamics, we show how to construct systematic, data-driven DC model representations using polynomials and machine learning techniques. We develop a robust tube MPC scheme that convexifies the online optimization by linearizing the concave components of the model, and we provide guarantees of recursive feasibility and robust stability. We present three data-driven procedures for computing DC models and compare performance using a planar vertical take-off and landing (PVTOL) aircraft case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01164v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martin Doff-Sotta, Zaheen A-Rahman, Mark Cannon</dc:creator>
    </item>
    <item>
      <title>Heuristics for the Worst Optimal Value of Interval Transportation Problems</title>
      <link>https://arxiv.org/abs/2602.01209</link>
      <description>arXiv:2602.01209v1 Announce Type: new 
Abstract: An interval transportation problem represents a model for a transportation problem in which the values of supply, demand, and transportation costs are affected by uncertainty and can vary independently within given interval ranges. One of the main tasks of solving interval programming models is computing the best and worst optimal value over all possible choices of the interval data. Although the best optimal value of an interval transportation problem can be computed in polynomial time, computing the worst (finite) optimal value was proved to be NP-hard. In this paper, we strengthen a previous result showing a quasi-extreme decomposition for finding the worst optimal value, and building on the result, we design heuristics for efficiently approximating the value. Using a simplified encoding of the scenarios, we first derive a local search method and a genetic algorithm for approximating the worst optimal value. Then, we integrate the two methods into a memetic algorithm, which combines the evolutionary improvement of a genetic algorithm with individual learning implemented via local search. Moreover, we include numerical experiments for a practical comparison of the three different approaches. We also show that the proposed memetic algorithm is competitive with the available state-of-the-art methods for approximating the worst optimal value of interval transportation problems, this is demonstrated by finding the new best solutions for several instances, among others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01209v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elif Radov\'a Garajov\'a, Miroslav Rada</dc:creator>
    </item>
    <item>
      <title>Novel closed-loop controllers for fractional linear quadratic tracking systems</title>
      <link>https://arxiv.org/abs/2602.01251</link>
      <description>arXiv:2602.01251v1 Announce Type: new 
Abstract: Anew method for finding closed-loop optimal controllers of fractional tracking quadratic optimal control problems is introduced. The optimality conditions for the fractional optimal control problem are obtained. Illustrative examples are presented to show the applicability and capabilities of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01251v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iman Malmir</dc:creator>
    </item>
    <item>
      <title>Global stabilization and finite element analysis of the viscous Burgers' equation with memory subject to Neumann boundary feedback control</title>
      <link>https://arxiv.org/abs/2602.01321</link>
      <description>arXiv:2602.01321v1 Announce Type: new 
Abstract: This paper presents a global stabilization result of the viscous Burgers' equation with the memory term by applying Neumann boundary feedback control laws. We construct suitable feedback control inputs using the control Lyapunov functional and establish stabilization in the \(L^{2}, H^{1},\) and \(H^{2}\)-norms. The existence and uniqueness of the solution are established through the Faedo-Galerkin method. Moreover, we show the global stabilization where the diffusion coefficient $\nu$ is unknown. Then, we apply a \(C^{0}\)-conforming finite element method to the spatial variable while keeping the time variable continuous. Furthermore, we obtain global stabilization of the semi-discrete scheme and optimal error estimates for the state variable in the \(L^{\infty}\), \(L^{2}\), and \(H^{1}\)-norms, using the Ritz-Volterra projection. Additionally, error estimates for the feedback control laws are established. Lastly, we present some numerical simulations to demonstrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01321v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shishu Pal Singh, Sudeep Kundu</dc:creator>
    </item>
    <item>
      <title>On Poly-Quadratic Stabilizability and Detectability of Polytopic LPV Systems</title>
      <link>https://arxiv.org/abs/2602.01337</link>
      <description>arXiv:2602.01337v1 Announce Type: new 
Abstract: In this technical communique, we generalize the well-known Lyapunov-based stabilizability and detectability tests for discrete-time linear time-invariant systems to polytopic linear parameter-varying systems using the class of so-called poly-quadratic Lyapunov functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01337v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. J. Meijer, V. S. Dolk, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Minimum cost network flow with interval capacities: The worst-case scenario</title>
      <link>https://arxiv.org/abs/2602.01360</link>
      <description>arXiv:2602.01360v1 Announce Type: new 
Abstract: We study the problem of determining the worst optimal value and characterizing the corresponding worst-case scenarios in minimum cost network flow problems with interval uncertainty in arc capacities. In this setting, each capacity can take any value within its specified lower and upper bounds. We prove that computing the worst optimal value is a strongly NP-hard problem and remains NP-hard even when restricted to series-parallel graphs. Further, we propose a mixed-integer linear programming formulation that computes the exact worst optimal value, as well as a pseudopolynomial-time algorithm designed for the special case of series-parallel graphs. We also examine the structural properties of the most extremal worst-case scenarios and show that the arcs whose capacities are not fixed at their interval bounds form a forest. This result establishes an upper bound on the number of such arcs, which we show to be tight by constructing a class of instances in which the bound is attained. Finally, we investigate the more-for-less paradox in minimum cost network flow problems with interval capacities, which occurs in instances where increasing the required flow leads to a decrease in the worst-case optimal cost. We provide a general characterization of this phenomenon using augmenting paths and establish a stronger characterization for complete graphs. In addition, we discuss the properties of the cost matrices immune against the paradox and prove that deciding whether a given cost matrix has this property is a strongly co-NP-hard problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01360v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miroslav Rada, Milan Hlad\'ik, Elif Radov\'a Garajov\'a, Francesco Carrabs, Raffaele Cerulli, Ciriaco D'Ambrosio</dc:creator>
    </item>
    <item>
      <title>Robust Sublinear Convergence Rates for Iterative Bregman Projections</title>
      <link>https://arxiv.org/abs/2602.01372</link>
      <description>arXiv:2602.01372v1 Announce Type: new 
Abstract: Entropic regularization provides a simple way to approximate linear programs whose constraints split into two (or more) tractable blocks. The resulting objectives are amenable to cyclic Kullback-Leibler (KL) Bregman projections, with the classical Sinkhorn algorithm for optimal transport (balanced, unbalanced, gradient flows, barycenters, \dots) as the canonical example. Assuming uniformly bounded primal mass and dual radius, we prove that the dual objective of these KL projections decreases at an $O(1/k)$ rate with a constant that scales only linearly in $1/\gamma$, where $\gamma$ is the entropic regularization parameter. This extends the guarantees known for entropic optimal transport to any such linearly constrained problem. Following the terminology introduced in [Chizat et al 2025], we call such rates "robust", because this mild dependence on $\gamma$ underpins favorable complexity bounds for approximating the unregularized problem via alternating KL projections. The crucial aspect of the analysis is that the dual radius should be measured according to a block-quotient dual seminorm, which depends on the structure of the split of the constraint into blocks. As an application, we derive the flow-Sinkhorn algorithm for the Wasserstein-1 distance on graphs. It achieves $\epsilon$-additive accuracy on the transshipment cost in $O(p/\epsilon^{4})$ arithmetic operations, where $p$ is the number of edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01372v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Peyr\'e</dc:creator>
    </item>
    <item>
      <title>Evaluation of Electricity Market Clearing Mechanisms via Reinforcement Learning: Prices, Remuneration and Competitive Dynamics</title>
      <link>https://arxiv.org/abs/2602.01392</link>
      <description>arXiv:2602.01392v1 Announce Type: new 
Abstract: The Pay-as-Clear (PaC) mechanism currently used in the European electricity market can generate significant submarginal profits for renewable sources when the clearing price is determined by the marginal offers of gas-fired generation units and the cost of natural gas exceeds certain levels. This exposes consumers to high price volatility related to the cost of natural gas. This report analyzes the recently proposed Segmented Pay-as-Clear (SPaC) mechanism as a market alternative, evaluating its system cost-effectiveness through simulations based on Reinforcement Learning (Q-Learning) to model the strategic behavior of operators. Three market models are compared, the two classic Pay-as-Clear (PaC) and Pay-as-Bid (PaB) along with SPaC, under two scenarios: a simplified one based on the 2030 NECP objectives and one built on the portfolios of ten operators obtained from the GME's 2024 public offers. The results show that the SPaC market clearing mechanism reduces intramarginal profits and price volatility compared to PaC, while maintaining fair participation incentives for all operators, and is more robust than PaB to the exercise of market power in oligopolistic contexts. The developed framework can serve as a support tool for regulators and policymakers in the evaluation of proposals for market design reforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01392v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Altamura, Fabrizio Lacalandra, Antonio Frangioni, Massimo La Scala</dc:creator>
    </item>
    <item>
      <title>Regret of $H_\infty$ Preview Controllers</title>
      <link>https://arxiv.org/abs/2602.01420</link>
      <description>arXiv:2602.01420v1 Announce Type: new 
Abstract: This paper studies preview control in both the $H_\infty$ and regret-optimal settings. The plant is modeled as a discrete-time, linear time-invariant system subject to external disturbances. The performance baseline is the optimal non-causal controller that has full knowledge of the disturbance sequence. We first review the construction of the $H_\infty$ preview controller with $p$-steps of disturbance preview. We then show that the closed-loop $H_\infty$ performance of this preview controller converges as $p\to \infty$ to the performance of the optimal non-causal controller. Furthermore, we prove that the optimal regret of the preview controller converges to zero. These results demonstrate that increasing preview length allows controllers to asymptotically achieve non-causal performance in both the $H_\infty$ and regret frameworks. A numerical example illustrates the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01420v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jietian Liu, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>The Dynamic Search for the Minimal Dynamic Extension</title>
      <link>https://arxiv.org/abs/2602.01457</link>
      <description>arXiv:2602.01457v1 Announce Type: new 
Abstract: Identifying the dynamic precompensator that renders a nonlinear control system feedback linearizable is a challenging problem. Researchers have explored the problem -- dynamic feedback linearization -- and produced existence conditions and constructive procedures for the dynamic precompensator. These remain, in general, either computationally expensive or restrictive. Treating the challenge as intrinsic, this article views the problem as a search problem over a category. Dynamic programming applies and, upon restriction to a finite category, classic search algorithms find the minimal dynamic extension. Alternatively, a heuristic aiming towards feedback linearizable systems can be employed to select amongst the infinitely-many extensions. This framing provides a distinctive, birds-eye view of the search for the dynamic precompensator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01457v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rollen S. D'Souza</dc:creator>
    </item>
    <item>
      <title>Non-Uniform Noise-to-Signal Ratio in the REINFORCE Policy-Gradient Estimator</title>
      <link>https://arxiv.org/abs/2602.01460</link>
      <description>arXiv:2602.01460v1 Announce Type: new 
Abstract: Policy-gradient methods are widely used in reinforcement learning, yet training often becomes unstable or slows down as learning progresses. We study this phenomenon through the noise-to-signal ratio (NSR) of a policy-gradient estimator, defined as the estimator variance (noise) normalized by the squared norm of the true gradient (signal). Our main result is that, for (i) finite-horizon linear systems with Gaussian policies and linear state-feedback, and (ii) finite-horizon polynomial systems with Gaussian policies and polynomial feedback, the NSR of the REINFORCE estimator can be characterized exactly-either in closed form or via numerical moment-evaluation algorithms-without approximation. For general nonlinear dynamics and expressive policies (including neural policies), we further derive a general upper bound on the variance. These characterizations enable a direct examination of how NSR varies across policy parameters and how it evolves along optimization trajectories (e.g. SGD and Adam). Across a range of examples, we find that the NSR landscape is highly non-uniform and typically increases as the policy approaches an optimum; in some regimes it blows up, which can trigger training instability and policy collapse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01460v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Han, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Conformal Prediction for Early Stopping in Mixed Integer Optimization</title>
      <link>https://arxiv.org/abs/2602.01476</link>
      <description>arXiv:2602.01476v1 Announce Type: new 
Abstract: Mixed-integer optimization solvers often find optimal solutions early in the search, yet spend the majority of computation time proving optimality. We exploit this by learning when to terminate solvers early on distributions of similar problem instances. Our method trains a neural network to estimate the true optimality gap from the solver state, then uses conformal prediction to calibrate a stopping threshold with rigorous probabilistic guarantees on solution quality. On five problem families from the distributional MIPLIB library, our method reduces solve time by over 60% while guaranteeing 0.1%- optimal solutions with 95% probability</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01476v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Clarke, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Why Does Adaptive Zeroth-Order Optimization Work?</title>
      <link>https://arxiv.org/abs/2602.01627</link>
      <description>arXiv:2602.01627v1 Announce Type: new 
Abstract: Zeroth-order (ZO) optimization is popular in real-world applications that accessing the gradient information is expensive or unavailable.
  Recently, adaptive ZO methods that normalize gradient estimators by the empirical standard deviation of function values have achieved strong practical performance, particularly in fine-tuning the large language model.
  However, the theoretical understanding of such strategy remains limited.
  In this work, we show that the empirical standard deviation is, with high probability, closely proportional to the norm of the (stochastic) gradient.
  Based on this insight, we analyze adaptive ZO methods under the generalized $(L_0,L_1)$-smoothness condition with respect to the matrix norm.
  We establish explicit convergence rates and query complexity bounds for both deterministic and stochastic settings, demonstrating that adaptive ZO methods achieve the faster convergence and the improved query efficiency compared to the vanilla ZO methods with fixed-step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01627v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haishan Ye, Luo Luo</dc:creator>
    </item>
    <item>
      <title>Optimal Liquidation in a Defaultable Market</title>
      <link>https://arxiv.org/abs/2602.01968</link>
      <description>arXiv:2602.01968v1 Announce Type: new 
Abstract: In this paper we address the problem of optimal liquidation of a large portfolio composed by securities exposed to default risk. The default time is described in terms of a Brownian motion representing the evolution of the value of the firm, whose assets are available in the market for investors. Considering that selling a large number of assets has a significant impact in the price, and hence in the portfolio's value, the control problem involved to describe the optimal strategy to liquidate a large position is analyzed. Under suitable assumptions in the model, an explicit solution is given to the value function and a precise description of the optimal strategy is obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01968v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Hern\'andez-Hern\'ndez, Harold A. Moreno-Franco, Jos\'e-Luis P\'erez</dc:creator>
    </item>
    <item>
      <title>Characterizations of inexact proximal operators</title>
      <link>https://arxiv.org/abs/2602.02022</link>
      <description>arXiv:2602.02022v1 Announce Type: new 
Abstract: Proximal operators are now ubiquitous in non-smooth optimization. Since their introduction in the seminal work of Moreau, many papers have shown their effectiveness on a wide variety of problems, culminating in their use to construct convergent deep learning methods. The characterization of these operators for non-convex penalties was completed recently in [Gribonval et al, A characterization of proximity operators, 2020]. In this paper, we propose to follow this line of work by characterizing inexact proximal operators, thus providing an answer to what constitutes a good approximation of these operators. We propose several definitions of approximations and discuss their regularity, approximation power, and their fixed points. Equipped with these characterizations, we investigate the convergence of proximal algorithms in the presence of errors that may be non-summable and/or non-vanishing. In particular, we look at the proximal point algorithm, and at the forward-backward, Peaceman-Rachford and Douglas-Rachford algorithms when we minimize the sum of a weakly convex function (whose proximal operator is approximated) and a strongly convex function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02022v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Lauga (LJAD), Samuel Vaiter (CNRS, LJAD)</dc:creator>
    </item>
    <item>
      <title>Well-Posed KL-Regularized Control via Wasserstein and Kalman-Wasserstein KL Divergences</title>
      <link>https://arxiv.org/abs/2602.02250</link>
      <description>arXiv:2602.02250v1 Announce Type: new 
Abstract: Kullback-Leibler divergence (KL) regularization is widely used in reinforcement learning, but it becomes infinite under support mismatch and can degenerate in low-noise limits. Utilizing a unified information-geometric framework, we introduce (Kalman)-Wasserstein-based KL analogues by replacing the Fisher-Rao geometry in the dynamical formulation of the KL with transport-based geometries, and we derive closed-form values for common distribution families. These divergences remain finite under support mismatch and yield a geometric interpretation of regularization heuristics used in Kalman ensemble methods. We demonstrate the utility of these divergences in KL-regularized optimal control. In the fully tractable setting of linear time-invariant systems with Gaussian process noise, the classical KL reduces to a quadratic control penalty that becomes singular as process noise vanishes. Our variants remove this singularity, yielding well-posed problems. On a double integrator and a cart-pole example, the resulting controls outperform KL-based regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02250v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktor Stein, Adwait Datar, Nihat Ay</dc:creator>
    </item>
    <item>
      <title>Games with Rational and Herding Players</title>
      <link>https://arxiv.org/abs/2602.02291</link>
      <description>arXiv:2602.02291v1 Announce Type: new 
Abstract: Classical game theory is a powerful framework to analyze the strategic interactions among rational players. However, in many real-life scenarios, players choose actions based on their inherent natural tendencies rather than deliberate reasoning. In this paper, we develop an analytical framework to study large population games with an alpha-fraction of rational and (1-alpha)-fraction of herding players. We introduce a new notion of equilibrium called alpha-Rational Nash Equilibrium (in short, alpha-RNE) and discuss its interpretations. Some classical equilibria may disappear, and some new ones may emerge, but only for smaller alpha &gt;0. Interestingly, rational players benefit from the presence of herding and may even achieve utility exceeding the socially optimum. Even more strikingly, in some cases, the herding players also benefit, attaining utility close to the social optimum.
  We further study the effect of the herding fraction on system performance using measures such as the Price of Anarchy (PoA). In transportation networks, a well-known paradox first studied by Pigou and later by Braess typically arises from rational decision-making: adding an extra link can reduce overall efficiency. Our analysis leads to a different conclusion. When a substantial fraction of users exhibit herding behavior, introducing a new link can increase efficiency, provided herding choices can be suitably influenced. The gains are larger when the herding fraction is higher and/or congestion is lower. By contrast, when herding decisions cannot be influenced, the added link may become detrimental. We also study a bandwidth sharing game in which herding tendencies improve system efficiency. Finally, we discuss the mechanism or influence design in the presence of herding, highlighting both opportunities and risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02291v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raghupati Vyas, Khushboo Agarwal, Konstantin Avrachenkov, Veeraruna Kavitha</dc:creator>
    </item>
    <item>
      <title>A Two-Stage Stochastic Optimization Model for the Equitable Deployment of Fixed and Mobile Electric Vehicle Charging Stations</title>
      <link>https://arxiv.org/abs/2602.02333</link>
      <description>arXiv:2602.02333v1 Announce Type: new 
Abstract: A major barrier to wide adoption of Electric Vehicles (EVs) is the absence of reliable and equitable charging infrastructure. Poorly located charging stations create coverage gaps and slow down EV adoption, especially in underserved communities. This paper proposes a two-stage stochastic mixed-integer programming model for the optimal deployment of Fixed and Mobile Charging Stations (FCSs and MCSs) across multiple zones and periods. Initially, a finite dominating set of candidate locations is identified using the Edge Scanning Algorithm for a Single Refueling Station (ESS), an exact continuous-location method. We modify the ESS algorithm to incorporate existing public charging stations, thereby avoiding redundant coverage. In the first stage of our model, FCSs are allocated based on long-term traffic patterns, budgetary constraints, and socioeconomic factors to ensure stable baseline coverage. The second stage dynamically assigns MCSs in response to short-term demand fluctuations and uncertainties, aiming to minimize relocation costs while maximizing coverage. We use a scenario-based framework to capture demand variability. Numerical experiments on realistic networks demonstrate the model's capacity to enhance system resilience and reduce unmet demand. These findings offer practical insights for planners and policymakers seeking to develop accessible and demand-responsive EV charging infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02333v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hamid Najafzad, Moddassir Khan Nayeem, Fuhad Ahmed Opu, Omar Abbaas, Gabriel Nicolosi</dc:creator>
    </item>
    <item>
      <title>Sequential Quadratic Sum-of-squares Programming for Nonlinear Control Systems</title>
      <link>https://arxiv.org/abs/2602.02394</link>
      <description>arXiv:2602.02394v1 Announce Type: new 
Abstract: Many problems in nonlinear systems analysis and control design, such as local region-of-attraction estimation, inner-approximations of reachable sets or control design under state and control constraints can be formulated as nonconvex sum-of-squares programs. Yet tractable and efficient solution methods are still lacking, limiting their application in control engineering. To address this gap, we propose a filter line-search algorithm that solves a sequence of quadratic subproblems. Numerical benchmarks demonstrate that the algorithm can significantly reduce the number of iterations, resulting in a substantial decrease in computation time compared to established methods for nonconvex sum-of-squares programs. An open-source implementation of the algorithm along with the numerical benchmarks is provided</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02394v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Olucak, Torbj{\o}rn Cunis</dc:creator>
    </item>
    <item>
      <title>Gauss-Newton Natural Gradient Descent for Shape Learning</title>
      <link>https://arxiv.org/abs/2602.00099</link>
      <description>arXiv:2602.00099v1 Announce Type: cross 
Abstract: We explore the use of the Gauss-Newton method for optimization in shape learning, including implicit neural surfaces and geometry-informed neural networks. The method addresses key challenges in shape learning, such as the ill-conditioning of the underlying differential constraints and the mismatch between the optimization problem in parameter space and the function space where the problem is naturally posed. This leads to significantly faster and more stable convergence than standard first-order methods, while also requiring far fewer iterations. Experiments across benchmark shape optimization tasks demonstrate that the Gauss-Newton method consistently improves both training speed and final solution accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00099v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James King, Arturs Berzins, Siddhartha Mishra, Marius Zeinhofer</dc:creator>
    </item>
    <item>
      <title>Facet-Defining Inequalities for the Angle-Based DC Optimal Transmission Switching Formulation</title>
      <link>https://arxiv.org/abs/2602.00281</link>
      <description>arXiv:2602.00281v1 Announce Type: cross 
Abstract: The switching of transmission lines can significantly improve the economic and operational efficiency of power systems. The Direct-Current Optimal Transmission Switching (DC-OTS) problem provides a formal framework for minimizing power generation costs by reconfiguring the transmission network topology under a linearized power flow model. DC-OTS is typically formulated as a mixed-integer linear program that incorporates disjunctive constraints to capture the required relationships between certain variables via big-M parameters. More specifically, these parameters represent upper bounds on voltage angle differences across non-operational transmission lines. In practice, overly conservative (and arbitrary) bounds tend to be used. The belief is that tightening these values requires the solution of the computationally intractable longest path problem. This work challenges that view through a novel polyhedral analysis of the angle-based DC-OTS formulation. We construct an extended formulation for the convex hull of an angle-based relaxation and derive facet-defining inequalities that tighten angle-difference bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00281v1</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Behnam Jabbari-Marand, Adolfo R. Escobedo</dc:creator>
    </item>
    <item>
      <title>Adaptive Momentum and Nonlinear Damping for Neural Network Training</title>
      <link>https://arxiv.org/abs/2602.00334</link>
      <description>arXiv:2602.00334v1 Announce Type: cross 
Abstract: We propose a continuous-time scheme for large-scale optimization that introduces individual, adaptive momentum coefficients regulated by the kinetic energy of each model parameter. This approach automatically adjusts to local landscape curvature to maintain stability without sacrificing convergence speed. We demonstrate that our adaptive friction can be related to cubic damping, a suppression mechanism from structural dynamics. Furthermore, we introduce two specific optimization schemes by augmenting the continuous dynamics of mSGD and Adam with a cubic damping term. Empirically, our methods demonstrate robustness and match or outperform Adam on training ViT, BERT, and GPT2 tasks where mSGD typically struggles. We further provide theoretical results establishing the exponential convergence of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00334v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aikaterini Karoni, Rajit Rajpal, Benedict Leimkuhler, Gabriel Stoltz</dc:creator>
    </item>
    <item>
      <title>3DGS$^2$-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting</title>
      <link>https://arxiv.org/abs/2602.00395</link>
      <description>arXiv:2602.00395v1 Announce Type: cross 
Abstract: We propose 3DGS$^2$-TR,a second-order optimizer for accelerating the scene training problem in 3D Gaussian Splatting (3DGS). Unlike existing second-order approaches that rely on explicit or dense curvature representations, such as 3DGS-LM (H\"ollein et al., 2025) or 3DGS2 (Lan et al., 2025), our method approximates curvature using only the diagonal of the Hessian matrix, efficiently via Hutchinson's method. Our approach is fully matrix-free and has the same complexity as ADAM (Kingma, 2024), $O(n)$ in both computation and memory costs. To ensure stable optimization in the presence of strong nonlinearity in the 3DGS rasterization process, we introduce a parameter-wise trust-region technique based on the squared Hellinger distance, regularizing updates to Gaussian parameters. Under identical parameter initialization and without densification, 3DGS$^2$-TR is able to achieve better reconstruction quality on standard datasets, using 50% fewer training iterations compared to ADAM, while incurring less than 1GB of peak GPU memory overhead (17% more than ADAM and 85% less than 3DGS-LM), enabling scalability to very large scenes and potentially to distributed training settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00395v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roger Hsiao, Yuchen Fang, Xiangru Huang, Ruilong Li, Hesam Rabeti, Zan Gojcic, Javad Lavaei, James Demmel, Sophia Shao</dc:creator>
    </item>
    <item>
      <title>Quality-Diversity Optimization as Multi-Objective Optimization</title>
      <link>https://arxiv.org/abs/2602.00478</link>
      <description>arXiv:2602.00478v1 Announce Type: cross 
Abstract: The Quality-Diversity (QD) optimization aims to discover a collection of high-performing solutions that simultaneously exhibit diverse behaviors within a user-defined behavior space. This paradigm has stimulated significant research interest and demonstrated practical utility in domains including robot control, creative design, and adversarial sample generation. A variety of QD algorithms with distinct design principles have been proposed in recent years. Instead of proposing a new QD algorithm, this work introduces a novel reformulation by casting the QD optimization as a multi-objective optimization (MOO) problem with a huge number of optimization objectives. By establishing this connection, we enable the direct adoption of well-established MOO methods, particularly set-based scalarization techniques, to solve QD problems through a collaborative search process. We further provide a theoretical analysis demonstrating that our approach inherits theoretical guarantees from MOO while providing desirable properties for the QD optimization. Experimental studies across several QD applications confirm that our method achieves performance competitive with state-of-the-art QD algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00478v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Lin, Ping Guo, Yilu Liu, Qingfu Zhang, Jianyong Sun</dc:creator>
    </item>
    <item>
      <title>Partition of Unity Neural Networks for Interpretable Classification with Explicit Class Regions</title>
      <link>https://arxiv.org/abs/2602.00511</link>
      <description>arXiv:2602.00511v1 Announce Type: cross 
Abstract: Despite their empirical success, neural network classifiers remain difficult to interpret. In softmax-based models, class regions are defined implicitly as solutions to systems of inequalities among logits, making them difficult to extract and visualize. We introduce Partition of Unity Neural Networks (PUNN), an architecture in which class probabilities arise directly from a learned partition of unity, without requiring a softmax layer.
  PUNN constructs $k$ nonnegative functions $h_1, \ldots, h_k$ satisfying $\sum_i h_i(x) = 1$, where each $h_i(x)$ directly represents $P(\text{class } i \mid x)$. Unlike softmax, where class regions are defined implicitly through coupled inequalities among logits, each PUNN partition function $h_i$ directly defines the probability of class $i$ as a standalone function of $x$.
  We prove that PUNN is dense in the space of continuous probability maps on compact domains. The gate functions $g_i$ that define the partition can use various activation functions (sigmoid, Gaussian, bump) and parameterizations ranging from flexible MLPs to parameter-efficient shape-informed designs (spherical shells, ellipsoids, spherical harmonics).
  Experiments on synthetic data, UCI benchmarks, and MNIST show that PUNN with MLP-based gates achieves accuracy within 0.3--0.6\% of standard multilayer perceptrons. When geometric priors match the data structure, shape-informed gates achieve comparable accuracy with up to 300$\times$ fewer parameters. These results demonstrate that interpretable-by-design architectures can be competitive with black-box models while providing transparent class probability assignments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00511v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akram Aldroubi</dc:creator>
    </item>
    <item>
      <title>A Cayley-free Two-Step Algorithm for Inverse Singular Value Problems</title>
      <link>https://arxiv.org/abs/2602.00517</link>
      <description>arXiv:2602.00517v1 Announce Type: cross 
Abstract: In this paper, we investigate numerical solutions for inverse singular value problems (for short, ISVPs) arising in various applications. Inspired by the methodologies employed for inverse eigenvalue problems, we propose a Cayley-free two-step algorithm for solving the ISVP. Compared to the existing two-step algorithms for the ISVP, our algorithm eliminates the need for Cayley transformations and consequently avoids solving $2(m+n)$ linear systems during the computation of approximate singular vectors at each outer iteration. Under the assumption that the Jacobian matrix at a solution is nonsingular, we present a convergence analysis for the proposed algorithm and prove a cubic root-convergence rate. Numerical experiments are conducted to validate the effectiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00517v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiechang Fan, Weiping Shen, Yusong Luo, Enping Lou</dc:creator>
    </item>
    <item>
      <title>Multi-Compartment Volume Conductor with Complete Electrode Model: Simulated Stereo-EEG Source Localization using Brainstorm-Zeffiro Plugin</title>
      <link>https://arxiv.org/abs/2602.00684</link>
      <description>arXiv:2602.00684v1 Announce Type: cross 
Abstract: This study introduces a novel integration of the Brainstorm (BST) software and the Zeffiro Interface (ZI) to enable whole-head, multi-compartment volume conductor modeling for electroencephalography (EEG) source imaging, with a particular focus on stereotactic EEG applications. We present the BST-2-ZI plugin, a MATLAB-based tool that facilitates seamless transfer of tissue segmentations and anatomical atlases from BST into ZI for finite element (FE) mesh generation as well as forward and inverse modeling. The generated FE meshes support variable spatial resolution and implement the complete electrode model (CEM), allowing for precise modeling of both invasive depth electrodes and non-invasive scalp electrodes. Using the ICBM152 template and synthetic source simulation, we demonstrate the end-to-end pipeline from MRI data to lead field (LF) computation and source localization in a stereotactic EEG (stereo-EEG) setting. Our numerical experiments highlight the capability of the pipeline to accurately model multi-compartment head geometry and conductivity with a stereotactic CEM-based electrode configuration. Our preliminary source localization results show how a synthetic stereo-EEG probe corresponding to a bidirectional deep brain stimulation (DBS) probe with four omnidirectional contacts can, in principle, be coupled with scalp electrodes to improve source localization in its vicinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00684v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Galaz Prieto, Takfarinas Medani, Chinmay Chinara, Richard M. Leahy, Sampsa Pursiainen</dc:creator>
    </item>
    <item>
      <title>Sporadic Gradient Tracking over Directed Graphs: A Theoretical Perspective on Decentralized Federated Learning</title>
      <link>https://arxiv.org/abs/2602.00791</link>
      <description>arXiv:2602.00791v1 Announce Type: cross 
Abstract: Decentralized Federated Learning (DFL) enables clients with local data to collaborate in a peer-to-peer manner to train a generalized model. In this paper, we unify two branches of work that have separately solved important challenges in DFL: (i) gradient tracking techniques for mitigating data heterogeneity and (ii) accounting for diverse availability of resources across clients. We propose $\textit{Sporadic Gradient Tracking}$ ($\texttt{Spod-GT}$), the first DFL algorithm that incorporates these factors over general directed graphs by allowing (i) client-specific gradient computation frequencies and (ii) heterogeneous and asymmetric communication frequencies. We conduct a rigorous convergence analysis of our methodology with relaxed assumptions on gradient estimation variance and gradient diversity of clients, providing consensus and optimality guarantees for GT over directed graphs despite intermittent client participation. Through numerical experiments on image classification datasets, we demonstrate the efficacy of $\texttt{Spod-GT}$ compared to well-known GT baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00791v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahryar Zehtabi, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher Brinton</dc:creator>
    </item>
    <item>
      <title>A Unified Matrix-Spectral Framework for Stability and Interpretability in Deep Learning</title>
      <link>https://arxiv.org/abs/2602.01136</link>
      <description>arXiv:2602.01136v1 Announce Type: cross 
Abstract: We develop a unified matrix-spectral framework for analyzing stability and interpretability in deep neural networks. Representing networks as data-dependent products of linear operators reveals spectral quantities governing sensitivity to input perturbations, label noise, and training dynamics.
  We introduce a Global Matrix Stability Index that aggregates spectral information from Jacobians, parameter gradients, Neural Tangent Kernel operators, and loss Hessians into a single stability scale controlling forward sensitivity, attribution robustness, and optimization conditioning. We further show that spectral entropy refines classical operator-norm bounds by capturing typical, rather than purely worst-case, sensitivity.
  These quantities yield computable diagnostics and stability-oriented regularization principles. Synthetic experiments and controlled studies on MNIST, CIFAR-10, and CIFAR-100 confirm that modest spectral regularization substantially improves attribution stability even when global spectral summaries change little.
  The results establish a precise connection between spectral concentration and analytic stability, providing practical guidance for robustness-aware model design and training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01136v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Katende</dc:creator>
    </item>
    <item>
      <title>Capabilities and Fundamental Limits of Latent Chain-of-Thought</title>
      <link>https://arxiv.org/abs/2602.01148</link>
      <description>arXiv:2602.01148v1 Announce Type: cross 
Abstract: Latent Chain-of-Thought (Latent CoT) models promise efficient reasoning via continuous representations, yet exhibit puzzling performance inconsistencies: excelling at exploration (ProsQA: 97.0%) but failing at computation (GSM8K: 34.1%). We reveal that this trade-off is governed by decisional certainty. Our contributions are threefold: (1) We theoretically characterize the fundamental Exploration-Execution Trade-off, proving that high certainty enables precise execution but inhibits exploration, while low certainty facilitates search but causes error accumulation. (2) We introduce the Symbolic Index--quantifying decisional commitment--as the core mechanism governing this trade-off and establish its causal relationship with both execution stability and exploration capability. (3) We prove that curriculum learning is theoretically necessary, as direct training provably fails due to distributional mismatch. Our framework shifts the design paradigm from binary architectural choices toward adaptive systems that dynamically regulate decisional certainty based on task demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01148v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaxuan Zou, Yaozhong Xiong, Yong Liu</dc:creator>
    </item>
    <item>
      <title>Statistical MIA: Rethinking Membership Inference Attack for Reliable Unlearning Auditing</title>
      <link>https://arxiv.org/abs/2602.01150</link>
      <description>arXiv:2602.01150v1 Announce Type: cross 
Abstract: Machine unlearning (MU) is essential for enforcing the right to be forgotten in machine learning systems. A key challenge of MU is how to reliably audit whether a model has truly forgotten specified training data. Membership Inference Attacks (MIAs) are widely used for unlearning auditing, where samples that evade membership detection are often regarded as successfully forgotten. After carefully revisiting the reliability of MIA, we show that this assumption is flawed: failed membership inference does not imply true forgetting. We theoretically demonstrate that MIA-based auditing, when formulated as a binary classification problem, inevitably incurs statistical errors whose magnitude cannot be observed during the auditing process. This leads to overly optimistic evaluations of unlearning performance, while incurring substantial computational overhead due to shadow model training. To address these limitations, we propose Statistical Membership Inference Attack (SMIA), a novel training-free and highly effective auditing framework. SMIA directly compares the distributions of member and non-member data using statistical tests, eliminating the need for learned attack models. Moreover, SMIA outputs both a forgetting rate and a corresponding confidence interval, enabling quantified reliability of the auditing results. Extensive experiments show that SMIA provides more reliable auditing with significantly lower computational cost than existing MIA-based approaches. Notably, the theoretical guarantees and empirical effectiveness of SMIA suggest it as a new paradigm for reliable machine unlearning auditing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01150v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jialong Sun, Zeming Wei, Jiaxuan Zou, Jiacheng Gong, Guanheng Wang, Chengyang Dong, Jialong Li, Bo Liu</dc:creator>
    </item>
    <item>
      <title>Finite element theta schemes for the viscous Burgers' equation with nonlinear Neumann boundary feedback control</title>
      <link>https://arxiv.org/abs/2602.01315</link>
      <description>arXiv:2602.01315v1 Announce Type: cross 
Abstract: In this article, we develop a fully discrete numerical scheme for the one-dimensional (1D) and two-dimensional (2D) viscous Burgers equations with nonlinear Neumann boundary feedback control. The temporal discretization employs a $\theta$-scheme, while a conforming finite element method is used for the spatial approximation. The existence and uniqueness of the fully discrete solution are established. We further prove that the scheme is unconditionally exponentially stable for $\theta \in [1/2, 1]$, thereby ensuring that the stabilization property of the continuous model is retained at the discrete level. In addition, optimal error estimates are obtained for both the state variable and the boundary control inputs in 1D and 2D frameworks. Finally, several numerical experiments are presented to validate our theoretical findings and to demonstrate the effectiveness of the proposed stabilization strategy under varying model parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01315v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shishu Pal Singh, Sudeep Kundu</dc:creator>
    </item>
    <item>
      <title>Nonlinear model reduction for transport-dominated problems</title>
      <link>https://arxiv.org/abs/2602.01397</link>
      <description>arXiv:2602.01397v1 Announce Type: cross 
Abstract: This article surveys nonlinear model reduction methods that remain effective in regimes where linear reduced-space approximations are intrinsically inefficient, such as transport-dominated problems with wave-like phenomena and moving coherent structures, which are commonly associated with the Kolmogorov barrier. The article organizes nonlinear model reduction techniques around three key elements -- nonlinear parametrizations, reduced dynamics, and online solvers -- and categorizes existing approaches into transformation-based methods, online adaptive techniques, and formulations that combine generic nonlinear parametrizations with instantaneous residual minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01397v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan S. Hesthaven, Benjamin Peherstorfer, Benjamin Unger</dc:creator>
    </item>
    <item>
      <title>Rod Flow: A Continuous-Time Model for Gradient Descent at the Edge of Stability</title>
      <link>https://arxiv.org/abs/2602.01480</link>
      <description>arXiv:2602.01480v1 Announce Type: cross 
Abstract: How can we understand gradient-based training over non-convex landscapes? The edge of stability phenomenon, introduced in Cohen et al. (2021), indicates that the answer is not so simple: namely, gradient descent (GD) with large step sizes often diverges away from the gradient flow. In this regime, the "Central Flow", recently proposed in Cohen et al. (2025), provides an accurate ODE approximation to the GD dynamics over many architectures. In this work, we propose Rod Flow, an alternative ODE approximation, which carries the following advantages: (1) it rests on a principled derivation stemming from a physical picture of GD iterates as an extended one-dimensional object -- a "rod"; (2) it better captures GD dynamics for simple toy examples and matches the accuracy of Central Flow for representative neural network architectures, and (3) is explicit and cheap to compute. Theoretically, we prove that Rod Flow correctly predicts the critical sharpness threshold and explains self-stabilization in quartic potentials. We validate our theory with a range of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01480v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Regis, Sinho Chewi</dc:creator>
    </item>
    <item>
      <title>Totally $\Delta$-Modular Tree Decompositions of Graphic Matrices for Integer Programming</title>
      <link>https://arxiv.org/abs/2602.01499</link>
      <description>arXiv:2602.01499v1 Announce Type: cross 
Abstract: We introduce the tree-decomposition-based parameter totally $\Delta$-modular treewidth (TDM-treewidth) for matrices with two nonzero entries per row. We show how to solve integer programs whose matrices have bounded TDM-treewidth when variables are bounded. This extends previous graph-based decomposition parameters for matrices with at most two nonzero entries per row to include matrices with entries outside of $\{-1,0,1\}$. We also give an analogue of the Grid Theorem of Robertson and Seymour for matrices of bounded TDM-treewidth in the language of rooted signed graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01499v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb McFarland</dc:creator>
    </item>
    <item>
      <title>Local Exponential Stability of Mean-Field Langevin Descent-Ascent in Wasserstein Space</title>
      <link>https://arxiv.org/abs/2602.01564</link>
      <description>arXiv:2602.01564v1 Announce Type: cross 
Abstract: We study the mean-field Langevin descent-ascent (MFL-DA), a coupled optimization dynamics on the space of probability measures for entropically regularized two-player zero-sum games. Although the associated mean-field objective admits a unique mixed Nash equilibrium, the long-time behavior of the original MFL-DA for general nonconvex-nonconcave payoffs has remained largely open. Answering an open question posed by Wang and Chizat (COLT 2024), we provide a partial resolution by proving that this equilibrium is locally exponentially stable: if the initialization is sufficiently close in Wasserstein metric, the dynamics trends to the equilibrium at an exponential rate. The key to our analysis is to establish a coercivity estimate for the entropy near equilibrium via spectral analysis of the linearized operator. We show that this coercivity effectively reveals a local displacement convex-concave structure, thereby driving contraction. This result settles the local stability and quantitative rate questions of Wang and Chizat, leaving global convergence as a remaining open challenge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01564v1</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geuntaek Seo, Minseop Shin, Pierre Monmarch\'e, Beomjun Choi</dc:creator>
    </item>
    <item>
      <title>The Effect of Mini-Batch Noise on the Implicit Bias of Adam</title>
      <link>https://arxiv.org/abs/2602.01642</link>
      <description>arXiv:2602.01642v1 Announce Type: cross 
Abstract: With limited high-quality data and growing compute, multi-epoch training is gaining back its importance across sub-areas of deep learning. Adam(W), versions of which are go-to optimizers for many tasks such as next token prediction, has two momentum hyperparameters $(\beta_1, \beta_2)$ controlling memory and one very important hyperparameter, batch size, controlling (in particular) the amount mini-batch noise. We introduce a theoretical framework to understand how mini-batch noise influences the implicit bias of memory in Adam (depending on $\beta_1$, $\beta_2$) towards sharper or flatter regions of the loss landscape, which is commonly observed to correlate with the generalization gap in multi-epoch training. We find that in the case of large batch sizes, higher $\beta_2$ increases the magnitude of anti-regularization by memory (hurting generalization), but as the batch size becomes smaller, the dependence of (anti-)regulariation on $\beta_2$ is reversed. A similar monotonicity shift (in the opposite direction) happens in $\beta_1$. In particular, the commonly "default" pair $(\beta_1, \beta_2) = (0.9, 0.999)$ is a good choice if batches are small; for larger batches, in many settings moving $\beta_1$ closer to $\beta_2$ is much better in terms of validation accuracy in multi-epoch training. Moreover, our theoretical derivations connect the scale of the batch size at which the shift happens to the scale of the critical batch size. We illustrate this effect in experiments with small-scale data in the about-to-overfit regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01642v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Boris Shigida</dc:creator>
    </item>
    <item>
      <title>Numerical methods for diffusion coefficient recovery</title>
      <link>https://arxiv.org/abs/2602.01656</link>
      <description>arXiv:2602.01656v1 Announce Type: cross 
Abstract: We revisit the inverse problem of reconstructing a spatially varying diffusion coefficient in stationary elliptic equations from boundary Cauchy data. From a theoretical perspective, we introduce a gradient-weighted modification of the coupled complex-boundary method (CCBM) incorporating an \(H^1\)-type term, and formulate the reconstruction as a regularized optimization problem over bounded admissible coefficients. We establish continuity and differentiability of the forward map, Lipschitz continuity of the modified cost functional, existence of minimizers, stability with respect to noisy data, and convergence under vanishing noise. From a numerical perspective, reconstructions are computed using a Sobolev-gradient descent scheme and evaluated through extensive numerical experiments across a range of noise levels, boundary inputs, and coefficient structures. In the reported tests, for sufficiently large but not excessive $H^1$-weights, the modified CCBM is observed to yield more stable reconstructions and to reduce certain high-frequency artifacts. Across the numerical scenarios considered in this study, the method often demonstrates favorable stability and robustness properties relative to several classical boundary-based formulations, although performance remains problem- and parameter-dependent. A projection-based extension further supports stable recovery of piecewise-constant diffusion coefficients in multi-subregion test cases. Our results indicate that, as long as all subdomains share a portion of the boundary, the proposed CCBM-based Tikhonov regularization approach with a pick-a-point strategy enables stable and reliable reconstruction of diffusion parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01656v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sahat Pandapotan Nainggolan, Julius Fergy Tiongson Rabago, Hirofumi Notsu</dc:creator>
    </item>
    <item>
      <title>Learning Sequential Decisions from Multiple Sources via Group-Robust Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2602.01825</link>
      <description>arXiv:2602.01825v1 Announce Type: cross 
Abstract: We often collect data from multiple sites (e.g., hospitals) that share common structure but also exhibit heterogeneity. This paper aims to learn robust sequential decision-making policies from such offline, multi-site datasets. To model cross-site uncertainty, we study distributionally robust MDPs with a group-linear structure: all sites share a common feature map, and both the transition kernels and expected reward functions are linear in these shared features. We introduce feature-wise (d-rectangular) uncertainty sets, which preserve tractable robust Bellman recursions while maintaining key cross-site structure. Building on this, we then develop an offline algorithm based on pessimistic value iteration that includes: (i) per-site ridge regression for Bellman targets, (ii) feature-wise worst-case (row-wise minimization) aggregation, and (iii) a data-dependent pessimism penalty computed from the diagonals of the inverse design matrices. We further propose a cluster-level extension that pools similar sites to improve sample efficiency, guided by prior knowledge of site similarity. Under a robust partial coverage assumption, we prove a suboptimality bound for the resulting policy. Overall, our framework addresses multi-site learning with heterogeneous data sources and provides a principled approach to robust planning without relying on strong state-action rectangularity assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01825v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyuan Xu, Zongqi Xia, Tianxi Cai, Doudou Zhou, Nian Si</dc:creator>
    </item>
    <item>
      <title>Super-twisting over networks: A Lyapunov approach for distributed differentiation</title>
      <link>https://arxiv.org/abs/2602.01857</link>
      <description>arXiv:2602.01857v1 Announce Type: cross 
Abstract: We study distributed differentiation, where agents in a networked system estimate the average of local time-varying signals and their derivatives under mild assumptions on the agents' signals and their first and second derivatives. Existing sliding-mode methods provide only local stability guarantees and lack systematic gain selection. By isolating the structural features shared with the super-twisting algorithm and encoding them into an abstract model, we construct a Lyapunov function enabling systematic gain design and proving global finite-time convergence to consensus for the distributed differentiator. Building on this framework, we develop an event-triggered hybrid system implementation using time-varying and state dependent threshold rules and derive minimum inter-event time guarantees and accuracy bounds that quantify the trade-off between estimation accuracy and communication effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01857v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rodrigo Aldana-L\'opez, Irene Perez Salesa, David Gomez Gutierrez, Rosario Aragues, Carlos Sagues</dc:creator>
    </item>
    <item>
      <title>Autocorrelated Optimize-via-Estimate: Predict-then-Optimize versus Finite-sample Optimal</title>
      <link>https://arxiv.org/abs/2602.01877</link>
      <description>arXiv:2602.01877v1 Announce Type: cross 
Abstract: Models that directly optimize for out-of-sample performance in the finite-sample regime have emerged as a promising alternative to traditional estimate-then-optimize approaches in data-driven optimization. In this work, we compare their performance in the context of autocorrelated uncertainties, specifically, under a Vector Autoregressive Moving Average VARMA(p,q) process. We propose an autocorrelated Optimize-via-Estimate (A-OVE) model that obtains an out-of-sample optimal solution as a function of sufficient statistics, and propose a recursive form for computing its sufficient statistics. We evaluate these models on a portfolio optimization problem with trading costs. A-OVE achieves low regret relative to a perfect information oracle, outperforming predict-then-optimize machine learning benchmarks. Notably, machine learning models with higher accuracy can have poorer decision quality, echoing the growing literature in data-driven optimization. Performance is retained under small mis-specification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01877v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zichun Wang, Gar Goei Loke, Ruiting Zuo</dc:creator>
    </item>
    <item>
      <title>Maximizing Reliability with Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2602.02432</link>
      <description>arXiv:2602.02432v1 Announce Type: cross 
Abstract: Bayesian optimization (BO) is a popular, sample-efficient technique for expensive, black-box optimization. One such problem arising in manufacturing is that of maximizing the reliability, or equivalently minimizing the probability of a failure, of a design which is subject to random perturbations - a problem that can involve extremely rare failures ($P_\mathrm{fail} = 10^{-6}-10^{-8}$). In this work, we propose two BO methods based on Thompson sampling and knowledge gradient, the latter approximating the one-step Bayes-optimal policy for minimizing the logarithm of the failure probability. Both methods incorporate importance sampling to target extremely small failure probabilities. Empirical results show the proposed methods outperform existing methods in both extreme and non-extreme regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02432v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack M. Buckingham, Ivo Couckuyt, Juergen Branke</dc:creator>
    </item>
    <item>
      <title>Stochastic smoothing accelerated gradient method for general constrained nonsmooth convex composite optimization</title>
      <link>https://arxiv.org/abs/2308.01252</link>
      <description>arXiv:2308.01252v3 Announce Type: replace 
Abstract: We propose a novel stochastic smoothing accelerated gradient (SSAG) method for general constrained nonsmooth convex composite optimization, and analyze the convergence rates. The SSAG method allows various smoothing techniques, and can deal with the nonsmooth term that is not easy to compute its proximal term, or that does not own the linear max structure. To the best of our knowledge, it is the first time to develop a stochastic approximation type method that treats the maximization of finite but numerous nonsmooth convex functions as a stochastic function, which significantly improves the computational efficiency. We prove that the SSAG method can simultaneously achieve the best-known order ${\cal{O}}(\frac{1}{\epsilon})$ of iteration complexity, and the optimal order ${\cal{O}}(\frac{1}{\epsilon^2})$ of $\cal{SFO}$ complexity, using variable sample-size. Numerical results on the application arising from the distributionally robust optimization demonstrate the effectiveness and efficiency of the proposed SSAG method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01252v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruyu Wang, Chao Zhang</dc:creator>
    </item>
    <item>
      <title>Sparse Extended Mean-Variance-CVaR Portfolios with Short-selling</title>
      <link>https://arxiv.org/abs/2404.00605</link>
      <description>arXiv:2404.00605v3 Announce Type: replace 
Abstract: This paper introduces a novel penalty decomposition algorithm customized for addressing the non-differentiable and nonconvex problem of extended mean-variance-CVaR portfolio optimization with short-selling and cardinality constraints. The proposed algorithm solves a sequence of penalty subproblems using a block coordinate descent (BCD) method while striving to fully exploit each component within the objective function and constraints. Through rigorous analysis, the well-posedness of each subproblem of the BCD method is established, and closed-form solutions are derived where possible. A comprehensive theoretical convergence analysis is provided to confirm the efficacy of the introduced algorithm in reaching a Lu--Zhang minimizer for this intractable optimization problem. Numerical experiments conducted on real-world datasets validate the practical applicability and effectiveness of the introduced algorithm based on various criteria. Notably, the existence of closed-form solutions within the BCD subproblems prominently underscores the efficiency of our algorithm when compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00605v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Mousavi, Maziar Salahi, Zois Boukouvalas</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization with Multimodal Decision-Dependent Ambiguity Sets</title>
      <link>https://arxiv.org/abs/2404.19185</link>
      <description>arXiv:2404.19185v2 Announce Type: replace 
Abstract: We consider a two-stage distributionally robust optimization (DRO) model with multimodal uncertainty, where both the mode probabilities and uncertainty distributions could be affected by the first-stage decisions. To address this setting, we propose a generic framework by introducing a $\phi$-divergence based ambiguity set to characterize the decision-dependent mode probabilities and further consider both moment-based and Wasserstein distance-based ambiguity sets to characterize the uncertainty distribution under each mode. We identify two special $\phi$-divergence examples (variation distance and $\chi^2$-distance) and provide specific forms of decision dependence relationships under which we can derive tractable reformulations. Furthermore, we investigate the benefits of considering multimodality in a DRO model compared to a single-modal counterpart through an analytical analysis. Additionally, we develop a separation-based decomposition algorithm to solve the resulting multimodal decision-dependent DRO models with finite convergence and optimality guarantee under certain settings. We provide a detailed computational study over two example problem settings, the facility location problem and shipment planning problem with pricing, to illustrate our results, which demonstrate that omission of multimodality or decision-dependent uncertainties within DRO frameworks result in inadequately performing solutions with worse in-sample and out-of-sample performances under various settings. We further demonstrate the speed-ups obtained by the solution algorithm against the off-the-shelf solver over various instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19185v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xian Yu, Beste Basciftci</dc:creator>
    </item>
    <item>
      <title>Better bounds on finite-order Grothendieck constants</title>
      <link>https://arxiv.org/abs/2409.03739</link>
      <description>arXiv:2409.03739v3 Announce Type: replace 
Abstract: Grothendieck constants $K_G(d)$ bound the advantage of $d$-dimensional strategies over $1$-dimensional ones in a specific optimisation task. They have applications ranging from approximation algorithms to quantum nonlocality. However, apart from $d=2$, their values are unknown. Here, we exploit a recent Frank-Wolfe approach to provide good candidates for lower bounding some of these constants. The complete proof relies on solving difficult binary quadratic optimisation problems. For $d\in\{3,4,5\}$, we construct specific rectangular instances that we can solve to certify better bounds than those previously known; by monotonicity, our lower bounds improve on the state of the art for $d\leqslant9$. For $d\in\{4,7,8\}$, we exploit elegant structures to build highly symmetric instances achieving even greater bounds; however, we can only solve them heuristically. We also recall the standard relation with violations of Bell inequalities and elaborate on it to interpret generalised Grothendieck constants $K_G(d\mapsto2)$ as the advantage of complex $d$-dimensional quantum mechanics over real qubit quantum mechanics. Motivated by this connection, we also improve the bounds on $K_G(d\mapsto2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03739v3</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/m5mn-c5dx</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. A 113, 022401 (2026)</arxiv:journal_reference>
      <dc:creator>S\'ebastien Designolle, Tam\'as V\'ertesi, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>An extension of Ordered Weighted Averaging over intervals with application to optimization under risk</title>
      <link>https://arxiv.org/abs/2410.09786</link>
      <description>arXiv:2410.09786v2 Announce Type: replace 
Abstract: The Ordered Weighted Averaging (OWA) operator is a traditional and commonly used criterion for aggregating discrete values of uncertain quantities. In this paper, it is shown that the discrete OWA naturally extends to the continuous case by using the concept of a distortion risk measure. It is shown how to apply the distortion risk measure to optimization problems with a linear objective function, whose coefficients are random variables with continuous distribution functions supported on intervals. The case where these coefficients are independent, uniformly distributed random variables is explored in more detail. The computational complexity of the resulting optimization problem is analyzed, and solution methods with approximation guarantees are proposed. These methods are also verified through computational experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09786v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Werner Baak, Marc Goerigk, Adam Kasperski, Pawe{\l} Zieli\'nski</dc:creator>
    </item>
    <item>
      <title>Polyak's Heavy Ball Method Achieves Accelerated Local Rate of Convergence under Polyak-Lojasiewicz Inequality</title>
      <link>https://arxiv.org/abs/2410.16849</link>
      <description>arXiv:2410.16849v2 Announce Type: replace 
Abstract: In this work, we analyze the convergence of Polyak's heavy ball method in both continuous and discrete time for non-convex $C^4$-objective functions satisfying the Polyak-Lojasiewicz inequality. Under this weak assumption, we recover the asymptotic convergence rates originally derived by Polyak in [Polyak, U.S.S.R. Comput. Math. and Math. Phys., 1964] for strongly convex objectives. Our results demonstrate that the heavy ball method exhibits asymptotic local acceleration on this class of functions. In particular, in the discrete time setting, we prove local convergence of the iterates to a minimum once the method enters a sufficiently small neighborhood of the set of minima, for a broad range of hyperparameters, including aggressive choices for the momentum parameter and the step-size for which global convergence is known to fail. Instead of the usually employed Lyapunov-type arguments, our approach leverages a new differential geometric perspective of the Polyak-Lojasiewicz inequality proposed in [Rebjock and Boumal, Math. Program., 2025].</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16849v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Kassing, Simon Weissmann</dc:creator>
    </item>
    <item>
      <title>A novel switched systems approach to nonconvex optimisation</title>
      <link>https://arxiv.org/abs/2410.21570</link>
      <description>arXiv:2410.21570v3 Announce Type: replace 
Abstract: We develop a novel switching dynamics that converges to the Karush-Kuhn-Tucker (KKT) point of a nonlinear optimisation problem. This new approach is particularly notable for its lower dimensionality compared to conventional primal-dual dynamics, as it focuses exclusively on estimating the primal variable. Our method is successfully illustrated on general quadratic optimisation problems, the minimisation of the classical Rosenbrock function, and a nonconvex optimisation problem stemming from the control of energy-efficient buildings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21570v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Ferguson, Saeed Ahmed, Juan E. Machado, Michele Cucuzzella, Jacquelien M. A. Scherpen</dc:creator>
    </item>
    <item>
      <title>A Variable Smoothing for Weakly Convex Composite Minimization with Manifold Constraint via Parametrization</title>
      <link>https://arxiv.org/abs/2412.04225</link>
      <description>arXiv:2412.04225v4 Announce Type: replace 
Abstract: In this paper, we address a manifold constrained nonsmooth optimization problem involving the composition of a weakly convex function and a smooth mapping under the availability of a parametrization of the manifold. To find a stationary point of the target problem, we propose a variable smoothing-type algorithm by combining the ideas of (i) translating the constrained problem into a Euclidean optimization problem with a parametrization of the constraint set; (ii) exploiting a sequence of smoothed surrogate functions, of the cost function, given with the Moreau envelope of a weakly convex function. The proposed algorithm produces a vector sequence by the gradient descent update of a smoothed surrogate function at each iteration. In a case where the proximity operator of the weakly convex function is available, the proposed algorithm does not require any iterative solver for subproblems therein. By leveraging tools in the variational analysis, we show the so-called {\em gradient consistency property}, which is a key ingredient for smoothing-type algorithms, of the smoothed surrogate function used in this paper. Based on the gradient consistency property, we also establish an asymptotic convergence analysis for the proposed algorithm regarding a stationary point. Numerical experiments demonstrate the efficacy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04225v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Line-Search Filter Differential Dynamic Programming for Optimal Control with Nonlinear Equality Constraints</title>
      <link>https://arxiv.org/abs/2504.08278</link>
      <description>arXiv:2504.08278v5 Announce Type: replace 
Abstract: We present FilterDDP, a differential dynamic programming algorithm for solving discrete-time, optimal control problems (OCPs) with nonlinear equality constraints. Unlike prior methods based on merit functions or the augmented Lagrangian class of algorithms, FilterDDP uses a step filter in conjunction with a line search to handle equality constraints. We identify two important design choices for the step filter criteria which lead to robust numerical performance: 1) we use the Lagrangian instead of the cost in the step acceptance criterion and, 2) in the backward pass, we perturb the value function Hessian. Both choices are rigorously justified, for 2) in particular by a formal proof of local quadratic convergence. In addition to providing a primal-dual interior point extension for handling OCPs with both equality and inequality constraints, we validate FilterDDP on three contact implicit trajectory optimisation problems which arise in robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08278v5</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Xu, Stephen Gould, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Enhancing the controllability of quantum systems via a static field</title>
      <link>https://arxiv.org/abs/2504.17303</link>
      <description>arXiv:2504.17303v4 Announce Type: replace 
Abstract: We provide a sufficient condition for the controllability of a bilinear closed quantum system steered by a static field and a time-varying field, based on the notion of weakly conically connected spectrum. More precisely, we show that if a controlled Hamiltonian with two inputs has a weakly conically connected spectrum, then, freezing one of the two inputs at almost every constant value, the obtained single-input system is controllable. The result is illustrated with two examples, enantio-selective excitation in a chiral molecule and the driven Jaynes-Cummings Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17303v4</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruikang Liang, Eugenio Pozzoli, Monika Leibscher, Mario Sigalotti, Christiane P. Koch, Ugo Boscain</dc:creator>
    </item>
    <item>
      <title>Minimisation of Quasar-Convex Functions Using Random Zeroth-Order Oracles</title>
      <link>https://arxiv.org/abs/2505.02281</link>
      <description>arXiv:2505.02281v2 Announce Type: replace 
Abstract: This paper explores the performance of a random Gaussian smoothing zeroth-order (ZO) scheme for minimising quasar-convex (QC) and strongly quasar-convex (SQC) functions in both unconstrained and constrained settings. For the unconstrained problem, we establish the ZO algorithm's convergence to a global minimum along with its complexity when applied to both QC and SQC functions. For the constrained problem, we introduce the new notion of proximal-quasar-convexity and prove analogous results to the unconstrained case. Specifically, we derive complexity bounds and prove convergence of the algorithm to a neighbourhood of a global minimum whose size can be controlled under a variance reduction scheme. Beyond the theoretical guarantees, we demonstrate the practical implications of our results on several machine learning problems where quasar-convexity naturally arises, including linear dynamical system identification and generalised linear models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02281v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amir Ali Farzin, Yuen-Man Pun, Philipp Braun, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Lions and Muons: Optimization via Stochastic Frank-Wolfe</title>
      <link>https://arxiv.org/abs/2506.04192</link>
      <description>arXiv:2506.04192v2 Announce Type: replace 
Abstract: Stochastic Frank-Wolfe is a classical optimization method for solving constrained optimization problems. On the other hand, recent optimizers such as Lion and Muon have gained quite significant popularity in deep learning. In this work, building on recent initiatives, we provide a unifying perspective by interpreting these seemingly disparate methods through the lens of Stochastic Frank-Wolfe. Specifically, we show that Lion and Muon with weight decay can be viewed as special instances of a Stochastic Frank-Wolfe, and we establish their convergence guarantees in terms of the Frank-Wolfe gap, a standard stationarity measure in non-convex optimization for Frank-Wolfe methods. We further find that convergence to this gap implies convergence to a KKT point of the original problem under a norm constraint for Lion and Muon. Moreover, motivated by recent empirical findings that stochastic gradients in modern machine learning tasks often exhibit heavy-tailed distributions, we extend Stochastic Frank-Wolfe to settings with heavy-tailed noise by developing two robust variants with strong theoretical guarantees that hold for general compact convex sets without the need for a large batch size, filling the gap in the literature on Stochastic Frank-Wolfe for non-convex optimization. Our contributions in the later part of this work, in turn, yield new variants of Lion and Muon, that better accommodate heavy-tailed gradient noise, thereby enhancing their practical scope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04192v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Eleni Sfyraki, Jun-Kun Wang</dc:creator>
    </item>
    <item>
      <title>Duality and Policy Evaluation in Distributionally Robust Bayesian Diffusion Control</title>
      <link>https://arxiv.org/abs/2506.19294</link>
      <description>arXiv:2506.19294v3 Announce Type: replace 
Abstract: We study diffusion control problems under parameter uncertainty. Controllers based on plug-in estimation can be brittle due to potential distribution shifts. Bayesian control with a prior on the parameters offers a formulation with beliefs about such shifts. However, as with any Bayesian model, the prior may be misspecified. To mitigate misspecification and reduce over-pessimism compared to classical robust control approaches (e.g. \citet{hansen2008robustness}), we propose a distributionally robust Bayesian control (DRBC) formulation in which an adversary perturbs the prior within a divergence neighborhood of a baseline prior. We develop a strong duality result that reduces the distributionally robust prior evaluation to a low-dimensional optimization and yields a practical simulation-based policy evaluation and learning procedure with structured policy parameterizations. We validate the efficiency of the algorithm on a synthetic linear-quadratic control example and real-data portfolio selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19294v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Blanchet, Jiayi Cheng, Yuewei Ling, Hao Liu, Yang Liu</dc:creator>
    </item>
    <item>
      <title>A Berger-Wang formula for impulsive linear switched systems</title>
      <link>https://arxiv.org/abs/2507.02434</link>
      <description>arXiv:2507.02434v2 Announce Type: replace 
Abstract: This paper addresses a class of impulsive systems defined by a mix of continuous-time and discrete-time switched linear dynamics. We first analyze a related class of weighted discrete-time switched systems for which we establish a Berger--Wang-type result. An analogous result is then derived for impulsive systems and subsequently used to characterize their exponential stability through a spectral approach, thereby extending existing results in switched-systems theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02434v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yacine Chitour (L2S), Jamal Daafouz (IUF, CRAN), Ihab Haidar (ENSEA, LJLL), Paolo Mason (L2S), Mario Sigalotti (LJLL)</dc:creator>
    </item>
    <item>
      <title>Stability criteria for singularly perturbed impulsive linear switched systems</title>
      <link>https://arxiv.org/abs/2507.02446</link>
      <description>arXiv:2507.02446v2 Announce Type: replace 
Abstract: We study a class of singularly perturbed impulsive linear switched systems exhibiting switching between slow and fast dynamics. To analyze their behavior, we construct auxiliary switched systems evolving in a single time scale. We prove that the stability or instability of these auxiliary systems directly determines that of the original system in the regime of small singular perturbation parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02446v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ihab Haidar (ENSEA, LJLL), Yacine Chitour (L2S), Jamal Daafouz (IUF, CRAN), Paolo Mason (L2S), Mario Sigalotti (LJLL)</dc:creator>
    </item>
    <item>
      <title>Combinatorial Algorithm for Tropical Linearly Factorized Programming</title>
      <link>https://arxiv.org/abs/2507.07596</link>
      <description>arXiv:2507.07596v3 Announce Type: replace 
Abstract: The tropical semiring is an algebraic system with addition ``$\max$'' and multiplication ``$+$''. As well as in conventional algebra, linear programming in the tropical semiring has been developed. In this study, we introduce a new type of tropical optimization problem, namely, tropical linearly factorized programming. This problem involves minimizing the objective function given by a product of tropical linear forms divided by a tropical monomial, subject to tropical linear inequality constraints. As the objective function is equivalent to the dual of the transportation problem, it is convex in the conventional sense but not in the tropical sense, while the feasible set is convex in the tropical sense but not in the conventional sense.
  Our algorithm for tropical linearly factorized programming is based on the descent method. We first show that a feasible descent direction can be characterized in terms of a specific digraph, called a tangent digraph. Especially in non-degenerate cases, we present a simplex-like algorithm that updates the tree structure of tangent digraphs iteratively. Each iteration can be executed in $O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of finite coefficients in the constraints and objective function, respectively. For integer instances, our algorithm finds a local optimum in pseudo-polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07596v3</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Nishida</dc:creator>
    </item>
    <item>
      <title>Well-posedness of an optical flow based optimal control formulation for image registration</title>
      <link>https://arxiv.org/abs/2507.10188</link>
      <description>arXiv:2507.10188v3 Announce Type: replace 
Abstract: We consider image registration as an optimal control problem using an optical flow formulation, i.e., we discuss an optimization problem that is governed by a linear hyperbolic transport equation. Requiring Lipschitz continuity of the vector fields that parametrize the transformation leads to an optimization problem in a non-reflexive Banach space. We introduce relaxations of the optimization problem involving smoothed maximum and minimum functions and appropriate Orlicz spaces. To derive well-posedness results for the relaxed optimization problem, we revisit and establish new existence and uniqueness results for the linear hyperbolic transport equations. We further discuss limit considerations with respect to the relaxation parameter and discretizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10188v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Johannes Haubner, Christian Clason</dc:creator>
    </item>
    <item>
      <title>A Correspondence-Driven Approach for Bilevel Decision-making with Nonconvex Lower-Level Problems</title>
      <link>https://arxiv.org/abs/2509.01148</link>
      <description>arXiv:2509.01148v2 Announce Type: replace 
Abstract: We consider bilevel optimization problems with general nonconvex lower-level objectives and show that the classical hyperfunction-based formulation is unsettled, since the global minimizer of the lower-level problem is generally unattainable. To address this issue, we propose a correspondence-driven hyperfunction $\phi^{\text{cd}}$. In this formulation, the follower is modeled not as a rational agent always attaining a global minimizer, but as an algorithm-based bounded rational agent whose decisions are produced by a fixed algorithm with initialization and step size. Since $\phi^{\text{cd}}$ is generally discontinuous, we apply Gaussian smoothing to obtain a smooth approximation $\phi^{\text{cd}}_\xi$, then show that its value and gradient converge to those of $\phi^{\text{cd}}$. In the nonconvex setting, we identify that bifurcation phenomena, which arise when $g(x,\cdot)$ has a degenerate stationary point, pose a key challenge for hyperfunction-based methods. This is especially the case when $\phi^{\text{cd}}_\xi$ is solved using gradient methods. To overcome this challenge, we analyze the geometric structure of the bifurcation set under some weak assumptions. Building on these results, we design a biased projected SGD-based algorithm SCiNBiO to solve $\phi^{\text{cd}}_\xi$ with a cubic-regularized Newton lower-level solver. We also provide convergence guarantees and oracle complexity bounds for the upper level. Finally, we connect bifurcation theory from dynamical systems to the bilevel setting and define the notion of fold bifurcation points in this setting. Under the assumption that all degenerate stationary points are fold bifurcation points, we establish the oracle complexity of SCiNBiO for the lower-level problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01148v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Jiang, Jiaxiang Li, Mingyi Hong, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Bilevel subsidy-enabled mobility hub network design with perturbed utility coalitional choice-based assignment</title>
      <link>https://arxiv.org/abs/2509.10465</link>
      <description>arXiv:2509.10465v2 Announce Type: replace 
Abstract: Urban mobility is undergoing rapid transformation with the emergence of new services. Mobility hubs (MHs) have been proposed as physical-digital convergence points, offering a range of public and private mobility options in close proximity. By supporting Mobility-as-a-Service, these hubs can serve as focal points where travel decisions intersect with operator strategies. We develop a bilevel MH platform design model that treats MHs as control levers. The upper level (platform) maximizes revenue or flow by setting subsidies to incentivize last-mile operators; the lower level captures joint traveler-operator decisions with a link-based Perturbed Utility Route Choice (PURC) assignment, yielding a strictly convex quadratic program. We reformulate the bilevel problem to a single-level program via the KKT conditions of the lower level and solve it with a gap-penalty method and an iterative warm-start scheme that exploits the computationally cheap lower-level problem. Numerical experiments on a toy network and a Long Island Rail Road (LIRR) case (244 nodes, 469 links, 78 ODs) show that the method attains sub-1% optimality gaps in minutes. In the base LIRR case, the model allows policymakers to quantify the social surplus value of a MH, or the value of enabling subsidy or regulating the microtransit operator's pricing. Comparing link-based subsidies to hub-based subsidies, the latter is computationally more expensive but offers an easier mechanism for comparison and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10465v2</guid>
      <category>math.OC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hai Yang, Joseph Y. J. Chow</dc:creator>
    </item>
    <item>
      <title>Minimization of Nonsmooth Weakly Convex Function over Prox-regular Set for Robust Low-rank Matrix Recovery</title>
      <link>https://arxiv.org/abs/2509.17549</link>
      <description>arXiv:2509.17549v2 Announce Type: replace 
Abstract: We propose a prox-regular-type low-rank constrained nonconvex nonsmooth optimization model for Robust Low-Rank Matrix Recovery (RLRMR), i.e., estimate problem of low-rank matrix from an observed signal corrupted by outliers. For RLRMR, the $\ell_{1}$-norm has been utilized as a convex loss to detect outliers as well as to keep tractability of optimization models. Nevertheless, the $\ell_{1}$-norm is not necessarily an ideal robust loss because the $\ell_{1}$-norm tends to overpenalize entries corrupted by outliers of large magnitude. In contrast, the proposed model can employ a weakly convex function as a more robust loss, against outliers, than the $\ell_{1}$-norm. For the proposed model, we present (i) a projected variable smoothing-type algorithm applicable for the minimization of a nonsmooth weakly convex function over a prox-regular set, and (ii) a convergence analysis of the proposed algorithm in terms of stationary point. Numerical experiments demonstrate the effectiveness of the proposed model compared with the existing models that employ the $\ell_{1}$-norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17549v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>QUASAR: An Evolutionary Algorithm to Accelerate High-Dimensional Numerical Optimization</title>
      <link>https://arxiv.org/abs/2511.13843</link>
      <description>arXiv:2511.13843v4 Announce Type: replace 
Abstract: High-dimensional numerical optimization presents a persistent challenge in computational science. This paper introduces Quasi-Adaptive Search with Asymptotic Reinitialization (QUASAR), an evolutionary algorithm to accelerate convergence in complex, non-differentiable problems afflicted by the curse of dimensionality. QUASAR expands upon the core principles of Differential Evolution (DE), introducing quasi-adaptive mechanisms to dynamically balance exploration and exploitation in its search. Inspired by the behavior of quantum particles, the algorithm utilizes three highly stochastic mechanisms that augment standard DE: 1) probabilistic mutation strategies and scaling factors; 2) rank-based crossover rates; 3) asymptotically decaying covariance reinitializations.
  Evaluated on the notoriously difficult CEC2017 benchmark suite of 29 test functions, QUASAR achieved the lowest overall rank sum (367) using the Friedman test, outperforming DE (735) and L-SHADE (452). Geometric mean comparisons show average final solution quality improvements of $3.85 \times$ and $2.07 \times$ compared to DE and L-SHADE, respectively ($p \ll 0.001$), with average optimization speed averaging $1.40 \times$ and $5.16 \times$ faster. QUASAR's performance establishes it as an effective, efficient, and user-friendly evolutionary algorithm for complex high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13843v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian G. Soltes</dc:creator>
    </item>
    <item>
      <title>Machine Learning for Scheduling: A Paradigm Shift from Solver-Centric to Data-Centric Approaches</title>
      <link>https://arxiv.org/abs/2512.22642</link>
      <description>arXiv:2512.22642v2 Announce Type: replace 
Abstract: Scheduling problems are a fundamental class of combinatorial optimization problems that underpin operational efficiency in manufacturing, logistics, and service systems. While operations research has traditionally developed solver-centric methods emphasizing model structure and optimality, recent advances in machine learning are reshaping scheduling toward a more data-centric approach that leverages experience and enables fast decision-making in dynamic environments. This paper offers a framework-based synthesis and perspective on this methodological transition. We use the paradigm shift from solver-centric optimization to data-centric learning as a unifying lens to organize and interpret a rapidly expanding literature. We first briefly revisit classical optimization-based approaches and discuss how machine learning has been integrated to improve computational efficiency and guide search while retaining solver-based feasibility and accountability. We then synthesize end-to-end learning approaches that generate scheduling solutions (or solution-generating policies) directly from data, clarifying the key design choices in solution generation and feasibility handling. Building on these organizing frameworks, we compare learning mechanisms and training signals (supervised, self-supervised, and reinforcement learning) in terms of scalability, interpretability, and generalization, and highlight the trade-offs that matter for reliable deployment. Finally, we outline an agenda along three interdependent dimensions, scalability, reliability, and universality, that together define a pathway toward adaptive, intelligent, and trustworthy scheduling systems for data-driven operations management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22642v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anbang Liu, Shaochong Lin, Jingchuan Chen, Peng Wu, Zuojun Max Shen</dc:creator>
    </item>
    <item>
      <title>Robust Spacecraft Low-Thrust Trajectory Design: A Chance-Constrained Covariance-Steering Approach</title>
      <link>https://arxiv.org/abs/2601.17629</link>
      <description>arXiv:2601.17629v2 Announce Type: replace 
Abstract: This paper proposes a systematic method for generating practical and robust low-thrust spacecraft trajectories. One contribution is to consider the change in mass of the spacecraft at two levels: a) the propulsive acceleration and b) the intensity of the stochastic disturbances. A covariance variable formulation is considered, which is computationally more efficient than the factorized covariance implementation. The proposed approach is applied to two- (i.e., planar) and three-dimensional heliocentric phases of spacecraft flight from Earth to Mars under the restricted two-body dynamics. The results highlight the importance of keeping track of mass change to generate more realistic, robust trajectories for interplanetary space missions to avoid underestimation of mission risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17629v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meysam Babapour, Ehsan Taheri</dc:creator>
    </item>
    <item>
      <title>The augmented NLP bound for maximum-entropy remote sampling</title>
      <link>https://arxiv.org/abs/2601.20970</link>
      <description>arXiv:2601.20970v2 Announce Type: replace 
Abstract: The maximum-entropy remote sampling problem (MERSP) is to select a subset of s random variables from a set of n random variables, so as to maximize the information concerning a set of target random variables that are not directly observable. We assume throughout that the set of all of these random variables follows a joint Gaussian distribution, and that we have the covariance matrix available. Finally, we measure information using Shannon's differential entropy.
  The main approach for exact solution of moderate-sized instances of MERSP has been branch-and-bound, and so previous work concentrated on upper bounds. Prior to our work, there were two upper-bounding methods for MERSP: the so-called NLP bound and the spectral bound, both introduced 25 years ago. We are able now to establish domination results between these two upper bounds. We propose an ``augmented NLP bound'' based on a subtle convex relaxation. We provide theoretical guarantees, giving sufficient conditions under which the augmented NLP bound strictly dominates the ordinary NLP bound. In addition, the augmented NLP formulation allows us to derive upper bounds for rank-deficient covariance matrices when they satisfy a technical condition. This is in contrast to the earlier work on the ordinary NLP bound that worked with only positive definite covariance matrices. Finally, we introduce a novel and very effective diagonal-scaling technique for MERSP, employing a positive vector of parameters. Numerical experiments on benchmark instances demonstrate the effectiveness of our approaches in advancing the state of the art for calculating upper bounds on MERSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20970v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>The dual-path fixing strategy and its application to the set-covering problem</title>
      <link>https://arxiv.org/abs/2601.20977</link>
      <description>arXiv:2601.20977v2 Announce Type: replace 
Abstract: We introduce the dual-path fixing strategy to exploit dual algorithms for solving relaxations of mixed-integer nonlinear-optimization problems. Such dual algorithms are naturally applied in the context of branch-and-bound, and eventual impact on the success of branch-and-bound is our strong motivation. Our fixing strategy aims to be more powerful than the common strategy of fixing variables based on a single dual-feasible solution (e.g., standard reduced-cost fixing for mixed-integer linear optimization), but to be much faster than ``strong fixing'', essentially requiring no more time than that of the dual algorithm that we exploit. We have successfully tested our ideas on mixed-integer linear-optimization set-covering instances from the literature, in the context of the dual-simplex method applied to the continuous relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20977v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paulo Michel F. Yamagishi, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>An Information-Theoretic Analysis of Continuous-Time Control and Filtering Limitations by the I-MMSE Relationships</title>
      <link>https://arxiv.org/abs/2201.00995</link>
      <description>arXiv:2201.00995v3 Announce Type: replace-cross 
Abstract: While information theory has been introduced to characterize the fundamental limitations of control and filtering for a few decades, the existing information-theoretic methods are indirect and cumbersome for analyzing the limitations of continuous-time systems. To answer this challenge, we lift the information-theoretic analysis to continuous function spaces by the I-MMSE relationships. Continuous-time control and filtering systems are modeled into the additive Gaussian channels with and without feedback, and the total information rate is identified as a control and filtering trade-off metric and calculated from the estimation error of channel inputs. Fundamental constraints for this trade-off metric are first derived in a general setup and then used to capture the limitations of various control and filtering systems subject to linear and nonlinear plant models. For linear scenarios, we show that the total information rate quantifies the performance limits, such as the minimum entropy cost and the lowest achievable mean-square estimation error, in the time domain. For nonlinear systems, we provide a direct method to calculate and interpret the total information rate and its lower bound by the Stratonovich-Kushner equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.00995v3</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neng Wan, Dapeng Li, Naira Hovakimyan</dc:creator>
    </item>
    <item>
      <title>Safe Control and Learning Using Generalized Action Governor</title>
      <link>https://arxiv.org/abs/2211.12628</link>
      <description>arXiv:2211.12628v3 Announce Type: replace-cross 
Abstract: This paper introduces the Generalized Action Governor (AG), a supervisory scheme that augments a nominal closed-loop system with the capability to enforce state and input constraints through online action adjustment. We develop a generalized AG theory for discrete-time systems under bounded uncertainties, and relax the usual requirement of positive invariance to returnability of a safe set. Based on the theory, we present tailored AG design procedures for linear systems and for discrete systems with finite state and action spaces. We further study safe online learning enabled by the AG and present two safe learning strategies, namely safe Q-learning and safe data-driven Koopman operator-based control, both integrated with the AG to guarantee constraint satisfaction during learning. Numerical results illustrate the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.12628v3</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peiyuan Fang, Weiqi Zhang, Lu Xiong, Nan Li, Yanjun Huang, Yutong Li, Ilya Kolmanovsky, Anouck Girard, H. Eric Tseng, Dimitar Filev</dc:creator>
    </item>
    <item>
      <title>The Gittins index is optimal for dynamic allocation with conditionally independent filtrations</title>
      <link>https://arxiv.org/abs/2312.09350</link>
      <description>arXiv:2312.09350v2 Announce Type: replace-cross 
Abstract: The dynamic allocation problem, also known as the `multi-armed bandit' problem, simulates a situation in which an agent is faced with a tradeoff between actions that yield an immediate reward and actions whose benefits can only be perceived in the future. In this paper, we show that the non-Markovian, discrete-time problem can be solved by following a Gittins index strategy, without the assumption that the rewards processes are independent. Instead, we require the underlying multi-parameter filtration to satisfy a conditional independence property. We provide three representations of the maximal attainable value under an optimal strategy. Furthermore, we discuss the relationship between index-type strategies and the `synchronization' paradigm from operations research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09350v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Wang</dc:creator>
    </item>
    <item>
      <title>End-to-End Conformal Calibration for Optimization Under Uncertainty</title>
      <link>https://arxiv.org/abs/2409.20534</link>
      <description>arXiv:2409.20534v2 Announce Type: replace-cross 
Abstract: Machine learning can significantly improve performance for decision-making under uncertainty across a wide range of domains. However, ensuring robustness guarantees requires well-calibrated uncertainty estimates, which can be difficult to achieve with neural networks. Moreover, in high-dimensional settings, there may be many valid uncertainty estimates, each with its own performance profile - i.e., not all uncertainty is equally valuable for downstream decision-making. To address this problem, this paper develops an end-to-end framework to learn uncertainty sets for conditional robust optimization in a way that is informed by the downstream decision-making loss, with robustness and calibration guarantees provided by conformal prediction. In addition, we propose to represent general convex uncertainty sets with partially input-convex neural networks, which are learned as part of our framework. Our approach consistently improves upon two-stage estimate-then-optimize baselines on concrete applications in energy storage arbitrage and portfolio optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20534v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, December 2025</arxiv:journal_reference>
      <dc:creator>Christopher Yeh, Nicolas Christianson, Alan Wu, Adam Wierman, Yisong Yue</dc:creator>
    </item>
    <item>
      <title>High-order Accurate Inference on Manifolds</title>
      <link>https://arxiv.org/abs/2501.06652</link>
      <description>arXiv:2501.06652v3 Announce Type: replace-cross 
Abstract: We present a new framework for statistical inference on Riemannian manifolds that achieves high-order accuracy, addressing the challenges posed by non-Euclidean parameter spaces frequently encountered in modern data science. Our approach leverages a novel and computationally efficient procedure to reach higher-order asymptotic precision. In particular, we develop a bootstrap algorithm on Riemannian manifolds that is both computationally efficient and accurate for hypothesis testing and confidence region construction. Although locational hypothesis testing can be reformulated as a standard Euclidean problem, constructing high-order accurate confidence regions necessitates careful treatment of manifold geometry. To this end, we establish high-order asymptotics under an appropriate coordinate representation induced by a second-order retraction, thereby enabling precise expansions that incorporate curvature effects. We demonstrate the versatility of this framework across various manifold settings, including spheres, the Stiefel manifold, fixed-rank matrix manifolds, and rank-one tensor manifolds; for Euclidean submanifolds, we also introduce a class of projection-like coordinate charts with strong consistency properties. Finally, numerical studies confirm the practical merits of the proposed procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06652v3</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chengzhu Huang, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic MPC with Online-optimized Policies and Closed-loop Guarantees</title>
      <link>https://arxiv.org/abs/2502.06469</link>
      <description>arXiv:2502.06469v2 Announce Type: replace-cross 
Abstract: This paper proposes a stochastic model predictive control method for linear systems affected by additive Gaussian disturbances that optimizes over disturbance feedback matrices online. Closed-loop satisfaction of probabilistic constraints and recursive feasibility of the underlying convex optimization problem is guaranteed. Optimization over feedback policies online increases performance and reduces conservatism compared to fixed-feedback approaches. The central mechanism is a finitely determined maximal admissible set for probabilistic constraints, together with the reconditioning of the predicted probabilistic constraints on the current knowledge at every time step. The proposed method's applicability is demonstrated on a building temperature control example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06469v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcell Bartos, Alexandre Didier, Jerome Sieber, Johannes K\"ohler, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>An Overview of Low-Rank Structures in the Training and Adaptation of Large Models</title>
      <link>https://arxiv.org/abs/2503.19859</link>
      <description>arXiv:2503.19859v3 Announce Type: replace-cross 
Abstract: The substantial computational demands of modern large-scale deep learning present significant challenges for efficient training and deployment. Recent research has revealed a widespread phenomenon wherein deep networks inherently learn low-rank structures in their weights and representations during training. This tutorial paper provides a comprehensive review of advances in identifying and exploiting these low-rank structures, bridging mathematical foundations with practical applications. We present two complementary theoretical perspectives on the emergence of low-rankness: viewing it through the optimization dynamics of gradient descent throughout training, and understanding it as a result of implicit regularization effects at convergence. Practically, these theoretical perspectives provide a foundation for understanding the success of techniques such as Low-Rank Adaptation (LoRA) in fine-tuning, inspire new parameter-efficient low-rank training strategies, and explain the effectiveness of masked training approaches like dropout and masked self-supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19859v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Balzano, Tianjiao Ding, Benjamin D. Haeffele, Soo Min Kwon, Qing Qu, Peng Wang, Zhangyang Wang, Can Yaras</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.10007</link>
      <description>arXiv:2505.10007v3 Announce Type: replace-cross 
Abstract: Motivated by practical applications where stable long-term performance is critical-such as robotics, operations research, and healthcare-we study the problem of distributionally robust (DR) average-reward reinforcement learning. We propose two algorithms that achieve near-optimal sample complexity. The first reduces the problem to a DR discounted Markov decision process (MDP), while the second, Anchored DR Average-Reward MDP, introduces an anchoring state to stabilize the controlled transition kernels within the uncertainty set. Assuming the nominal MDP is uniformly ergodic, we prove that both algorithms attain a sample complexity of $\widetilde{O}\left(|\mathbf{S}||\mathbf{A}| t_{\mathrm{mix}}^2\varepsilon^{-2}\right)$ for estimating the optimal policy as well as the robust average reward under KL and $f_k$-divergence-based uncertainty sets, provided the uncertainty radius is sufficiently small. Here, $\varepsilon$ is the target accuracy, $|\mathbf{S}|$ and $|\mathbf{A}|$ denote the sizes of the state and action spaces, and $t_{\mathrm{mix}}$ is the mixing time of the nominal MDP. This represents the first finite-sample convergence guarantee for DR average-reward reinforcement learning. We further validate the convergence rates of our algorithms through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10007v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijun Chen, Shengbo Wang, Nian Si</dc:creator>
    </item>
    <item>
      <title>When higher-order interactions enhance synchronization: the case of the Kuramoto model on random hypergraphs</title>
      <link>https://arxiv.org/abs/2508.10992</link>
      <description>arXiv:2508.10992v2 Announce Type: replace-cross 
Abstract: Synchronization is a fundamental phenomenon in complex systems, observed across a wide range of natural and engineered contexts. The Kuramoto model provides a foundational framework for understanding synchronization among coupled oscillators, traditionally assuming pairwise interactions. However, many real-world systems exhibit group and many-body interactions, which can be effectively modeled through hypergraphs. Previous studies suggest that higher-order interactions shrink the attraction basin of the synchronous state, making it harder to reach and potentially impairing synchronization, despite enriching the dynamics. In this work, we show that this is not always the case. Through a numerical study of higher-order Kuramoto models on random hypergraphs, we find that while strong higher-order interactions do generally work against synchronization, weak higher-order interactions can actually enhance it when combined with pairwise ones. This result is further corroborated by a cost-benefit analysis: under a constrained budget of both pairwise and higher-order interactions, a mixed allocation involving both consistently achieves higher synchronization than relying on either interaction type alone. These findings provide new insights into the role of higher-order interactions in shaping collective dynamics and point to design principles for optimizing synchronization in complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10992v2</guid>
      <category>nlin.AO</category>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <category>nlin.PS</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Muolo, Hiroya Nakao, Marco Coraggio</dc:creator>
    </item>
    <item>
      <title>Flatness-Aware Stochastic Gradient Langevin Dynamics</title>
      <link>https://arxiv.org/abs/2510.02174</link>
      <description>arXiv:2510.02174v2 Announce Type: replace-cross 
Abstract: Flatness of the loss landscape has been widely studied as an important perspective for understanding the behavior and generalization of deep learning algorithms. Motivated by this view, we propose Flatness-Aware Stochastic Gradient Langevin Dynamics (fSGLD), a first-order optimization method that biases learning its dynamics toward flat basins while retaining the computational and memory efficiency of SGD and SGLD. We provide a non-asymptotic theoretical analysis showing that fSGLD converges to a flatness-biased Gibbs distribution under a theoretically prescribed coupling between the noise scale $\sigma$ and the inverse temperature $\beta$, together with explicit excess risk guarantees. We empirically evaluate fSGLD across standard optimizer benchmarks, Bayesian image classification, uncertainty quantification, and out-of-distribution detection, demonstrating consistently strong performance and reliable uncertainty estimates. Additional experiments confirm the effectiveness of the theoretically prescribed $\beta$-$\sigma$ coupling compared to decoupled choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02174v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Bruno, Youngsik Hwang, Jaehyeon An, Sotirios Sabanis, Dong-Young Lim</dc:creator>
    </item>
    <item>
      <title>A Neural Surrogate-Enhanced Multi-Method Framework for Robust Wing Design Optimization</title>
      <link>https://arxiv.org/abs/2510.08582</link>
      <description>arXiv:2510.08582v4 Announce Type: replace-cross 
Abstract: This paper introduces a modular and scalable design optimization framework for the wing design process that enables faster early-phase design while ensuring aerodynamic stability. The pipeline starts with the generation of initial wing geometries and then proceeds to optimize the wing using several algorithms. Aerodynamic performance is assessed using a Vortex Lattice Method (VLM) applied to a carefully selected dataset of wing configurations. These results are employed to develop surrogate neural network models, which can predict lift and drag rapidly and accurately. The stability evaluation is implemented by setting the control surfaces and components to fixed positions in order to have realistic flight dynamics. The approach unifies and compares several optimization techniques, including Particle Swarm Optimization (PSO), Genetic Algorithms (GA), gradient-based MultiStart methods, Bayesian optimization, and Lipschitz optimization. Each method ensures constraint management via adaptive strategies and penalty functions, where the targets for lift and design feasibility are enforced. The progression of aerodynamic characteristics and geometries over the optimization iterations will be investigated in order to clarify each algorithm's convergence characteristics and performance efficiency. Our results show improvement in aerodynamic qualities and robust stability properties, offering a mechanism for wing design at speed and precision. In the interest of reproducibility and community development, the complete implementation is publicly available at Github.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08582v4</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Fath Lipaei, AmirHossein Ghaemi, Melika Sabzikari</dc:creator>
    </item>
    <item>
      <title>DER Day-Ahead Offering: A Neural Network Column-and-Constraint Generation Approach</title>
      <link>https://arxiv.org/abs/2511.12384</link>
      <description>arXiv:2511.12384v2 Announce Type: replace-cross 
Abstract: In the day-ahead energy market, the offering strategy of distributed energy resource (DER) aggregators must be submitted before the uncertainty realization in the form of price-quantity pairs. This work addresses the day-ahead offering problem through a two-stage adaptive robust stochastic optimization model, wherein the first-stage price-quantity pairs and second-stage operational commitment decisions are made before and after DER uncertainty is realized, respectively. Uncertainty in day-ahead price is addressed using a stochastic programming-based approach, while uncertainty of DER generation is handled through robust optimization. To address the max-min structure of the second-stage problem, a neural network-accelerated column-and-constraint generation method is developed. A dedicated neural network is trained to approximate the value function, while optimality is maintained by the design of the network architecture. Numerical studies indicate that the proposed method yields high-quality solutions and is up to 100 times faster than Gurobi and 33 times faster than classical column-and-constraint generation on the same 1028-node synthetic distribution network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12384v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiqi Meng, Hongyi Li, Bai Cui</dc:creator>
    </item>
    <item>
      <title>Performative Policy Gradient: Optimality in Performative Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.20576</link>
      <description>arXiv:2512.20576v2 Announce Type: replace-cross 
Abstract: Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms the existing performative RL algorithms aiming for stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20576v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Debabrota Basu, Udvas Das, Brahim Driss, Uddalak Mukherjee</dc:creator>
    </item>
    <item>
      <title>Analytic and Variational Stability in Deep Learning Systems</title>
      <link>https://arxiv.org/abs/2512.21208</link>
      <description>arXiv:2512.21208v2 Announce Type: replace-cross 
Abstract: We propose a unified analytic and variational framework for stability in deep learning systems viewed as coupled representation-parameter dynamics. The central object is the Learning Stability Profile, which measures how infinitesimal perturbations propagate through representations, parameters, and update mechanisms along the learning trajectory.
  Our main result, the Fundamental Analytic Stability Theorem, shows that uniform boundedness of these sensitivities is equivalent, up to norm equivalence, to the existence of a Lyapunov-type energy dissipating along the learning flow. In smooth regimes, this yields explicit stability exponents linking spectral norms, activation regularity, step sizes, and learning rates to contractive behavior. Classical spectral stability of feedforward networks, CFL-type conditions for residual architectures, and temporal stability laws for stochastic gradient methods follow as direct consequences.
  The framework extends to non-smooth systems, including ReLU networks, proximal and projected updates, and stochastic subgradient flows, by replacing classical derivatives with Clarke generalized derivatives and smooth energies with variational Lyapunov functionals.
  The resulting theory provides a unified dynamical description of stability across architectures and optimization methods, clarifying how design and training choices jointly control robustness and sensitivity to perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21208v2</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Katende</dc:creator>
    </item>
    <item>
      <title>A Counterexample to the Optimality Conjecture in Convex Quantum Channel Optimization</title>
      <link>https://arxiv.org/abs/2512.22863</link>
      <description>arXiv:2512.22863v2 Announce Type: replace-cross 
Abstract: This paper presents a counterexample to the optimality conjecture in convex quantum channel optimization proposed by Coutts et al. The conjecture posits that for nuclear norm minimization problems in quantum channel optimization, the dual certificate of an optimal solution can be uniquely determined via the spectral calculus of the Choi matrix. By constructing a counterexample in 2-dimensional Hilbert spaces, we disprove this conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22863v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianting Yang</dc:creator>
    </item>
    <item>
      <title>Optimization of maximal quantum f-divergences between unitary orbits</title>
      <link>https://arxiv.org/abs/2601.08268</link>
      <description>arXiv:2601.08268v2 Announce Type: replace-cross 
Abstract: Maximal quantum $f$-divergences, defined via the commutant Radon--Nikodym derivative, form a fundamental class of distinguishability measures for quantum states associated with operator convex functions. In this paper, we study the optimization of maximal quantum $f$-divergences along unitary orbits of two quantum states.
  For any operator convex function $f:(0,+\infty)\to\mathbb{R}$, we determine the exact minimum and maximum of $$ U \longmapsto \widehat S_f(\rho\|U^*\sigma U) $$ over the unitary group, and derive explicit spectral formulas for these extremal values together with complete characterizations of the unitaries that attain them.
  Our approach combines the integral representation of operator convex functions with majorization theory and a unitary-orbit variational method. A key step is to show that any extremizer must commute with the reference state, which reduces the noncommutative optimization problem to a spectral permutation problem. As a consequence, the minimum is achieved by pairing the decreasing eigenvalues of $\rho$ and $\sigma$, while the maximum corresponds to pairing the decreasing eigenvalues of $\rho$ with the increasing eigenvalues of $\sigma$. Hence, the range of the maximal quantum $f$-divergence along the unitary orbit is exactly the closed interval determined by these two extremal configurations.
  Finally, we compare our results with recent unitary-orbit optimization results for quantum $f$-divergences defined via the quantum hockey-stick divergence, highlighting fundamental structural differences between the two frameworks. Our findings extend earlier extremal results for Umegaki, R\'enyi, and related quantum divergences, and clarify the distinct operator-theoretic nature of maximal quantum $f$-divergences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08268v2</guid>
      <category>math.QA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Minh Nguyen, Hoang An Nguyen, Cong Trinh Le</dc:creator>
    </item>
  </channel>
</rss>
