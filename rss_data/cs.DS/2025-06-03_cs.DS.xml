<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jun 2025 01:53:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Randomized Dimensionality Reduction for Euclidean Maximization and Diversity Measures</title>
      <link>https://arxiv.org/abs/2506.00165</link>
      <description>arXiv:2506.00165v1 Announce Type: new 
Abstract: Randomized dimensionality reduction is a widely-used algorithmic technique for speeding up large-scale Euclidean optimization problems. In this paper, we study dimension reduction for a variety of maximization problems, including max-matching, max-spanning tree, max TSP, as well as various measures for dataset diversity. For these problems, we show that the effect of dimension reduction is intimately tied to the \emph{doubling dimension} $\lambda_X$ of the underlying dataset $X$ -- a quantity measuring intrinsic dimensionality of point sets. Specifically, we prove that a target dimension of $O(\lambda_X)$ suffices to approximately preserve the value of any near-optimal solution,which we also show is necessary for some of these problems. This is in contrast to classical dimension reduction results, whose dependence increases with the dataset size $|X|$. We also provide empirical results validating the quality of solutions found in the projected space, as well as speedups due to dimensionality reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00165v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Gao, Rajesh Jayaram, Benedikt Kolbe, Shay Sapir, Chris Schwiegelshohn, Sandeep Silwal, Erik Waingarten</dc:creator>
    </item>
    <item>
      <title>Faster negative length shortest paths by bootstrapping hop reducers</title>
      <link>https://arxiv.org/abs/2506.00428</link>
      <description>arXiv:2506.00428v1 Announce Type: new 
Abstract: The textbook algorithm for real-weighted single-source shortest paths takes $O(m n)$ time on a graph with $m$ edges and $n$ vertices. The breakthrough algorithm by Fineman [Fin24] takes $\tilde{O}(m n^{8/9})$ randomized time. The running time was subsequently improved to $\tilde{O}(mn^{4/5})$ [HJQ25].
  We build on [Fin24; HJQ25] to obtain an $\tilde{O}(m n^{3/4} + m^{4/5} n)$ randomized running time. (Equivalently, $\tilde{O}(mn^{3/4})$ for $m \geq n^{5/4}$, and $\tilde{O}(m^{4/5} n)$ for $m \leq n^{5/4}$.) The main new technique replaces the hop-reducing auxiliary graph from [Fin24] with a bootstrapping process where constant-hop reducers for small subgraphs of the input graph are iteratively amplified and expanded until the desired polynomial-hop reduction is achieved over the entire graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00428v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Huang, Peter Jin, Kent Quanrud</dc:creator>
    </item>
    <item>
      <title>Controlling the Spread of Epidemics on Networks with Differential Privacy</title>
      <link>https://arxiv.org/abs/2506.00745</link>
      <description>arXiv:2506.00745v1 Announce Type: new 
Abstract: Designing effective strategies for controlling epidemic spread by vaccination is an important question in epidemiology, especially in the early stages when vaccines are limited. This is a challenging question when the contact network is very heterogeneous, and strategies based on controlling network properties, such as the degree and spectral radius, have been shown to be effective. Implementation of such strategies requires detailed information on the contact structure, which might be sensitive in many applications. Our focus here is on choosing effective vaccination strategies when the edges are sensitive and differential privacy guarantees are needed. Our main contributions are $(\varepsilon,\delta)$-differentially private algorithms for designing vaccination strategies by reducing the maximum degree and spectral radius. Our key technique is a private algorithm for the multi-set multi-cover problem, which we use for controlling network properties. We evaluate privacy-utility tradeoffs of our algorithms on multiple synthetic and real-world networks, and show their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00745v1</guid>
      <category>cs.DS</category>
      <category>cs.CE</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dung Nguyen, Aravind Srinivasan, Renata Valieva, Anil Vullikanti, Jiayi Wu</dc:creator>
    </item>
    <item>
      <title>Learning DNF through Generalized Fourier Representations</title>
      <link>https://arxiv.org/abs/2506.01075</link>
      <description>arXiv:2506.01075v1 Announce Type: new 
Abstract: The Fourier representation for the uniform distribution over the Boolean cube has found numerous applications in algorithms and complexity analysis. Notably, in learning theory, learnability of Disjunctive Normal Form (DNF) under uniform as well as product distributions has been established through such representations. This paper makes five main contributions. First, it introduces a generalized Fourier expansion that can be used with any distribution $D$ through the representation of the distribution as a Bayesian network (BN). Second, it shows that the main algorithmic tools for learning with the Fourier representation, that use membership queries to approximate functions by recovering their heavy Fourier coefficients, can be used with slight modifications with the generalized expansion. These results hold for any distribution. Third, it analyzes the $L_1$ spectral norm of conjunctions under the new expansion, showing that it is bounded for a class of distributions which can be represented by difference bounded tree BN, where a parent node in the BN representation can change the conditional expectation of a child node by at most $\alpha&lt;0.5$. Lower bounds are presented to show that such constraints are necessary. The fourth contribution uses these results to show the learnability of DNF with membership queries under difference bounded tree BN. The final contribution is to develop an algorithm for learning difference-bounded tree BN distributions, thus extending the DNF learnability result to cases where the distribution is not known in advance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01075v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Heidari, Roni Khardon</dc:creator>
    </item>
    <item>
      <title>BWT for string collections</title>
      <link>https://arxiv.org/abs/2506.01092</link>
      <description>arXiv:2506.01092v1 Announce Type: new 
Abstract: We survey the different methods used for extending the BWT to collections of strings, following largely [Cenzato and Lipt\'ak, CPM 2022, Bioinformatics 2024]. We analyze the specific aspects and combinatorial properties of the resulting BWT variants and give a categorization of publicly available tools for computing the BWT of string collections. We show how the specific method used impacts on the resulting transform, including the number of runs, and on the dynamicity of the transform with respect to adding or removing strings from the collection. We then focus on the number of runs of these BWT variants and present the optimal BWT introduced in [Cenzato et al., DCC 2023], which implements an algorithm originally proposed by [Bentley et al., ESA 2020] to minimize the number of BWT-runs. We also discuss several recent heuristics and study their impact on the compression of biological sequences. We conclude with an overview of the applications and the impact of the BWT of string collections in bioinformatics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01092v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Cenzato, Zsuzsanna Lipt\'ak, Nadia Pisanti, Giovanna Rosone, Marinella Sciortino</dc:creator>
    </item>
    <item>
      <title>Nearly-Linear Time Private Hypothesis Selection with the Optimal Approximation Factor</title>
      <link>https://arxiv.org/abs/2506.01162</link>
      <description>arXiv:2506.01162v1 Announce Type: new 
Abstract: Estimating the density of a distribution from its samples is a fundamental problem in statistics. Hypothesis selection addresses the setting where, in addition to a sample set, we are given $n$ candidate distributions -- referred to as hypotheses -- and the goal is to determine which one best describes the underlying data distribution. This problem is known to be solvable very efficiently, requiring roughly $O(\log n)$ samples and running in $\tilde{O}(n)$ time. The quality of the output is measured via the total variation distance to the unknown distribution, and the approximation factor of the algorithm determines how large this distance is compared to the optimal distance achieved by the best candidate hypothesis. It is known that $\alpha = 3$ is the optimal approximation factor for this problem. We study hypothesis selection under the constraint of differential privacy. We propose a differentially private algorithm in the central model that runs in nearly-linear time with respect to the number of hypotheses, achieves the optimal approximation factor, and incurs only a modest increase in sample complexity, which remains polylogarithmic in $n$. This resolves an open question posed by [Bun, Kamath, Steinke, Wu, NeurIPS 2019]. Prior to our work, existing upper bounds required quadratic time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01162v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Aliakbarpour, Zhan Shi, Ria Stevens, Vincent X. Wang</dc:creator>
    </item>
    <item>
      <title>Reweighted Spectral Partitioning Works: Bounds for Special Graph Classes</title>
      <link>https://arxiv.org/abs/2506.01228</link>
      <description>arXiv:2506.01228v1 Announce Type: new 
Abstract: Spectral partitioning is a method that can be used to compute small sparse cuts or small edge-separators in a wide variety of graph classes, by computing the second-smallest eigenvalue (and eigenvector) of the Laplacian matrix. Upper bounds on this eigenvalue for certain graph classes imply that the method obtains small edge-separators for these classes, usually with a sub-optimal dependence on the maximum degree. In this work, we show that a related method, called reweighted spectral partitioning, guarantees near-optimal sparse vertex-cuts and vertex-separators in a wide variety of graph classes. In many cases, this involves little-to-no necessary dependence on maximum degree.
  We also obtain a new proof of the planar separator theorem, a strengthened eigenvalue bound for bounded-genus graphs, and a refined form of the recent Cheeger-style inequality for vertex expansion via a specialized dimension-reduction step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01228v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jack Spalding-Jamieson</dc:creator>
    </item>
    <item>
      <title>A Ranking Framework for Network Resource Allocation and Scheduling via Hypergraphs</title>
      <link>https://arxiv.org/abs/2506.01571</link>
      <description>arXiv:2506.01571v1 Announce Type: new 
Abstract: Resource allocation and scheduling are a common problem in various distributed systems. Although widely studied, the state-of-the-art solutions either do not scale or lack the expressive power to capture the most complex instances of the problem. To that end, we present a mathematical framework for hypergraph ranking and analysis, unifying graph theory, lattice theory, and semantic analysis. In our fundamental theorem, we prove the existence of partial order on entities of hypergraphs, extending traditional hypergraph analysis by introducing semantic operators that capture relationships between vertices and hyperedges. Within the boundaries of our framework, we introduce an algorithm to rank the node-hyperedge pairs with respect to the captured semantics. The strength of our approach lies in its applicability to complex ranking problems that can be modeled as hypergraphs, including network resource allocation, task scheduling, and table selection in Text-to-SQL. Through simulations, we demonstrate that our framework delivers nearly optimal problem solutions at a superior run time performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01571v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rajpreet Singh, Novak Bo\v{s}kov, Aditya Gudal, Manzoor A. Khan</dc:creator>
    </item>
    <item>
      <title>The Price of Being Partial: Complexity of Partial Generalized Dominating Set on Bounded-Treewidth Graphs</title>
      <link>https://arxiv.org/abs/2506.01645</link>
      <description>arXiv:2506.01645v1 Announce Type: new 
Abstract: The $(\sigma, \rho)$-domination framework introduced by Telle [Nord. J. Comput.'94] captures many classical graph problems. For fixed sets $\sigma, \rho$ of non-negative integers, a $(\sigma,\rho)$-set of a graph $G$ is a set $S$ such that for every $v\in V(G)$, we have (1) if $v \in S$, then $|N(v) \cap S| \in \sigma$, and (2) if $v \not\in S$, then $|N(v) \cap S| \in \rho$. We initiate the study of a natural partial variant of the problem, in which the constraints given by $\sigma, \rho$ need not be fulfilled for all vertices, but we want to maximize the number of vertices that are happy in the sense that they satisfy (1) or (2) above. Given a graph $G$ and integers $k$ and $\ell$, the task of $(\sigma,\rho)$-MinParDomSet is to decide whether there is a set $S \subseteq V(G)$ of size at most $k$ such that at most $\ell$ vertices of the graph are not happy under $S$.
  We consider the problem on graphs of bounded treewidth for nonempty finite or simple cofinite sets $\sigma$ and $\rho$, and give matching upper and lower bounds for every such fixed $\sigma$ and $\rho$ (under the Primal Pathwidth Strong Exponential Time Hypothesis). Let $s_\sigma^\textsf{p} = \max \sigma + 1$ when $\sigma$ is finite, and $\min \sigma$ when $\sigma$ is simple cofinite; define $s_\rho^{\textsf{p}}$ similarly for $\rho$. We show that the problem $(\sigma,\rho)$-MinParDomSet (1) can be solved in time $(s_\sigma^\textsf{p} + s_\rho^{\textsf{p}} + 2)^{tw} \cdot |G|^{O(1)}$, when a tree decomposition of width $tw$ is provided together with the input, and (2) for any $\varepsilon&gt;0$, no algorithm can exist that solves the problem in time $(s_\sigma^\textsf{p} + s_\rho^{\textsf{p}} + 2 - \varepsilon)^{pw} \cdot |G|^{O(1)}$, even when a path decomposition of width $pw$ is provided together with the input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01645v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob Greilhuber, D\'aniel Marx</dc:creator>
    </item>
    <item>
      <title>A 0.51-Approximation of Maximum Matching in Sublinear $n^{1.5}$ Time</title>
      <link>https://arxiv.org/abs/2506.01669</link>
      <description>arXiv:2506.01669v1 Announce Type: new 
Abstract: We study the problem of estimating the size of a maximum matching in sublinear time. The problem has been studied extensively in the literature and various algorithms and lower bounds are known for it. Our result is a $0.5109$-approximation algorithm with a running time of $\tilde{O}(n\sqrt{n})$.
  All previous algorithms either provide only a marginal improvement (e.g., $2^{-280}$) over the $0.5$-approximation that arises from estimating a \emph{maximal} matching, or have a running time that is nearly $n^2$. Our approach is also arguably much simpler than other algorithms beating $0.5$-approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01669v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepideh Mahabadi, Mohammad Roghani, Jakub Tarnawski</dc:creator>
    </item>
    <item>
      <title>Tradeoffs between Mistakes and ERM Oracle Calls in Online and Transductive Online Learning</title>
      <link>https://arxiv.org/abs/2506.00135</link>
      <description>arXiv:2506.00135v1 Announce Type: cross 
Abstract: We study online and transductive online learning when the learner interacts with the concept class only via Empirical Risk Minimization (ERM) or weak consistency oracles on arbitrary instance subsets. This contrasts with standard online models, where the learner knows the entire class. The ERM oracle returns a hypothesis minimizing loss on a given subset, while the weak consistency oracle returns a binary signal indicating whether the subset is realizable by some concept. The learner is evaluated by the number of mistakes and oracle calls. In the standard online setting with ERM access, we prove tight lower bounds in both realizable and agnostic cases: $\Omega(2^{d_{VC}})$ mistakes and $\Omega(\sqrt{T 2^{d_{LD}}})$ regret, where $T$ is the number of timesteps and $d_{LD}$ is the Littlestone dimension. We further show that existing online learning results with ERM access carry over to the weak consistency setting, incurring an additional $O(T)$ in oracle calls. We then consider the transductive online model, where the instance sequence is known but labels are revealed sequentially. For general Littlestone classes, we show that optimal realizable and agnostic mistake bounds can be achieved using $O(T^{d_{VC}+1})$ weak consistency oracle calls. On the negative side, we show that limiting the learner to $\Omega(T)$ weak consistency queries is necessary for transductive online learnability, and that restricting the learner to $\Omega(T)$ ERM queries is necessary to avoid exponential dependence on the Littlestone dimension. Finally, for certain concept classes, we reduce oracle calls via randomized algorithms while maintaining similar mistake bounds. In particular, for Thresholds on an unknown ordering, $O(\log T)$ ERM queries suffice; for $k$-Intervals, $O(T^3 2^{2k})$ weak consistency queries suffice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00135v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Idan Attias, Steve Hanneke, Arvind Ramaswami</dc:creator>
    </item>
    <item>
      <title>Learning Juntas under Markov Random Fields</title>
      <link>https://arxiv.org/abs/2506.00764</link>
      <description>arXiv:2506.00764v1 Announce Type: cross 
Abstract: We give an algorithm for learning $O(\log n)$ juntas in polynomial-time with respect to Markov Random Fields (MRFs) in a smoothed analysis framework where only the external field has been randomly perturbed. This is a broad generalization of the work of Kalai and Teng, who gave an algorithm that succeeded with respect to smoothed product distributions (i.e., MRFs whose dependency graph has no edges). Our algorithm has two phases: (1) an unsupervised structure learning phase and (2) a greedy supervised learning algorithm. This is the first example where algorithms for learning the structure of an undirected graphical model lead to provably efficient algorithms for supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00764v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gautam Chandrasekaran, Adam Klivans</dc:creator>
    </item>
    <item>
      <title>Constant-Factor Algorithms for Revenue Management with Consecutive Stays</title>
      <link>https://arxiv.org/abs/2506.00909</link>
      <description>arXiv:2506.00909v1 Announce Type: cross 
Abstract: We study network revenue management problems motivated by applications such as railway ticket sales and hotel room bookings. Request types that require a resource for consecutive stays sequentially arrive with known arrival probabilities. We investigate two scenarios: the reject-or-accept scenario, where the request can be fulfilled by any available resource, and the choice-based scenario, which generalizes the former by incorporating customer preferences through basic attraction models. We develop constant-factor approximation algorithms: $1-1/e$ for the reject-or-accept scenario and $0.125$ for the choice-based scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00909v1</guid>
      <category>econ.TH</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Hu, Tongwen Wu</dc:creator>
    </item>
    <item>
      <title>Speeding Up Hyper-Heuristics With Markov-Chain Operator Selection and the Only-Worsening Acceptance Operator</title>
      <link>https://arxiv.org/abs/2506.01107</link>
      <description>arXiv:2506.01107v1 Announce Type: cross 
Abstract: The move-acceptance hyper-heuristic was recently shown to be able to leave local optima with astonishing efficiency (Lissovoi et al., Artificial Intelligence (2023)). In this work, we propose two modifications to this algorithm that demonstrate impressive performances on a large class of benchmarks including the classic Cliff$_d$ and Jump$_m$ function classes. (i) Instead of randomly choosing between the only-improving and any-move acceptance operator, we take this choice via a simple two-state Markov chain. This modification alone reduces the runtime on Jump$_m$ functions with gap parameter $m$ from $\Omega(n^{2m-1})$ to $O(n^{m+1})$. (ii) We then replace the all-moves acceptance operator with the operator that only accepts worsenings. Such a, counter-intuitive, operator has not been used before in the literature. However, our proofs show that our only-worsening operator can greatly help in leaving local optima, reducing, e.g., the runtime on Jump functions to $O(n^3 \log n)$ independent of the gap size. In general, we prove a remarkably good runtime of $O(n^{k+1} \log n)$ for our Markov move-acceptance hyper-heuristic on all members of a new benchmark class SEQOPT$_k$, which contains a large number of functions having $k$ successive local optima, and which contains the commonly studied Jump$_m$ and Cliff$_d$ functions for $k=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01107v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Joint Conference on Artificial Intelligence (IJCAI), 2025</arxiv:journal_reference>
      <dc:creator>Abderrahim Bendahi, Benjamin Doerr, Adrien Fradin, Johannes F. Lutzeyer</dc:creator>
    </item>
    <item>
      <title>Computing Diverse and Nice Triangulations</title>
      <link>https://arxiv.org/abs/2506.01323</link>
      <description>arXiv:2506.01323v1 Announce Type: cross 
Abstract: We initiate the study of computing diverse triangulations to a given polygon. Given a simple $n$-gon $P$, an integer $ k \geq 2 $, a quality measure $\sigma$ on the set of triangulations of $P$ and a factor $ \alpha \geq 1 $, we formulate the Diverse and Nice Triangulations (DNT) problem that asks to compute $k$ \emph{distinct} triangulations $T_1,\dots,T_k$ of $P$ such that a) their diversity, $\sum_{i &lt; j} d(T_i,T_j) $, is as large as possible \emph{and} b) they are nice, i.e., $\sigma(T_i) \leq \alpha \sigma^* $ for all $1\leq i \leq k$. Here, $d$ denotes the symmetric difference of edge sets of two triangulations, and $\sigma^*$ denotes the best quality of triangulations of $P$, e.g., the minimum Euclidean length.
  As our main result, we provide a $\mathrm{poly}(n,k)$-time approximation algorithm for the DNT problem that returns a collection of $k$ distinct triangulations whose diversity is at least $1 - \Theta(1/k)$ of the optimal, and each triangulation satisfies the quality constraint. This is accomplished by studying \emph{bi-criteria triangulations} (BCT), which are triangulations that simultaneously optimize two criteria, a topic of independent interest. We complement our approximation algorithms by showing that the DNT problem and the BCT problem are NP-hard.
  Finally, for the version where diversity is defined as $\min_{i &lt; j} d(T_i,T_j) $, we show a reduction from the problem of computing optimal Hamming codes, and provide an $n^{O(k)}$-time $\tfrac12$-approximation algorithm. Note that this improves over the naive brutef-orce $2^{O(nk)}$ time bound for enumerating all $k$-tuples among the triangulations of a simple $n$-gon, whose total number can be the $(n-2)$-th Catalan number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01323v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waldo G\'alvez, Mayank Goswami, Arturo Merino, GiBeom Park, Meng-Tsung Tsai</dc:creator>
    </item>
    <item>
      <title>New aspects of quantum topological data analysis: Betti number estimation, and testing and tracking of homology and cohomology classes</title>
      <link>https://arxiv.org/abs/2506.01432</link>
      <description>arXiv:2506.01432v1 Announce Type: cross 
Abstract: Recently, the application of quantum computation to topological data analysis (TDA) has received increasing attention. In particular, several quantum algorithms have been proposed for estimating (normalized) Betti numbers, a central challenge in TDA. However, it was recently proven that estimating Betti numbers is an NP-hard problem, revealing a complexity-theoretic limitation to achieving a generic quantum advantage for this task. Motivated by this limitation and inspired by previous progress, we explore broader quantum approaches to TDA. First, we consider scenarios in which a simplicial complex is specified in a more informative form, enabling alternative quantum algorithms to estimate Betti numbers and persistent Betti numbers. We then move beyond Betti numbers and study the problem of testing the homology class of a given cycle, as well as distinguishing between homology classes. We also introduce cohomological techniques for these problems, along with a quantum algorithm. We then discuss their potential use in the testing and tracking of homology classes, which can be useful for TDA applications. Our results show that, despite the hardness of general Betti number estimation, quantum algorithms can still offer speed-ups in structured settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01432v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.AT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nhat A. Nghiem, Junseo Lee</dc:creator>
    </item>
    <item>
      <title>Quantum Speedups for Bayesian Network Structure Learning</title>
      <link>https://arxiv.org/abs/2305.19673</link>
      <description>arXiv:2305.19673v2 Announce Type: replace 
Abstract: The Bayesian network structure learning (BNSL) problem asks for a directed acyclic graph that maximizes a given score function. For networks with $n$ nodes, the fastest known algorithms run in time $O(2^n n^2)$ in the worst case, with no improvement in the asymptotic bound for two decades. Inspired by recent advances in quantum computing, we ask whether BNSL admits a polynomial quantum speedup, that is, whether the problem can be solved by a quantum algorithm in time $O(c^n)$ for some constant $c$ less than $2$. We answer the question in the affirmative by giving two algorithms achieving $c \le 1.817$ and $c \le 1.982$ assuming the number of potential parent sets is, respectively, subexponential and $O(1.453^n)$. Both algorithms assume the availability of a quantum random access memory. We also prove that one presumably cannot lower the base $2$ for any classical algorithm, as that would refute the strong exponential time hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19673v2</guid>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juha Harviainen (University of Helsinki), Kseniya Rychkova (University of Queensland), Mikko Koivisto (University of Helsinki)</dc:creator>
    </item>
    <item>
      <title>Random-Order Interval Selection</title>
      <link>https://arxiv.org/abs/2407.20941</link>
      <description>arXiv:2407.20941v2 Announce Type: replace 
Abstract: In the problem of online unweighted interval selection, the objective is to maximize the number of non-conflicting intervals accepted by the algorithm. In the conventional online model of irrevocable decisions, there is an Omega(n) lower bound on the competitive ratio, even for randomized algorithms [Bachmann et al. 2013]. In a line of work that allows for revocable acceptances, [Faigle and Nawijn 1995] gave a greedy 1-competitive (i.e. optimal) algorithm in the real-time model, where intervals arrive in order of non-decreasing starting times. The natural extension of their algorithm in the adversarial (any-order) model is 2k-competitive [Borodin and Karavasilis 2023], when there are at most k different interval lengths, and that is optimal for all deterministic, and memoryless randomized algorithms. We study this problem in the random-order model, where the adversary chooses the instance, but the online sequence is a uniformly random permutation of the items. We consider the same algorithm that is optimal in the cases of the real-time and any-order models, and give an upper bound of 2.5 on the competitive ratio under random-order arrivals. We also initiate a study of utilizing random-order arrivals to extract random bits with the goal of derandomizing algorithms. Besides producing simple algorithms, simulating random bits through random arrivals enhances our understanding of the comparative strength of the two models. Our main extraction process returns a bit with a worst-case bias of 2 - sqrt(2) = 0.585 and operates under the mild assumption that there exist at least two distinct items in the input. We motivate the applicability of this process by using it to simulate a number of barely random algorithms for interval selection (single-length arbitrary weights, and C-benevolent instances), the general knapsack problem, string guessing, minimum makespan, and job throughput scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20941v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan Borodin, Christodoulos Karavasilis</dc:creator>
    </item>
    <item>
      <title>Almost Optimal Fully Dynamic $k$-Center Clustering with Recourse</title>
      <link>https://arxiv.org/abs/2410.11470</link>
      <description>arXiv:2410.11470v2 Announce Type: replace 
Abstract: In this paper, we consider the \emph{metric $k$-center} problem in the fully dynamic setting, where we are given a metric space $(V,d)$ evolving via a sequence of point insertions and deletions and our task is to maintain a subset $S \subseteq V$ of at most $k$ points that minimizes the objective $\max_{x \in V} \min_{y \in S}d(x, y)$. We want to design our algorithm so that we minimize its \emph{approximation ratio}, \emph{recourse} (the number of changes it makes to the solution $S$), and \emph{update time} (the time it takes to handle an update). We give a simple algorithm for dynamic $k$-center that maintains a $O(1)$-approximate solution with $O(1)$ amortized recourse and $\tilde O(k)$ amortized update time, \emph{obtaining near-optimal approximation, recourse, and update time simultaneously}. We obtain our result by combining a variant of the dynamic $k$-center algorithm of Bateni et al.~[SODA'23] with the dynamic sparsifier of Bhattacharya et al.~[NeurIPS'23].</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11470v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sayan Bhattacharya, Mart\'in Costa, Ermiya Farokhnejad, Silvio Lattanzi, Nikos Parotsidis</dc:creator>
    </item>
    <item>
      <title>Matroid Secretary via Labeling Schemes</title>
      <link>https://arxiv.org/abs/2411.12069</link>
      <description>arXiv:2411.12069v2 Announce Type: replace 
Abstract: The Matroid Secretary Problem (MSP) is one of the most prominent settings for online resource allocation and optimal stopping. A decision-maker is presented with a ground set of elements $E$ revealed sequentially and in random order. Upon arrival, an irrevocable decision is made in a take-it-or-leave-it fashion, subject to a feasibility constraint on the set of selected elements captured by a matroid defined over $E$. The decision-maker only has ordinal access to compare the elements, and the goal is to design an algorithm that selects every element of the optimal basis with probability at least $\alpha$ (i.e., $\alpha$-probability-competitive). While the existence of a constant probability-competitive algorithm for MSP remains a major open question, simple greedy policies are at the core of state-of-the-art algorithms for several matroid classes.
  We introduce a flexible and general algorithmic framework to analyze greedy-like algorithms for MSP based on constructing a language associated with the matroid. Using this language, we establish a lower bound on the probability-competitiveness of the algorithm by studying a corresponding Poisson point process that governs the words' distribution in the language. Using our framework, we break the state-of-the-art guarantee for laminar matroids by settling the probability-competitiveness of the greedy-improving algorithm to be exactly $1-\ln(2) \approx 0.3068$. We also showcase the capabilities of our framework in graphic matroids, to show a probability-competitiveness of $0.2693$ for simple graphs and $0.2504$ for general graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12069v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krist\'of B\'erczi, Vasilis Livanos, Jos\'e Soto, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Dynamic Consistent $k$-Center Clustering with Optimal Recourse</title>
      <link>https://arxiv.org/abs/2412.03238</link>
      <description>arXiv:2412.03238v3 Announce Type: replace 
Abstract: Given points from an arbitrary metric space and a sequence of point updates sent by an adversary, what is the minimum recourse per update (i.e., the minimum number of changes needed to the set of centers after an update), in order to maintain a constant-factor approximation to a $k$-clustering problem? This question has received attention in recent years under the name consistent clustering.
  Previous works by Lattanzi and Vassilvitskii [ICLM '17] and Fichtenberger, Lattanzi, Norouzi-Fard, and Svensson [SODA '21] studied $k$-clustering objectives, including the $k$-center and the $k$-median objectives, under only point insertions. In this paper we study the $k$-center objective in the fully dynamic setting, where the update is either a point insertion or a point deletion. Before our work, {\L}\k{a}cki, Haeupler, Grunau, Rozho\v{n}, and Jayaram [SODA '24] gave a deterministic fully dynamic constant-factor approximation algorithm for the $k$-center objective with worst-case recourse of $2$ per update.
  In this work, we prove that the $k$-center clustering problem admits optimal recourse bounds by developing a deterministic fully dynamic constant-factor approximation algorithm with worst-case recourse of $1$ per update. Moreover our algorithm performs simple choices based on light data structures, and thus is arguably more direct and faster than the previous one which uses a sophisticated combinatorial structure. Additionally, we develop a new deterministic decremental algorithm and a new deterministic incremental algorithm, both of which maintain a $6$-approximate $k$-center solution with worst-case recourse of $1$ per update. Our incremental algorithm improves over the $8$-approximation algorithm by Charikar, Chekuri, Feder, and Motwani [STOC '97]. Finally, we remark that since all three of our algorithms are deterministic, they work against an adaptive adversary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03238v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Forster, Antonis Skarlatos</dc:creator>
    </item>
    <item>
      <title>Adaptive Approximation Schemes for Matching Queues</title>
      <link>https://arxiv.org/abs/2501.08775</link>
      <description>arXiv:2501.08775v2 Announce Type: replace 
Abstract: We study a continuous-time, infinite-horizon dynamic bipartite matching problem. Suppliers arrive according to a Poisson process; while waiting, they may abandon the queue at a uniform rate. Customers on the other hand must be matched upon arrival. The objective is to minimize the expected long-term average cost subject to a throughput constraint on the total match rate.
  Previous literature on dynamic matching focuses on "static" policies, where the matching decisions do not depend explicitly on the state of the supplier queues, achieving constant-factor approximations. By contrast, we design "adaptive" policies, which leverage queue length information, and obtain near-optimal polynomial-time algorithms for several classes of instances.
  First, we develop a bi-criteria fully polynomial-time approximation scheme for dynamic matching on networks with a constant number of queues--that computes a $(1-\epsilon)$-approximation of the optimal policy in time polynomial in both the input size and $1/\epsilon$. A key new technique is a hybrid LP relaxation, which combines static and state-dependent LP approximations of the queue dynamics, after a decomposition of the network. Networks with a constant number of queues are motivated by deceased organ donation schemes, where the supply types can be divided according to blood and tissue types.
  The above algorithm, combined with a careful cell decomposition gives an efficient polynomial-time approximation scheme for dynamic matching on Euclidean networks of fixed dimension. The Euclidean case is of interest in ride-hailing and spatial service platforms, where the goal is to fulfill as many trips as possible while minimizing driving distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08775v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza AmaniHamedani, Ali Aouad, Amin Saberi</dc:creator>
    </item>
    <item>
      <title>Hardness and Approximation Algorithms for Balanced Districting Problems</title>
      <link>https://arxiv.org/abs/2501.17277</link>
      <description>arXiv:2501.17277v2 Announce Type: replace 
Abstract: We introduce and study the problem of balanced districting, where given an undirected graph with vertices carrying two types of weights (different population, resource types, etc) the goal is to maximize the total weights covered in vertex disjoint districts such that each district is a star or (in general) a connected induced subgraph with the two weights to be balanced. This problem is strongly motivated by political redistricting, where contiguity, population balance, and compactness are essential. We provide hardness and approximation algorithms for this problem. In particular, we show NP-hardness for an approximation better than $n^{1/2-\delta}$ for any constant $\delta&gt;0$ in general graphs even when the districts are star graphs, as well as NP-hardness on complete graphs, tree graphs, planar graphs and other restricted settings. On the other hand, we develop an algorithm for balanced star districting that gives an $O(\sqrt{n})$-approximation on any graph (which is basically tight considering matching hardness of approximation results), an $O(\log n)$ approximation on planar graphs with extensions to minor-free graphs. Our algorithm uses a modified Whack-a-Mole algorithm [Bhattacharya, Kiss, and Saranurak, SODA 2023] to find a sparse solution of a fractional packing linear program (despite exponentially many variables) and to get a good approximation ratio of the rounding procedure, a crucial element in the analysis is the \emph{balanced scattering separators} for planar graphs and minor-free graphs - separators that can be partitioned into a small number of $k$-hop independent sets for some constant $k$ - which may find independent interest in solving other packing style problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17277v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prathamesh Dharangutte, Jie Gao, Shang-En Huang, Fang-Yi Yu</dc:creator>
    </item>
    <item>
      <title>Decay of correlation for edge colorings when $q&gt;3\Delta$</title>
      <link>https://arxiv.org/abs/2502.06586</link>
      <description>arXiv:2502.06586v2 Announce Type: replace 
Abstract: We examine various perspectives on the decay of correlation for the uniform distribution over proper $q$-edge colorings of graphs with maximum degree $\Delta$.
  First, we establish the coupling independence property when $q\ge 3\Delta$ for general graphs. Together with the work of Chen et al. (2024), this result implies a fully polynomial-time approximation scheme (FPTAS) for counting the number of proper $q$-edge colorings.
  Next, we prove the strong spatial mixing property on trees, provided that $q&gt; (3+o(1))\Delta$. The strong spatial mixing property is derived from the spectral independence property of a version of the weighted edge coloring distribution, which is established using the matrix trickle-down method developed in Abdolazimi, Liu and Oveis Gharan (FOCS, 2021) and Wang, Zhang and Zhang (STOC, 2024).
  Finally, we show that the weak spatial mixing property holds on trees with maximum degree $\Delta$ if and only if $q\ge 2\Delta-1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06586v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zejia Chen, Yulin Wang, Chihao Zhang, Zihan Zhang</dc:creator>
    </item>
    <item>
      <title>Algorithms and Hardness for Estimating Statistical Similarity</title>
      <link>https://arxiv.org/abs/2502.10527</link>
      <description>arXiv:2502.10527v3 Announce Type: replace 
Abstract: We introduce and study the computational problem of determining statistical similarity between probability distributions. For distributions $P$ and $Q$ over a finite sample space, their statistical similarity is defined as $S_{\mathrm{stat}}(P, Q) := \sum_x \min(P(x), Q(x))$. Despite its fundamental nature as a measure of similarity between distributions, capturing essential concepts such as Bayes error in prediction and hypothesis testing, this computational problem has not been previously explored. Recent work on computing statistical distance has established that, somewhat surprisingly, even for the simple class of product distributions, exactly computing statistical similarity is $\#\mathsf{P}$-hard. This motivates the question of designing approximation algorithms for statistical similarity. Our first contribution is a Fully Polynomial-Time deterministic Approximation Scheme (FPTAS) for estimating statistical similarity between two product distributions. Furthermore, we also establish a complementary hardness result. In particular, we show that it is $\mathsf{NP}$-hard to estimate statistical similarity when $P$ and $Q$ are Bayes net distributions of in-degree $2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10527v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Bhattacharyya, Sutanu Gayen, Kuldeep S. Meel, Dimitrios Myrisiotis, A. Pavan, N. V. Vinodchandran</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Algorithms for Boolean Satisfiability</title>
      <link>https://arxiv.org/abs/2505.06146</link>
      <description>arXiv:2505.06146v2 Announce Type: replace 
Abstract: Learning-augmented algorithms are a prominent recent development in beyond worst-case analysis. In this framework, a problem instance is provided with a prediction (``advice'') from a machine-learning oracle, which provides partial information about an optimal solution, and the goal is to design algorithms that leverage this advice to improve worst-case performance. We study the classic Boolean satisfiability (SAT) decision and optimization problems within this framework using two forms of advice. ``Subset advice" provides a random $\epsilon$ fraction of the variables from an optimal assignment, whereas ``label advice" provides noisy predictions for all variables in an optimal assignment.
  For the decision problem $k$-SAT, by using the subset advice we accelerate the exponential running time of the PPSZ family of algorithms due to Paturi, Pudlak, Saks and Zane, which currently represent the state of the art in the worst case. We accelerate the running time by a multiplicative factor of $2^{-c}$ in the base of the exponent, where $c$ is a function of $\epsilon$ and $k$. For the optimization problem, we show how to incorporate subset advice in a black-box fashion with any $\alpha$-approximation algorithm, improving the approximation ratio to $\alpha + (1 - \alpha)\epsilon$. Specifically, we achieve approximations of $0.94 + \Omega(\epsilon)$ for MAX-$2$-SAT, $7/8 + \Omega(\epsilon)$ for MAX-$3$-SAT, and $0.79 + \Omega(\epsilon)$ for MAX-SAT. Moreover, for label advice, we obtain near-optimal approximation for instances with large average degree, thereby generalizing recent results on MAX-CUT and MAX-$2$-LIN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06146v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Idan Attias, Xing Gao, Lev Reyzin</dc:creator>
    </item>
    <item>
      <title>On Computing Vertex Connectivity of 1-Plane Graphs</title>
      <link>https://arxiv.org/abs/2212.06782</link>
      <description>arXiv:2212.06782v3 Announce Type: replace-cross 
Abstract: The vertex connectivity of a graph $G$ is the size of the smallest set of vertices $S$ such that $G \setminus S$ is disconnected. For the class of planar graphs, the problem of vertex connectivity is well-studied, both from structural and algorithmic perspectives. Let $G$ be a plane embedded graph, and $\Lambda(G)$ be an auxiliary graph obtained by inserting a face vertex inside each face and connecting it to all vertices of $G$ incident with the face. If $S$ is a minimal vertex cut of $G$, then there exists a cycle of length $2|S|$ whose vertices alternate between vertices of $S$ and face vertices. This structure facilitates the designing of a linear-time algorithm to find minimum vertex cuts of planar graphs. In this paper, we attempt a similar approach for the class of 1-plane graphs -- these are graphs with a drawing on the plane where each edge is crossed at most once.
  We consider different classes of 1-plane graphs based on the subgraphs induced by the endpoints of crossings. For 1-plane graphs where the endpoints of every crossing induce the complete graph $K_4$, we show that the structure of minimum vertex cuts is identical to that in plane graphs, as mentioned above. For 1-plane graphs where the endpoints of every crossing induce at least three edges (i.e., one edge apart from the crossing pair of edges), we show that for any minimal vertex cut $S$, there exists a cycle of diameter $O(|S|)$ in $\Lambda(G)$ such that all vertices of $S$ are in the neighbourhood of the cycle. This structure enables us to design a linear time algorithm to compute the vertex connectivity of all such 1-plane graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.06782v3</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Therese Biedl, Karthik Murali</dc:creator>
    </item>
    <item>
      <title>Counting overlapping pairs of words</title>
      <link>https://arxiv.org/abs/2405.09393</link>
      <description>arXiv:2405.09393v3 Announce Type: replace-cross 
Abstract: A correlation is a binary vector that encodes all possible positions of overlaps of two words, where an overlap for an ordered pair of words (u,v) occurs if a suffix of word u matches a prefix of word v. As multiple pairs can have the same correlation, it is relevant to count how many pairs of words share the same correlation depending on the alphabet size and word length n. We exhibit recurrences to compute the number of such pairs -- which is termed population size -- for any correlation; for this, we exploit a relationship between overlaps of two words and self-overlap of one word. This theorem allows us to compute the number of pairs with a longest overlap of a given length and to show that the expected length of the longest border of two words asymptotically converges, which solves two open questions raised by Gabric in 2022. Finally, we also provide bounds for the asymptotic of the population ratio of any correlation. Given the importance of word overlaps in areas like word combinatorics, bioinformatics, and digital communication, our results may ease analyses of algorithms for string processing, code design, or genome assembly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09393v3</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eric Rivals, Pengfei Wang</dc:creator>
    </item>
    <item>
      <title>Directed st-connectivity with few paths is in quantum logspace</title>
      <link>https://arxiv.org/abs/2408.12473</link>
      <description>arXiv:2408.12473v2 Announce Type: replace-cross 
Abstract: We present a $\mathsf{BQSPACE}(O(\log n))$-procedure to count $st$-paths on directed graphs for which we are promised that there are at most polynomially many paths starting in $s$ and polynomially many paths ending in $t$. For comparison, the best known classical upper bound in this case just to decide $st$-connectivity is $\mathsf{DSPACE}(O(\log^2 n/ \log \log n))$. The result establishes a new relationship between~$\mathsf{BQL}$ and unambiguity and fewness subclasses of $\mathsf{NL}$. Further, we also show how to \emph{recognize} directed graphs with at most polynomially many paths between any two nodes in $\mathsf{BQSPACE}(O(\log n))$. This yields the first natural candidate for a language separating $\mathsf{BQL}$ from $\mathsf{L}$ and~$\mathsf{BPL}$. Until now, all candidates potentially separating these classes were inherently promise problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12473v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Apers, Roman Edenhofer</dc:creator>
    </item>
    <item>
      <title>High-level quantum algorithm programming using Silq</title>
      <link>https://arxiv.org/abs/2409.10231</link>
      <description>arXiv:2409.10231v2 Announce Type: replace-cross 
Abstract: Quantum computing, with its vast potential, is fundamentally shaped by the intricacies of quantum mechanics, which both empower and constrain its capabilities. The development of a universal, robust quantum programming language has emerged as a key research focus in this rapidly evolving field. This paper explores Silq, a recent high-level quantum programming language, highlighting its strengths and unique features. We aim to share our insights on designing and implementing high-level quantum algorithms using Silq, demonstrating its practical applications and advantages for quantum programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10231v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktorija Bezganovic, Marco Lewis, Sadegh Soudjani, Paolo Zuliani</dc:creator>
    </item>
    <item>
      <title>A Generalisation of Voter Model: Influential Nodes and Convergence Properties</title>
      <link>https://arxiv.org/abs/2411.04564</link>
      <description>arXiv:2411.04564v2 Announce Type: replace-cross 
Abstract: Consider an undirected graph G, representing a social network, where each node is blue or red, corresponding to positive or negative opinion on a topic. In the voter model, in discrete time rounds, each node picks a neighbour uniformly at random and adopts its colour. Despite its significant popularity, this model does not capture some fundamental real-world characteristics such as the difference in the strengths of individuals connections, individuals with neutral opinion on a topic, and individuals who are reluctant to update their opinion. To address these issues, we introduce and study a generalisation of the voter model. Motivating by campaigning strategies, we study the problem of selecting a set of seeds blue nodes to maximise the expected number of blue nodes after some rounds. We prove that the problem is NP- hard and provide a polynomial time approximation algorithm with the best possible approximation guarantee. Our experiments on real-world and synthetic graph data demonstrate that the proposed algorithm outperforms other algorithms. We also investigate the convergence properties of the model. We prove that the process could take an exponential number of rounds to converge. However, if we limit ourselves to strongly connected graphs, the convergence time is polynomial and the period (the number of states in convergence) divides the length of all cycles in the graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04564v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhiram Manohara, Ahad N. Zehmakan</dc:creator>
    </item>
    <item>
      <title>A Framework for the Design of Efficient Diversification Algorithms to NP-Hard Problems</title>
      <link>https://arxiv.org/abs/2501.12261</link>
      <description>arXiv:2501.12261v3 Announce Type: replace-cross 
Abstract: There has been considerable recent interest in computing a diverse collection of solutions to a given optimization problem, both in the AI and theory communities. Given a classical optimization problem $\Pi$ (e.g., spanning tree, minimum cuts, maximum matching, minimum vertex cover) with input size $n$ and an integer $k\geq 1$, the goal is to generate a collection of $k$ maximally diverse solutions to $\Pi$. This diverse-X paradigm not only allows the user to generate very different solutions, but also helps make systems more secure and robust by handling uncertainty, and achieve energy efficiency.
  For problems $\Pi$ in P (such as spanning tree and minimum cut), there are efficient $\text{poly}(n,k)$ approximation algorithms available for the diverse variants [Hanaka et al. AAAI 2021, 2022, 2023, Gao et al. LATIN 2022, de Berg et al. ISAAC 2023]. In contrast, only FPT algorithms are known for NP-hard problems such as vertex covers and independent sets [Baste et al. IJCAI 2020, Eiben et al. SODA 2024, Misra et al. ISAAC 2024, Austrin et al. ICALP 2025], but in the worst case, these algorithms run in time $\exp((kn)^c)$ for some $c&gt;0$. In this work, we address this gap and give $\text{poly}(n,k)$ or $f(k)\text{poly}(n)$ time approximation algorithms for diversification variants of several NP-hard problems such as knapsack, maximum weight independent sets (MWIS) and minimum vertex covers in planar graphs, geometric (rectangle) knapsack, enclosing points by polygon, and MWIS in unit-disk-graphs of points in convex position. Our results are achieved by developing a general framework and applying it to problems with textbook dynamic-programming algorithms to find one solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12261v3</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waldo G\'alvez, Mayank Goswami, Arturo Merino, GiBeom Park, Meng-Tsung Tsai, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Fast Compressed-Domain N-Point Discrete Fourier Transform: The "Twiddless" FFT Algorithm</title>
      <link>https://arxiv.org/abs/2505.23718</link>
      <description>arXiv:2505.23718v2 Announce Type: replace-cross 
Abstract: In this work, we present the \emph{twiddless fast Fourier transform (TFFT)}, a novel algorithm for computing the $N$-point discrete Fourier transform (DFT). The TFFT's divide strategy builds on recent results that decimate an $N$-point signal (by a factor of $p$) into an $N/p$-point compressed signal whose DFT readily yields $N/p$ coefficients of the original signal. However, existing compression-domain DFT analyses have been limited to computing only the even-indexed DFT coefficients. With TFFT, we overcome this limitation by efficiently computing both \emph{even- and odd-indexed} DFT coefficients in the compressed domain with $O(N \log N)$ complexity. TFFT introduces a new recursive decomposition of the DFT problem, wherein $N/2^i$ coefficients of the original input are computed at recursion level $i$, with no need for twiddle factor multiplications or butterfly structures. Additionally, TFFT generalizes the input length to $N = c \cdot 2^k$ (for $k \geq 0$ and non-power-of-two $c &gt; 0$), reducing the need for zero-padding and potentially improving efficiency and stability over classical FFTs. We believe TFFT represents a \emph{novel paradigm} for DFT computation, opening new directions for research in optimized implementations, hardware design, parallel computation, and sparse transforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23718v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saulo Queiroz</dc:creator>
    </item>
  </channel>
</rss>
