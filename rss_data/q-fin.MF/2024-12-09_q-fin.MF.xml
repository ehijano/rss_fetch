<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.MF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.MF</link>
    <description>q-fin.MF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.MF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Dec 2024 03:50:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enhancing Fourier pricing with machine learning</title>
      <link>https://arxiv.org/abs/2412.05070</link>
      <description>arXiv:2412.05070v1 Announce Type: new 
Abstract: Fourier pricing methods such as the Carr-Madan formula or the COS method are classic tools for pricing European options for advanced models such as the Heston model. These methods require tuning parameters such as a damping factor, a truncation range, a number of terms, etc. Estimating these tuning parameters is difficult or computationally expensive. Recently, machine learning techniques have been proposed for fast pricing: they are able to learn the functional relationship between the parameters of the Heston model and the option price. However, machine learning techniques suffer from error control and require retraining for different error tolerances. In this research, we propose to learn the tuning parameters of the Fourier methods (instead of the prices) using machine learning techniques. As a result, we obtain very fast algorithms with full error control: Our approach works with any error tolerance without retraining, as demonstrated in numerical experiments using the Heston model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05070v1</guid>
      <category>q-fin.MF</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gero Junike, Hauke Stier</dc:creator>
    </item>
    <item>
      <title>Inverting the Markovian projection for pure jump processes</title>
      <link>https://arxiv.org/abs/2412.04589</link>
      <description>arXiv:2412.04589v1 Announce Type: cross 
Abstract: Markovian projections arise in problems where we aim to mimic the one-dimensional marginal laws of an It\^o semimartingale by using another It\^o process with simpler dynamics. In applications, Markovian projections are useful in calibrating jump-diffusion models with both local and stochastic features, leading to the study of the inversion problems. In this paper, we invert the Markovian projections for pure jump processes, which can be used to construct calibrated local stochastic intensity (LSI) models for credit risk applications. Such models are jump process analogues of the notoriously hard to construct local stochastic volatility (LSV) models used in equity modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04589v1</guid>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Larsson, Shukun Long</dc:creator>
    </item>
  </channel>
</rss>
