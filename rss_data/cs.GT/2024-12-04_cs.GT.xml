<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Dec 2024 02:44:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Theoretical Foundations of Data Exchange Economies</title>
      <link>https://arxiv.org/abs/2412.01968</link>
      <description>arXiv:2412.01968v1 Announce Type: new 
Abstract: The immense success of ML systems relies heavily on large-scale, high-quality data. The high demand for data has led to many paradigms that involve selling, exchanging, and sharing data, motivating the study of economic processes with data as an asset. However, data differs from classical economic assets in terms of free duplication: there is no concept of limited supply since it can be replicated at zero marginal cost. This distinction introduces fundamental differences between economic processes involving data and those concerning other assets.
  We study a parallel to exchange (Arrow-Debreu) markets where data is the asset. Here, agents with datasets exchange data fairly and voluntarily, aiming for mutual benefit without monetary compensation. This framework is particularly relevant for non-profit organizations that seek to improve their ML models through data exchange, yet are restricted from selling their data for profit.
  We propose a general framework for data exchange, built on two core principles: (i) fairness, ensuring that each agent receives utility proportional to their contribution to others; contributions are quantifiable using standard credit-sharing functions like the Shapley value, and (ii) stability, ensuring that no coalition of agents can identify an exchange among themselves which they unanimously prefer to the current exchange. We show that fair and stable exchanges exist for all monotone continuous utility functions. Next, we investigate the computational complexity of finding approximate fair and stable exchanges. We present a local search algorithm for instances with monotone submodular utility functions, where each agent contributions are measured using the Shapley value. We prove that this problem lies in CLS under mild assumptions. Our framework opens up several intriguing theoretical directions for research in data economics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01968v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Bhaskar Ray Chaudhury, Jugal Garg, Aniket Murhekar</dc:creator>
    </item>
    <item>
      <title>Reactive Synthesis of Sensor Revealing Strategies in Hypergames on Graphs</title>
      <link>https://arxiv.org/abs/2412.01975</link>
      <description>arXiv:2412.01975v1 Announce Type: new 
Abstract: In many security applications of cyber-physical systems, a system designer must guarantee that critical missions are satisfied against attacks in the sensors and actuators of the CPS. Traditional security design of CPSs often assume that attackers have complete knowledge of the system. In this article, we introduce a class of deception techniques and study how to leverage asymmetric information created by deception to strengthen CPS security. Consider an adversarial interaction between a CPS defender and an attacker, who can perform sensor jamming attacks. To mitigate such attacks, the defender introduces asymmetrical information by deploying a "hidden sensor," whose presence is initially undisclosed but can be revealed if queried. We introduce hypergames on graphs to model this game with asymmetric information. Building on the solution concept called subjective rationalizable strategies in hypergames, we identify two stages in the game: An initial game stage where the defender commits to a strategy perceived rationalizable by the attacker until he deviates from the equilibrium in the attacker's perceptual game; Upon the deviation, a delay-attack game stage starts where the defender plays against the attacker, who has a bounded delay in attacking the sensor being revealed. Based on backward induction, we develop an algorithm that determines, for any given state, if the defender can benefit from hiding a sensor and revealing it later. If the answer is affirmative, the algorithm outputs a sensor revealing strategy to determine when to reveal the sensor during dynamic interactions. We demonstrate the effectiveness of our deceptive strategies through two case studies related to CPS security applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01975v1</guid>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumukha Udupa, Ahmed Hemida, Charles A. Kamhoua, Jie Fu</dc:creator>
    </item>
    <item>
      <title>Sequential Payment Rules: Approximately Fair Budget Divisions via Simple Spending Dynamics</title>
      <link>https://arxiv.org/abs/2412.02435</link>
      <description>arXiv:2412.02435v1 Announce Type: new 
Abstract: In approval-based budget division, a budget needs to be distributed to some candidates based on the voters' approval ballots over these candidates. In the pursuit of simple, well-behaved, and approximately fair rules for this setting, we introduce the class of sequential payment rules, where each voter controls a part of the budget and repeatedly spends his share on his approved candidates to determine the final distribution. We show that all sequential payment rules satisfy a demanding population consistency notion and we identify two particularly appealing rules within this class called the maximum payment rule (MP) and the $\frac{1}{3}$-multiplicative sequential payment rule ($\frac{1}{3}$-MP). More specifically, we prove that (i) MP is, apart from one other rule, the only monotonic sequential payment rule and gives a $2$-approximation to a fairness notion called average fair share, and (ii) $\frac{1}{3}$-MP gives a $\frac{3}{2}$-approximation to average fair share, which is optimal among sequential payment rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02435v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haris Aziz, Patrick Lederer, Xinhang Lu, Mashbat Suzuki, Jeremy Vollen</dc:creator>
    </item>
    <item>
      <title>Learning Aggregation Rules in Participatory Budgeting: A Data-Driven Approach</title>
      <link>https://arxiv.org/abs/2412.01864</link>
      <description>arXiv:2412.01864v1 Announce Type: cross 
Abstract: Participatory Budgeting (PB) offers a democratic process for communities to allocate public funds across various projects through voting. In practice, PB organizers face challenges in selecting aggregation rules either because they are not familiar with the literature and the exact details of every existing rule or because no existing rule echoes their expectations. This paper presents a novel data-driven approach utilizing machine learning to address this challenge. By training neural networks on PB instances, our approach learns aggregation rules that balance social welfare, representation, and other societal beneficial goals. It is able to generalize from small-scale synthetic PB examples to large, real-world PB instances. It is able to learn existing aggregation rules but also generate new rules that adapt to diverse objectives, providing a more nuanced, compromise-driven solution for PB processes. The effectiveness of our approach is demonstrated through extensive experiments with synthetic and real-world PB data, and can expand the use and deployment of PB solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01864v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roy Fairstein, Dan Vilenchik, Kobi Gal</dc:creator>
    </item>
    <item>
      <title>Explore Reinforced: Equilibrium Approximation with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2412.02016</link>
      <description>arXiv:2412.02016v1 Announce Type: cross 
Abstract: Current approximate Coarse Correlated Equilibria (CCE) algorithms struggle with equilibrium approximation for games in large stochastic environments but are theoretically guaranteed to converge to a strong solution concept. In contrast, modern Reinforcement Learning (RL) algorithms provide faster training yet yield weaker solutions. We introduce Exp3-IXrl - a blend of RL and game-theoretic approach, separating the RL agent's action selection from the equilibrium computation while preserving the integrity of the learning process. We demonstrate that our algorithm expands the application of equilibrium approximation algorithms to new environments. Specifically, we show the improved performance in a complex and adversarial cybersecurity network environment - the Cyber Operations Research Gym - and in the classical multi-armed bandit settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02016v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Yu, Mateusz Nowak, Qintong Xie, Michelle Yilin Feng, Peter Chin</dc:creator>
    </item>
    <item>
      <title>The Problem of Social Cost in Multi-Agent General Reinforcement Learning: Survey and Synthesis</title>
      <link>https://arxiv.org/abs/2412.02091</link>
      <description>arXiv:2412.02091v1 Announce Type: cross 
Abstract: The AI safety literature is full of examples of powerful AI agents that, in blindly pursuing a specific and usually narrow objective, ends up with unacceptable and even catastrophic collateral damage to others. In this paper, we consider the problem of social harms that can result from actions taken by learning and utility-maximising agents in a multi-agent environment. The problem of measuring social harms or impacts in such multi-agent settings, especially when the agents are artificial generally intelligent (AGI) agents, was listed as an open problem in Everitt et al, 2018. We attempt a partial answer to that open problem in the form of market-based mechanisms to quantify and control the cost of such social harms. The proposed setup captures many well-studied special cases and is more general than existing formulations of multi-agent reinforcement learning with mechanism design in two ways: (i) the underlying environment is a history-based general reinforcement learning environment like in AIXI; (ii) the reinforcement-learning agents participating in the environment can have different learning strategies and planning horizons. To demonstrate the practicality of the proposed setup, we survey some key classes of learning algorithms and present a few applications, including a discussion of the Paperclips problem and pollution control with a cap-and-trade system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02091v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kee Siong Ng, Samuel Yang-Zhao, Timothy Cadogan-Cowper</dc:creator>
    </item>
    <item>
      <title>Wasserstein Markets for Differentially-Private Data</title>
      <link>https://arxiv.org/abs/2412.02609</link>
      <description>arXiv:2412.02609v1 Announce Type: cross 
Abstract: Data is an increasingly vital component of decision making processes across industries. However, data access raises privacy concerns motivating the need for privacy-preserving techniques such as differential privacy. Data markets provide a means to enable wider access as well as determine the appropriate privacy-utility trade-off. Existing data market frameworks either require a trusted third party to perform computationally expensive valuations or are unable to capture the combinatorial nature of data value and do not endogenously model the effect of differential privacy. This paper addresses these shortcomings by proposing a valuation mechanism based on the Wasserstein distance for differentially-private data, and corresponding procurement mechanisms by leveraging incentive mechanism design theory, for task-agnostic data procurement, and task-specific procurement co-optimisation. The mechanisms are reformulated into tractable mixed-integer second-order cone programs, which are validated with numerical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02609v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Saurab Chhachhi, Fei Teng</dc:creator>
    </item>
    <item>
      <title>Revenue in First- and Second-Price Display Advertising Auctions: Understanding Markets with Learning Agents</title>
      <link>https://arxiv.org/abs/2312.00243</link>
      <description>arXiv:2312.00243v3 Announce Type: replace 
Abstract: The transition of display ad exchanges from second-price auctions (SPA) to first-price auctions (FPA) has raised questions about its impact on revenue. Auction theory predicts the revenue equivalence between these two auction formats. However, display ad auctions are different from standard models in auction theory. First, automated bidding agents cannot easily derive equilibrium strategies in FPA because information regarding competitors is not readily available. Second, due to principal-agent problems, bidding agents typically maximize return-on-investment (ROI), not payoff. The literature on learning agents for real-time bidding is growing because of the practical relevance of this area; most research has found that learning agents do not converge to an equilibrium. Specifically, research on algorithmic collusion in display ad auctions has argued that FPA can induce symmetric Q-learning agents to tacitly collude, resulting in bids below equilibrium, leading to lower revenue compared to the SPA. Whether bids are in equilibrium cannot easily be determined from field data since the underlying values of bidders are unknown. In this paper, we draw on analytical modeling and numerical experiments and explore the convergence behavior of widespread online learning algorithms in both complete and incomplete information models. Contrary to prior results, we show that there are no systematic deviations from equilibrium behavior. We also explore the differences in revenue of the FPA and SPA, which have not been done for utility functions relevant to this domain, such as ROI. We show that learning algorithms also converge to equilibrium. Still, revenue equivalence does not hold, indicating that collusion may not be the explanation for lower revenue with FPA, and the change in auction format might have had substantial and non-obvious consequences for ad exchanges and advertisers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00243v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bichler, Alok Gupta, Matthias Oberlechner</dc:creator>
    </item>
    <item>
      <title>Ex-post Individually Rational Bayesian Persuasion</title>
      <link>https://arxiv.org/abs/2312.04973</link>
      <description>arXiv:2312.04973v2 Announce Type: replace 
Abstract: In the Bayesian persuasion model, a sender can convince a receiver to choose an alternative action to the one originally preferred by the receiver. A crucial assumption in this model is the sender's commitment to a predetermined information disclosure policy (signaling scheme) and the receiver's trust in this commitment. However, in practice, it is difficult to monitor whether the sender adheres to the disclosure policy, and the receiver may refuse to follow the persuasion due to a lack of trust. Trust becomes particularly strained when the receiver knows that the sender will incur obvious losses when truthfully following the protocol. In this work, we propose the notion of ex-post individually rational (ex-post IR) Bayesian persuasion: after observing the state, the sender is never asked to send a signal that is less preferred than no information disclosure. An ex-post IR Bayesian persuasion policy is more likely to be truthfully followed by the sender, thereby providing stronger incentives for the receiver to trust the sender. Our contributions are threefold. First, we demonstrate that the optimal ex-post IR persuasion policy can be efficiently computed through a linear program, while also offering its geometric characterization. Second, we show that surprisingly, for non-trivial classes of games, the requirement of ex-post IR constraints does not incur any cost to the sender's utility. Finally, we compare ex-post IR Bayesian persuasion to other information disclosure models that ensure different notions of credibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04973v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahao Zhang, Shuran Zheng, Renato Paes Leme, Zhiwei Steven Wu</dc:creator>
    </item>
    <item>
      <title>Designing Equilibria in Concurrent Games with Social Welfare and Temporal Logic Constraints</title>
      <link>https://arxiv.org/abs/2306.03045</link>
      <description>arXiv:2306.03045v5 Announce Type: replace-cross 
Abstract: In game theory, mechanism design is concerned with the design of incentives so that a desired outcome of the game can be achieved. In this paper, we explore the concept of equilibrium design, where incentives are designed to obtain a desirable equilibrium that satisfies a specific temporal logic property. Our study is based on a framework where system specifications are represented as temporal logic formulae, games as quantitative concurrent game structures, and players' goals as mean-payoff objectives. We consider system specifications given by LTL and GR(1) formulae, and show that designing incentives to ensure that a given temporal logic property is satisfied on some/every Nash equilibrium of the game can be achieved in PSPACE for LTL properties and in NP/{\Sigma}P 2 for GR(1) specifications. We also examine the complexity of related decision and optimisation problems, such as optimality and uniqueness of solutions, as well as considering social welfare, and show that the complexities of these problems lie within the polynomial hierarchy. Equilibrium design can be used as an alternative solution to rational synthesis and verification problems for concurrent games with mean-payoff objectives when no solution exists or as a technique to repair concurrent games with undesirable Nash equilibria in an optimal way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03045v5</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Gutierrez, Muhammad Najib, Giuseppe Perelli, Michael Wooldridge</dc:creator>
    </item>
  </channel>
</rss>
