<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 Apr 2025 04:00:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Stability of Polling Systems for a Large Class of Markovian Switching Policies</title>
      <link>https://arxiv.org/abs/2504.13315</link>
      <description>arXiv:2504.13315v1 Announce Type: new 
Abstract: We consider a polling system with two queues, where a single server is attending the queues in a cyclic order and requires non-zero switching times to switch between the queues. Our aim is to identify a fairly general and comprehensive class of Markovian switching policies that renders the system stable. Potentially a class of policies that can cover the Pareto frontier related to individual-queue-centric performance measures like the stationary expected number of waiting customers in each queue; for instance, such a class of policies is identified recently for a polling system near the fluid regime (with large arrival and departure rates), and we aim to include that class. We also aim to include a second class that facilitates switching between the queues at the instance the occupancy in the opposite queue crosses a threshold and when that in the visiting queue is below a threshold (this inclusion facilitates design of `robust' polling systems). Towards this, we consider a class of two-phase switching policies, which includes the above mentioned classes. In the maximum generality, our policies can be represented by eight parameters, while two parameters are sufficient to represent the aforementioned classes. We provide simple conditions to identify the sub-class of switching policies that ensure system stability. By numerically tuning the parameters of the proposed class, we illustrate that the proposed class can cover the Pareto frontier for the stationary expected number of customers in the two queues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13315v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>math.PR</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantin Avrachenkov, Kousik Das, Veeraruna Kavitha, Vartika Singh</dc:creator>
    </item>
    <item>
      <title>Open-Loop and Closed-Loop Strategies for Linear Quadratic Mean Field Games: The Direct Approach</title>
      <link>https://arxiv.org/abs/2504.13496</link>
      <description>arXiv:2504.13496v1 Announce Type: new 
Abstract: This paper delves into studying the differences and connections between open-loop and closed-loop strategies for the linear quadratic (LQ) mean field games (MFGs) by the direct approach. The investigation begins with the finite-population system for solving the solvability of open-loop and closed-loop systems within a unified framework under the global information pattern. By a comprehensive analysis through variational methods, the necessary and sufficient conditions are obtained for the existence of centralized open-loop and closed-loop Nash equilibria, which are characterized by the solvability of a system of forward-backward stochastic differential equations and a system of Riccati equations, respectively. The connections and disparities between centralized open-loop and closed-loop Nash equilibria are analyzed. Then, the decentralized control is designed by studying the asymptotic solvability for both open-loop and closed-loop systems. Asymptotically decentralized Nash equilibria are obtained by considering the centralized open-loop and closed-loop Nash equilibria in the infinite-population system, which requires a standard and an asymmetric Riccati equations. The results demonstrate that divergences between the centralized open-loop and closed-loop Nash equilibria in the finite-population system, but the corresponding asymptotically decentralized Nash equilibria in the infinite-population system are consistent. Therefore, the choice of open-loop and closed-loop strategies does not play an essential role in the design of decentralized control for LQ MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13496v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Liang, Bing-Chang Wang, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>The non-linear multiple stopping problem: between the discrete and the continuous time</title>
      <link>https://arxiv.org/abs/2504.13503</link>
      <description>arXiv:2504.13503v1 Announce Type: new 
Abstract: We consider the non-linear optimal multiple stopping problem under general conditions on the non-linear evaluation operators, which might depend on two time indices: the time of evaluation/assessment and the horizon (when the reward or loss is incurred). We do not assume convexity/concavity or cash-invariance. We focus on the case where the agent's stopping strategies are what we call Bermudan stopping strategies, a framework which can be seen as lying between the discrete and the continuous time. We first study the non-linear double optimal stopping problem by using a reduction approach. We provide a necessary and a sufficient condition for optimal pairs, and a result on existence of optimal pairs. We then generalize the results to the non-linear $d$-optimal stopping problem. We treat the symmetric case (of additive and multiplicative reward families) as examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13503v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miryana Grigorova (UPCit\'e, LPSM), Marie-Claire Quenez (UPCit\'e, LPSM), Peng Yuan</dc:creator>
    </item>
    <item>
      <title>Punitive policies to combat misreporting in dynamic supply chains</title>
      <link>https://arxiv.org/abs/2504.13780</link>
      <description>arXiv:2504.13780v1 Announce Type: new 
Abstract: Wholesale price contracts are known to be associated with double marginalization effects, which prevents supply chains from achieving their true market share. In a dynamic setting under information asymmetry, these inefficiencies manifest in the form of misreporting of the market potential by the manufacturer to the supplier, again leading to the loss of market share. We pose the dynamics of interaction between the supplier and manufacturer as the Stackelberg game and develop theoretical results for optimal punitive strategies that the supplier can implement to ensure that the manufacturer truthfully reveals the market potential in the single-stage setting. Later, we validate these results through the randomly generated, Monte-Carlo simulation based numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13780v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Madhu Dhiman, Atul Maurya, Veeraruna Kavitha, Priyank Sinha</dc:creator>
    </item>
    <item>
      <title>Constrained Average-Reward Intermittently Observable MDPs</title>
      <link>https://arxiv.org/abs/2504.13823</link>
      <description>arXiv:2504.13823v1 Announce Type: new 
Abstract: In Markov Decision Processes (MDPs) with intermittent state information, decision-making becomes challenging due to periods of missing observations. Linear programming (LP) methods can play a crucial role in solving MDPs, in particular, with constraints. However, the resultant belief MDPs lead to infinite dimensional LPs, even when the original MDP is with a finite state and action spaces. The verification of strong duality becomes non-trivial. This paper investigates the conditions for no duality gap in average-reward finite Markov decision process with intermittent state observations. We first establish that in such MDPs, the belief MDP is unichain if the original Markov chain is recurrent. Furthermore, we establish strong duality of the problem, under the same assumption. Finally, we provide a wireless channel example, where the belief state depends on the last channel state received and the age of the channel state. Our numerical results indicate interesting properties of the solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13823v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Konstantin Avrachenkov, Madhu Dhiman, Veeraruna Kavitha</dc:creator>
    </item>
    <item>
      <title>Training Autoencoders Using Stochastic Hessian-Free Optimization with LSMR</title>
      <link>https://arxiv.org/abs/2504.13302</link>
      <description>arXiv:2504.13302v1 Announce Type: cross 
Abstract: Hessian-free (HF) optimization has been shown to effectively train deep autoencoders (Martens, 2010). In this paper, we aim to accelerate HF training of autoencoders by reducing the amount of data used in training. HF utilizes the conjugate gradient algorithm to estimate update directions. Instead, we propose using the LSMR method, which is known for effectively solving large sparse linear systems. We also incorporate Chapelle &amp; Erhan (2011)'s improved preconditioner for HF optimization. In addition, we introduce a new mini-batch selection algorithm to mitigate overfitting. Our algorithm starts with a small subset of the training data and gradually increases the mini-batch size based on (i) variance estimates obtained during the computation of a mini-batch gradient (Byrd et al., 2012) and (ii) the relative decrease in objective value for the validation data. Our experimental results demonstrate that our stochastic Hessian-free optimization, using the LSMR method and the new sample selection algorithm, leads to rapid training of deep autoencoders with improved generalization error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13302v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ibrahim Emirahmetoglu, David E. Stewart</dc:creator>
    </item>
    <item>
      <title>Target search optimization by threshold resetting</title>
      <link>https://arxiv.org/abs/2504.13501</link>
      <description>arXiv:2504.13501v1 Announce Type: cross 
Abstract: We introduce a new class of first passage time optimization driven by threshold resetting, inspired by many natural processes where crossing a critical limit triggers failure, degradation or transition. In here, search agents are collectively reset when a threshold is reached, creating event-driven, system-coupled simultaneous resets that induce long-range interactions. We develop a unified framework to compute search times for these correlated stochastic processes, with ballistic searchers as a key example uncovering diverse optimization behaviors. A cost function, akin to breakdown penalties, reveals that optimal resetting can forestall larger losses. This formalism generalizes to broader stochastic systems with multiple degrees of freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13501v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.ST</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arup Biswas, Satya N Majumdar, Arnab Pal</dc:creator>
    </item>
    <item>
      <title>Efficient algorithms for the Hadamard decomposition</title>
      <link>https://arxiv.org/abs/2504.13633</link>
      <description>arXiv:2504.13633v1 Announce Type: cross 
Abstract: The Hadamard decomposition is a powerful technique for data analysis and matrix compression, which decomposes a given matrix into the element-wise product of two or more low-rank matrices. In this paper, we develop an efficient algorithm to solve this problem, leveraging an alternating optimization approach that decomposes the global non-convex problem into a series of convex sub-problems. To improve performance, we explore advanced initialization strategies inspired by the singular value decomposition (SVD) and incorporate acceleration techniques by introducing momentum-based updates. Beyond optimizing the two-matrix case, we also extend the Hadamard decomposition framework to support more than two low-rank matrices, enabling approximations with higher effective ranks while preserving computational efficiency. Finally, we conduct extensive experiments to compare our method with the existing gradient descent-based approaches for the Hadamard decomposition and with traditional low-rank approximation techniques. The results highlight the effectiveness of our proposed method across diverse datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13633v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Wertz, Arnaud Vandaele, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>A Zeroth-order Proximal Stochastic Gradient Method for Weakly Convex Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2205.01633</link>
      <description>arXiv:2205.01633v3 Announce Type: replace 
Abstract: In this paper we analyze a zeroth-order proximal stochastic gradient method suitable for the minimization of weakly convex stochastic optimization problems. We consider nonsmooth and nonlinear stochastic composite problems, for which (sub-)gradient information might be unavailable. The proposed algorithm utilizes the well-known Gaussian smoothing technique, which yields unbiased zeroth-order gradient estimators of a related partially smooth surrogate problem (in which one of the two nonsmooth terms in the original problem's objective is replaced by a smooth approximation). This allows us to employ a standard proximal stochastic gradient scheme for the approximate solution of the surrogate problem, which is determined by a single smoothing parameter, and without the utilization of first-order information. We provide state-of-the-art convergence rates for the proposed zeroth-order method using minimal assumptions. The proposed scheme is numerically compared against alternative zeroth-order methods as well as a stochastic sub-gradient scheme on a standard phase retrieval problem. Further, we showcase the usefulness and effectiveness of our method for the unique setting of automated hyper-parameter tuning. In particular, we focus on automatically tuning the parameters of optimization algorithms by minimizing a novel heuristic model. The proposed approach is tested on a proximal alternating direction method of multipliers for the solution of $\mathcal{L}_1/\mathcal{L}_2$-regularized PDE-constrained optimal control problems, with evident empirical success.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.01633v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>A Zeroth-Order Proximal Stochastic Gradient Method for Weakly Convex Stochastic Optimization, SIAM Journal on Scientific Computing, Vol. 45, Iss. 5, A2679-A2702, 2023</arxiv:journal_reference>
      <dc:creator>Spyridon Pougkakiotis, Dionysios S. Kalogerias</dc:creator>
    </item>
    <item>
      <title>Block Backstepping for Isotachic Hyperbolic PDEs and Multilayer Timoshenko Beams</title>
      <link>https://arxiv.org/abs/2310.11416</link>
      <description>arXiv:2310.11416v2 Announce Type: replace 
Abstract: In this paper, we investigate the rapid stabilization of N-layer Timoshenko composite beams with anti-damping and anti-stiffness at the uncontrolled boundaries. The problem of stabilization for a two-layer composite beam has been previously studied by transforming the model into a 1-D hyperbolic PIDE-ODE form and then applying backstepping to this new system. In principle this approach is generalizable to any number of layers. However, when some of the layers have the same physical properties (as e.g. in lamination of repeated layers), the approach leads to isotachic hyperbolic PDEs (i.e. where some states have the same transport speed). This particular yet physical and interesting case has not received much attention beyond a few remarks in the early hyperbolic design. Thus, this work starts by extending the theory of backstepping control of (m + n) hyperbolic PIDEs and m ODEs to blocks of isotachic states, leading to a block backstepping design. Then, returning to multilayer Timoshenko beams, the Riemann transformation is used to transform the states of N-layer Timoshenko beams into a 1-D hyperbolic PIDE-ODE system. The block backstepping method is then applied to this model, obtaining closed-loop stability of the origin in the L2 sense. An arbitrarily rapid convergence rate can be obtained by adjusting control parameters. Finally, numerical simulations are presented corroborating the theoretical developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11416v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangwei Chen, Rafael Vazquez, Junfei Qiao, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Convergence of the majorized PAM method with subspace correction for low-rank composite factorization model</title>
      <link>https://arxiv.org/abs/2406.04588</link>
      <description>arXiv:2406.04588v2 Announce Type: replace 
Abstract: This paper focuses on the convergence certificates of the majorized proximal alternating minimization (PAM) method with subspace correction, proposed in \cite{TaoQianPan22} for the column $\ell_{2,0}$-norm regularized factorization model and now extended to a class of low-rank composite factorization models from matrix completion. The convergence analysis of this PAM method becomes extremely challenging because a subspace correction step is introduced to every proximal subproblem to ensure a closed-form solution. We establish the full convergence of the iterate sequence and column subspace sequences of factor pairs generated by the PAM, under the KL property of the objective function and a condition that holds automatically for the column $\ell_{2,0}$-norm function. Numerical comparison with the popular proximal alternating linearized minimization (PALM) method is conducted on one-bit matrix completion problems, which indicates that the PAM with subspace correction has an advantage in seeking lower relative error within less time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04588v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Tao, Yitian Qian, Shaohua Pan</dc:creator>
    </item>
    <item>
      <title>An Improved Analysis of the Clipped Stochastic subGradient Method under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2410.00573</link>
      <description>arXiv:2410.00573v2 Announce Type: replace 
Abstract: In this paper, we provide novel optimal (or near optimal) convergence rates for a clipped version of the stochastic subgradient method. We consider nonsmooth convex problems over possibly unbounded domains, under heavy-tailed noise that possesses only the first $p$ moments for $p \in \left]1,2\right]$. For the last iterate, we establish convergence in expectation for the objective values with rates of order $(\log^{1/p} k)/k^{(p-1)/p}$ and $1/k^{(p-1)/p}$, for anytime and finite-horizon respectively. We also derive new convergence rates, in expectation and with high probability, for the objective values along the average iterates--improving existing results by a $\log^{(2p-1)/p} k$ factor. Those results are applied to the problem of supervised learning with kernels demonstrating the effectiveness of our theory. Finally, we give preliminary experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00573v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniela Angela Parletta, Andrea Paudice, Saverio Salzo</dc:creator>
    </item>
    <item>
      <title>Backstepping for Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2410.15146</link>
      <description>arXiv:2410.15146v3 Announce Type: replace 
Abstract: Systems modeled by partial differential equations (PDEs) are at least as ubiquitous as systems that are by nature finite-dimensional and modeled by ordinary differential equations (ODEs). And yet, systematic and readily usable methodologies, for such a significant portion of real systems, have been historically scarce. Around the year 2000, the backstepping approach to PDE control began to offer not only a less abstract alternative to PDE control techniques replicating optimal and spectrum assignment techniques of the 1960s, but also enabled the methodologies of adaptive and nonlinear control, matured in the 1980s and 1990s, to be extended from ODEs to PDEs, allowing feedback synthesis for physical and engineering systems that are uncertain, nonlinear, and infinite-dimensional. The PDE backstepping literature has grown in its nearly a quarter century of development to many hundreds of papers and nearly a dozen books. This survey aims to facilitate the entry, for a new researcher, into this thriving area of overwhelming size and topical diversity. Designs of controllers and observers, for parabolic, hyperbolic, and other classes of PDEs, in one and more dimensions (in box and spherical geometries), with nonlinear, adaptive, sampled-data, and event-triggered extensions, are covered in the survey. The lifeblood of control are technology and physics. The survey places a particular emphasis on applications that have motivated the development of the theory and which have benefited from the theory and designs: applications involving flows, flexible structures, materials, thermal and chemically reacting dynamics, energy (from oil drilling to batteries and magnetic confinement fusions), and vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15146v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafael Vazquez, Jean Auriol, Federico Bribiesca-Argomedo, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Partial Smoothness, Subdifferentials and Set-valued Operators</title>
      <link>https://arxiv.org/abs/2501.15540</link>
      <description>arXiv:2501.15540v2 Announce Type: replace 
Abstract: Over the past decades, the concept "partial smoothness" has been playing as a powerful tool in several fields involving nonsmooth analysis, such as nonsmooth optimization, inverse problems and operation research, etc. The essence of partial smoothness is that it builds an elegant connection between the optimization variable and the objective function value through the subdifferential. Identifiability is the most appealing property of partial smoothness, as locally it allows us to conduct much finer or even sharp analysis, such as linear convergence or sensitivity analysis. However, currently the identifiability relies on non-degeneracy condition and exact dual convergence, which limits the potential application of partial smoothness. In this paper, we provide an alternative characterization of partial smoothness through only subdifferentials. This new perspective enables us to establish stronger identification results, explain identification under degeneracy and non-vanishing error. Moreover, we can generalize this new characterization to set-valued operators, and provide a complement definition of partly smooth operator proposed in [14].</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15540v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqi Qin, Jingwei Liang</dc:creator>
    </item>
    <item>
      <title>Joint Oscillation Damping and Inertia Provision Service for Converter-Interfaced Generation</title>
      <link>https://arxiv.org/abs/2309.01321</link>
      <description>arXiv:2309.01321v2 Announce Type: replace-cross 
Abstract: Power systems dominated by converter-interfaced distributed energy resources (DERs) typically exhibit weaker damping capabilities and lower inertia, compromising system stability. Although individual DER controllers are evolving to provide superior oscillation damping capabilities and inertia supports, there is a lack of network-wide coordinated management measures for multiple DERs, potentially leading to unexpected instability and cost-effectiveness problems. To address this gap, this paper introduces a hybrid oscillation damping and inertia management strategy for multiple DERs, considering network coupling effects, and seeks to encourage DERs to provide enhanced damping and inertia with appropriate economic incentives. We first formulate an optimization problem to tune and allocate damping and inertia coefficients for DERs, minimizing associated power and energy costs while ensuring hard constraints for system frequency stability and small-signal stability. The problem is built upon a novel convex parametric formulation that integrates oscillation mode location and frequency trajectory requirements, equipped with a theoretical guarantee, and eliminating the need for iterative tuning and computation burdens. Furthermore, to increase the willingness of DERs to cooperate, we further design appropriate economic incentives to compensate for DERs' costs based on the proposed cost minimization problem, and assess its impact on system cost-efficiency. Numerical tests highlight the effectiveness of the proposed method in promoting system stability and offer insights into potential economic benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01321v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPWRS.2025.3562811</arxiv:DOI>
      <dc:creator>Cheng Feng, Linbin Huang, Xiuqiang He, Yi Wang, Florian D\"orfler, Chongqing Kang</dc:creator>
    </item>
    <item>
      <title>Algorithms for mean-field variational inference via polyhedral optimization in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2312.02849</link>
      <description>arXiv:2312.02849v3 Announce Type: replace-cross 
Abstract: We develop a theory of finite-dimensional polyhedral subsets over the Wasserstein space and optimization of functionals over them via first-order methods. Our main application is to the problem of mean-field variational inference, which seeks to approximate a distribution $\pi$ over $\mathbb{R}^d$ by a product measure $\pi^\star$. When $\pi$ is strongly log-concave and log-smooth, we provide (1) approximation rates certifying that $\pi^\star$ is close to the minimizer $\pi^\star_\diamond$ of the KL divergence over a \emph{polyhedral} set $\mathcal{P}_\diamond$, and (2) an algorithm for minimizing $\text{KL}(\cdot\|\pi)$ over $\mathcal{P}_\diamond$ based on accelerated gradient descent over $\R^d$. As a byproduct of our analysis, we obtain the first end-to-end analysis for gradient-based algorithms for MFVI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02849v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiheng Jiang, Sinho Chewi, Aram-Alexandre Pooladian</dc:creator>
    </item>
    <item>
      <title>Splitting Guarantees for Prophet Inequalities via Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2406.17767</link>
      <description>arXiv:2406.17767v2 Announce Type: replace-cross 
Abstract: The prophet inequality is one of the cornerstone problems in optimal stopping theory and has become a crucial tool for designing sequential algorithms in Bayesian settings. In the i.i.d. $k$-selection prophet inequality problem, we sequentially observe $n$ non-negative random values sampled from a known distribution. Each time, a decision is made to accept or reject the value, and under the constraint of accepting at most $k$. For $k=1$, Hill and Kertz [Ann. Probab. 1982] provided an upper bound on the worst-case approximation ratio that was later matched by an algorithm of Correa et al. [Math. Oper. Res. 2021]. The worst-case tight approximation ratio for $k=1$ is computed by studying a differential equation that naturally appears when analyzing the optimal dynamic programming policy. A similar result for $k&gt;1$ has remained elusive.
  In this work, we introduce a nonlinear system of differential equations for the i.i.d. $k$-selection prophet inequality that generalizes Hill and Kertz's equation when $k=1$. Our nonlinear system is defined by $k$ constants that determine its functional structure, and their summation provides a lower bound on the optimal policy's asymptotic approximation ratio for the i.i.d. $k$-selection prophet inequality. To obtain this result, we introduce for every $k$ an infinite-dimensional linear programming formulation that fully characterizes the worst-case tight approximation ratio of the $k$-selection prophet inequality problem for every $n$, and then we follow a dual-fitting approach to link with our nonlinear system for sufficiently large values of $n$. As a corollary, we use our provable lower bounds to establish a tight approximation ratio for the stochastic sequential assignment problem in the i.i.d. non-negative regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17767v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Brustle, Sebastian Perez-Salazar, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Unsupervised Machine Learning Hybrid Approach Integrating Linear Programming in Loss Function: A Robust Optimization Technique</title>
      <link>https://arxiv.org/abs/2408.09967</link>
      <description>arXiv:2408.09967v2 Announce Type: replace-cross 
Abstract: This paper presents a novel hybrid approach that integrates linear programming (LP) within the loss function of an unsupervised machine learning model. By leveraging the strengths of both optimization techniques and machine learning, this method introduces a robust framework for solving complex optimization problems where traditional methods may fall short. The proposed approach encapsulates the constraints and objectives of a linear programming problem directly into the loss function, guiding the learning process to adhere to these constraints while optimizing the desired outcomes. This technique not only preserves the interpretability of linear programming but also benefits from the flexibility and adaptability of machine learning, making it particularly well-suited for unsupervised or semi-supervised learning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09967v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Kiruluta, Andreas Lemos</dc:creator>
    </item>
    <item>
      <title>A Dynamic Safety Shield for Safe and Efficient Reinforcement Learning of Navigation Tasks</title>
      <link>https://arxiv.org/abs/2412.04153</link>
      <description>arXiv:2412.04153v2 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) has been successfully applied to a variety of robotics applications, where it outperforms classical methods. However, the safety aspect of RL and the transfer to the real world remain an open challenge. A prominent field for tackling this challenge and ensuring the safety of the agents during training and execution is safe reinforcement learning. Safe RL can be achieved through constrained RL and safe exploration approaches. The former learns the safety constraints over the course of training to achieve a safe behavior by the end of training, at the cost of high number of collisions at earlier stages of the training. The latter offers robust safety by enforcing the safety constraints as hard constraints, which prevents collisions but hinders the exploration of the RL agent, resulting in lower rewards and poor performance. To overcome those drawbacks, we propose a novel safety shield, that combines the robustness of the optimization-based controllers with the long prediction capabilities of the RL agents, allowing the RL agent to adaptively tune the parameters of the controller. Our approach is able to improve the exploration of the RL agents for navigation tasks, while minimizing the number of collisions. Experiments in simulation show that our approach outperforms state-of-the-art baselines in the reached goals-to-collisions ratio in different challenging environments. The goals-to-collisions ratio metrics emphasizes the importance of minimizing the number of collisions, while learning to accomplish the task. Our approach achieves a higher number of reached goals compared to the classic safety shields and fewer collisions compared to constrained RL approaches. Finally, we demonstrate the performance of the proposed method in a real-world experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04153v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Murad Dawood, Ahmed Shokry, Maren Bennewitz</dc:creator>
    </item>
    <item>
      <title>Optimizing quasi-dissipative evolution equations with the moment-SOS hierarchy</title>
      <link>https://arxiv.org/abs/2412.07361</link>
      <description>arXiv:2412.07361v3 Announce Type: replace-cross 
Abstract: We prove that there is no relaxation gap between a quasi-dissipative nonlinear evolution equation in a Hilbert space and its linear Liouville equation reformulation on probability measures. In other words, strong and generalized solutions of such equations are unique in the class of measure-valued solutions. As a major consequence, non-convex numerical optimization over these non-linear partial differential equations can be carried out with the infinite-dimensional moment-SOS hierarchy with global convergence guarantees. This covers in particular all reaction-diffusion equations with polynomial nonlinearity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07361v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saroj Prasad Chhatoi (LAAS-POP), Didier Henrion (LAAS-POP, FEL CTU), Swann Marx (LS2N), Nicolas Seguin (IMAG, ANGUS)</dc:creator>
    </item>
    <item>
      <title>A two-player voting game in Euclidean space</title>
      <link>https://arxiv.org/abs/2504.01713</link>
      <description>arXiv:2504.01713v2 Announce Type: replace-cross 
Abstract: Given a finite set $S$ of points in $\mathbb{R}^d$, which we regard as the locations of voters on a $d$-dimensional political `spectrum', two candidates (Alice and Bob) select one point in $\mathbb{R}^d$ each, in an attempt to get as many votes as possible. Alice goes first and Bob goes second, and then each voter simply votes for the candidate closer to them in terms of Euclidean distance. If a voter's distance from the two candidates is the same, they vote for nobody. We give a geometric characterization of the sets $S$ for which each candidate wins, assuming that Alice wins if they get an equal number of votes. We also show that, if not all the voters lie on a single line, then, whenever Alice has a winning strategy, there is a unique winning point for her. We also provide an algorithm which decides whether Alice has a winning point, and determines the location of that point, both in finite (in fact polynomial) time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01713v2</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stelios Stylianou</dc:creator>
    </item>
    <item>
      <title>Optimal Control for Kuramoto Model: from Many-Particle Liouville Equation to Diffusive Mean-Field Problem</title>
      <link>https://arxiv.org/abs/2504.09425</link>
      <description>arXiv:2504.09425v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate the mean-field optimal control problem of a swarm of Kuramoto oscillators. Using the notion of wrapped distribution, we explain the connection between the stochastic particle system and the mean-field PDE on the periodic domain. In the limit of an infinite number of oscillators the collective dynamics of the agents' density is described by a diffusive mean-field model in the form of a non-local PDE, where the non-locality arises from the synchronization mechanism. We prove the existence of the optimal control of the mean-field model by using $\Gamma$-convergence strategy of the cost functional corresponding to the Liouville equation on the particle level. In the discussion of propagation of chaos for fixed control functions we complete the relative entropy estimate by using large deviation estimate given by \cite{MR3858403}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09425v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Chen, Yucheng Wang, Valeriia Zhidkova</dc:creator>
    </item>
  </channel>
</rss>
