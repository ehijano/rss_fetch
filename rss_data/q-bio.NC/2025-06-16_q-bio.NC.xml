<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 02:27:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Decoding Cortical Microcircuits: A Generative Model for Latent Space Exploration and Controlled Synthesis</title>
      <link>https://arxiv.org/abs/2506.11062</link>
      <description>arXiv:2506.11062v1 Announce Type: new 
Abstract: A central idea in understanding brains and building artificial intelligence is that structure determines function. Yet, how the brain's complex structure arises from a limited set of genetic instructions remains a key question. The ultra high-dimensional detail of neural connections vastly exceeds the information storage capacity of genes, suggesting a compact, low-dimensional blueprint must guide brain development. Our motivation is to uncover this blueprint. We introduce a generative model, to learn this underlying representation from detailed connectivity maps of mouse cortical microcircuits. Our model successfully captures the essential structural information of these circuits in a compressed latent space. We found that specific, interpretable directions within this space directly relate to understandable network properties. Building on this, we demonstrate a novel method to controllably generate new, synthetic microcircuits with desired structural features by navigating this latent space. This work offers a new way to investigate the design principles of neural circuits and explore how structure gives rise to function, potentially informing the development of more advanced artificial neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11062v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Liu, Yubin Li, Guozhang Chen</dc:creator>
    </item>
    <item>
      <title>Sparse Autoencoders Bridge The Deep Learning Model and The Brain</title>
      <link>https://arxiv.org/abs/2506.11123</link>
      <description>arXiv:2506.11123v1 Announce Type: new 
Abstract: We present SAE-BrainMap, a novel framework that directly aligns deep learning visual model representations with voxel-level fMRI responses using sparse autoencoders (SAEs). First, we train layer-wise SAEs on model activations and compute the correlations between SAE unit activations and cortical fMRI signals elicited by the same natural image stimuli with cosine similarity, revealing strong activation correspondence (maximum similarity up to 0.76). Depending on this alignment, we construct a voxel dictionary by optimally assigning the most similar SAE feature to each voxel, demonstrating that SAE units preserve the functional structure of predefined regions of interest (ROIs) and exhibit ROI-consistent selectivity. Finally, we establish fine-grained hierarchical mapping between model layers and the human ventral visual pathway, also by projecting voxel dictionary activations onto individual cortical surfaces, we visualize the dynamic transformation of the visual information in deep learning models. It is found that ViT-B/16$_{CLIP}$ tends to utilize low-level information to generate high-level semantic information in the early layers and reconstructs the low-dimension information later. Our results establish a direct, downstream-task-free bridge between deep neural networks and human visual cortex, offering new insights into model interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11123v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziming Mao, Jia Xu, Zeqi Zheng, Haofang Zheng, Dabing Sheng, Yaochu Jin, Guoyuan Yang</dc:creator>
    </item>
    <item>
      <title>Convolutional method for data assimilation An improved method on neuronal electrophysiological data</title>
      <link>https://arxiv.org/abs/2506.11365</link>
      <description>arXiv:2506.11365v1 Announce Type: new 
Abstract: We present a convolution-based data assimilation method tailored to neuronal electrophysiology, addressing the limitations of traditional value-based synchronization approaches. While conventional methods rely on nudging terms and pointwise deviation metrics, they often fail to account for spike timing precision, a key feature in neural signals. Our approach applies a Gaussian convolution to both measured data and model estimates, enabling a cost function that evaluates both amplitude and timing alignment via spike overlap. This formulation remains compatible with gradient-based optimization. Through twin experiments and real hippocampal neuron recordings, we demonstrate improved parameter estimation and prediction quality, particularly in capturing sharp, time-sensitive dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11365v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dawei Li, Henry D. I. Abarbanel</dc:creator>
    </item>
    <item>
      <title>Voxel-Level Brain States Prediction Using Swin Transformer</title>
      <link>https://arxiv.org/abs/2506.11455</link>
      <description>arXiv:2506.11455v1 Announce Type: new 
Abstract: Understanding brain dynamics is important for neuroscience and mental health. Functional magnetic resonance imaging (fMRI) enables the measurement of neural activities through blood-oxygen-level-dependent (BOLD) signals, which represent brain states. In this study, we aim to predict future human resting brain states with fMRI. Due to the 3D voxel-wise spatial organization and temporal dependencies of the fMRI data, we propose a novel architecture which employs a 4D Shifted Window (Swin) Transformer as encoder to efficiently learn spatio-temporal information and a convolutional decoder to enable brain state prediction at the same spatial and temporal resolution as the input fMRI data. We used 100 unrelated subjects from the Human Connectome Project (HCP) for model training and testing. Our novel model has shown high accuracy when predicting 7.2s resting-state brain activities based on the prior 23.04s fMRI time series. The predicted brain states highly resemble BOLD contrast and dynamics. This work shows promising evidence that the spatiotemporal organization of the human brain can be learned by a Swin Transformer model, at high resolution, which provides a potential for reducing the fMRI scan time and the development of brain-computer interfaces in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11455v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Sun, Daniel Chahine, Qinghao Wen, Tianming Liu, Xiang Li, Yixuan Yuan, Fernando Calamante, Jinglei Lv</dc:creator>
    </item>
    <item>
      <title>Differences in Neurovascular Coupling in Patients with Major Depressive Disorder: Evidence from Simultaneous Resting-State EEG-fNIRS</title>
      <link>https://arxiv.org/abs/2506.11634</link>
      <description>arXiv:2506.11634v1 Announce Type: new 
Abstract: Neurovascular coupling (NVC) refers to the process by which local neural activity, through energy consumption, induces changes in regional cerebral blood flow to meet the metabolic demands of neurons. Event-related studies have shown that the hemodynamic response typically lags behind neural activation by 4-6 seconds. However, little is known about how NVC is altered in patients with major depressive disorder (MDD) and throughout the recovery process. In this study, we employed simultaneous resting-state electroencephalography (rsEEG) and functional near-infrared spectroscopy (fNIRS) to monitor neural and hemodynamic signals. Twelve patients with MDD during the acute phase, ten patients in the maintenance or consolidation phase, and six healthy controls were involved. We calculated the differences in coherence and temporal delay between spontaneous peak electrophysiological activity and hemodynamic responses across groups during the resting state in the prefrontal cortex (PFC). We found that the neural activity and its subsequent correlation with hemodynamic responses were significantly higher in patients during the maintenance phase. The rise time from the lowest to the highest point of correlation was shorter in healthy individuals than in patients in the acute phase, and gradually recovered during remission. By leveraging wearable neuroimaging techniques, this study reveals alterations in neurovascular coupling in depression and offers novel multimodal insights into potential biomarkers for MDD and its recovery process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11634v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feng Yan, Xiaobin Wang, Yao Zhao, Shuyi Yang, Zhiren Wang</dc:creator>
    </item>
    <item>
      <title>The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI</title>
      <link>https://arxiv.org/abs/2506.11015</link>
      <description>arXiv:2506.11015v1 Announce Type: cross 
Abstract: In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as "grokking" and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological "schemata" and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11015v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barbara Oakley, Michael Johnston, Ken-Zen Chen, Eulho Jung, Terrence J. Sejnowski</dc:creator>
    </item>
    <item>
      <title>Brain2Vec: A Deep Learning Framework for EEG-Based Stress Detection Using CNN-LSTM-Attention</title>
      <link>https://arxiv.org/abs/2506.11179</link>
      <description>arXiv:2506.11179v1 Announce Type: cross 
Abstract: Mental stress has become a pervasive factor affecting cognitive health and overall well-being, necessitating the development of robust, non-invasive diagnostic tools. Electroencephalogram (EEG) signals provide a direct window into neural activity, yet their non-stationary and high-dimensional nature poses significant modeling challenges. Here we introduce Brain2Vec, a new deep learning tool that classifies stress states from raw EEG recordings using a hybrid architecture of convolutional, recurrent, and attention mechanisms. The model begins with a series of convolutional layers to capture localized spatial dependencies, followed by an LSTM layer to model sequential temporal patterns, and concludes with an attention mechanism to emphasize informative temporal regions. We evaluate Brain2Vec on the DEAP dataset, applying bandpass filtering, z-score normalization, and epoch segmentation as part of a comprehensive preprocessing pipeline. Compared to traditional CNN-LSTM baselines, our proposed model achieves an AUC score of 0.68 and a validation accuracy of 81.25%. These findings demonstrate Brain2Vec's potential for integration into wearable stress monitoring platforms and personalized healthcare systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11179v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Mynoddin, Troyee Dev, Rishita Chakma</dc:creator>
    </item>
    <item>
      <title>Equivalence of stationary dynamical solutions in a directed chain and a Delay Differential Equation of neuroscientific relevance</title>
      <link>https://arxiv.org/abs/2506.11654</link>
      <description>arXiv:2506.11654v1 Announce Type: cross 
Abstract: While synchronized states, and the dynamical pathways through which they emerge, are often regarded as the paradigm to understand the dynamics of information spreading on undirected networks of nonlinear dynamical systems, when we consider directed network architectures, dynamical stationary states can arise. To study this phenomenon we consider the simplest directed network, a single cycle, and excitable FitzHugh-Nagumo (FHN) neurons. We show numerically that a stationary dynamical state emerges in the form of a self-sustained traveling wave, through a saddle-point bifurcation of limit cycles that does not destabilize the global fixed point of the system. We then formulate an effective model for the dynamical steady state of the cycle in terms of a single-neuron Delay Differential Equation (DDE) featuring an explicitly delayed feedback, demonstrating numerically the possibility of mapping stationary solutions between the two models. The DDE based model is shown to reproduce the entire bifurcation, which also in this case does not destabilize the global fixed point, even though global properties differ in general between the systems. The discrete nature of the cycle graph is revealed as the origin of these coordinated states by the parametric analysis of solutions, and the DDE effective model is shown to preserve this feature accurately. Finally, the scaling of the inter-site propagation times hints to a solitonic nature of the wave state in the limit of large chain size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11654v1</guid>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulio Colombini, Nicola Guglielmi, Armando Bazzani</dc:creator>
    </item>
    <item>
      <title>Synchronous Propagation of Periodic Signals in Feedforward Networks of Standard Model Neurons</title>
      <link>https://arxiv.org/abs/2506.11776</link>
      <description>arXiv:2506.11776v1 Announce Type: cross 
Abstract: Periodic signals propagating along chains are common in biology, for example in locomotion and peristalsis, and are also of interest for continuum robots. In previous work we constructed such networks as 'feedforward lifts' of a central pattern generator (CPG). When the CPG undergoes periodic oscillations, created by Hopf bifurcation or other mechanisms, it can then transmit periodic signals along one or more feedforward chains in a synchronous or phase-synchronous manner. We proved necessary and sufficient conditions for the stability of these lifted periodic orbits, in several senses. Here we examine the implications of the resulting theory for chains of neurons, using several standard neuron models: FitzHugh-Nagumo, Morris-Lecar, Hindmarsh-Rose, and Hodgkin-Huxley. We compare different notions of transverse stability, and summarize some numerical simulations showing that for all these neuron models the propagating signal can be transversely Floquet stable. Finally we discuss implications for less idealized models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11776v1</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian Stewart, David Wood</dc:creator>
    </item>
    <item>
      <title>Tensor formalism for predicting synaptic connections with ensemble modeling or optimization</title>
      <link>https://arxiv.org/abs/2310.20309</link>
      <description>arXiv:2310.20309v3 Announce Type: replace 
Abstract: Theoretical neuroscientists often try to understand how the structure of a neural network relates to its function by focusing on structural features that would either follow from optimization or occur consistently across possible implementations. Both optimization theories and ensemble modeling approaches have repeatedly proven their worth, and it would simplify theory building considerably if predictions from both theory types could be derived and tested simultaneously. Here we show how tensor formalism from theoretical physics can be used to unify and solve many optimization and ensemble modeling approaches to predicting synaptic connectivity from neuronal responses. We specifically focus on analyzing the solution space of synaptic weights that allow a threshold-linear neural network to respond in a prescribed way to a limited number of input conditions. For optimization purposes, we compute the synaptic weight vector that minimizes an arbitrary quadratic loss function. For ensemble modeling, we identify synaptic weight features that occur consistently across all solutions bounded by an arbitrary ellipsoid. We derive a common solution to this suite of nonlinear problems by showing how each of them reduces to an equivalent linear problem that can be solved analytically. Although identifying the equivalent linear problem is nontrivial, our tensor formalism provides an elegant geometrical perspective that allows us to solve the problem approximately in an analytical way or exactly using numeric methods. The final algorithm is applicable to a wide range of interesting neuroscience problems, and the associated geometric insights may carry over to other scientific problems that require constrained optimization. We conclude by applying and testing our ensemble modeling framework to whole-brain recordings of larval zebrafish performing optomotor and optokinetic responses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.20309v3</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.bio-ph</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tirthabir Biswas, Tianzhi Lambus Li, Selimzhan Chalyshkan, Fumi Kubo, James E. Fitzgerald</dc:creator>
    </item>
    <item>
      <title>Naturalistic Computational Cognitive Science: Towards generalizable models and theories that capture the full range of natural behavior</title>
      <link>https://arxiv.org/abs/2502.20349</link>
      <description>arXiv:2502.20349v2 Announce Type: replace 
Abstract: How can cognitive science build generalizable theories that span the full scope of natural situations and behaviors? We argue that progress in Artificial Intelligence (AI) offers timely opportunities for cognitive science to embrace experiments with increasingly naturalistic stimuli, tasks, and behaviors; and computational models that can accommodate these changes. We first review a growing body of research spanning neuroscience, cognitive science, and AI that suggests that incorporating a broader range of naturalistic experimental paradigms, and models that accommodate them, may be necessary to resolve some aspects of natural intelligence and ensure that our theories generalize. First, we review cases from cognitive science and neuroscience where naturalistic paradigms elicit distinct behaviors or engage different processes. We then discuss recent progress in AI that shows that learning from naturalistic data yields qualitatively different patterns of behavior and generalization, and discuss how these findings impact the conclusions we draw from cognitive modeling, and can help yield new hypotheses for the roots of cognitive and neural phenomena. We then suggest that integrating recent progress in AI and cognitive science will enable us to engage with more naturalistic phenomena without giving up experimental control or the pursuit of theoretically grounded understanding. We offer practical guidance on how methodological practices can contribute to cumulative progress in naturalistic computational cognitive science, and illustrate a path towards building computational models that solve the real problems of natural cognition, together with a reductive understanding of the processes and principles by which they do so.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20349v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wilka Carvalho, Andrew Lampinen</dc:creator>
    </item>
    <item>
      <title>NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models</title>
      <link>https://arxiv.org/abs/2506.04536</link>
      <description>arXiv:2506.04536v2 Announce Type: replace-cross 
Abstract: Characterizing the diverse computational properties of human neurons via multimodal electrophysiological, transcriptomic, and morphological data provides the foundation for constructing and validating bio-realistic neuron models that can advance our understanding of fundamental mechanisms underlying brain function. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. To capture variability, ensembles of deterministic models are often used, but are difficult to scale as model generation requires repeating computationally expensive optimization for each neuron. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce NOBLE, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on data generated from biophysically realistic neuron models, NOBLE predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. NOBLE is the first scaled-up deep learning framework validated on real experimental data, enabling efficient generation of synthetic neurons that exhibit trial-to-trial variability and achieve a $4200\times$ speedup over numerical solvers. To this end, NOBLE captures fundamental neural properties, opening the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04536v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Ghafourpour, Valentin Duruisseaux, Bahareh Tolooshams, Philip H. Wong, Costas A. Anastassiou, Anima Anandkumar</dc:creator>
    </item>
  </channel>
</rss>
