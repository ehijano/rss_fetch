<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Oct 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fully Parallel Multi-Agent Photonic Optimizer</title>
      <link>https://arxiv.org/abs/2510.06424</link>
      <description>arXiv:2510.06424v1 Announce Type: new 
Abstract: Optimization problems are central to many important cross-disciplinary applications.In their conventional implementations, the sequential nature of operations imposes strict limitations on the computational efficiency. Here, we discuss how analog optical computing can overcome this fundamental bottleneck. We propose a photonic optimizer unit, together with supporting algorithms that uses in memory computation within a nature inspired, multi agent cooperative framework. The system performs a sequence of reconfigurable parallel matrix vector operations, enabled by the high bandwidth and multiplexing capabilities inherent to photonic circuits. This approach provides a pathway toward fast paced and high quality solutions for difficult optimization and search problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06424v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ghazi Sarwat Syed, Philipp Schmidt, Frank Br\"uckerhoff-Pl\"uckelmann, Jelle Dijkstra, Wolfram H. P Pernice, Abu Sebastian</dc:creator>
    </item>
    <item>
      <title>Application of deep neural networks for computing the renormalization group flow of the two-dimensional phi^4 field theory</title>
      <link>https://arxiv.org/abs/2510.06508</link>
      <description>arXiv:2510.06508v1 Announce Type: new 
Abstract: We introduce RGFlow, a deep neural network-based real-space renormalization group (RG) framework tailored for continuum scalar field theories. Leveraging generative capabilities of flow-based neural networks, RGFlow autonomously learns real-space RG transformations from data without prior knowledge of the underlying model. In contrast to conventional approaches, RGFlow is bijective (information-preserving) and is optimized based on the principle of minimal mutual information. We demonstrate the method on two examples. The first one is a one-dimensional Gaussian model, where RGFlow is shown to learn the classical decimation rule. The second is the two-dimensional phi^4 theory, where the network successfully identifies a Wilson-Fisher-like critical point and provides an estimate of the correlation-length critical exponent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06508v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueqi Zhao, Michael M. Fogler, Yi-Zhuang You</dc:creator>
    </item>
    <item>
      <title>Beyond the non-Hermitian skin effect: scaling-controlled topology from Exceptional-Bound Bands</title>
      <link>https://arxiv.org/abs/2510.06338</link>
      <description>arXiv:2510.06338v1 Announce Type: cross 
Abstract: We establish a novel mechanism for topological transitions in non-Hermitian systems that are controlled by the system size. Based on a new paradigm known as exceptional-bound (EB) band engineering, its mechanism hinges on the unique critical scaling behavior near an exceptional point, totally unrelated to the well-known non-Hermitian skin effect. Through a series of ansatz models, we analytically derive and numerically demonstrate how topological transitions depend on the system size with increasingly sophisticated topological phase boundaries. Our approach can be generically applied to design scaling-dependent bands in multi-dimensional lattices, gapped or gapless, challenging established critical and entanglement behavior. It can be experimentally demonstrated in any non-Hermitian platform with versatile couplings or multi-orbital unit cells, such as photonic crystals, as well as classical and quantum circuits. The identification of this new EB band mechanism provides new design principles for engineering band structures through scaling-dependent phenomena unique to non-Hermitian systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06338v1</guid>
      <category>cond-mat.other</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mes-hall</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>quant-ph</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengjie Yang, Ching Hua Lee</dc:creator>
    </item>
    <item>
      <title>Fisher Information, Training and Bias in Fourier Regression Models</title>
      <link>https://arxiv.org/abs/2510.06945</link>
      <description>arXiv:2510.06945v1 Announce Type: cross 
Abstract: Motivated by the growing interest in quantum machine learning, in particular quantum neural networks (QNNs), we study how recently introduced evaluation metrics based on the Fisher information matrix (FIM) are effective for predicting their training and prediction performance. We exploit the equivalence between a broad class of QNNs and Fourier models, and study the interplay between the \emph{effective dimension} and the \emph{bias} of a model towards a given task, investigating how these affect the model's training and performance. We show that for a model that is completely agnostic, or unbiased, towards the function to be learned, a higher effective dimension likely results in a better trainability and performance. On the other hand, for models that are biased towards the function to be learned a lower effective dimension is likely beneficial during training. To obtain these results, we derive an analytical expression of the FIM for Fourier models and identify the features controlling a model's effective dimension. This allows us to construct models with tunable effective dimension and bias, and to compare their training. We furthermore introduce a tensor network representation of the considered Fourier models, which could be a tool of independent interest for the analysis of QNN models. Overall, these findings provide an explicit example of the interplay between geometrical properties, model-task alignment and training, which are relevant for the broader machine learning community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06945v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.data-an</category>
      <category>quant-ph</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Pastori, Veronika Eyring, Mierk Schwabe</dc:creator>
    </item>
    <item>
      <title>Diffusion Codes: Self-Correction from Small(er)-Set Expansion with Tunable Non-locality</title>
      <link>https://arxiv.org/abs/2510.07179</link>
      <description>arXiv:2510.07179v1 Announce Type: cross 
Abstract: Optimal constructions of classical LDPC codes can be obtained by choosing the Tanner graph uniformly at random among biregular graphs. We introduce a class of codes that we call ``diffusion codes'', defined by placing each edge connecting bits and checks on some graph, and acting on that graph with a random SWAP network. By tuning the depth of the SWAP network, we can tune a tradeoff between the amount of randomness -- and hence the optimality of code parameters -- and locality with respect to the underlying graph. For diffusion codes defined on the cycle graph, if the SWAP network has depth $\sim Tn$ with $T&gt; n^{2\beta}$ for arbitrary $\beta&gt;0$, then we prove that almost surely the Tanner graph is a lossless ``smaller set'' vertex expander for small sets up size $\delta \sim \sqrt T \sim n^{\beta}$, with bounded bit and check degree. At the same time, the geometric size of the largest stabilizer is bounded by $\sqrt T$ in graph distance. We argue, based on physical intuition, that this result should hold more generally on arbitrary graphs. By taking hypergraph products of these classical codes we obtain quantum LDPC codes defined on the torus with smaller-set boundary and co-boundary expansion and the same expansion/locality tradeoffs as for the classical codes. These codes are self-correcting and admit single-shot decoding, while having the geometric size of the stabilizer growing as an arbitrarily small power law. Our proof technique establishes mixing of a random SWAP network on small subsystems at times scaling with only the subsystem size, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07179v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adithya Sriram, Vedika Khemani, Benedikt Placke</dc:creator>
    </item>
    <item>
      <title>Renormalization of Interacting Random Graph Models</title>
      <link>https://arxiv.org/abs/2510.07186</link>
      <description>arXiv:2510.07186v1 Announce Type: cross 
Abstract: Random graphs offer a useful mathematical representation of a variety of real world complex networks. Exponential random graphs, for example, are particularly suited towards generating random graphs constrained to have specified statistical moments. In this investigation, we elaborate on a generalization of the former where link probabilities are conditioned on the appearance of other links, corresponding to the introduction of interactions in an effective generalized statistical mechanical formalism. When restricted to the simplest non-trivial case of pairwise interactions, one can derive a closed form renormalization group transformation for maximum coordination number two on the corresponding line graph. Higher coordination numbers do not admit exact closed form renormalization group transformations, a feature that paraphrases the usual absence of exact transformations in two or more dimensional lattice systems. We introduce disorder and study the induced renormalization group flow on its probability assignments, highlighting its formal equivalence to time reversed anisotropic drift-diffusion on the statistical manifold associated with the effective Hamiltonian. We discuss the implications of our findings, stressing the long wavelength irrelevance of certain classes of pair-wise conditioning on random graphs, and conclude with possible applications. These include modeling the scaling behavior of preferential effects on social networks, opinion dynamics, and reinforcement effects on neural networks, as well as how our findings offer a systematic framework to deal with data limitations in inference and reconstruction problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07186v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>hep-th</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessio Catanzaro, Diego Garlaschelli, Subodh P. Patil</dc:creator>
    </item>
    <item>
      <title>Renormalization-Group Analysis of the Many-Body Localization Transition in the Random-Field XXZ Chain</title>
      <link>https://arxiv.org/abs/2410.12430</link>
      <description>arXiv:2410.12430v2 Announce Type: replace 
Abstract: We analyze the spectral properties of the Heisenberg spin-1/2 chain with random fields in light of recent works of the renormalization-group flow of the Anderson model in infinite dimension. We reconstruct the beta function of the order parameter from the numerical data, and show that it does not admit a one-parameter scaling form and a simple Wilson-Fisher fixed point. Rather, it is compatible with a two-parameter, Berezinskii-Kosterlitz-Thouless-like flow with a line of fixed points (the many-body localized phase), which terminates into the localization transition critical point. Therefore, we argue that previous studies, which assumed the existence of an isolated Wilson- Fisher fixed point and performed one-parameter finite-size scaling analysis, could not explain the numerical data in a coherent way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12430v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/gcwf-jdlr</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. B 112, (2025)</arxiv:journal_reference>
      <dc:creator>Jacopo Niedda, Giacomo Bracci Testasecca, Giuseppe Magnifico, Federico Balducci, Carlo Vanoni, Antonello Scardicchio</dc:creator>
    </item>
    <item>
      <title>Performance of machine-learning-assisted Monte Carlo in sampling from simple statistical physics models</title>
      <link>https://arxiv.org/abs/2505.22598</link>
      <description>arXiv:2505.22598v4 Announce Type: replace 
Abstract: Recent years have seen a rise in the application of machine learning techniques to aid the simulation of hard-to-sample systems that cannot be studied using traditional methods. Despite the introduction of many different architectures and procedures, a wide theoretical understanding is still lacking, with the risk of suboptimal implementations. As a first step to address this gap, we provide here a complete analytic study of the widely-used Sequential Tempering procedure applied to a shallow MADE architecture for the Curie-Weiss model. The contribution of this work is twofold: firstly, we give a description of the optimal weights and of the training under Gradient Descent optimization. Secondly, we compare what happens in Sequential Tempering with and without the addition of local Metropolis Monte Carlo steps. We are thus able to give theoretical predictions on the best procedure to apply in this case. This work establishes a clear theoretical basis for the integration of machine learning techniques into Monte Carlo sampling and optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22598v4</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/s1rm-29zx</arxiv:DOI>
      <arxiv:journal_reference>Physical Review E, 112(4), 045307 (2025)</arxiv:journal_reference>
      <dc:creator>Luca Maria Del Bono, Federico Ricci-Tersenghi, Francesco Zamponi</dc:creator>
    </item>
  </channel>
</rss>
