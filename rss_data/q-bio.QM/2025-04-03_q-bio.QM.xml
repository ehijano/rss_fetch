<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Apr 2025 01:47:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-Marker Similarity enables reduced-reference and interpretable image quality assessment in optical microscopy</title>
      <link>https://arxiv.org/abs/2504.01537</link>
      <description>arXiv:2504.01537v1 Announce Type: new 
Abstract: Optical microscopy contributes to the ever-increasing progress in biological and biomedical studies, as it allows the implementation of minimally invasive experimental pipelines to translate the data of measured samples into valuable knowledge. Within these pipelines, reliable quality assessment must be ensured to validate the generated results. Image quality assessment is often applied with full-reference methods to estimate the similarity between the ground truth and the output images. However, current methods often show poor agreement with visual perception and lead to the generation of various full-reference metrics tailored to specific applications. Additionally, they rely on pixel-wise comparisons, emphasizing local intensity similarity while often overlooking comprehensive and interpretable image quality assessment. To address these issues, we have developed a multi-marker similarity method that compares standard quality markers, such as resolution, signal-to-noise ratio, contrast, and high frequency components. The method computes a similarity score between the image and the ground truth for each marker, then combines these scores into an overall similarity estimate. This provides a full-reference estimate of image quality while extracting global quality features and detecting experimental artifacts. Multi-marker similarity provides a reliable and interpretable method for image quality assessment and the generation of quality rankings. By focusing on the comparison of quality markers rather than direct image distances, the method enables reduced reference implementations, where a single field of view is used as a benchmark for multiple measurements. This opens the way for reliable automatic evaluation of big datasets, typical of large biomedical studies, when manual assessment of single images and defining the ground truth for each field of view is not feasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01537v1</guid>
      <category>q-bio.QM</category>
      <category>physics.optics</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Corbetta, Thomas Bocklitz</dc:creator>
    </item>
    <item>
      <title>Glycemic Variability Before And After Hypoglycemia Across Different Timeframes In Type 1 Diabetes With And Without Automated Insulin Delivery</title>
      <link>https://arxiv.org/abs/2504.01624</link>
      <description>arXiv:2504.01624v1 Announce Type: new 
Abstract: Managing Type 1 diabetes (T1D) aims to optimize glucose levels within the target range while minimizing hyperglycemia and hypoglycemia. Exercise presents additional challenges due to complex effects on glucose dynamics. Despite advancements in diabetes technology, significant gaps remain in understanding the relationship between exercise, glycemic variability (GV), and hypoglycemia in both automated insulin delivery (AID) and non-AID users. Additionally, limited research explores the temporal progression of GV before and after hypoglycemia and the impact of long-duration episodes on glucose recovery. This study analyses the Type 1 Diabetes and Exercise Initiative (T1DEXI) dataset, assessing GV, hypoglycemia, gender, and exercise interactions in AID (n=222) and non-AID (n=276) users. The study examined patterns of glycemic variability metrics like time below range (TBR) surrounding hypoglycemia events, focusing on the 48 hours before and after these events. We further assess the impact of different hypoglycemia levels (41-50 mg/dL, 51-60 mg/dL, and 61-70 mg/dL) on post-event glucose stability. GV increased before and after hypoglycemia up to 48 hours in both AID and non-AID users, with statistically significant differences. TBR elevation persisted across all groups, peaking around hypoglycemic episodes. Notably, females using AID achieved significantly improved glucose stability compared to non-AID females - a larger within-group difference than that observed in males. Individual-level AID analyses showed that long hypoglycemia episodes (&gt;40 minutes) led to prolonged TBR elevation, suggesting slower recovery despite AID intervention. GV trends may aid in predicting hypoglycemia over extended periods. Integrating GV patterns into AID systems could enhance glucose stability and mitigate hypoglycemia cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01624v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ahtsham Zafar, Abiodun Solanke, Dana M. Lewis, Arsalan Shahid</dc:creator>
    </item>
    <item>
      <title>Integrating experimental feedback improves generative models for biological sequences</title>
      <link>https://arxiv.org/abs/2504.01593</link>
      <description>arXiv:2504.01593v1 Announce Type: cross 
Abstract: Generative probabilistic models have shown promise in designing artificial RNA and protein sequences but often suffer from high rates of false positives, where sequences predicted as functional fail experimental validation. To address this critical limitation, we explore the impact of reintegrating experimental feedback into the model design process. We propose a likelihood-based reintegration scheme, which we test through extensive computational experiments on both RNA and protein datasets, as well as through wet-lab experiments on the self-splicing ribozyme from the group I intron RNA family where our approach demonstrates particular efficacy. We show that integrating recent experimental data enhances the model's capacity of generating functional sequences (e.g. from 6.7\% to 63.7\% of active designs at 45 mutations). This feedback-driven approach thus provides a significant improvement in the design of biomolecular sequences by directly tackling the false-positive challenge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01593v1</guid>
      <category>q-bio.BM</category>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Francesco Calvanese, Giovanni Peinetti, Polina Pavlinova, Philippe Nghe, Martin Weigt</dc:creator>
    </item>
    <item>
      <title>Practical and scalable simulations of non-Markovian stochastic processes and temporal networks with individual node properties</title>
      <link>https://arxiv.org/abs/2212.05059</link>
      <description>arXiv:2212.05059v5 Announce Type: replace 
Abstract: Discrete stochastic processes are prevalent in natural systems, with applications in physics, biochemistry, epidemiology, sociology, and finance. While analytic solutions often cannot be derived, existing simulation frameworks can generate stochastic trajectories compatible with the dynamical laws underlying the random phenomena. Still, most simulation algorithms assume the system dynamics are memoryless (Markovian assumption), under which assumption, future occurrences only depend on the system's present state. This enables efficient and exact simulation via the Gillespie algorithm. However, many real-world systems are inherently non-Markovian and exhibit memory effects. Such systems are difficult to study analytically, and current numerical methods are often computationally expensive or limited by strong simplifying assumptions that conflict with empirical data. To address these limitations, we introduce the Rejection-based Gillespie algorithm for non-Markovian Reactions (REGIR), a general and scalable framework for simulating non-Markovian stochastic systems with arbitrary inter-event time distributions. REGIR provides user-defined accuracy while preserving the same asymptotic computational complexity as the classical Gillespie algorithm. We derive a lower bound on REGIR's approximation accuracy and demonstrate its capabilities across three representative classes of non-Markovian systems: (1) reaction channels with delays, (2) stochastic processes driven by individual reactant properties, and (3) temporal networks governed by node activity. In all cases, REGIR accurately captures memory-dependent dynamics and outperforms existing approaches in terms of flexibility and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.05059v5</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aurelien Pelissier, Miroslav Phan, Didier Le Bail, Niko Beerenwinkel, Maria Rodriguez Martinez</dc:creator>
    </item>
    <item>
      <title>Leveraging statistical models to improve pre-season forecasting and in-season management of a recreational fishery</title>
      <link>https://arxiv.org/abs/2503.17293</link>
      <description>arXiv:2503.17293v4 Announce Type: replace 
Abstract: Effective management of recreational fisheries requires accurate forecasting of future harvests and real-time monitoring of ongoing harvests. Traditional methods that rely on historical catch data to predict short-term harvests can be unreliable, particularly if changes in management regulations alter angler behavior. In contrast, statistical modeling approaches can provide faster, more flexible, and potentially more accurate predictions, enhancing management outcomes. In this study, we developed and tested models to improve predictions of Gulf of Mexico gag harvests for both pre-season planning and in-season monitoring. Our best-fitting model outperformed traditional methods (i.e., estimates derived from historical average harvest) for both cumulative pre-season projections and in-season monitoring. Notably, our modeling framework appeared to be more accurate in more recent, shorter seasons due to its ability to account for effort compression. A key advantage of our framework is its ability to explicitly quantify the probability of exceeding harvest quotas for any given season duration. This feature enables managers to evaluate trade-offs between season duration and conservation goals. This is especially critical for vulnerable, highly targeted stocks. Our findings also underscore the value of statistical models to complement and advance traditional fisheries management approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17293v4</guid>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Challen Hyman, Chloe Ramsay, Tiffanie A. Cross, Beverly Sauls, Thomas K. Frazer</dc:creator>
    </item>
    <item>
      <title>Why risk matters for protein binder design</title>
      <link>https://arxiv.org/abs/2504.00146</link>
      <description>arXiv:2504.00146v2 Announce Type: replace-cross 
Abstract: Bayesian optimization (BO) has recently become more prevalent in protein engineering applications and hence has become a fruitful target of benchmarks. However, current BO comparisons often overlook real-world considerations like risk and cost constraints. In this work, we compare 72 model combinations of encodings, surrogate models, and acquisition functions on 11 protein binder fitness landscapes, specifically from this perspective. Drawing from the portfolio optimization literature, we adopt metrics to quantify the cold-start performance relative to a random baseline, to assess the risk of an optimization campaign, and to calculate the overall budget required to reach a fitness threshold. Our results suggest the existence of Pareto-optimal models on the risk-performance axis, the shift of this preference depending on the landscape explored, and the robust correlation between landscape properties such as epistasis with the average and worst-case model performance. They also highlight that rigorous model selection requires substantial computational and statistical efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00146v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tudor-Stefan Cotet, Igor Krawczuk</dc:creator>
    </item>
  </channel>
</rss>
