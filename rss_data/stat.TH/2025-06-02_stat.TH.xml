<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Jun 2025 03:06:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive finite element type decomposition of Gaussian processes</title>
      <link>https://arxiv.org/abs/2505.24066</link>
      <description>arXiv:2505.24066v1 Announce Type: new 
Abstract: In this paper, we investigate a class of approximate Gaussian processes (GP) obtained by taking a linear combination of compactly supported basis functions with the basis coefficients endowed with a dependent Gaussian prior distribution. This general class includes a popular approach that uses a finite element approximation of the stochastic partial differential equation (SPDE) associated with Mat\'ern GP. We explored another scalable alternative popularly used in the computer emulation literature where the basis coefficients at a lattice are drawn from a Gaussian process with an inverse-Gamma bandwidth. For both approaches, we study concentration rates of the posterior distribution. We demonstrated that the SPDE associated approach with a fixed smoothness parameter leads to a suboptimal rate despite how the number of basis functions and bandwidth are chosen when the underlying true function is sufficiently smooth. On the flip side, we showed that the later approach is rate-optimal adaptively over all smoothness levels of the underlying true function if an appropriate prior is placed on the number of basis functions. Efficient computational strategies are developed and numerics are provided to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24066v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaehoan Kim, Anirban Bhattacharya, Debdeep Pati</dc:creator>
    </item>
    <item>
      <title>Neural Drift Estimation for Ergodic Diffusions: Non-parametric Analysis and Numerical Exploration</title>
      <link>https://arxiv.org/abs/2505.24383</link>
      <description>arXiv:2505.24383v1 Announce Type: new 
Abstract: We take into consideration generalization bounds for the problem of the estimation of the drift component for ergodic stochastic differential equations, when the estimator is a ReLU neural network and the estimation is non-parametric with respect to the statistical model. We show a practical way to enforce the theoretical estimation procedure, enabling inference on noisy and rough functional data. Results are shown for a simulated It\^o-Taylor approximation of the sample paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24383v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-92383-8_20</arxiv:DOI>
      <arxiv:journal_reference>New Trends Funct. Stat. Relat. Fields, Chap. 20. Springer (2025)</arxiv:journal_reference>
      <dc:creator>Simone Di Gregorio, Francesco Iafrate</dc:creator>
    </item>
    <item>
      <title>Locally Differentially Private Two-Sample Testing</title>
      <link>https://arxiv.org/abs/2505.24811</link>
      <description>arXiv:2505.24811v1 Announce Type: new 
Abstract: We consider the problem of two-sample testing under a local differential privacy constraint where a permutation procedure is used to calibrate the tests. We develop testing procedures which are optimal up to logarithmic factors, for general discrete distributions and continuous distributions subject to a smoothness constraint. Both non-interactive and interactive tests are considered, and we show allowing interactivity results in an improvement in the minimax separation rates. Our results show that permutation procedures remain feasible in practice under local privacy constraints, despite the inability to permute the non-private data directly and only the private views. Further, through a refined theoretical analysis of the permutation procedure, we are able to avoid an equal sample size assumption which has been made in the permutation testing literature regardless of the presence of the privacy constraint. Lastly, we conduct numerical experiments which demonstrate the performance of our proposed test and verify the theoretical findings, especially the improved performance enabled by allowing interactivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24811v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Kent, Thomas B. Berrett, Yi Yu</dc:creator>
    </item>
    <item>
      <title>Consistent line clustering using geometric hypergraphs</title>
      <link>https://arxiv.org/abs/2505.24868</link>
      <description>arXiv:2505.24868v1 Announce Type: new 
Abstract: Traditional data analysis often represents data as a weighted graph with pairwise similarities, but many problems do not naturally fit this framework. In line clustering, points in a Euclidean space must be grouped so that each cluster is well approximated by a line segment. Since any two points define a line, pairwise similarities fail to capture the structure of the problem, necessitating the use of higher-order interactions modeled by geometric hypergraphs. We encode geometry into a 3-uniform hypergraph by treating sets of three points as hyperedges whenever they are approximately collinear. The resulting hypergraph contains information about the underlying line segments, which can then be extracted using community recovery algorithms. In contrast to classical hypergraph block models, latent geometric constraints in this construction introduce significant dependencies between hyperedges, which restricts the applicability of many standard theoretical tools. We aim to determine the fundamental limits of line clustering and evaluate hypergraph-based line clustering methods. To this end, we derive information-theoretic thresholds for exact and almost exact recovery for data generated from intersecting lines on a plane with additive Gaussian noise. We develop a polynomial-time spectral algorithm and show that it succeeds under noise conditions that match the information-theoretic bounds up to a polylogarithmic factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24868v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kalle Alaluusua, Konstantin Avrachenkov, B. R. Vinay Kumar, Lasse Leskel\"a</dc:creator>
    </item>
    <item>
      <title>Sharp Concentration of Simple Random Tensors II: Asymmetry</title>
      <link>https://arxiv.org/abs/2505.24144</link>
      <description>arXiv:2505.24144v1 Announce Type: cross 
Abstract: This paper establishes sharp concentration inequalities for simple random tensors. Our theory unveils a phenomenon that arises only for asymmetric tensors of order $p \ge 3:$ when the effective ranks of the covariances of the component random variables lie on both sides of a critical threshold, an additional logarithmic factor emerges that is not present in sharp bounds for symmetric tensors. To establish our results, we develop empirical process theory for products of $p$ different function classes evaluated at $p$ different random variables, extending generic chaining techniques for quadratic and product empirical processes to higher-order settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24144v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaheng Chen, Daniel Sanz-Alonso</dc:creator>
    </item>
    <item>
      <title>Equilibrium Distribution for t-Distributed Stochastic Neighbor Embedding with Generalized Kernels</title>
      <link>https://arxiv.org/abs/2505.24311</link>
      <description>arXiv:2505.24311v1 Announce Type: cross 
Abstract: T-distributed stochastic neighbor embedding (t-SNE) is a well-known algorithm for visualizing high-dimensional data by finding low-dimensional representations. In this paper, we study the convergence of t-SNE with generalized kernels and extend the results of Auffinger and Fletcher in 2023. Our work starts by giving a concrete formulation of generalized input and output kernels. Then we prove that under certain conditions, the t-SNE algorithm converges to an equilibrium distribution for a wide range of input and output kernels as the number of data points diverges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24311v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yi Gu</dc:creator>
    </item>
    <item>
      <title>Density Ratio Permutation Tests with connections to distributional shifts and conditional two-sample testing</title>
      <link>https://arxiv.org/abs/2505.24529</link>
      <description>arXiv:2505.24529v1 Announce Type: cross 
Abstract: We introduce novel hypothesis tests to allow for statistical inference for density ratios. More precisely, we introduce the Density Ratio Permutation Test (DRPT) for testing $H_0: g \propto r f$ based on independent data drawn from distributions with densities $f$ and $g$, where the hypothesised density ratio $r$ is a fixed function. The proposed test employs an efficient Markov Chain Monte Carlo algorithm to draw permutations of the combined dataset according to a distribution determined by $r$, producing exchangeable versions of the whole sample and thereby establishing finite-sample validity. Regarding the test's behaviour under the alternative hypothesis, we begin by demonstrating that if the test statistic is chosen as an Integral Probability Metric (IPM), the DRPT is consistent under mild assumptions on the function class that defines the IPM. We then narrow our focus to the setting where the function class is a Reproducing Kernel Hilbert Space, and introduce a generalisation of the classical Maximum Mean Discrepancy (MMD), which we term Shifted-MMD. For continuous data, assuming that a normalised version of $g - rf$ lies in a Sobolev ball, we establish the minimax optimality of the DRPT based on the Shifted-MMD. We further extend our approach to scenarios with an unknown shift factor $r$, estimating it from part of the data using Density Ratio Estimation techniques, and derive Type-I error bounds based on estimation error. Additionally, we demonstrate how the DRPT can be adapted for conditional two-sample testing, establishing it as a versatile tool for assessing modelling assumptions on importance weights, covariate shifts and related scenarios, which frequently arise in contexts such as transfer learning and causal inference. Finally, we validate our theoretical findings through experiments on both simulated and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24529v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Bordino, Thomas B. Berrett</dc:creator>
    </item>
    <item>
      <title>Sample-optimal learning of quantum states using gentle measurements</title>
      <link>https://arxiv.org/abs/2505.24587</link>
      <description>arXiv:2505.24587v1 Announce Type: cross 
Abstract: Gentle measurements of quantum states do not entirely collapse the initial state. Instead, they provide a post-measurement state at a prescribed trace distance $\alpha$ from the initial state together with a random variable used for quantum learning of the initial state. We introduce here the class of $\alpha-$locally-gentle measurements ($\alpha-$LGM) on a finite dimensional quantum system which are product measurements on product states and prove a strong quantum Data-Processing Inequality (qDPI) on this class using an improved relation between gentleness and quantum differential privacy. We further show a gentle quantum Neyman-Pearson lemma which implies that our qDPI is asymptotically optimal (for small $\alpha$). This inequality is employed to show that the necessary number of quantum states for prescribed accuracy $\epsilon$ is of order $1/(\epsilon^2 \alpha^2)$ for both quantum tomography and quantum state certification. Finally, we propose an $\alpha-$LGM called quantum Label Switch that attains these bounds. It is a general implementable method to turn any two-outcome measurement into an $\alpha-$LGM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24587v1</guid>
      <category>quant-ph</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristina Butucea, Jan Johannes, Henning Stein</dc:creator>
    </item>
    <item>
      <title>Generalization Dynamics of Linear Diffusion Models</title>
      <link>https://arxiv.org/abs/2505.24769</link>
      <description>arXiv:2505.24769v1 Announce Type: cross 
Abstract: Diffusion models trained on finite datasets with $N$ samples from a target distribution exhibit a transition from memorisation, where the model reproduces training examples, to generalisation, where it produces novel samples that reflect the underlying data distribution. Understanding this transition is key to characterising the sample efficiency and reliability of generative models, but our theoretical understanding of this transition is incomplete. Here, we analytically study the memorisation-to-generalisation transition in a simple model using linear denoisers, which allow explicit computation of test errors, sampling distributions, and Kullback-Leibler divergences between samples and target distribution. Using these measures, we predict that this transition occurs roughly when $N \asymp d$, the dimension of the inputs. When $N$ is smaller than the dimension of the inputs $d$, so that only a fraction of relevant directions of variation are present in the training data, we demonstrate how both regularization and early stopping help to prevent overfitting. For $N &gt; d$, we find that the sampling distributions of linear diffusion models approach their optimum (measured by the Kullback-Leibler divergence) linearly with $d/N$, independent of the specifics of the data distribution. Our work clarifies how sample complexity governs generalisation in a simple model of diffusion-based generative models and provides insight into the training dynamics of linear denoisers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24769v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudia Merger, Sebastian Goldt</dc:creator>
    </item>
    <item>
      <title>Algorithms for mean-field variational inference via polyhedral optimization in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2312.02849</link>
      <description>arXiv:2312.02849v4 Announce Type: replace 
Abstract: We develop a theory of finite-dimensional polyhedral subsets over the Wasserstein space and optimization of functionals over them via first-order methods. Our main application is to the problem of mean-field variational inference, which seeks to approximate a distribution $\pi$ over $\mathbb{R}^d$ by a product measure $\pi^\star$. When $\pi$ is strongly log-concave and log-smooth, we provide (1) approximation rates certifying that $\pi^\star$ is close to the minimizer $\pi^\star_\diamond$ of the KL divergence over a \emph{polyhedral} set $\mathcal{P}_\diamond$, and (2) an algorithm for minimizing $\text{KL}(\cdot\|\pi)$ over $\mathcal{P}_\diamond$ based on accelerated gradient descent over $\R^d$. As a byproduct of our analysis, we obtain the first end-to-end analysis for gradient-based algorithms for MFVI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02849v4</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiheng Jiang, Sinho Chewi, Aram-Alexandre Pooladian</dc:creator>
    </item>
    <item>
      <title>Nested Nonparametric Instrumental Variable Regression</title>
      <link>https://arxiv.org/abs/2112.14249</link>
      <description>arXiv:2112.14249v4 Announce Type: replace-cross 
Abstract: Several causal parameters in short panel data models are functionals of a nested nonparametric instrumental variable regression (nested NPIV). Recent examples include mediated, time varying, and long term treatment effects identified using proxy variables. In econometrics, examples arise in triangular simultaneous equations and hedonic price systems. However, it appears that explicit mean square convergence rates for nested NPIV are unknown, preventing inference on some of these parameters with generic machine learning. A major challenge is compounding ill posedness due to the nested inverse problems. To limit how ill posedness compounds, we introduce two techniques: relative well posedness, and multiple robustness to ill posedness. With these techniques, we provide explicit mean square rates for nested NPIV and efficient inference for recently identified causal parameters. Our nonasymptotic analysis accommodates neural networks, random forests, and reproducing kernel Hilbert spaces. It extends to causal functions, e.g. heterogeneous long term treatment effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.14249v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isaac Meza, Rahul Singh</dc:creator>
    </item>
    <item>
      <title>Efficient Sampling for Realized Variance Estimation in Time-Changed Diffusion Models</title>
      <link>https://arxiv.org/abs/2212.11833</link>
      <description>arXiv:2212.11833v3 Announce Type: replace-cross 
Abstract: This paper analyzes the benefits of sampling intraday returns in intrinsic time for the realized variance (RV) estimator. We theoretically show in finite samples that depending on the permitted sampling information, the RV estimator is most efficient under either hitting time sampling that samples whenever the price changes by a pre-determined threshold, or under the new concept of realized business time that samples according to a combination of observed trades and estimated tick variance. The analysis builds on the assumption that asset prices follow a diffusion that is time-changed with a jump process that separately models the transaction times. This provides a flexible model that allows for leverage specifications and Hawkes-type jump processes and separately captures the empirically varying trading intensity and tick variance processes, which are particularly relevant for disentangling the driving forces of the sampling schemes. Extensive simulations confirm our theoretical results and show that for low levels of noise, hitting time sampling remains superior while for increasing noise levels, realized business time becomes the empirically most efficient sampling scheme. An application to stock data provides empirical evidence for the benefits of using these intrinsic sampling schemes to construct more efficient RV estimators as well as for an improved forecast performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11833v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>q-fin.RM</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Dimitriadis, Roxana Halbleib, Jeannine Polivka, Jasper Rennspies, Sina Streicher, Axel Friedrich Wolter</dc:creator>
    </item>
    <item>
      <title>Perturbation-based Effect Measures for Compositional Data</title>
      <link>https://arxiv.org/abs/2311.18501</link>
      <description>arXiv:2311.18501v5 Announce Type: replace-cross 
Abstract: Existing effect measures for compositional features are inadequate for many modern applications, for example, in microbiome research, since they display traits such as high-dimensionality and sparsity that can be poorly modelled with traditional parametric approaches. Further, assessing -- in an unbiased way -- how summary statistics of a composition (e.g., racial diversity) affect a response variable is not straightforward. We propose a framework based on hypothetical data perturbations which defines interpretable statistical functionals on the compositions themselves, which we call average perturbation effects. These effects naturally account for confounding that biases frequently used marginal dependence analyses. We show how average perturbation effects can be estimated efficiently by deriving a perturbation-dependent reparametrization and applying semiparametric estimation techniques. We analyze the proposed estimators empirically on simulated and semi-synthetic data and demonstrate advantages over existing techniques on data from New York schools and microbiome data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18501v5</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Rask Lundborg, Niklas Pfister</dc:creator>
    </item>
    <item>
      <title>Least squares for cardinal paired comparisons data</title>
      <link>https://arxiv.org/abs/2401.07018</link>
      <description>arXiv:2401.07018v3 Announce Type: replace-cross 
Abstract: Least square estimators for graphical models for cardinal paired comparison data with and without covariates are rigorously analyzed. Novel, graph--based, necessary and sufficient conditions that guarantee strong consistency, asymptotic normality and the exponential convergence of the estimated ranks are emphasized. A complete theory for models with covariates is laid out. In particular, conditions under which covariates can be safely omitted from the model are provided. The methodology is employed in the analysis of both finite and infinite sets of ranked items where the case of large sparse comparison graphs is addressed. The proposed methods are explored by simulation and applied to the ranking of teams in the National Basketball Association (NBA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07018v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahul Singh, George Iliopoulos, Ori Davidov</dc:creator>
    </item>
    <item>
      <title>Functional weak convergence of stochastic integrals for moving averages and continuous-time random walks</title>
      <link>https://arxiv.org/abs/2401.13543</link>
      <description>arXiv:2401.13543v3 Announce Type: replace-cross 
Abstract: There is an extensive theory of weak convergence for moving averages and continuous-time random walks (CTRWs) with respect to Skorokhod's M1 and J1 topologies. Here we address the fundamental question of how this translates into functional limit theorems in the M1 or J1 topology for stochastic integrals driven by these processes. As an important application, we provide weak approximation results for general SDEs driven by time-changed L\'evy processes. Such SDEs and their associated fractional Fokker--Planck--Kolmogorov equations are central to models of anomalous diffusion in statistical physics. Our results yield a rigorous functional characterisation of these as continuum limits of the underlying models driven by CTRWs. With regard to strictly M1 convergent moving averages and correlated CTRWs, it turns out that the convergence of stochastic integrals can fail decidedly and fundamental new challenges arise compared to the J1 setting. Nevertheless, we identify natural classes of integrand processes for which there is M1 convergence of the stochastic integrals. We also show that these results are flexible enough to yield functional limit theorems in the M1 topology for certain stochastic delay differential equations driven by moving averages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13543v3</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas S{\o}jmark, Fabrice Wunderlich</dc:creator>
    </item>
    <item>
      <title>Robust random graph matching in Gaussian models via vector approximate message passing</title>
      <link>https://arxiv.org/abs/2412.16457</link>
      <description>arXiv:2412.16457v2 Announce Type: replace-cross 
Abstract: In this paper, we focus on the matching recovery problem between a pair of correlated Gaussian Wigner matrices with a latent vertex correspondence. We are particularly interested in a robust version of this problem such that our observation is a perturbed input $(A+E,B+F)$ where $(A,B)$ is a pair of correlated Gaussian Wigner matrices and $E,F$ are adversarially chosen matrices supported on an unknown $\epsilon n * \epsilon n$ principle minor of $A,B$, respectively. We propose a vector approximate message passing (vector AMP) algorithm that succeeds in polynomial time as long as the correlation $\rho$ between $(A,B)$ is a non-vanishing constant and $\epsilon = o\big( \tfrac{1}{(\log n)^{20}} \big)$.
  The main methodological inputs for our result are the iterative random graph matching algorithm proposed in \cite{DL22+, DL23+} and the spectral cleaning procedure proposed in \cite{IS24+}. To the best of our knowledge, our algorithm is the first efficient random graph matching type algorithm that is robust under any adversarial perturbations of $n^{1-o(1)}$ size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16457v2</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Supervised Quadratic Feature Analysis: Information Geometry Approach for Dimensionality Reduction</title>
      <link>https://arxiv.org/abs/2502.00168</link>
      <description>arXiv:2502.00168v3 Announce Type: replace-cross 
Abstract: Supervised dimensionality reduction aims to map labeled data to a low-dimensional feature space while maximizing class discriminability. Directly computing discriminability is often impractical, so an alternative approach is to learn features that maximize a distance or dissimilarity measure between classes. The Fisher-Rao distance is an important information geometry distance in statistical manifolds. It is induced by the Fisher information metric, a tool widely used for understanding neural representations. Despite its theoretical and pratical appeal, Fisher-Rao distances between classes have not been used as a maximization objective in supervised feature learning. Here, we present Supervised Quadratic Feature Analysis (SQFA), a linear dimensionality reduction method that maximizes Fisher-Rao distances between class distributions, by exploiting the information geometry of the symmetric positive definite manifold. SQFA maximizes distances using first- and second-order statistics, and its features allow for quadratic discriminability (i.e. QDA performance) matching or surpassing state-of-the-art methods on real-world datasets. We theoretically motivate Fisher-Rao distances as a proxy for quadratic discriminability, and compare its performance to other popular distances (e.g. Wasserstein distances). SQFA provides a flexible state-of-the-art method for dimensionality reduction. Its successful use of Fisher-Rao distances between classes motivates future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00168v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Herrera-Esposito, Johannes Burge</dc:creator>
    </item>
    <item>
      <title>Estimating Time Delays between Signals under Mixed Noise Influence with Novel Cross- and Bispectral Methods</title>
      <link>https://arxiv.org/abs/2502.17474</link>
      <description>arXiv:2502.17474v2 Announce Type: replace-cross 
Abstract: A common problem to signal processing are biases introduced by correlated noise. When quantifying time delays between two signals, mixed noise introduces a bias towards zero delay in conventional delay estimates based on the cross- or bispectrum. Here we propose two novel time delay estimators that address these shortcomings: (1) A cross-spectrum based approach that relies on estimating the periodicity of the phase spectrum rather than its slope, and (2) a bispectrum based approach, bispectral antisymmetrization, which removes contributions from not just Gaussian but all independent sources. In a simulation study, we compare conventional and novel TDE approaches and resolve differences in performance with respect to noise Gaussianity and auto-correlation structure. As a proof-of concept, we also perform TDE analysis on a neural stimulation dataset (n=3). We find that antisymmetrization consistently outperforms conventional bispectral methods at low signal-to-noise ratios (SNR) and prevents spurious zero-delay estimates in all mixed-noise environments. Time delay estimation based on phase periodicity also improves signal sensitivity compared to conventional cross-spectral methods. These observations are stable with respect to the magnitude of the delay and the statistical properties of the noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17474v2</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tin Jurhar, Franziska Pellegrini, Ana I. Nu\~nes del Toro, Tilman Stephani, Guido Nolte, Stefan Haufe</dc:creator>
    </item>
    <item>
      <title>Graphical Models and Efficient Inference Methods for Multivariate Phase Probability Distributions</title>
      <link>https://arxiv.org/abs/2504.00459</link>
      <description>arXiv:2504.00459v2 Announce Type: replace-cross 
Abstract: Multivariate phase relationships are important to characterize and understand numerous physical, biological, and chemical systems, from electromagnetic waves to neural oscillations. These systems exhibit complex spatiotemporal dynamics and intricate interdependencies among their constituent elements. While classical models of multivariate phase relationships, such as the wave equation and Kuramoto model, give theoretical models to describe phenomena, the development of statistical tools for hypothesis testing and inference for multivariate phase relationships in complex systems remains limited. This paper introduces a novel probabilistic modeling framework to characterize multivariate phase relationships, with wave-like phenomena serving as a key example. This approach describes spatial patterns and interactions between oscillators through a pairwise exponential family distribution. Building upon the literature of graphical model inference, including methods like Ising models, graphical lasso, and interaction screening, this work bridges the gap between classical wave dynamics and modern statistical approaches. Efficient inference methods are introduced, leveraging the Chow-Liu algorithm for directed tree approximations and interaction screening for general graphical models. Simulated experiments demonstrate the utility of these methods for uncovering wave properties and sparse interaction structures, highlighting their applicability to diverse scientific domains. This framework establishes a new paradigm for statistical modeling of multivariate phase relationships, providing a powerful toolset for exploring the complexity of these systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00459v2</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew S. Perley, Todd P. Coleman</dc:creator>
    </item>
  </channel>
</rss>
