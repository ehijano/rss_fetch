<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Jun 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Lower Bound on Swap Regret in Extensive-Form Games</title>
      <link>https://arxiv.org/abs/2406.13116</link>
      <description>arXiv:2406.13116v1 Announce Type: new 
Abstract: Recent simultaneous works by Peng and Rubinstein [2024] and Dagan et al. [2024] have demonstrated the existence of a no-swap-regret learning algorithm that can reach $\epsilon$ average swap regret against an adversary in any extensive-form game within $m^{\tilde{\mathcal O}(1/\epsilon)}$ rounds, where $m$ is the number of nodes in the game tree. However, the question of whether a $\mathrm{poly}(m, 1/\epsilon)$-round algorithm could exist remained open. In this paper, we show a lower bound that precludes the existence of such an algorithm. In particular, we show that achieving average swap regret $\epsilon$ against an oblivious adversary in general extensive-form games requires at least $\mathrm{exp}\left(\Omega\left(\min\left\{m^{1/14}, \epsilon^{-1/6}\right\}\right)\right)$ rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13116v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantinos Daskalakis, Gabriele Farina, Noah Golowich, Tuomas Sandholm, Brian Hu Zhang</dc:creator>
    </item>
    <item>
      <title>Submodular Participatory Budgeting</title>
      <link>https://arxiv.org/abs/2406.13586</link>
      <description>arXiv:2406.13586v1 Announce Type: new 
Abstract: Participatory budgeting refers to the practice of allocating public resources by collecting and aggregating individual preferences. Most existing studies in this field often assume an additive utility function, where each individual holds a private utility for each candidate project, and the total utility of a set of funded projects is simply the sum of the utilities of all projects. We argue that this assumption does not always hold in reality. For example, building two playgrounds in the same neighborhood does not necessarily lead to twice the utility of building a single playground.
  To address this, we extend the existing study by proposing a submodular participatory budgeting problem, assuming that the utility function of each individual is a monotone and submodular function over funded projects. We propose and examine three preference elicitation methods, including \emph{ranking-by-marginal-values}, \emph{ranking-by-values} and \emph{threshold approval votes}, and analyze their performances in terms of distortion. Notably, if the utility function is addicative, our aggregation rule designed for threshold approval votes achieves a better distortion than the state-of-the-art approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13586v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing Yuan, Shaojie Tang</dc:creator>
    </item>
    <item>
      <title>Symmetrically Fair Allocations of Indivisible Goods</title>
      <link>https://arxiv.org/abs/2406.13824</link>
      <description>arXiv:2406.13824v1 Announce Type: new 
Abstract: We consider allocating indivisible goods with provable fairness guarantees that are satisfied regardless of which bundle of items each agent receives. Symmetrical allocations of this type are known to exist for divisible resources, such as consensus splitting of a cake into parts, each having equal value for all agents, ensuring that in any allocation of the cake slices, no agent would envy another. For indivisible goods, one analogous concept relaxes envy freeness to guarantee the existence of an allocation in which any bundle is worth as much as any other, up to the value of a bounded number of items from the other bundle. Previous work has studied the number of items that need to be removed. In this paper, we improve upon these bounds for the specific setting in which the number of bundles equals the number of agents.
  Concretely, we develop the theory of symmetrically envy free up to one good, or symEF1, allocations. We prove that a symEF1 allocation exists if the vertices of a related graph can be partitioned (colored) into as many independent sets as there are agents. This sufficient condition always holds for two agents, and for agents that have identical, disjoint, or binary valuations. We further prove conditions under which exponentially-many distinct symEF1 allocations exist. Finally, we perform computational experiments to study the incidence of symEF1 allocations as a function of the number of agents and items when valuations are drawn uniformly at random.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13824v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Connor Johnston, Aleksandr M. Kazachkov</dc:creator>
    </item>
    <item>
      <title>Bundling in Oligopoly: Revenue Maximization with Single-Item Competitors</title>
      <link>https://arxiv.org/abs/2406.13835</link>
      <description>arXiv:2406.13835v1 Announce Type: new 
Abstract: We consider a principal seller with $m$ heterogeneous products to sell to an additive buyer over independent items. The principal can offer an arbitrary menu of product bundles, but faces competition from smaller and more agile single-item sellers. The single-item sellers choose their prices after the principal commits to a menu, potentially under-cutting the principal's offerings. We explore to what extent the principal can leverage the ability to bundle product together to extract revenue.
  Any choice of menu by the principal induces an oligopoly pricing game between the single-item sellers, which may have multiple equilibria. When there is only a single item this model reduces to Bertrand competition, for which the principal's revenue is $0$ at any equilibrium, so we assume that no single item's value is too dominant. We establish an upper bound on the principal's optimal revenue at every equilibrium: the expected welfare after truncating each item's value to its revenue-maximizing price. Under a technical condition on the value distributions -- that the monopolist's revenue is sufficiently sensitive to price -- we show that the principal seller can simply price the grand-bundle and ensure (in any equilibrium) a constant approximation to this bound (and hence to the optimal revenue). We also show that for some value distributions violating our conditions, grand-bundle pricing does not yield a constant approximation to the optimal revenue in any equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13835v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moshe Babaioff, Linda Cai, Brendan Lucier</dc:creator>
    </item>
    <item>
      <title>Planning Against a Prophet: A Graph-Theoretic Framework for Making Sequential Decisions</title>
      <link>https://arxiv.org/abs/2406.13911</link>
      <description>arXiv:2406.13911v1 Announce Type: new 
Abstract: We devise a general graph-theoretic framework for studying prophet inequalities. In this framework, an agent traverses a directed acyclic graph from a starting node $s$ to a target node $t$. Each edge has a value that is sampled from a known distribution. When the agent reaches a node $v$ it observes the realized values of all the outgoing edges from $v$. The agent's objective is to maximize the expected total value of the path it takes. As in prophet inequalities, we compare the agent's performance against a prophet who observes all the realizations of the edges' values ahead of time. Our analysis reveals that this ratio highly depends on the number of paths $k$ required to cover all the nodes in the graph. In particular, we provide an algorithm that guarantees a prophet inequality ratio of $\frac{1}{2k}$ and show an upper bound of $\frac{1}{k+1}$.
  Our framework captures planning problems in which there is uncertainty regarding the costs/benefits of each action. In particular, it captures an over-time variant of the classic prophet inequality in which a seller leases a durable item, such as an apartment, for $n$ time units. Each period a lessee appears and may have a different value for each lease term. We obtain a tight bound of $1/2$ for this variant. To make this framework even more expressive, we further generalize it to accommodate correlations between edges originating from the same node and allow for additional constraints on the edges the agent can take. The generalized framework captures many well-studied prophet inequality problems, including $d$-dimensional matching, $k$-prophet inequality, and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13911v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'es Cristi, Sigal Oren</dc:creator>
    </item>
    <item>
      <title>Tracking solutions of time-varying variational inequalities</title>
      <link>https://arxiv.org/abs/2406.14059</link>
      <description>arXiv:2406.14059v1 Announce Type: new 
Abstract: Tracking the solution of time-varying variational inequalities is an important problem with applications in game theory, optimization, and machine learning. Existing work considers time-varying games or time-varying optimization problems. For strongly convex optimization problems or strongly monotone games, these results provide tracking guarantees under the assumption that the variation of the time-varying problem is restrained, that is, problems with a sublinear solution path.  In this work we extend existing results in two ways:  In our first result, we provide tracking bounds for (1) variational inequalities with a sublinear solution path but not necessarily monotone functions, and (2) for periodic time-varying variational inequalities that do not necessarily have a sublinear solution path-length. Our second main contribution is an extensive study of the convergence behavior and trajectory of discrete dynamical systems of periodic time-varying VI. We show that these systems can exhibit provably chaotic behavior or can converge to the solution. Finally, we illustrate our theoretical results with experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14059v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H\'edi Hadiji (UvA), Sarah Sachs (UvA), Crist\'obal Guzm\'an (UC)</dc:creator>
    </item>
    <item>
      <title>Tractable Equilibrium Computation in Markov Games through Risk Aversion</title>
      <link>https://arxiv.org/abs/2406.14156</link>
      <description>arXiv:2406.14156v1 Announce Type: new 
Abstract: A significant roadblock to the development of principled multi-agent reinforcement learning is the fact that desired solution concepts like Nash equilibria may be intractable to compute. To overcome this obstacle, we take inspiration from behavioral economics and show that -- by imbuing agents with important features of human decision-making like risk aversion and bounded rationality -- a class of risk-averse quantal response equilibria (RQE) become tractable to compute in all $n$-player matrix and finite-horizon Markov games. In particular, we show that they emerge as the endpoint of no-regret learning in suitably adjusted versions of the games. Crucially, the class of computationally tractable RQE is independent of the underlying game structure and only depends on agents' degree of risk-aversion and bounded rationality. To validate the richness of this class of solution concepts we show that it captures peoples' patterns of play in a number of 2-player matrix games previously studied in experimental economics. Furthermore, we give a first analysis of the sample complexity of computing these equilibria in finite-horizon Markov games when one has access to a generative model and validate our findings on a simple multi-agent reinforcement learning benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14156v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Eric Mazumdar, Kishan Panaganti, Laixi Shi</dc:creator>
    </item>
    <item>
      <title>Mechanism design augmented with output advice</title>
      <link>https://arxiv.org/abs/2406.14165</link>
      <description>arXiv:2406.14165v1 Announce Type: new 
Abstract: Our work revisits the design of mechanisms via the learning-augmented framework. In this model, the algorithm is enhanced with imperfect (machine-learned) information concerning the input, usually referred to as prediction. The goal is to design algorithms whose performance degrades gently as a function of the prediction error and, in particular, perform well if the prediction is accurate, but also provide a worst-case guarantee under any possible error. This framework has been successfully applied recently to various mechanism design settings, where in most cases the mechanism is provided with a prediction about the types of the players.
  We adopt a perspective in which the mechanism is provided with an output recommendation. We make no assumptions about the quality of the suggested outcome, and the goal is to use the recommendation to design mechanisms with low approximation guarantees whenever the recommended outcome is reasonable, but at the same time to provide worst-case guarantees whenever the recommendation significantly deviates from the optimal one. We propose a generic, universal measure, which we call quality of recommendation, to evaluate mechanisms across various information settings. We demonstrate how this new metric can provide refined analysis in existing results.
  This model introduces new challenges, as the mechanism receives limited information comparing to settings that use predictions about the types of the agents. We study, through this lens, several well-studied mechanism design paradigms, devising new mechanisms, but also providing refined analysis for existing ones, using as a metric the quality of recommendation. We complement our positive results, by exploring the limitations of known classes of strategyproof mechanisms that can be devised using output recommendation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14165v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Christodoulou, Alkmini Sgouritsa, Ioannis Vlachos</dc:creator>
    </item>
    <item>
      <title>Strategy-proof Selling: a Geometric Approach</title>
      <link>https://arxiv.org/abs/2406.12279</link>
      <description>arXiv:2406.12279v1 Announce Type: cross 
Abstract: We consider one buyer and one seller. For a bundle $(t,q)\in [0,\infty[\times [0,1]=\mathbb{Z}$, $q$ either refers to the wining probability of an object or a share of a good, and $t$ denotes the payment that the buyer makes. We define classical and restricted classical preferences of the buyer on $\mathbb{Z}$; they incorporate quasilinear, non-quasilinear, risk averse preferences with multidimensional pay-off relevant parameters. We define rich single-crossing subsets of the two classes, and characterize strategy-proof mechanisms by using monotonicity of the mechanisms and continuity of the indirect preference correspondences. We also provide a computationally tractable optimization program to compute the optimal mechanism. We do not use revenue equivalence and virtual valuations as tools in our proofs. Our proof techniques bring out the geometric interaction between the single-crossing property and the positions of bundles $(t,q)$s. Our proofs are simple and provide computationally tractable optimization program to compute the optimal mechanism. The extension of the optimization program to the $n-$ buyer environment is immediate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12279v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mridu Prabal Goswami</dc:creator>
    </item>
    <item>
      <title>The Surprising Benefits of Base Rate Neglect in Robust Aggregation</title>
      <link>https://arxiv.org/abs/2406.13490</link>
      <description>arXiv:2406.13490v1 Announce Type: cross 
Abstract: Robust aggregation integrates predictions from multiple experts without knowledge of the experts' information structures. Prior work assumes experts are Bayesian, providing predictions as perfect posteriors based on their signals. However, real-world experts often deviate systematically from Bayesian reasoning. Our work considers experts who tend to ignore the base rate. We find that a certain degree of base rate neglect helps with robust forecast aggregation.
  Specifically, we consider a forecast aggregation problem with two experts who each predict a binary world state after observing private signals. Unlike previous work, we model experts exhibiting base rate neglect, where they incorporate the base rate information to degree $\lambda\in[0,1]$, with $\lambda=0$ indicating complete ignorance and $\lambda=1$ perfect Bayesian updating. To evaluate aggregators' performance, we adopt Arieli et al. (2018)'s worst-case regret model, which measures the maximum regret across the set of considered information structures compared to an omniscient benchmark. Our results reveal the surprising V-shape of regret as a function of $\lambda$. That is, predictions with an intermediate incorporating degree of base rate $\lambda&lt;1$ can counter-intuitively lead to lower regret than perfect Bayesian posteriors with $\lambda=1$. We additionally propose a new aggregator with low regret robust to unknown $\lambda$. Finally, we conduct an empirical study to test the base rate neglect model and evaluate the performance of various aggregators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13490v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Kong, Shu Wang, Ying Wang</dc:creator>
    </item>
    <item>
      <title>Nicer Than Humans: How do Large Language Models Behave in the Prisoner's Dilemma?</title>
      <link>https://arxiv.org/abs/2406.13605</link>
      <description>arXiv:2406.13605v1 Announce Type: cross 
Abstract: The behavior of Large Language Models (LLMs) as artificial social agents is largely unexplored, and we still lack extensive evidence of how these agents react to simple social stimuli. Testing the behavior of AI agents in classic Game Theory experiments provides a promising theoretical framework for evaluating the norms and values of these agents in archetypal social situations. In this work, we investigate the cooperative behavior of Llama2 when playing the Iterated Prisoner's Dilemma against random adversaries displaying various levels of hostility. We introduce a systematic methodology to evaluate an LLM's comprehension of the game's rules and its capability to parse historical gameplay logs for decision-making. We conducted simulations of games lasting for 100 rounds, and analyzed the LLM's decisions in terms of dimensions defined in behavioral economics literature. We find that Llama2 tends not to initiate defection but it adopts a cautious approach towards cooperation, sharply shifting towards a behavior that is both forgiving and non-retaliatory only when the opponent reduces its rate of defection below 30%. In comparison to prior research on human participants, Llama2 exhibits a greater inclination towards cooperative behavior. Our systematic approach to the study of LLMs in game theoretical scenarios is a step towards using these simulations to inform practices of LLM auditing and alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13605v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicol\'o Fontana, Francesco Pierri, Luca Maria Aiello</dc:creator>
    </item>
    <item>
      <title>An Algorithm for the Assignment Game Beyond Additive Valuations</title>
      <link>https://arxiv.org/abs/2406.13620</link>
      <description>arXiv:2406.13620v1 Announce Type: cross 
Abstract: The assignment game, introduced by Shapley and Shubik (1971), is a classic model for two-sided matching markets between buyers and sellers. In the original assignment game, it is assumed that payments lead to transferable utility and that buyers have unit-demand valuations for the items being sold. Two important and mostly independent lines of work have studied more general settings with imperfectly transferable utility and gross substitutes valuations. Multiple efficient algorithms have been proposed for computing a competitive equilibrium, the standard solution concept in assignment games, in these two settings. Our main result is an efficient algorithm for computing competitive equilibria in a setting with both imperfectly transferable utility and gross substitutes valuations. Our algorithm combines augmenting path techniques from maximum matching and algorithms for matroid intersection. We also show that, in a mild generalization of our model, computing a competitive equilibrium is NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13620v1</guid>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Balkanski, Christopher En, Yuri Faenza</dc:creator>
    </item>
    <item>
      <title>Nash equilibria of quasisupermodular games</title>
      <link>https://arxiv.org/abs/2406.13783</link>
      <description>arXiv:2406.13783v1 Announce Type: cross 
Abstract: We prove three results on the existence and structure of Nash equilibria for quasisupermodular games. A theorem is purely order-theoretic, and the other two involve topological hypotheses. Our topological results genralize Zhou's theorem (for supermodular games) and Calciano's theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13783v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Yu</dc:creator>
    </item>
    <item>
      <title>Guaranteed shares of benefits and costs</title>
      <link>https://arxiv.org/abs/2406.14198</link>
      <description>arXiv:2406.14198v1 Announce Type: cross 
Abstract: In a general fair division model with transferable utilities we discuss endogenous lower and upper guarantees on individual shares of benefits or costs. Like the more familiar exogenous bounds on individual shares described by an outside option or a stand alone utility, these guarantees depend on my type but not on others' types, only on their number and the range of types. Keeping the range from worst share to best share as narrow as permitted by the physical constraints of the model still leaves a large menu of tight guarantee functions. We describe in detail these design options in several iconic problems where each tight pair of guarantees has a clear normative meaning: the allocation of indivisible goods or costly chores, cost sharing of a public facility and the exploitation of a commons with substitute or complementary inputs. The corresponding benefit or cost functions are all sub- or super-modular, and for this class we characterise the set of minimal upper and maximal lower guarantees in all two agent problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14198v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Bogomolnaia, Herv\'e Moulin</dc:creator>
    </item>
    <item>
      <title>In This Apportionment Lottery, the House Always Wins</title>
      <link>https://arxiv.org/abs/2202.11061</link>
      <description>arXiv:2202.11061v2 Announce Type: replace 
Abstract: Apportionment is the problem of distributing $h$ indivisible seats across states in proportion to the states' populations. In the context of the US House of Representatives, this problem has a rich history and is a prime example of interactions between mathematical analysis and political practice. Grimmett (2004) suggested to apportion seats in a randomized way such that each state receives exactly their proportional share $q_i$ of seats in expectation (ex ante proportionality) and receives either $\lfloor q_i \rfloor$ or $\lceil q_i \rceil$ many seats ex post (quota). However, there is a vast space of randomized apportionment methods satisfying these two axioms, and so we additionally consider prominent axioms from the apportionment literature. Our main result is a randomized method satisfying quota, ex ante proportionality and house monotonicity - a property that prevents paradoxes when the number of seats changes and which we require to hold ex post. This result is based on a generalization of dependent rounding on bipartite graphs, which we call cumulative rounding and which might be of independent interest, as we demonstrate via applications beyond apportionment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.11061v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3490486.3538299</arxiv:DOI>
      <dc:creator>Paul G\"olz, Dominik Peters, Ariel D. Procaccia</dc:creator>
    </item>
    <item>
      <title>On the Uniqueness of Bayesian Coarse Correlated Equilibria in Standard First-Price and All-Pay Auctions</title>
      <link>https://arxiv.org/abs/2401.01185</link>
      <description>arXiv:2401.01185v3 Announce Type: replace 
Abstract: We study the Bayesian coarse correlated equilibrium (BCCE) of continuous and discretised first-price and all-pay auctions under the standard symmetric independent private-values model. Our goal is to determine how the canonical Bayes-Nash equilibrium (BNE) of the auction relates to the outcome when all buyers bid following no-regret algorithms. Numerical experiments show that in two buyer first-price auctions the Wasserstein-$2$ distance of buyers' marginal bid distributions decline as $O(1/n)$ in the discretisation size in instances where the prior distribution is concave, whereas all-pay auctions exhibit similar behaviour without prior dependence. To explain this convergence to a near-equilibrium, we study uniqueness of the BCCE of the continuous auction. Our uniqueness results translate to provable convergence of deterministic self-play to a near equilibrium outcome in these auctions. In the all-pay auction, we show that independent of the prior distribution there is a unique BCCE with symmetric, differentiable, and increasing bidding strategies, which is equivalent to the unique strict BNE. In the first-price auction, we need stronger conditions. Either the prior is strictly concave or the learning algorithm has to be restricted to strictly increasing strategies. Without such strong assumptions, no-regret algorithms can end up in low-price pooling strategies. This is important because it proves that in repeated first-price auctions such as in display ad actions, algorithmic collusion cannot be ruled out without further assumptions even if all bidders rely on no-regret algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01185v3</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mete \c{S}eref Ahunbay, Martin Bichler</dc:creator>
    </item>
    <item>
      <title>Learning to Maximize Gains From Trade in Small Markets</title>
      <link>https://arxiv.org/abs/2401.11596</link>
      <description>arXiv:2401.11596v2 Announce Type: replace 
Abstract: We study the problem of designing a two-sided market (double auction) to maximize the gains from trade (social welfare) under the constraints of (dominant-strategy) incentive compatibility and budget-balance. Our goal is to do so for an unknown distribution from which we are given a polynomial number of samples. Our first result is a general impossibility for the case of correlated distributions of values even between just one seller and two buyers, in contrast to the case of one seller and one buyer (bilateral trade) where this is possible. Our second result is an efficient learning algorithm for one seller and two buyers in the case of independent distributions which is based on a novel algorithm for computing optimal mechanisms for finitely supported and explicitly given independent distributions. Both results rely heavily on characterizations of (dominant-strategy) incentive compatible mechanisms that are strongly budget-balanced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11596v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moshe Babaioff, Amitai Frey, Noam Nisan</dc:creator>
    </item>
    <item>
      <title>Blockchain Bribing Attacks and the Efficacy of Counterincentives</title>
      <link>https://arxiv.org/abs/2402.06352</link>
      <description>arXiv:2402.06352v2 Announce Type: replace 
Abstract: We analyze bribing attacks in Proof-of-Stake distributed ledgers from a game theoretic perspective. In bribing attacks, an adversary offers participants a reward in exchange for instructing them how to behave, with the goal of attacking the protocol's properties. Specifically, our work focuses on adversaries that target blockchain safety. We consider two types of bribing, depending on how the bribes are awarded: i) guided bribing, where the bribe is given as long as the bribed party behaves as instructed; ii) effective bribing, where bribes are conditional on the attack's success, w.r.t. well-defined metrics. We analyze each type of attack in a game theoretic setting and identify relevant equilibria. In guided bribing, we show that the protocol is not an equilibrium and then describe good equilibria, where the attack is unsuccessful, and a negative one, where all parties are bribed such that the attack succeeds. In effective bribing, we show that both the protocol and the "all bribed" setting are equilibria. Using the identified equilibria, we then compute bounds on the Prices of Stability and Anarchy. Our results indicate that additional mitigations are needed for guided bribing, so our analysis concludes with incentive-based mitigation techniques, namely slashing and dilution. Here, we present two positive results, that both render the protocol an equilibrium and achieve maximal welfare for all parties, and a negative result, wherein an attack becomes more plausible if it severely affects the ledger's token's market price.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06352v2</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dimitris Karakostas, Aggelos Kiayias, Thomas Zacharias</dc:creator>
    </item>
    <item>
      <title>Collusion-Resilience in Transaction Fee Mechanism Design</title>
      <link>https://arxiv.org/abs/2402.09321</link>
      <description>arXiv:2402.09321v2 Announce Type: replace 
Abstract: Users bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC'21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum's EIP-1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA'23) considered an alternative notion of collusion-resilience, called c-side-contract-proofness (c-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and c-SCP for any c at least 1. OCA-proofness asserts that the users and a miner should not be able to "steal from the protocol." On the other hand, the c-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).
  Our main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness. This result resolves the main open question in Roughgarden (EC'21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09321v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3670865.3673550</arxiv:DOI>
      <dc:creator>Hao Chung, Tim Roughgarden, Elaine Shi</dc:creator>
    </item>
    <item>
      <title>Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles</title>
      <link>https://arxiv.org/abs/2405.21027</link>
      <description>arXiv:2405.21027v3 Announce Type: replace 
Abstract: A popular approach for solving zero-sum games is to maintain populations of policies to approximate the Nash Equilibrium (NE). Previous studies have shown that Policy Space Response Oracle (PSRO) algorithm is an effective multi-agent reinforcement learning framework for solving such games. However, repeatedly training new policies from scratch to approximate Best Response (BR) to opponents' mixed policies at each iteration is both inefficient and costly. While some PSRO variants initialize a new policy by inheriting from past BR policies, this approach limits the exploration of new policies, especially against challenging opponents. To address this issue, we propose Fusion-PSRO, which employs policy fusion to initialize policies for better approximation to BR. By selecting high-quality base policies from meta-NE, policy fusion fuses the base policies into a new policy through model averaging. This approach allows the initialized policies to incorporate multiple expert policies, making it easier to handle difficult opponents compared to inheriting from past BR policies or initializing from scratch. Moreover, our method only modifies the policy initialization phase, allowing its application to nearly all PSRO variants without additional training overhead. Our experiments on non-transitive matrix games, Leduc Poker, and the more complex Liars Dice demonstrate that Fusion-PSRO enhances the performance of nearly all PSRO variants, achieving lower exploitability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.21027v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiesong Lian, Yucong Huang, Mingzhi Wang, Chengdong Ma, Yixue Hao, Ying Wen, Yaodong Yang</dc:creator>
    </item>
    <item>
      <title>On the Smoothed Complexity of Combinatorial Local Search</title>
      <link>https://arxiv.org/abs/2211.07547</link>
      <description>arXiv:2211.07547v4 Announce Type: replace-cross 
Abstract: We propose a unifying framework for smoothed analysis of combinatorial local optimization problems, and show how a diverse selection of problems within the complexity class PLS can be cast within this model. This abstraction allows us to identify key structural properties, and corresponding parameters, that determine the smoothed running time of local search dynamics. We formalize this via a black-box tool that provides concrete bounds on the expected maximum number of steps needed until local search reaches an exact local optimum. This bound is particularly strong, in the sense that it holds for any starting feasible solution, any choice of pivoting rule, and does not rely on the choice of specific noise distributions that are applied on the input, but it is parameterized by just a global upper bound $\phi$ on the probability density. The power of this tool can be demonstrated by instantiating it for various PLS-hard problems of interest to derive efficient smoothed running times (as a function of $\phi$ and the input size).
  Most notably, we focus on the important local optimization problem of finding pure Nash equilibria in Congestion Games, that has not been studied before from a smoothed analysis perspective. Specifically, we propose novel smoothed analysis models for general and Network Congestion Games, under various representations, including explicit, step-function, and polynomial resource latencies. We study PLS-hard instances of these problems and show that their standard local search algorithms run in polynomial smoothed time.
  Finally, we present further applications of our framework to a wide range of additional combinatorial problems, including local Max-Cut in weighted graphs, the Travelling Salesman problem (TSP) under the $k$-opt local heuristic, and finding pure equilibria in Network Coordination Games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07547v4</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiannis Giannakopoulos, Alexander Grosz, Themistoklis Melissourgos</dc:creator>
    </item>
    <item>
      <title>Multi-Sender Persuasion: A Computational Perspective</title>
      <link>https://arxiv.org/abs/2402.04971</link>
      <description>arXiv:2402.04971v4 Announce Type: replace-cross 
Abstract: We consider the multi-sender persuasion problem: multiple players with informational advantage signal to convince a single self-interested actor to take certain actions. This problem generalizes the seminal Bayesian Persuasion framework and is ubiquitous in computational economics, multi-agent learning, and multi-objective machine learning. The core solution concept here is the Nash equilibrium of senders' signaling policies. Theoretically, we prove that finding an equilibrium in general is PPAD-Hard; in fact, even computing a sender's best response is NP-Hard. Given these intrinsic difficulties, we turn to finding local Nash equilibria. We propose a novel differentiable neural network to approximate this game's non-linear and discontinuous utilities. Complementing this with the extra-gradient algorithm, we discover local equilibria that Pareto dominates full-revelation equilibria and those found by existing neural networks. Broadly, our theoretical and empirical contributions are of interest to a large class of economic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04971v4</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Safwan Hossain, Tonghan Wang, Tao Lin, Yiling Chen, David C. Parkes, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Federated Learning Algorithms without Data Similarity</title>
      <link>https://arxiv.org/abs/2403.02347</link>
      <description>arXiv:2403.02347v2 Announce Type: replace-cross 
Abstract: Data similarity assumptions have traditionally been relied upon to understand the convergence behaviors of federated learning methods. Unfortunately, this approach often demands fine-tuning step sizes based on the level of data similarity. When data similarity is low, these small step sizes result in an unacceptably slow convergence speed for federated methods. In this paper, we present a novel and unified framework for analyzing the convergence of federated learning algorithms without the need for data similarity conditions. Our analysis centers on an inequality that captures the influence of step sizes on algorithmic convergence performance. By applying our theorems to well-known federated algorithms, we derive precise expressions for three widely used step size schedules: fixed, diminishing, and step-decay step sizes, which are independent of data similarity conditions. Finally, we conduct comprehensive evaluations of the performance of these federated learning algorithms, employing the proposed step size strategies to train deep neural network models on benchmark datasets under varying data similarity conditions. Our findings demonstrate significant improvements in convergence speed and overall performance, marking a substantial advancement in federated learning research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02347v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ali Beikmohammadi, Sarit Khirirat, Sindri Magn\'usson</dc:creator>
    </item>
    <item>
      <title>ElicitationGPT: Text Elicitation Mechanisms via Language Models</title>
      <link>https://arxiv.org/abs/2406.09363</link>
      <description>arXiv:2406.09363v2 Announce Type: replace-cross 
Abstract: Scoring rules evaluate probabilistic forecasts of an unknown state against the realized state and are a fundamental building block in the incentivized elicitation of information and the training of machine learning models. This paper develops mechanisms for scoring elicited text against ground truth text using domain-knowledge-free queries to a large language model (specifically ChatGPT) and empirically evaluates their alignment with human preferences. The empirical evaluation is conducted on peer reviews from a peer-grading dataset and in comparison to manual instructor scores for the peer reviews.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09363v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Wu, Jason Hartline</dc:creator>
    </item>
  </channel>
</rss>
