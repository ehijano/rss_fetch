<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 01:52:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Probability Spaces of QuickSort</title>
      <link>https://arxiv.org/abs/2504.04133</link>
      <description>arXiv:2504.04133v1 Announce Type: new 
Abstract: QuickSort and the analysis of its expected run time was presented 1962 in a classical paper by C.A.R Hoare. There the run time analysis hinges on a by now well known recurrence equation for the expected run time, which in turn was justified by referring to ``the law of conditional expectations''. A probability space for the runs of the algorithms was not constructed. Subsequent textbooks treated the recurrence relation as self evident and present it until this day without proof. Here we give an inductive definition of the probability space for the runs of randomized QuickSort and subsequently derive the recurrence equation with a not completely trivial proof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04133v1</guid>
      <category>cs.CC</category>
      <category>math.PR</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George Nadareishvili, Jonas Oberhauser, Wolfgang J. Paul</dc:creator>
    </item>
    <item>
      <title>Meta-Mathematics of Computational Complexity Theory</title>
      <link>https://arxiv.org/abs/2504.04416</link>
      <description>arXiv:2504.04416v1 Announce Type: new 
Abstract: We survey results on the formalization and independence of mathematical statements related to major open problems in computational complexity theory. Our primary focus is on recent findings concerning the (un)provability of complexity bounds within theories of bounded arithmetic. This includes the techniques employed and related open problems, such as the (non)existence of a feasible proof that P = NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04416v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726856.3726862</arxiv:DOI>
      <dc:creator>Igor C. Oliveira</dc:creator>
    </item>
    <item>
      <title>Ineffectiveness for Search and Undecidability of PCSP Meta-Problems</title>
      <link>https://arxiv.org/abs/2504.04639</link>
      <description>arXiv:2504.04639v1 Announce Type: new 
Abstract: It is an open question whether the search and decision versions of promise CSPs are equivalent. Most known algorithms for PCSPs solve only their \emph{decision} variant, and it is unknown whether they can be adapted to solve \emph{search} as well. The main approaches, called BLP, AIP and BLP+AIP, handle a PCSP by finding a solution to a relaxation of some integer program. We prove that rounding those solutions to a proper search certificate can be as hard as any problem in the class TFNP. In other words, these algorithms are ineffective for search. Building on the algebraic approach to PCSPs, we find sufficient conditions that imply ineffectiveness for search. Our tools are tailored to algorithms that are characterized by minions in a suitable way, and can also be used to prove undecidability results for meta-problems. This way, we show that the families of templates solvable via BLP, AIP, and BLP+AIP are undecidable.
  Using the same techniques we also analyze several algebraic conditions that are known to guarantee the tractability of finite-template CSPs. We prove that several meta-problems related to cyclic polymorphims and WNUs are undecidable for PCSPs. In particular, there is no algorithm deciding whether a finite PCSP template (1) admits cyclic a polymorphism, (2) admits a WNU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04639v1</guid>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Larrauri</dc:creator>
    </item>
    <item>
      <title>Finding large $k$-colorable induced subgraphs in (bull, chair)-free and (bull,E)-free graphs</title>
      <link>https://arxiv.org/abs/2504.04984</link>
      <description>arXiv:2504.04984v1 Announce Type: new 
Abstract: We study the Max Partial $k$-Coloring problem, where we are given a vertex-weighted graph, and we ask for a maximum-weight induced subgraph that admits a proper $k$-coloring. For $k=1$ this problem coincides with Maximum Weight Independent Set, and for $k=2$ the problem is equivalent (by complementation) to Minimum Odd Cycle Transversal. Furthermore, it generalizes $k$-Coloring. We show that Max Partial $k$-Coloring on $n$-vertex instances with clique number $\omega$ can be solved in time
  * $n^{\mathcal{O}(k\omega)}$ if the input graph excludes the bull and the chair as an induced subgraph,
  * $n^{\mathcal{O}(k\omega \log n)}$ if the input graph excludes the bull and E as an induced subgraph.
  This implies that $k$-Coloring can be solved in polynomial time in the former class, and in quasipolynomial-time in the latter one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04984v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadzieja Hodur, Monika Pil\'sniak, Magdalena Prorok, Pawe{\l} Rz\k{a}\.zewski</dc:creator>
    </item>
    <item>
      <title>Have Large Language Models Learned to Reason? A Characterization via 3-SAT Phase Transition</title>
      <link>https://arxiv.org/abs/2504.03930</link>
      <description>arXiv:2504.03930v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have been touted as AI models possessing advanced reasoning abilities. In theory, autoregressive LLMs with Chain-of-Thought (CoT) can perform more serial computations to solve complex reasoning tasks. However, recent studies suggest that, despite this capacity, LLMs do not truly learn to reason but instead fit on statistical features. To study the reasoning capabilities in a principled fashion, we adopt a computational theory perspective and propose an experimental protocol centered on 3-SAT -- the prototypical NP-complete problem lying at the core of logical reasoning and constraint satisfaction tasks. Specifically, we examine the phase transitions in random 3-SAT and characterize the reasoning abilities of state-of-the-art LLMs by varying the inherent hardness of the problem instances. By comparing DeepSeek R1 with other LLMs, our findings reveal two key insights (1) LLM accuracy drops significantly on harder instances, suggesting all current models struggle when statistical shortcuts are unavailable (2) Unlike other LLMs, R1 shows signs of having learned the underlying reasoning. Following a principled experimental protocol, our study moves beyond the benchmark-driven evidence often found in LLM reasoning research. Our findings highlight important gaps and suggest clear directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03930v1</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rishi Hazra, Gabriele Venturato, Pedro Zuidberg Dos Martires, Luc De Raedt</dc:creator>
    </item>
    <item>
      <title>Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent</title>
      <link>https://arxiv.org/abs/2504.04702</link>
      <description>arXiv:2504.04702v1 Announce Type: cross 
Abstract: Recent advancements in Transformer-based architectures have led to impressive breakthroughs in natural language processing tasks, with models such as GPT-4, Claude, and Gemini demonstrating human-level reasoning abilities. However, despite their high performance, concerns remain about the inherent limitations of these models, especially when it comes to learning basic logical functions. While complexity-theoretic analyses indicate that Transformers can represent simple logic functions (e.g., $\mathsf{AND}$, $\mathsf{OR}$, and majority gates) by its nature of belonging to the $\mathsf{TC}^0$ class, these results assume ideal parameter settings and do not account for the constraints imposed by gradient descent-based training methods. In this work, we investigate whether Transformers can truly learn simple majority functions when trained using gradient-based methods. We focus on a simplified variant of the Transformer architecture and consider both $n=\mathrm{poly}(d)$ and $n=\exp(\Omega(d))$ number of training samples, where each sample is a $d$-size binary string paired with the output of a basic majority function. Our analysis demonstrates that even after $\mathrm{poly}(d)$ gradient queries, the generalization error of the Transformer model still remains substantially large, growing exponentially with $d$. This work highlights fundamental optimization challenges in training Transformers for the simplest logical reasoning tasks and provides new insights into their theoretical limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04702v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bo Chen, Zhenmei Shi, Zhao Song, Jiahao Zhang</dc:creator>
    </item>
    <item>
      <title>The Complexity of Maximal Common Subsequence Enumeration</title>
      <link>https://arxiv.org/abs/2504.04757</link>
      <description>arXiv:2504.04757v1 Announce Type: cross 
Abstract: Frequent pattern mining is widely used to find ``important'' or ``interesting'' patterns in data. While it is not easy to mathematically define such patterns, maximal frequent patterns are promising candidates, as frequency is a natural indicator of relevance and maximality helps to summarize the output. As such, their mining has been studied on various data types, including itemsets, graphs, and strings. The complexity of mining maximal frequent itemsets and subtrees has been thoroughly investigated (e.g., [Boros et al., 2003], [Uno et al., 2004]) in the literature. On the other hand, while the idea of mining frequent subsequences in sequential data was already introduced in the seminal paper [Agrawal et al., 1995], the complexity of the problem is still open.
  In this paper, we investigate the complexity of the maximal common subsequence enumeration problem, which is both an important special case of maximal frequent subsequence mining and a generalization of the classic longest common subsequence (LCS) problem. We show the hardness of enumerating maximal common subsequences between multiple strings, ruling out the possibility of an \emph{output-polynomial time} enumeration algorithm under $P \neq NP$, that is, an algorithm that runs in time ${\rm poly}(|\mathcal I| + N)$, where $|\mathcal I|$ and $N$ are the size of the input and number of output solutions, respectively. To circumvent this intractability, we also investigate the parameterized complexity of the problem, and show several results when the alphabet size, the number of strings, and the length of a string are taken into account as parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04757v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3725252</arxiv:DOI>
      <dc:creator>Giovanni Buzzega, Alessio Conte, Yasuaki Kobayashi, Kazuhiro Kurita, Giulia Punzi</dc:creator>
    </item>
    <item>
      <title>Nonlocal techniques for the analysis of deep ReLU neural network approximations</title>
      <link>https://arxiv.org/abs/2504.04847</link>
      <description>arXiv:2504.04847v1 Announce Type: cross 
Abstract: Recently, Daubechies, DeVore, Foucart, Hanin, and Petrova introduced a system of piece-wise linear functions, which can be easily reproduced by artificial neural networks with the ReLU activation function and which form a Riesz basis of $L_2([0,1])$. This work was generalized by two of the authors to the multivariate setting. We show that this system serves as a Riesz basis also for Sobolev spaces $W^s([0,1]^d)$ and Barron classes ${\mathbb B}^s([0,1]^d)$ with smoothness $0&lt;s&lt;1$. We apply this fact to re-prove some recent results on the approximation of functions from these classes by deep neural networks. Our proof method avoids using local approximations and allows us to track also the implicit constants as well as to show that we can avoid the curse of dimension. Moreover, we also study how well one can approximate Sobolev and Barron functions by ANNs if only function values are known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04847v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cornelia Schneider, Mario Ullrich, Jan Vybiral</dc:creator>
    </item>
    <item>
      <title>The Minimum Eternal Vertex Cover Problem on a Subclass of Series-Parallel Graphs</title>
      <link>https://arxiv.org/abs/2504.04897</link>
      <description>arXiv:2504.04897v1 Announce Type: cross 
Abstract: Eternal vertex cover is the following two-player game between a defender and an attacker on a graph. Initially, the defender positions k guards on k vertices of the graph; the game then proceeds in turns between the defender and the attacker, with the attacker selecting an edge and the defender responding to the attack by moving some of the guards along the edges, including the attacked one. The defender wins a game on a graph G with k guards if they have a strategy such that, in every round of the game, the vertices occupied by the guards form a vertex cover of G, and the attacker wins otherwise. The eternal vertex cover number of a graph G is the smallest number k of guards allowing the defender to win and Eternal Vertex Cover is the problem of computing the eternal vertex cover number of the given graph.
  We study this problem when restricted to the well-known class of series-parallel graphs. In particular, we prove that Eternal Vertex Cover can be solved in linear time when restricted to melon graphs, a proper subclass of series-parallel graphs. Moreover, we also conjecture that this problem is NP-hard on series-parallel graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04897v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiziana Calamoneri, Federico Cor\`o, Giacomo Paesani</dc:creator>
    </item>
    <item>
      <title>Descriptive Complexity of Sensitivity of Cellular Automata</title>
      <link>https://arxiv.org/abs/2504.05012</link>
      <description>arXiv:2504.05012v1 Announce Type: cross 
Abstract: We study the computational complexity of determining whether a cellular automaton is sensitive to initial conditions. We show that this problem is $\Pi^0_2$-complete in dimension 1 and $\Sigma^0_3$-complete in dimension 2 and higher. This solves a question posed by Sablik and Theyssier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05012v1</guid>
      <category>math.DS</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Favereau, Ville Salo</dc:creator>
    </item>
    <item>
      <title>Distributed Quantum Advantage in Locally Checkable Labeling Problems</title>
      <link>https://arxiv.org/abs/2504.05191</link>
      <description>arXiv:2504.05191v1 Announce Type: cross 
Abstract: In this paper, we present the first known example of a locally checkable labeling problem (LCL) that admits asymptotic distributed quantum advantage in the LOCAL model of distributed computing: our problem can be solved in $O(\log n)$ communication rounds in the quantum-LOCAL model, but it requires $\Omega(\log n \cdot \log^{0.99} \log n)$ communication rounds in the classical randomized-LOCAL model. We also show that distributed quantum advantage cannot be arbitrarily large: if an LCL problem can be solved in $T(n)$ rounds in the quantum-LOCAL model, it can also be solved in $\tilde O(\sqrt{n T(n)})$ rounds in the classical randomized-LOCAL model. In particular, a problem that is strictly global classically is also almost-global in quantum-LOCAL. Our second result also holds for $T(n)$-dependent probability distributions. As a corollary, if there exists a finitely dependent distribution over valid labelings of some LCL problem $\Pi$, then the same problem $\Pi$ can also be solved in $\tilde O(\sqrt{n})$ rounds in the classical randomized-LOCAL and deterministic-LOCAL models. That is, finitely dependent distributions cannot exist for global LCL problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05191v1</guid>
      <category>cs.DC</category>
      <category>cs.CC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alkida Balliu, Filippo Casagrande, Francesco d'Amore, Massimo Equi, Barbara Keller, Henrik Lievonen, Dennis Olivetti, Gustav Schmid, Jukka Suomela</dc:creator>
    </item>
    <item>
      <title>Improved Hardness and Approximations for Cardinality-Based Minimum $s$-$t$ Cuts Problems in Hypergraphs</title>
      <link>https://arxiv.org/abs/2409.07201</link>
      <description>arXiv:2409.07201v3 Announce Type: replace 
Abstract: In hypergraphs, an edge that crosses a cut (i.e., a bipartition of nodes) can be split in several ways, depending on how many nodes are placed on each side of the cut. A cardinality-based splitting function assigns a nonnegative cost of $w_i$ for each cut hyperedge $e$ with exactly $i$ nodes on the side of the cut that contains the minority of nodes from $e$. The cardinality-based minimum $s$-$t$ cut aims to find an $s$-$t$ cut with minimum total cost. We answer a recently posed open question by proving that the problem becomes NP-hard outside the submodular region shown by~\cite{veldt2022hypergraph}. Our result also holds for $r$-uniform hypergraphs with $r \geq 4$. Specifically for $4$-uniform hypergraphs we show that the problem is NP-hard for all $w_2 &gt; 2$, and additionally prove that the No-Even-Split problem is NP-hard. We then turn our attention to approximation strategies and approximation hardness results in the non-submodular case. We design a strategy for projecting non-submodular penalties to the submodular region, which we prove gives the optimal approximation among all such projection strategies. We also show that alternative approaches are unlikely to provide improved guarantees, by showing matching approximation hardness bounds assuming the Unique Games Conjecture and asymptotically tight approximation hardness bounds assuming $\text{P} \neq \text{NP}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07201v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian Adriaens, Vedangi Bengali, Iiro Kumpulainen, Nikolaj Tatti, Nate Veldt</dc:creator>
    </item>
    <item>
      <title>SARRIGUREN: a polynomial-time complete algorithm for random $k$-SAT with relatively dense clauses</title>
      <link>https://arxiv.org/abs/2401.09234</link>
      <description>arXiv:2401.09234v2 Announce Type: replace-cross 
Abstract: SARRIGUREN, a new complete algorithm for SAT based on counting clauses (which is valid also for Unique-SAT and #SAT) is described, analyzed and tested. Although existing complete algorithms for SAT perform slower with clauses with many literals, that is an advantage for SARRIGUREN, because the more literals are in the clauses the bigger is the probability of overlapping among clauses, a property that makes the clause counting process more efficient. Actually, it provides a $O(m^2 \times n/k)$ time complexity for random $k$-SAT instances of $n$ variables and $m$ relatively dense clauses, where that density level is relative to the number of variables $n$, that is, clauses are relatively dense when $k\geq7\sqrt{n}$. Although theoretically there could be worst-cases with exponential complexity, the probability of those cases to happen in random $k$-SAT with relatively dense clauses is practically zero. The algorithm has been empirically tested and that polynomial time complexity maintains also for $k$-SAT instances with less dense clauses ($k\geq5\sqrt{n}$). That density could, for example, be of only 0.049 working with $n=20000$ variables and $k=989$ literals. In addition, they are presented two more complementary algorithms that provide the solutions to $k$-SAT instances and valuable information about number of solutions for each literal. Although this algorithm does not solve the NP=P problem (it is not a polynomial algorithm for 3-SAT), it broads the knowledge about that subject, because $k$-SAT with $k&gt;3$ and dense clauses is not harder than 3-SAT. Moreover, the Python implementation of the algorithms, and all the input datasets and obtained results in the experiments are made available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09234v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alfredo Go\~ni Sarriguren</dc:creator>
    </item>
    <item>
      <title>Commuting Local Hamiltonians Beyond 2D</title>
      <link>https://arxiv.org/abs/2410.10495</link>
      <description>arXiv:2410.10495v4 Announce Type: replace-cross 
Abstract: Commuting local Hamiltonians provide a testing ground for studying many of the most interesting open questions in quantum information theory, including the quantum PCP conjecture and the existence of area laws. Although they are a simplified model of quantum computation, the status of the commuting local Hamiltonian problem remains largely unknown. A number of works have shown that increasingly expressive families of commuting local Hamiltonians admit completely classical verifiers. Despite intense work, the largest class of commuting local Hamiltonians we can place in NP are those on a square lattice, where each lattice site is a qutrit. Even worse, many of the techniques used to analyze these problems rely heavily on the geometry of the square lattice and the properties of the numbers 2 and 3 as local dimensions. In this work, we present a new technique to analyze the complexity of various families of commuting local Hamiltonians: guided reductions. Intuitively, these are a generalization of typical reduction where the prover provides a guide so that the verifier can construct a simpler Hamiltonian. The core of our reduction is a new rounding technique based on a combination of Jordan's Lemma and the Structure Lemma. Our rounding technique is much more flexible than previous work, and allows us to show that a larger family of commuting local Hamiltonians is in NP, albiet with the restriction that all terms are rank-1. Specifically, we prove the following two results:
  1. Commuting local Hamiltonians in 2D that are rank-1 are contained in NP, independent of the qudit dimension. Note that this family of commuting local Hamiltonians has no restriction on the local dimension or the locality.
  2. We prove that rank-1, 3D commuting Hamiltonians with qudits on edges are in NP. To our knowledge this is the first time a family of 3D commuting local Hamiltonians has been contained in NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10495v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Bostanci, Yeongwoo Hwang</dc:creator>
    </item>
    <item>
      <title>Complexity Theory for Quantum Promise Problems</title>
      <link>https://arxiv.org/abs/2411.03716</link>
      <description>arXiv:2411.03716v2 Announce Type: replace-cross 
Abstract: We begin by establishing structural results for several fundamental quantum complexity classes: p/mBQP, p/mQ(C)MA, $\text{p/mQSZK}_{\text{hv}}$, p/mQIP, p/mBQP/qpoly, p/mBQP/poly, and p/mPSPACE. This includes identifying complete problems, as well as proving containment and separation results among these classes. Here, p/mC denotes the corresponding quantum promise complexity class with pure (p) or mixed (m) quantum input states for any classical complexity class C. Surprisingly, our findings uncover relationships that diverge from their classical analogues -- specifically, we show unconditionally that p/mQIP$\neq$p/mPSPACE and p/mBQP/qpoly$\neq$p/mBQP/poly. This starkly contrasts the classical setting, where QIP$=$PSPACE and separations such as BQP/qpoly$\neq$BQP/poly are only known relative to oracles.
  For applications, we address interesting questions in quantum cryptography, quantum property testing, and unitary synthesis using this new framework. In particular, we show the first unconditional secure auxiliary-input quantum commitment with statistical hiding, solving an open question in [Qia24,MNY24], and demonstrate the first pure quantum state property testing problem that only needs exponentially fewer samples and runtime in the interactive model than the single-party model, which is analogous to Chiesa and Gur [CG18] studying interactive mode for distribution testing. Also, our works offer new insights into Impagliazzo's five worlds view. Roughly, by substituting classical complexity classes in Pessiland, Heuristica, and Algorithmica with mBQP and mQCMA or $\text{mQSZK}_\text{hv}$, we establish a natural connection between quantum cryptography and quantum promise complexity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03716v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nai-Hui Chia, Kai-Min Chung, Tzu-Hsiang Huang, Jhih-Wei Shih</dc:creator>
    </item>
    <item>
      <title>High Probability Complexity Bounds of Trust-Region Stochastic Sequential Quadratic Programming with Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2503.19091</link>
      <description>arXiv:2503.19091v2 Announce Type: replace-cross 
Abstract: In this paper, we consider nonlinear optimization problems with a stochastic objective and deterministic equality constraints. We propose a Trust-Region Stochastic Sequential Quadratic Programming (TR-SSQP) method and establish its high-probability iteration complexity bounds for identifying first- and second-order $\epsilon$-stationary points. In our algorithm, we assume that exact objective values, gradients, and Hessians are not directly accessible but can be estimated via zeroth-, first-, and second-order probabilistic oracles. Compared to existing complexity studies of SSQP methods that rely on a zeroth-order oracle with sub-exponential tail noise (i.e., light-tailed) and focus mostly on first-order stationarity, our analysis accommodates irreducible and heavy-tailed noise in the zeroth-order oracle and significantly extends the analysis to second-order stationarity. We show that under heavy-tailed noise conditions, our SSQP method achieves the same high-probability first-order iteration complexity bounds as in the light-tailed noise setting, while further exhibiting promising second-order iteration complexity bounds. Specifically, the method identifies a first-order $\epsilon$-stationary point in $\mathcal{O}(\epsilon^{-2})$ iterations and a second-order $\epsilon$-stationary point in $\mathcal{O}(\epsilon^{-3})$ iterations with high probability, provided that $\epsilon$ is lower bounded by a constant determined by the irreducible noise level in estimation. We validate our theoretical findings and evaluate the practical performance of our method on CUTEst benchmark test set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19091v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Fang, Javad Lavaei, Sen Na</dc:creator>
    </item>
  </channel>
</rss>
