<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 03:30:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multi-Period Martingale Optimal Transport: Classical Theory, Neural Acceleration, and Financial Applications</title>
      <link>https://arxiv.org/abs/2601.05290</link>
      <description>arXiv:2601.05290v1 Announce Type: new 
Abstract: This paper develops a computational framework for Multi-Period Martingale Optimal Transport (MMOT), addressing convergence rates, algorithmic efficiency, and financial calibration. Our contributions include: (1) Theoretical analysis: We establish discrete convergence rates of $O(\sqrt{\Delta t} \log(1/\Delta t))$ via Donsker's principle and linear algorithmic convergence of $(1-\kappa)^{2/3}$; (2) Algorithmic improvements: We introduce incremental updates ($O(M^2)$ complexity) and adaptive sparse grids; (3) Numerical implementation: A hybrid neural-projection solver is proposed, combining transformer-based warm-starting with Newton-Raphson projection. Once trained, the pure neural solver achieves a $1{,}597\times$ online inference speedup ($4.7$s $\to 2.9$ms) suitable for real-time applications, while the hybrid solver ensures martingale constraints to $10^{-6}$ precision. Validated on 12,000 synthetic instances (GBM, Merton, Heston) and 120 real market scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05290v1</guid>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sri Sairam Gautam B</dc:creator>
    </item>
    <item>
      <title>When the Rules Change: Adaptive Signal Extraction via Kalman Filtering and Markov-Switching Regimes</title>
      <link>https://arxiv.org/abs/2601.05716</link>
      <description>arXiv:2601.05716v1 Announce Type: new 
Abstract: Static linear models of order flow assume constant parameters, failing precisely when they are needed most: during periods of market stress and structural change. This paper proposes a dynamic, state-dependent framework for order flow signal extraction that adapts to shifting market conditions in the Korean stock market. Using daily transaction data from 2020--2024 covering 2,439 stocks and 2.79 million stock-day observations, we implement three complementary methodologies: (1) an Adaptive Kalman Filter where measurement noise variance is explicitly coupled to market volatility; (2) a three-state Markov-Switching model identifying Bull, Normal, and Crisis regimes; and (3) an Asymmetric Response Function capturing differential investor reactions to positive versus negative shocks. We find that foreign investor predictive power increases 8.9-fold during crisis periods relative to bull markets ($\beta_{crisis}=0.00204$ vs. $\beta_{bull}=0.00023$), while individual investors exhibit momentum-chasing behavior with 6.3 times stronger response to positive shocks. The integrated ``All-Weather'' strategy provides modest drawdown reduction during extreme market events, though challenges remain in the post-COVID high-rate environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05716v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sungwoo Kang</dc:creator>
    </item>
    <item>
      <title>All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection</title>
      <link>https://arxiv.org/abs/2601.04160</link>
      <description>arXiv:2601.04160v3 Announce Type: replace-cross 
Abstract: We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04160v3</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuechen Jiang, Zhiwei Liu, Yupeng Cao, Yueru He, Ziyang Xu, Chen Xu, Zhiyang Deng, Prayag Tiwari, Xi Chen, Alejandro Lopez-Lira, Jimin Huang, Junichi Tsujii, Sophia Ananiadou</dc:creator>
    </item>
  </channel>
</rss>
