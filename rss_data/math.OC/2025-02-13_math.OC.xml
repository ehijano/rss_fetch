<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Feb 2025 02:47:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Regularization for the Approximation of 2D Set of Points via the Length of the Curve</title>
      <link>https://arxiv.org/abs/2502.07915</link>
      <description>arXiv:2502.07915v1 Announce Type: new 
Abstract: We study the problem of approximation of 2D set of points. Such type of problems always occur in physical experiments, econometrics, data analysis and other areas. The often problems of outliers or spikes usually make researchers to apply regularization techniques, such as Lasso, Ridge or Elastic Net. These approaches always employ penalty coefficient. So the important question of evaluation of the upper bound for the coefficient arises. In the current study we propose a novel way of regularization and derive the upper bound for the used penalty coefficient.
  First the problem in a general form is stated. The solution is sought in the class of piecewise continuously differentiable functions. It is shown that the optimal solution belongs to the class of piecewise linear functions. So the problem of obtaining the piecewise linear approximation that fits 2D set of point the best is stated. We show that the optimal solution is trivial and tends to a line as penalty coefficient tends to infinity. Then the main result is stated and proved. It provides the upper bound for the penalty coefficient prior to which the optimal solution differs from the line more than some pregiven positive number. We also demonstrate the proposed ideas on numerical examples which include comparison with other regularization approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07915v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Majid E. Abbasov, Anna I. Belenok</dc:creator>
    </item>
    <item>
      <title>Sign Operator for Coping with Heavy-Tailed Noise: High Probability Convergence Bounds with Extensions to Distributed Optimization and Comparison Oracle</title>
      <link>https://arxiv.org/abs/2502.07923</link>
      <description>arXiv:2502.07923v1 Announce Type: new 
Abstract: The growing popularity of AI optimization problems involving severely corrupted data has increased the demand for methods capable of handling heavy-tailed noise, i.e., noise with bounded $\kappa$-th moment, $\kappa \in (1,2]$. For the widely used clipping technique, effectiveness heavily depends on the careful tuning of clipping levels throughout training. In this paper, we demonstrate that using only the sign of the input, without introducing additional hyperparameters, is sufficient to cope with heavy-tailed noise effectively. For smooth non-convex functions, we prove that SignSGD achieves optimal sample complexity $\tilde{O}\left(\varepsilon^{-\frac{3\kappa - 2}{\kappa - 1}}\right)$ with high probability for attaining an average gradient norm accuracy of $\varepsilon$. Under the assumption of symmetric noise, we use SignSGD with Majority Voting to extend this bound to the distributed optimization or reduce the sample complexity to $\tilde{O}(\varepsilon^{-4})$ in the case of a single worker with arbitrary parameters. Furthermore, we explore the application of the sign operator in zeroth-order optimization with an oracle that can only compare function values at two different points. We propose a novel method, MajorityVote-CompsSGD, and provide the first-known high-probability bound $\tilde{O}(\varepsilon^{-6})$ for the number of comparisons under symmetric noise assumption. Our theoretical findings are supported by the superior performance of sign-based methods in training Large Language Models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07923v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Kornilov, Philip Zmushko, Andrei Semenov, Alexander Gasnikov, Alexander Beznosikov</dc:creator>
    </item>
    <item>
      <title>Second-Order Time to Collision With Non-Static Acceleration</title>
      <link>https://arxiv.org/abs/2502.08066</link>
      <description>arXiv:2502.08066v1 Announce Type: new 
Abstract: We propose a second-order time to collision (TTC) considering non-static acceleration and turning with realistic assumptions. This is equivalent to considering that the steering wheel is held at a fixed angle with constant pressure on the gas or brake pedal and matches the well-known bicycle model. Past works that use acceleration to compute TTC consider only longitudinally aligned acceleration.
  We additionally develop and present the Second-Order Time-to-Collision Algorithm using Region-based search (STAR) to efficiently compute the proposed second-order TTC and overcome the current limitations of the existing built-in functions. The evaluation of the algorithm in terms of error and computation time is conducted through statistical analysis.
  Through numerical simulations and publicly accessible real-world trajectory datasets, we show that the proposed second-order TTC with non-static acceleration is superior at reflecting accurate collision times, especially when turning is involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08066v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hossein Nick Zinat Matin, Yuneil Yeo, Amelie Ju-Kang Ngo, Antonio R. Paiva, Jean Utke, Maria Laura Delle Monache</dc:creator>
    </item>
    <item>
      <title>Price and Assortment Optimization under the Multinomial Logit Model with Opaque Products</title>
      <link>https://arxiv.org/abs/2502.08124</link>
      <description>arXiv:2502.08124v1 Announce Type: new 
Abstract: An opaque product is a product for which only partial information is disclosed to the buyer at the time of purchase. Opaque products are common in sectors such as travel and online retail, where the car type or product color is hidden in the opaque product. Opaque products enable sellers to target customers who prefer a price discount in exchange for being flexible about the product they receive. In this paper, we integrate opaque products and traditional products together into the multinomial logit (MNL) choice model and study the associated price and assortment optimization problems. For the price optimization problem, we surprisingly show that uniform pricing is optimal which implies it has the same optimal pricing solution and value as the traditional MNL model. While adding an opaque product priced at the revenue-maximizing price may enhance revenue given arbitrary traditional product prices, this advantage disappears when all prices are optimized jointly. For the assortment optimization problem, we show that the revenue-maximizing assortment is nested-by-valuation for uniformly priced products. For non-uniformly priced cases, we propose a natural nested-by-revenue-and-valuation heuristic that performs extremely well in an extensive numerical study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08124v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar El Housni, Adam N. Elmachtoub, Harsh Sheth, Jiaqi Shi</dc:creator>
    </item>
    <item>
      <title>A new method for reducing algebraic programs to polynomial programs</title>
      <link>https://arxiv.org/abs/2502.08210</link>
      <description>arXiv:2502.08210v1 Announce Type: new 
Abstract: We consider a generalization of polynomial programs: algebraic programs, which are optimization or feasibility problems with algebraic objectives or constraints. Algebraic functions are defined as zeros of multivariate polynomials. They are a rich set of functions that includes polynomials themselves, but also ratios and radicals, and finite compositions thereof. When an algebraic program is given in terms of radical expressions, a straightforward way of reformulating into a polynomial program is to introduce a new variable for each distinct radical that appears. Hence, the rich theory and algorithms for polynomial programs, including satisfiability via cylindrical algebraic decomposition, infeasibility certificates via Positivstellensatz theorems, and optimization with sum-of-squares programming directly apply to algebraic programs. We propose a different reformulation, that in many cases introduces significantly fewer new variables, and thus produces polynomial programs that are easier to solve. First, we exhibit an algorithm that finds a defining polynomial of an algebraic function given as a radical expression. As a polynomial does not in general define a unique algebraic function, additional constraints need to be added that isolate the algebraic function from others defined by the same polynomial. Using results from real algebraic geometry, we develop an algorithm that generates polynomial inequalities that isolate an algebraic function. This allows us to reformulate an algebraic program into a polynomial one, by introducing only a single new variable for each algebraic function. On modified versions of classic optimization benchmarks with added algebraic terms, our formulation achieves speedups of up to 50x compared to the straightforward reformulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08210v1</guid>
      <category>math.OC</category>
      <category>cs.SC</category>
      <category>math.AG</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Maaz, Adam W. Strzebo\'nski</dc:creator>
    </item>
    <item>
      <title>Fare Structure Design in Public Transport</title>
      <link>https://arxiv.org/abs/2502.08228</link>
      <description>arXiv:2502.08228v1 Announce Type: new 
Abstract: Fare planning is one among several steps in public transport planning. Fares are relevant for the covering of costs of the public transport operator, but also affect the ridership and the passenger satisfaction. A fare structure is the assignment of prices to all paths in a network. In practice, often a given fare structure shall be changed to fulfill new requirements, meaning that a new fare strategy is desired. This motivates the usage of prices of the former fare structure or other desirable prices as reference prices. In this paper, we investigate the fare structure design problem that aims to determine fares such that the sum of absolute deviations between the new fares and the reference prices is minimized. Fare strategies that are considered here are flat tariffs, affine distance tariffs and zone tariffs. Additionally, we regard constraints that ensure that it is not beneficial to buy a ticket for a longer journey than actually traveled (no-elongation property) or to split a ticket into several sub-tickets to cover a journey (no-stopover property). Our literature review provides an overview of the research on fare planning. We analyze the fare structure design problem for flat, distance and zone tariffs, pointing out connections to median problems. Further, we study its complexity which ranges from linear-time solvability to NP-complete cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08228v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anita Sch\"obel, Reena Urban</dc:creator>
    </item>
    <item>
      <title>Polynomial algorithm for the disjoint bilinear programming problem with an acute-angled polytope for a disjoint subset</title>
      <link>https://arxiv.org/abs/2502.08286</link>
      <description>arXiv:2502.08286v1 Announce Type: new 
Abstract: We consider the disjoint bilinear programming problem in which one of the disjoint subsets has the structure of an acute-angled polytope. An optimality criterion for such a problem is formulated and proved, and based on this, a polynomial algorithm for its solving is proposed and grounded. We show that the proposed algorithm can be efficiently used for studying and solving the boolean linear programming problem and the piecewise linear concave programming problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08286v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitrii Lozovanu</dc:creator>
    </item>
    <item>
      <title>prunAdag: an adaptive pruning-aware gradient method</title>
      <link>https://arxiv.org/abs/2502.08308</link>
      <description>arXiv:2502.08308v1 Announce Type: new 
Abstract: A pruning-aware adaptive gradient method is proposed which classifies the variables in two sets before updating them using different strategies. This technique extends the ``relevant/irrelevant" approach of Ding (2019) and Zimmer et al. (2022) and allows a posteriori sparsification of the solution of model parameter fitting problems. The new method is proved to be convergent with a global rate of decrease of the averaged gradient's norm of the form $\calO(\log(k)/\sqrt{k+1})$. Numerical experiments on several applications show that it is competitive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08308v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Margherita Porcelli, Giovanni Seraghiti, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Strong bounds for large-scale Minimum Sum-of-Squares Clustering</title>
      <link>https://arxiv.org/abs/2502.08397</link>
      <description>arXiv:2502.08397v1 Announce Type: new 
Abstract: Clustering is a fundamental technique in data analysis and machine learning, used to group similar data points together. Among various clustering methods, the Minimum Sum-of-Squares Clustering (MSSC) is one of the most widely used. MSSC aims to minimize the total squared Euclidean distance between data points and their corresponding cluster centroids. Due to the unsupervised nature of clustering, achieving global optimality is crucial, yet computationally challenging. The complexity of finding the global solution increases exponentially with the number of data points, making exact methods impractical for large-scale datasets. Even obtaining strong lower bounds on the optimal MSSC objective value is computationally prohibitive, making it difficult to assess the quality of heuristic solutions. We address this challenge by introducing a novel method to validate heuristic MSSC solutions through optimality gaps. Our approach employs a divide-and-conquer strategy, decomposing the problem into smaller instances that can be handled by an exact solver. The decomposition is guided by an auxiliary optimization problem, the "anticlustering problem", for which we design an efficient heuristic. Computational experiments demonstrate the effectiveness of the method for large-scale instances, achieving optimality gaps below 3% in most cases while maintaining reasonable computational times. These results highlight the practicality of our approach in assessing feasible clustering solutions for large datasets, bridging a critical gap in MSSC evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08397v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Livia Croella, Veronica Piccialli, Antonio M. Sudoso</dc:creator>
    </item>
    <item>
      <title>Predictive Control Barrier Functions: Bridging model predictive control and control barrier functions</title>
      <link>https://arxiv.org/abs/2502.08400</link>
      <description>arXiv:2502.08400v1 Announce Type: new 
Abstract: In this paper, we establish a connection between model predictive control (MPC) techniques and Control Barrier Functions (CBFs). Recognizing the similarity between CBFs and Control Lyapunov Functions (CLFs), we propose a safe MPC formulation that ensures invariance and safety without relying on explicit stability conditions. The value function of our proposed safe MPC is a CBF, which we refer to as the Predictive Control Barrier Function (PCBF), similar to traditional MPC formulations which encode stability by having value functions as CLFs. Our formulation is simpler than previous PCBF approaches and is based on weaker assumptions while proving a similar theorem that guarantees safety recovery. Notably, our safe MPC formulation does not require the value function to be strictly decreasing to ensure convergence to a safe invariant set. Numerical examples demonstrate the effectiveness of our approach in guaranteeing safety and constructing non-conservative CBFs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08400v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jingyi Huang, Han Wang, Kostas Margellos, Paul Goulart</dc:creator>
    </item>
    <item>
      <title>Solving Large-Scale Two-Echelon Location Routing Problems in City Logistics</title>
      <link>https://arxiv.org/abs/2502.08403</link>
      <description>arXiv:2502.08403v1 Announce Type: new 
Abstract: Logistic service providers increasingly focus on two-echelon distribution systems to efficiently manage thousands of deliveries in urban environments. Effectively operating such systems requires designing cost-efficient delivery networks while addressing the challenges of increasing e-commerce demands. In this context, we focus on a two-echelon location routing problem with mobile depots and direct shipment, where decisions involve locating micro-depots, and designing first and second-level routes. Our model also incorporates the flexibility of direct shipments from the main depot to customers.
  To solve such large-scale problems efficiently, we propose a metaheuristic approach that integrates a set cover problem with an adaptive large neighborhood search (ALNS). Our ALNS approach generates a set of promising routes and micro-depot locations using destroy and repair operators while using a local search for intensification. We then utilize the set cover problem to find better network configurations. Additionally, we present a decomposition-based cluster-first, route-second approach to solve large-scale instances efficiently. We show the efficacy of our algorithm on well-known benchmark datasets and provide managerial insights based on a case study for the city of Munich. Our decomposition approach provides comparable results while reducing computational times by a factor of 15. Our case study results show that allowing direct shipment can reduce total costs by 4.7% and emissions by 11%, while increasing truck utilizations by 42%. We find that integrating both stationary and mobile micro-depots, along with allowing direct shipments, can reduce total costs by 5.9% compared to traditional two-echelon delivery structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08403v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Banu Ulusoy Dereli, Gerhard Hiermann, Maximilian Schiffer</dc:creator>
    </item>
    <item>
      <title>Nonlinearly Preconditioned Gradient Methods under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2502.08532</link>
      <description>arXiv:2502.08532v1 Announce Type: new 
Abstract: We analyze nonlinearly preconditioned gradient methods for solving smooth minimization problems. We introduce a generalized smoothness property, based on the notion of abstract convexity, that is broader than Lipschitz smoothness and provide sufficient first- and second-order conditions. Notably, our framework encapsulates algorithms associated with the clipping gradient method and brings out novel insights for the class of $(L_0,L_1)$-smooth functions that has received widespread interest recently, thus allowing us to go beyond already established methods. We investigate the convergence of the proposed method in both the convex and nonconvex setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08532v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Konstantinos Oikonomidis, Jan Quan, Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Separable Approximations of Optimal Value Functions and Their Representation by Neural Networks</title>
      <link>https://arxiv.org/abs/2502.08559</link>
      <description>arXiv:2502.08559v1 Announce Type: new 
Abstract: The use of separable approximations is proposed to mitigate the curse of dimensionality related to the approximation of high-dimensional value functions in optimal control. The separable approximation exploits intrinsic decaying sensitivity properties of the system, where the influence of a state variable on another diminishes as their spatial, temporal, or graph-based distance grows. This property allows the efficient representation of global functions as a sum of localized contributions. A theoretical framework for constructing separable approximations in the context of optimal control is proposed by leveraging decaying sensitivity in both discrete and continuous time. Results extend prior work on decay properties of solutions to Lyapunov and Riccati equations, offering new insights into polynomial and exponential decay regimes. Connections to neural networks are explored, demonstrating how separable structures enable scalable representations of high-dimensional value functions while preserving computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08559v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Sperl, Luca Saluzzi, Dante Kalise, Lars Gr\"une</dc:creator>
    </item>
    <item>
      <title>Increasing competitiveness by imbalanced groups: The example of the 48-team FIFA World Cup</title>
      <link>https://arxiv.org/abs/2502.08565</link>
      <description>arXiv:2502.08565v1 Announce Type: new 
Abstract: A match played in a sports tournament can be called stakeless if at least one team is indifferent to its outcome because it already has qualified or has been eliminated. Such a game threatens fairness since teams may not exert full effort without incentives. This paper suggests a novel classification for stakeless matches according to their expected outcome: they are more costly if the indifferent team is more likely to win by playing honestly. Our approach is illustrated with the 2026 FIFA World Cup, the first edition of the competition with 48 teams. We propose a novel format based on imbalanced groups, which drastically reduces the probability of stakeless matches played by the strongest teams according to Monte Carlo simulations. The new design also increases the uncertainty of match outcomes and requires fewer matches. Governing bodies in sports are encouraged to consider our innovative idea in order to enhance the competitiveness of their tournaments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08565v1</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o, Andr\'as Gyimesi</dc:creator>
    </item>
    <item>
      <title>Optimal Risk Scores for Continuous Predictors</title>
      <link>https://arxiv.org/abs/2502.08588</link>
      <description>arXiv:2502.08588v1 Announce Type: new 
Abstract: In this paper, we propose a novel Mixed-Integer Non-Linear Optimization formulation to construct a risk score, where we optimize the logistic loss with sparsity constraints. Previous approaches are typically designed to handle binary datasets, where continuous predictor variables are discretized in a preprocessing step by using arbitrary thresholds, such as quantiles. In contrast, we allow the model to decide for each continuous predictor variable the particular threshold that is critical for prediction. The usefulness of the resulting optimization problem is tested in synthetic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08588v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cristina Molero-R\'io, Claudia D'Ambrosio</dc:creator>
    </item>
    <item>
      <title>An Initial Condition-Dependent Neural Network Approach for Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2502.08607</link>
      <description>arXiv:2502.08607v1 Announce Type: new 
Abstract: In this work, we investigate an indirect approach for the numerical solution of optimal control problems via neural networks. A customized neural network is constructed, where optimal state, co-state and control trajectories are approximated by minimizing the underlying parameterized Hamiltonian, relying on Pontryagin's Minimum Principle. Departing from previous results reported in the literature, we propose novel, modified networks with both time and trajectory initial condition as inputs. Numerical results demonstrate the ability of neural networks to integrate both time and initial condition information in solving optimal control problems. Finally, it is empirically demonstrated that approximation accuracy may be enhanced through a structural modification incorporating an intermediate layer of Fourier coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08607v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mominul Rubel, Gabriel Nicolosi</dc:creator>
    </item>
    <item>
      <title>Enhancing kidney transplantation through multi-agent kidney exchange programs: A comprehensive review and optimization models</title>
      <link>https://arxiv.org/abs/2502.07819</link>
      <description>arXiv:2502.07819v1 Announce Type: cross 
Abstract: This paper presents a comprehensive review of the last two decades of research on Kidney Exchange Programs (KEPs), systematically categorizing and classifying key contributions to provide readers with a structured understanding of advancements in the field. The review highlights the evolution of KEP methodologies and lays the foundation for our contribution. We propose three mathematical models aimed at improving both the quantity and quality of kidney transplants. Model 1 maximizes the number of transplants by focusing on compatibility based on blood type and PRA, without additional constraints. Model 2 introduces a minimum Human Leukocyte Antigen (HLA) compatibility threshold to enhance transplant quality, though this leads to fewer matches. Model 3 extends the problem to a Multi-Agent Kidney Exchange Program (MKEP), pooling incompatible donor-recipient pairs across multiple agents, resulting in a higher number of successful transplants while ensuring fairness across agents. Sensitivity analyses demonstrate trade-offs between transplant quantity and quality, with Model 3 striking the optimal balance by leveraging multi-agent collaboration to improve both the number and quality of transplants. These findings underscore the potential benefits of more integrated kidney exchange systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07819v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5267/j.ijiec.2024.12.002</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Industrial Engineering Computations, 16(2). Growing Science (2024)</arxiv:journal_reference>
      <dc:creator>Shayan Sharifi</dc:creator>
    </item>
    <item>
      <title>Minimal Shortfall Strategies for Liquidation of a Basket of Stocks using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.07868</link>
      <description>arXiv:2502.07868v1 Announce Type: cross 
Abstract: This paper studies the ubiquitous problem of liquidating large quantities of highly correlated stocks, a task frequently encountered by institutional investors and proprietary trading firms. Traditional methods in this setting suffer from the curse of dimensionality, making them impractical for high-dimensional problems. In this work, we propose a novel method based on stochastic optimal control to optimally tackle this complex multidimensional problem. The proposed method minimizes the overall execution shortfall of highly correlated stocks using a reinforcement learning approach. We rigorously establish the convergence of our optimal trading strategy and present an implementation of our algorithm using intra-day market data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07868v1</guid>
      <category>q-fin.TR</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moustapha Pemy, Na Zhang</dc:creator>
    </item>
    <item>
      <title>RESIST: Resilient Decentralized Learning Using Consensus Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.07977</link>
      <description>arXiv:2502.07977v1 Announce Type: cross 
Abstract: Empirical risk minimization (ERM) is a cornerstone of modern machine learning (ML), supported by advances in optimization theory that ensure efficient solutions with provable algorithmic convergence rates, which measure the speed at which optimization algorithms approach a solution, and statistical learning rates, which characterize how well the solution generalizes to unseen data. Privacy, memory, computational, and communications constraints increasingly necessitate data collection, processing, and storage across network-connected devices. In many applications, these networks operate in decentralized settings where a central server cannot be assumed, requiring decentralized ML algorithms that are both efficient and resilient. Decentralized learning, however, faces significant challenges, including an increased attack surface for adversarial interference during decentralized learning processes. This paper focuses on the man-in-the-middle (MITM) attack, which can cause models to deviate significantly from their intended ERM solutions. To address this challenge, we propose RESIST (Resilient dEcentralized learning using conSensus gradIent deScenT), an optimization algorithm designed to be robust against adversarially compromised communication links. RESIST achieves algorithmic and statistical convergence for strongly convex, Polyak-Lojasiewicz, and nonconvex ERM problems. Experimental results demonstrate the robustness and scalability of RESIST for real-world decentralized learning in adversarial environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07977v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Fang, Rishabh Dixit, Waheed U. Bajwa, Mert Gurbuzbalaban</dc:creator>
    </item>
    <item>
      <title>Optimizing Asynchronous Federated Learning: A Delicate Trade-Off Between Model-Parameter Staleness and Update Frequency</title>
      <link>https://arxiv.org/abs/2502.08206</link>
      <description>arXiv:2502.08206v1 Announce Type: cross 
Abstract: Synchronous federated learning (FL) scales poorly with the number of clients due to the straggler effect. Algorithms like FedAsync and GeneralizedFedAsync address this limitation by enabling asynchronous communication between clients and the central server. In this work, we rely on stochastic modeling to better understand the impact of design choices in asynchronous FL algorithms, such as the concurrency level and routing probabilities, and we leverage this knowledge to optimize loss. We characterize in particular a fundamental trade-off for optimizing asynchronous FL: minimizing gradient estimation errors by avoiding model parameter staleness, while also speeding up the system by increasing the throughput of model updates. Our two main contributions can be summarized as follows. First, we prove a discrete variant of Little's law to derive a closed-form expression for relative delay, a metric that quantifies staleness. This allows us to efficiently minimize the average loss per model update, which has been the gold standard in literature to date. Second, we observe that naively optimizing this metric leads us to slow down the system drastically by overemphazing staleness at the detriment of throughput. This motivates us to introduce an alternative metric that also takes system speed into account, for which we derive a tractable upper-bound that can be minimized numerically. Extensive numerical results show that these optimizations enhance accuracy by 10% to 30%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08206v1</guid>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdelkrim Alahyane (LAAS-SARA, LAAS-RISC, LAAS), C\'eline Comte (CNRS, LAAS-SARA, LAAS-RISC, LAAS), Matthieu Jonckheere (CNRS, LAAS-SARA, LAAS-RISC, LAAS), \'Eric Moulines (X)</dc:creator>
    </item>
    <item>
      <title>Equitable Auction Design: With and Without Distributions</title>
      <link>https://arxiv.org/abs/2502.08369</link>
      <description>arXiv:2502.08369v1 Announce Type: cross 
Abstract: We study a mechanism design problem where a seller aims to allocate a good to multiple bidders, each with a private value. The seller supports or favors a specific group, referred to as the minority group. Specifically, the seller requires that allocations to the minority group are at least a predetermined fraction (equity level) of those made to the rest of the bidders. Such constraints arise in various settings, including government procurement and corporate supply chain policies that prioritize small businesses, environmentally responsible suppliers, or enterprises owned by historically disadvantaged individuals. We analyze two variants of this problem: stochastic mechanism design, which assumes bidders' values follow a known distribution and seeks to maximize expected revenue, and regret-based mechanism design, which makes no distributional assumptions and aims to minimize the worst-case regret. We characterize a closed-form optimal stochastic mechanism and propose a closed-form regret-based mechanism, and establish that the ex-post regret under the latter is at most a constant multiple (dependent on the equity level) of the optimal worst-case regret. We further quantify that this approximation constant is at most 1.31 across different equity levels. Both mechanisms can be interpreted as set-asides, a common policy tool that reserves a fraction of goods for minority groups. Furthermore, numerical results demonstrate that the stochastic mechanism performs well when the bidders' value distribution is accurately estimated, while the regret-based mechanism exhibits greater robustness under estimation errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08369v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiqin Wang, Cagil Kocyigit, Napat Rujeerapaiboon</dc:creator>
    </item>
    <item>
      <title>Matrix Completion with Graph Information: A Provable Nonconvex Optimization Approach</title>
      <link>https://arxiv.org/abs/2502.08536</link>
      <description>arXiv:2502.08536v1 Announce Type: cross 
Abstract: We consider the problem of matrix completion with graphs as side information depicting the interrelations between variables. The key challenge lies in leveraging the similarity structure of the graph to enhance matrix recovery. Existing approaches, primarily based on graph Laplacian regularization, suffer from several limitations: (1) they focus only on the similarity between neighboring variables, while overlooking long-range correlations; (2) they are highly sensitive to false edges in the graphs and (3) they lack theoretical guarantees regarding statistical and computational complexities. To address these issues, we propose in this paper a novel graph regularized matrix completion algorithm called GSGD, based on preconditioned projected gradient descent approach. We demonstrate that GSGD effectively captures the higher-order correlation information behind the graphs, and achieves superior robustness and stability against the false edges. Theoretically, we prove that GSGD achieves linear convergence to the global optimum with near-optimal sample complexity, providing the first theoretical guarantees for both recovery accuracy and efficacy in the perspective of nonconvex optimization. Our numerical experiments on both synthetic and real-world data further validate that GSGD achieves superior recovery accuracy and scalability compared with several popular alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08536v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Wang, Yiyang Yang, Kaidong Wang, Shanxing Gao, Xiuwu Liao</dc:creator>
    </item>
    <item>
      <title>Robustly Learning Monotone Generalized Linear Models via Data Augmentation</title>
      <link>https://arxiv.org/abs/2502.08611</link>
      <description>arXiv:2502.08611v1 Announce Type: cross 
Abstract: We study the task of learning Generalized Linear models (GLMs) in the agnostic model under the Gaussian distribution. We give the first polynomial-time algorithm that achieves a constant-factor approximation for \textit{any} monotone Lipschitz activation. Prior constant-factor GLM learners succeed for a substantially smaller class of activations. Our work resolves a well-known open problem, by developing a robust counterpart to the classical GLMtron algorithm (Kakade et al., 2011). Our robust learner applies more generally, encompassing all monotone activations with bounded $(2+\zeta)$-moments, for any fixed $\zeta&gt;0$ -- a condition that is essentially necessary. To obtain our results, we leverage a novel data augmentation technique with decreasing Gaussian noise injection and prove a number of structural results that may be useful in other settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08611v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikos Zarifis, Puqian Wang, Ilias Diakonikolas, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Continuous-Time Zeroth-Order Dynamics with Projection Maps: Model-Free Feedback Optimization with Safety Guarantees</title>
      <link>https://arxiv.org/abs/2303.06858</link>
      <description>arXiv:2303.06858v3 Announce Type: replace 
Abstract: This paper introduces a class of model-free feedback methods for solving generic constrained optimization problems where the specific mathematical forms of the objective and constraint functions are not available. The proposed methods, termed Projected Zeroth-Order (P-ZO) dynamics, incorporate projection maps into a class of continuous-time model-free dynamics that make use of periodic dithering for the purpose of gradient learning. In particular, the proposed P-ZO algorithms can be interpreted as new extremum-seeking algorithms that autonomously drive an unknown system toward a neighborhood of the set of solutions of an optimization problem using only output feedback, while systematically guaranteeing that the input trajectories remain in a feasible set for all times. In this way, the P-ZO algorithms can properly handle hard and asymptotical constraints in model-free optimization problems without using penalty terms or barrier functions. Moreover, the proposed dynamics have suitable robustness properties with respect to small bounded additive disturbances on the states and dynamics, a property that is fundamental for practical real-world implementations. Additional tracking results for time-varying and switching cost functions are also derived under stronger convexity and smoothness assumptions and using tools from hybrid dynamical systems. Numerical examples are presented throughout the paper to illustrate the above results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.06858v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xin Chen, Jorge I. Poveda, Na Li</dc:creator>
    </item>
    <item>
      <title>Faster Algorithms for Structured Linear and Kernel Support Vector Machines</title>
      <link>https://arxiv.org/abs/2307.07735</link>
      <description>arXiv:2307.07735v3 Announce Type: replace 
Abstract: Quadratic programming is a ubiquitous prototype in convex programming. Many machine learning problems can be formulated as quadratic programming, including the famous Support Vector Machines (SVMs). Linear and kernel SVMs have been among the most popular models in machine learning over the past three decades, prior to the deep learning era.
  Generally, a quadratic program has an input size of $\Theta(n^2)$, where $n$ is the number of variables. Assuming the Strong Exponential Time Hypothesis ($\textsf{SETH}$), it is known that no $O(n^{2-o(1)})$ time algorithm exists when the quadratic objective matrix is positive semidefinite (Backurs, Indyk, and Schmidt, NeurIPS'17). However, problems such as SVMs usually admit much smaller input sizes: one is given $n$ data points, each of dimension $d$, and $d$ is oftentimes much smaller than $n$. Furthermore, the SVM program has only $O(1)$ equality linear constraints. This suggests that faster algorithms are feasible, provided the program exhibits certain structures.
  In this work, we design the first nearly-linear time algorithm for solving quadratic programs whenever the quadratic objective admits a low-rank factorization, and the number of linear constraints is small. Consequently, we obtain results for SVMs:
  * For linear SVM when the input data is $d$-dimensional, our algorithm runs in time $\widetilde O(nd^{(\omega+1)/2}\log(1/\epsilon))$ where $\omega\approx 2.37$ is the fast matrix multiplication exponent;
  * For Gaussian kernel SVM, when the data dimension $d = {\color{black}O(\log n)}$ and the squared dataset radius is sub-logarithmic in $n$, our algorithm runs in time $O(n^{1+o(1)}\log(1/\epsilon))$. We also prove that when the squared dataset radius is at least $\Omega(\log^2 n)$, then $\Omega(n^{2-o(1)})$ time is required. This improves upon the prior best lower bound in both the dimension $d$ and the squared dataset radius.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07735v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuzhou Gu, Zhao Song, Lichen Zhang</dc:creator>
    </item>
    <item>
      <title>Maximum Load Assortment Optimization: Approximation Algorithms and Adaptivity Gaps</title>
      <link>https://arxiv.org/abs/2309.01772</link>
      <description>arXiv:2309.01772v2 Announce Type: replace 
Abstract: Motivated by modern-day applications such as Attended Home Delivery and Preference-based Group Scheduling, where decision makers wish to steer a large number of customers toward choosing the exact same alternative, we introduce a novel class of assortment optimization problems, referred to as Maximum Load Assortment Optimization. In such settings, given a universe of substitutable products, we are facing a stream of customers, each choosing between either selecting a product out of an offered assortment or opting to leave without making a selection. Assuming that these decisions are governed by the Multinomial Logit choice model, we define the random load of any underlying product as the total number of customers who select it. Our objective is to offer an assortment of products to each customer so that the expected maximum load across all products is maximized. We consider both static and dynamic formulations. In the static setting, a single offer set is carried throughout the entire process of customer arrivals, whereas in the dynamic setting, the decision maker offers a personalized assortment to each customer, based on the entire information available at that time. The main contribution of this paper resides in proposing efficient algorithmic approaches for computing near-optimal static and dynamic assortment policies. In particular, we develop a polynomial-time approximation scheme (PTAS) for the static formulation. Additionally, we demonstrate that an elegant policy utilizing weight-ordered assortments yields a 1/2- approximation. Concurrently, we prove that such policies are sufficiently strong to provide a 1/4-approximation with respect to the dynamic formulation, establishing a constant-factor bound on its adaptivity gap. Finally, we design an adaptive policy whose expected maximum load is within factor 1-\eps of optimal, admitting a quasi-polynomial time implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01772v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar El Housni, Marouane Ibn Brahim, Danny Segev</dc:creator>
    </item>
    <item>
      <title>Distributed Discrete-time Dynamic Outer Approximation of the Intersection of Ellipsoids</title>
      <link>https://arxiv.org/abs/2403.01478</link>
      <description>arXiv:2403.01478v2 Announce Type: replace 
Abstract: This paper presents the first discrete-time distributed algorithm to track the tightest ellipsoids that outer approximates the global dynamic intersection of ellipsoids. Given an undirected network, we consider a setup where each node measures an ellipsoid, defined as a time-varying positive semidefinite matrix. The goal is to devise a distributed algorithm to track the tightest outer approximation of the intersection of all the ellipsoids. The solution is based on a novel distributed reformulation of the original centralized semi-definite outer L\"owner-John program, characterized by a non-separable objective function and global constraints. We prove finite-time convergence to the global minima of the centralized problem in the static case and finite-time bounded tracking error in the dynamic case. Moreover, we prove boundedness of estimation in the tracking of the global optimum and robustness in the estimation against time-varying inputs. We illustrate the properties of the algorithm with different simulated examples, including a distributed estimation showcase where our proposal is integrated into a distributed Kalman filter to surpass the state-of-the-art in mean square error performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01478v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Sebasti\'an, Rodrigo Aldana-L\'opez, Rosario Arag\"u\'es, Eduardo Montijano, Carlos Sag\"u\'es</dc:creator>
    </item>
    <item>
      <title>An enhanced heuristic framework for solving the Rank Pricing Problem</title>
      <link>https://arxiv.org/abs/2405.15702</link>
      <description>arXiv:2405.15702v2 Announce Type: replace 
Abstract: The Rank Pricing Problem (RPP) is a challenging bilevel optimization problem with binary variables whose objective is to determine the optimal pricing strategy for a set of products to maximize the total benefit, given that customer preferences influence the price for each product. Traditional methods for solving RPP are based on exact approaches which may be computationally expensive. In contrast, this paper presents a novel heuristic approach that takes advantage of the structure of the problem to obtain good solutions. The proposed approach consists of two phases. Firstly, a standard heuristic is applied to get a pricing strategy. In our case, we choose to use the Variable Neighborhood Search (VNS), and the genetic algorithm. Both methodologies are very popular for their effectiveness in solving combinatorial optimization problems. The solution obtained after running these algorithms is improved in a second phase, where four different local searches are applied. Such local searches use the information of the RPP to get better solutions, that is, there is no need to solve new optimization problems. Even though our methodology does not have optimality guarantees, our computational experiments show that it outperforms Mixed Integer Program solvers regarding solution quality and computational burden.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15702v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Asunci\'on Jim\'enez-Cordero, Salvador Pineda, Juan Miguel Morales</dc:creator>
    </item>
    <item>
      <title>Converse Theorems for Certificates of Safety and Stability</title>
      <link>https://arxiv.org/abs/2406.14823</link>
      <description>arXiv:2406.14823v2 Announce Type: replace 
Abstract: Motivated by the key role of control barrier functions (CBFs) in assessing safety and enabling the synthesis of safe controllers in nonlinear control systems, this paper presents a suite of converse results on CBFs. Given any safe set, we first identify a set of general sufficient conditions which guarantee the existence of a CBF. Our technical analysis also enables us to define an extended notion of CBF which is always guaranteed to exist if the set is safe. We next turn our attention to the problem of joint safety and stability, and give conditions under which the notions of control Lyapunov-barrier function (CLBF) and compatible control Lyapunov function (CLF) and CBF pair are guaranteed to exist. Finally, we identify conditions under which a CLBF and a compatible CLF-CBF pair can be constructed from a non-compatible CLF-CBF pair. Throughout the paper, we intersperse different examples and counterexamples to motivate our results and position them within the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14823v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>Convergence of Descent Optimization Algorithms under Polyak-\L ojasiewicz-Kurdyka Conditions</title>
      <link>https://arxiv.org/abs/2407.00812</link>
      <description>arXiv:2407.00812v2 Announce Type: replace 
Abstract: This paper develops a comprehensive convergence analysis for generic classes of descent algorithms in nonsmooth and nonconvex optimization under several conditions of the Polyak-\L ojasiewicz-Kurdyka (PLK) type. Along other results, we prove the finite termination of generic algorithms under the PLK conditions with lower exponents. Specifications are given to establish new convergence rates for inexact reduced gradient methods and some versions of the boosted algorithm in DC programming. It is revealed, e.g., that the lower exponent PLK conditions for a broad class of difference programs are incompatible with the gradient Lipschitz continuity for the plus function around a local minimizer. On the other hand, we show that the above inconsistency observation may fail if the Lipschitz continuity is replaced by merely the gradient continuity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00812v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>G. C. Bento, B. S. Mordukhovich, T. S. Mota, Yu. Nesterov</dc:creator>
    </item>
    <item>
      <title>Occasionally Observed Piecewise-deterministic Markov Processes</title>
      <link>https://arxiv.org/abs/2408.01335</link>
      <description>arXiv:2408.01335v2 Announce Type: replace 
Abstract: Piecewise-deterministic Markov processes (PDMPs) are often used to model abrupt changes in the global environment or capabilities of a controlled system. This is typically done by considering a set of "operating modes" (each with its own system dynamics and performance metrics) and assuming that the mode can switch stochastically while the system state evolves. Such models have a broad range of applications in engineering, economics, manufacturing, robotics, and biological sciences. Here, we introduce and analyze an "occasionally observed" version of mode-switching PDMPs. We show how such systems can be controlled optimally if the planner is not alerted to mode-switches as they occur but may instead have access to infrequent mode observations. We first develop a general framework for handling this through dynamic programming on a higher-dimensional mode-belief space. While quite general, this method is rarely practical due to the curse of dimensionality. We then discuss assumptions that allow for solving the same problem much more efficiently, with the computational costs growing linearly (rather than exponentially) with the number of modes. We use this approach to derive Hamilton-Jacobi-Bellman PDEs and quasi-variational inequalities encoding the optimal behavior for a variety of planning horizons (fixed, infinite, indefinite, random) and mode-observation schemes (at fixed times or on-demand). We discuss the computational challenges associated with each version and illustrate the resulting methods on test problems from surveillance-evading path planning. We also include an example based on robotic navigation: a Mars rover that minimizes the expected time to target while accounting for the possibility of unobserved/incremental damages and dynamics-altering breakdowns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01335v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marissa Gee, Alexander Vladimirsky</dc:creator>
    </item>
    <item>
      <title>Learning in Herding Mean Field Games: Single-Loop Algorithm with Finite-Time Convergence Analysis</title>
      <link>https://arxiv.org/abs/2408.04780</link>
      <description>arXiv:2408.04780v5 Announce Type: replace 
Abstract: We consider discrete-time stationary mean field games (MFG) with unknown dynamics and design algorithms for finding the equilibrium with finite-time complexity guarantees. Prior solutions to the problem assume either the contraction of a mean field optimality-consistency operator or strict weak monotonicity, which may be overly restrictive. In this work, we introduce a new class of solvable MFGs, named the "fully herding class", which expands the known solvable class of MFGs and for the first time includes problems with multiple equilibria. We propose a direct policy optimization method, Accelerated Single-loop Actor Critic Algorithm for Mean Field Games (ASAC-MFG), that provably finds a global equilibrium for MFGs within this class, under suitable access to a single trajectory of Markovian samples. Different from the prior methods, ASAC-MFG is single-loop and single-sample-path. We establish the finite-time and finite-sample convergence of ASAC-MFG to a mean field equilibrium via new techniques that we develop for multi-time-scale stochastic approximation. We support the theoretical results with illustrative numerical simulations.
  When the mean field does not affect the transition and reward, a MFG reduces to a Markov decision process (MDP) and ASAC-MFG becomes an actor-critic algorithm for finding the optimal policy in average-reward MDPs, with a sample complexity matching the state-of-the-art. Previous works derive the complexity assuming a contraction on the Bellman operator, which is invalid for average-reward MDPs. We match the rate while removing the untenable assumption through an improved Lyapunov function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04780v5</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Sujay Bhatt, Alec Koppel, Sumitra Ganesh</dc:creator>
    </item>
    <item>
      <title>A Stability Principle for Learning under Non-Stationarity</title>
      <link>https://arxiv.org/abs/2310.18304</link>
      <description>arXiv:2310.18304v4 Announce Type: replace-cross 
Abstract: We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory and numerical experiments showcase the adaptivity of this approach to unknown non-stationarity. We prove regret bounds that are minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18304v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengpiao Huang, Kaizheng Wang</dc:creator>
    </item>
    <item>
      <title>Online Learning Quantum States with the Logarithmic Loss via VB-FTRL</title>
      <link>https://arxiv.org/abs/2311.04237</link>
      <description>arXiv:2311.04237v3 Announce Type: replace-cross 
Abstract: Online learning of quantum states with the logarithmic loss (LL-OLQS) is a quantum generalization of online portfolio selection (OPS), a classic open problem in online learning for over three decades. This problem also emerges in designing stochastic optimization algorithms for maximum-likelihood quantum state tomography. Recently, Jezequel et al. (arXiv:2209.13932) proposed the VB-FTRL algorithm, the first regret-optimal algorithm for OPS with moderate computational complexity. In this paper, we generalize VB-FTRL for LL-OLQS. Let $d$ denote the dimension and $T$ the number of rounds. The generalized algorithm achieves a regret rate of $O ( d^2 \log ( d + T ) )$ for LL-OLQS. Each iteration of the algorithm consists of solving a semidefinite program that can be implemented in polynomial time by, for example, cutting-plane methods. For comparison, the best-known regret rate for LL-OLQS is currently $O ( d^2 \log T )$, achieved by an exponential weight method. However, no explicit implementation is available for the exponential weight method for LL-OLQS. To facilitate the generalization, we introduce the notion of VB-convexity. VB-convexity is a sufficient condition for the volumetric barrier associated with any function to be convex and is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04237v3</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei-Fu Tseng, Kai-Chun Chen, Zi-Hong Xiao, Yen-Huan Li</dc:creator>
    </item>
    <item>
      <title>am-AMM: An Auction-Managed Automated Market Maker</title>
      <link>https://arxiv.org/abs/2403.03367</link>
      <description>arXiv:2403.03367v4 Announce Type: replace-cross 
Abstract: Automated market makers (AMMs) have emerged as the dominant market mechanism for trading on decentralized exchanges implemented on blockchains. This paper presents a single mechanism that targets two important unsolved problems for AMMs: reducing losses to informed orderflow, and maximizing revenue from uninformed orderflow. The ``auction-managed AMM'' works by running a censorship-resistant onchain auction for the right to temporarily act as ``pool manager'' for a constant-product AMM. The pool manager sets the swap fee rate on the pool, and also receives the accrued fees from swaps. The pool manager can exclusively capture some arbitrage by trading against the pool in response to small price movements, and also can set swap fees incorporating price sensitivity of retail orderflow and adapting to changing market conditions, with the benefits from both ultimately accruing to liquidity providers. Liquidity providers can enter and exit the pool freely in response to changing rent, though they must pay a small fee on withdrawal. We prove that under certain assumptions, this AMM should have higher liquidity in equilibrium than any standard, fixed-fee AMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03367v4</guid>
      <category>q-fin.TR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Austin Adams, Ciamac C. Moallemi, Sara Reynolds, Dan Robinson</dc:creator>
    </item>
    <item>
      <title>Convergence of Distributed Adaptive Optimization with Local Updates</title>
      <link>https://arxiv.org/abs/2409.13155</link>
      <description>arXiv:2409.13155v2 Announce Type: replace-cross 
Abstract: We study distributed adaptive algorithms with local updates (intermittent communication). Despite the great empirical success of adaptive methods in distributed training of modern machine learning models, the theoretical benefits of local updates within adaptive methods, particularly in terms of reducing communication complexity, have not been fully understood yet. In this paper, for the first time, we prove that \em Local SGD \em with momentum (\em Local \em SGDM) and \em Local \em Adam can outperform their minibatch counterparts in convex and weakly convex settings in certain regimes, respectively. Our analysis relies on a novel technique to prove contraction during local iterations, which is a crucial yet challenging step to show the advantages of local updates, under generalized smoothness assumption and gradient clipping strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13155v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziheng Cheng, Margalit Glasgow</dc:creator>
    </item>
    <item>
      <title>Logarithmic Regret for Unconstrained Submodular Maximization Stochastic Bandit</title>
      <link>https://arxiv.org/abs/2410.08578</link>
      <description>arXiv:2410.08578v2 Announce Type: replace-cross 
Abstract: We address the online unconstrained submodular maximization problem (Online USM), in a setting with stochastic bandit feedback. In this framework, a decision-maker receives noisy rewards from a non monotone submodular function taking values in a known bounded interval. This paper proposes Double-Greedy - Explore-then-Commit (DG-ETC), adapting the Double-Greedy approach from the offline and online full-information settings. DG-ETC satisfies a $O(d\log(dT))$ problem-dependent upper bound for the $1/2$-approximate pseudo-regret, as well as a $O(dT^{2/3}\log(dT)^{1/3})$ problem-free one at the same time, outperforming existing approaches. In particular, we introduce a problem-dependent notion of hardness characterizing the transition between logarithmic and polynomial regime for the upper bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08578v2</guid>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Zhou (Thoth, STATIFY), Pierre Gaillard (Thoth), Thibaud Rahier (STATIFY), Julyan Arbel (STATIFY)</dc:creator>
    </item>
    <item>
      <title>Unsupervised Training of Diffusion Models for Feasible Solution Generation in Neural Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2411.00003</link>
      <description>arXiv:2411.00003v4 Announce Type: replace-cross 
Abstract: Recent advancements in neural combinatorial optimization (NCO) methods have shown promising results in generating near-optimal solutions without the need for expert-crafted heuristics. However, high performance of these approaches often rely on problem-specific human-expertise-based search after generating candidate solutions, limiting their applicability to commonly solved CO problems such as Traveling Salesman Problem (TSP). In this paper, we present IC/DC, an unsupervised CO framework that directly trains a diffusion model from scratch. We train our model in a self-supervised way to minimize the cost of the solution while adhering to the problem-specific constraints. IC/DC is specialized in addressing CO problems involving two distinct sets of items, and it does not need problem-specific search processes to generate valid solutions. IC/DC employs a novel architecture capable of capturing the intricate relationships between items, and thereby enabling effective optimization in challenging CO scenarios. IC/DC achieves state-of-the-art performance relative to existing NCO methods on the Parallel Machine Scheduling Problem (PMSP) and Asymmetric Traveling Salesman Problem (ATSP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00003v4</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seong-Hyun Hong, Hyun-Sung Kim, Zian Jang, Deunsol Yoon, Hyungseok Song, Byung-Jun Lee</dc:creator>
    </item>
    <item>
      <title>Sketched Equivariant Imaging Regularization and Deep Internal Learning for Inverse Problems</title>
      <link>https://arxiv.org/abs/2411.05771</link>
      <description>arXiv:2411.05771v3 Announce Type: replace-cross 
Abstract: Equivariant Imaging (EI) regularization has become the de-facto technique for unsupervised training of deep imaging networks, without any need of ground-truth data. Observing that the EI-based unsupervised training paradigm currently has significant computational redundancy leading to inefficiency in high-dimensional applications, we propose a sketched EI regularization which leverages the randomized sketching techniques for acceleration. We then extend our sketched EI regularization to develop an accelerated deep internal learning framework, Sketched Equivariant Deep Image Prior (Sk-EI-DIP), which can be efficiently applied for single-image and task-adapted reconstruction. Additionally, for network adaptation tasks, we propose a parameter-efficient approach for accelerating both EI-DIP and Sk-EI-DIP via optimizing only the normalization layers. Our numerical study on X-ray CT and multi-coil MRI image reconstruction tasks demonstrate that our approach can achieve significant computational acceleration over standard EI-based counterpart in single-input setting and network adaptation at test time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05771v3</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guixian Xu, Jinglai Li, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>The Utility and Complexity of in- and out-of-Distribution Machine Unlearning</title>
      <link>https://arxiv.org/abs/2412.09119</link>
      <description>arXiv:2412.09119v2 Announce Type: replace-cross 
Abstract: Machine unlearning, the process of selectively removing data from trained models, is increasingly crucial for addressing privacy concerns and knowledge gaps post-deployment. Despite this importance, existing approaches are often heuristic and lack formal guarantees. In this paper, we analyze the fundamental utility, time, and space complexity trade-offs of approximate unlearning, providing rigorous certification analogous to differential privacy. For in-distribution forget data -- data similar to the retain set -- we show that a surprisingly simple and general procedure, empirical risk minimization with output perturbation, achieves tight unlearning-utility-complexity trade-offs, addressing a previous theoretical gap on the separation from unlearning "for free" via differential privacy, which inherently facilitates the removal of such data. However, such techniques fail with out-of-distribution forget data -- data significantly different from the retain set -- where unlearning time complexity can exceed that of retraining, even for a single sample. To address this, we propose a new robust and noisy gradient descent variant that provably amortizes unlearning time complexity without compromising utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09119v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youssef Allouah, Joshua Kazdan, Rachid Guerraoui, Sanmi Koyejo</dc:creator>
    </item>
    <item>
      <title>On the convergence rate of noisy Bayesian Optimization with Expected Improvement</title>
      <link>https://arxiv.org/abs/2501.09262</link>
      <description>arXiv:2501.09262v2 Announce Type: replace-cross 
Abstract: Expected improvement (EI) is one of the most widely used acquisition functions in Bayesian optimization (BO). Despite its proven success in applications for decades, important open questions remain on the theoretical convergence behaviors and rates for EI. In this paper, we contribute to the convergence theory of EI in three novel and critical areas. First, we consider objective functions that fit under the Gaussian process (GP) prior assumption, whereas existing works mostly focus on functions in the reproducing kernel Hilbert space (RKHS). Second, we establish for the first time the asymptotic error bound and its corresponding rate for GP-EI with noisy observations under the GP prior assumption. Third, by investigating the exploration and exploitation properties of the non-convex EI function, we establish improved error bounds of GP-EI for both the noise-free and noisy cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09262v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyi Wang, Haowei Wang, Nai-Yuan Chiang, Cosmin G. Petra</dc:creator>
    </item>
    <item>
      <title>Explainable and Class-Revealing Signal Feature Extraction via Scattering Transform and Constrained Zeroth-Order Optimization</title>
      <link>https://arxiv.org/abs/2502.05722</link>
      <description>arXiv:2502.05722v2 Announce Type: replace-cross 
Abstract: We propose a new method to extract discriminant and explainable features from a particular machine learning model, i.e., a combination of the scattering transform and the multiclass logistic regression. Although this model is well-known for its ability to learn various signal classes with high classification rate, it remains elusive to understand why it can generate such successful classification, mainly due to the nonlinearity of the scattering transform. In order to uncover the meaning of the scattering transform coefficients selected by the multiclass logistic regression (with the Lasso penalty), we adopt zeroth-order optimization algorithms to search an input pattern that maximizes the class probability of a class of interest given the learned model. In order to do so, it turns out that imposing sparsity and smoothness of input patterns is important. We demonstrate the effectiveness of our proposed method using a couple of synthetic time-series classification problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05722v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoki Saito, David Weber</dc:creator>
    </item>
  </channel>
</rss>
