<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Apr 2025 01:49:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Simplified Condition For Quantile Regression</title>
      <link>https://arxiv.org/abs/2504.18769</link>
      <description>arXiv:2504.18769v1 Announce Type: new 
Abstract: Quantile regression is effective in modeling and inferring the conditional quantile given some predictors and has become popular in risk management due to wide applications of quantile-based risk measures. When forecasting risk for economic and financial variables, quantile regression has to account for heteroscedasticity, which raises the question of whether the identification condition on residuals in quantile regression is equivalent to one independent of heteroscedasticity. In this paper, we present some identification conditions under three probability models and use them to establish simplified conditions in quantile regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18769v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Liang Peng, Yongcheng Qi</dc:creator>
    </item>
    <item>
      <title>Semiparametric M-estimation with overparameterized neural networks</title>
      <link>https://arxiv.org/abs/2504.19089</link>
      <description>arXiv:2504.19089v1 Announce Type: new 
Abstract: We focus on semiparametric regression that has played a central role in statistics, and exploit the powerful learning ability of deep neural networks (DNNs) while enabling statistical inference on parameters of interest that offers interpretability. Despite the success of classical semiparametric method/theory, establishing the $\sqrt{n}$-consistency and asymptotic normality of the finite-dimensional parameter estimator in this context remains challenging, mainly due to nonlinearity and potential tangent space degeneration in DNNs. In this work, we introduce a foundational framework for semiparametric $M$-estimation, leveraging the approximation ability of overparameterized neural networks that circumvent tangent degeneration and align better with training practice nowadays. The optimization properties of general loss functions are analyzed, and the global convergence is guaranteed. Instead of studying the ``ideal'' solution to minimization of an objective function in most literature, we analyze the statistical properties of algorithmic estimators, and establish nonparametric convergence and parametric asymptotic normality for a broad class of loss functions. These results hold without assuming the boundedness of the network output and even when the true function lies outside the specified function space. To illustrate the applicability of the framework, we also provide examples from regression and classification, and the numerical experiments provide empirical support to the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19089v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunxing Yan, Ziyuan Chen, Fang Yao</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo confidence intervals using quantiles of randomized nets</title>
      <link>https://arxiv.org/abs/2504.19138</link>
      <description>arXiv:2504.19138v1 Announce Type: new 
Abstract: Recent advances in quasi-Monte Carlo integration have demonstrated that the median trick significantly enhances the convergence rate of linearly scrambled digital net estimators. In this work, we leverage the quantiles of such estimators to construct confidence intervals with asymptotically valid coverage for high-dimensional integrals. By analyzing the distribution of the integration error for a class of infinitely differentiable integrands, we prove that as the sample size grows, the error decomposes into an asymptotically symmetric component and a vanishing perturbation, which guarantees that a quantile-based interval for the median estimator asymptotically captures the target integral with the nominal coverage probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19138v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexin Pan</dc:creator>
    </item>
    <item>
      <title>Optimal experimental design for parameter estimation in the presence of observation noise</title>
      <link>https://arxiv.org/abs/2504.19233</link>
      <description>arXiv:2504.19233v1 Announce Type: new 
Abstract: Using mathematical models to assist in the interpretation of experiments is becoming increasingly important in research across applied mathematics, and in particular in biology and ecology. In this context, accurate parameter estimation is crucial; model parameters are used to both quantify observed behaviour, characterise behaviours that cannot be directly measured and make quantitative predictions. The extent to which parameter estimates are constrained by the quality and quantity of available data is known as parameter identifiability, and it is widely understood that for many dynamical models the uncertainty in parameter estimates can vary over orders of magnitude as the time points at which data are collected are varied. Here, we use both local sensitivity measures derived from the Fisher Information Matrix and global measures derived from Sobol' indices to explore how parameter uncertainty changes as the number of measurements, and their placement in time, are varied. We use these measures within an optimisation algorithm to determine the observation times that give rise to the lowest uncertainty in parameter estimates. Applying our framework to models in which the observation noise is both correlated and uncorrelated demonstrates that correlations in observation noise can significantly impact the optimal time points for observing a system, and highlights that proper consideration of observation noise should be a crucial part of the experimental design process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19233v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Qi, Ruth E. Baker</dc:creator>
    </item>
    <item>
      <title>Bahadur asymptotic efficiency in the zone of moderate deviation probabilities</title>
      <link>https://arxiv.org/abs/2504.19331</link>
      <description>arXiv:2504.19331v1 Announce Type: new 
Abstract: For a sequence of independent identically distributed random variables having a distribution function with an unknown parameter from a set $\Theta \subset \mathbf{R}^d$, we prove an analogue of the lower bound of Bahadur asymptotic efficiency for the zone of moderate deviation probabilities. The assumptions coincide with assumptions conditions under which the locally asymptotically minimax lower bound of Hajek-Le Cam was proved. The lower bound for local Bahadur asymptotic efficiency is a special case of this lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19331v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mikhail Ermakov</dc:creator>
    </item>
    <item>
      <title>Frequency Domain Resampling for Gridded Spatial Data</title>
      <link>https://arxiv.org/abs/2504.19337</link>
      <description>arXiv:2504.19337v1 Announce Type: new 
Abstract: In frequency domain analysis for spatial data, spectral averages based on the periodogram often play an important role in understanding spatial covariance structure, but also have complicated sampling distributions due to complex variances from aggregated periodograms. In order to nonparametrically approximate these sampling distributions for purposes of inference, resampling can be useful, but previous developments in spatial bootstrap have faced challenges in the scope of their validity, specifically due to issues in capturing the complex variances of spatial spectral averages. As a consequence, existing frequency domain bootstraps for spatial data are highly restricted in application to only special processes (e.g. Gaussian) or certain spatial statistics. To address this limitation and to approximate a wide range of spatial spectral averages, we propose a practical hybrid-resampling approach that combines two different resampling techniques in the forms of spatial subsampling and spatial bootstrap. Subsampling helps to capture the variance of spectral averages while bootstrap captures the distributional shape. The hybrid resampling procedure can then accurately quantify uncertainty in spectral inference under mild spatial assumptions. Moreover, compared to the more studied time series setting, this work fills a gap in the theory of subsampling/bootstrap for spatial data regarding spectral average statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19337v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Souvick Bera, Daniel J. Nordman, Soutir Bandyopadhyay</dc:creator>
    </item>
    <item>
      <title>Signal detection from spiked noise via asymmetrization</title>
      <link>https://arxiv.org/abs/2504.19450</link>
      <description>arXiv:2504.19450v1 Announce Type: new 
Abstract: The signal plus noise model $H=S+Y$ is a fundamental model in signal detection when a low rank signal $S$ is polluted by noise $Y$. In the high-dimensional setting, one often uses the leading singular values and corresponding singular vectors of $H$ to conduct the statistical inference of the signal $S$. Especially, when $Y$ consists of iid random entries, the singular values of $S$ can be estimated from those of $H$ as long as the signal $S$ is strong enough. However, when the $Y$ entries are heteroscedastic or correlated, this standard approach may fail. Especially in this work, we consider a situation that can easily arise with heteroscedastic noise but is particularly difficult to address using the singular value approach, namely, when the noise $Y$ itself may create spiked singular values. It has been a recurring question how to distinguish the signal $S$ from the spikes in $Y$, as this seems impossible by examining the leading singular values of $H$. Inspired by the work \cite{CCF21}, we turn to study the eigenvalues of an asymmetrized model when two samples $H_1=S+Y_1$ and $H_2=S+Y_2$ are available. We show that by looking into the leading eigenvalues (in magnitude) of the asymmetrized model $H_1H_2^*$, one can easily detect $S$. Unlike \cite{CCF21}, we show that even if the spikes from $Y$ is much larger than the strength of $S$, and thus the operator norm of $Y$ is much larger than that of $S$, the detection is still effective. Second, we establish the precise detection threshold. Third, we do not require any structural assumption on the singular vectors of $S$. Finally, we derive precise limiting behaviour of the leading eigenvalues of the asymmetrized model. Based on the limiting results, we propose a completely data-based approach for the detection of $S$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19450v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhigang Bao, Kha Man Cheong, Yuji Li</dc:creator>
    </item>
    <item>
      <title>On Stopping Times of Power-one Sequential Tests: Tight Lower and Upper Bounds</title>
      <link>https://arxiv.org/abs/2504.19952</link>
      <description>arXiv:2504.19952v1 Announce Type: new 
Abstract: We prove two lower bounds for stopping times of sequential tests between general composite nulls and alternatives. The first lower bound is for the setting where the type-1 error level $\alpha$ approaches zero, and equals $\log(1/\alpha)$ divided by a certain infimum KL divergence, termed $\operatorname{KL_{inf}}$. The second lower bound applies to the setting where $\alpha$ is fixed and $\operatorname{KL_{inf}}$ approaches 0 (meaning that the null and alternative sets are not separated) and equals $c \operatorname{KL_{inf}}^{-1} \log \log \operatorname{KL_{inf}}^{-1}$ for a universal constant $c &gt; 0$. We also provide a sufficient condition for matching the upper bounds and show that this condition is met in several special cases. Given past work, these upper and lower bounds are unsurprising in their form; our main contribution is the generality in which they hold, for example, not requiring reference measures or compactness of the classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19952v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubhada Agrawal, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Inverse Problems Over Probability Measure Space</title>
      <link>https://arxiv.org/abs/2504.18999</link>
      <description>arXiv:2504.18999v1 Announce Type: cross 
Abstract: Define a forward problem as $\rho_y = G_\#\rho_x$, where the probability distribution $\rho_x$ is mapped to another distribution $\rho_y$ using the forward operator $G$. In this work, we investigate the corresponding inverse problem: Given $\rho_y$, how to find $\rho_x$? Depending on whether $ G$ is overdetermined or underdetermined, the solution can have drastically different behavior. In the overdetermined case, we formulate a variational problem $\min_{\rho_x} D( G_\#\rho_x, \rho_y)$, and find that different choices of the metric $ D$ significantly affect the quality of the reconstruction. When $ D$ is set to be the Wasserstein distance, the reconstruction is the marginal distribution, while setting $ D$ to be a $\phi$-divergence reconstructs the conditional distribution. In the underdetermined case, we formulate the constrained optimization $\min_{\{ G_\#\rho_x=\rho_y\}} E[\rho_x]$. The choice of $ E$ also significantly impacts the construction: setting $ E$ to be the entropy gives us the piecewise constant reconstruction, while setting $ E$ to be the second moment, we recover the classical least-norm solution. We also examine the formulation with regularization: $\min_{\rho_x} D( G_\#\rho_x, \rho_y) + \alpha \mathsf R[\rho_x]$, and find that the entropy-entropy pair leads to a regularized solution that is defined in a piecewise manner, whereas the $W_2$-$W_2$ pair leads to a least-norm solution where $W_2$ is the 2-Wasserstein metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18999v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qin Li, Maria Oprea, Li Wang, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>A new look at fiducial inference</title>
      <link>https://arxiv.org/abs/2504.19172</link>
      <description>arXiv:2504.19172v1 Announce Type: cross 
Abstract: Since the idea of fiducial inference was put forward by Fisher, researchers have been attempting to place it within a rigorous and well motivated framework. It is fair to say that a general definition has remained elusive. In this paper we start with a representation of Bayesian posterior distributions provided by Doob that relies on martingales. This is explicit in defining how a true parameter value should depend on a random sample and hence an approach to "inverse probability" (Fisher, 1930). Taking this as our cue, we introduce a definition of fiducial inference that extends existing ones due to Hannig.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19172v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pier Giovanni Bissiri, Chris Holmes, Stephen Walker</dc:creator>
    </item>
    <item>
      <title>Learning High-dimensional Gaussians from Censored Data</title>
      <link>https://arxiv.org/abs/2504.19446</link>
      <description>arXiv:2504.19446v1 Announce Type: cross 
Abstract: We provide efficient algorithms for the problem of distribution learning from high-dimensional Gaussian data where in each sample, some of the variable values are missing. We suppose that the variables are missing not at random (MNAR). The missingness model, denoted by $S(y)$, is the function that maps any point $y$ in $R^d$ to the subsets of its coordinates that are seen. In this work, we assume that it is known. We study the following two settings:
  (i) Self-censoring: An observation $x$ is generated by first sampling the true value $y$ from a $d$-dimensional Gaussian $N(\mu*, \Sigma*)$ with unknown $\mu*$ and $\Sigma*$. For each coordinate $i$, there exists a set $S_i$ subseteq $R^d$ such that $x_i = y_i$ if and only if $y_i$ in $S_i$. Otherwise, $x_i$ is missing and takes a generic value (e.g., "?"). We design an algorithm that learns $N(\mu*, \Sigma*)$ up to total variation (TV) distance epsilon, using $poly(d, 1/\epsilon)$ samples, assuming only that each pair of coordinates is observed with sufficiently high probability.
  (ii) Linear thresholding: An observation $x$ is generated by first sampling $y$ from a $d$-dimensional Gaussian $N(\mu*, \Sigma)$ with unknown $\mu*$ and known $\Sigma$, and then applying the missingness model $S$ where $S(y) = {i in [d] : v_i^T y &lt;= b_i}$ for some $v_1, ..., v_d$ in $R^d$ and $b_1, ..., b_d$ in $R$. We design an efficient mean estimation algorithm, assuming that none of the possible missingness patterns is very rare conditioned on the values of the observed coordinates and that any small subset of coordinates is observed with sufficiently high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19446v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Bhattacharyya, Constantinos Daskalakis, Themis Gouleakis, Yuhao Wang</dc:creator>
    </item>
    <item>
      <title>Marginal expected shortfall: Systemic risk measurement under dependence uncertainty</title>
      <link>https://arxiv.org/abs/2504.19953</link>
      <description>arXiv:2504.19953v1 Announce Type: cross 
Abstract: Measuring the contribution of a bank or an insurance company to the overall systemic risk of the market is an important issue, especially in the aftermath of the 2007-2009 financial crisis and the financial downturn of 2020. In this paper, we derive the worst-case and best-case bounds for marginal expected shortfall (MES) -- a key measure of systemic risk contribution -- under the assumption of known marginal distributions for individual companies' risks but an unknown dependence structure. We further derive improved bounds for the MES risk measure when partial information on companies' risk exposures -- and hence their dependence -- is available. To capture this partial information, we utilize three commonly used background risk models: the additive, minimum-based, and multiplicative factor models. Finally, we present an alternative set of improved MES bounds based on a linear regression relationship between individual companies' risks and overall market risk, consistent with the assumptions of the Capital Asset Pricing Model in finance and the Weighted Insurance Pricing Model in insurance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19953v1</guid>
      <category>q-fin.RM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinghui Chen, Edward Furman, X. Sheldon Lin</dc:creator>
    </item>
    <item>
      <title>Stochastic Subspace via Probabilistic Principal Component Analysis for Characterizing Model Error</title>
      <link>https://arxiv.org/abs/2504.19963</link>
      <description>arXiv:2504.19963v1 Announce Type: cross 
Abstract: This paper proposes a probabilistic model of subspaces based on the probabilistic principal component analysis (PCA). Given a sample of vectors in the embedding space -- commonly known as a snapshot matrix -- this method uses quantities derived from the probabilistic PCA to construct distributions of the sample matrix, as well as the principal subspaces. It is applicable to projection-based reduced-order modeling methods, such as proper orthogonal decomposition and related model reduction methods. The stochastic subspace thus constructed can be used, for example, to characterize model-form uncertainty in computational mechanics. The proposed method has multiple desirable properties: (1) it is naturally justified by the probabilistic PCA and has analytic forms for the induced random matrix models; (2) it satisfies linear constraints, such as boundary conditions of all kinds, by default; (3) it has only one hyperparameter, which significantly simplifies training; and (4) its algorithm is very easy to implement. We compare the proposed method with existing approaches in a low-dimensional visualization example and a parametric static problem, and demonstrate its performance in a dynamics model of a space structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19963v1</guid>
      <category>cs.CE</category>
      <category>math.ST</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Yadav, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptation using spatially distributed Gaussian Processes</title>
      <link>https://arxiv.org/abs/2312.14130</link>
      <description>arXiv:2312.14130v2 Announce Type: replace 
Abstract: We consider the accuracy of an approximate posterior distribution in nonparametric regression problems by combining posterior distributions computed on subsets of the data defined by the locations of the independent variables. We show that this approximate posterior retains the rate of recovery of the full data posterior distribution, where the rate of recovery adapts to the smoothness of the true regression function. As particular examples we consider Gaussian process priors based on integrated Brownian motion and the Mat\'ern kernel augmented with a prior on the length scale. Besides theoretical guarantees we present a numerical study of the methods both on synthetic and real world data. We also propose a new aggregation technique, which numerically outperforms previous approaches. Finally, we demonstrate empirically that spatially distributed methods can adapt to local regularities, potentially outperforming the original Gaussian process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14130v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Botond Szabo, Amine Hadji, Aad van der Vaart</dc:creator>
    </item>
    <item>
      <title>Sampling and estimation on manifolds using the Langevin diffusion</title>
      <link>https://arxiv.org/abs/2312.14882</link>
      <description>arXiv:2312.14882v3 Announce Type: replace 
Abstract: Error bounds are derived for sampling and estimation using a discretization of an intrinsically defined Langevin diffusion with invariant measure $\text{d}\mu_\phi \propto e^{-\phi} \mathrm{dvol}_g $ on a compact Riemannian manifold. Two estimators of linear functionals of $\mu_\phi $ based on the discretized Markov process are considered: a time-averaging estimator based on a single trajectory and an ensemble-averaging estimator based on multiple independent trajectories. Imposing no restrictions beyond a nominal level of smoothness on $\phi$, first-order error bounds, in discretization step size, on the bias and variance/mean-square error of both estimators are derived. The order of error matches the optimal rate in Euclidean and flat spaces, and leads to a first-order bound on distance between the invariant measure $\mu_\phi$ and a stationary measure of the discretized Markov process. This order is preserved even upon using retractions when exponential maps are unavailable in closed form, thus enhancing practicality of the proposed algorithms. Generality of the proof techniques, which exploit links between two partial differential equations and the semigroup of operators corresponding to the Langevin diffusion, renders them amenable for the study of a more general class of sampling algorithms related to the Langevin diffusion. Conditions for extending analysis to the case of non-compact manifolds are discussed. Numerical illustrations with distributions, log-concave and otherwise, on the manifolds of positive and negative curvature elucidate on the derived bounds and demonstrate practical utility of the sampling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14882v3</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Bharath, Alexander Lewis, Akash Sharma, Michael V Tretyakov</dc:creator>
    </item>
    <item>
      <title>Functional Sieve Bootstrap for the Partial Sum Process with Application to Change-Point Detection</title>
      <link>https://arxiv.org/abs/2408.05071</link>
      <description>arXiv:2408.05071v4 Announce Type: replace 
Abstract: This paper applies the functional sieve bootstrap (FSB) to estimate the distribution of the partial sum process for time series stemming from a weakly stationary functional process. Consistency of the FSB procedure under weak assumptions on the underlying functional process is established. This result allows for the application of the FSB procedure to testing for a change-point in the mean of a functional time series using the CUSUM-statistic. We show that the FSB asymptotically correctly estimates critical values of the CUSUM-based test under the null-hypothesis. Consistency of the FSB-based test under local alternatives also is proven. The finite sample performance of the procedure is studied via simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05071v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Efstathios Paparoditis, Lea Wegner, Martin Wendler</dc:creator>
    </item>
    <item>
      <title>Creating non-reversible rejection-free samplers by rebalancing skew-balanced Markov jump processes</title>
      <link>https://arxiv.org/abs/2504.12190</link>
      <description>arXiv:2504.12190v2 Announce Type: replace 
Abstract: Markov chain sampling methods form the backbone of modern computational statistics. However, many popular methods are prone to random walk behavior, i.e., diffusion-like exploration of the sample space, leading to slow mixing that requires intricate tuning to alleviate. Non-reversible samplers can resolve some of these issues. We introduce a device that turns jump processes that satisfy a skew-detailed balance condition for a reference measure into a process that samples a target measure that is absolutely continuous with respect to the reference measure. The resulting sampler is rejection-free, non-reversible, and continuous-time. As an example, we apply the device to Hamiltonian dynamics discretized by the leapfrog integrator, resulting in a rejection-free non-reversible continuous-time version of Hamiltonian Monte Carlo (HMC). We prove the geometric ergodicity of the resulting sampler under certain convexity conditions, and demonstrate its qualitatively different behavior to HMC through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12190v2</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Jansson, Moritz Schauer, Ruben Seyer, Akash Sharma</dc:creator>
    </item>
    <item>
      <title>Semiparametric Conditional Factor Models in Asset Pricing</title>
      <link>https://arxiv.org/abs/2112.07121</link>
      <description>arXiv:2112.07121v5 Announce Type: replace-cross 
Abstract: We introduce a simple and tractable methodology for estimating semiparametric conditional latent factor models. Our approach disentangles the roles of characteristics in capturing factor betas of asset returns from ``alpha.'' We construct factors by extracting principal components from Fama-MacBeth managed portfolios. Applying this methodology to the cross-section of U.S. individual stock returns, we find compelling evidence of substantial nonzero pricing errors, even though our factors demonstrate superior performance in standard asset pricing tests. Unexplained ``arbitrage'' portfolios earn high Sharpe ratios, which decline over time. Combining factors with these orthogonal portfolios produces out-of-sample Sharpe ratios exceeding 4.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.07121v5</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qihui Chen, Nikolai Roussanov, Xiaoliang Wang</dc:creator>
    </item>
    <item>
      <title>Causal Q-Aggregation for CATE Model Selection</title>
      <link>https://arxiv.org/abs/2310.16945</link>
      <description>arXiv:2310.16945v5 Announce Type: replace-cross 
Abstract: Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error terms related to products of errors in the nuisance functions. Crucially, our regret rate does not require that any of the candidate CATE models be close to the truth. We validate our new method on many semi-synthetic datasets and also provide extensions of our work to CATE model selection with instrumental variables and unobserved confounding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16945v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hui Lan, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>Building a stable classifier with the inflated argmax</title>
      <link>https://arxiv.org/abs/2405.14064</link>
      <description>arXiv:2405.14064v2 Announce Type: replace-cross 
Abstract: We propose a new framework for algorithmic stability in the context of multiclass classification. In practice, classification algorithms often operate by first assigning a continuous score (for instance, an estimated probability) to each possible label, then taking the maximizer -- i.e., selecting the class that has the highest score. A drawback of this type of approach is that it is inherently unstable, meaning that it is very sensitive to slight perturbations of the training data, since taking the maximizer is discontinuous. Motivated by this challenge, we propose a pipeline for constructing stable classifiers from data, using bagging (i.e., resampling and averaging) to produce stable continuous scores, and then using a stable relaxation of argmax, which we call the "inflated argmax," to convert these scores to a set of candidate labels. The resulting stability guarantee places no distributional assumptions on the data, does not depend on the number of classes or dimensionality of the covariates, and holds for any base classifier. Using a common benchmark data set, we demonstrate that the inflated argmax provides necessary protection against unstable classifiers, without loss of accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14064v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake A. Soloff, Rina Foygel Barber, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>Kronecker-product random matrices and a matrix least squares problem</title>
      <link>https://arxiv.org/abs/2406.00961</link>
      <description>arXiv:2406.00961v2 Announce Type: replace-cross 
Abstract: We study the eigenvalue distribution and resolvent of a Kronecker-product random matrix model $A \otimes I_{n \times n}+I_{n \times n} \otimes B+\Theta \otimes \Xi \in \mathbb{C}^{n^2 \times n^2}$, where $A,B$ are independent Wigner matrices and $\Theta,\Xi$ are deterministic and diagonal. For fixed spectral arguments, we establish a quantitative approximation for the Stieltjes transform by that of an approximating free operator, and a diagonal deterministic equivalent approximation for the resolvent. We further obtain sharp estimates in operator norm for the $n \times n$ resolvent blocks, and show that off-diagonal resolvent entries fall on two differing scales of $n^{-1/2}$ and $n^{-1}$ depending on their locations in the Kronecker structure.
  Our study is motivated by consideration of a matrix-valued least-squares optimization problem $\min_{X \in \mathbb{R}^{n \times n}} \frac{1}{2}\|XA+BX\|_F^2+\frac{1}{2}\sum_{ij} \xi_i\theta_j x_{ij}^2$ subject to a linear constraint. For random instances of this problem defined by Wigner inputs $A,B$, our analyses imply an asymptotic characterization of the minimizer $X$ and its associated minimum objective value as $n \to \infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00961v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhou Fan, Renyuan Ma</dc:creator>
    </item>
    <item>
      <title>Adaptive Sample Aggregation In Transfer Learning</title>
      <link>https://arxiv.org/abs/2408.16189</link>
      <description>arXiv:2408.16189v2 Announce Type: replace-cross 
Abstract: Transfer Learning aims to optimally aggregate samples from a target distribution, with related samples from a so-called source distribution to improve target risk. Multiple procedures have been proposed over the last two decades to address this problem, each driven by one of a multitude of possible divergence measures between source and target distributions. A first question asked in this work is whether there exist unified algorithmic approaches that automatically adapt to many of these divergence measures simultaneously.
  We show that this is indeed the case for a large family of divergences proposed across classification and regression tasks, as they all happen to upper-bound the same measure of continuity between source and target risks, which we refer to as a weak modulus of transfer. This more unified view allows us, first, to identify algorithmic approaches that are simultaneously adaptive to these various divergence measures via a reduction to particular confidence sets. Second, it allows for a more refined understanding of the statistical limits of transfer under such divergences, and in particular, reveals regimes with faster rates than might be expected under coarser lenses.
  We then turn to situations that are not well captured by the weak modulus and corresponding divergences: these are situations where the aggregate of source and target data can improve target performance significantly beyond what's possible with either source or target data alone. We show that common such situations -- as may arise, e.g., under certain causal models with spurious correlations -- are well described by a so-called strong modulus of transfer which supersedes the weak modulus. We finally show that the strong modulus also admits adaptive procedures, which achieve near optimal rates in terms of the unknown strong modulus, and therefore apply in more general settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16189v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steve Hanneke, Samory Kpotufe</dc:creator>
    </item>
    <item>
      <title>Language all the way down: Grammatical structures in mathematics</title>
      <link>https://arxiv.org/abs/2410.07569</link>
      <description>arXiv:2410.07569v2 Announce Type: replace-cross 
Abstract: The ability to read, write, and speak mathematics is critical to students becoming comfortable with statistical models and skills. Faster development of those skills may act as encouragement to further engage with the discipline. Vocabulary has been the focus of scholarship in existing literature on the linguistics of mathematics and statistics but there are structures such as grammar that go beyond the content of words and symbols. Here I introduce ideas for grammar structures through a sequence of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07569v2</guid>
      <category>stat.OT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tess O'Brien</dc:creator>
    </item>
    <item>
      <title>Online Clustering with Bandit Information</title>
      <link>https://arxiv.org/abs/2501.11421</link>
      <description>arXiv:2501.11421v3 Announce Type: replace-cross 
Abstract: We study the problem of online clustering within the multi-armed bandit framework under the fixed confidence setting. In this multi-armed bandit problem, we have $M$ arms, each providing i.i.d. samples that follow a multivariate Gaussian distribution with an {\em unknown} mean and a known unit covariance. The arms are grouped into $K$ clusters based on the distance between their means using the Single Linkage (SLINK) clustering algorithm on the means of the arms. Since the true means are unknown, the objective is to obtain the above clustering of the arms with the minimum number of samples drawn from the arms, subject to an upper bound on the error probability. We introduce a novel algorithm, Average Tracking Bandit Online Clustering (ATBOC), and prove that this algorithm is order optimal, meaning that the upper bound on its expected sample complexity for given error probability $\delta$ is within a factor of 2 of an instance-dependent lower bound as $\delta \rightarrow 0$. Furthermore, we propose a computationally more efficient algorithm, Lower and Upper Confidence Bound-based Bandit Online Clustering (LUCBBOC), inspired by the LUCB algorithm for best arm identification. Simulation results demonstrate that the performance of LUCBBOC is comparable to that of ATBOC. We numerically assess the effectiveness of the proposed algorithms through numerical experiments on both synthetic datasets and the real-world MovieLens dataset. To the best of our knowledge, this is the first work on bandit online clustering that allows arms with different means in a cluster and $K$ greater than 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11421v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G Dhinesh Chandran, Srinivas Reddy Kota, Srikrishna Bhashyam</dc:creator>
    </item>
    <item>
      <title>Variations on the Expectation due to Changes in the Probability Measure</title>
      <link>https://arxiv.org/abs/2502.02887</link>
      <description>arXiv:2502.02887v2 Announce Type: replace-cross 
Abstract: In this paper, closed-form expressions are presented for the variation of the expectation of a given function due to changes in the probability measure used for the expectation. They unveil interesting connections with Gibbs probability measures, mutual information, and lautum information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02887v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samir M. Perlaza, Gaetan Bisson</dc:creator>
    </item>
    <item>
      <title>One-Shot Learning for k-SAT</title>
      <link>https://arxiv.org/abs/2502.07135</link>
      <description>arXiv:2502.07135v2 Announce Type: replace-cross 
Abstract: Consider a $k$-SAT formula $\Phi$ where every variable appears at most $d$ times, and let $\sigma$ be a satisfying assignment of $\Phi$ sampled proportionally to $e^{\beta m(\sigma)}$ where $m(\sigma)$ is the number of variables set to true and $\beta$ is a real parameter. Given $\Phi$ and $\sigma$, can we learn the value of $\beta$ efficiently?
  This problem falls into a recent line of works about single-sample ("one-shot") learning of Markov random fields. The $k$-SAT setting we consider here was recently studied by Galanis, Kandiros, and Kalavasis (SODA'24) where they showed that single-sample learning is possible when roughly $d\leq 2^{k/6.45}$ and impossible when $d\geq (k+1) 2^{k-1}$. Crucially, for their impossibility results they used the existence of unsatisfiable instances which, aside from the gap in $d$, left open the question of whether the feasibility threshold for one-shot learning is dictated by the satisfiability threshold of $k$-SAT formulas of bounded degree.
  Our main contribution is to answer this question negatively. We show that one-shot learning for $k$-SAT is infeasible well below the satisfiability threshold; in fact, we obtain impossibility results for degrees $d$ as low as $k^2$ when $\beta$ is sufficiently large, and bootstrap this to small values of $\beta$ when $d$ scales exponentially with $k$, via a probabilistic construction. On the positive side, we simplify the analysis of the learning algorithm and obtain significantly stronger bounds on $d$ in terms of $\beta$. In particular, for the uniform case $\beta\rightarrow 0$ that has been studied extensively in the sampling literature, our analysis shows that learning is possible under the condition $d\lesssim 2^{k/2}$. This is nearly optimal (up to constant factors) in the sense that it is known that sampling a uniformly-distributed satisfying assignment is NP-hard for $d\gtrsim 2^{k/2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07135v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Galanis, Leslie Ann Goldberg, Xusheng Zhang</dc:creator>
    </item>
    <item>
      <title>Low-Rank Thinning</title>
      <link>https://arxiv.org/abs/2502.12063</link>
      <description>arXiv:2502.12063v5 Announce Type: replace-cross 
Abstract: The goal in thinning is to summarize a dataset using a small set of representative points. Remarkably, sub-Gaussian thinning algorithms like Kernel Halving and Compress can match the quality of uniform subsampling while substantially reducing the number of summary points. However, existing guarantees cover only a restricted range of distributions and kernel-based quality measures and suffer from pessimistic dimension dependence. To address these deficiencies, we introduce a new low-rank analysis of sub-Gaussian thinning that applies to any distribution and any kernel, guaranteeing high-quality compression whenever the kernel or data matrix is approximately low-rank. To demonstrate the broad applicability of the techniques, we design practical sub-Gaussian thinning approaches that improve upon the best known guarantees for approximating attention in transformers, accelerating stochastic gradient training through reordering, and distinguishing distributions in near-linear time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12063v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annabelle Michael Carrell, Albert Gong, Abhishek Shetty, Raaz Dwivedi, Lester Mackey</dc:creator>
    </item>
    <item>
      <title>Low degree conjecture implies sharp computational thresholds in stochastic block model</title>
      <link>https://arxiv.org/abs/2502.15024</link>
      <description>arXiv:2502.15024v2 Announce Type: replace-cross 
Abstract: We investigate implications of the (extended) low-degree conjecture (recently formalized in [MW23]) in the context of the symmetric stochastic block model. Assuming the conjecture holds, we establish that no polynomial-time algorithm can weakly recover community labels below the Kesten-Stigum (KS) threshold. In particular, we rule out polynomial-time estimators that, with constant probability, achieve correlation with the true communities that is significantly better than random. Whereas, above the KS threshold, polynomial-time algorithms are known to achieve constant correlation with the true communities with high probability[Mas14,AS15].
  To our knowledge, we provide the first rigorous evidence for the sharp transition in recovery rate for polynomial-time algorithms at the KS threshold. Notably, under a stronger version of the low-degree conjecture, our lower bound remains valid even when the number of blocks diverges. Furthermore, our results provide evidence of a computational-to-statistical gap in learning the parameters of stochastic block models.
  In contrast to prior work, which either (i) rules out polynomial-time algorithms for hypothesis testing with 1-o(1) success probability [Hopkins18, BBK+21a] under the low-degree conjecture, or (ii) rules out low-degree polynomials for learning the edge connection probability matrix [LG23], our approach provides stronger lower bounds on the recovery and learning problem.
  Our proof combines low-degree lower bounds from [Hopkins18, BBK+21a] with graph splitting and cross-validation techniques. In order to rule out general recovery algorithms, we employ the correlation preserving projection method developed in [HS17].</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15024v2</guid>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingqiu Ding, Yiding Hua, Lucas Slot, David Steurer</dc:creator>
    </item>
  </channel>
</rss>
