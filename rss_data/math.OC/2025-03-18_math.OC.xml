<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Mar 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimal Replenishment Policies for Industrial Vending Machines</title>
      <link>https://arxiv.org/abs/2503.13643</link>
      <description>arXiv:2503.13643v1 Announce Type: new 
Abstract: Industrial Vending Machines (IVMs) automate the dispensing of a variety of supplies like safety equipment and tools at customer sites, providing 24/7 access while tracking inventory in real-time. Industrial distribution companies typically manage the replenishment of IVMs using periodic schedules, which do not take advantage of these advanced real-time monitoring capabilities. We develop two approaches to optimize the long-term average cost of replenishments and stockouts per unit time: a state-dependent optimal control policy that jointly considers all inventory levels (referred to as trigger set policy) and a fixed cycle policy that optimizes replenishment frequency. We prove the monotonicity of the optimal trigger set policy and leverage it to design a computationally efficient approximate online control framework. Unlike existing methods, which typically handle a very limited number of items due to computational constraints, our approach scales to hundreds of items while achieving near-optimal performance. Leveraging transaction data from our industrial partner, we conduct an extensive set of numerical experiments to demonstrate this claim. Our results show that optimal fixed cycle replenishment reduces costs by 61.7 to 78.6% compared to current practice, with our online control framework delivering an additional 4.1 to 22.9% improvement. Our novel theoretical results provide practical tools for effective replenishment management in this modern vendor-managed inventory context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13643v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karina M. Sindermann, Esma S. Gel, Nesim K. Erkip</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained Covariance Steering for Discrete-Time Markov Jump Linear Systems</title>
      <link>https://arxiv.org/abs/2503.13675</link>
      <description>arXiv:2503.13675v1 Announce Type: new 
Abstract: In this paper, we propose a novel convex optimization framework to solve the optimal covariance steering problem for discrete-time Markov Jump Linear Systems (MJLS) with chance constraints. We derive the analytical expressions for the mean and covariance trajectories of time-varying discrete-time MJLS and show that they cannot be separated even without chance constraints, unlike the single-mode dynamics case. To solve the covariance steering problem, we propose a two-step convex optimization framework, which optimizes the mean and covariance subproblems sequentially. Further, we use Gaussian approximations to incorporate chance constraints and propose an iterative optimization framework to solve the chance-constrained covariance steering problem. Both problems are originally nonconvex, and we derive convex relaxations which are proved to be lossless at optimality using the Karush-Kuhn-Tucker (KKT) conditions. Numerical simulations demonstrate the proposed method by achieving target covariances while respecting chance constraints under Gaussian noise and Markovian jump dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13675v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaurya Shrivastava, Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Value-Oriented Forecast Combinations for Unit Commitment</title>
      <link>https://arxiv.org/abs/2503.13677</link>
      <description>arXiv:2503.13677v1 Announce Type: new 
Abstract: Value-oriented forecasts for two-stage power system operational problems have been demonstrated to reduce cost, but prove to be computationally challenging for large-scale systems because the underlying optimization problem must be internalized into the forecast model training. Therefore, existing approaches typically scale poorly in the usable training data or require relaxations of the underlying optimization. This paper presents a method for value-oriented forecast combinations using progressive hedging, which unlocks high-fidelity, at-scale models and large-scale datasets in training. We also derive a direct one-shot training model for reference and study how different modifications of the training model impact the solution quality. Our method reduces operation cost by 1.8% on average and trains forecast combinations for a 2736-bus test system with one year of data within 20 hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13677v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehrnoush Ghazanfariharandi, Robert Mieth</dc:creator>
    </item>
    <item>
      <title>Young measure relaxation gaps for controllable systems with smooth state constraints</title>
      <link>https://arxiv.org/abs/2503.13776</link>
      <description>arXiv:2503.13776v1 Announce Type: new 
Abstract: In this article, we tackle the problem of the existence of a gap corresponding to Young measure relaxations for state-constrained optimal control problems. We provide a counterexample proving that a gap may occur in a very regular setting, namely for a smooth controllable system state-constrained to the closed unit ball, provided that the Lagrangian density (i.e., the running cost) is non-convex in the control variables. The example is constructed in the setting of sub-Riemannian geometry with the core ingredient being an unusual admissible curve that exhibits a certain form of resistance to state-constrained approximation. Specifically, this curve cannot be approximated by neighboring admissible curves while obeying the state constraint due to the intricate nature of the dynamics near the boundary of the constraint set. Our example also presents an occupation measure relaxation gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13776v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Augier, Milan Korda, Rodolfo Rios-Zertuche</dc:creator>
    </item>
    <item>
      <title>Sufficient conditions for the absence of relaxation gaps in state-constrained optimal control</title>
      <link>https://arxiv.org/abs/2503.13780</link>
      <description>arXiv:2503.13780v1 Announce Type: new 
Abstract: This work presents new sufficient conditions for the absence of a gap corresponding to Young measure and occupation measure relaxations for constrained optimal control problems. Unlike existing conditions, these sufficient conditions do not rely on convexity of the Lagrangian or the set of admissible velocities. We use these conditions to derive new bounds for the size of the relaxation gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13780v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Augier, Milan Korda, Rodolfo Rios-Zertuche</dc:creator>
    </item>
    <item>
      <title>General mean-field stochastic linear quadratic control problem driven by L\'evy processes with random coefficients</title>
      <link>https://arxiv.org/abs/2503.13835</link>
      <description>arXiv:2503.13835v1 Announce Type: new 
Abstract: This paper studies a stochastic mean-field linear-quadratic optimal control problem with random coefficients. The state equation is a general linear stochastic differential equation with mean-field terms $\EE X(t)$ and $\EE u(t)$ of the state and the control processes and is driven by a Brownian motion and a Poisson random measure. By the coupled system of Riccati equations, an explicit expressions for the optimal state feedback control is obtained. As a by-product, the non-homogeneous stochastic linear-quadratic control problem with random coefficients and L\'evy driving noises is also studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13835v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanyan Tang, Jie Xiong</dc:creator>
    </item>
    <item>
      <title>On the invariance of super-linearization under polynomial automorphisms</title>
      <link>https://arxiv.org/abs/2503.13849</link>
      <description>arXiv:2503.13849v1 Announce Type: new 
Abstract: We prove that the super-linearizability of polynomial systems is preserved by all currently known classes of polynomial automorphisms of $\R^n$. We then establish connections between such automorphisms and a sufficient condition for super-linearizability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13849v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anmol Harshana, Mohamed-Ali Belabbas</dc:creator>
    </item>
    <item>
      <title>A Relaxed Wasserstein Distance Formulation for Mixtures of Radially Contoured Distributions</title>
      <link>https://arxiv.org/abs/2503.13893</link>
      <description>arXiv:2503.13893v1 Announce Type: new 
Abstract: Recently, a Wasserstein-type distance for Gaussian mixture models has been proposed. However, that framework can only be generalized to identifiable mixtures of general elliptically contoured distributions whose components come from the same family and satisfy marginal consistency. In this paper, we propose a simple relaxed Wasserstein distance for identifiable mixtures of radially contoured distributions whose components can come from different families. We show some properties of this distance and that its definition does not require marginal consistency. We apply this distance in color transfer tasks and compare its performance with the Wasserstein-type distance for Gaussian mixture models in an experiment. The error of our method is more stable and the color distribution of our output image is more desirable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13893v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyu Chen, Zetian Wang, Yunxin Zhang</dc:creator>
    </item>
    <item>
      <title>Controlled Optimization with a Prescribed Finite-Time Convergence Using a Time Varying Feedback Gradient Flow</title>
      <link>https://arxiv.org/abs/2503.13910</link>
      <description>arXiv:2503.13910v1 Announce Type: new 
Abstract: From the perspective of control theory, the gradient descent optimization methods can be regarded as a dynamic system where various control techniques can be designed to enhance the performance of the optimization method. In this paper, we propose a prescribed finite-time convergent gradient flow that uses time-varying gain nonlinear feedback that can drive the states smoothly towards the minimum. This idea is different from the traditional finite-time convergence algorithms that relies on fractional-power or signed gradient as a nonlinear feedback, that is proved to have finite/fixed time convergence satisfying strongly convex or the Polyak-{\L}ojasiewicz (P{\L}) inequality, where due to its nature, the proposed approach was shown to achieve this property for both strongly convex function, and for those satisfies Polyak-{\L}ojasiewic inequality. Our method is proved to converge in a prescribed finite time via Lyapunov theory. Numerical experiments were presented to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13910v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osama F. Abdel Aal, Necdet Sinan Ozbek, Jairo Viola, YangQuan Chen</dc:creator>
    </item>
    <item>
      <title>First-Order Projected Algorithms With the Same Linear Convergence Rates as Their Unconstrained Counterparts</title>
      <link>https://arxiv.org/abs/2503.13965</link>
      <description>arXiv:2503.13965v1 Announce Type: new 
Abstract: In this paper, we propose a systematic approach for constructing first-order projected algorithms for optimization problems with general set constraints. These projected algorithms build upon their unconstrained counterparts written in a Lur'e form and retain the same linear convergence rates, provided a quadratic Lyapunov function exists for the unconstrained dynamics. In the convergence analysis, we show that the projection remains invariant under the linear transformation associated with the Lyapunov matrix, and establish the contraction of the composition mappings. Our results indicate that, when analyzing worst-case convergence rates or synthesizing controllers for general first-order algorithms, it suffices to focus solely on the unconstrained dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13965v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmou Li, Ioannis Lestas, Masaaki Nagahara</dc:creator>
    </item>
    <item>
      <title>Variable smoothing algorithm for inner-loop-free DC composite optimizations</title>
      <link>https://arxiv.org/abs/2503.13990</link>
      <description>arXiv:2503.13990v1 Announce Type: new 
Abstract: We propose a variable smoothing algorithm for minimizing a nonsmooth and nonconvex cost function. The cost function is the sum of a smooth function and a composition of a difference-of-convex (DC) function with a smooth mapping. At each step of our algorithm, we generate a smooth surrogate function by using the Moreau envelope of each weakly convex function in the DC function, and then perform the gradient descent update of the surrogate function. The proposed algorithm does not require any inner loop unlike many existing algorithms for DC problem. We also present a convergence analysis in terms of a DC critical point for the proposed algorithm as well as its application to robust phase retrieval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13990v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kumataro Yazawa, Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization with Lower Confidence Bounds for Minimization Problems with Known Outer Structure</title>
      <link>https://arxiv.org/abs/2503.14015</link>
      <description>arXiv:2503.14015v1 Announce Type: new 
Abstract: This paper considers Bayesian optimization (BO) for problems with known outer problem structure. In contrast to the classic BO setting, where the objective function itself is unknown and needs to be iteratively estimated from noisy observations, we analyze the case where the objective has a known outer structure - given in terms of a loss function - while the inner structure - an unknown input-output model - is again iteratively estimated from noisy observations of the model outputs. We introduce a novel lower confidence bound algorithm for this particular problem class which exploits the known outer problem structure. The proposed method is analyzed in terms of regret for the special case of convex loss functions and probabilistic parametric models which are linear in the uncertain parameters. Numerical examples illustrate the superior performance of structure-exploiting methods compared to structure-agnostic approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14015v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katrin Baumg\"artner, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Linear quadratic control of parabolic-like evolutions with memory of the inputs</title>
      <link>https://arxiv.org/abs/2503.14046</link>
      <description>arXiv:2503.14046v1 Announce Type: new 
Abstract: A study of the linear quadratic (LQ) control problem on a finite time interval for a model equation in Hilbert spaces which comprehends the memory of the inputs was performed recently by the authors. The outcome included a closed-loop representation of the unique optimal control, along with the derivation of a related coupled system of three quadratic (operator) equations which is shown to be well-posed. Notably, in the absence of memory the above elements -- namely, formula and system -- reduce to the known feedback formula and single differential Riccati equation, respectively. In this work we take the next natural step, and prove the said results for a class of evolutions where the control operator is no longer bounded. These findings appear to be the first ones of their kind; furthermore, they extend the classical theory of the LQ problem and Riccati equations for parabolic partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14046v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Acquistapace, Francesca Bucci</dc:creator>
    </item>
    <item>
      <title>Modular Distributed Nonconvex Learning with Error Feedback</title>
      <link>https://arxiv.org/abs/2503.14055</link>
      <description>arXiv:2503.14055v1 Announce Type: new 
Abstract: In this paper, we design a novel distributed learning algorithm using stochastic compressed communications. In detail, we pursue a modular approach, merging ADMM and a gradient-based approach, benefiting from the robustness of the former and the computational efficiency of the latter. Additionally, we integrate a stochastic integral action (error feedback) enabling almost sure rejection of the compression error. We analyze the resulting method in nonconvex scenarios and guarantee almost sure asymptotic convergence to the set of stationary points of the problem. This result is obtained using system-theoretic tools based on stochastic timescale separation. We corroborate our findings with numerical simulations in nonconvex classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14055v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guido Carnevale, Nicola Bastianello</dc:creator>
    </item>
    <item>
      <title>Sparse control in microscopic and mean-field leader-follower models</title>
      <link>https://arxiv.org/abs/2503.14113</link>
      <description>arXiv:2503.14113v1 Announce Type: new 
Abstract: This work investigates the decay properties of Lyapunov functions in leader-follower systems seen as a sparse control framework. Starting with a microscopic representation, we establish conditions under which the total Lyapunov function, encompassing both leaders and followers, exhibits exponential decay. The analysis is extended to a hybrid setting combining a mean-field description for followers and a microscopic model for leaders. We identify sufficient conditions on control gain and interaction strengths that guarantee stabilization of the linear system towards a target state. The results highlight the influence of sparse control and interaction parameters in achieving coordinated behavior in multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14113v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melanie Harms, Michael Herty, Chiara Segala, Eva Zerz</dc:creator>
    </item>
    <item>
      <title>Analytical Strategies and Winning Conditions for Elliptic-Orbit Target-Attacker-Defender Game</title>
      <link>https://arxiv.org/abs/2503.14252</link>
      <description>arXiv:2503.14252v1 Announce Type: new 
Abstract: This paper proposes an analytical framework for the orbital Target-Attacker-Defender game with a non-maneuvering target along elliptic orbits. Focusing on the linear quadratic game, we derive an analytical solution to the matrix Riccati equation, which yields analytical Nash-equilibrium strategies for all players. Based on the analytical strategies, we derive the analytical form of the necessary and sufficient winning conditions for the attacker. The simulation results show good consistency between the analytical and numerical methods, exhibiting 0.004$\%$ relative error in the cost function. The analytical method achieves over 99.9$\%$ reduction in CPU time compared to the conventional numerical method, strengthening the advantage of developing the analytical strategies. Furthermore, we verify the proposed winning conditions and investigate the effects of eccentricity on the game outcomes. Our analysis reveals that for games with hovering initial states, the initial position of the defender should be constrained inside a mathematically definable set to ensure that the attacker wins the game. This constrained set furthermore permits geometric interpretation through our proposed framework. This work establishes the analytical framework for orbital Target-Attacker-Defender games, providing fundamental insights into the solution analysis of the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14252v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuyue Fu, Shengping Gong, Di Wu, Peng Shi</dc:creator>
    </item>
    <item>
      <title>Controllability concepts for mean-field dynamics with reduced-rank coefficients</title>
      <link>https://arxiv.org/abs/2503.14278</link>
      <description>arXiv:2503.14278v1 Announce Type: new 
Abstract: In this paper we explore several novel notions of exact controllability for mean-field linear controlled stochastic differential equations (SDEs). A key feature of our study is that the noise coefficient is not required to be of full rank. We begin by demonstrating that classical exact controllability with $\mathbb{L}^2$-controls necessarily requires both rank conditions on the noise introduced in [8] and subsequent works. When these rank conditions are not satisfied, we introduce alternative rank requirements on the drift, which enable exact controllability by relaxing the regularity of the controls. In cases where both the aforementioned rank conditions fail, we propose and characterize a new notion of exact terminal controllability to normal laws (ETCNL). Additionally, we investigate a new class of Wasserstein-set-valued backward SDEs that arise naturally associated to ETCNL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14278v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dan Goreac, Juan Li, Xinru Zhang</dc:creator>
    </item>
    <item>
      <title>Risk-Sensitive Model Predictive Control for Interaction-Aware Planning -- A Sequential Convexification Algorithm</title>
      <link>https://arxiv.org/abs/2503.14328</link>
      <description>arXiv:2503.14328v1 Announce Type: new 
Abstract: This paper considers risk-sensitive model predictive control for stochastic systems with a decision-dependent distribution. This class of systems is commonly found in human-robot interaction scenarios. We derive computationally tractable convex upper bounds to both the objective function, and to frequently used penalty terms for collision avoidance, allowing us to efficiently solve the generally nonconvex optimal control problem as a sequence of convex problems. Simulations of a robot navigating a corridor demonstrate the effectiveness and the computational advantage of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14328v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renzi Wang, Mathijs Schuurmans, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Polyhedral reconstruction via Boundary Control method</title>
      <link>https://arxiv.org/abs/2503.14367</link>
      <description>arXiv:2503.14367v1 Announce Type: new 
Abstract: We study uniqueness of an elliptic Riemannian polyhedron using the elliptic version for Boundary Control method, which we presented in [1]. We also present interface detection criteria for hyperbolic Riemannian manifolds through introduction of the waveguide notion, the four-wave mixing notion, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14367v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitra Kyriakopoulou</dc:creator>
    </item>
    <item>
      <title>Approximation of diffeomorphisms for quantum state transfers</title>
      <link>https://arxiv.org/abs/2503.14450</link>
      <description>arXiv:2503.14450v1 Announce Type: new 
Abstract: In this paper, we seek to combine two emerging standpoints in control theory. On the one hand, recent advances in infinite-dimensional geometric control have unlocked a method for controlling (with arbitrary precision and in arbitrarily small times) state transfers for bilinear Schr\"odinger PDEs posed on a Riemannian manifold $M$. In particular, these arguments rely on controllability results in the group of the diffeomorphisms of $M$. On the other hand, using tools of $\Gamma$-convergence, it has been proved that we can phrase the retrieve of a diffeomorphism of $M$ as an ensemble optimal control problem. More precisely, this is done by employing a control-affine system for \emph{simultaneously} steering a finite swarm of points towards the respective targets. Here we blend these two theoretical approaches and numerically find control laws driving state transitions (such as eigenstate transfers) in a bilinear Schr\"{o}dinger PDE posed on the torus. Such systems have experimental relevance and are currently used to model rotational dynamics of molecules, and cold atoms trapped in periodic optical lattices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14450v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenio Pozzoli, Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>La M\'ethode du Gradient Proxim\'e</title>
      <link>https://arxiv.org/abs/2503.14479</link>
      <description>arXiv:2503.14479v1 Announce Type: new 
Abstract: English version of abstract for "The Proximal Gradient Method": The proximal gradient method is a splitting algorithm for the minimization of the sum of two convex functions, one of which is smooth. It has applications in areas such as mechanics, inverse problems, machine learning, image reconstruction, variational inequalities, statistics, operations research, and optimal transportation. Its formalism encompasses a wide variety of numerical methods in optimization such as gradient descent, projected gradient, iterative thresholding, alternating projections, the constrained Landweber method, as well as various algorithms in statistics and sparse data analysis. This paper aims at providing an account of the main properties of the proximal gradient method and to discuss some of its applications. --  --  --  --  -- -
  R\'esum\'e : La m\'ethode du gradient proxim\'e est un algorithme d'\'eclatement pour la minimisation de la somme de deux fonctions convexes, dont l'une est lisse. Elle trouve des applications dans des domaines tels que la m\'ecanique, le traitement du signal, les probl\`emes inverses, l'apprentissage automatique, la reconstruction d'images, les in\'equations variationnelles, les statistiques, la recherche op\'erationnelle et le transport optimal. Son formalisme englobe une grande vari\'et\'e de m\'ethodes num\'eriques en optimisation, telles que la descente de gradient, le gradient projet\'e, la m\'ethode de seuillage it\'eratif, la m\'ethode des projections altern\'ees, la m\'ethode de Landweber contrainte, ainsi que divers algorithmes en statistique et en analyse parcimonieuse de donn\'ees. Cet article vise \`a donner un aper\c{c}u des principales propri\'et\'es de la m\'ethode du gradient proxim\'e et d'aborder certaines de ses applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14479v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes</dc:creator>
    </item>
    <item>
      <title>Ranking matters: Does the new format select the best teams for the knockout phase in the UEFA Champions League?</title>
      <link>https://arxiv.org/abs/2503.13569</link>
      <description>arXiv:2503.13569v1 Announce Type: cross 
Abstract: Starting in the 2024/25 season, the Union of European Football Associations (UEFA) has fundamentally changed the format of its club competitions: the group stage has been replaced by a league phase played by 36 teams in an incomplete round robin format. This makes ranking the teams based on their results challenging because teams play against different sets of opponents, whose strengths vary. In this research note, we apply several well-known ranking methods for incomplete round robin tournaments to the 2024/25 UEFA Champions League league phase. Our results show that it is doubtful whether the currently used point-based system provides the best ranking of the teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13569v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o, Karel Devriesere, Dries Goossens, Andr\'as Gyimesi, Roel Lambers, Frits Spieksma</dc:creator>
    </item>
    <item>
      <title>Quantum EigenGame for excited state calculation</title>
      <link>https://arxiv.org/abs/2503.13644</link>
      <description>arXiv:2503.13644v1 Announce Type: cross 
Abstract: Computing the excited states of a given Hamiltonian is computationally hard for large systems, but methods that do so using quantum computers scale tractably. This problem is equivalent to the PCA problem where we are interested in decomposing a matrix into a collection of principal components. Classically, PCA is a well-studied problem setting, for which both centralized and distributed approaches have been developed. On the distributed side, one recent approach is that of EigenGame, a game-theoretic approach to finding eigenvectors where each eigenvector reaches a Nash equilibrium either sequentially or in parallel. With this work, we extend the EigenGame algorithm for both a $0^\text{th}$-order approach and for quantum computers, and harness the framework that quantum computing provides in computing excited states. Results show that using the Quantum EigenGame allows us to converge to excited states of a given Hamiltonian without the need of a deflation step. We also develop theory on error accumulation for finite-differences and parameterized approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13644v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Quiroga, Jason Han, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>Improved Scalable Lipschitz Bounds for Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2503.14297</link>
      <description>arXiv:2503.14297v1 Announce Type: cross 
Abstract: Computing tight Lipschitz bounds for deep neural networks is crucial for analyzing their robustness and stability, but existing approaches either produce relatively conservative estimates or rely on semidefinite programming (SDP) formulations (namely the LipSDP condition) that face scalability issues. Building upon ECLipsE-Fast, the state-of-the-art Lipschitz bound method that avoids SDP formulations, we derive a new family of improved scalable Lipschitz bounds that can be combined to outperform ECLipsE-Fast. Specifically, we leverage more general parameterizations of feasible points of LipSDP to derive various closed-form Lipschitz bounds, avoiding the use of SDP solvers. In addition, we show that our technique encompasses ECLipsE-Fast as a special case and leads to a much larger class of scalable Lipschitz bounds for deep neural networks. Our empirical study shows that our bounds improve ECLipsE-Fast, further advancing the scalability and precision of Lipschitz estimation for large neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14297v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Usman Syed, Bin Hu</dc:creator>
    </item>
    <item>
      <title>Assortment Optimization under the Decision Forest Model</title>
      <link>https://arxiv.org/abs/2103.14067</link>
      <description>arXiv:2103.14067v3 Announce Type: replace 
Abstract: We study the problem of finding the optimal assortment that maximizes expected revenue under the decision forest model, a recently proposed nonparametric choice model that is capable of representing any discrete choice model and in particular, can be used to represent non-rational customer behavior. This problem is of practical importance because it allows a firm to tailor its product offerings to profitably exploit deviations from rational customer behavior, but at the same time is challenging due to the extremely general nature of the decision forest model. We approach this problem from a mixed-integer optimization perspective and present two different formulations. We theoretically compare the two formulations in strength, and analyze when they are integral in the special case of a single tree. We further propose a methodology for solving the two formulations at a large-scale based on Benders decomposition, and show that the Benders subproblem can be solved efficiently by primal dual greedy algorithms when the master solution is fractional for one of the formulations, and in closed form when the master solution is binary for both formulations. Using synthetically generated instances, we demonstrate the practical tractability of our formulations and our Benders decomposition approach, and their edge over heuristic approaches. In a case study based on a real-world transaction data, we demonstrate that our proposed approach can factor the behavioral anomalies observed in consumer choice into assortment decision and create higher revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.14067v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi-Chun Akchen, Velibor V. Mi\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>Accelerated Minimax Algorithms Flock Together</title>
      <link>https://arxiv.org/abs/2205.11093</link>
      <description>arXiv:2205.11093v2 Announce Type: replace 
Abstract: Several new accelerated methods in minimax optimization and fixed-point iterations have recently been discovered, and, interestingly, they rely on a mechanism distinct from Nesterov's momentum-based acceleration. In this work, we show that these accelerated algorithms exhibit what we call the merging path (MP) property; the trajectories of these algorithms merge quickly. Using this novel MP property, we establish point convergence of existing accelerated minimax algorithms and derive new state-of-the-art algorithms for the strongly-convex-strongly-concave setup and for the prox-grad setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.11093v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/22M1504597</arxiv:DOI>
      <arxiv:journal_reference>SIAM journal on optimization, 2025-03, Vol.35 (1), p.180-209</arxiv:journal_reference>
      <dc:creator>TaeHo Yoon, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Convergence and Inference of Stream SGD, with Applications to Queueing Systems and Inventory Control</title>
      <link>https://arxiv.org/abs/2309.09545</link>
      <description>arXiv:2309.09545v2 Announce Type: replace 
Abstract: Stream stochastic gradient descent (SGD) is a simple and efficient method for solving online optimization problems in operations research (OR), where data is generated by parameter-dependent Markov chains. Unlike traditional approaches which require increasing batch sizes during iterations, stream SGD uses a single sample per iteration, significantly improving sample efficiency. This paper establishes a systematic framework for analyzing stream SGD, leveraging the Poisson equation solution to address gradient bias and statistical dependence. We prove optimal O(1/T) convergence rates and the state-of-the-art O(log T) regret, while also introducing an online inference method for uncertainty quantification and supporting it by a novel functional central limit theorem. We propose a novel Wasserstein-type divergence to describe the framework's conditions, which makes the assumptions in question directly verified via coupling techniques tailored to underlying OR models. We consider applications in queueing systems and inventory management, demonstrating the practicality and broad relevance, as well as providing new insights into the effectiveness of stream SGD in OR fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09545v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Jiadong Liang, Xinyun Chen, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Deck of Cards method for Hierarchical, Robust and Stochastic Ordinal Regression</title>
      <link>https://arxiv.org/abs/2405.04313</link>
      <description>arXiv:2405.04313v3 Announce Type: replace 
Abstract: We consider the recently introduced application of the Deck of Cards Method (DCM) to ordinal regression proposing two extensions related to two main research trends in Multiple Criteria Decision Aiding, namely scaling and ordinal regression generalizations. On the one hand, procedures, different from DCM (e.g. AHP, BWM, MACBETH) to collect and elaborate Decision Maker's (DM's) preference information are considered to define an overall evaluation of reference alternatives. On the other hand, Robust Ordinal Regression and Stochastic Multicriteria Acceptability Analysis are used to offer the DM more detailed and realistic decision-support outcomes. More precisely, we take into account preference imprecision and indetermination through a set of admissible comprehensive evaluations of alternatives provided by the whole set of value functions compatible with DM's preference information rather than the univocal assessment obtained from a single value function. In addition, we also consider alternatives evaluated on a set of criteria hierarchically structured. The methodology we propose allows the DM to provide precise or imprecise information at different levels of the hierarchy of criteria. Like scaling procedures, the compatible value function we consider can be of a different nature, such as weighted sum, linear or general monotone value function, or Choquet integral. Consequently, the approach we propose is versatile and well-equipped to be adapted to DM's characteristics and requirements. The applicability of the proposed methodology is shown by a didactic example based on a large ongoing research project in which Italian regions are evaluated on criteria representing Circular Economy, Innovation-Driven Development and Smart Specialization Strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04313v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salvatore Corrente, Salvatore Greco, Silvano Zappal\'a</dc:creator>
    </item>
    <item>
      <title>Congestion and Penalization in Optimal Transport</title>
      <link>https://arxiv.org/abs/2410.07363</link>
      <description>arXiv:2410.07363v4 Announce Type: replace 
Abstract: We introduce a novel model based on the discrete optimal transport problem that incorporates congestion costs and replaces traditional constraints with weighted penalization terms. This approach better captures real-world scenarios characterized by demand-supply imbalances and heterogeneous congestion costs. We develop an analytical method for computing interior solutions, which proves particularly useful under specific conditions. Additionally, we propose an $O((N+L)N^2 L^2)$ algorithm to compute the optimal interior solution. For certain cases, we derive a closed-form solution and conduct a comparative statics analysis. Finally, we present examples demonstrating how our model yields solutions distinct from classical approaches, leading to more accurate outcomes in specific contexts, such as Peru's health and education sectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07363v4</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcelo Gallardo, Manuel Loaiza, Jorge Ch\'avez</dc:creator>
    </item>
    <item>
      <title>Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping</title>
      <link>https://arxiv.org/abs/2412.19529</link>
      <description>arXiv:2412.19529v3 Announce Type: replace 
Abstract: Recently, the study of heavy-tailed noises in first-order nonconvex stochastic optimization has gotten a lot of attention since it was recognized as a more realistic condition as suggested by many empirical observations. Specifically, the stochastic noise (the difference between the stochastic and true gradient) is considered to have only a finite $\mathfrak{p}$-th moment where $\mathfrak{p}\in\left(1,2\right]$ instead of assuming it always satisfies the classical finite variance assumption. To deal with this more challenging setting, people have proposed different algorithms and proved them to converge at an optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate for smooth objectives after $T$ iterations. Notably, all these new-designed algorithms are based on the same technique - gradient clipping. Naturally, one may want to know whether the clipping method is a necessary ingredient and the only way to guarantee convergence under heavy-tailed noises. In this work, by revisiting the existing Batched Normalized Stochastic Gradient Descent with Momentum (Batched NSGDM) algorithm, we provide the first convergence result under heavy-tailed noises but without gradient clipping. Concretely, we prove that Batched NSGDM can achieve the optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate even under the relaxed smooth condition. More interestingly, we also establish the first $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{2\mathfrak{p}}})$ convergence rate in the case where the tail index $\mathfrak{p}$ is unknown in advance, which is arguably the common scenario in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19529v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Safe adaptive NMPC using ellipsoidal tubes</title>
      <link>https://arxiv.org/abs/2501.14670</link>
      <description>arXiv:2501.14670v2 Announce Type: replace 
Abstract: A computationally efficient nonlinear Model Predictive Control (NMPC) algorithm is proposed for safe learning-based control with a system model represented by an incompletely known affine combination of basis functions and subject to additive set-bounded disturbances. The proposed algorithm employs successive linearization around predicted trajectories and accounts for the uncertain components of future states due to linearization, modelling errors and disturbances using ellipsoidal sets centered on the predicted nominal state trajectory. An ellipsoidal tube-based approach ensures satisfaction of constraints on control variables and model states. Feasibility is ensured using local bounds on linearization errors and a procedure based on a backtracking line search. We combine the approach with a set membership parameter estimation strategy in numerical simulations. We show that the ellipsoidal embedding of the predicted uncertainty scales favourably with the problem size. The resulting algorithm is recursively feasible and provides closed-loop stability and performance guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14670v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Buerger, Mark Cannon</dc:creator>
    </item>
    <item>
      <title>Passive feedback control for nonlinear systems</title>
      <link>https://arxiv.org/abs/2502.04987</link>
      <description>arXiv:2502.04987v2 Announce Type: replace 
Abstract: Dynamical systems can be used to model a broad class of physical processes, and conservation laws give rise to system properties like passivity or port-Hamiltonian structure. An important problem in practical applications is to steer dynamical systems to prescribed target states, and feedback controllers combining a regulator and an observer are a powerful tool to do so. However, controllers designed using classical methods do not necessarily obey energy principles, which makes it difficult to model the controller-plant interaction in a structured manner. In this paper, we show that a particular choice of the observer gain gives rise to passivity properties of the controller that are independent of the plant structure. Furthermore, we state conditions for the controller to have a port-Hamiltonian realization and show that a model order reduction scheme can be deduced using the framework of nonlinear balanced truncation. In addition, we propose a novel passivity preserving discrete gradient scheme for the time discretization of passive systems. To illustrate our results, we numerically realize the controller using the policy iteration and compare it to a controller where the observer gain is given by the extended Kalman filter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04987v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Breiten, Attila Karsai</dc:creator>
    </item>
    <item>
      <title>Lower Bounds and Accelerated Algorithms in Distributed Stochastic Optimization with Communication Compression</title>
      <link>https://arxiv.org/abs/2305.07612</link>
      <description>arXiv:2305.07612v2 Announce Type: replace-cross 
Abstract: Communication compression is an essential strategy for alleviating communication overhead by reducing the volume of information exchanged between computing nodes in large-scale distributed stochastic optimization. Although numerous algorithms with convergence guarantees have been obtained, the optimal performance limit under communication compression remains unclear.
  In this paper, we investigate the performance limit of distributed stochastic optimization algorithms employing communication compression. We focus on two main types of compressors, unbiased and contractive, and address the best-possible convergence rates one can obtain with these compressors. We establish the lower bounds for the convergence rates of distributed stochastic optimization in six different settings, combining strongly-convex, generally-convex, or non-convex functions with unbiased or contractive compressor types. To bridge the gap between lower bounds and existing algorithms' rates, we propose NEOLITHIC, a nearly optimal algorithm with compression that achieves the established lower bounds up to logarithmic factors under mild conditions. Extensive experimental results support our theoretical findings. This work provides insights into the theoretical limitations of existing compressors and motivates further research into fundamentally new compressor properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07612v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong He, Xinmeng Huang, Yiming Chen, Wotao Yin, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Level Set Teleportation: An Optimization Perspective</title>
      <link>https://arxiv.org/abs/2403.03362</link>
      <description>arXiv:2403.03362v2 Announce Type: replace-cross 
Abstract: We study level set teleportation, an optimization routine which tries to accelerate gradient descent (GD) by maximizing the gradient norm over a level set of the objective. While teleportation intuitively speeds-up GD via bigger steps, current work lacks convergence theory for convex functions, guarantees for solving the teleportation operator, and even clear empirical evidence showing this acceleration. We resolve these open questions. For convex functions satisfying Hessian stability, we prove that GD with teleportation obtains a combined sub-linear/linear convergence rate which is strictly faster than GD when the optimality gap is small. This is in sharp contrast to the standard (strongly) convex setting, where teleportation neither improves nor worsens convergence. To evaluate teleportation in practice, we develop a projected-gradient method requiring only Hessian-vector products. We use this to show that gradient methods with access to a teleportation oracle out-perform their standard versions on a variety of problems. We also find that GD with teleportation is faster than truncated Newton methods, particularly for non-convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03362v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Mishkin, Alberto Bietti, Robert M. Gower</dc:creator>
    </item>
    <item>
      <title>Generalized cyclic symmetric decompositions for the matrix multiplication tensor</title>
      <link>https://arxiv.org/abs/2404.16699</link>
      <description>arXiv:2404.16699v2 Announce Type: replace-cross 
Abstract: A new generalized cyclic symmetric structure in the factor matrices of polyadic decompositions of matrix multiplication tensors for non-square matrix multiplication is proposed to reduce the number of variables in the optimization problem and in this way improve the convergence. The structure is implemented in an existing numerical optimization algorithm. Extensive numerical experiments are given that the proposed structure indeed finds more (practical) decompositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16699v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charlotte Vermeylen, Marc Van Barel</dc:creator>
    </item>
    <item>
      <title>Sublinear Regret for a Class of Continuous-Time Linear-Quadratic Reinforcement Learning Problems</title>
      <link>https://arxiv.org/abs/2407.17226</link>
      <description>arXiv:2407.17226v3 Announce Type: replace-cross 
Abstract: We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an RL algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{\frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17226v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilie Huang, Yanwei Jia, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Cooperative distributed model predictive control for embedded systems: Experiments with hovercraft formations</title>
      <link>https://arxiv.org/abs/2409.13334</link>
      <description>arXiv:2409.13334v2 Announce Type: replace-cross 
Abstract: This paper presents experiments for embedded cooperative distributed model predictive control applied to a team of hovercraft floating on an air hockey table. The hovercraft collectively solve a centralized optimal control problem in each sampling step via a stabilizing decentralized real-time iteration scheme using the alternating direction method of multipliers. The efficient implementation does not require a central coordinator, executes onboard the hovercraft, and facilitates sampling intervals in the millisecond range. The formation control experiments showcase the flexibility of the approach on scenarios with point-to-point transitions, trajectory tracking, collision avoidance, and moving obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13334v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\"osta Stomberg, Roland Schwan, Andrea Grillo, Colin N. Jones, Timm Faulwasser</dc:creator>
    </item>
    <item>
      <title>Offline Hierarchical Reinforcement Learning via Inverse Optimization</title>
      <link>https://arxiv.org/abs/2410.07933</link>
      <description>arXiv:2410.07933v2 Announce Type: replace-cross 
Abstract: Hierarchical policies enable strong performance in many sequential decision-making problems, such as those with high-dimensional action spaces, those requiring long-horizon planning, and settings with sparse rewards. However, learning hierarchical policies from static offline datasets presents a significant challenge. Crucially, actions taken by higher-level policies may not be directly observable within hierarchical controllers, and the offline dataset might have been generated using a different policy structure, hindering the use of standard offline learning algorithms. In this work, we propose OHIO: a framework for offline reinforcement learning (RL) of hierarchical policies. Our framework leverages knowledge of the policy structure to solve the \textit{inverse problem}, recovering the unobservable high-level actions that likely generated the observed data under our hierarchical policy. This approach constructs a dataset suitable for off-the-shelf offline training. We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness. We investigate a variety of instantiations of our framework, both in direct deployment of policies trained offline and when online fine-tuning is performed. Code and data are available at https://ohio-offline-hierarchical-rl.github.io</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07933v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carolin Schmidt, Daniele Gammelli, James Harrison, Marco Pavone, Filipe Rodrigues</dc:creator>
    </item>
    <item>
      <title>Riemannian Variational Calculus: Optimal Trajectories Under Inertia, Gravity, and Drag Effects</title>
      <link>https://arxiv.org/abs/2410.09657</link>
      <description>arXiv:2410.09657v2 Announce Type: replace-cross 
Abstract: Robotic motion optimization often focuses on task-specific solutions, overlooking fundamental motion principles. Building on Riemannian geometry and the calculus of variations (often appearing as indirect methods of optimal control), we derive an optimal control equation that expresses general forces as functions of configuration and velocity, revealing how inertia, gravity, and drag shape optimal trajectories. Our analysis identifies three key effects: (i) curvature effects of inertia manifold, (ii) curvature effects of potential field, and (iii) shortening effects from resistive force. We validate our approach on a two-link manipulator and a UR5, demonstrating a unified geometric framework for understanding optimal trajectories beyond geodesic-based planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09657v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinwoo Choi, Alejandro Cabrera, Ross L. Hatton</dc:creator>
    </item>
    <item>
      <title>Koopman-based control of nonlinear systems with closed-loop guarantees</title>
      <link>https://arxiv.org/abs/2411.10359</link>
      <description>arXiv:2411.10359v3 Announce Type: replace-cross 
Abstract: In this paper, we provide a tutorial overview and an extension of a recently developed framework for data-driven control of unknown nonlinear systems with rigorous closed-loop guarantees. The proposed approach relies on the Koopman operator representation of the nonlinear system, for which a bilinear surrogate model is estimated based on data. In contrast to existing Koopman-based estimation procedures, we state guaranteed bounds on the approximation error using the stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) framework. The resulting surrogate model and the uncertainty bounds allow us to design controllers via robust control theory and sum-of-squares optimization, guaranteeing desirable properties for the closed-loop system. We present results on stabilization both in discrete and continuous time, and we derive a method for controller design with performance objectives. The benefits of the presented framework over established approaches are demonstrated with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10359v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Str\"asser, Julian Berberich, Manuel Schaller, Karl Worthmann, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Totally $\Delta$-modular IPs with two non-zeros in most rows</title>
      <link>https://arxiv.org/abs/2411.15282</link>
      <description>arXiv:2411.15282v2 Announce Type: replace-cross 
Abstract: Integer programs (IPs) on constraint matrices with bounded subdeterminants are conjectured to be solvable in polynomial time. We give a strongly polynomial time algorithm to solve IPs where the constraint matrix has bounded subdeterminants and at most two non-zeros per row after removing a constant number of rows and columns. This result extends the work by Fiorini, Joret, Weltge \&amp; Yuditsky (J. ACM 72(1), 1-50 (2025)) by allowing for additional, unifying constraints and variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15282v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Kober</dc:creator>
    </item>
    <item>
      <title>Memorization and Regularization in Generative Diffusion Models</title>
      <link>https://arxiv.org/abs/2501.15785</link>
      <description>arXiv:2501.15785v2 Announce Type: replace-cross 
Abstract: Diffusion models have emerged as a powerful framework for generative modeling. At the heart of the methodology is score matching: learning gradients of families of log-densities for noisy versions of the data distribution at different scales. When the loss function adopted in score matching is evaluated using empirical data, rather than the population loss, the minimizer corresponds to the score of a time-dependent Gaussian mixture. However, use of this analytically tractable minimizer leads to data memorization: in both unconditioned and conditioned settings, the generative model returns the training samples. This paper contains an analysis of the dynamical mechanism underlying memorization. The analysis highlights the need for regularization to avoid reproducing the analytically tractable minimizer; and, in so doing, lays the foundations for a principled understanding of how to regularize. Numerical experiments investigate the properties of: (i) Tikhonov regularization; (ii) regularization designed to promote asymptotic consistency; and (iii) regularizations induced by under-parameterization of a neural network or by early stopping when training a neural network. These experiments are evaluated in the context of memorization, and directions for future development of regularization are highlighted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15785v2</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Baptista, Agnimitra Dasgupta, Nikola B. Kovachki, Assad Oberai, Andrew M. Stuart</dc:creator>
    </item>
    <item>
      <title>Learning an Optimal Assortment Policy under Observational Data</title>
      <link>https://arxiv.org/abs/2502.06777</link>
      <description>arXiv:2502.06777v2 Announce Type: replace-cross 
Abstract: We study the fundamental problem of offline assortment optimization under the Multinomial Logit (MNL) model, where sellers must determine the optimal subset of the products to offer based solely on historical customer choice data. While most existing approaches to learning-based assortment optimization focus on the online learning of the optimal assortment through repeated interactions with customers, such exploration can be costly or even impractical in many real-world settings. In this paper, we consider the offline learning paradigm and investigate the minimal data requirements for efficient offline assortment optimization. To this end, we introduce Pessimistic Rank-Breaking (PRB), an algorithm that combines rank-breaking with pessimistic estimation. We prove that PRB is nearly minimax optimal by establishing the tight suboptimality upper bound and a nearly matching lower bound. This further shows that "optimal item coverage" - where each item in the optimal assortment appears sufficiently often in the historical data - is both sufficient and necessary for efficient offline learning. This significantly relaxes the previous requirement of observing the complete optimal assortment in the data. Our results provide fundamental insights into the data requirements for offline assortment optimization under the MNL model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06777v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Han, Han Zhong, Miao Lu, Jose Blanchet, Zhengyuan Zhou</dc:creator>
    </item>
  </channel>
</rss>
