<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Jan 2026 05:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From FPT Decision to FPT Enumeration</title>
      <link>https://arxiv.org/abs/2512.24137</link>
      <description>arXiv:2512.24137v1 Announce Type: new 
Abstract: Fixed-parameter tractable (FPT) algorithms have been successfully applied to many intractable problems -- with a focus on decision and optimization problems. Their aim is to confine the exponential explosion to some parameter, while the time complexity only depends polynomially on the instance size. In contrast, intractable enumeration problems have received comparatively little attention so far. The goal of this work is to study how FPT decision algorithms could be turned into FPT enumeration algorithms. We thus inspect several fundamental approaches for designing FPT decision or optimization algorithms and we present ideas how they can be extended to FPT enumeration algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24137v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadia Creignou, Timo Camillo Merkl, Reinhard Pichler, Daniel Unterberger</dc:creator>
    </item>
    <item>
      <title>Thin Tree Verification is coNP-Complete</title>
      <link>https://arxiv.org/abs/2512.25043</link>
      <description>arXiv:2512.25043v1 Announce Type: new 
Abstract: An $\alpha$-thin tree $T$ of a graph $G$ is a spanning tree such that every cut of $G$ has at most an $\alpha$ proportion of its edges in $T$. The Thin Tree Conjecture proposes that there exists a function $f$ such that for any $\alpha &gt; 0$, every $f(\alpha)$-edge-connected graph has an $\alpha$-thin tree. Aside from its independent interest, an algorithm which could efficiently construct an $O(1)/k$-thin tree for a given $k$-edge-connected graph would directly lead to an $O(1)$-approximation algorithm for the asymmetric travelling salesman problem (ATSP)(arXiv:0909.2849). However, it was not even known whether it is possible to efficiently verify that a given tree is $\alpha$-thin. We prove that determining the thinness of a tree is coNP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.25043v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alice Moayyedi</dc:creator>
    </item>
    <item>
      <title>Syndrome aware mitigation of logical errors</title>
      <link>https://arxiv.org/abs/2512.23810</link>
      <description>arXiv:2512.23810v1 Announce Type: cross 
Abstract: Broad applications of quantum computers will require error correction (EC). However, quantum hardware roadmaps indicate that physical qubit numbers will remain limited in the foreseeable future, leading to residual logical errors that limit the size and accuracy of achievable computations. Recent work suggested logical error mitigation (LEM), which applies known error mitigation (EM) methods to logical errors, eliminating their effect at the cost of a runtime overhead. Improving the efficiency of LEM is crucial for increasing the logical circuit volumes it enables to execute.
  We introduce syndrome-aware logical error mitigation (SALEM), which makes use of the syndrome data measured during error correction, when mitigating the logical errors. The runtime overhead of SALEM is exponentially lower than that of previously proposed LEM schemes, resulting in significantly increased circuit volumes that can be executed accurately. Notably, relative to the routinely used combination of error correction and syndrome rejection (post-selection), SALEM increases the size of reliably executable computations by orders of magnitude. In this practical setting in which space and time are both resources that need to be optimized, our work reveals a surprising phenomenon: SALEM, which tightly combines EC with EM, can outperform physical EM even above the standard fault-tolerance threshold. Thus, SALEM can make use of EC in regimes of physical error rates at which EC is commonly deemed useless.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23810v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dorit Aharonov, Yosi Atia, Eyal Bairey, Zvika Brakerski, Itsik Cohen, Omri Golan, Ilya Gurwich, Netanel H. Lindner, Maor Shutman</dc:creator>
    </item>
    <item>
      <title>Kidney Exchange: Faster Parameterized Algorithms and Tighter Lower Bounds</title>
      <link>https://arxiv.org/abs/2512.24037</link>
      <description>arXiv:2512.24037v1 Announce Type: cross 
Abstract: The kidney exchange mechanism allows many patient-donor pairs who are otherwise incompatible with each other to come together and exchange kidneys along a cycle. However, due to infrastructure and legal constraints, kidney exchange can only be performed in small cycles in practice. In reality, there are also some altruistic donors who do not have any paired patients. This allows us to also perform kidney exchange along paths that start from some altruistic donor. Unfortunately, the computational task is NP-complete. To overcome this computational barrier, an important line of research focuses on designing faster algorithms, both exact and using the framework of parameterized complexity.
  The standard parameter for the kidney exchange problem is the number $t$ of patients that receive a healthy kidney. The current fastest known deterministic FPT algorithm for this problem, parameterized by $t$, is $O^\star\left(14^t\right)$. In this work, we improve this by presenting a deterministic FPT algorithm that runs in time $O^\star\left((4e)^t\right)\approx O^\star\left(10.88^t\right)$. This problem is also known to be W[1]-hard parameterized by the treewidth of the underlying undirected graph. A natural question here is whether the kidney exchange problem admits an FPT algorithm parameterized by the pathwidth of the underlying undirected graph. We answer this negatively in this paper by proving that this problem is W[1]-hard parameterized by the pathwidth of the underlying undirected graph. We also present some parameterized intractability results improving the current understanding of the problem under the framework of parameterized complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24037v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aritra Banik, Sujoy Bhore, Palash Dey, Abhishek Sahu</dc:creator>
    </item>
    <item>
      <title>Proper colorings of a graph in linear time using a number of colors linear in the maximum degree of the graph</title>
      <link>https://arxiv.org/abs/2512.24522</link>
      <description>arXiv:2512.24522v1 Announce Type: cross 
Abstract: A new algorithm for exactly sampling from the set of proper colorings of a graph is presented. This is the first such algorithm that has an expected running time that is guaranteed to be linear in the size of a graph with maximum degree \( \Delta \) when the number of colors is greater than \( 3.637 \Delta + 1\).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24522v1</guid>
      <category>math.PR</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kritika Bhandari, Mark Huber</dc:creator>
    </item>
    <item>
      <title>Approximate Computation via Le Cam Simulability</title>
      <link>https://arxiv.org/abs/2512.24860</link>
      <description>arXiv:2512.24860v1 Announce Type: cross 
Abstract: We propose a decision-theoretic framework for computational complexity, complementary to classical theory: moving from syntactic exactness (Turing / Shannon) to semantic simulability (Le Cam). While classical theory classifies problems by the cost of exact solution, modern computation often seeks only decision-valid approximations. We introduce a framework where "computation" is viewed as the efficient simulation of a target statistical experiment within a bounded risk distortion (Le Cam deficiency).
  We formally define computational deficiency ($\delta_{\text{poly}}$) and use it to construct the complexity class LeCam-P (Decision-Robust Polynomial Time), characterizing problems that may be syntactically hard but semantically easy to approximate. We show that classical Karp reductions can be viewed as zero-deficiency simulations, and that approximate reductions correspond to bounded deficiency. Furthermore, we establish the No-Free-Transfer Inequality, showing that strictly invariant representations inevitably destroy decision-relevant information. This framework offers a statistical perspective on approximation theory, bridging the gap between algorithmic complexity and decision theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24860v1</guid>
      <category>math.ST</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deniz Akdemir</dc:creator>
    </item>
    <item>
      <title>Diffusion Language Models are Provably Optimal Parallel Samplers</title>
      <link>https://arxiv.org/abs/2512.25014</link>
      <description>arXiv:2512.25014v1 Announce Type: cross 
Abstract: Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.25014v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haozhe Jiang, Nika Haghtalab, Lijie Chen</dc:creator>
    </item>
    <item>
      <title>Enumeration and updates for conjunctive linear algebra queries through expressibility</title>
      <link>https://arxiv.org/abs/2310.04118</link>
      <description>arXiv:2310.04118v5 Announce Type: replace 
Abstract: Due to the importance of linear algebra and matrix operations in data analytics, there is significant interest in using relational query optimization and processing techniques for evaluating (sparse) linear algebra programs. In particular, in recent years close connections have been established between linear algebra programs and relational algebra that allow transferring optimization techniques of the latter to the former. In this paper, we ask ourselves which linear algebra programs in MATLANG correspond to the free-connex and q-hierarchical fragments of conjunctive first-order logic. Both fragments have desirable query processing properties: free-connex conjunctive queries support constant-delay enumeration after a linear-time preprocessing phase, and q-hierarchical conjunctive queries further allow constant-time updates. By characterizing the corresponding fragments of MATLANG, we hence identify the fragments of linear algebra programs that one can evaluate with constant-delay enumeration after linear-time preprocessing and with constant-time updates. To derive our results, we improve and generalize previous correspondences between MATLANG and relational algebra evaluated over semiring-annotated relations. In addition, we identify properties on semirings that allow to generalize the complexity bounds for free-connex and q-hierarchical conjunctive queries from Boolean annotations to general semirings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04118v5</guid>
      <category>cs.CC</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Mu\~noz, Cristian Riveros, Stijn Vansummeren</dc:creator>
    </item>
    <item>
      <title>Cubic Incompleteness: Hilbert's Tenth Problem at Degree Three</title>
      <link>https://arxiv.org/abs/2510.00759</link>
      <description>arXiv:2510.00759v4 Announce Type: replace-cross 
Abstract: We analyze the cubic fragment $\mathcal D_3$ over $\mathbb N$ by isolating the uniform closure principle any total correct cubic solver would have to realize. In $\mathsf{HA}$ we give a fully constructive, additive and degree-controlled encoding of bounded verification: for each externally fixed bound, we effectively produce a finite system of degree-3 Diophantine equations whose solutions represent the existence of the corresponding finite proof or computation trace. The encoding is purely syntactic, using "gadgets" and "Carryless Pairing". In a classical metatheory (e.g. $\mathsf{PA}$) we show that the global solver hypothesis implies a uniform operator eliminating the bound inside $\mathcal D_3$, which is incompatible with standard non-uniformity/realizability constraints. Hence no uniform cubic can exist clasically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00759v4</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milan Rosko</dc:creator>
    </item>
    <item>
      <title>A Unified Approach to Submodular Maximization Under Noise</title>
      <link>https://arxiv.org/abs/2510.21128</link>
      <description>arXiv:2510.21128v2 Announce Type: replace-cross 
Abstract: We consider the problem of maximizing a submodular function with access to a noisy value oracle for the function instead of an exact value oracle. Similar to prior work, we assume that the noisy oracle is persistent in that multiple calls to the oracle for a specific set always return the same value. In this model, Hassidim and Singer (2017) design a $(1-1/e)$-approximation algorithm for monotone submodular maximization subject to a cardinality constraint, and Huang et al (2022) design a $(1-1/e)/2$-approximation algorithm for monotone submodular maximization subject to any arbitrary matroid constraint. In this paper, we design a meta-algorithm that allows us to take any "robust" algorithm for exact submodular maximization as a black box and transform it into an algorithm for the noisy setting while retaining the approximation guarantee. By using the meta-algorithm with the measured continuous greedy algorithm, we obtain a $(1-1/e)$-approximation (resp. $1/e$-approximation) for monotone (resp. non-monotone) submodular maximization subject to a matroid constraint under noise. Furthermore, by using the meta-algorithm with the double greedy algorithm, we obtain a $1/2$-approximation for unconstrained (non-monotone) submodular maximization under noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21128v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kshipra Bhawalkar, Yang Cai, Zhe Feng, Christopher Liaw, Tao Lin</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Bipartite Degree Realizability</title>
      <link>https://arxiv.org/abs/2512.17709</link>
      <description>arXiv:2512.17709v2 Announce Type: replace-cross 
Abstract: We study the \emph{Bipartite Degree Realization} (BDR) problem: given a graphic degree sequence $D$, decide whether it admits a realization as a bipartite graph. While bipartite realizability for a fixed vertex partition can be decided in polynomial time via the Gale--Ryser theorem, the computational complexity of BDR without a prescribed partition remains unresolved. We address this question through a parameterized analysis.
  For constants $0 \le c_1 \le c_2 \le 1$, we define $\mathrm{BDR}_{c_1,c_2}$ as the restriction of BDR to degree sequences of length $n$ whose degrees lie in the interval $[c_1 n, c_2 n]$. Our main result shows that $\mathrm{BDR}_{c_1,c_2}$ is solvable in polynomial time whenever $0 \le c_1 \le c_2 \le \frac{\sqrt{c_1(c_1+4)}-c_1}{2}$, as well as for all $c_1 &gt; \tfrac12$. The proof relies on a reduction to extremal \emph{least balanced degree sequences} and a detailed verification of the critical Gale--Ryser inequalities, combined with a bounded subset-sum formulation.
  We further show that, assuming the NP-completeness of unrestricted BDR, the problem $\mathrm{BDR}_{c_1,c_2}$ remains NP-complete for all $0 &lt; c_2 &lt; \frac{1}{2}$ and $c_1 &lt; 1 - c_2 - \sqrt{1-2c_2}$. % This establishes a sharp conditional boundary between tractable and intractable parameter regimes. Our results clarify the algorithmic landscape of bipartite degree realization and contribute to the broader study of potentially bipartite graphic degree sequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17709v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Istv\'an Mikl\'os</dc:creator>
    </item>
    <item>
      <title>Poincar\'e Duality and Multiplicative Structures on Quantum Codes</title>
      <link>https://arxiv.org/abs/2512.21922</link>
      <description>arXiv:2512.21922v2 Announce Type: replace-cross 
Abstract: Quantum LDPC codes have attracted intense interest due to their advantageous properties for realizing efficient fault-tolerant quantum computing. In particular, sheaf codes represent a novel framework that encompasses all well-known good qLDPC codes with profound underlying mathematics. In this work, we generalize Poincar\'e duality from manifolds to both classical and quantum codes defined via sheaf theory on $t$-dimensional cell complexes. Viewing important code properties including the encoding rate, code distance, local testability soundness, and efficient decoders as parameters of the underlying (co)chain complexes, we rigorously prove a duality relationship between the $i$-th chain and the $(t-i)$-th cochain of sheaf codes.
  We further build multiplicative structures such as cup and cap products on sheaved chain complexes, inspired by the standard notions of multiplicative structures and Poincar\'e duality on manifolds. This immediately leads to an explicit isomorphism between (co)homology groups of sheaf codes via a cap product. As an application, we obtain transversal disjoint logical $\mathrm{C}Z$ gates with $k_{\mathrm{C}Z}=\Theta(n)$ on families of good qLDPC and almost-good quantum locally testable codes. Moreover, we provide multiple new methods to construct transversal circuits composed of $\mathrm{C}\mathrm{C}Z$ gates as well as for higher order controlled-$Z$ that are provably logical operations on the code space. We conjecture that they generate nontrivial logical actions, pointing towards fault-tolerant non-Clifford gates on nearly optimal qLDPC sheaf codes. Mathematically, our results are built on establishing the equivalence between sheaf cohomology in the derived-functor sense, \v{C}ech cohomology, and the cohomology of sheaf codes, thereby introducing new mathematical tools into quantum coding theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21922v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Li, Zimu Li, Zi-Wen Liu, Quynh T. Nguyen</dc:creator>
    </item>
    <item>
      <title>The Simultaneous Triple Product Property and Group-theoretic Results for the Exponent of Matrix Multiplication</title>
      <link>https://arxiv.org/abs/cs/0703145</link>
      <description>arXiv:cs/0703145v5 Announce Type: replace-cross 
Abstract:   We describe certain special consequences of certain elementary methods from group theory for studying the algebraic complexity of matrix multiplication, as developed by H. Cohn, C. Umans et. al. in 2003 and 2005. The measure of complexity here is the exponent of matrix multiplication, a real parameter between 2 and 3, which has been conjectured to be 2. More specifically, a finite group may simultaneously "realize" several independent matrix multiplications via its regular algebra if it has a family of triples of "index" subsets which satisfy the so-called simultaneous triple product property (STPP), in which case the complexity of these several multiplications does not exceed the rank (complexity) of the algebra. This leads to bounds for the exponent in terms of the size of the group and the sizes of its STPP triples, as well as the dimensions of its distinct irreducible representations. Wreath products of Abelian with symmetric groups appear especially important, in this regard, and we give an example of such a group which shows that the exponent is less than 2.84, and could be possibly be as small as 2.02 depending on the number of simultaneous matrix multiplications it realizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:cs/0703145v5</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.GR</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:creator>Sandeep Murthy</dc:creator>
    </item>
  </channel>
</rss>
