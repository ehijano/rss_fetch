<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 02:34:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Intrinsic dimension concentration inequalities for self-adjoint operators</title>
      <link>https://arxiv.org/abs/2602.13465</link>
      <description>arXiv:2602.13465v1 Announce Type: new 
Abstract: We derive novel concentration inequalities for the operator norm of the sum of self-adjoint operators that do not explicitly depend on the underlying dimension of the operator, but rather an intrinsic notion of it. Our analysis leads to tighter results (in terms of constants) and simplified proofs. Our results unify the current intrinsic-dimension and ambient-dimension inequalities under independence, strictly improving both categories of bounds (such as by Tropp and Minsker). We present a general master theorem that we instantiate to obtain specific sub-Gaussian, Hoeffding, Bernstein, Bennett, and sub-exponential type inequalities. We also establish widely applicable concentration bounds under martingale dependence that provide tighter control than existing results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13465v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Martinez-Taboada, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>An Improved Milstein Method for the Numerical Solution of Multidimensional Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2602.13565</link>
      <description>arXiv:2602.13565v1 Announce Type: new 
Abstract: Stochastic differential equations (SDEs) offer powerful and accessible mathematical models for capturing both deterministic and probabilistic aspects of dynamic behavior across a wide range of physical, financial, and social systems. However, analytical solutions for many SDEs are often unavailable, necessitating the use of numerical approximation methods. The rate of convergence of such numerical methods is of great importance, as it directly influences both computational efficiency and accuracy. This paper presents a proposed theorem, along with its proof, that facilitates the numerical evaluation of the strong (and weak) order of convergence of a numerical scheme for an SDE when the analytical solution is unavailable. Additionally, we address the challenge of numerically computing the multiple stochastic integrals required by the Milstein method to achieve improved convergence rates for multidimensional SDEs. In this context, two newly proposed numerical techniques for computing these multiple stochastic integrals are introduced and compared with existing approaches in terms of efficiency and effectiveness. The methodologies are further illustrated through simulation studies and applications to widely used financial models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13565v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Paromita Banerjee, Anirban Mondal</dc:creator>
    </item>
    <item>
      <title>Semi-supervised linear regression with missing covariates</title>
      <link>https://arxiv.org/abs/2602.13729</link>
      <description>arXiv:2602.13729v1 Announce Type: new 
Abstract: Missing values in datasets are common in applied statistics. For regression problems, theoretical work thus far has largely considered the issue of missing covariates as distinct from missing responses. However, in practice, many datasets have both forms of missingness. Motivated by this gap, we study linear regression with a labelled dataset containing missing covariates, potentially alongside an unlabelled dataset. We consider both structured (blockwise-missing) and unstructured missingness patterns, along with sparse and non-sparse regression parameters. For the non-sparse case, we provide an estimator based on imputing the missing data combined with a reweighting step. For the high-dimensional sparse case, we use a modified version of the Dantzig selector. We provide non-asymptotic upper bounds on the risk of both procedures. These are matched by several new minimax lower bounds, demonstrating the rate optimality of our estimators. Notably, even when the linear model is well-specified, our results characterise substantial differences in the minimax rates when unlabelled data is present relative to the fully supervised setting. Particular consequences of our sparse and non-sparse results include the first matching upper and lower bounds on the minimax rate for the supervised setting when either unstructured or structured missingness is present. Our theory is coupled with extensive simulations and a semi-synthetic application to the California housing dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13729v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benedict M. Risebrow, Thomas B. Berrett</dc:creator>
    </item>
    <item>
      <title>Ensemble-Conditional Gaussian Processes (Ens-CGP): Representation, Geometry, and Inference</title>
      <link>https://arxiv.org/abs/2602.13871</link>
      <description>arXiv:2602.13871v1 Announce Type: new 
Abstract: We formulate Ensemble-Conditional Gaussian Processes (Ens-CGP), a finite-dimensional synthesis that centers ensemble-based inference on the conditional Gaussian law. Conditional Gaussian processes (CGP) arise directly from Gaussian processes under conditioning and, in linear-Gaussian settings, define the full posterior distribution for a Gaussian prior and linear observations. Classical Kalman filtering is a recursive algorithm that computes this same conditional law under dynamical assumptions; the conditional Gaussian law itself is therefore the underlying representational object, while the filter is one computational realization. In this sense, CGP provides the probabilistic foundation for Kalman-type methods as well as equivalent formulations as a strictly convex quadratic program (MAP estimation), RKHS-regularized regression, and classical regularization. Ens-CGP is the ensemble instantiation of this object, obtained by treating empirical ensemble moments as a (possibly low-rank) Gaussian prior and performing exact conditioning. By separating representation (GP -&gt; CGP -&gt; Ens-CGP) from computation (Kalman filters, EnKF variants, and iterative ensemble schemes), the framework links an earlier-established representational foundation for inference to ensemble-derived priors and clarifies the relationships among probabilistic, variational, and ensemble perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13871v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Ravela, Jae Deok Kim, Kenneth Gee, Xingjian Yan, Samson Mercier, Lubna Albarghouty, Anamitra Saha</dc:creator>
    </item>
    <item>
      <title>Mean-Square Convergence of a New Parameterized Leapfrog Scheme for Hamiltonian Systems Driven by Gaussian Process Potentials</title>
      <link>https://arxiv.org/abs/2602.14053</link>
      <description>arXiv:2602.14053v1 Announce Type: new 
Abstract: This paper establishes the mean-square convergence of a new stochastic, parameterized leapfrog scheme introduced in our companion paper Mazumder et al. (2026) for Hamiltonian systems with Gaussian process potentials. We consider a one-step numerical integrator and provide a complete, rigorous analysis under minimal regularity assumptions on the Gaussian potential. The key technical contribution is identifying and exploiting the symplectic structure ingrained in our stochastic, parameterized leapfrog method. Combined with local truncation error analysis, this leads to a global error bound of O({\delta}t) in mean-square sense. Our results establish that although the spatio-temporal model of Mazumder et al. (2026) arises as the anticipated new stochastic leapfrog solution of a system of modified (parameterized) stochastic Hamiltonian equations, the new stochastic leapfrog actually solves the traditional stochastic Hamiltonian equations, driven by Gaussian process potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14053v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourabh Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Kernel Estimation Of Chatterjee's Dependence Coefficient</title>
      <link>https://arxiv.org/abs/2602.14206</link>
      <description>arXiv:2602.14206v1 Announce Type: new 
Abstract: Dette, Siburg, and Stoimenov (2013) introduced a copula-based measure of dependence, which implies independence if it vanishes and is equal to 1 if one variable is a measurable function of the other. For continuous distributions, the dependence measure also appears as stochastic limit of Chatterjee's rank correlation (Chatterjee, 2021). They proved asymptotic normality of a corresponding kernel estimator with a parametric rate of convergence. In recent work Shi, Drton, and Han (2022) revealed empirically and theoretically that under independence the asymptotic variance degenerates. In this note, we derive the correct asymptotic distribution of the kernel estimator under the null hypothesis of independence. We show that after a suitable centering and rescaling at a rate larger than $\sqrt{n}$ (where $n$ is the sample size), the estimator is asymptotically normal. The analysis relies on a refined central limit theorem for double-indexed linear permutation statistics and accounts for boundary effects that are asymptotically non-negligible. As a consequence, we obtain a valid basis for independence testing without relying on permutations and argue that tests based on the kernel estimator detect local alternatives converging to the null at a faster rate than those detectable by Chatterjee's rank correlation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14206v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mona Azadkia, Holger Dette</dc:creator>
    </item>
    <item>
      <title>High-accuracy log-concave sampling with stochastic queries</title>
      <link>https://arxiv.org/abs/2602.14342</link>
      <description>arXiv:2602.14342v1 Announce Type: new 
Abstract: We show that high-accuracy guarantees for log-concave sampling -- that is, iteration and query complexities which scale as $\mathrm{poly}\log(1/\delta)$, where $\delta$ is the desired target accuracy -- are achievable using stochastic gradients with subexponential tails. Notably, this exhibits a separation with the problem of convex optimization, where stochasticity (even additive Gaussian noise) in the gradient oracle incurs $\mathrm{poly}(1/\delta)$ queries. We also give an information-theoretic argument that light-tailed stochastic gradients are necessary for high accuracy: for example, in the bounded variance case, we show that the minimax-optimal query complexity scales as $\Theta(1/\delta)$. Our framework also provides similar high accuracy guarantees under stochastic zeroth order (value) queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14342v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Chen, Sinho Chewi, Constantinos Daskalakis, Alexander Rakhlin</dc:creator>
    </item>
    <item>
      <title>Frequentist Regret Analysis of Gaussian Process Thompson Sampling via Fractional Posteriors</title>
      <link>https://arxiv.org/abs/2602.14472</link>
      <description>arXiv:2602.14472v1 Announce Type: new 
Abstract: We study Gaussian Process Thompson Sampling (GP-TS) for sequential decision-making over compact, continuous action spaces and provide a frequentist regret analysis based on fractional Gaussian process posteriors, without relying on domain discretization as in prior work. We show that the variance inflation commonly assumed in existing analyses of GP-TS can be interpreted as Thompson Sampling with respect to a fractional posterior with tempering parameter $\alpha \in (0,1)$. We derive a kernel-agnostic regret bound expressed in terms of the information gain parameter $\gamma_t$ and the posterior contraction rate $\epsilon_t$, and identify conditions on the Gaussian process prior under which $\epsilon_t$ can be controlled. As special cases of our general bound, we recover regret of order $\tilde{\mathcal{O}}(T^{\frac{1}{2}})$ for the squared exponential kernel, $\tilde{\mathcal{O}}(T^{\frac{2\nu+3d}{2(2\nu+d)}} )$ for the Mat\'ern-$\nu$ kernel, and a bound of order $\tilde{\mathcal{O}}(T^{\frac{2\nu+3d}{2(2\nu+d)}})$ for the rational quadratic kernel. Overall, our analysis provides a unified and discretization-free regret framework for GP-TS that applies broadly across kernel classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14472v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Somjit Roy, Prateek Jaiswal, Anirban Bhattacharya, Debdeep Pati, Bani K. Mallick</dc:creator>
    </item>
    <item>
      <title>Bias analysis of a linear order-statistic inequality index estimator: Unbiasedness under gamma populations</title>
      <link>https://arxiv.org/abs/2602.14861</link>
      <description>arXiv:2602.14861v1 Announce Type: new 
Abstract: This paper studies a class of rank-based inequality measures built from linear combinations of expected order statistics. The proposed framework unifies several well-known indices, including the classical Gini coefficient, the $m$th Gini index, extended $m$th Gini index and $S$-Gini index, and also connects to spectral inequality measures through an integral representation. We investigate the finite-sample behavior of a natural U-statistic-type estimator that averages weighted order-statistic contrasts over all subsamples of fixed size and normalizes by the sample mean. A general bias decomposition is derived in terms of components that isolate the effect of random normalization on each rank level, yielding analytical expressions that can be evaluated under broad non-negative distributions via Laplace-transform methods. Under mild moment conditions, the estimator is shown to be asymptotically unbiased. Moreover, we prove exact unbiasedness under gamma populations for any sample size, extending earlier unbiasedness results for Gini-type estimators. A Monte Carlo study is performed to numerically check that the theoretical unbiasednes under gamma populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14861v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Vila, Helton Saulo</dc:creator>
    </item>
    <item>
      <title>Topological trivialization in non-convex empirical risk minimization</title>
      <link>https://arxiv.org/abs/2602.14969</link>
      <description>arXiv:2602.14969v1 Announce Type: new 
Abstract: Given data $\{({\boldsymbol x}_i,y_i): i\le n\}$, with ${\boldsymbol x}_i$ standard $d$-dimensional Gaussian feature vectors, and $y_i\in{\mathbb R}$ response variables, we study the general problem of learning a model parametrized by ${\boldsymbol \theta}\in{\mathbb R}^d$, by minimizing a loss function that depends on ${\boldsymbol \theta}$ via the one-dimensional projections ${\boldsymbol \theta}^{\sf T}{\boldsymbol x}_i$. While previous work mostly dealt with convex losses, our approach assumes general (non-convex) losses hence covering classical, yet poorly understood examples such as the perceptron and non-convex robust regression. We use the Kac-Rice formula to control the asymptotics of the expected number of local minima of the empirical risk, under the proportional asymptotics $n,d\to\infty$, $n/d\to\alpha &gt;1$. Specifically, we prove a finite dimensional variational formula for the exponential growth rate of the expected number of local minima. Further we provide sufficient conditions under which the exponential growth rate vanishes and all empirical risk minimizers have the same asymptotic properties (in fact, we expect the minimizer to be unique in these circumstances). We refer to this phenomenon as `rate trivialization.' If the population risk has a unique minimizer, our sufficient condition for rate trivialization is typically verified when the samples/parameters ratio $\alpha$ is larger than a suitable constant $\alpha_{\star}$. Previous general results of this type required $n\ge Cd \log d$. We illustrate our results in the case of non-convex robust regression. Based on heuristic arguments and numerical simulations, we present a conjecture for the exact location of the trivialization phase transition $\alpha_{\text{tr}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14969v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Montanari, Basil Saeed</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference of the Win Ratio for Two Hierarchical Endpoints Subject to Censoring and Missing Data</title>
      <link>https://arxiv.org/abs/2602.13533</link>
      <description>arXiv:2602.13533v1 Announce Type: cross 
Abstract: The win ratio (WR) is a widely used metric to compare treatments in randomized clinical trials with hierarchically ordered endpoints. Counting-based approaches, such as Pocock's algorithm, are the standard for WR estimation. However, this algorithm treats participants with censored or missing data inadequately, which may lead to biased and inefficient estimates, particularly in the presence of heterogeneous censoring or missing data between treatment groups. Although recent extensions have addressed some of these limitations for hierarchical time-to-event endpoints, no existing methods -- aside from the computationally intensive multiple imputation approach -- can accommodate settings that include non-survival endpoints that are subject to missing data. In this paper, we propose a simple nonparametric maximum likelihood estimator (NPMLE) of WR for two hierarchical endpoints that are subject to censoring and missing data. Our method uses all observed data, avoids strong parametric assumptions, and comes with a closed-form asymptotic variance estimator. We demonstrate its performance using simulation studies and two data examples, based on the HEART-FID and ISCHEMIA trials. The proposed method provides a consistent estimator, improves estimation efficiency, and is robust under non-informative censoring and missing at random (MAR) assumptions, offering a flexible alternative to existing WR estimation methods. A user-friendly R package, WinRS, is available to facilitate implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13533v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Liu, Huiman Barnhart, Sean O'Brien, Yuliya Lokhnygina, Roland A. Matsouaka</dc:creator>
    </item>
    <item>
      <title>Why Self-Training Helps and Hurts: Denoising vs. Signal Forgetting</title>
      <link>https://arxiv.org/abs/2602.14029</link>
      <description>arXiv:2602.14029v1 Announce Type: cross 
Abstract: Iterative self-training (self-distillation) repeatedly refits a model on pseudo-labels generated by its own predictions. We study this procedure in overparameterized linear regression: an initial estimator is trained on noisy labels, and each subsequent iterate is trained on fresh covariates with noiseless pseudo-labels from the previous model. In the high-dimensional regime, we derive deterministic-equivalent recursions for the prediction risk and effective noise across iterations, and prove that the empirical quantities concentrate sharply around these limits. The recursion separates two competing forces: a systematic component that grows with iteration due to progressive signal forgetting, and a stochastic component that decays due to denoising via repeated data-dependent projections. Their interaction yields a $U$-shaped test-risk curve and an optimal early-stopping time. In spiked covariance models, iteration further acts as an iteration-dependent spectral filter that preserves strong eigendirections while suppressing weaker ones, inducing an implicit form of soft feature selection distinct from ridge regression. Finally, we propose an iterated generalized cross-validation criterion and prove its uniform consistency for estimating the risk along the self-training trajectory, enabling fully data-driven selection of the stopping time and regularization. Experiments on synthetic covariances validate the theory and illustrate the predicted denoising-forgetting trade-off.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14029v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingqi Wu, Archer Y. Yang, Qiang Sun</dc:creator>
    </item>
    <item>
      <title>Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow</title>
      <link>https://arxiv.org/abs/2602.14587</link>
      <description>arXiv:2602.14587v1 Announce Type: cross 
Abstract: Many real-world control problems, ranging from finance to robotics, evolve in continuous time with non-uniform, event-driven decisions. Standard discrete-time reinforcement learning (RL), based on fixed-step Bellman updates, struggles in this setting: as time gaps shrink, the $Q$-function collapses to the value function $V$, eliminating action ranking. Existing continuous-time methods reintroduce action information via an advantage-rate function $q$. However, they enforce optimality through complicated martingale losses or orthogonality constraints, which are sensitive to the choice of test processes. These approaches entangle $V$ and $q$ into a large, complex optimization problem that is difficult to train reliably. To address these limitations, we propose a novel decoupled continuous-time actor-critic algorithm with alternating updates: $q$ is learned from diffusion generators on $V$, and $V$ is updated via a Hamiltonian-based value flow that remains informative under infinitesimal time steps, where standard max/softmax backups fail. Theoretically, we prove rigorous convergence via new probabilistic arguments, sidestepping the challenge that generator-based Hamiltonians lack Bellman-style contraction under the sup-norm. Empirically, our method outperforms prior continuous-time and leading discrete-time baselines across challenging continuous-control benchmarks and a real-world trading task, achieving 21% profit over a single quarter$-$nearly doubling the second-best method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14587v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Block Empirical Likelihood Inference for Longitudinal Generalized Partially Linear Single-Index Models</title>
      <link>https://arxiv.org/abs/2602.14981</link>
      <description>arXiv:2602.14981v1 Announce Type: cross 
Abstract: Generalized partially linear single-index models (GPLSIMs) provide a flexible and interpretable semiparametric framework for longitudinal outcomes by combining a low-dimensional parametric component with a nonparametric index component. For repeated measurements, valid inference is challenging because within-subject correlation induces nuisance parameters and variance estimation can be unstable in semiparametric settings. We propose a profile estimating-equation approach based on spline approximation of the unknown link function and construct a subject-level block empirical likelihood (BEL) for joint inference on the parametric coefficients and the single-index direction. The resulting BEL ratio statistic enjoys a Wilks-type chi-square limit, yielding likelihood-free confidence regions without explicit sandwich variance estimation. We also discuss practical implementation, including constrained optimization for the index parameter, working-correlation choices, and bootstrap-based confidence bands for the nonparametric component. Simulation studies and an application to the epilepsy longitudinal study illustrate the finite-sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14981v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianni Zhang, Yuyao Wang, Yu Lu, and Mengfei Ran</dc:creator>
    </item>
    <item>
      <title>Random geometric graphs with smooth kernels: sharp detection threshold and a spectral conjecture</title>
      <link>https://arxiv.org/abs/2602.14998</link>
      <description>arXiv:2602.14998v1 Announce Type: cross 
Abstract: A random geometric graph (RGG) with kernel $K$ is constructed by first sampling latent points $x_1,\ldots,x_n$ independently and uniformly from the $d$-dimensional unit sphere, then connecting each pair $(i,j)$ with probability $K(\langle x_i,x_j\rangle)$. We study the sharp detection threshold, namely the highest dimension at which an RGG can be distinguished from its Erd\H{o}s--R\'enyi counterpart with the same edge density.
  For dense graphs, we show that for smooth kernels the critical scaling is $d = n^{3/4}$, substantially lower than the threshold $d = n^3$ known for the hard RGG with step-function kernels \cite{bubeck2016testing}. We further extend our results to kernels whose signal-to-noise ratio scales with $n$, and formulate a unifying conjecture that the critical dimension is determined by $n^3 \mathop{\rm tr}^2(\kappa^3) = 1$, where $\kappa$ is the standardized kernel operator on the sphere.
  Departing from the prevailing approach of bounding the Kullback-Leibler divergence by successively exposing latent points, which breaks down in the sublinear regime of $d=o(n)$, our key technical contribution is a careful analysis of the posterior distribution of the latent points given the observed graph, in particular, the overlap between two independent posterior samples. As a by-product, we establish that $d=\sqrt{n}$ is the critical dimension for non-trivial estimation of the latent vectors up to a global rotation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14998v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Mao, Yihong Wu, Jiaming Xu</dc:creator>
    </item>
    <item>
      <title>Efficient Sampling with Discrete Diffusion Models: Sharp and Adaptive Guarantees</title>
      <link>https://arxiv.org/abs/2602.15008</link>
      <description>arXiv:2602.15008v1 Announce Type: cross 
Abstract: Diffusion models over discrete spaces have recently shown striking empirical success, yet their theoretical foundations remain incomplete. In this paper, we study the sampling efficiency of score-based discrete diffusion models under a continuous-time Markov chain (CTMC) formulation, with a focus on $\tau$-leaping-based samplers. We establish sharp convergence guarantees for attaining $\varepsilon$ accuracy in Kullback-Leibler (KL) divergence for both uniform and masking noising processes. For uniform discrete diffusion, we show that the $\tau$-leaping algorithm achieves an iteration complexity of order $\tilde O(d/\varepsilon)$, with $d$ the ambient dimension of the target distribution, eliminating linear dependence on the vocabulary size $S$ and improving existing bounds by a factor of $d$; moreover, we establish a matching algorithmic lower bound showing that linear dependence on the ambient dimension is unavoidable in general. For masking discrete diffusion, we introduce a modified $\tau$-leaping sampler whose convergence rate is governed by an intrinsic information-theoretic quantity, termed the effective total correlation, which is bounded by $d \log S$ but can be sublinear or even constant for structured data. As a consequence, the sampler provably adapts to low-dimensional structure without prior knowledge or algorithmic modification, yielding sublinear convergence rates for various practical examples (such as hidden Markov models, image data, and random graphs). Our analysis requires no boundedness or smoothness assumptions on the score estimator beyond control of the score entropy loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15008v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Dmitriev, Zhihan Huang, Yuting Wei</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation of trawl processes: Theory and applications</title>
      <link>https://arxiv.org/abs/2209.05894</link>
      <description>arXiv:2209.05894v3 Announce Type: replace 
Abstract: Trawl processes belong to the class of continuous-time, strictly stationary, infinitely divisible processes; they are defined as Levy bases evaluated over deterministic trawl sets. 
This article presents the first nonparametric estimator of the trawl function characterising the trawl set and the serial correlation of the process. Moreover, it establishes a detailed asymptotic theory for the proposed estimator, including a law of large numbers and a central limit theorem for various asymptotic relations between an in-fill and a long-span asymptotic regime. In addition, it develops consistent estimators for both the asymptotic bias and variance, which are subsequently used for establishing feasible central limit theorems which can be applied to data. A simulation study shows the good finite sample performance of the proposed estimators. The new methodology is applied to model misspecification testing, forecasting high-frequency financial spread data from a limit order book and to estimating the busy-time distribution of a stochastic queue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.05894v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Orimar Sauri, Almut E. D. Veraart</dc:creator>
    </item>
    <item>
      <title>Asymptotic Properties of Multi-Treatment Covariate Adaptive Randomization Procedures for Balancing Observed and Unobserved Covariates</title>
      <link>https://arxiv.org/abs/2305.13842</link>
      <description>arXiv:2305.13842v3 Announce Type: replace 
Abstract: Applications of CAR for balancing continuous covariates remain comparatively rare, especially in multi-treatment clinical trials, and the theoretical properties of multi-treatment CAR have remained largely elusive for decades. In this paper, we consider a general framework of CAR procedures for multi-treatment clinal trials which can balance general covariate features, such as quadratic and interaction terms which can be discrete, continuous, and mixing. We show that under widely satisfied conditions the proposed procedures have superior balancing properties; in particular, the convergence rate of imbalance vectors can attain the best rate $O_P(1)$ for discrete covariates, continuous covariates, or combinations of both discrete and continuous covariates, and at the same time, the convergence rate of the imbalance of unobserved covariates is $O_P(\sqrt n)$, where $n$ is the sample size. The general framework unifies many existing methods and related theories, introduces a much broader class of new and useful CAR procedures, and provides new insights and a complete picture of the properties of CAR procedures. The favorable balancing properties lead to the precision of the treatment effect test in the presence of a heteroscedastic linear model with dependent covariate features. As an application, the properties of the test of treatment effect with unobserved covariates are studied under the CAR procedures, and consistent tests are proposed so that the test has an asymptotic precise type I error even if the working model is wrong and covariates are unobserved in the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13842v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li-Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Robust Signal Detection with Quadratically Convex Orthosymmetric Constraints</title>
      <link>https://arxiv.org/abs/2308.13036</link>
      <description>arXiv:2308.13036v3 Announce Type: replace 
Abstract: This paper studies the problem of robust signal detection in Gaussian noise under quadratically convex orthosymmetric (QCO) constraints. We consider a minimax testing framework where the signal belongs to a QCO set and is separated from zero in Euclidean norm, while an adversary is allowed to arbitrarily corrupt a fraction $\epsilon $ of the samples. We establish the minimax separation radius between the null and alternative purely in terms of the constraint geometry, sample size, corruption rate, and noise scale. Our analysis argues that the Kolmogorov widths of the constraint set play a central role in determining the detection limits, paralleling to classic results in estimation problem. The derived lower bounds exhibit phase transitions with respect to the corruption rate and confirm that robust testing is statistically easier than robust estimation. While the information-theoretic upper bound is achieved by a computationally intractable test, we develop a polynomial-time algorithm that achieves the minimax lower bound up to logarithmic factors. Unlike prior work, our algorithm handles signals of arbitrary Euclidean length while respecting the QCO constraints. Finally, we extend these results to the robust $\ell _{p}$ norm testing for $1 \le p &lt; 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13036v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yikun Li, Matey Neykov</dc:creator>
    </item>
    <item>
      <title>A Theory of Feature Learning in Kernel Models</title>
      <link>https://arxiv.org/abs/2310.11736</link>
      <description>arXiv:2310.11736v4 Announce Type: replace 
Abstract: We study feature learning in a compositional variant of kernel ridge regression in which the predictor is applied to a learnable linear transformation of the input. When the response depends on the input only through a low-dimensional predictive subspace, we show that all global minimizers of the population objective for the linear transformation annihilate directions orthogonal to this subspace, and in certain regimes, exactly identify the subspace. Moreover, we show that global minimizers of the finite-sample objective inherit the exact same low-dimensional structure with high probability, even without any explicit penalization on the linear transformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11736v4</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunlu Chen, Yang Li, Keli Liu, Feng Ruan</dc:creator>
    </item>
    <item>
      <title>Rolled Gaussian process models for curves on manifolds</title>
      <link>https://arxiv.org/abs/2503.21980</link>
      <description>arXiv:2503.21980v2 Announce Type: replace 
Abstract: Given a planar curve, imagine rolling a sphere along that curve without slipping or twisting, and by this means tracing out a curve on the sphere. It is well known that such a rolling operation induces a local isometry between the sphere and the plane so that the two curves uniquely determine each other, and moreover, the operation extends to a general class of manifolds in any dimension. We use rolling to construct an analogue of a Gaussian process on a manifold starting from a Euclidean Gaussian process with mean $m$ and covariance $K$, and refer to it as a rolled Gaussian process parameterized by $m$ and $K$. The resulting model is generative, and is amenable to statistical inference given data as curves on a manifold. We identify conditions on the manifold under which the rolling of $m$ equals the Fr\'echet mean of the rolled Gaussian process, propose computationally simple estimators of $m$ and $K$, and derive their rates of convergence. We illustrate with examples on the unit sphere, symmetric positive-definite matrices, and with a robotics application involving 3D orientations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21980v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Preston, Karthik Bharath, Pablo Lopez-Custodio, Alfred Kume</dc:creator>
    </item>
    <item>
      <title>High-Dimensional Asymptotics of Differentially Private PCA</title>
      <link>https://arxiv.org/abs/2511.07270</link>
      <description>arXiv:2511.07270v2 Announce Type: replace 
Abstract: In differential privacy, statistics of a sensitive dataset are privatized by introducing random noise. Most privacy analyses provide privacy bounds specifying a noise level sufficient to achieve a target privacy guarantee. Sometimes, these bounds are pessimistic and suggest adding excessive noise, which overwhelms the meaningful signal. It remains unclear if such high noise levels are truly necessary or a limitation of the proof techniques. This paper explores whether we can obtain sharp privacy characterizations that identify the smallest noise level required to achieve a target privacy level for a given mechanism. We study this problem in the context of differentially private principal component analysis, where the goal is to privatize the leading principal components (PCs) of a dataset with n samples and p features. We analyze the exponential mechanism for this problem in a model-free setting and provide sharp utility and privacy characterizations in the high-dimensional limit ($p\rightarrow\infty$). Our privacy result shows that, in high dimensions, detecting the presence of a target individual in the dataset using the privatized PCs is exactly as hard as distinguishing two Gaussians with slightly different means, where the mean difference depends on certain spectral properties of the dataset. Our privacy analysis combines the hypothesis-testing formulation of privacy guarantees proposed by Dong, Roth, and Su (2022) with classical contiguity arguments due to Le Cam to obtain sharp high-dimensional privacy characterizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07270v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youngjoo Yun, Rishabh Dudeja</dc:creator>
    </item>
    <item>
      <title>Model-Agnostic Bounds for Augmented Inverse Probability Weighted Estimators' Wald-Confidence Interval Coverage in Randomized Controlled Trials</title>
      <link>https://arxiv.org/abs/2512.18898</link>
      <description>arXiv:2512.18898v2 Announce Type: replace 
Abstract: Nonparametric estimators, such as the augmented inverse probability weighted (AIPW) estimator, have become increasingly popular in causal inference. Numerous nonparametric estimators have been proposed, but they are all asymptotically normal with the same asymptotic variance under similar conditions, leaving little guidance for practitioners to choose an estimator. In this paper, I focus on another important perspective of their asymptotic behaviors beyond asymptotic normality, the convergence of the Wald-confidence interval (CI) coverage to the nominal coverage. Such results have been established for simpler estimators (e.g., the Berry-Esseen Theorem), but are lacking for nonparametric estimators. I consider a simple but practical setting where the AIPW estimator based on a black-box nuisance estimator, with or without cross-fitting, is used to estimate the average treatment effect in randomized controlled trials. I derive non-asymptotic Berry-Esseen-type bounds on the difference between Wald-CI coverage and the nominal coverage. I also analyze the bias of variance estimators, showing that the cross-fit variance estimator might overestimate while the non-cross-fit variance estimator might underestimate, which might explain why cross-fitting has been empirically observed to improve Wald-CI coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18898v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongxiang Qiu</dc:creator>
    </item>
    <item>
      <title>Bayes, E-values and Testing</title>
      <link>https://arxiv.org/abs/2602.04146</link>
      <description>arXiv:2602.04146v4 Announce Type: replace 
Abstract: We separate sequential evidence into three typed layers: (i)~\emph{representation} (Radon--Nikod\'ym / likelihood-ratio geometry), (ii)~\emph{validity} (Ville/martingale control under optional stopping), and (iii)~\emph{decision} (boundary choice and power/efficiency calibration). Within the coherent predictive/log-loss subclass, the Bayes-risk/Fubini decomposition forces a likelihood-ratio (Bayes-factor) representation of evidence, while validity only e-process constructions remain strictly broader. A typed calculus then organizes these layers and their bridges: the monoidal log-loss map connects Bayes factors, sequential testing, and information-theoretic regret through Good's weight of evidence; Markov/Ville inequalities supply anytime-valid certificates; and decision-theoretic cutoffs determine rejection regions from priors and losses rather than from Markov bounds. Within the coherent predictive subclass, this reduces evidence to likelihood-ratio or Bayes-factor testing; general e-process constructions may extend beyond this representation. We separate \emph{representation} from \emph{construction}: expectation-based recipes (e.g.\ Markov cutoffs) produce valid certificates but need not recover Bayes-optimal rejection regions, whereas the Fubini decomposition yields likelihood-ratio regions directly from Bayes risk. A typing discipline formalizes when bridges exist between probabilistic evidence, coding/MDL objects, and algorithmic randomness -- and when they provably fail: NML codes violate filtration-measurability, while prequential codes \citep{Dawid1984} and the universal semimeasure provide valid but non-computable alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04146v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Polson, Vadim Sokolov, Daniel Zantedeschi</dc:creator>
    </item>
    <item>
      <title>Ergodicity of an Adaptive MCMC Sampler under a Probability Bound</title>
      <link>https://arxiv.org/abs/2602.06568</link>
      <description>arXiv:2602.06568v2 Announce Type: replace 
Abstract: This paper provides sufficient conditions over the sequence of samples and parameters of an adaptive Markov Chain Monte Carlo (MCMC) algorithm to ensure ergodicity with respect to a target distribution that can have unbounded support. These conditions aim to make more easily usable the conditions of Containment and Diminishing Adaptation from Roberts and Rosenthal [2007] formulated over the transition kernels, without needing, as was done in other works, an artificial assumption of the compactness over both sample and parameter spaces. The paper shows that the condition of compactness can be relaxed to a more realistic bound in probability over the sequence of both samples and parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06568v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Chotard (LISIC)</dc:creator>
    </item>
    <item>
      <title>Asymptotically normal estimators in high-dimensional linear regression</title>
      <link>https://arxiv.org/abs/2602.07480</link>
      <description>arXiv:2602.07480v2 Announce Type: replace 
Abstract: We establish asymptotic normality for estimators in high-dimensional linear regression by proving weak convergence in a separable Hilbert space, thereby enabling direct use of standard asymptotic tools, for example, the continuous mapping theorem. The approach allows the number of non-zero coefficients to grow, provided only a fixed number have moderate magnitude. As an application, we test linear hypotheses with a statistic whose null limit is a finite weighted sum of independent chi-squared variables, yielding plug-in critical values with asymptotically correct size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07480v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kou Fujimori, Koji Tsukuda</dc:creator>
    </item>
    <item>
      <title>Covariate-Adaptive Randomization in Clinical Trials without Inflated Variances</title>
      <link>https://arxiv.org/abs/2602.10760</link>
      <description>arXiv:2602.10760v2 Announce Type: replace 
Abstract: Covariate adaptive randomization (CAR) procedures are extensively used to reduce the likelihood of covariate imbalances occurring in clinical trials. In literatures, a lot of CAR procedures have been proposed so that the specified covariates are balanced well between treatments. However, the variance of the imbalance of the unspecified covariates may be inflated comparing to the one under the simple randomization. The inflation of the variance causes the usual test of treatment effects being not valid and adjusting the test being not an easy work. In this paper, we propose a new kind covariate adaptive randomization procedures to balance covariates between two treatments with a ratio $\rho:(1-\rho)$. Under this kind of CAR procedures, the convergence rate of the imbalance of the specified covariates is $o(n^{1/2})$, and at the same time the asymptotic variance of the imbalance of any unspecified (observed or unobserved) covariates does not exceed the one under the simple randomization. The ``shift problem'' found by Liu, Hu, and Ma (2025) will not appear under the new CAR procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10760v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhang Li-Xin</dc:creator>
    </item>
    <item>
      <title>Entropic vector quantile regression: Duality and Gaussian case</title>
      <link>https://arxiv.org/abs/2602.11290</link>
      <description>arXiv:2602.11290v2 Announce Type: replace 
Abstract: Vector quantile regression (VQR) is an optimal transport (OT) problem subject to a mean-independence constraint that extends classical linear quantile regression to vector response variables. Motivated by computational considerations, prior work has considered entropic relaxation of VQR, but its fundamental structural and approximation properties are still much less understood than entropic OT. The goal of this paper is to address some of these gaps. First, we study duality theory for entropic VQR and establish strong duality and dual attainment for marginals with possibly unbounded supports. In addition, when all marginals are compactly supported, we show that dual potentials are real analytic. Second, building on our duality theory, when all marginals are Gaussian, we show that entropic VQR has a closed-form optimal solution, which is again Gaussian, and establish the precise approximation rate toward unregularized VQR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11290v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Kato, Boyu Wang</dc:creator>
    </item>
    <item>
      <title>General-purpose post-sampling reweighting method for multimodal target measures</title>
      <link>https://arxiv.org/abs/2602.12027</link>
      <description>arXiv:2602.12027v2 Announce Type: replace 
Abstract: When sampling multi-modal probability distributions, correctly estimating the relative probability of each mode, even when the modes have been discovered and locally sampled, remains challenging. We test a simple reweighting scheme designed for this situation, which consists in minimizing (in terms of weights) the Kullback-Leibler divergence of a weighted (regularized) empirical distribution of the samples with respect to the target measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12027v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Monmarch\'e</dc:creator>
    </item>
    <item>
      <title>Spatial Proportional Hazards Model with Differential Regularization</title>
      <link>https://arxiv.org/abs/2410.13420</link>
      <description>arXiv:2410.13420v5 Announce Type: replace-cross 
Abstract: The Proportional Hazards (PH) model is one of the most widely used models in survival analysis, typically assuming a log-linear relationship between covariates and the hazard function. However, in the context of spatial survival data, where the time-to-event variable is associated with a spatial location within a given domain, this assumption is often unrealistic in capturing spatial effects. Thus, this paper proposes modeling the location effect through a nonparametric function of spatial location. The function is approximated using finite element methods on a triangulated mesh to accommodate irregular domains. Estimation is carried out within the classical partial likelihood framework, with smoothness of the spatial effect enforced through differential penalization. Using sieve methods, we establish the consistency and asymptotic normality of the parametric component. Simulations and two empirical applications demonstrate superior performance compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13420v5</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Tedesco, Francesco Finazzi</dc:creator>
    </item>
    <item>
      <title>Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality</title>
      <link>https://arxiv.org/abs/2410.18784</link>
      <description>arXiv:2410.18784v3 Announce Type: replace-cross 
Abstract: The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this line of work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Notably, our work is closely aligned with the independent concurrent work Potaptchik et al. (2024) -- posted two weeks prior to ours -- in establishing nearly linear-$k$ convergence guarantees for the DDPM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18784v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Huang, Yuting Wei, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Denoising Diffusions with Optimal Transport: Localization, Curvature, and Multi-Scale Complexity</title>
      <link>https://arxiv.org/abs/2411.01629</link>
      <description>arXiv:2411.01629v2 Announce Type: replace-cross 
Abstract: Adding noise is easy; what about denoising? Diffusion is easy; what about reverting a diffusion? Diffusion-based generative models aim to denoise a Langevin diffusion chain, moving from a log-concave equilibrium measure $\nu$, say an isotropic Gaussian, back to a complex, possibly non-log-concave initial measure $\mu$. The score function performs denoising, moving backward in time, and predicting the conditional mean of the past location given the current one. We show that score denoising is the optimal backward map in transportation cost. What is its localization uncertainty? We show that the curvature function determines this localization uncertainty, measured as the conditional variance of the past location given the current. We study in this paper the effectiveness of the diffuse-then-denoise process: the contraction of the forward diffusion chain, offset by the possible expansion of the backward denoising chain, governs the denoising difficulty. For any initial measure $\mu$, we prove that this offset net contraction at time $t$ is characterized by the curvature complexity of a smoothed $\mu$ at a specific signal-to-noise ratio (SNR) scale $r(t)$. We discover that the multi-scale curvature complexity collectively determines the difficulty of the denoising chain. Our multi-scale complexity quantifies a fine-grained notion of average-case curvature instead of the worst-case. Curiously, it depends on an integrated tail function, measuring the relative mass of locations with positive curvature versus those with negative curvature; denoising at a specific SNR scale is easy if such an integrated tail is light. We conclude with several non-log-concave examples to demonstrate how the multi-scale complexity probes the bottleneck SNR for the diffuse-then-denoise process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01629v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2026</arxiv:journal_reference>
      <dc:creator>Tengyuan Liang, Kulunu Dharmakeerthi, Takuya Koriyama</dc:creator>
    </item>
    <item>
      <title>Residual Feature Integration is Sufficient to Prevent Negative Transfer</title>
      <link>https://arxiv.org/abs/2505.11771</link>
      <description>arXiv:2505.11771v2 Announce Type: replace-cross 
Abstract: Transfer learning has become a central paradigm in modern machine learning, yet it suffers from the long-standing problem of negative transfer, where leveraging source representations can harm rather than help performance on the target task. Although empirical remedies have been proposed, there remains little theoretical understanding of how to reliably avoid negative transfer. In this paper, we investigate a simple yet remarkably effective strategy: augmenting frozen, pretrained source-side features with a trainable target-side encoder that adapts target features to capture residual signals overlooked by models pretrained on the source data. We show this residual feature integration strategy is sufficient to provably prevent negative transfer, by establishing theoretical guarantees that it has no worse convergence rate than training from scratch under the informative class of target distributions up to logarithmic factors, and that the convergence rate can transition seamlessly from nonparametric to near-parametric when source representations are informative. To our knowledge, this is the first theoretical work that ensures protection against negative transfer. We carry out extensive numerical experiments across image, text and tabular benchmarks, and empirically verify that the method consistently safeguards performance under distribution shift, label noise, semantic perturbation, and class imbalance. We additionally demonstrate that this residual integration mechanism uniquely supports adapt-time multimodality extension, enabling a pretrained single-cell foundation model to incorporate spatial signals for lymph-node anatomical classification despite the source model being trained without them. Our study thus advances the theory of safe transfer learning, and provides a principled approach that is simple, robust, architecture-agnostic, and broadly applicable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11771v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yichen Xu, Ryumei Nakada, Linjun Zhang, Lexin Li</dc:creator>
    </item>
    <item>
      <title>Multiple Hypothesis Testing To Estimate The Number Of Communities in Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2507.15471</link>
      <description>arXiv:2507.15471v2 Announce Type: replace-cross 
Abstract: Clustering of single-cell RNA sequencing (scRNA-seq) datasets can give key insights into the biological functions of cells. Therefore, it is not surprising that network-based community detection methods (one of the better clustering methods) are increasingly being used for the clustering of scRNA-seq datasets. The main challenge in implementing network-based community detection methods for scRNA-seq datasets is that these methods \emph{apriori} require the true number of communities or blocks for estimating the community memberships. Although there are existing methods for estimating the number of communities, they are not suitable for noisy scRNA-seq datasets. Moreover, we require an appropriate method for extracting suitable networks from scRNA-seq datasets. For addressing these issues, we present a two-fold solution: i) a simple likelihood-based approach for extracting stochastic block models (SBMs) out of scRNA-seq datasets, ii) a new sequential multiple testing (SMT) method for estimating the number of communities in SBMs. We study the theoretical properties of SMT and establish its consistency under moderate sparsity conditions. In addition, we compare the numerical performance of the SMT with several existing methods. We also show that our approach performs competitively well against existing methods for estimating the number of communities on benchmark scRNA-seq datasets. Finally, we use our approach for estimating subgroups of a human retina bipolar single cell dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15471v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chetkar Jha, Mingyao Li, Ian Barnett</dc:creator>
    </item>
    <item>
      <title>Differentially Private Two-Stage Gradient Descent for Instrumental Variable Regression</title>
      <link>https://arxiv.org/abs/2509.22794</link>
      <description>arXiv:2509.22794v3 Announce Type: replace-cross 
Abstract: We study instrumental variable regression (IVaR) under differential privacy constraints. Classical IVaR methods (like two-stage least squares regression) rely on solving moment equations that directly use sensitive covariates and instruments, creating significant risks of privacy leakage and posing challenges in designing algorithms that are both statistically efficient and differentially private. We propose a noisy two-stage gradient descent algorithm that ensures $\rho$-zero-concentrated differential privacy by injecting carefully calibrated noise into the gradient updates. Our analysis establishes finite-sample convergence rates for the proposed method, showing that the algorithm achieves consistency while preserving privacy. In particular, we derive precise bounds quantifying the trade-off among optimization, privacy, and sampling error. To the best of our knowledge, this is the first work to provide both privacy guarantees and provable convergence rates for instrumental variable regression in linear models. We further validate our theoretical findings with experiments on both synthetic and real datasets, demonstrating that our method offers practical accuracy-privacy trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22794v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haodong Liang, Yanhao Jin, Krishnakumar Balasubramanian, Lifeng Lai</dc:creator>
    </item>
    <item>
      <title>Inverse Mixed-Integer Programming: Learning Constraints then Objective Functions</title>
      <link>https://arxiv.org/abs/2510.04455</link>
      <description>arXiv:2510.04455v2 Announce Type: replace-cross 
Abstract: Data-driven inverse optimization for mixed-integer linear programs (MILPs), which seeks to learn an objective function and constraints consistent with observed decisions, is important for building accurate mathematical models in a variety of domains, including power systems and scheduling. However, to the best of our knowledge, existing data-driven inverse optimization methods primarily focus on learning objective functions under known constraints, and learning both objective functions and constraints from data remains largely unexplored. In this paper, we propose a two-stage approach for a class of inverse optimization problems in which the objective is a linear combination of given feature functions and the constraints are parameterized by unknown functions and thresholds. Our method first learns the constraints and then, conditioned on the learned constraints, estimates the objective-function weights. On the theoretical side, we provide finite-sample guarantees for solving the proposed inverse optimization problem. To this end, we develop statistical learning tools for pseudo-metric spaces under sub-Gaussian assumptions and use them to derive a learning-theoretic framework for inverse optimization with both unknown objectives and constraints. On the experimental side, we demonstrate that our method successfully solves inverse optimization problems on scheduling instances formulated as ILPs with up to 100 decision variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04455v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Akira Kitaoka</dc:creator>
    </item>
    <item>
      <title>The non-backtracking random walk and its usage for node and edge clustering</title>
      <link>https://arxiv.org/abs/2512.24434</link>
      <description>arXiv:2512.24434v3 Announce Type: replace-cross 
Abstract: Relation between the real eigenvalues of the non-backtracking matrix and those of the non-backtracking Laplacian is considered with respect to node clustering. For this purpose we use the real eigenvalues of the transition probability matrix (when the random walk goes through the oriented edges with the rule of ``not going back in the next step'') which have a linear relation to those of the non-backtracking Laplacian of Jost and Mulas. ``Inflation--deflation'' techniques are also developed for clustering the nodes of the original graph when it comes from the sparse stochastic block model of Bordenave and Decelle. Via the symmetrized normalized non-backtracking Laplacian, ``bottlenecks'' in the non-backtracking graph are detected, where the random walk goes through rarely in any direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24434v3</guid>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marianna Bolla</dc:creator>
    </item>
  </channel>
</rss>
