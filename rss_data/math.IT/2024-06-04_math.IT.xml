<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Jun 2024 04:09:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Stochastic Incentive-based Demand Response Program for Virtual Power Plant with Solar, Battery, Electric Vehicles, and Controllable Loads</title>
      <link>https://arxiv.org/abs/2406.00163</link>
      <description>arXiv:2406.00163v1 Announce Type: new 
Abstract: The growing integration of distributed energy resources (DERs) into the power grid necessitates an effective coordination strategy to maximize their benefits. Acting as an aggregator of DERs, a virtual power plant (VPP) facilitates this coordination, thereby amplifying their impact on the transmission level of the power grid. Further, a demand response program enhances the scheduling approach by managing the energy demands in parallel with the uncertain energy outputs of the DERs. This work presents a stochastic incentive-based demand response model for the scheduling operation of VPP comprising solar-powered generating stations, battery swapping stations, electric vehicle charging stations, and consumers with controllable loads. The work also proposes a priority mechanism to consider the individual preferences of electric vehicle users and consumers with controllable loads. The scheduling approach for the VPP is framed as a multi-objective optimization problem, normalized using the utopia-tracking method. Subsequently, the normalized optimization problem is transformed into a stochastic formulation to address uncertainties in energy demand from charging stations and controllable loads. The proposed VPP scheduling approach is addressed on a 33-node distribution system simulated using MATLAB software, which is further validated using a real-time digital simulator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00163v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pratik Harsh, Hongjian Sun, Debapriya Das, Goyal Awagan, Jing Jiang</dc:creator>
    </item>
    <item>
      <title>Over-the-Air Collaborative Inference with Feature Differential Privacy</title>
      <link>https://arxiv.org/abs/2406.00256</link>
      <description>arXiv:2406.00256v1 Announce Type: new 
Abstract: Collaborative inference in next-generation networks can enhance Artificial Intelligence (AI) applications, including autonomous driving, personal identification, and activity classification. This method involves a three-stage process: a) data acquisition through sensing, b) feature extraction, and c) feature encoding for transmission. Transmission of the extracted features entails the potential risk of exposing sensitive personal data. To address this issue, in this work a new privacy-protecting collaborative inference mechanism is developed. Under this mechanism, each edge device in the network protects the privacy of extracted features before transmitting them to a central server for inference. This mechanism aims to achieve two main objectives while ensuring effective inference performance: 1) reducing communication overhead, and 2) maintaining strict privacy guarantees during features transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00256v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Seif, Yuqi Nie, Andrea Goldsmith, Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Toward Quantum CSS-T Codes from Sparse Matrices</title>
      <link>https://arxiv.org/abs/2406.00425</link>
      <description>arXiv:2406.00425v1 Announce Type: new 
Abstract: CSS-T codes were recently introduced as quantum error-correcting codes that respect a transversal gate. A CSS-T code depends on a pair $(C_1, C_2)$ of binary linear codes $C_1$ and $C_2$ that satisfy certain conditions. We prove that $C_1$ and $C_2$ form a CSS-T pair if and only if $C_2 \subset \operatorname{Hull}(C_1) \cap \operatorname{Hull}(C_1^2)$, where the hull of a code is the intersection of the code with its dual. We show that if $(C_1,C_2)$ is a CSS-T pair, and the code $C_2$ is degenerated on $\{i\}$, meaning that the $i^{th}$-entry is zero for all the elements in $C_2$, then the pair of punctured codes $(C_1|_i,C_2|_i)$ is also a CSS-T pair. Finally, we provide Magma code based on our results and quasi-cyclic codes as a step toward finding quantum LDPC or LDGM CSS-T codes computationally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00425v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Camps-Moreno, Hiram H. L\'opez, Gretchen L. Matthews, Emily McMillon</dc:creator>
    </item>
    <item>
      <title>Cost-Effectiveness Analysis and Design of Cost-Efficient Cell-Free Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2406.00538</link>
      <description>arXiv:2406.00538v1 Announce Type: new 
Abstract: Cell-free massive multi-input multi-output (MIMO) has recently attracted much attention, attributed to its potential to deliver uniform service quality. However, the adoption of a cell-free architecture raises concerns about the high implementation costs associated with deploying numerous distributed access points (APs) and the need for fronthaul network installation. To ensure the sustainability of next-generation wireless networks, it is crucial to improve cost-effectiveness, alongside achieving high performance. To address this, we conduct a cost analysis of cell-free massive MIMO and build a unified model with varying numbers of antennas per AP. Our objective is to explore whether employing multi-antenna APs could reduce system costs while maintaining performance. The analysis and evaluation result in the identification of a cost-effective design for cell-free massive MIMO, providing valuable insights for practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00538v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Hans D. Schotten</dc:creator>
    </item>
    <item>
      <title>Lens-Type Redirective Intelligent Surfaces for Multi-User MIMO Communication</title>
      <link>https://arxiv.org/abs/2406.00556</link>
      <description>arXiv:2406.00556v1 Announce Type: new 
Abstract: This paper explores the idea of using redirective reconfigurable intelligent surfaces (RedRIS) to overcome many of the challenges associated with the conventional reflective RIS. We develop a framework for jointly optimizing the switching matrix of the lens-type RedRIS ports along with the active precoding matrix at the base station (BS) and the receive scaling factor. A joint non-convex optimization problem is formulated under the minimum mean-square error (MMSE) criterion with the aim to maximize the spectral efficiency of each user. In the single-cell scenario, the optimum active precoding matrix at the multi-antenna BS and the receive scaling factor are found in closed-form by applying Lagrange optimization, while the optimal switching matrix of the lens-type RedRIS is obtained by means of a newly developed alternating optimization algorithm. We then extend the framework to the multi-cell scenario with single-antenna base stations that are aided by the same lens-type RedRIS. We further present two methods for reducing the number of effective connections of the RedRIS ports that result in appreciable overhead savings while enhancing the robustness of the system. The proposed RedRIS-based schemes are gauged against conventional reflective RIS-aided systems under both perfect and imperfect channel state information (CSI). The simulation results show the superiority of the proposed schemes in terms of overall throughput while incurring much less control overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00556v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bamelak Tadele, Faouzi Bellili, Amine Mezghani, Md Jawwad Chowdhury, Haseeb Ur Rehman</dc:creator>
    </item>
    <item>
      <title>Reflection Map Construction: Enhancing and Speeding Up Indoor Localization</title>
      <link>https://arxiv.org/abs/2406.00563</link>
      <description>arXiv:2406.00563v1 Announce Type: new 
Abstract: This paper introduces an indoor localization method using fixed reflector objects within the environment, leveraging a base station (BS) equipped with Angle of Arrival (AoA) and Time of Arrival (ToA) measurement capabilities. The localization process includes two phases. In the offline phase, we identify effective reflector points within a specific region using significantly fewer test points than typical methods. In the online phase, we solve a maximization problem to locate users based on BS measurements and offline phase information. We introduce the reflectivity parameter (\(n_r\)), which quantifies the typical number of first-order reflection paths from the transmitter to the receiver, demonstrating its impact on localization accuracy. The log-scale accuracy ratio (\(R_a\)) is defined as the logarithmic function of the localization area divided by the localization ambiguity area, serving as an accuracy indicator. We show that in scenarios where the Signal-to-Noise Ratio (SNR) approaches infinity, without a line of sight (LoS) link, \(R_a\) is upper-bounded by \(n_r \log_{2}\left(1 + \frac{\mathrm{Vol}(\mathcal{S}_A)}{\mathrm{Vol}(\mathcal{S}_{\epsilon}(\mathcal{M}_s))}\right)\). Here, \(\mathrm{Vol}(\mathcal{S}_A)\) and \(\mathrm{Vol}(\mathcal{S}_{\epsilon}(\mathcal{M}_s))\) represent the areas of the localization region and the area containing all reflector points with a probability of at least \(1 - \epsilon\), respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00563v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milad Johnny, Shahrokh Valaee</dc:creator>
    </item>
    <item>
      <title>Artificial General Intelligence (AGI) for the oil and gas industry: a review</title>
      <link>https://arxiv.org/abs/2406.00594</link>
      <description>arXiv:2406.00594v1 Announce Type: new 
Abstract: Artificial General Intelligence (AGI) is set to profoundly impact the oil and gas industry by introducing unprecedented efficiencies and innovations. This paper explores AGI's foundational principles and its transformative applications, particularly focusing on the advancements brought about by large language models (LLMs) and extensive computer vision systems in the upstream sectors of the industry. The integration of Artificial Intelligence (AI) has already begun reshaping the oil and gas landscape, offering enhancements in production optimization, downtime reduction, safety improvements, and advancements in exploration and drilling techniques. These technologies streamline logistics, minimize maintenance costs, automate monotonous tasks, refine decision-making processes, foster team collaboration, and amplify profitability through error reduction and actionable insights extraction. Despite these advancements, the deployment of AI technologies faces challenges, including the necessity for skilled professionals for implementation and the limitations of model training on constrained datasets, which affects the models' adaptability across different contexts. The advent of generative AI, exemplified by innovations like ChatGPT and the Segment Anything Model (SAM), heralds a new era of high-density innovation. These developments highlight a shift towards natural language interfaces and domain-knowledge-driven AI, promising more accessible and tailored solutions for the oil and gas industry. This review articulates the vast potential AGI holds for tackling complex operational challenges within the upstream oil and gas industry, requiring near-human levels of intelligence. We discussed the promising applications, the hurdles of large-scale AGI model deployment, and the necessity for domain-specific knowledge in maximizing the benefits of these technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00594v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jimmy Xuekai Li, Tiancheng Zhang, Yiran Zhu, Zhongwei Chen</dc:creator>
    </item>
    <item>
      <title>Hybrid Beamforming Design for Integrated Sensing and Communication Exploiting Prior Information</title>
      <link>https://arxiv.org/abs/2406.00689</link>
      <description>arXiv:2406.00689v1 Announce Type: new 
Abstract: In this paper, we investigate the hybrid beamforming design for a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system, where a multi-antenna base station (BS) with hybrid analog-digital transmit antenna arrays sends dual-functional signals to communicate with a multi-antenna user and simultaneously sense the location information of a point target based on the reflected echo signals. Specifically, we aim to sense the target's unknown and random angle information by exploiting its prior distribution information, with posterior Cram\'{e}r-Rao bound (PCRB) employed as the sensing performance metric. First, we consider a sensing-only case and study the hybrid beamforming optimization to minimize the sensing PCRB. We analytically prove that hybrid beamforming can achieve the same performance as the optimized digital beamforming as long as the number of radio frequency (RF) chains is larger than 1. Then, we propose a convex relaxation based algorithm for the hybrid beamforming design with a single RF chain. Next, we study the hybrid beamforming optimization to minimize the PCRB subject to a communication rate target. Due to the intractability of the exact PCRB expression, we replace it with a tight upper bound. Although this problem is still non-convex and challenging to solve, we propose an alternating optimization (AO) algorithm for finding a high-quality suboptimal solution based on the feasible point pursuit successive convex approximation (FPP-SCA) method. Numerical results validate the effectiveness of our proposed hybrid beamforming design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00689v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhuo Wang, Shuowen Zhang</dc:creator>
    </item>
    <item>
      <title>Age-Gain-Dependent Random Access for Event-Driven Periodic Updating</title>
      <link>https://arxiv.org/abs/2406.00720</link>
      <description>arXiv:2406.00720v1 Announce Type: new 
Abstract: This paper considers utilizing the knowledge of age gains to reduce the network average age of information (AoI) in random access with event-driven periodic updating for the first time. Built on the form of slotted ALOHA, we require each device to determine its age gain threshold and transmission probability in an easily implementable decentralized manner, so that the unavoided contention can be limited to devices with age gains as high as possible. For the basic case that each device utilizes its knowledge of age gain of only itself, we provide an analytical modeling approach by a multi-layer discrete-time Markov chains (DTMCs), where an external infinite-horizon DTMC manages the jumps between the beginnings of frames and an internal finite-horizon DTMC manages the evolution during an arbitrary frame. Such modelling enables that optimal access parameters can be obtained offline. For the enhanced case that each device utilizes its knowledge of age gains of all the devices, we require each device to adjust its access parameters for maximizing the estimated network \textit{expected AoI reduction} (EAR) per slot, which captures the essential for improving the contribution of the throughput to the AoI performance. To estimate the network EAR, we require each device to use Bayes' rule to keep a posteriori joint probability distribution of local age and age gain of an arbitrary device based on the channel observations. Numerical results validate our theoretical analysis and demonstrate the advantage of the proposed schemes over the existing schemes in a wide range of network configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00720v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Zhu, Yiwen Zhu, Aoyu Gong, Yan Lin, Yijin Zhang</dc:creator>
    </item>
    <item>
      <title>A Toolbox for Refined Information-Theoretic Analyses with Applications</title>
      <link>https://arxiv.org/abs/2406.00744</link>
      <description>arXiv:2406.00744v1 Announce Type: new 
Abstract: This monograph offers a toolbox of mathematical techniques, which have been effective and widely applicable in information-theoretic analysis. The first tool is a generalization of the method of types to Gaussian settings, and then to general exponential families. The second tool is Laplace and saddle-point integration, which allow to refine the results of the method of types, and are capable of obtaining more precise results. The third is the type class enumeration method, a principled method to evaluate the exact random-coding exponent of coded systems, which results in the best known exponent in various problem settings. The fourth subset of tools aimed at evaluating the expectation of non-linear functions of random variables, either via integral representations, or by a refinement of Jensen's inequality via change-of-measure, by complementing Jensen's inequality with a reversed inequality, or by a class of generalized Jensen's inequalities that are applicable for functions beyond convex/concave. Various application examples of all these tools are provided along this monograph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00744v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neri Merhav, Nir Weinberger</dc:creator>
    </item>
    <item>
      <title>Bounds on f-Divergences between Distributions within Generalized Quasi-$\varepsilon$-Neighborhood</title>
      <link>https://arxiv.org/abs/2406.00939</link>
      <description>arXiv:2406.00939v1 Announce Type: new 
Abstract: A general reverse Pinsker's inequality is derived to give an upper bound on f-divergences in terms of total variational distance when two distributions are close measured under our proposed generalized local information geometry framework. In addition, relationships between two f-divergences equipped with functions that are third order differentiable are established in terms of the lower and upper bounds of their ratio, when the underlying distributions are within a generalized quasi-$\varepsilon$-neighborhood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00939v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinchun Yu, Shuangqing Wei, Shao-Lun Huang, Xiao-Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Geometric constellation shaping for wireless optical intensity channels</title>
      <link>https://arxiv.org/abs/2406.01031</link>
      <description>arXiv:2406.01031v1 Announce Type: new 
Abstract: A simple geometric shaping method is proposed for optical wireless communication systems based on intensity modulation and direct detection (IM/DD). Constellations consisting of equiprobable levels with exponential-like distribution are obtained. The method possesses asymptotic optimality in the sense that the high-SNR channel capacity can be approached by such constellations with increasing size. By an additional quantization step, all $2^b$ levels ($b \in \mathbb N$) of the obtained constellation can be represented by a basic level and $b+2$ bits, thereby reducing the required resolution of the digital-to-analog converter (DAC) without affecting the asymptotic optimality. Achievable information rate evaluations verify the asymptotic optimality of the proposed method. As an example, error performance results of a simple 16-level LDPC coded modulation scheme show that a shaping gain of 0.8 dB can be obtained by applying the proposed constellation design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01031v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Suhua Zhou, Tianqi Li, Zhaoxi Fang, Jing Zhou, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>3D Trajectory Design for Energy-constrained Aerial CRNs Under Probabilistic LoS Channel</title>
      <link>https://arxiv.org/abs/2406.01313</link>
      <description>arXiv:2406.01313v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) have been attracting significant attention because there is a high probability of line-of-sight links being obtained between them and terrestrial nodes in high-rise urban areas. In this work, we investigate cognitive radio networks (CRNs) by jointly designing three-dimensional (3D) trajectory, the transmit power of the UAV, and user scheduling. Considering the UAV's onboard energy consumption, an optimization problem is formulated in which the average achievable rate of the considered system is maximized by jointly optimizing the UAV's 3D trajectory, transmission power, and user scheduling. Due to the non-convex optimization problem, a lower bound on the average achievable rate is utilized to reduce the complexity of the solution. Subsequently, the original optimization problem is decoupled into four subproblems by using block coordinate descent, and each subproblem is transformed into manageable convex optimization problems by introducing slack variables and successive convex approximation. Numerical results validate the effectiveness of our proposed algorithm and demonstrate that the 3D trajectories of UAVs can enhance the average achievable rate of aerial CRNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01313v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongjiang Lei, Xiaqiu Wu, Ki-Hong Park, Gaofeng Pan</dc:creator>
    </item>
    <item>
      <title>Performance Trade-off of Integrated Sensing and Communications for Multi-User Backscatter Systems</title>
      <link>https://arxiv.org/abs/2406.01331</link>
      <description>arXiv:2406.01331v1 Announce Type: new 
Abstract: This paper studies the performance trade-off in a multi-user backscatter communication (BackCom) system for integrated sensing and communications (ISAC), where the multi-antenna ISAC transmitter sends excitation signals to power multiple single-antenna passive backscatter devices (BD), and the multi-antenna ISAC receiver performs joint sensing (localization) and communication tasks based on the backscattered signals from all BDs. Specifically, the localization performance is measured by the Cram\'{e}r-Rao bound (CRB) on the transmission delay and direction of arrival (DoA) of the backscattered signals, whose closed-form expression is obtained by deriving the corresponding Fisher information matrix (FIM), and the communication performance is characterized by the sum transmission rate of all BDs. Then, to characterize the trade-off between the localization and communication performances, the CRB minimization problem with the communication rate constraint is formulated, and is shown to be non-convex in general. By exploiting the hidden convexity, we propose an approach that combines fractional programming (FP) and Schur complement techniques to transform the original problem into an equivalent convex form. Finally, numerical results reveal the trade-off between the CRB and sum transmission rate achieved by our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01331v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanming Tian, Dan Wang, Chuan Huang, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>High Throughput Polar Code Decoders with Information Bottleneck Quantization</title>
      <link>https://arxiv.org/abs/2406.01426</link>
      <description>arXiv:2406.01426v1 Announce Type: new 
Abstract: In digital baseband processing, the forward error correction (FEC) unit belongs to the most demanding components in terms of computational complexity and power consumption. Hence, efficient implementation of FEC decoders is crucial for next generation mobile broadband standards and an ongoing research topic. Quantization has a significant impact on the decoder area, power consumption and throughput. Thus, lower bit-widths are preferred for efficient implementations but degrade the error-correction capability. To address this issue, a non-uniform quantization based on the Information Bottleneck (IB) method was proposed that enables a low bit width while maintaining the essential information. Many investigations on the use of IB method for Low-density parity-check code (LDPC) decoders exist and have shown its advantages from an implementation perspective. However, for polar code decoder implementations, there exists only one publication that is not based on the state-of-the-art Fast-SSC decoding algorithm, and only synthesis implementation results without energy estimation are shown. In contrast, our paper presents several optimized Fast Simplified Successive-Cancellation (Fast-SSC) polar code decoder implementations using IB-based quantization with placement&amp;routing results in an advanced 12 nm FinFET technology. Gains of up to 16% in area and 13% in energy efficiency are achieved with IB-based quantization at a Frame Error Rate (FER) of 10-7 and a Polar Code of N = 1024, R = 0.5 compared to state-of-the-art decoders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01426v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claus Kestel, Lucas Johannsen, Norbert Wehn</dc:creator>
    </item>
    <item>
      <title>Near-Field Beam Tracking with Extremely Large Dynamic Metasurface Antennas</title>
      <link>https://arxiv.org/abs/2406.01488</link>
      <description>arXiv:2406.01488v1 Announce Type: new 
Abstract: The interplay between large antenna apertures and high frequencies in future generations of wireless networks will give rise to near-field communications. In this paper, we focus on the hybrid analog and digital beamforming architecture of dynamic metasurface antennas, which constitutes a recent prominent enabler of extremely massive antenna architectures, and devise a near-field beam tracking framework that initiates near-field beam sweeping only when the base station estimates that its provided beamforming gain drops below a threshold from its theoretically optimum value. Novel analytical expressions for the correlation function between any two beam focusing vectors, the beamforming gain with respect to user coordinate mismatch, the direction of the user movement yielding the fastest beamforming gain deterioration, and the minimum user displacement for a certain performance loss are presented. We also design a non-uniform coordinate grid for effectively sampling the user area of interest at each position estimation slot. Our extensive simulation results validate our theoretical analysis and showcase the superiority of the proposed near-field beam tracking over benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01488v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Panagiotis Gavriilidis, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>There are no good infinite families of toric codes</title>
      <link>https://arxiv.org/abs/2406.00243</link>
      <description>arXiv:2406.00243v1 Announce Type: cross 
Abstract: Soprunov and Soprunova introduced the notion of a good infinite family of toric codes. We prove that such good families do not exist by proving a more general Szemer\'edi-type result: for all $c\in(0,1]$ and all positive integers $N$, subsets of density at least $c$ in $\{0,1,\dots,N-1\}^n$ contain hypercubes of arbitrarily large dimension as $n$ grows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00243v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.AG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason P. Bell, Sean Monahan, Matthew Satriano, Karen Situ, Zheng Xie</dc:creator>
    </item>
    <item>
      <title>Coded Computing: A Learning-Theoretic Framework</title>
      <link>https://arxiv.org/abs/2406.00300</link>
      <description>arXiv:2406.00300v1 Announce Type: cross 
Abstract: Coded computing has emerged as a promising framework for tackling significant challenges in large-scale distributed computing, including the presence of slow, faulty, or compromised servers. In this approach, each worker node processes a combination of the data, rather than the raw data itself. The final result then is decoded from the collective outputs of the worker nodes. However, there is a significant gap between current coded computing approaches and the broader landscape of general distributed computing, particularly when it comes to machine learning workloads. To bridge this gap, we propose a novel foundation for coded computing, integrating the principles of learning theory, and developing a new framework that seamlessly adapts with machine learning applications. In this framework, the objective is to find the encoder and decoder functions that minimize the loss function, defined as the mean squared error between the estimated and true values. Facilitating the search for the optimum decoding and functions, we show that the loss function can be upper-bounded by the summation of two terms: the generalization error of the decoding function and the training error of the encoding function. Focusing on the second-order Sobolev space, we then derive the optimal encoder and decoder. We show that in the proposed solution, the mean squared error of the estimation decays with the rate of $O(S^4 N^{-3})$ and $O(S^{\frac{8}{5}}N^{\frac{-3}{5}})$ in noiseless and noisy computation settings, respectively, where $N$ is the number of worker nodes with at most $S$ slow servers (stragglers). Finally, we evaluate the proposed scheme on inference tasks for various machine learning models and demonstrate that the proposed framework outperforms the state-of-the-art in terms of accuracy and rate of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00300v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Parsa Moradi, Behrooz Tahmasebi, Mohammad Ali Maddah-Ali</dc:creator>
    </item>
    <item>
      <title>Conformal Transformation of Kernels: A Geometric Perspective on Text Classification</title>
      <link>https://arxiv.org/abs/2406.00499</link>
      <description>arXiv:2406.00499v1 Announce Type: cross 
Abstract: In this article we investigate the effects of conformal transformations on kernel functions used in Support Vector Machines. Our focus lies in the task of text document categorization, which involves assigning each document to a particular category. We introduce a new Gaussian Cosine kernel alongside two conformal transformations. Building upon previous studies that demonstrated the efficacy of conformal transformations in increasing class separability on synthetic and low-dimensional datasets, we extend this analysis to the high-dimensional domain of text data. Our experiments, conducted on the Reuters dataset on two types of binary classification tasks, compare the performance of Linear, Gaussian, and Gaussian Cosine kernels against their conformally transformed counterparts. The findings indicate that conformal transformations can significantly improve kernel performance, particularly for sub-optimal kernels. Specifically, improvements were observed in 60% of the tested scenarios for the Linear kernel, 84% for the Gaussian kernel, and 80% for the Gaussian Cosine kernel. In light of these findings, it becomes clear that conformal transformations play a pivotal role in enhancing kernel performance, offering substantial benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00499v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.DG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioana R\u{a}dulescu (L\u{a}z\u{a}rescu), Alexandra B\u{a}icoianu, Adela Mihai</dc:creator>
    </item>
    <item>
      <title>Generalized Exponentiated Gradient Algorithms and Their Application to On-Line Portfolio Selection</title>
      <link>https://arxiv.org/abs/2406.00655</link>
      <description>arXiv:2406.00655v1 Announce Type: cross 
Abstract: This paper introduces a novel family of generalized exponentiated gradient (EG) updates derived from an Alpha-Beta divergence regularization function. Collectively referred to as EGAB, the proposed updates belong to the category of multiplicative gradient algorithms for positive data and demonstrate considerable flexibility by controlling iteration behavior and performance through three hyperparameters: $\alpha$, $\beta$, and the learning rate $\eta$. To enforce a unit $l_1$ norm constraint for nonnegative weight vectors within generalized EGAB algorithms, we develop two slightly distinct approaches. One method exploits scale-invariant loss functions, while the other relies on gradient projections onto the feasible domain. As an illustration of their applicability, we evaluate the proposed updates in addressing the online portfolio selection problem (OLPS) using gradient-based methods. Here, they not only offer a unified perspective on the search directions of various OLPS algorithms (including the standard exponentiated gradient and diverse mean-reversion strategies), but also facilitate smooth interpolation and extension of these updates due to the flexibility in hyperparameter selection. Simulation results confirm that the adaptability of these generalized gradient updates can effectively enhance the performance for some portfolios, particularly in scenarios involving transaction costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00655v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrzej Cichocki, Sergio Cruces, Auxiliadora Sarmiento, Toshihisa Tanaka</dc:creator>
    </item>
    <item>
      <title>How disinformation and fake news impact public policies?: A review of international literature</title>
      <link>https://arxiv.org/abs/2406.00951</link>
      <description>arXiv:2406.00951v1 Announce Type: cross 
Abstract: This study investigates the impact of disinformation on public policies. Using 28 sets of keywords in eight databases, a systematic review was carried out following the Prisma 2020 model (Page et al., 2021). After applying filters and inclusion and exclusion criteria to 4,128 articles and materials found, 46 publications were analyzed, resulting in 23 disinformation impact categories. These categories were organized into two main axes: State and Society and Actors and Dynamics, covering impacts on State actors, society actors, State dynamics and society dynamics. The results indicate that disinformation affects public decisions, adherence to policies, prestige of institutions, perception of reality, consumption, public health and other aspects. Furthermore, this study suggests that disinformation should be treated as a public problem and incorporated into the public policy research agenda, contributing to the development of strategies to mitigate its effects on government actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00951v1</guid>
      <category>cs.CY</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ergon Cugler de Moraes Silva, Jose Carlos Vaz</dc:creator>
    </item>
    <item>
      <title>Precise Analysis of Covariance Identifiability for Activity Detection in Grant-Free Random Access</title>
      <link>https://arxiv.org/abs/2406.01138</link>
      <description>arXiv:2406.01138v1 Announce Type: cross 
Abstract: We consider the identifiability issue of maximum likelihood based activity detection in massive MIMO based grant-free random access. A prior work by Chen et al. indicates that the identifiability undergoes a phase transition for commonly-used random signatures. In this paper, we provide an analytical characterization of the boundary of the phase transition curve. Our theoretical results agree well with the numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01138v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengsong Luo, Junjie Ma, Chongbin Xu, Xin Wang</dc:creator>
    </item>
    <item>
      <title>Agnostic Learning of Mixed Linear Regressions with EM and AM Algorithms</title>
      <link>https://arxiv.org/abs/2406.01149</link>
      <description>arXiv:2406.01149v1 Announce Type: cross 
Abstract: Mixed linear regression is a well-studied problem in parametric statistics and machine learning. Given a set of samples, tuples of covariates and labels, the task of mixed linear regression is to find a small list of linear relationships that best fit the samples. Usually it is assumed that the label is generated stochastically by randomly selecting one of two or more linear functions, applying this chosen function to the covariates, and potentially introducing noise to the result. In that situation, the objective is to estimate the ground-truth linear functions up to some parameter error. The popular expectation maximization (EM) and alternating minimization (AM) algorithms have been previously analyzed for this.
  In this paper, we consider the more general problem of agnostic learning of mixed linear regression from samples, without such generative models. In particular, we show that the AM and EM algorithms, under standard conditions of separability and good initialization, lead to agnostic learning in mixed linear regression by converging to the population loss minimizers, for suitably defined loss functions. In some sense, this shows the strength of AM and EM algorithms that converges to ``optimal solutions'' even in the absence of realizable generative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01149v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avishek Ghosh, Arya Mazumdar</dc:creator>
    </item>
    <item>
      <title>Linear Index for Logarithmic Search-Time for any String under any Internal Node in Suffix Trees</title>
      <link>https://arxiv.org/abs/2406.01174</link>
      <description>arXiv:2406.01174v1 Announce Type: cross 
Abstract: Suffix trees are key and efficient data structure for solving string problems. A suffix tree is a compressed trie containing all the suffixes of a given text of length $n$ with a linear construction cost. In this work, we introduce an algorithm to build a linear index that allows finding a pattern of any length under any internal node in a suffix tree in O(logn) time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01174v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anas Al-okaily</dc:creator>
    </item>
    <item>
      <title>Physics-informed deep learning and compressive collocation for high-dimensional diffusion-reaction equations: practical existence theory and numerics</title>
      <link>https://arxiv.org/abs/2406.01539</link>
      <description>arXiv:2406.01539v1 Announce Type: cross 
Abstract: On the forefront of scientific computing, Deep Learning (DL), i.e., machine learning with Deep Neural Networks (DNNs), has emerged a powerful new tool for solving Partial Differential Equations (PDEs). It has been observed that DNNs are particularly well suited to weakening the effect of the curse of dimensionality, a term coined by Richard E. Bellman in the late `50s to describe challenges such as the exponential dependence of the sample complexity, i.e., the number of samples required to solve an approximation problem, on the dimension of the ambient space. However, although DNNs have been used to solve PDEs since the `90s, the literature underpinning their mathematical efficiency in terms of numerical analysis (i.e., stability, accuracy, and sample complexity), is only recently beginning to emerge. In this paper, we leverage recent advancements in function approximation using sparsity-based techniques and random sampling to develop and analyze an efficient high-dimensional PDE solver based on DL. We show, both theoretically and numerically, that it can compete with a novel stable and accurate compressive spectral collocation method. In particular, we demonstrate a new practical existence theorem, which establishes the existence of a class of trainable DNNs with suitable bounds on the network architecture and a sufficient condition on the sample complexity, with logarithmic or, at worst, linear scaling in dimension, such that the resulting networks stably and accurately approximate a diffusion-reaction PDE with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01539v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Brugiapaglia, Nick Dexter, Samir Karam, Weiqi Wang</dc:creator>
    </item>
    <item>
      <title>Near-Field Wideband Beamforming for Extremely Large Antenna Arrays</title>
      <link>https://arxiv.org/abs/2109.10054</link>
      <description>arXiv:2109.10054v4 Announce Type: replace 
Abstract: The natural integration of extremely large antenna arrays (ELAAs) and terahertz (THz) communications can potentially achieve Tbps data rates in 6G networks. However, due to the extremely large array aperture and wide bandwidth, a new phenomenon called "near-field beam split" emerges. This phenomenon causes beams at different frequencies to focus on distinct physical locations, leading to a significant gain loss of beamforming. To address this challenging problem, we first harness a piecewise-far-field channel model to approximate the complicated near-field wideband channel. In this model, the entire large array is partitioned into several small sub-arrays. While the wireless channel's phase discrepancy across the entire array is modeled as near-field spherical, the phase discrepancy within each sub-array is approximated as far-field planar. Built on this approximation, a phase-delay focusing (PDF) method employing delay phase precoding (DPP) architecture is proposed. Our PDF method could compensate for the intra-array far-field phase discrepancy and the inter-array near-field phase discrepancy via the joint control of phase shifters and time delayers, respectively. Theoretical and numerical results are provided to demonstrate the efficiency of the proposed PDF method in mitigating the near-field beam split effect.Finally, we define and derive a novel metric termed the "effective Rayleigh distance" by the evaluation of beamforming gain loss. Compared to classical Rayleigh distance, the effective Rayleigh distance is more accurate in determining the near-field range for practical communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.10054v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mingyao Cui, Linglong Dai</dc:creator>
    </item>
    <item>
      <title>Secure SWIPT in the Multiuser STAR-RIS Aided MISO Rate Splitting Downlink</title>
      <link>https://arxiv.org/abs/2211.09081</link>
      <description>arXiv:2211.09081v3 Announce Type: replace 
Abstract: Recently, simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) have emerged as a novel technology that provides 360 coverage and new degrees-of-freedom (DoFs). They are also capable of manipulating signal propagation and simultaneous wireless information and power transfer (SWIPT). This paper introduces a novel STAR-RIS-aided secure SWIPT system for downlink multiple input single output rate-splitting multiple access (RSMA) networks. The transmitter concurrently communicates with the information receivers (IRs) and sends energy to untrusted energy receivers (UERs). The UERs are also capable of wiretapping the IR streams. We assume that the channel state information (CSI) of the IRs is known at the information transmitter, but only imperfect CSI for the UERs is available at the energy transmitter. By exploiting RSMA, the base station splits the messages of the IRs into common and private parts. The former is encoded into a common stream that can be decoded by all IRs, while the private messages are individually decoded by their respective IRs. We find the precoders and STAR-RIS configuration that maximizes the achievable worst-case sum secrecy rate of the IRs under a total transmit power constraint, a sum energy constraint for the UERs, and subject to constraints on the transmission and reflection coefficients. The formulated problem is non-convex and has intricately coupled variables. To tackle this challenge, a suboptimal two-step iterative algorithm based on the sequential parametric convex approximation method is proposed. Simulations demonstrate that the RSMA-based algorithm implemented with a STAR-RIS enhances both the rate of confidential information transmission and the total spectral efficiency. Furthermore, our method surpasses the performance of both orthogonal multiple access (OMA) and non-OMA (NOMA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09081v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2024.3398057</arxiv:DOI>
      <dc:creator>Hamid Reza Hashempour, Hamed Bastami, Majid Moradikia, Seyed A. Zekavat, Hamid Behroozi, Gilberto Berardinelli, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Pilotless Uplink for Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2305.12431</link>
      <description>arXiv:2305.12431v2 Announce Type: replace 
Abstract: Massive MIMO OFDM waveforms help support a large number of users in the same time-frequency resource and also provide significant array gain for uplink reception in cellular systems. However, channel estimation in such large antenna systems can be tricky as pilot assignment for multiple users becomes more challenging with increasing number of users. Additionally, the pilot overhead especially for wideband rapidly changing channels can diminish the system throughput quite significantly. In this paper, we propose an iterative matrix decomposition algorithm for the blind demodulation of massive MIMO OFDM signals without using any pilots. This new decomposition technique provides estimates of both the user symbols and the user channel in the frequency domain simultaneously (to a scaling factor) without any pilots. We discuss methods for finding the appropriate initial points for the algorithm that ensure its convergence in different types of wireless channels. We also propose new methods for resolving the scaling factor in the estimated signal that do not increase pilot overhead. We show how the method can be adapted to both single-user and multi-user systems. Simulation results demonstrate that the lack of pilots does not affect the error performance of the proposed algorithm when compared to the conventional pilot-based channel estimation and equalization methods across a wide range of channels for both single and multi-user cases. We also demonstrate techniques to reduce the complexity of the estimation algorithm over multiple OFDM symbols in a 5G MIMO system by leveraging the temporal correlations in the channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12431v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/GLOBECOM54140.2023.10437723</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2023 IEEE Global Communications Conference, 4205-4210</arxiv:journal_reference>
      <dc:creator>P Aswathylakshmi, Radha Krishna Ganti</dc:creator>
    </item>
    <item>
      <title>Accelerating Graph Neural Networks via Edge Pruning for Power Allocation in Wireless Networks</title>
      <link>https://arxiv.org/abs/2305.12639</link>
      <description>arXiv:2305.12639v2 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) have recently emerged as a promising approach to tackling power allocation problems in wireless networks. Since unpaired transmitters and receivers are often spatially distant, the distance-based threshold is proposed to reduce the computation time by excluding or including the channel state information in GNNs. In this paper, we are the first to introduce a neighbour-based threshold approach to GNNs to reduce the time complexity. Furthermore, we conduct a comprehensive analysis of both distance-based and neighbour-based thresholds and provide recommendations for selecting the appropriate value in different communication channel scenarios. We design the corresponding neighbour-based Graph Neural Networks (N-GNN) with the aim of allocating transmit powers to maximise the network throughput. Our results show that our proposed N-GNN offer significant advantages in terms of reducing time complexity while preserving strong performance and generalisation capacity. Besides, we show that by choosing a suitable threshold, the time complexity is reduced from O(|V|^2) to O(|V|), where |V| is the total number of transceiver pairs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12639v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/GCWkshps58843.2023.10465155</arxiv:DOI>
      <arxiv:journal_reference>2023 IEEE Globecom Workshops (GC Workshops)</arxiv:journal_reference>
      <dc:creator>Lili Chen, Jingge Zhu, Jamie Evans</dc:creator>
    </item>
    <item>
      <title>Optimal Transmit Antenna Deployment and Power Allocation for Wireless Power Supply in an Indoor Space</title>
      <link>https://arxiv.org/abs/2307.02076</link>
      <description>arXiv:2307.02076v2 Announce Type: replace 
Abstract: As Internet of Things (IoT) devices proliferate, sustainable methods for powering them are becoming indispensable. The wireless provision of power enables battery-free operation and is crucial for complying with weight and size restrictions. For the energy harvesting (EH) components of these devices to be small, a high operating frequency is necessary. In conjunction with a large transmit antenna, the receivers may be located in the radiating near-field (Fresnel) region, e.g., in indoor scenarios. In this paper, we propose a wireless power transfer (WPT) system ensuring reliable supply of power to an arbitrary number of mobile, low-power, and single-antenna receivers, whose locations in a three-dimensional cuboid room are unknown. A max-min optimisation problem is formulated to determine the optimal transmit power distribution. We rigorously prove that the optimal transmit power distribution's support has a lower dimensionality than its domain and thus, the employment of a continuous aperture antenna, utilised in Holographic MIMO (HMIMO), is unnecessary in the context of the considered WPT problem. Indeed, deploying a discrete transmit antenna architecture, i.e., a transmit antenna array, is sufficient and our proposed solution provides the optimal transmit antenna deployment and power allocation. Moreover, for a one-dimensional transmit antenna architecture, a finite number of transmit antennas is proven to be optimal. The proposed optimal solution is validated through computer simulations. Our simulation results indicate that the optimal transmit antenna architecture requires a finite number of transmit antennas and depends on the geometry of the environment and the dimensionality of the transmit antenna array.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.02076v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/OJCOMS.2024.3407861</arxiv:DOI>
      <dc:creator>Kenneth M. Mayer, Laura Cottatellucci, Robert Schober</dc:creator>
    </item>
    <item>
      <title>Octonion Phase Retrieval</title>
      <link>https://arxiv.org/abs/2308.15784</link>
      <description>arXiv:2308.15784v2 Announce Type: replace 
Abstract: Signal processing over hypercomplex numbers arises in many optical imaging applications. In particular, spectral image or color stereo data are often processed using octonion algebra. Recently, the eight-band multispectral image phase recovery has gained salience, wherein it is desired to recover the eight bands from the phaseless measurements. In this paper, we tackle this hitherto unaddressed hypercomplex variant of the popular phase retrieval (PR) problem. We propose octonion Wirtinger flow (OWF) to recover an octonion signal from its intensity-only observation. However, contrary to the complex-valued Wirtinger flow, the non-associative nature of octonion algebra and the consequent lack of octonion derivatives make the extension to OWF non-trivial. We resolve this using the pseudo-real-matrix representation of octonion to perform the derivatives in each OWF update. We demonstrate that our approach recovers the octonion signal up to a right-octonion phase factor. Numerical experiments validate OWF-based PR with high accuracy under both noiseless and noisy measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15784v2</guid>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Jacome, Kumar Vijay Mishra, Brian M. Sadler, Henry Arguello</dc:creator>
    </item>
    <item>
      <title>Flag Sequence Set Design for Low-Complexity Delay-Doppler Estimation</title>
      <link>https://arxiv.org/abs/2310.10457</link>
      <description>arXiv:2310.10457v2 Announce Type: replace 
Abstract: This paper studies Flag sequences for low-complexity delay-Doppler estimation by exploiting their distinctive peak-curtain ambiguity functions (AFs). Unlike the existing Flag sequence designs that are limited to prime lengths and periodic auto-AFs, we aim to design Flag sequence sets of arbitrary lengths with low (nontrivial) periodic/aperiodic auto- and cross-AFs. Since every Flag sequence consists of a Curtain sequence and a Peak sequence, we first investigate the algebraic design of Curtain sequence sets of arbitrary lengths. Our proposed design gives rise to novel Curtain sequence sets with ideal curtain auto-AFs and zero/near-zero cross-AFs within the delay-Doppler zone of operation. Leveraging these Curtain sequence sets, two optimization problems are formulated to minimize the Weighted Integrated masked Sidelobe Level (WImSL) of the Flag sequence set. Accelerated Parallel Partially Majorization-Minimization Algorithms are proposed to jointly optimize the transmit Flag sequences and symmetric/asymmetric reference sequences stored in the receiver. Simulations demonstrate that our proposed Flag sequences lead to improved WImSL and peak-to-max-masked-sidelobe ratio compared with the existing Flag sequences. Additionally, our Flag sequences under the Flag method exhibit Mean Squared Errors that approach the Cram\'er-Rao Lower Bound and the Sampling Bound at high signal-to-noise power ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10457v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingsheng Meng, Yong Liang Guan, Yao Ge, Zilong Liu</dc:creator>
    </item>
    <item>
      <title>Wireless 6G Connectivity for Massive Number of Devices and Critical Services</title>
      <link>https://arxiv.org/abs/2401.01127</link>
      <description>arXiv:2401.01127v3 Announce Type: replace 
Abstract: Compared to the generations up to 4G, whose main focus was on broadband and coverage aspects, 5G has expanded the scope of wireless cellular systems towards embracing two new types of connectivity: massive machine-type communication (mMTC) and ultra-reliable low-latency communications (URLLC). This paper will discuss the possible evolution of these two types of connectivity within the umbrella of 6G wireless systems. The paper consists of three parts. The first part deals with the connectivity for a massive number of devices. While mMTC research in 5G was predominantly focused on the problem of uncoordinated access in the uplink for a large number of devices, the traffic patterns in 6G may become more symmetric, leading to closed-loop massive connectivity. One of the drivers for this is distributed learning/inference. The second part of the paper will discuss the evolution of wireless connectivity for critical services. While latency and reliability are tightly coupled in 5G, 6G will support a variety of safety critical control applications with different types of timing requirements, as evidenced by the emergence of metrics related to information freshness and information value. Additionally, ensuring ultra-high reliability for safety critical control applications requires modeling and estimation of the tail statistics of the wireless channel, queue length, and delay. The fulfillment of these stringent requirements calls for the development of novel AI-based techniques, incorporating optimization theory, explainable AI, generative AI and digital twins. The third part will analyze the coexistence of massive connectivity and critical services. We will consider scenarios in which a massive number of devices need to support traffic patterns of mixed criticality. This will be followed by a discussion about the management of wireless resources shared by services with different criticality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01127v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anders E. Kal{\o}r, Giuseppe Durisi, Sinem Coleri, Stefan Parkvall, Wei Yu, Andreas Mueller, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Secure Spatial Signal Design for ISAC in a Cell-Free MIMO Network</title>
      <link>https://arxiv.org/abs/2401.12901</link>
      <description>arXiv:2401.12901v2 Announce Type: replace 
Abstract: In this paper, we study a cell-free multiple-input multiple-output network equipped with integrated sensing and communication (ISAC) access points (APs). The distributed APs are used to jointly serve the communication needs of user equipments (UEs) while sensing a target, assumed to be an eavesdropper (Eve). To increase the system's robustness towards said Eve, we develop an ISAC waveform model that includes artificial noise (AN) aimed at degrading the Eve channel quality. The central processing unit receives the observations from each AP and calculates the optimal precoding and AN covariance matrices by solving a semi-definite relaxation of a constrained Cramer-Rao bound (CRB) minimization problem. Simulation results highlight an underlying trade-off between sensing and communication performances: in particular, the UEs signal-to-noise and interference ratio and the maximum Eve's signal to noise ratio are directly proportional to the CRB. Furthermore, the optimal AN covariance matrix is rank-1 and has a peak in the eve's direction, leading to a surprising inverse-proportionality between the UEs-Eve distance and optimal-CRB magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12901v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Rivetti, Emil Bjornson, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Machine Learning of the Prime Distribution</title>
      <link>https://arxiv.org/abs/2403.12588</link>
      <description>arXiv:2403.12588v2 Announce Type: replace 
Abstract: In the present work we use maximum entropy methods to derive several theorems in probabilistic number theory, including a version of the Hardy-Ramanujan Theorem. We also provide a theoretical argument explaining the experimental observations of Yang-Hui He about the learnability of primes, and posit that the Erd\H{o}s-Kac law would very unlikely be discovered by current machine learning techniques. Numerical experiments that we perform corroborate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12588v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1371/journal.pone.0301240</arxiv:DOI>
      <dc:creator>Alexander Kolpakov, A. Alistair Rocke</dc:creator>
    </item>
    <item>
      <title>Generalization the parameters of minimal linear codes over the ring $\mathbb{Z}_{p^l}$ and $\mathbb{Z}_{{p_1}{p_2}}$</title>
      <link>https://arxiv.org/abs/2404.09561</link>
      <description>arXiv:2404.09561v2 Announce Type: replace 
Abstract: In this article, We introduce a condition that is both necessary and sufficient for a linear code to achieve minimality when analyzed over the rings $\mathbb{Z}_{n}$.The fundamental inquiry in minimal linear codes is the existence of a $[m,k]$ minimal linear code where $k$ is less than or equal to $m$. W. Lu et al. ( see \cite{nine}) showed that there exists a positive integer $m(k;q)$ such that for $m\geq m(k;q)$ a minimal linear code of length $m$ and dimension $k$ over a finite field $\mathbb{F}_q$ must exist. They give the upper and lower bound of $m(k;q)$. In this manuscript, we establish both an upper and lower bound for $m(k;p^l)$ and $m(k;p_1p_2)$ within the ring $\mathbb{Z}_{p^l}$ and $\mathbb{Z}_{p_1p_2}$ respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09561v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Biplab Chatterjee, Ratnesh Kumar Mishra</dc:creator>
    </item>
    <item>
      <title>Optimizing Information Freshness in IoT Systems with Update Rate Constraints: A Token-Based Approach</title>
      <link>https://arxiv.org/abs/2405.04431</link>
      <description>arXiv:2405.04431v2 Announce Type: replace 
Abstract: In Internet of Things (IoT) status update systems, where information is sampled and subsequently transmitted from a source to a destination node, the imperative necessity lies in maintaining the timeliness of information and updating the system with optimal frequency. Optimizing information freshness in resource-limited status update systems often involves Constrained Markov Decision Process (CMDP) problems with update rate constraints. Solving CMDP problems, especially with multiple constraints, is a challenging task. To address this, we present a token-based approach that transforms CMDP into an unconstrained MDP, simplifying the solution process. We apply this approach to systems with one and two update rate constraints for optimizing Age of Incorrect Information (AoII) and Age of Information (AoI) metrics, respectively, and explore the analytical and numerical aspects. Additionally, we introduce an iterative triangle bisection method for solving the CMDP problems with two constraints, comparing its results with the token-based MDP approach. Our findings show that the token-based approach yields superior performance over baseline policies, converging to the optimal policy as the maximum number of tokens increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04431v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erfan Delfani, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>Max-Min Fairness and PHY-Layer Design of Uplink MIMO Rate-Splitting Multiple Access with Finite Blocklength</title>
      <link>https://arxiv.org/abs/2405.11996</link>
      <description>arXiv:2405.11996v2 Announce Type: replace 
Abstract: Rate-Splitting Multiple Access (RSMA) has emerged as a potent and reliable multiple access and interference management technique in wireless communications. While downlink Multiple-Input Multiple-Ouput (MIMO) RSMA has been widely investigated, uplink MIMO RSMA has not been fully explored. In this paper, we investigate the performance of uplink RSMA in short-packet communications with perfect Channel State Information at Transmitter (CSIT) and Channel State Information at Receiver (CSIR). We propose an uplink MIMO RSMA framework and optimize both precoders and combiners with Max-Min Fairness (MMF) metric and Finite Blocklength (FBL) constraints. Due to the high coupling between precoders and combiners, we apply the Alternating Optimization (AO) to decompose the optimization problem into two subproblems. To tackle these subproblems, we propose a Successive Convex Approximation (SCA)-based approach. Additionally, we introduce a low-complexity scheme to design the decoding order at the receiver. Subsequently, the Physical (PHY)-layer of the uplink MIMO RSMA architecture is designed and evaluated using multi-user Link-Level Simulations (LLS), accounting for finite constellation modulation, finite length polar codes, message splitting, adaptive modulation and coding, and Successive Interference Cancellation (SIC) at the receiver. Numerical results demonstrate that applying RSMA in uplink MIMO with FBL constraints not only achieves MMF gains over conventional transmission schemes such as Space Division Multiple Access (SDMA) and Non-orthogonal Multiple Access (NOMA) but also exhibits robustness to network loads. The benefits of splitting messages from multiple users are also illustrated. LLS results confirm the improved max-min throughput benefits of RSMA over SDMA and NOMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11996v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Xu, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>TATTOOED: A Robust Deep Neural Network Watermarking Scheme based on Spread-Spectrum Channel Coding</title>
      <link>https://arxiv.org/abs/2202.06091</link>
      <description>arXiv:2202.06091v3 Announce Type: replace-cross 
Abstract: Watermarking of deep neural networks (DNNs) has gained significant traction in recent years, with numerous (watermarking) strategies being proposed as mechanisms that can help verify the ownership of a DNN in scenarios where these models are obtained without the permission of the owner. However, a growing body of work has demonstrated that existing watermarking mechanisms are highly susceptible to removal techniques, such as fine-tuning, parameter pruning, or shuffling. In this paper, we build upon extensive prior work on covert (military) communication and propose TATTOOED, a novel DNN watermarking technique that is robust to existing threats. We demonstrate that using TATTOOED as their watermarking mechanisms, the DNN owner can successfully obtain the watermark and verify model ownership even in scenarios where 99% of model parameters are altered. Furthermore, we show that TATTOOED is easy to employ in training pipelines, and has negligible impact on model performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.06091v3</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulio Pagnotta, Dorjan Hitaj, Briland Hitaj, Fernando Perez-Cruz, Luigi V. Mancini</dc:creator>
    </item>
    <item>
      <title>Reliable Quantum Communications based on Asymmetry in Distillation and Coding</title>
      <link>https://arxiv.org/abs/2305.00949</link>
      <description>arXiv:2305.00949v2 Announce Type: replace-cross 
Abstract: The reliable provision of entangled qubits is an essential precondition in a variety of schemes for distributed quantum computing. This is challenged by multiple nuisances, such as errors during the transmission over quantum links, but also due to degradation of the entanglement over time due to decoherence. The latter can be seen as a constraint on the latency of the quantum protocol, which brings the problem of quantum protocol design into the context of latency-reliability constraints. We address the problem through hybrid schemes that combine: (1) indirect transmission based on teleportation and distillation; (2) direct transmission, based on quantum error correction (QEC). The intuition is that, at present, the quantum hardware offers low fidelity, which demands distillation; on the other hand, low latency can be obtained by QEC techniques. It is shown that, in the proposed framework, the distillation protocol gives rise to asymmetries that can be exploited by asymmetric quantum error correcting code (QECC), which sets the basis for unique hybrid distillation and coding design. Our results show that ad-hoc asymmetric codes give, compared to conventional QEC, a performance boost and codeword size reduction both in a single link and in a quantum network scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00949v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TQE.2024.3399609</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Quantum Engineering, vol. 5, pp. 1-13, 2024</arxiv:journal_reference>
      <dc:creator>Lorenzo Valentini, Ren\'e B{\o}dker Christensen, Petar Popovski, Marco Chiani</dc:creator>
    </item>
    <item>
      <title>Kruskal--Katona-Type Problems via the Entropy Method</title>
      <link>https://arxiv.org/abs/2307.15379</link>
      <description>arXiv:2307.15379v3 Announce Type: replace-cross 
Abstract: In this paper, we investigate several extremal combinatorics problems that ask for the maximum number of copies of a fixed subgraph given the number of edges. We call problems of this type Kruskal--Katona-type problems. Most of the problems that will be discussed in this paper are related to the joints problem. There are two main results in this paper. First, we prove that, in a $3$-edge-colored graph with $R$ red, $G$ green, $B$ blue edges, the number of rainbow triangles is at most $\sqrt{2RGB}$, which is sharp. Second, we give a generalization of the Kruskal--Katona theorem that implies many other previous generalizations. Both arguments use the entropy method, and the main innovation lies in a more clever argument that improves bounds given by Shearer's inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15379v3</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ting-Wei Chao, Hung-Hsun Hans Yu</dc:creator>
    </item>
    <item>
      <title>The Information Geometry of UMAP</title>
      <link>https://arxiv.org/abs/2309.01237</link>
      <description>arXiv:2309.01237v5 Announce Type: replace-cross 
Abstract: Although UMAP was derived from Category Theory observations, its underlying mechanisms may be clarified using Information Geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01237v5</guid>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.GT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Kolpakov, Aidan Rocke</dc:creator>
    </item>
    <item>
      <title>Goal-oriented Estimation of Multiple Markov Sources in Resource-constrained Systems</title>
      <link>https://arxiv.org/abs/2311.07346</link>
      <description>arXiv:2311.07346v3 Announce Type: replace-cross 
Abstract: This paper investigates goal-oriented communication for remote estimation of multiple Markov sources in resource-constrained networks. An agent decides the updating times of the sources and transmits the packet to a remote destination over an unreliable channel with delay. The destination is tasked with source reconstruction for actuation. We utilize the metric \textit{cost of actuation error} (CAE) to capture the state-dependent actuation costs. We aim for a sampling policy that minimizes the long-term average CAE subject to an average resource constraint. We formulate this problem as an average-cost constrained Markov Decision Process (CMDP) and relax it into an unconstrained problem by utilizing \textit{Lyapunov drift} techniques. Then, we propose a low-complexity \textit{drift-plus-penalty} (DPP) policy for systems with known source/channel statistics and a Lyapunov optimization-based deep reinforcement learning (LO-DRL) policy for unknown environments. Our policies significantly reduce the number of uninformative transmissions by exploiting the timing of the important information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07346v3</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiping Luo, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>The Origin of Information Handling</title>
      <link>https://arxiv.org/abs/2404.04374</link>
      <description>arXiv:2404.04374v2 Announce Type: replace-cross 
Abstract: A major challenge when describing the origin of life is to explain how instructional information control systems emerge naturally and spontaneously from mere molecular dynamics. So far, no one has clarified how information control emerged ab initio and how primitive control mechanisms in life might have evolved, becoming increasingly refined. Based on recent experimental results showing that chemical computation does not require the presence of life-related chemistry, we elucidate the origin and early evolution of information handling by chemical automata, from information processing (computation) to information storage (memory) and information transmission (communication). In contrast to other theories that assume the existence of initial complex structures, our narrative starts from trivial self-replicators whose interaction leads to the arising of more powerful molecular machines. By describing precisely the primordial transitions in chemistry-based computation, our metaphor is capable of explaining the above-mentioned gaps and can be translated to other models of computation, which allow us to explore biological phenomena at multiple spatial and temporal scales. At the end of our manuscript, we propose some ways to extend our ideas, including experimental validation of our theory (both in vitro and in silico).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04374v2</guid>
      <category>physics.bio-ph</category>
      <category>cs.IT</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <category>nlin.AO</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amahury Jafet L\'opez-D\'iaz, Hiroki Sayama, Carlos Gershenson</dc:creator>
    </item>
    <item>
      <title>Active Sensing for Multiuser Beam Tracking with Reconfigurable Intelligent Surface</title>
      <link>https://arxiv.org/abs/2405.03129</link>
      <description>arXiv:2405.03129v2 Announce Type: replace-cross 
Abstract: This paper studies a beam tracking problem in which an access point (AP), in collaboration with a reconfigurable intelligent surface (RIS), dynamically adjusts its downlink beamformers and the reflection pattern at the RIS in order to maintain reliable communications with multiple mobile user equipments (UEs). Specifically, the mobile UEs send uplink pilots to the AP periodically during the channel sensing intervals, the AP then adaptively configures the beamformers and the RIS reflection coefficients for subsequent data transmission based on the received pilots. This is an active sensing problem, because channel sensing involves configuring the RIS coefficients during the pilot stage and the optimal sensing strategy should exploit the trajectory of channel state information (CSI) from previously received pilots. Analytical solution to such an active sensing problem is very challenging. In this paper, we propose a deep learning framework utilizing a recurrent neural network (RNN) to automatically summarize the time-varying CSI obtained from the periodically received pilots into state vectors. These state vectors are then mapped to the AP beamformers and RIS reflection coefficients for subsequent downlink data transmissions, as well as the RIS reflection coefficients for the next round of uplink channel sensing. The mappings from the state vectors to the downlink beamformers and the RIS reflection coefficients for both channel sensing and downlink data transmission are performed using graph neural networks (GNNs) to account for the interference among the UEs. Simulations demonstrate significant and interpretable performance improvement of the proposed approach over the existing data-driven methods with nonadaptive channel sensing schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03129v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Han, Tao Jiang, Wei Yu</dc:creator>
    </item>
    <item>
      <title>FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information</title>
      <link>https://arxiv.org/abs/2405.12807</link>
      <description>arXiv:2405.12807v5 Announce Type: replace-cross 
Abstract: This paper establishes a mathematical foundation for the Adam optimizer, elucidating its connection to natural gradient descent through Riemannian and information geometry. We rigorously analyze the diagonal empirical Fisher information matrix (FIM) in Adam, clarifying all detailed approximations and advocating for the use of log probability functions as loss, which should be based on discrete distributions, due to the limitations of empirical FIM. Our analysis uncovers flaws in the original Adam algorithm, leading to proposed corrections such as enhanced momentum calculations, adjusted bias corrections, adaptive epsilon, and gradient clipping. We refine the weight decay term based on our theoretical framework. Our modified algorithm, Fisher Adam (FAdam), demonstrates superior performance across diverse domains including LLM, ASR, and VQ-VAE, achieving state-of-the-art results in ASR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12807v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongseong Hwang</dc:creator>
    </item>
  </channel>
</rss>
