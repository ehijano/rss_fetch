<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Sep 2025 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Revealing Inherent Concurrency in Event Data: A Partial Order Approach to Process Discovery</title>
      <link>https://arxiv.org/abs/2509.15346</link>
      <description>arXiv:2509.15346v1 Announce Type: new 
Abstract: Process discovery algorithms traditionally linearize events, failing to capture the inherent concurrency of real-world processes. While some techniques can handle partially ordered data, they often struggle with scalability on large event logs. We introduce a novel, scalable algorithm that directly leverages partial orders in process discovery. Our approach derives partially ordered traces from event data and aggregates them into a sound-by-construction, perfectly fitting process model. Our hierarchical algorithm preserves inherent concurrency while systematically abstracting exclusive choices and loop patterns, enhancing model compactness and precision. We have implemented our technique and demonstrated its applicability on complex real-life event logs. Our work contributes a scalable solution for a more faithful representation of process behavior, especially when concurrency is prevalent in event data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15346v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Humam Kourani, Gyunam Park, Wil M. P. van der Aalst</dc:creator>
    </item>
    <item>
      <title>Optimization techniques for SQL+ML queries: A performance analysis of real-time feature computation in OpenMLDB</title>
      <link>https://arxiv.org/abs/2509.15529</link>
      <description>arXiv:2509.15529v1 Announce Type: new 
Abstract: In this study, we optimize SQL+ML queries on top of OpenMLDB, an open-source database that seamlessly integrates offline and online feature computations. The work used feature-rich synthetic dataset experiments in Docker, which acted like production environments that processed 100 to 500 records per batch and 6 to 12 requests per batch in parallel. Efforts have been concentrated in the areas of better query plans, cached execution plans, parallel processing, and resource management. The experimental results show that OpenMLDB can support approximately 12,500 QPS with less than 1 ms latency, outperforming SparkSQL and ClickHouse by a factor of 23 and PostgreSQL and MySQL by 3.57 times. This study assessed the impact of optimization and showed that query plan optimization accounted for 35% of the performance gains, caching for 25%, and parallel processing for 20%. These results illustrate OpenMLDB's capability for time-sensitive ML use cases, such as fraud detection, personalized recommendation, and time series forecasting. The system's modular optimization framework, which combines batch and stream processing without interference, contributes to its significant performance gain over traditional database systems, particularly in applications that require real-time feature computation and serving. This study contributes to the understanding and design of high-performance SQL+ML systems and highlights the need for specialized SQL optimization for ML workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15529v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5121/ijdms.2025.17501</arxiv:DOI>
      <dc:creator>Mashkhal A. Sidiq, Aras A. Salih, Samrand M. Hassan</dc:creator>
    </item>
    <item>
      <title>Discovering Top-k Periodic and High-Utility Patterns</title>
      <link>https://arxiv.org/abs/2509.15732</link>
      <description>arXiv:2509.15732v1 Announce Type: new 
Abstract: With a user-specified minimum utility threshold (minutil), periodic high-utility pattern mining (PHUPM) aims to identify high-utility patterns that occur periodically in a transaction database. A pattern is deemed periodic if its period aligns with the periodicity constraint set by the user. However, users may not be interested in all periodic high-utility patterns (PHUPs). Moreover, setting minutil in advance is also a challenging issue. To address these issues, our research introduces an algorithm called TPU for extracting the most significant top-k periodic and high-utility patterns that may or may not include negative utility values. This TPU algorithm utilizes positive and negative utility lists (PNUL) and period-estimated utility co-occurrence structure (PEUCS) to store pertinent itemset information. It incorporates the periodic real item utility (PIU), periodic co-occurrence utility descending (PCUD), and periodic real utility (PRU) threshold-raising strategies to elevate the thresholds rapidly. By using the proposed threshold-raising strategies, the runtime was reduced by approximately 5\% on the datasets used in the experiments. Specifically, the runtime was reduced by up to 50\% on the mushroom\_negative and kosarak\_negative datasets, and by up to 10\% on the chess\_negative dataset. Memory consumption was reduced by about 2\%, with the largest reduction of about 30\% observed on the mushroom\_negative dataset. Through extensive experiments, we have demonstrated that our algorithm can accurately and effectively extract the top-k periodic high-utility patterns. This paper successfully addresses the top-k mining issue and contributes to data science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15732v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingfeng Zhou, Wensheng Gan, Guoting Chen</dc:creator>
    </item>
    <item>
      <title>Utility-based Privacy Preserving Data Mining</title>
      <link>https://arxiv.org/abs/2509.15755</link>
      <description>arXiv:2509.15755v1 Announce Type: new 
Abstract: With the advent of big data, periodic pattern mining has demonstrated significant value in real-world applications, including smart home systems, healthcare systems, and the medical field. However, advances in network technology have enabled malicious actors to extract sensitive information from publicly available datasets, posing significant threats to data providers and, in severe cases, hindering societal development. To mitigate such risks, privacy-preserving utility mining (PPUM) has been proposed. However, PPUM is unsuitable for addressing privacy concerns in periodic information mining. To address this issue, we innovatively extend the existing PPUM framework and propose two algorithms, Maximum sensitive Utility-MAximum maxPer item (MU-MAP) and Maximum sensitive Utility-MInimum maxPer item (MU-MIP). These algorithms aim to hide sensitive periodic high-utility itemsets while generating sanitized datasets. To enhance the efficiency of the algorithms, we designed two novel data structures: the Sensitive Itemset List (SISL) and the Sensitive Item List (SIL), which store essential information about sensitive itemsets and their constituent items. Moreover, several performance metrics were employed to evaluate the performance of our algorithms compared to the state-of-the-art PPUM algorithms. The experimental results show that our proposed algorithms achieve an Artificial Cost (AC) value of 0 on all datasets when hiding sensitive itemsets. In contrast, the traditional PPUM algorithm yields non-zero AC. This indicates that our algorithms can successfully hide sensitive periodic itemsets without introducing misleading patterns, whereas the PPUM algorithm generates additional itemsets that may interfere with user decision-making. Moreover, the results also reveal that our algorithms maintain Database Utility Similarity (DUS) of over 90\% after the sensitive itemsets are hidden.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15755v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingfeng Zhou, Wensheng Gan, Zhenlian Qi, Philip S. Yu</dc:creator>
    </item>
    <item>
      <title>Clustering with Set Outliers and Applications in Relational Clustering</title>
      <link>https://arxiv.org/abs/2509.16194</link>
      <description>arXiv:2509.16194v1 Announce Type: cross 
Abstract: We introduce and study the $k$-center clustering problem with set outliers, a natural and practical generalization of the classical $k$-center clustering with outliers. Instead of removing individual data points, our model allows discarding up to $z$ subsets from a given family of candidate outlier sets $\mathcal{H}$. Given a metric space $(P,\mathsf{dist})$, where $P$ is a set of elements and $\mathsf{dist}$ a distance metric, a family of sets $\mathcal{H}\subseteq 2^P$, and parameters $k, z$, the goal is to compute a set of $k$ centers $S\subseteq P$ and a family of $z$ sets $H\subseteq \mathcal{H}$ to minimize $\max_{p\in P\setminus(\bigcup_{h\in H} h)} \min_{s\in S}\mathsf{dist}(p,s)$. This abstraction captures structured noise common in database applications, such as faulty data sources or corrupted records in data integration and sensor systems.
  We present the first approximation algorithms for this problem in both general and geometric settings. Our methods provide tri-criteria approximations: selecting up to $2k$ centers and $2f z$ outlier sets (where $f$ is the maximum number of sets that a point belongs to), while achieving $O(1)$-approximation in clustering cost. In geometric settings, we leverage range and BBD trees to achieve near-linear time algorithms. In many real applications $f=1$. In this case we further improve the running time of our algorithms by constructing small \emph{coresets}. We also provide a hardness result for the general problem showing that it is unlikely to get any sublinear approximation on the clustering cost selecting less than $f\cdot z$ outlier sets.
  We demonstrate that this model naturally captures relational clustering with outliers: outliers are input tuples whose removal affects the join output. We provide approximation algorithms for both, establishing a tight connection between robust clustering and relational query evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16194v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vaishali Surianarayanan, Neeraj Kumar, Stavros Sintos</dc:creator>
    </item>
    <item>
      <title>Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents</title>
      <link>https://arxiv.org/abs/2504.01029</link>
      <description>arXiv:2504.01029v2 Announce Type: replace-cross 
Abstract: The rapid growth of artificial intelligence (AI) technologies has raised major privacy and ethical concerns. However, existing AI incident taxonomies and guidelines lack grounding in real-world cases, limiting their effectiveness for prevention and mitigation. We analyzed 202 real-world AI privacy and ethical incidents to develop a taxonomy that classifies them across AI lifecycle stages and captures contributing factors, including causes, responsible entities, sources of disclosure, and impacts. Our findings reveal widespread harms from poor organizational decisions and legal non-compliance, limited corrective interventions, and rare reporting from AI developers and adopting entities. Our taxonomy offers a structured approach for systematic incident reporting and emphasizes the weaknesses of current AI governance frameworks. Our findings provide actionable guidance for policymakers and practitioners to strengthen user protections, develop targeted AI policies, enhance reporting practices, and foster responsible AI governance and innovation, especially in contexts such as social media and child protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01029v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.HC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1080/10447318.2025.2549073</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Human-Computer Interaction (2025): 1-45</arxiv:journal_reference>
      <dc:creator>Hilda Hadan, Reza Hadi Mogavi, Leah Zhang-Kennedy, Lennart E. Nacke</dc:creator>
    </item>
    <item>
      <title>Integrating Activity Predictions in Knowledge Graphs</title>
      <link>https://arxiv.org/abs/2507.19733</link>
      <description>arXiv:2507.19733v3 Announce Type: replace-cross 
Abstract: We argue that ontology-structured knowledge graphs can play a crucial role in generating predictions about future events. By leveraging the semantic framework provided by Basic Formal Ontology (BFO) and Common Core Ontologies (CCO), we demonstrate how data such as the movements of a fishing vessel can be organized in and retrieved from a knowledge graph. These query results are then used to create Markov chain models, allowing us to predict future states based on the vessel's history. To fully support this process, we introduce the term `spatiotemporal instant' to complete the necessary structural semantics. Additionally, we critique the prevailing ontological model of probability, according to which probabilities are about the future. We propose an alternative view, where at least some probabilities are treated as being about actual process profiles, which better captures the dynamics of real-world phenomena. Finally, we demonstrate how our Markov chain-based probability calculations can be seamlessly integrated back into the knowledge graph, enabling further analysis and decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19733v3</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Forrest Hare, Alec Sculley, Cameron Stockton</dc:creator>
    </item>
  </channel>
</rss>
