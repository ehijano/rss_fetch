<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Mar 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Local Projections or VARs? A Primer for Macroeconomists</title>
      <link>https://arxiv.org/abs/2503.17144</link>
      <description>arXiv:2503.17144v1 Announce Type: new 
Abstract: What should applied macroeconomists know about local projection (LP) and vector autoregression (VAR) impulse response estimators? The two methods share the same estimand, but in finite samples lie on opposite ends of a bias-variance trade-off. While the low bias of LPs comes at a quite steep variance cost, this cost must be paid to achieve robust uncertainty assessments. VARs should thus only be used with long lag lengths, ensuring equivalence with LP. For LP estimation, we provide guidance on selection of lag length and controls, bias correction, and confidence interval construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17144v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e Luis Montiel Olea, Mikkel Plagborg-M{\o}ller, Eric Qian, Christian K. Wolf</dc:creator>
    </item>
    <item>
      <title>Calibration Strategies for Robust Causal Estimation: Theoretical and Empirical Insights on Propensity Score Based Estimators</title>
      <link>https://arxiv.org/abs/2503.17290</link>
      <description>arXiv:2503.17290v1 Announce Type: cross 
Abstract: The partitioning of data for estimation and calibration critically impacts the performance of propensity score based estimators like inverse probability weighting (IPW) and double/debiased machine learning (DML) frameworks. We extend recent advances in calibration techniques for propensity score estimation, improving the robustness of propensity scores in challenging settings such as limited overlap, small sample sizes, or unbalanced data. Our contributions are twofold: First, we provide a theoretical analysis of the properties of calibrated estimators in the context of DML. To this end, we refine existing calibration frameworks for propensity score models, with a particular emphasis on the role of sample-splitting schemes in ensuring valid causal inference. Second, through extensive simulations, we show that calibration reduces variance of inverse-based propensity score estimators while also mitigating bias in IPW, even in small-sample regimes. Notably, calibration improves stability for flexible learners (e.g., gradient boosting) while preserving the doubly robust properties of DML. A key insight is that, even when methods perform well without calibration, incorporating a calibration step does not degrade performance, provided that an appropriate sample-splitting approach is chosen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17290v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Rabenseifner, Sven Klaassen, Jannis Kueck, Philipp Bach</dc:creator>
    </item>
    <item>
      <title>Dynamic Regression Discontinuity: An Event-Study Approach</title>
      <link>https://arxiv.org/abs/2307.14203</link>
      <description>arXiv:2307.14203v3 Announce Type: replace 
Abstract: I propose a novel argument to identify economically interpretable intertemporal treatment effects in dynamic regression discontinuity designs (RDDs). Specifically, I develop a dynamic potential outcomes model and reformulate two assumptions from the difference-in-differences literature, no anticipation and common trends, to attain point identification of cutoff-specific impulse responses. The estimand of each target parameter can be expressed as the sum of two static RDD contrasts, thereby allowing for nonparametric estimation and inference with standard local polynomial methods. I also propose a nonparametric approach to aggregate treatment effects across calendar time and treatment paths, leveraging a limited path independence restriction to reduce the dimensionality of the parameter space. I apply this method to estimate the dynamic effects of school district expenditure authorizations on housing prices in Wisconsin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14203v3</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Ruggieri</dc:creator>
    </item>
    <item>
      <title>One-inflated zero-truncated Poisson and negative binomial regression models</title>
      <link>https://arxiv.org/abs/2402.02272</link>
      <description>arXiv:2402.02272v2 Announce Type: replace 
Abstract: The workhorse model for zero-truncated count data (y = 1, 2, ...) is the zero-truncated negative binomial (ZTNB) model. We find it should seldom be used. Instead, we recommend the one-inflated zero-truncated negative binomial (OIZTNB) model developed here. Zero-truncated count data often contain an excess of 1s, leading to bias and inconsistency in the ZTNB model. The importance of the OIZTNB model is apparent given the obvious presence of one-inflation in four datasets that have traditionally championed the standard ZTNB. We provide estimation, marginal effects, and a suite of accompanying tools in the R package oneinfl, available on CRAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02272v2</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryan T. Godwin</dc:creator>
    </item>
    <item>
      <title>SNPL: Simultaneous Policy Learning and Evaluation for Safe Multi-Objective Policy Improvement</title>
      <link>https://arxiv.org/abs/2503.12760</link>
      <description>arXiv:2503.12760v2 Announce Type: replace-cross 
Abstract: To design effective digital interventions, experimenters face the challenge of learning decision policies that balance multiple objectives using offline data. Often, they aim to develop policies that maximize goal outcomes, while ensuring there are no undesirable changes in guardrail outcomes. To provide credible recommendations, experimenters must not only identify policies that satisfy the desired changes in goal and guardrail outcomes, but also offer probabilistic guarantees about the changes these policies induce. In practice, however, policy classes are often large, and digital experiments tend to produce datasets with small effect sizes relative to noise. In this setting, standard approaches such as data splitting or multiple testing often result in unstable policy selection and/or insufficient statistical power. In this paper, we provide safe noisy policy learning (SNPL), a novel approach that leverages the concept of algorithmic stability to address these challenges. Our method enables policy learning while simultaneously providing high-confidence guarantees using the entire dataset, avoiding the need for data-splitting. We present finite-sample and asymptotic versions of our algorithm that ensure the recommended policy satisfies high-probability guarantees for avoiding guardrail regressions and/or achieving goal outcome improvements. We test both variants of our approach approach empirically on a real-world application of personalizing SMS delivery. Our results on real-world data suggest that our approach offers dramatic improvements in settings with large policy classes and low signal-to-noise across both finite-sample and asymptotic safety guarantees, offering up to 300\% improvements in detection rates and 150\% improvements in policy gains at significantly smaller sample sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12760v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Cho, Ana-Roxana Pop, Ariel Evnine, Nathan Kallus</dc:creator>
    </item>
  </channel>
</rss>
