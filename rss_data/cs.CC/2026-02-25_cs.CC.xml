<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Feb 2026 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Polynomial Identity Testing and Reconstruction for Depth-4 Powering Circuits of High Degree</title>
      <link>https://arxiv.org/abs/2602.20832</link>
      <description>arXiv:2602.20832v1 Announce Type: new 
Abstract: We study deterministic polynomial identity testing (PIT) and reconstruction algorithms for depth-$4$ arithmetic circuits of the form \[ \Sigma^{[r]}\!\wedge^{[d]}\!\Sigma^{[s]}\!\Pi^{[\delta]}. \] This model generalizes Waring decompositions and diagonal circuits, and captures sums of powers of low-degree sparse polynomials. Specifically, each circuit computes a sum of $r$ terms, where each term is a $d$-th power of an $s$-sparse polynomial of degree $\delta$. This model also includes algebraic representations that arise in tensor decomposition and moment-based learning tasks such as mixture models and subspace learning.
  We give deterministic worst-case algorithms for PIT and reconstruction in this model. Our PIT construction applies when $d&gt;r^2$ and yields explicit hitting sets of size $O(r^4 s^4 n^2 d \delta^3)$. The reconstruction algorithm runs in time $\textrm{poly}(n,s,d)$ under the condition $d=\Omega(r^4\delta)$, and in particular it tolerates polynomially large top fan-in $r$ and bottom degree $\delta$.
  Both results hold over fields of characteristic zero and over fields of sufficiently large characteristic. These algorithms provide the first polynomial-time deterministic solutions for depth-$4$ powering circuits with unbounded top fan-in. In particular, the reconstruction result improves upon previous work which required non-degeneracy or average-case assumptions.
  The PIT construction relies on the ABC theorem for function fields (Mason-Stothers theorem), which ensures linear independence of high-degree powers of sparse polynomials after a suitable projection. The reconstruction algorithm combines this with Wronskian-based differential operators, structural properties of their kernels, and a robust version of the Klivans-Spielman hitting set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20832v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Shpilka, Yann Tal</dc:creator>
    </item>
    <item>
      <title>Exponential Lower Bounds for 2-query Relaxed Locally Decodable Codes</title>
      <link>https://arxiv.org/abs/2602.20278</link>
      <description>arXiv:2602.20278v1 Announce Type: cross 
Abstract: Locally Decodable Codes (LDCs) are error-correcting codes $C\colon\Sigma^n\rightarrow \Sigma^m,$ encoding \emph{messages} in $\Sigma^n$ to \emph{codewords} in $\Sigma^m$, with super-fast decoding algorithms. They are important mathematical objects in many areas of theoretical computer science, yet the best constructions so far have codeword length $m$ that is super-polynomial in $n$, for codes with constant query complexity and constant alphabet size.
  In a very surprising result, Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan (SICOMP 2006) show how to construct a relaxed version of LDCs (RLDCs) with constant query complexity and almost linear codeword length over the binary alphabet, and used them to obtain significantly-improved constructions of Probabilistically Checkable Proofs.
  In this work, we study RLDCs in the standard Hamming-error setting. We prove an exponential lower bound on the length of Hamming RLDCs making $2$ queries (even adaptively) over the binary alphabet. This answers a question explicitly raised by Gur and Lachish (SICOMP 2021) and is the first exponential lower bound for RLDCs. Combined with the results of Ben-Sasson et al., our result exhibits a ``phase-transition''-type behavior on the codeword length for some constant-query complexity. We achieve these lower bounds via a transformation of RLDCs to standard Hamming LDCs, using a careful analysis of restrictions of message bits that fix codeword bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20278v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander R. Block (University of Illinois at Chicago), Jeremiah Blocki (Purdue University), Kuan Cheng (Peking University), Elena Grigorescu (University of Waterloo), Xin Li (Johns Hopkins University), Yu Zheng, Minshen Zhu</dc:creator>
    </item>
    <item>
      <title>Markets are competitive if and only if P != NP</title>
      <link>https://arxiv.org/abs/2602.20415</link>
      <description>arXiv:2602.20415v1 Announce Type: cross 
Abstract: I prove that competitive market outcomes require computational intractability. If P = NP, firms can efficiently solve the collusion detection problem, identifying deviations from cooperative agreements in complex, noisy markets and thereby making collusion sustainable as an equilibrium. If P != NP, the collusion detection problem is computationally infeasible for markets satisfying a natural instance-hardness condition on their demand structure, rendering punishment threats non-credible and collusion unstable. Combined with Maymin (2011), who proved that market efficiency requires P = NP, this yields a fundamental impossibility: markets can be informationally efficient or competitive, but not both. Artificial intelligence, by expanding firms' computational capabilities, is pushing markets from the competitive regime toward the collusive regime, explaining the empirical emergence of algorithmic collusion without explicit coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20415v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>econ.TH</category>
      <category>q-fin.CP</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Z. Maymin</dc:creator>
    </item>
    <item>
      <title>Is a LOCAL algorithm computable?</title>
      <link>https://arxiv.org/abs/2602.21022</link>
      <description>arXiv:2602.21022v1 Announce Type: cross 
Abstract: Common definitions of the "standard" LOCAL model tend to be sloppy and even self-contradictory on one point: do the nodes update their state using an arbitrary function or a computable function? So far, this distinction has been safe to neglect, since problems where it matters seem contrived and quite different from e.g. typical local graph problems studied in this context.
  We show that this question matters even for locally checkable labeling problems (LCLs), perhaps the most widely studied family of problems in the context of the LOCAL model. Furthermore, we show that assumptions about computability are directly connected to another aspect already recognized as highly relevant: whether we have any knowledge of $n$, the size of the graph. Concretely, we show that there is an LCL problem $\Pi$ with the following properties:
  1. $\Pi$ can be solved in $O(\log n)$ rounds if the \textsf{LOCAL} model is uncomputable.
  2. $\Pi$ can be solved in $O(\log n)$ rounds in the computable model if we know any upper bound on $n$.
  3. $\Pi$ requires $\Omega(\sqrt{n})$ rounds in the computable model if we do not know anything about $n$.
  We also show that the connection between computability and knowledge of $n$ holds in general: for any LCL problem $\Pi$, if you have any bound on $n$, then $\Pi$ has the same round complexity in the computable and uncomputable models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21022v1</guid>
      <category>cs.DC</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Antonio Cruciani, Avinandan Das, Massimo Equi, Henrik Lievonen, Diep Luong-Le, Augusto Modanese, Jukka Suomela</dc:creator>
    </item>
    <item>
      <title>A Space-space Trade-off for Directed st-Connectivity</title>
      <link>https://arxiv.org/abs/2602.21088</link>
      <description>arXiv:2602.21088v1 Announce Type: cross 
Abstract: We prove a space-space trade-off for directed $st$-connectivity in the catalytic space model. For any integer $k \leq n$, we give an algorithm that decides directed $st$-connectivity using $O(\log n \cdot \log k+\log n)$ regular workspace and $O\left(\frac{n}{k} \cdot \log^2 n\right)$ bits of catalytic memory. This interpolates between the classical $O(\log^2 n)$-space bound from Savitch's algorithm and a catalytic endpoint with $O(\log n)$ workspace and $O(n\cdot \log^2 n)$ catalytic memory.
  As a warm-up, we present a catalytic variant of Savitch's algorithm achieving the endpoint above. Up to logarithmic factors, this matches the smallest catalyst size currently known for catalytic logspace algorithms, due to Cook and Pyne (ITCS 2026). Our techniques also extend to counting the number of walks from $s$ to $t$ of a given length $\ell\leq n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21088v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Edenhofer</dc:creator>
    </item>
    <item>
      <title>Frontier Space-Time Algorithms Using Only Full Memory</title>
      <link>https://arxiv.org/abs/2602.21089</link>
      <description>arXiv:2602.21089v1 Announce Type: cross 
Abstract: We develop catalytic algorithms for fundamental problems in algorithm design that run in polynomial time, use only $\mathcal{O}(\log(n))$ workspace, and use sublinear catalytic space matching the best-known space bounds of non-catalytic algorithms running in polynomial time.
  First, we design a polynomial time algorithm for directed $s$-$t$ connectivity using $n \big/ 2^{\Theta(\sqrt{\log n})}$ catalytic space, which matches the state-of-the-art time-space bounds in the non-catalytic setting [Barnes et al., 1998], and improves the catalytic space usage of the best known algorithm [Cook and Pyne, 2026]. Furthermore, using only $\mathcal{O}(\log(n))$ random bits we get a randomized algorithm whose running time nearly matches the fastest time bounds known for space-unrestricted algorithms.
  Second, we design polynomial time algorithms for the problems of computing Edit Distance, Longest Common Subsequence, and the Discrete Fr\'{e}chet Distance, again using $n \big/ 2^{\Theta(\sqrt{\log n})}$ catalytic space. This again matches non-catalytic time-space frontier for Edit Distance and Least Common Subsequence [Kiyomi et al., 2021].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21089v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petr Chmel, Aditi Dudeja, Michal Kouck\'y, Ian Mertz, Ninad Rajgopal</dc:creator>
    </item>
    <item>
      <title>Computational Complexity of Physical Information Sufficiency</title>
      <link>https://arxiv.org/abs/2601.15571</link>
      <description>arXiv:2601.15571v3 Announce Type: replace 
Abstract: We study physical information sufficiency as a decision-theoretic meta-problem. For $\mathcal{D}=(A,S,U)$ with factored state space $S=X_1\times\cdots\times X_n$, a coordinate set $I$ is sufficient when $$s_I=s'_I \implies \operatorname{Opt}(s)=\operatorname{Opt}(s').$$ This asks whether projected information preserves the full optimal-action correspondence.
  Complexity landscape.
  - SUFFICIENCY-CHECK is coNP-complete; MINIMUM-SUFFICIENT-SET is coNP-complete; ANCHOR-SUFFICIENCY is $\Sigma_{2}^{P}$-complete.
  - Under explicit-state encoding, polynomial-time algorithms hold for bounded actions, separable utility, and tree-structured utility.
  - Under succinct encoding, hardness is regime-dependent: with ETH, there are worst-case families with $k^*=n$ requiring $2^{\Omega(n)}$ time.
  - Under query access, the finite-state core has worst-case Opt-oracle complexity $\Omega(|S|)$, with Boolean value-entry and state-batch refinements preserving the obstruction.
  Physical grounding. The paper formalizes a physical-to-core encoding $E:\mathcal{P}\to\mathcal{D}$ and a transport rule: declared physical assumptions transfer to core assumptions, and core claims lift back to encoded physical instances. Encoded physical counterexamples induce core failures on the encoded slice. Discrete-time interface semantics (decision event = one tick) and budgeted thermodynamic lifts (bit lower bounds to energy/carbon lower bounds under declared constants) are formalized in the same assumption-typed framework. All theorem-level claims are machine-checked in Lean 4 (13969 lines, 609 theorem/lemma statements). Complexity-class completeness follows by composition with standard complexity results; regime-dependent and physical-transport consequences are proved as assumption-explicit closures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15571v3</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tristan Simas</dc:creator>
    </item>
    <item>
      <title>Embedding arbitrary Boolean circuits into fungal automata with arbitrary update sequences</title>
      <link>https://arxiv.org/abs/2602.19477</link>
      <description>arXiv:2602.19477v2 Announce Type: replace 
Abstract: The sandpile automata of Bak, Tang, and Wiesenfeld (Phys. Rev. Lett., 1987) are a simple model for the diffusion of particles in space. A fundamental problem related to the complexity of the model is predicting its evolution in the parallel setting. Despite decades of effort, a classification of this problem for two-dimensional sandpile automata remains outstanding. Fungal automata were recently proposed by Goles et al. (Phys. Lett. A, 2020) as a spin-off of the model in which diffusion occurs either in horizontal $(H)$ or vertical $(V)$ directions according to a so-called update scheme. Goles et al. proved that the prediction problem for this model with the update scheme $H^4V^4$ is $\textbf{P}$-complete. This result was subsequently improved by Modanese and Worsch (Algorithmica, 2024), who showed the problem is $\textbf{P}$-complete also for the simpler updatenscheme $HV$. In this work, we fill in the gaps and prove that the prediction problem is $\textbf{P}$-complete for any update scheme that contains both $H$ and $V$ at least once.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19477v2</guid>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Goles, Augusto Modanese, Mart\'in R\'ios-Wilson, Domingo Ruiz-Tala, Thomas Worsch</dc:creator>
    </item>
    <item>
      <title>Efficiently Computing Equilibria in Budget-Aggregation Games</title>
      <link>https://arxiv.org/abs/2509.08767</link>
      <description>arXiv:2509.08767v3 Announce Type: replace-cross 
Abstract: Budget aggregation deals with the social choice problem of distributing an exogenously given budget among a set of public projects, given agents' preferences. Taking a game-theoretic perspective, we study budget-aggregation games where each agent has virtual decision power over some fraction of the budget. We investigate the structure and show efficient computability of Nash equilibria for various common preference models in this setting. In particular, we show that equilibria for Leontief utilities can be found in polynomial time, solving an open problem from Brandt et al. [2023], and give an explicit polynomial-time algorithm for computing equilibria for $\ell_1$ preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08767v3</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Becker, Alexander Fries, Matthias Greger, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Multiparty equality in the local broadcast model</title>
      <link>https://arxiv.org/abs/2510.09143</link>
      <description>arXiv:2510.09143v2 Announce Type: replace-cross 
Abstract: In this paper we consider the multiparty equality problem in graphs, where every vertex of a graph $G$ is given an input, and the goal of the vertices is to decide whether all inputs are equal. We study this problem in the local broadcast model, where a message sent by a vertex is received by all its neighbors and the total cost of a protocol is the sum of the lengths of the messages sent by the vertices. This setting was studied by Khan and Vaidya, who gave in 2021 a protocol achieving a 4-approximation in the general case.
  We study this multiparty communication problem through the lens of network topology. We design a new protocol for 2-connected graphs, whose efficiency relies on the notion of total vertex cover in graph theory. This protocol outperforms the aforementioned 4-approximation in a number of cases. To demonstrate its applicability, we apply it to obtain optimal or asymptotically optimal protocols for several natural network topologies such as cycles, hypercubes, and grids. On the way we also provide new bounds of independent interest on the size of total vertex covers in regular graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09143v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis Esperet, Jean-Florent Raymond</dc:creator>
    </item>
    <item>
      <title>On the complexity of covering points by guillotine cuts</title>
      <link>https://arxiv.org/abs/2602.17294</link>
      <description>arXiv:2602.17294v2 Announce Type: replace-cross 
Abstract: We show that the problem of covering a set of points in the plane with a minimum number of guillotine cuts is NP-complete. To that end, first we present a new NP-completeness proof for the problem of covering points with disjoint line segments. Then, we adapt the proof to show that the problem remains NP-complete when the segments are guillotine cuts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17294v2</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delia Garijo, Alberto M\'arquez, Rodrigo I. Silveira</dc:creator>
    </item>
  </channel>
</rss>
