<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Oct 2025 01:44:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust and Generalizable Background Subtraction on Images of Calorimeter Jets using Unsupervised Generative Learning</title>
      <link>https://arxiv.org/abs/2510.23717</link>
      <description>arXiv:2510.23717v1 Announce Type: cross 
Abstract: Accurate separation of signal from background is one of the main challenges for precision measurements across high-energy and nuclear physics. Conventional supervised learning methods are insufficient here because the required paired signal and background examples are impossible to acquire in real experiments. Here, we introduce an unsupervised unpaired image-to-image translation neural network that learns to separate the signal and background from the input experimental data using cycle-consistency principles. We demonstrate the efficacy of this approach using images composed of simulated calorimeter data from the sPHENIX experiment, where physics signals (jets) are immersed in the extremely dense and fluctuating heavy-ion collision environment. Our method outperforms conventional subtraction algorithms in fidelity and overcomes the limitations of supervised methods. Furthermore, we evaluated the model's robustness in an out-of-distribution test scenario designed to emulate modified jets as in real experimental data. The model, trained on a simpler dataset, maintained its high fidelity on a more realistic, highly modified jet signal. This work represents the first use of unsupervised unpaired generative models for full detector jet background subtraction and offers a path for novel applications in real experimental data, enabling high-precision analyses across a wide range of imaging-based experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23717v1</guid>
      <category>nucl-ex</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeonju Go, Dmitrii Torbunov, Yi Huang, Shuhang Li, Timothy Rinn, Haiwang Yu, Brett Viren, Meifeng Lin, Yihui Ren, Dennis Perepelitsa, Jin Huang</dc:creator>
    </item>
    <item>
      <title>Algorithmic Randomness, Exchangeability, and the Principal Principle</title>
      <link>https://arxiv.org/abs/2510.24054</link>
      <description>arXiv:2510.24054v1 Announce Type: cross 
Abstract: We introduce a framework uniting algorithmic randomness with exchangeable credences to address foundational questions in philosophy of probability and philosophy of science. To demonstrate its power, we show how one might use the framework to derive the Principal Principle -- the norm that rational credence should match known objective chance -- without circularity. The derivation brings together de Finetti's exchangeability, Martin-L\"of randomness, Lewis's and Skyrms's chance-credence norms, and statistical constraining laws (arXiv:2303.01411). Laws that constrain histories to algorithmically random sequences naturally pair with exchangeable credences encoding inductive symmetries. Using the de Finetti representation theorem, we show that this pairing directly entails the Principal Principle of this framework. We extend the proof to partial exchangeability and provide finite-history bounds that vanish in the infinite limit. The Principal Principle thus emerges as a mathematical consequence of the alignment between nomological constraints and inductive learning. This reveals how algorithmic randomness and exchangeability can illuminate foundational questions about chance, frequency, and rational belief.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24054v1</guid>
      <category>physics.hist-ph</category>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <category>quant-ph</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jeffrey A. Barrett, Eddy Keming Chen</dc:creator>
    </item>
    <item>
      <title>Forecasting precipitation in the Arctic using probabilistic machine learning informed by causal climate drivers</title>
      <link>https://arxiv.org/abs/2510.24254</link>
      <description>arXiv:2510.24254v1 Announce Type: cross 
Abstract: Understanding and forecasting precipitation events in the Arctic maritime environments, such as Bear Island and Ny-{\AA}lesund, is crucial for assessing climate risk and developing early warning systems in vulnerable marine regions. This study proposes a probabilistic machine learning framework for modeling and predicting the dynamics and severity of precipitation. We begin by analyzing the scale-dependent relationships between precipitation and key atmospheric drivers (e.g., temperature, relative humidity, cloud cover, and air pressure) using wavelet coherence, which captures localized dependencies across time and frequency domains. To assess joint causal influences, we employ Synergistic-Unique-Redundant Decomposition, which quantifies the impact of interaction effects among each variable on future precipitation dynamics. These insights inform the development of data-driven forecasting models that incorporate both historical precipitation and causal climate drivers. To account for uncertainty, we employ the conformal prediction method, which enables the generation of calibrated non-parametric prediction intervals. Our results underscore the importance of utilizing a comprehensive framework that combines causal analysis with probabilistic forecasting to enhance the reliability and interpretability of precipitation predictions in Arctic marine environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24254v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Madhurima Panja, Dhiman Das, Tanujit Chakraborty, Arnob Ray, R. Athulya, Chittaranjan Hens, Syamal K. Dana, Nuncio Murukesh, Dibakar Ghosh</dc:creator>
    </item>
    <item>
      <title>Transfer entropy for finite data</title>
      <link>https://arxiv.org/abs/2506.16215</link>
      <description>arXiv:2506.16215v2 Announce Type: replace 
Abstract: Transfer entropy is a widely used measure for quantifying directed information flows in complex systems. While the challenges of estimating transfer entropy for continuous data are well known, it has two major shortcomings for data of finite cardinality: it exhibits a substantial positive bias for sparse bin counts, and it has no clear means to assess statistical significance. By computing information content in finite data streams without explicitly considering symbols as instances of random variables, we derive a transfer entropy measure which is asymptotically equivalent to the standard plug-in estimator but remedies these issues for time series of small size and/or high cardinality, permitting a fully nonparametric assessment of statistical significance without simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16215v2</guid>
      <category>physics.data-an</category>
      <category>cs.SI</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alec Kirkley</dc:creator>
    </item>
    <item>
      <title>Optimal Binning for Small-Angle Neutron Scattering Data Using the Freedman-Diaconis Rule</title>
      <link>https://arxiv.org/abs/2510.09581</link>
      <description>arXiv:2510.09581v2 Announce Type: replace 
Abstract: Small-Angle Neutron Scattering (SANS) data analysis often relies on fixed-width binning schemes that overlook variations in signal strength and structural complexity. We introduce a statistically grounded approach based on the Freedman-Diaconis (FD) rule, which minimizes the mean integrated squared error between the histogram estimate and the true intensity distribution. By deriving the competing scaling relations for counting noise ($\propto h^{-1}$) and binning distortion ($\propto h^{2}$), we establish an optimal bin width that balances statistical precision and structural resolution. Application to synthetic data from the Debye scattering function of a Gaussian polymer chain demonstrates that the FD criterion quantitatively determines the most efficient binning, faithfully reproducing the curvature of $I(Q)$ while minimizing random error. The optimal width follows the expected scaling $h_{\mathrm{opt}} \propto N_{\mathrm{total}}^{-1/3}$, delineating the transition between noise- and resolution-limited regimes. This framework provides a unified, physics-informed basis for adaptive, statistically efficient binning in neutron scattering experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09581v2</guid>
      <category>physics.data-an</category>
      <category>physics.app-ph</category>
      <category>physics.ins-det</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jessie E. An, Chi-Huan Tung, Changwoo Do, Wei-Ren Chen</dc:creator>
    </item>
    <item>
      <title>Filtering amplitude dependence of correlation dynamics in complex systems: application to the cryptocurrency market</title>
      <link>https://arxiv.org/abs/2509.18820</link>
      <description>arXiv:2509.18820v2 Announce Type: replace-cross 
Abstract: Based on the cryptocurrency market dynamics, this study presents a general methodology for analyzing evolving correlation structures in complex systems using the $q$-dependent detrended cross-correlation coefficient \rho(q,s). By extending traditional metrics, this approach captures correlations at varying fluctuation amplitudes and time scales. The method employs $q$-dependent minimum spanning trees ($q$MSTs) to visualize evolving network structures. Using minute-by-minute exchange rate data for 140 cryptocurrencies on Binance (Jan 2021-Oct 2024), a rolling window analysis reveals significant shifts in $q$MSTs, notably around April 2022 during the Terra/Luna crash. Initially centralized around Bitcoin (BTC), the network later decentralized, with Ethereum (ETH) and others gaining prominence. Spectral analysis confirms BTC's declining dominance and increased diversification among assets. A key finding is that medium-scale fluctuations exhibit stronger correlations than large-scale ones, with $q$MSTs based on the latter being more decentralized. Properly exploiting such facts may offer the possibility of a more flexible optimal portfolio construction. Distance metrics highlight that major disruptions amplify correlation differences, leading to fully decentralized structures during crashes. These results demonstrate $q$MSTs' effectiveness in uncovering fluctuation-dependent correlations, with potential applications beyond finance, including biology, social and other complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18820v2</guid>
      <category>q-fin.ST</category>
      <category>cs.CE</category>
      <category>econ.EM</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/v7cl-h7xr</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 112, 044309 (2025)</arxiv:journal_reference>
      <dc:creator>Marcin W\k{a}torek, Marija Bezbradica, Martin Crane, Jaros{\l}aw Kwapie\'n, Stanis{\l}aw Dro\.zd\.z</dc:creator>
    </item>
  </channel>
</rss>
