<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Aug 2025 01:26:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Network-Specific Models for Multimodal Brain Response Prediction</title>
      <link>https://arxiv.org/abs/2508.06499</link>
      <description>arXiv:2508.06499v1 Announce Type: new 
Abstract: In this work, we present a network-specific approach for predicting brain responses to complex multimodal movies, leveraging the Yeo 7-network parcellation of the Schaefer atlas. Rather than treating the brain as a homogeneous system, we grouped the seven functional networks into four clusters and trained separate multi-subject, multi-layer perceptron (MLP) models for each. This architecture supports cluster-specific optimization and adaptive memory modeling, allowing each model to adjust temporal dynamics and modality weighting based on the functional role of its target network. Our results demonstrate that this clustered strategy significantly enhances prediction accuracy across the 1,000 cortical regions of the Schaefer atlas. The final model achieved an eighth-place ranking in the Algonauts Project 2025 Challenge, with out-of-distribution (OOD) correlation scores nearly double those of the baseline model used in the selection phase. Code is available at https://github.com/Corsi01/algo2025.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06499v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Corsico, Giorgia Rigamonti, Simone Zini, Luigi Celona, Paolo Napoletano</dc:creator>
    </item>
    <item>
      <title>Computing with Canonical Microcircuits</title>
      <link>https://arxiv.org/abs/2508.06501</link>
      <description>arXiv:2508.06501v1 Announce Type: new 
Abstract: The human brain represents the only known example of general intelligence that naturally aligns with human values. On a mere 20-watt power budget, the brain achieves robust learning and adaptive decision-making in ways that continue to elude advanced AI systems. Inspired by the brain, we present a computational architecture based on canonical microcircuits (CMCs) - stereotyped patterns of neurons found ubiquitously throughout the cortex. We implement these circuits as neural ODEs comprising spiny stellate, inhibitory, and pyramidal neurons, forming an 8-dimensional dynamical system with biologically plausible recurrent connections. Our experiments show that even a single CMC node achieves 97.8 percent accuracy on MNIST, while hierarchical configurations - with learnable inter-regional connectivity and recurrent connections - yield improved performance on more complex image benchmarks. Notably, our approach achieves competitive results using substantially fewer parameters than conventional deep learning models. Phase space analysis revealed distinct dynamical trajectories for different input classes, highlighting interpretable, emergent behaviors observed in biological systems. These findings suggest that neuromorphic computing approaches can improve both efficiency and interpretability in artificial neural networks, offering new directions for parameter-efficient architectures grounded in the computational principles of the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06501v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>PK Douglas</dc:creator>
    </item>
    <item>
      <title>Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors</title>
      <link>https://arxiv.org/abs/2508.06503</link>
      <description>arXiv:2508.06503v1 Announce Type: new 
Abstract: How do we predict others from patterns in their behavior and what are the computational constraints that limit this ability? We investigate these questions by modeling human behavior over repeated games of rock, paper, scissors from Brockbank &amp; Vul (2024). Against algorithmic opponents that varied in strategic sophistication, people readily exploit simple transition patterns (e.g., consistently playing rock after paper) but struggle to detect more complex sequential dependencies. To understand the cognitive mechanisms underlying these abilities and their limitations, we deploy Hypothetical Minds (HM), a large language model-based agent that generates and tests hypotheses about opponent strategies, as a cognitive model of this behavior (Cross et al., 2024). We show that when applied to the same experimental conditions, HM closely mirrors human performance patterns, succeeding and failing in similar ways. To better understand the source of HM's failures and whether people might face similar cognitive bottlenecks in this context, we performed a series of ablations and augmentations targeting different components of the system. When provided with natural language descriptions of the opponents' strategies, HM successfully exploited 6/7 bot opponents with win rates &gt;80% suggesting that accurate hypothesis generation is the primary cognitive bottleneck in this task. Further, by systematically manipulating the model's hypotheses through pedagogically-inspired interventions, we find that the model substantially updates its causal understanding of opponent behavior, revealing how model-based analyses can produce testable hypotheses about human cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06503v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Cross, Erik Brockbank, Tobias Gerstenberg, Judith E. Fan, Daniel L. K. Yamins, Nick Haber</dc:creator>
    </item>
    <item>
      <title>Synthetic Data Generation for Classifying Electrophysiological and Morpho-Electrophysiological Neurons from Mouse Visual Cortex</title>
      <link>https://arxiv.org/abs/2508.06514</link>
      <description>arXiv:2508.06514v1 Announce Type: new 
Abstract: The accurate classification of neuronal cell types is central to decoding brain function, yet remains hindered by data scarcity and cellular heterogeneity. Here, we benchmarked classical and deep generative synthetic data augmentation strategies -- including SMOTE, GANs, VAEs, Normalizing Flows, and DDPMs -- for supervised classification of both electrophysiological (e-type) and morpho-electrophysiological (mee-type) neuron types from the mouse visual cortex. Using a curated dataset annotated with 48 electrophysiological and 24 morphological features, we established baseline classifiers and introduced synthetic data generated by each method. Our results demonstrate that SMOTE-based augmentation yields the highest classification accuracies (absolute gains of 0.16 for e-types, 0.12 for mee-types), outperforming deep generative models. GANs approached similar performance when hyperparameters and sample sizes were optimized, but were more sensitive to model specification. In addition, we benchmarked synthetic neuron fidelity by comparing mean absolute errors between synthetic and real class profiles against the natural phenotypic variability observed between real neuronal classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06514v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Vasques, Laura Cif</dc:creator>
    </item>
    <item>
      <title>Data-Efficient Neural Training with Dynamic Connectomes</title>
      <link>https://arxiv.org/abs/2508.06817</link>
      <description>arXiv:2508.06817v1 Announce Type: new 
Abstract: The study of dynamic functional connectomes has provided valuable insights into how patterns of brain activity change over time. Neural networks process information through artificial neurons, conceptually inspired by patterns of activation in the brain. However, their hierarchical structure and high-dimensional parameter space pose challenges for understanding and controlling training dynamics. In this study, we introduce a novel approach to characterize training dynamics in neural networks by representing evolving neural activations as functional connectomes and extracting dynamic signatures of activity throughout training. Our results show that these signatures effectively capture key transitions in the functional organization of the network. Building on this analysis, we propose the use of a time series of functional connectomes as an intrinsic indicator of learning progress, enabling a principled early stopping criterion. Our framework performs robustly across benchmarks and provides new insights into neural network training dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06817v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Wu, Peilin He, Tananun Songdechakraiwut</dc:creator>
    </item>
    <item>
      <title>Sensory robustness through top-down feedback and neural stochasticity in recurrent vision models</title>
      <link>https://arxiv.org/abs/2508.07115</link>
      <description>arXiv:2508.07115v1 Announce Type: new 
Abstract: Biological systems leverage top-down feedback for visual processing, yet most artificial vision models succeed in image classification using purely feedforward or recurrent architectures, calling into question the functional significance of descending cortical pathways. Here, we trained convolutional recurrent neural networks (ConvRNN) on image classification in the presence or absence of top-down feedback projections to elucidate the specific computational contributions of those feedback pathways. We found that ConvRNNs with top-down feedback exhibited remarkable speed-accuracy trade-off and robustness to noise perturbations and adversarial attacks, but only when they were trained with stochastic neural variability, simulated by randomly silencing single units via dropout. By performing detailed analyses to identify the reasons for such benefits, we observed that feedback information substantially shaped the representational geometry of the post-integration layer, combining the bottom-up and top-down streams, and this effect was amplified by dropout. Moreover, feedback signals coupled with dropout optimally constrained network activity onto a low-dimensional manifold and encoded object information more efficiently in out-of-distribution regimes, with top-down information stabilizing the representational dynamics at the population level. Together, these findings uncover a dual mechanism for resilient sensory coding. On the one hand, neural stochasticity prevents unit-level co-adaptation albeit at the cost of more chaotic dynamics. On the other hand, top-down feedback harnesses high-level information to stabilize network activity on compact low-dimensional manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07115v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonino Greco, Marco D'Alessandro, Karl J. Friston, Giovanni Pezzulo, Markus Siegel</dc:creator>
    </item>
    <item>
      <title>Modeling bias in decision-making attractor networks</title>
      <link>https://arxiv.org/abs/2508.07471</link>
      <description>arXiv:2508.07471v1 Announce Type: new 
Abstract: Attractor neural network models of cortical decision-making circuits represent them as dynamical systems in the state space of neural firing rates with the attractors of the network encoding possible decisions. While the attractors of these models are well studied, far less attention is paid to the basins of attraction even though their sizes can be said to encode the biases towards the corresponding decisions. The parameters of an attractor network control both the attractors and the basins of attraction. However, findings in behavioral economics suggest that the framing of a decision-making task can affect preferences even when the same choices are being offered. This suggests that the circuit encodes both choices and biases separately, that preferences can be changed without disrupting the encoding of the choices themselves. In the context of attractor networks, this would mean that the parameters can be adjusted to reshape the basins of attraction without changing the attractors themselves. How can this be realized and how do the parameters shape decision-making biases?
  In this PhD thesis we study this question mathematically in the context of threshold linear networks, a common firing rate model used in computational neuroscience. (Note: This is an abbreviated abstract. Please see the document for the full abstract.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07471v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Safaan Sadiq</dc:creator>
    </item>
    <item>
      <title>PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets</title>
      <link>https://arxiv.org/abs/2508.07253</link>
      <description>arXiv:2508.07253v1 Announce Type: cross 
Abstract: Reliable seizure detection is critical for diagnosing and managing epilepsy, yet clinical workflows remain dependent on time-consuming manual EEG interpretation. While machine learning has shown promise, existing approaches often rely on dataset-specific optimisations, limiting their real-world applicability and reproducibility. Here, we introduce an innovative, open-source machine-learning framework that enables robust and generalisable seizure detection across varied clinical datasets. We evaluate our approach on two publicly available EEG datasets that differ in patient populations and electrode configurations. To enhance robustness, the framework incorporates an automated pre-processing pipeline to standardise data and a majority voting mechanism, in which multiple models independently assess each second of EEG before reaching a final decision. We train, tune, and evaluate models within each dataset, assessing their cross-dataset transferability. Our models achieve high within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and 0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets despite differences in EEG setups and populations (AUC 0.615+/-0.039 for models trained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case) without any post-processing. Furthermore, a mild post-processing improved the within-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset results to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the potential of, and essential considerations for, deploying our framework in diverse clinical settings. By making our methodology fully reproducible, we provide a foundation for advancing clinically viable, dataset-agnostic seizure detection systems. This approach has the potential for widespread adoption, complementing rather than replacing expert interpretation, and accelerating clinical integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07253v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bartlomiej Chybowski, Shima Abdullateef, Hollan Haule, Alfredo Gonzalez-Sulser, Javier Escudero</dc:creator>
    </item>
    <item>
      <title>Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment</title>
      <link>https://arxiv.org/abs/2508.07283</link>
      <description>arXiv:2508.07283v1 Announce Type: cross 
Abstract: This study explores the intersection of electroencephalography (EEG) microstates and Large Language Models (LLMs) to enhance the assessment of cognitive load states. By utilizing EEG microstate features, the research aims to fine-tune LLMs for improved predictions of distinct cognitive states, specifically 'Rest' and 'Load'. The experimental design is delineated in four comprehensive stages: dataset collection and preprocessing, microstate segmentation and EEG backfitting, feature extraction paired with prompt engineering, and meticulous LLM model selection and refinement. Employing a supervised learning paradigm, the LLM is trained to identify cognitive load states based on EEG microstate features integrated into prompts, producing accurate discrimination of cognitive load. A curated dataset, linking EEG features to specified cognitive load conditions, underpins the experimental framework. The results indicate a significant improvement in model performance following the proposed fine-tuning, showcasing the potential of EEG-informed LLMs in cognitive neuroscience and cognitive AI applications. This approach not only contributes to the understanding of brain dynamics but also paves the way for advancements in machine learning techniques applicable to cognitive load and cognitive AI research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07283v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bujar Raufi</dc:creator>
    </item>
    <item>
      <title>From Transformer to Biology: A Hierarchical Model for Attention in Complex Problem-Solving</title>
      <link>https://arxiv.org/abs/2406.14100</link>
      <description>arXiv:2406.14100v2 Announce Type: replace 
Abstract: Attention is fundamental to cognition, yet it remains a challenge to understand attention in tasks approaching real-world complexity. Here, we approached this problem by modeling gaze patterns of monkeys playing Pac-Man. We first show a transformer network trained to reproduce their gameplay developed internal attention patterns closely matching the monkeys' eye movements. By dissecting the network's attention, we revealed a hierarchical structure comprising two components: a value-based layer encoding fixed object salience, coupled with a dynamic interaction layer tracking relational information between game elements. We further developed a condensed model in which reward-driven attention serves as a gain modulator and is integrated with spatial attention maps, predicting attention as well as the transformer. Together, our study pioneers the use of AI architectures as analytical tools and bridges mechanistic interpretability with cognitive neuroscience to yield novel, testable insights into how the brain coordinates reward, spatial cognition, and attention in complex environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14100v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongqiao Lin, Yunwei Li, Tianming Yang</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control on the Neural Manifold</title>
      <link>https://arxiv.org/abs/2406.14801</link>
      <description>arXiv:2406.14801v2 Announce Type: replace 
Abstract: Neural manifolds are an attractive theoretical framework for characterizing the complex behaviors of neural populations. However, many of the tools for identifying these low-dimensional subspaces are correlational and provide limited insight into the underlying dynamics. The ability to precisely control the latent activity of a circuit would allow researchers to investigate the structure and function of neural manifolds. We simulate controlling the latent dynamics of a neural population using closed-loop, dynamically generated sensory inputs. Using a spiking neural network (SNN) as a model of a neural circuit, we find low-dimensional representations of both the network activity (the neural manifold) and a set of salient visual stimuli. The fields of classical and optimal control offer a range of methods to choose from for controlling dynamics on the neural manifold, which differ in performance, computational cost, and ease of implementation. Here, we focus on two commonly used control methods: proportional-integral-derivative (PID) control and model predictive control (MPC). PID is a computationally lightweight controller that is simple to implement. In contrast, MPC is a model-based, anticipatory controller with a much higher computational cost and engineering overhead. We evaluate both methods on trajectory-following tasks in latent space, under partial observability and in the presence of unknown noise. While both controllers in some cases were able to successfully control the latent dynamics on the neural manifold, MPC consistently produced more accurate control and required less hyperparameter tuning. These results demonstrate how MPC can be applied on the neural manifold using data-driven dynamics models, and provide a framework to experimentally test for causal relationships between manifold dynamics and external stimuli.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14801v2</guid>
      <category>q-bio.NC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christof Fehrman, C. Daniel Meliza</dc:creator>
    </item>
    <item>
      <title>"What" x "When" working memory representations using Laplace Neural Manifolds</title>
      <link>https://arxiv.org/abs/2409.20484</link>
      <description>arXiv:2409.20484v2 Announce Type: replace 
Abstract: Working memory - the ability to remember recent events as they recede continuously into the past - requires the ability to represent any stimulus at any time delay. This property requires neurons coding working memory to show mixed selectivity, with conjunctive receptive fields (RFs) for stimuli and time, forming a representation of 'what' x 'when'. We study the properties of such a working memory in simple experiments where a single stimulus must be remembered for a short time. The requirement of conjunctive receptive fields allows the covariance matrix of the network to decouple neatly, allowing an understanding of the low-dimensional dynamics of the population. Different choices of temporal basis functions lead to qualitatively different dynamics. We study a specific choice - a Laplace space with exponential basis functions for time coupled to an "Inverse Laplace" space with circumscribed basis functions in time. We refer to this choice with basis functions that evenly tile log time as a Laplace Neural Manifold. Despite the fact that they are related to one another by a linear projection, the Laplace population shows a stable stimulus-specific subspace whereas the Inverse Laplace population shows rotational dynamics. The growth of the rank of the covariance matrix with time depends on the density of the temporal basis set; logarithmic tiling shows good agreement with data. We sketch a continuous attractor CANN that constructs a Laplace Neural Manifold. The attractor in the Laplace space appears as an edge; the attractor for the inverse space appears as a bump. This work provides a map for going from more abstract cognitive models of WM to circuit-level implementation using continuous attractor neural networks, and places constraints on the types of neural dynamics that support working memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20484v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aakash Sarkar, Chenyu Wang, Shangfu Zuo, Marc W. Howard</dc:creator>
    </item>
    <item>
      <title>Multihead self-attention in cortico-thalamic circuits</title>
      <link>https://arxiv.org/abs/2504.06354</link>
      <description>arXiv:2504.06354v3 Announce Type: replace 
Abstract: Both biological cortico-thalamic networks and artificial transformer networks use canonical computations to perform a wide range of cognitive tasks. In this work, we propose that the structure of cortico-thalamic circuits is well suited to realize a computation analogous to multihead self-attention, the main algorithmic innovation of transformer networks. We assign distinct computational roles to superficial and deep pyramidal cells of the cortex: while superficial pyramidal cells maintain a key-value memory, deep pyramidal cells encode the current query, gain-modulated by the key-value memory in the superficial layer. We show that the structure of this computation matches the fine-grained structure of core and matrix projections from the thalamus to the cortex. We then suggest the parallel between one head of attention and a cortical area, and propose that a thalamo-cortico-thalamic pathway implements a computation akin to a multihead, unnormalized, linear self-attention block. Cross-attention corresponds to the key-value memory of one cortical area being used for retrieval by the query in another cortical area. Finally, as a first step towards a mechanistic theory of synaptic learning of cortical transformers, we derive the formal gradients of a typical loss function with respect to the parameters of such computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06354v3</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arno Granier, Walter Senn</dc:creator>
    </item>
    <item>
      <title>Summary statistics of learning link changing neural representations to behavior</title>
      <link>https://arxiv.org/abs/2504.16920</link>
      <description>arXiv:2504.16920v3 Announce Type: replace 
Abstract: How can we make sense of large-scale recordings of neural activity across learning? Theories of neural network learning with their origins in statistical physics offer a potential answer: for a given task, there are often a small set of summary statistics that are sufficient to predict performance as the network learns. Here, we review recent advances in how summary statistics can be used to build theoretical understanding of neural network learning. We then argue for how this perspective can inform the analysis of neural data, enabling better understanding of learning in biological and artificial neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16920v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob A. Zavatone-Veth, Blake Bordelon, Cengiz Pehlevan</dc:creator>
    </item>
    <item>
      <title>Markov Blanket Density and Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2506.05794</link>
      <description>arXiv:2506.05794v5 Announce Type: replace 
Abstract: This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics, including the minimization of variational and expected free energy, naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05794v5</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca M. Possati</dc:creator>
    </item>
  </channel>
</rss>
