<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Dec 2025 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Subgradient Methods for Lipschitz Convex Optimization with Error Bounds</title>
      <link>https://arxiv.org/abs/2512.13863</link>
      <description>arXiv:2512.13863v1 Announce Type: new 
Abstract: We study the iteration complexity of Lipschitz convex optimization problems satisfying a general error bound. We show that for this class of problems, subgradient descent with either Polyak stepsizes or decaying stepsizes achieves minimax optimal convergence guarantees for decreasing distance-to-optimality. The main contribution is a novel lower-bounding argument that produces hard functions simultaneously satisfying zero-chain conditions and global error bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13863v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>DAMA: A Unified Accelerated Approach for Decentralized Nonconvex Minimax Optimization-Part I: Algorithm Development and Results</title>
      <link>https://arxiv.org/abs/2512.13920</link>
      <description>arXiv:2512.13920v1 Announce Type: new 
Abstract: In this work and its accompanying Part II [1], we develop an accelerated algorithmic framework, DAMA (Decentralized Accelerated Minimax Approach), for nonconvex Polyak-Lojasiewicz minimax optimization over decentralized multi-agent networks. Our approach integrates online and offline stochastic minimax algorithms with various decentralized learning strategies, yielding a versatile framework with broader flexibility than existing methods. Our unification is threefold: (i) we propose a unified decentralized learning strategy for minimax optimization that subsumes existing bias-correction techniques, such as gradient tracking, while introducing new variants that achieve tighter network-dependent bounds; (ii) we introduce a probabilistic gradient estimator, GRACE (Gradient Acceleration Estimator), which unifies momentum-based methods and loopless variance-reduction techniques for constructing accelerated gradients within DAMA, and is broadly applicable to general stochastic optimization problems; and (iii) we develop a unified analytical framework that establishes a general performance bound for DAMA, achieving state-of-the-art results with the best-known sample complexity. To the best of our knowledge, DAMA is the first framework to achieve a multi-level unification of decentralized learning strategies and accelerated gradient techniques. This work focuses on algorithm development and the main results, while Part II provides the theoretical analysis that substantiates these results and presents empirical validation across diverse network topologies using synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13920v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyuan Cai, Sulaiman A. Alghunaim, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>DAMA: A Unified Accelerated Approach for Decentralized Nonconvex Minimax Optimization-Part II: Convergence and Performance Analyses</title>
      <link>https://arxiv.org/abs/2512.13923</link>
      <description>arXiv:2512.13923v1 Announce Type: new 
Abstract: In Part I of this work [1], we developed an accelerated algorithmic framework, DAMA (Decentralized Accelerated Minimax Approach), for nonconvex Polyak-Lojasiewicz (PL) minimax optimization over decentralized multi-agent networks. To further enhance convergence in online and offline scenarios, Part I of this work [1] also proposed a novel accelerated gradient estimator, namely, GRACE (GRadient ACceleration Estimator), which unifies several momentum-based methods (e.g., STORM) and loopless variance-reduction techniques (e.g., PAGE, Loopless SARAH), thereby enabling accelerated gradient updates within DAMA. Part I reported a unified performance bound for DAMA and refined guarantees for specific algorithmic instances, demonstrating the superior performance of several new variants on sparsely connected networks. In this Part II, we focus on the convergence and performance bounds that substantiate the main results presented in Part I [1]. In particular, we establish a unified performance bound for DAMA using the transformed recursion derived in Part I and subsequently refine this bound for its various special cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13923v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Haoyuan Cai, Sulaiman A. Alghunaim, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Volume Formulae for the Convex Hull of the Graph of a Trilinear Monomial: A Complete Characterization for General Box Domains</title>
      <link>https://arxiv.org/abs/2512.13964</link>
      <description>arXiv:2512.13964v1 Announce Type: new 
Abstract: Solving difficult mixed-integer nonlinear programs via spatial branch-and-bound requires effective convex outer-approximations of nonconvex sets. In this framework, complex problem formulations are decomposed into simpler library functions, whose relaxations are then composed to build relaxations of the overall problem. The trilinear monomial serves as one such fundamental library function, appearing frequently as a building block across diverse applications. By definition, its convex hull provides the tightest possible relaxation and thus serves as a benchmark for evaluating alternatives. Mixed volume techniques have yielded a parameterized volume formula for the convex hull of the graph of a trilinear monomial; however, existing results only address the case where all six bounds of the box domain are nonnegative. This restriction represents a notable gap in the literature, as variables with mixed-sign domains arise naturally in practice. In this work, we close the gap by extending to the general case via an exhaustive case analysis. We demonstrate that removing the nonnegative domain assumption alters the underlying structure of the convex hull polytope, leading to six distinct volume formulae that together characterize all possible parameter configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13964v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lillian Makhoul, Emily Speakman</dc:creator>
    </item>
    <item>
      <title>Complete Characterizations of Well-Posedness in Parametric Composite Optimization</title>
      <link>https://arxiv.org/abs/2512.14124</link>
      <description>arXiv:2512.14124v1 Announce Type: new 
Abstract: This paper provides complete characterization of well-posedness for Karush-Kuhn-Tucker (KKT) systems associated with general problems of perturbed composite optimization. Leveraging the property of parabolic regularity for composite models, we show that the second-order subderivative of the cost function reduces to the novel second-order variational function playing a crucial role in the subsequent analysis. This foundational result implies that the strong second-order sufficient condition (SSOSC) introduced in this work for the general class of composite optimization problems naturally extends the classical second-order sufficient condition in nonlinear programming. Then we obtain several equivalent characterizations of the second-order qualification condition (SOQC) and highlight its equivalence to the constraint nondegeneracy condition under the $\mathcal{C}^{2}$-cone reducibility assumption. These insights lead us to multiple equivalent conditions for the major Lipschitz-like/Aubin property of KKT systems, including the SOQC combined with the new second-order subdifferential condition and the SOQC combined with tilt stability of local minimizers. Furthermore, under $\mathcal{C}^{2}$-cone reducibility, we prove that the Lipschitz-like property of the reference KKT system is equivalent to its strong regularity. Finally, we demonstrate that the Lipschitz-like property is equivalent to the nonsingularity of the generalized Jacobian associated with the KKT system under a certain verifiable assumption. These results provide a unified and rigorous framework for analyzing stability and sensitivity of solutions to composite optimization problems, as well as for the design and justification of numerical algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14124v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Boris S. Mordukhovich, Peipei Tang, Chengjing Wang</dc:creator>
    </item>
    <item>
      <title>Shape design with phase field methods for structural hemivariational inequalities in contact problems</title>
      <link>https://arxiv.org/abs/2512.14226</link>
      <description>arXiv:2512.14226v1 Announce Type: new 
Abstract: We develop mathematical models for shape design and topology optimization in structural contact problems involving friction between elastic and rigid bodies. The governing mechanical constraint is a nonlinear, non-smooth, and non-convex hemivariational inequality, which provides a more general and realistic description of frictional contact forces than standard variational inequalities, but is also more challenging due to its non-convexity. For energy-type shape functionals, the Eulerian derivative of the hemivariational inequality is derived through rigorous shape sensitivity analysis. The rationality of a regularization approach is justified by asymptotic analysis, and this method is further applied to handle the non-smoothness of general shape functionals in the sensitivity framework. Based on these theoretical results, a numerical boundary variational method is proposed for shape optimization. For topology optimization, three phase-field algorithms are developed: a gradient-flow phase-field method, a phase-field method with second-order regularization of the cost functional, and a phase-field method coupled with topological derivatives. To the best of our knowledge, these approaches are new for shape design in hemivariational inequalities. Various numerical experiments confirm the accuracy and effectiveness of the proposed shape and topology optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14226v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Tan, Fang Feng, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>Randomized multi-class classification under system constraints: a unified approach via post-processing</title>
      <link>https://arxiv.org/abs/2512.14246</link>
      <description>arXiv:2512.14246v1 Announce Type: new 
Abstract: We study the problem of multi-class classification under system-level constraints expressible as linear functionals over randomized classifiers. We propose a post-processing approach that adjusts a given base classifier to satisfy general constraints without retraining. Our method formulates the problem as a linearly constrained stochastic program over randomized classifiers, and leverages entropic regularization and dual optimization techniques to construct a feasible solution. We provide finite-sample guarantees for the risk and constraint satisfaction for the final output of our algorithm under minimal assumptions. The framework accommodates a broad class of constraints, including fairness, abstention, and churn requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14246v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evgenii Chzhen (LMO, CELESTE), Mohamed Hebiri (LAMA), Gayane Taturyan (LAMA, IMT)</dc:creator>
    </item>
    <item>
      <title>Towards Real Time Control of Water Engineering with Nonlinear Hyperbolic Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2512.14387</link>
      <description>arXiv:2512.14387v1 Announce Type: new 
Abstract: This paper examines aspirational requirements for software addressing mixed-integer optimization problems constrained by the nonlinear Shallow Water partial differential equations (PDEs), motivated by applications such as river-flow management in hydropower cascades. Realistic deployment of such software would require the simultaneous treatment of nonlinear and potentially non-smooth PDE dynamics, limited theoretical guarantees on the existence and regularity of control-to-state mappings under varying boundary conditions, and computational performance compatible with operational decision-making. In addition, practical settings motivate consideration of uncertainty arising from forecasts of demand, inflows, and environmental conditions. At present, the theoretical foundations, numerical optimization methods, and large-scale scientific computing tools required to address these challenges in a unified and tractable manner remain the subject of ongoing research across the associated research communities. Rather than proposing a complete solution, this work uses the problem as a case study to identify and organize the mathematical, algorithmic, and computational components that would be necessary for its realization. The resulting framework highlights open challenges and intermediate research directions, and may inform both more circumscribed related problems and the design of future large-scale collaborative efforts aimed at addressing such objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14387v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio DiFonzo, Michael Holst, Morteza Kimiaei, Vyacheslav Kungurtsev, Songqiang Qiu</dc:creator>
    </item>
    <item>
      <title>A preconditioned second-order convex splitting algorithm with extrapolation</title>
      <link>https://arxiv.org/abs/2512.14468</link>
      <description>arXiv:2512.14468v1 Announce Type: new 
Abstract: Nonconvex optimization problems are widespread in modern machine learning and data science. We introduce an extrapolation strategy into a class of preconditioned second-order convex splitting algorithms for nonconvex optimization problems. The proposed algorithms combine second-order backward differentiation formulas (BDF2) with an extrapolation method. Meanwhile, the implicit-explicit scheme simplifies the subproblem through a preconditioned process. As a result, our approach solves nonconvex problems efficiently without significant computational overhead. Theoretical analysis establishes global convergence of the algorithms using Kurdyka-\L ojasiewicz properties. Numerical experiments include a benchmark problem, the least squares problem with SCAD regularization, and an image segmentation problem. These results demonstrate that our algorithms are highly efficient, as they achieve reduced solution times and competitive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14468v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xinhua Shen, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>An Inexact Modified Quasi-Newton Method for Nonsmooth Regularized Optimization</title>
      <link>https://arxiv.org/abs/2512.14507</link>
      <description>arXiv:2512.14507v1 Announce Type: new 
Abstract: We introduce iR2N, a modified proximal quasi-Newton method for minimizing the sum of a smooth function $f$ and a lower semi-continuous prox-bounded function $h$, allowing inexact evaluations of $f$, its gradient, and the associated proximal operators. Both $f$ and $h$ may be nonconvex. iR2N is particularly suited to settings where proximal operators are computed via iterative procedures that can be stopped early, or where the accuracy of $f$ and $\nabla f$ can be controlled, leading to significant computational savings. At each iteration, the method approximately minimizes the sum of a quadratic model of $f$, a model of $h$, and an adaptive quadratic regularization term ensuring global convergence. Under standard accuracy assumptions, we prove global convergence in the sense that a first-order stationarity measure converges to zero, with worst-case evaluation complexity $O(\epsilon^{-2})$. Numerical experiments with $\ell_p$ norms, $\ell_p$ total variation, and the indicator of the nonconvex pseudo $p$-norm ball illustrate the effectiveness and flexibility of the approach, and show how controlled inexactness can substantially reduce computational effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14507v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.32728.97288</arxiv:DOI>
      <dc:creator>Nathan Allaire, S\'ebastien Le Digabel, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>The Innovation Null Space of the Kalman Predictor: A Stochastic Perspective for DeePC</title>
      <link>https://arxiv.org/abs/2512.14520</link>
      <description>arXiv:2512.14520v1 Announce Type: new 
Abstract: Willems' fundamental lemma uses a key decision variable $g$ to combine measured input-output data and describe trajectories of a linear time-invariant system. In this paper, we ask: what is a good choice for this vector $g$ when the system is affected by noise? For a linear system with Gaussian noise, we show that there exists an optimal subspace for this decision variable $g$, which is the null space of the innovation Hankel matrix. If the decision vector lies in this null space, the resulting predictor gets closer to the Kalman predictor. To show this, we use a result that we refer to as the Kalman Filter Fundamental Lemma (KFFL), which applies Willems' lemma to the Kalman predictor. This viewpoint also explains several existing data-driven predictive control methods: regularized DeePC schemes act as soft versions of the innovation null-space constraint, instrumental-variable methods enforce it by construction, and ARX-based approaches explicitly estimate this innovation null space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14520v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aihui Liu, Magnus Jansson</dc:creator>
    </item>
    <item>
      <title>Enhancing Orbital Debris Remediation with Reconfigurable Space-Based Laser Constellations</title>
      <link>https://arxiv.org/abs/2512.14682</link>
      <description>arXiv:2512.14682v1 Announce Type: new 
Abstract: Orbital debris poses an escalating threat to space missions and the long-term sustainability of Earth's orbital environment. The literature proposes various approaches for orbital debris remediation, including the use of multiple space-based lasers that collaboratively engage debris targets. While the proof of concept for this laser-based approach has been demonstrated, critical questions remain about its scalability and responsiveness as the debris population continues to expand rapidly. This paper introduces constellation reconfiguration as a system-level strategy to address these limitations. Through coordinated orbital maneuvers, laser-equipped satellites can dynamically adapt their positions to respond to evolving debris distributions and time-critical events. We formalize this concept as the Reconfigurable Laser-to-Debris Engagement Scheduling Problem (R-L2D-ESP), an optimization framework that determines the optimal sequence of constellation reconfigurations and laser engagements to maximize debris remediation capacity, which quantifies the constellation's ability to nudge, deorbit, or perform just-in-time collision avoidance maneuvers on debris objects. To manage the complexity of this combinatorial optimization problem, we employ a receding horizon approach. Our experiments reveal that reconfigurable constellations significantly outperform static ones, achieving greater debris remediation capacity and successfully deorbiting substantially more debris objects. Additionally, our sensitivity analyses identify the key parameters that influence remediation performance the most, providing essential insights for future system design. These findings demonstrate that constellation reconfiguration represents a promising advancement for laser-based debris removal systems, offering the adaptability and scalability necessary to enhance this particular approach to orbital debris remediation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14682v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David O. Williams Rogers, Hang Woon Lee</dc:creator>
    </item>
    <item>
      <title>A Convex Obstacle Avoidance Formulation</title>
      <link>https://arxiv.org/abs/2512.13836</link>
      <description>arXiv:2512.13836v1 Announce Type: cross 
Abstract: Autonomous driving requires reliable collision avoidance in dynamic environments. Nonlinear Model Predictive Controllers (NMPCs) are suitable for this task, but struggle in time-critical scenarios requiring high frequency. To meet this demand, optimization problems are often simplified via linearization, narrowing the horizon window, or reduced temporal nodes, each compromising accuracy or reliability. This work presents the first general convex obstacle avoidance formulation, enabled by a novel approach to integrating logic. This facilitates the incorporation of an obstacle avoidance formulation into convex MPC schemes, enabling a convex optimization framework with substantially improved computational efficiency relative to conventional nonconvex methods. A key property of the formulation is that obstacle avoidance remains effective even when obstacles lie outside the prediction horizon, allowing shorter horizons for real-time deployment. In scenarios where nonconvex formulations are unavoidable, the proposed method meets or exceeds the performance of representative nonconvex alternatives. The method is evaluated in autonomous vehicle applications, where system dynamics are highly nonlinear.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13836v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo Tapia, Iman Soltani</dc:creator>
    </item>
    <item>
      <title>Safe Online Control-Informed Learning</title>
      <link>https://arxiv.org/abs/2512.13868</link>
      <description>arXiv:2512.13868v1 Announce Type: cross 
Abstract: This paper proposes a Safe Online Control-Informed Learning framework for safety-critical autonomous systems. The framework unifies optimal control, parameter estimation, and safety constraints into an online learning process. It employs an extended Kalman filter to incrementally update system parameters in real time, enabling robust and data-efficient adaptation under uncertainty. A softplus barrier function enforces constraint satisfaction during learning and control while eliminating the dependence on high-quality initial guesses. Theoretical analysis establishes convergence and safety guarantees, and the framework's effectiveness is demonstrated on cart-pole and robot-arm systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13868v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tianyu Zhou, Zihao Liang, Zehui Lu, Shaoshuai Mou</dc:creator>
    </item>
    <item>
      <title>Multiple Scale Methods For Optimization Of Discretized Continuous Functions</title>
      <link>https://arxiv.org/abs/2512.13993</link>
      <description>arXiv:2512.13993v1 Announce Type: cross 
Abstract: A multiscale optimization framework for problems over a space of Lipschitz continuous functions is developed. The method solves a coarse-grid discretization followed by linear interpolation to warm-start project gradient descent on progressively finer grids. Greedy and lazy variants are analyzed and convergence guarantees are derived that show the multiscale approach achieves provably tighter error bounds at lower computational cost than single-scale optimization. The analysis extends to any base algorithm with iterate convergence at a fixed rate. Constraint modification techniques preserve feasibility across scales. Numerical experiments on probability density estimation problems, including geological data, demonstrate speedups of an order of magnitude or better.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13993v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas J. E. Richardson, Noah Marusenko, Michael P. Friedlander</dc:creator>
    </item>
    <item>
      <title>Monge solutions and uniqueness in multi-marginal optimal transport with hierarchical jumps</title>
      <link>https://arxiv.org/abs/2512.14072</link>
      <description>arXiv:2512.14072v1 Announce Type: cross 
Abstract: We introduce Hierarchical Jump multi-marginal transport (HJMOT), a generalization of multi-marginal optimal transport where mass can "jump" over intermediate spaces via augmented isolated points. Established on Polish spaces, the framework guarantees the existence of Kantorovich solutions and, under sequential differentiability and a twist condition, the existence and uniqueness of Monge solutions. This core theory extends robustly to diverse settings, including smooth Riemannian manifolds, demonstrating its versatility as a unified framework for optimal transport across complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14072v1</guid>
      <category>math.PR</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Xu</dc:creator>
    </item>
    <item>
      <title>Physically consistent model learning for reaction-diffusion systems</title>
      <link>https://arxiv.org/abs/2512.14240</link>
      <description>arXiv:2512.14240v1 Announce Type: cross 
Abstract: This paper addresses the problem of learning reaction-diffusion (RD) systems from data while ensuring physical consistency and well-posedness of the learned models. Building on a regularization-based framework for structured model learning, we focus on learning parameterized reaction terms and investigate how to incorporate key physical properties, such as mass conservation and quasipositivity, directly into the learning process. Our main contributions are twofold: First, we propose techniques to systematically modify a given class of parameterized reaction terms such that the resulting terms inherently satisfy mass conservation and quasipositivity, ensuring that the learned RD systems preserve non-negativity and adhere to physical principles. These modifications also guarantee well-posedness of the resulting PDEs under additional regularity and growth conditions. Second, we extend existing theoretical results on regularization-based model learning to RD systems using these physically consistent reaction terms. Specifically, we prove that solutions to the learning problem converge to a unique, regularization-minimizing solution of a limit system even when conservation laws and quasipositivity are enforced. In addition, we provide approximation results for quasipositive functions, essential for constructing physically consistent parameterizations. These results advance the development of interpretable and reliable data-driven models for RD systems that align with fundamental physical laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14240v1</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erion Morina, Martin Holler</dc:creator>
    </item>
    <item>
      <title>On fractal minimizers and potentials of occupation measures</title>
      <link>https://arxiv.org/abs/2512.14248</link>
      <description>arXiv:2512.14248v1 Announce Type: cross 
Abstract: We consider four prototypes of variational problems and prove the existence of fractal minimizers through the direct method in the calculus of variations. By design these minimizers are H\"older curves or H\"older parametrizations of hypersurfaces whose images generally have a non-integer Hausdorff dimension. Although their origin is deterministic, their regularity properties are roughly similar to those of typical realizations of stochastic processes. As a key tool, we prove novel continuity and boundedness results for potentials of occupation measures of Gaussian random fields. These results complement well-known results for local times, but hold under much less restrictive assumptions. In an auxiliary section, we generalize earlier results on non-linear compositions of fractional Sobolev functions with $BV$-functions to higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14248v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Hinz, Jonas M. T\"olle, Lauri Viitasaari</dc:creator>
    </item>
    <item>
      <title>Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2512.14263</link>
      <description>arXiv:2512.14263v1 Announce Type: cross 
Abstract: Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14263v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Leenders, Thomas Quadt, Boris Cule, Roy Lindelauf, Herman Monsuur, Joost van Oijen, Mark Voskuijl</dc:creator>
    </item>
    <item>
      <title>An Additively Preconditioned Trust Region Strategy for Machine Learning</title>
      <link>https://arxiv.org/abs/2512.14286</link>
      <description>arXiv:2512.14286v1 Announce Type: cross 
Abstract: Modern machine learning, especially the training of deep neural networks, depends on solving large-scale, highly nonconvex optimization problems, whose objective function exhibit a rough landscape. Motivated by the success of parallel preconditioners in the context of Krylov methods for large scale linear systems, we introduce a novel nonlinearly preconditioned Trust-Region method that makes use of an additive Schwarz correction at each minimization step, thereby accelerating convergence.
  More precisely, we propose a variant of the Additively Preconditioned Trust-Region Strategy (APTS), which combines a right-preconditioned additive Schwarz framework with a classical Trust-Region algorithm. By decomposing the parameter space into sub-domains, APTS solves local non-linear sub-problems in parallel and assembles their corrections additively. The resulting method not only shows fast convergence; due to the underlying Trust-Region strategy, it furthermore largely obviates the need for hyperparameter tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14286v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Cruz Alegr\'ia, Bindi \c{C}apriqi, Shega Likaj, Ken Trotti, Rolf Krause</dc:creator>
    </item>
    <item>
      <title>Separation-free exponential fitting with structured noise, with applications to inverse problems in parabolic PDEs</title>
      <link>https://arxiv.org/abs/2512.14301</link>
      <description>arXiv:2512.14301v1 Announce Type: cross 
Abstract: We investigate the recovery of exponents and amplitudes of an exponential sum, where the exponents $\left\{\lambda_n \right\}_{n=1}^{N_1}$ are the first $N_1$ eigenvalues of a Sturm-Liouville operator, from finitely many measurements subject to measurement noise. This inverse problem is extremely ill-conditioned when the noise is arbitrary and unstructured. Surprisingly, however, the extreme ill-conditioning exhibited by this problem disappears when considering a \emph{structured} noise term, taken as an exponential sum with exponents given by the subsequent eigenvalues $\left\{\lambda_n \right\}_{n=N_1+1}^{N_1+N_2}$ of the Sturm-Liouville operator, multiplied by a noise magnitude parameter $\varepsilon&gt;0$. In this case, we rigorously show that the exponents and amplitudes can be recovered with super-exponential accuracy: we both prove the theoretical result and show that it can be achieved numerically by a specific algorithm. By leveraging recent results on the mathematical theory of super-resolution, we show in this paper that the classical Prony's method attains the analytic optimal error decay also in the ``separation-free'' regime where $\lambda_n \to \infty$ as $n \to \infty$, thereby extending the applicability of Prony's method to new settings. As an application of our theoretical analysis, we show that the approximated eigenvalues obtained by our method can be used to recover an unknown potential in a linear reaction-diffusion equation from discrete solution traces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14301v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Katz, Dmitry Batenkov, Giulia Giordano</dc:creator>
    </item>
    <item>
      <title>From STLS to Projection-based Dictionary Selection in Sparse Regression for System Identification</title>
      <link>https://arxiv.org/abs/2512.14404</link>
      <description>arXiv:2512.14404v1 Announce Type: cross 
Abstract: In this work, we revisit dictionary-based sparse regression, in particular, Sequential Threshold Least Squares (STLS), and propose a score-guided library selection to provide practical guidance for data-driven modeling, with emphasis on SINDy-type algorithms. STLS is an algorithm to solve the $\ell_0$ sparse least-squares problem, which relies on splitting to efficiently solve the least-squares portion while handling the sparse term via proximal methods. It produces coefficient vectors whose components depend on both the projected reconstruction errors, here referred to as the scores, and the mutual coherence of dictionary terms. The first contribution of this work is a theoretical analysis of the score and dictionary-selection strategy. This could be understood in both the original and weak SINDy regime. Second, numerical experiments on ordinary and partial differential equations highlight the effectiveness of score-based screening, improving both accuracy and interpretability in dynamical system identification. These results suggest that integrating score-guided methods to refine the dictionary more accurately may help SINDy users in some cases to enhance their robustness for data-driven discovery of governing equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14404v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hangjun Cho, Fabio V. G. Amaral, Andrei A. Klishin, Cassio M. Oishi, Steven L. Brunton</dc:creator>
    </item>
    <item>
      <title>Solving the Heilbronn Triangle Problem using Global Optimization Methods</title>
      <link>https://arxiv.org/abs/2512.14505</link>
      <description>arXiv:2512.14505v1 Announce Type: cross 
Abstract: We study the Heilbronn triangle problem, which involves placing n points in the unit square such that the minimum area of any triangle formed by these points is maximized. A straightforward maximin formulation of this problem is highly non-linear and non-convex due to the existence of bilinear terms and absolute value equations. We propose two mixed-integer quadratically constrained programming (MIQCP) and one QCP formulation, which can be readily solved by any global optimization solver. We develop several formulation enhancements in the form of bound tightening and symmetry breaking inequalities that are prevalent in the global optimization literature in addition to other enhancements that exploit the problem structure. With the help of these enhancements, our models reproduce proven optimal values for instances up to n = 8 points with certified optimality in the order of seconds. In the case of n = 9 points, for which no analytical proof is known, we establish a certified optimal value by a computational effort of one day. This is a significant improvement over the previous benchmark established in 31 days of computations by Chen et al. (2017).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14505v1</guid>
      <category>cs.CG</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirhossein Monji, Amirali Modir, Burak Kocuk</dc:creator>
    </item>
    <item>
      <title>On Viscosity Solutions of Hamilton-Jacobi Equations in the Wasserstein space and the Vanishing Viscosity Limit</title>
      <link>https://arxiv.org/abs/2512.14568</link>
      <description>arXiv:2512.14568v1 Announce Type: cross 
Abstract: The aim of this article is twofold. First, we develop a unified framework for viscosity solutions to both first-order Hamilton-Jacobi equations and semilinear Hamilton-Jacobi equations driven by the idiosyncratic operator. Second, we establish a vanishing-viscosity limit-extending beyond the classical control-theoretic setting-for solutions of semilinear Hamilton-Jacobi equations, proving their convergence to the corresponding first-order solution as the idiosyncratic noise vanishes. Our approach provides an optimal convergence rate.
  We also present some results of independent interest. These include existence theorems for the first-order equation, obtained through an appropriate Hopf-Lax representation, and a useful description of the action of the idiosyncratic operator on geodesically convex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14568v1</guid>
      <category>math.AP</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Ceccherini Silberstein, Daniela Tonon</dc:creator>
    </item>
    <item>
      <title>gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation</title>
      <link>https://arxiv.org/abs/2512.14658</link>
      <description>arXiv:2512.14658v1 Announce Type: cross 
Abstract: We introduce gridfm-datakit-v1, a Python library for generating realistic and diverse Power Flow (PF) and Optimal Power Flow (OPF) datasets for training Machine Learning (ML) solvers. Existing datasets and libraries face three main challenges: (1) lack of realistic stochastic load and topology perturbations, limiting scenario diversity; (2) PF datasets are restricted to OPF-feasible points, hindering generalization of ML solvers to cases that violate operating limits (e.g., branch overloads or voltage violations); and (3) OPF datasets use fixed generator cost functions, limiting generalization across varying costs. gridfm-datakit addresses these challenges by: (1) combining global load scaling from real-world profiles with localized noise and supporting arbitrary N-k topology perturbations to create diverse yet realistic datasets; (2) generating PF samples beyond operating limits; and (3) producing OPF data with varying generator costs. It also scales efficiently to large grids (up to 10,000 buses). Comparisons with OPFData, OPF-Learn, PGLearn, and PF$\Delta$ are provided. Available on GitHub at https://github.com/gridfm/gridfm-datakit under Apache 2.0 and via `pip install gridfm-datakit`.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14658v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alban Puech, Matteo Mazzonelli, Celia Cintas, Tamara R. Govindasamy, Mangaliso Mngomezulu, Jonas Weiss, Matteo Ba\`u, Anna Varbella, Fran\c{c}ois Mirall\`es, Kibaek Kim, Le Xie, Hendrik F. Hamann, Etienne Vos, Thomas Brunschwiler</dc:creator>
    </item>
    <item>
      <title>Bias-Variance Trade-off for Clipped Stochastic First-Order Methods: From Bounded Variance to Infinite Mean</title>
      <link>https://arxiv.org/abs/2512.14686</link>
      <description>arXiv:2512.14686v1 Announce Type: cross 
Abstract: Stochastic optimization is fundamental to modern machine learning. Recent research has extended the study of stochastic first-order methods (SFOMs) from light-tailed to heavy-tailed noise, which frequently arises in practice, with clipping emerging as a key technique for controlling heavy-tailed gradients. Extensive theoretical advances have further shown that the oracle complexity of SFOMs depends on the tail index $\alpha$ of the noise. Nonetheless, existing complexity results often cover only the case $\alpha \in (1,2]$, that is, the regime where the noise has a finite mean, while the complexity bounds tend to infinity as $\alpha$ approaches $1$. This paper tackles the general case of noise with tail index $\alpha\in(0,2]$, covering regimes ranging from noise with bounded variance to noise with an infinite mean, where the latter case has been scarcely studied. Through a novel analysis of the bias-variance trade-off in gradient clipping, we show that when a symmetry measure of the noise tail is controlled, clipped SFOMs achieve improved complexity guarantees in the presence of heavy-tailed noise for any tail index $\alpha \in (0,2]$. Our analysis of the bias-variance trade-off not only yields new unified complexity guarantees for clipped SFOMs across this full range of tail indices, but is also straightforward to apply and can be combined with classical analyses under light-tailed noise to establish oracle complexity guarantees under heavy-tailed noise. Finally, numerical experiments validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14686v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He</dc:creator>
    </item>
    <item>
      <title>Assortment Optimization under the Decision Forest Model</title>
      <link>https://arxiv.org/abs/2103.14067</link>
      <description>arXiv:2103.14067v4 Announce Type: replace 
Abstract: We study the problem of finding the optimal assortment that maximizes expected revenue under the decision forest model, a recently proposed nonparametric choice model that is capable of representing any discrete choice model and in particular, can be used to represent non-rational customer behavior. This problem is of practical importance because it allows a firm to tailor its product offerings to profitably exploit deviations from rational customer behavior, but at the same time is challenging due to the extremely general nature of the decision forest model. We approach this problem from a mixed-integer optimization perspective and present two different formulations. We theoretically compare the two formulations in strength, and analyze when they are integral in the special case of a single tree. We further propose a methodology for solving the two formulations at a large-scale based on Benders decomposition, and show that the Benders subproblem can be solved efficiently by primal-dual greedy algorithms when the master solution is fractional for one of the formulations, and in closed form when the master solution is binary for both formulations. Using synthetically generated instances, we demonstrate the practical tractability of our formulations and our Benders decomposition approach, and their edge over heuristic approaches. In a case study based on a real-world transaction data, we demonstrate that our proposed approach can factor the behavioral anomalies observed in consumer choice into assortment decision and create higher revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.14067v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi-Chun Akchen, Velibor V. Mi\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>Semidefinite network games: multiplayer minimax and complementarity problems</title>
      <link>https://arxiv.org/abs/2310.20333</link>
      <description>arXiv:2310.20333v2 Announce Type: replace 
Abstract: Network games provide a powerful framework for modeling agent interactions in networked systems, where players are represented by nodes in a graph and their payoffs depend on the actions taken by their neighbors. Extending the framework of network games, we introduce and study semidefinite network games. In this model, each player selects a positive semidefinite matrix with trace equal to one, known as a density matrix, to engage in a two-player game with every neighboring node. The player's payoff is the cumulative payoff acquired from these edge games. Initially, we focus on the zero-sum setting, where the sum of all players' payoffs is equal to zero. We establish that, in this class of games, Nash equilibria can be characterized as the projection of a spectrahedron. Furthermore, we show that determining whether a semidefinite network game is a zero-sum game is equivalent to deciding if the value of a semidefinite program is zero. Beyond the zero-sum case, we characterize Nash equilibria as the solutions of a semidefinite linear complementarity problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.20333v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Ickstadt, Thorsten Theobald, Elias Tsigaridas, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Optimal Control of a Sub-diffusion Model using Dirichlet-Neumann and Neumann-Neumann Waveform Relaxation Algorithms</title>
      <link>https://arxiv.org/abs/2404.13283</link>
      <description>arXiv:2404.13283v2 Announce Type: replace 
Abstract: This paper explores the convergence behavior of two waveform relaxation algorithms, namely the Dirichlet-Neumann and Neumann-Neumann Waveform Relaxation algorithms, for an optimal control problem with a sub-diffusion partial differential equation (PDE) constraint. The algorithms are tested on regular 1D domains with multiple subdomains, and the analysis focuses on how different constant values of the generalized diffusion coefficient affect the convergence of these algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13283v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Soura Sana, Bankim C. Mandal</dc:creator>
    </item>
    <item>
      <title>Flexible block-iterative analysis for the Frank-Wolfe algorithm</title>
      <link>https://arxiv.org/abs/2409.06931</link>
      <description>arXiv:2409.06931v3 Announce Type: replace 
Abstract: We prove that the block-coordinate Frank-Wolfe (BCFW) algorithm converges with state-of-the-art rates in both convex and nonconvex settings under a very mild "block-iterative" assumption. This appears to be the first result on BCFW addressing the setting of nonconvex objective functions with Lipschitz-continuous gradients and no additional assumptions. This analysis newly allows for (I) progress without activating the most-expensive linear minimization oracle(s), LMO(s), at every iteration, (II) parallelized updates that do not require all LMOs, and therefore (III) deterministic parallel update strategies that take into account the numerical cost of the problem's LMOs. Our results apply for short-step BCFW as well as an adaptive method for convex functions. New relationships between updated coordinates and primal progress are proven, and a favorable speedup is demonstrated using FrankWolfe.jl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06931v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G\'abor Braun, Jannis Halbey, Sebastian Pokutta, Zev Woodstock</dc:creator>
    </item>
    <item>
      <title>On uniqueness in structured model learning</title>
      <link>https://arxiv.org/abs/2410.22009</link>
      <description>arXiv:2410.22009v2 Announce Type: replace 
Abstract: This paper addresses the problem of uniqueness in learning physical laws for systems of partial differential equations (PDEs). Contrary to most existing approaches, it considers a framework of structured model learning, where existing, approximately correct physical models are augmented with components that are learned from data. The main result of the paper is a uniqueness result that covers a large class of PDEs and a suitable class of neural networks used for approximating the unknown model components. The uniqueness result shows that, in the idealized setting of full, noiseless measurements, a unique identification of the unknown model components is possible as regularization-minimizing solution of the PDE system. Furthermore, the paper provides a convergence result showing that model components learned on the basis of incomplete, noisy measurements approximate the regularization-minimizing solution of the PDE system in the limit. These results are possible under specific properties of the approximating neural networks and due to a dedicated choice of regularization. With this, a practical contribution of this analytic paper is to provide a class of model learning frameworks different to standard settings where uniqueness can be expected in the limit of full measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22009v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Holler, Erion Morina</dc:creator>
    </item>
    <item>
      <title>Integrated Wind Farm Design: Optimizing Turbine Placement and Cable Routing with Wake Effects</title>
      <link>https://arxiv.org/abs/2501.07203</link>
      <description>arXiv:2501.07203v2 Announce Type: replace 
Abstract: An accelerated deployment of renewable energy sources is crucial for a successful transformation of the current energy system, with wind energy playing a key role in this transition. This study addresses the integrated wind farm layout and cable routing problem, a challenging nonlinear optimization problem. We model this problem as an extended version of the quota Steiner tree problem (QSTP), optimizing turbine placement and network connectivity simultaneously to meet specified expansion targets. Our proposed approach accounts for the wake effect $-$ a region of reduced wind speed induced by each installed turbine $-$ and enforces minimum spacing between turbines. We introduce an exact solution framework in terms of the novel quota Steiner tree problem with interference (QSTPI). By leveraging an interference-based splitting strategy, we develop an advanced solver capable of tackling large-scale problem instances. The presented approach outperforms generic state-of-the-art mixed integer programming solvers on our dataset by up to two orders of magnitude. Further, we present a hop-constrained variant of the QSTPI to handle cable capacities in the context of radial topologies. Moreover, we demonstrate that our integrated method significantly reduces the costs in contrast to a sequential approach. Thus, we provide a planning tool that enhances existing planning methodologies for supporting a faster and cost-efficient expansion of wind energy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07203v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jaap Pedersen, Niels Lindner, Daniel Rehfeldt, Thorsten Koch</dc:creator>
    </item>
    <item>
      <title>High-precision linear minimization is no slower than projection</title>
      <link>https://arxiv.org/abs/2501.18454</link>
      <description>arXiv:2501.18454v4 Announce Type: replace 
Abstract: This note demonstrates that, for all compact convex sets, high-precision linear minimization can be performed via a single evaluation of the projection and a scalar-vector multiplication. In consequence, if $\varepsilon$-approximate linear minimization takes at least $L(\varepsilon)$ real vector-arithmetic operations and projection requires $P$ operations, then $\mathcal{O}(P)\geq \mathcal{O}(L(\varepsilon))$ is guaranteed. This concept is expounded with examples, an explicit error bound, and an exact linear minimization result for polyhedral sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18454v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zev Woodstock</dc:creator>
    </item>
    <item>
      <title>Proximal Gradient Descent Ascent Methods for Nonsmooth Nonconvex-Concave Minimax Problems on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2505.02140</link>
      <description>arXiv:2505.02140v2 Announce Type: replace 
Abstract: Nonsmooth nonconvex-concave minimax problems have attracted significant attention due to their wide applications in many fields. In this paper, we consider a class of nonsmooth nonconvex-concave minimax problems on Riemannian manifolds. Owing to the nonsmoothness of the objective function, existing minimax manifold optimization methods cannot be directly applied to solve this problem. We propose two manifold proximal gradient descent ascent (MPGDA) algorithms for solving the problem. The first algorithm alternatively performs one or multiple manifold proximal gradient descent steps and a proximal ascent step at each iteration, and we prove that it can find an $\varepsilon$-game-stationary point and an $\varepsilon$-optimization-stationary point within $\mathcal{O}(\varepsilon^{-3})$ outer iterations. The second algorithm alternatively performs one manifold proximal gradient descent step and a proximal gradient ascent step, and we show that it can reach an $\varepsilon$-game-stationary point and an $\varepsilon$-optimization-stationary point within $\mathcal{O}(\varepsilon^{-4})$ outer iterations. Numerical experiments on an analytic example, fair sparse PCA, and sparse spectral clustering are conducted to illustrate the advantages of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02140v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiyuan Xie, Qia Li</dc:creator>
    </item>
    <item>
      <title>The Monge optimal transport barycenter problem</title>
      <link>https://arxiv.org/abs/2507.03669</link>
      <description>arXiv:2507.03669v2 Announce Type: replace 
Abstract: A novel methodology is developed for the solution of the data-driven Monge optimal transport barycenter problem, where the pushforward condition is formulated in terms of the statistical independence between two sets of random variables: the factors $z$ and a transformed outcome $y$. Relaxing independence to the uncorrelation between all functions of $z$ and $y$ within suitable finite-dimensional spaces leads to an adversarial formulation, for which the adversarial strategy can be found in closed form through the first principal components of a small-dimensional matrix. The resulting pure minimization problem can be solved very efficiently through gradient descent driven flows in phase space. The methodology extends beyond scenarios where only discrete factors affect the outcome, to multivariate sets of both discrete and continuous factors, for which the corresponding barycenter problems have infinitely many marginals. Corollaries include a new framework for the solution of the Monge optimal transport problem, a procedure for the data-based simulation and estimation of conditional probability densities, and a nonparametric methodology for Bayesian inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03669v2</guid>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew D. Lipnick, Esteban G. Tabak, Giulio Trigila, Yating Wang, Xuancheng Ye, Wenjun Zhao</dc:creator>
    </item>
    <item>
      <title>Gradient descent avoids strict saddles with a simple line-search method too</title>
      <link>https://arxiv.org/abs/2507.13804</link>
      <description>arXiv:2507.13804v2 Announce Type: replace 
Abstract: It is known that gradient descent (GD) on a $C^2$ cost function generically avoids strict saddle points when using a small, constant step size. However, no such guarantee existed for GD with a line-search method. We provide one for a modified version of the standard Armijo backtracking method with generic, arbitrarily large initial step size. The proof underlines the double role of the Luzin $N^{-1}$ property for the iteration maps, and allows to forgo the habitual Lipschitz gradient assumption.
  We extend this to the Riemannian setting (RGD), assuming the retraction is real analytic (though the cost function still only needs to be $C^2$). In closing, we also improve guarantees for RGD with a constant step size in some scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13804v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreea-Alexandra Mu\c{s}at, Nicolas Boumal</dc:creator>
    </item>
    <item>
      <title>A constrained optimization approach to nonlinear system identification through simulation error minimization</title>
      <link>https://arxiv.org/abs/2509.01461</link>
      <description>arXiv:2509.01461v2 Announce Type: replace 
Abstract: This paper introduces a novel approach to system identification for nonlinear input-output models that minimizes the simulation error and frames the problem as a constrained optimization task. The proposed method addresses vanishing gradient issues, enabling faster convergence than traditional gradient-based techniques. We present an algorithm based on feedback linearization control of Lagrange multipliers and conduct a theoretical analysis of its performance. We prove that the algorithm converges to a local minimum, and it enhances computational efficiency by exploiting the problem's structure. Numerical experiments demonstrate that our approach outperforms gradient-based methods in both computational effort and estimation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01461v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vito Cerone, Sophie M. Fosson, Simone Pirrera, Diego Regruto</dc:creator>
    </item>
    <item>
      <title>Efficient Local and Tabu Search Strategies for Large-Scale Quadratic Integer Programming</title>
      <link>https://arxiv.org/abs/2409.14176</link>
      <description>arXiv:2409.14176v3 Announce Type: replace-cross 
Abstract: This study investigates the area of general quadratic integer programming (QIP), encompassing both unconstrained (UQIP) and constrained (CQIP) variants. These NP-hard problems have far-reaching applications, yet the non-convex cases have received limited attention in the literature. To address this gap, we introduce a closed-form formula for single-variable changes, establishing novel necessary and sufficient conditions for 1-Opt local improvement in UQIP and CQIP. We develop a simple local and sophisticated tabu search with an oscillation strategy tailored for large-scale problems. Experimental results on instances with up to 8000 variables demonstrate the efficiency of these strategies, producing high-quality solutions within a short time. Our approaches significantly outperform the Gurobi 11.0.2 solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14176v3</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Wang, Bahram Alidaee</dc:creator>
    </item>
    <item>
      <title>$\K$-Lorentzian and $\K$-CLC Polynomials in Stability Analysis</title>
      <link>https://arxiv.org/abs/2501.02375</link>
      <description>arXiv:2501.02375v2 Announce Type: replace-cross 
Abstract: We study the class of $\K$-Lorentzian polynomials, a generalization of the distinguished class of Lorentzian polynomials. As shown in \cite{GPlorentzian}, the set of $\K$-Lorentzian polynomials is equivalent to the set of $\K$-completely log-concave (aka $\K$-CLC) forms. Throughout this paper, we interchangeably use the terms $\K$-Lorentzian polynomials for the homogeneous setting and $\K$-CLC polynomials for the non-homogeneous setting. By introducing an alternative definition of $\K$-CLC polynomials through univariate restrictions, we establish that any strictly $\K$-CLC polynomial of degree $d \leq 4$ is Hurwitz-stable polynomial over $\K$. Additionally, we characterize the conditions under which a strictly $\K$-CLC of degree $d \geq 5$ is Hurwitz-stable over $\K$. Furthermore, we associate the largest possible proper cone, denoted by $\K(f,v)$, with a given $\K$-Lorentzian polynomial $f$ in the direction $v \in \inter \K$. Finally, we investigate applications of $\K$-CLC polynomials in the stability analysis of evolution variational inequalities (EVI) dynamical systems governed by differential equations and inequality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02375v2</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Papri Dey</dc:creator>
    </item>
    <item>
      <title>Small-time local controllability of a KdV system for all critical lengths</title>
      <link>https://arxiv.org/abs/2501.13640</link>
      <description>arXiv:2501.13640v2 Announce Type: replace-cross 
Abstract: In this paper, we consider the small-time local controllability problem for the KdV system on an interval with a Neumann boundary control. In 1997, Rosier discovered that the linearized system is uncontrollable if and only if the length is critical, namely $L=2\pi\sqrt{(k^2+ kl+ l^2)/3}$ for some integers $k$ and $l$.
  Coron and Cr\'epeau (2003) proved that the nonlinear system is small-time locally controllable even if the linearized system is not, provided that $k= l$ is the only solution pair. Later, Cerpa and Crepeau showed that the system is large-time locally controllable for all critical lengths. In 2020, Coron, Koenig, and Nguyen found that the system is not small-time locally controllable if $2k+l\not \in 3\mathbb{N}^*$.
  We demonstrate that if the critical length satisfies $2k+l \in 3\mathbb{N}^*$ with $k\neq l$, then the system is not small-time locally controllable. This paper, together with the above results, gives a complete answer to the longstanding open problem on the small-time local controllability of KdV on all critical lengths since the pioneer work by Rosier</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13640v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingrui Niu, Shengquan Xiang</dc:creator>
    </item>
    <item>
      <title>Optimal Sizing and Material Choice for Additively Manufactured Compact Plate Heat Exchangers</title>
      <link>https://arxiv.org/abs/2504.03372</link>
      <description>arXiv:2504.03372v2 Announce Type: replace-cross 
Abstract: Advances in additive manufacturing (AM) enable new opportunities to design compact heat exchangers (cHEXs) by leveraging flexible geometries to improve energy and material efficiency. However, it is well known that reducing size in counterflow cHEXs can degrade effectiveness due to axial heat conduction through the solid material, which depends strongly on material thermal conductivity and wall thickness. Understanding the interaction between fundamental heat transfer mechanisms and manufacturing constraints is essential for designing next generation compact thermal systems that fully exploit AM's shaping flexibility. This study investigates how material selection and AM thin wall limitations influence the maximum achievable power density in compact plate heat exchangers. An optimization framework evaluates six materials including plastic, austenitic steel, Al2O3, AlN, aluminum, and copper under fixed pressure drop and effectiveness, while accounting for AM specific thickness constraints and a minimum plate spacing to address fouling risks. Results show that copper consistently yields the lowest power density despite having the highest thermal conductivity, whereas plastic achieves the highest power density across most optimization scenarios. Without manufacturing or fouling constraints, plastic outperforms the baseline steel design by nearly three orders of magnitude. With uniform plate thickness or fouling constraints, the performance gap narrows, making plastic and austenitic steel comparable. When material specific thickness limits are applied, plastic again leads in compactness due to its superior thin wall manufacturability. These findings highlight that AM constraints strongly affect cHEX compactness and that lower conductivity materials can outperform metals such as copper in power dense heat exchanger designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03372v2</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehmet Basaran, Frederik Rogiers, Martine Baelmans, Maarten Blommaert</dc:creator>
    </item>
    <item>
      <title>The Phantom of Davis-Wielandt Shell: A Unified Framework for Graphical Stability Analysis of MIMO LTI Systems</title>
      <link>https://arxiv.org/abs/2507.19918</link>
      <description>arXiv:2507.19918v2 Announce Type: replace-cross 
Abstract: This paper presents a unified framework based on Davis-Wielandt (DW) shell for graphical stability analysis of multi-input and multi-output linear time-invariant feedback systems. Connections between DW shells and various graphical representations, as well as gain and phase measures, are established through an intuitive geometric perspective. Within this framework, we map the relationships and relative conservatism among various separation conditions. A rotated scaled relative graph ($\theta$-SRG) concept is proposed as a mixed gain-phase representation, from which a closed-loop stability criterion is derived and shown to be the least conservative among the existing 2-D graphical conditions for bi-component feedback loops. We also propose a reliable and generalizable algorithm for visualizing the $\theta$-SRGs and include a system example to demonstrate the reduced conservatism of the proposed condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19918v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.RA</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ding Zhang, Xiaokan Yang, Axel Ringh, Li Qiu</dc:creator>
    </item>
    <item>
      <title>Understanding Sampler Stochasticity in Training Diffusion Models for RLHF</title>
      <link>https://arxiv.org/abs/2510.10767</link>
      <description>arXiv:2510.10767v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning from Human Feedback (RLHF) is increasingly used to fine-tune diffusion models, but a key challenge arises from the mismatch between stochastic samplers used during training and deterministic samplers used during inference. In practice, models are fine-tuned using stochastic SDE samplers to encourage exploration, while inference typically relies on deterministic ODE samplers for efficiency and stability. This discrepancy induces a reward gap, raising concerns about whether high-quality outputs can be expected during inference. In this paper, we theoretically characterize this reward gap and provide non-vacuous bounds for general diffusion models, along with sharper convergence rates for Variance Exploding (VE) and Variance Preserving (VP) Gaussian models. Methodologically, we adopt the generalized denoising diffusion implicit models (gDDIM) framework to support arbitrarily high levels of stochasticity, preserving data marginals throughout. Empirically, our findings through large-scale experiments on text-to-image models using denoising diffusion policy optimization (DDPO) and mixed group relative policy optimization (MixGRPO) validate that reward gaps consistently narrow over training, and ODE sampling quality improves when models are updated using higher-stochasticity SDE training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10767v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayuan Sheng, Hanyang Zhao, Haoxian Chen, David D. Yao, Wenpin Tang</dc:creator>
    </item>
    <item>
      <title>Axial Symmetric Navier Stokes Equations and the Beltrami /anti Beltrami spectrum in view of Physics Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2512.08846</link>
      <description>arXiv:2512.08846v2 Announce Type: replace-cross 
Abstract: In this paper, I further continue an investigation on Beltrami Flows began in 2015 with A. Sorin and amply revised and developed in 2022 with M. Trigiante. Instead of a compact $3$-torus $T^3=\mathbb{R}^3/\Lambda$ where $\Lambda$ is a crystallographic lattice, as done in previous work, here I considered flows confined in a cylinder with identified opposite bases. In this topology I considered axial symmetric flows and found a complete basis of axial symmetric harmonic $1$-forms that, for each energy level, decomposes into six components: two Beltrami, two anti-Beltrami and two closed forms. These objects, that are written in terms of trigonometric and Bessel functions, constitute a function basis for an $L^2$ space of axial symmetric flows. I have presented a general scheme for the search of axial symmetric solutions of Navier Stokes equation by reducing the latter to an hierachy of quadratic relations on the development coefficients of the flow in the above described functional basis. It is proposed that the coefficients can be determined by means of a Physics Informed like Neural Network optimization recursive algorithm. Indeed the present paper provides the theoretical foundations for such a algorithmic construction that is planned for a future publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08846v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pietro Fr\'e</dc:creator>
    </item>
  </channel>
</rss>
