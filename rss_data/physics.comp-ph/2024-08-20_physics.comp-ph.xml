<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Aug 2024 01:48:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Application of mesh refinement to relativistic magnetic reconnection</title>
      <link>https://arxiv.org/abs/2408.08960</link>
      <description>arXiv:2408.08960v1 Announce Type: new 
Abstract: During relativistic magnetic reconnection, antiparallel magnetic fields undergo a rapid change in topology, releasing a large amount of energy in the form of non-thermal particle acceleration. This work explores the application of mesh refinement to 2D reconnection simulations to efficiently model the ineherent disparity in length-scales. We have systematically investigated the effects of mesh refinement and determined necessary modifications to the algorithm required to mitigate non-physical artifacts at the coarse-fine interface. We have used the ultrahigh-order Pseudo-Spectral Analytical Time-Domain (PSATD) Maxwell solver to analyze how its use can mitigate the numerical dispersion that occurs with the finite-difference time-domain (FDTD) (or ``Yee'') method. Absorbing layers are introduced at the coarse-fine interface to eliminate spurious effects that occur with mesh refinement. We also study how damping the electromagnetic fields and current density in the absorbing layer can help prevent the non-physical accumulation of charge and current density at the coarse-fine interface. Using a mesh refinement ratio of 8 for two-dimensional magnetic reconnection simulations, we obtained good agreement with the high resolution baseline simulation, using only 36% of the macroparticles and 71% of the node-hours needed for the baseline. The methods presented here are especially applicable to 3D systems where higher memory savings are expected than in 2D, enabling comprehensive, computationally efficient 3D reconnection studies in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08960v1</guid>
      <category>physics.comp-ph</category>
      <category>astro-ph.HE</category>
      <category>physics.plasm-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Revathi Jambunathan, Henry Jones, Lizzette Corrales, Hannah Klion, Michael Rowan, Andrew Myers, Weiqun Zhang, Jean-Luc Vay</dc:creator>
    </item>
    <item>
      <title>GSIS-ALE for moving boundary problems in rarefied gas flows</title>
      <link>https://arxiv.org/abs/2408.09316</link>
      <description>arXiv:2408.09316v1 Announce Type: new 
Abstract: Multiscale rarefied gas flows with moving boundaries pose significant challenges to the numerical simulation, where the primary difficulties involve robustly managing the mesh movement and ensuring computational efficiency across all flow regimes. Build upon recent advancements of the general synthetic iterative scheme (GSIS), this paper presents an efficient solver to simulate the large displacement of rigid-body in rarefied gas flows. The newly developed solver utilizes a dual time step method to solve the mesoscopic kinetic and macroscopic synthetic equations alternately, in an arbitrary Lagrangian-Eulerian framework. Additionally, the overset mesh is used and the six degree-of-freedom rigid body dynamics equation is integrated to track the motion of solids. Four moving boundary problems encompassing a wide range of flow velocities and gas rarefaction are simulated, including the periodic pitching of airfoil, particle motion in lid-driven cavity flow, two-body separation in supersonic flow, and three-dimensional lunar landing, demonstrating the accuracy and efficiency of the GSIS in handling multi-scale moving boundary problems within an overset framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09316v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianan Zeng, Yanbing Zhang, Lei Wu</dc:creator>
    </item>
    <item>
      <title>PhysBERT: A Text Embedding Model for Physics Scientific Literature</title>
      <link>https://arxiv.org/abs/2408.09574</link>
      <description>arXiv:2408.09574v1 Announce Type: new 
Abstract: The specialized language and complex concepts in physics pose significant challenges for information extraction through Natural Language Processing (NLP). Central to effective NLP applications is the text embedding model, which converts text into dense vector representations for efficient information retrieval and semantic analysis. In this work, we introduce PhysBERT, the first physics-specific text embedding model. Pre-trained on a curated corpus of 1.2 million arXiv physics papers and fine-tuned with supervised data, PhysBERT outperforms leading general-purpose models on physics-specific tasks including the effectiveness in fine-tuning for specific physics subdomains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09574v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thorsten Hellert, Jo\~ao Montenegro, Andrea Pollastro</dc:creator>
    </item>
    <item>
      <title>Towards a Field Based Bayesian Evidence Inference from Nested Sampling Data</title>
      <link>https://arxiv.org/abs/2408.09889</link>
      <description>arXiv:2408.09889v1 Announce Type: new 
Abstract: Nested sampling (NS) is a stochastic method for computing the log-evidence of a Bayesian problem. It relies on stochastic estimates of prior volumes enclosed by likelihood contours, which limits the accuracy of the log-evidence calculation. We propose to transform the prior volume estimation into a Bayesian inference problem, which allows us to incorporate a smoothness assumption for likelihood-prior volume relations. As a result, we aim to increase the accuracy of the volume estimates and thus improve the overall log-evidence calculation using NS. The method presented works as a post-processing step for NS and provides posterior samples of the likelihood-prior-volume relation, from which the log-evidence can be calculated. We demonstrate an implementation of the algorithm and compare its results with plain NS on two synthetic datasets for which the underlying evidence is known. We find a significant improvement in accuracy for runs with less than one hundred active samples in NS, but are prone to numerical problems beyond this point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09889v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Margret Westerkamp, Jakob Roth, Philipp Frank, Will Handley, Torsten En{\ss}lin</dc:creator>
    </item>
    <item>
      <title>Chaotic Dynamics in a Galactic Multipolar Halo with a Compact Primary</title>
      <link>https://arxiv.org/abs/2408.09011</link>
      <description>arXiv:2408.09011v1 Announce Type: cross 
Abstract: Observational evidence strongly supports the existence of a Super Massive Black Hole (SMBH) at the Galactic center, surrounded by dense stellar clusters. Modeling galactic centers with intricate structures like shells and rings pose challenges, prompting the use of simplified models such as a spherical monopole potential with a multipolar halo mass distribution. This approach, employing a multipolar expansion model, provides versatility for numerical analyses, revealing the complex dynamics of stars in this region. Pseudo-Potentials like Paczynsky-Wiita and Artemova-Bjornsson-Novikov are utilized to simulate the impacts of strong gravity from non-rotating and rotating compact objects respectively, elucidating their influence on stellar dynamics. Chaos naturally arises due to non-central forces, visualized using the Poincar\'e section technique. Of particular importance is the utilization of the Smaller Alignment Index (SALI), a powerful nonlinear dynamical tool, which categorizes particle orbits as escaping, regular, sticky, or chaotic. We exhaustively examine all combinations of multipolar moments up to the octupolar term along with spin using this tool, which had not been studied earlier. SALI provides a straightforward yet efficient method for assessing the interplay between the system's different multipolar moments, their combinations, and spin. Thus, our findings offer insights into the dynamics of compact objects enshrouded in a halo mass distribution and lay the groundwork for understanding complex astrophysical systems in galactic centers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09011v1</guid>
      <category>astro-ph.GA</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yeasin Ali, Suparna Roychowdhury</dc:creator>
    </item>
    <item>
      <title>Ambient air plasma acceleration in tightly-focused ultrashort infrared laser beams</title>
      <link>https://arxiv.org/abs/2408.09052</link>
      <description>arXiv:2408.09052v1 Announce Type: cross 
Abstract: Recent experimental and theoretical results have demonstrated the possibility of accelerating electrons in the MeV range by focusing tightly a few-cycle laser beam in ambient air. Using Particle-In-Cell (PIC) simulations, this configuration is revisited within a more accurate modelling approach to analyze and optimize the mechanism responsible for electron acceleration. In particular, an analytical model for a linearly polarized tightly-focused ultrashort laser field is derived and coupled to a PIC code, allowing us to model the interaction of laser beams reflected by high-numerical aperture mirrors with laser-induced plasmas. A set of 3D PIC simulations is performed where the laser wavelength is varied from 800 nm to 7.0 $\mu$m while the normalized amplitude of the electric field is varied from $a_{0} = 3.6$ to $a_{0} = 7.0$. The preferential forward acceleration of electrons, as well as the analysis of the laser intensity evolution in the plasma and data on electron number density, confirm that the relativistic ponderomotive force is responsible for the acceleration. We also demonstrate that the electron kinetic energy reaches a maximum of $\approx1.6$ MeV when the central wavelength is of 2.5 $\mu$m.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09052v1</guid>
      <category>physics.plasm-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marianna Lytova, Fran\c{c}ois Fillion-Gourdeau, Simon Valli\`eres, Sylvain Fourmaux, Fran\c{c}ois L\'egar\'e, Steve MacLean</dc:creator>
    </item>
    <item>
      <title>Modifications to Swisdak (2013)'s rejection sampling algorithm for a Maxwell-J\"{u}ttner distribution in particle simulations</title>
      <link>https://arxiv.org/abs/2408.09105</link>
      <description>arXiv:2408.09105v1 Announce Type: cross 
Abstract: Modifications to Swisdak [Phys. Plasmas 20, 062110 (2013)]'s rejection sampling algorithm for drawing a Maxwell-J\"{u}ttner distribution in particle simulations are presented. Handy approximations for $e$-folding points and a linear slope in the envelope function are proposed, to make the algorithm self-contained and more efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09105v1</guid>
      <category>physics.plasm-ph</category>
      <category>astro-ph.HE</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seiji Zenitani</dc:creator>
    </item>
    <item>
      <title>Understanding and mitigating noise in molecular quantum linear response for spectroscopic properties on quantum computers</title>
      <link>https://arxiv.org/abs/2408.09308</link>
      <description>arXiv:2408.09308v1 Announce Type: cross 
Abstract: The promise of quantum computing to circumvent the exponential scaling of quantum chemistry has sparked a race to develop chemistry algorithms for quantum architecture. However, most works neglect the quantum-inherent shot noise, let alone the effect of current noisy devices. Here, we present a comprehensive study of quantum linear response (qLR) theory obtaining spectroscopic properties on simulated fault-tolerant quantum computers and present-day near-term quantum hardware. This work introduces novel metrics to analyze and predict the origins of noise in the quantum algorithm, proposes an Ansatz-based error mitigation technique, and highlights the significant impact of Pauli saving in reducing measurement costs and noise. Our hardware results using up to cc-pVTZ basis set serve as proof-of-principle for obtaining absorption spectra on quantum hardware in a general approach with the accuracy of classical multi-configurational methods. Importantly, our results exemplify that substantial improvements in hardware error rates and measurement speed are necessary to lift quantum computational chemistry from proof-of-concept to an actual impact in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09308v1</guid>
      <category>quant-ph</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Karl Michael Ziems, Erik Rosendahl Kjellgren, Stephan P. A. Sauer, Jacob Kongsted, Sonia Coriani</dc:creator>
    </item>
    <item>
      <title>All-Electron Molecular Tunnel Ionization Based on the Weak-Field Asymptotic Theory in the Integral Representation</title>
      <link>https://arxiv.org/abs/2408.09372</link>
      <description>arXiv:2408.09372v1 Announce Type: cross 
Abstract: Tunnel ionization (TI) underlies many important ultrafast processes, such as high-harmonic generation and strong-field ionization. Among the existing theories for TI, many-electron weak-field asymptotic theory (ME-WFAT) is by design capable of accurately treating many-electron effects in TI. An earlier version of ME-WFAT relied on an accurate representation of the asymptotic tail of the orbitals, which hindered its implementation in Gaussian-basis-set-based quantum chemistry programs. In this work, we reformulate ME-WFAT in the integral representation, which makes the quality of the asymptotic tail much less critical, hence greatly facilitating its implementation in standard quantum chemistry packages. The integral reformulation introduced here is therefore much more robust when applied to molecules with arbitrary geometry. We present several case studies, among which is the CO molecule where some earlier theories disagree with experiments. Here, we find that ME-WFAT produces the largest ionization probability when the field points from C to O, as experiments suggest. An attractive feature of ME-WFAT is that it can be used with various types of multi-electron methods whether of density functional [Phys. Rev. A 106, 052211 (2022)] or multiconfiguration types, which facilitates tunnel ionization calculation in systems exhibiting a strong multireference character, such as transition-metal-containing molecules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09372v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.atm-clus</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Imam S. Wahyutama, Denawakage D. Jayasinghe, Francois Mauger, Kenneth Lopata, Kenneth J. Schafer</dc:creator>
    </item>
    <item>
      <title>Parameterized Physics-informed Neural Networks for Parameterized PDEs</title>
      <link>https://arxiv.org/abs/2408.09446</link>
      <description>arXiv:2408.09446v1 Announce Type: cross 
Abstract: Complex physical systems are often described by partial differential equations (PDEs) that depend on parameters such as the Reynolds number in fluid mechanics. In applications such as design optimization or uncertainty quantification, solutions of those PDEs need to be evaluated at numerous points in the parameter space. While physics-informed neural networks (PINNs) have emerged as a new strong competitor as a surrogate, their usage in this scenario remains underexplored due to the inherent need for repetitive and time-consuming training. In this paper, we address this problem by proposing a novel extension, parameterized physics-informed neural networks (P$^2$INNs). P$^2$INNs enable modeling the solutions of parameterized PDEs via explicitly encoding a latent representation of PDE parameters. With the extensive empirical evaluation, we demonstrate that P$^2$INNs outperform the baselines both in accuracy and parameter efficiency on benchmark 1D and 2D parameterized PDEs and are also effective in overcoming the known "failure modes".</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09446v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Woojin Cho, Minju Jo, Haksoo Lim, Kookjin Lee, Dongeun Lee, Sanghyun Hong, Noseong Park</dc:creator>
    </item>
    <item>
      <title>Deconvoluting Thermomechanical Effects in X-ray Diffraction Data using Machine Learning</title>
      <link>https://arxiv.org/abs/2408.09447</link>
      <description>arXiv:2408.09447v1 Announce Type: cross 
Abstract: X-ray diffraction is ideal for probing sub-surface state during complex or rapid thermomechanical loading of crystalline materials. However, challenges arise as the size of diffraction volumes increase due to spatial broadening and inability to deconvolute the effects of different lattice deformation mechanisms. Here we present a novel approach to use combinations of physics-based modeling and machine learning to deconvolve thermal and mechanical elastic strains for diffraction data analysis. The method builds on a previous effort to extract thermal strain distribution information from diffraction data. The new approach is applied to extract the evolution of thermomechanical state during laser melting of an Inconel 625 wall specimen which produces significant residual stress upon cooling. A combination of heat transfer and fluid flow, elasto-plasticity, and X-ray diffraction simulations are used to generate training data for machine-learning (Gaussian Process Regression, GPR) models that map diffracted intensity distributions to underlying thermomechanical strain fields. First-principles density functional theory is used to determine accurate temperature-dependent thermal expansion and elastic stiffness used in the elasto-plasticity modeling. The trained GPR models are found to be capable of deconvoluting the effects of thermal and mechanical strains, in addition to providing information about underlying strain distributions, even from complex diffraction patterns with irregularly shaped peaks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09447v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rachel E. Lim, Shun-Li Shang, Chihpin Chuang, Thien Q. Phan, Zi-Kui Liu, Darren C. Pagan</dc:creator>
    </item>
    <item>
      <title>Enhancing Quantum Memory Lifetime with Measurement-Free Local Error Correction and Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.09524</link>
      <description>arXiv:2408.09524v1 Announce Type: cross 
Abstract: Reliable quantum computation requires systematic identification and correction of errors that occur and accumulate in quantum hardware. To diagnose and correct such errors, standard quantum error-correcting protocols utilize $\textit{global}$ error information across the system obtained by mid-circuit readout of ancillary qubits. We investigate circuit-level error-correcting protocols that are measurement-free and based on $\textit{local}$ error information. Such a local error correction (LEC) circuit consists of faulty multi-qubit gates to perform both syndrome extraction and ancilla-controlled error removal. We develop and implement a reinforcement learning framework that takes a fixed set of faulty gates as inputs and outputs an optimized LEC circuit. To evaluate this approach, we quantitatively characterize an extension of logical qubit lifetime by a noisy LEC circuit. For the 2D classical Ising model and 4D toric code, our optimized LEC circuit performs better at extending a memory lifetime compared to a conventional LEC circuit based on Toom's rule in a sub-threshold gate error regime. We further show that such circuits can be used to reduce the rate of mid-circuit readouts to preserve a 2D toric code memory. Finally, we discuss the application of the LEC protocol on dissipative preparation of quantum states with topological phases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09524v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mincheol Park, Nishad Maskara, Marcin Kalinowski, Mikhail D. Lukin</dc:creator>
    </item>
    <item>
      <title>Giant magnetic anisotropy of Pb atoms in 3d-based magnets</title>
      <link>https://arxiv.org/abs/2408.09580</link>
      <description>arXiv:2408.09580v1 Announce Type: cross 
Abstract: Electronic structure analysis is performed to study the properties of several Pb-containing 3d-intermetallics. Our study reveals that binary metastable Co3Pb and Fe3Pb intermetallic compounds exhibit very attractive intrinsic magnetic properties. We primarily focus on the magnetic anisotropic properties arising from the high spin-orbit coupling of the Pb atom. Decomposing the total anisotropy into intra- and interatomic contributions reveals a significant deviation from single ion anisotropy model with strong symmetric anisotropic pair interactions present. Furthermore, we consider magnetic properties of ternary Pb-based 3d-intermetallics which recently have been reported as stable or metastable. Giant magnetic anisotropy is found on Pb atoms in these systems. The origin of such strong anisotropy in La18Co28Pb3 appears from two sources: spin-orbit and interelectronic Breit couplings. The significance of Breit interaction for magnetic anisotropy in bulk systems has not been reported previously. It is expected that Breit coupling induced anisotropy is dominating in magnetic Pb-based magnets with lower dimensionality including thin films.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09580v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiyi Xia, Cai-Zhuang Wang, Vladimir Antropov</dc:creator>
    </item>
    <item>
      <title>Machine Learning for the Physics of Climate</title>
      <link>https://arxiv.org/abs/2408.09627</link>
      <description>arXiv:2408.09627v1 Announce Type: cross 
Abstract: An exponential growth in computing power, which has brought more sophisticated and higher resolution simulations of the climate system, and an exponential increase in observations since the first weather satellite was put in orbit, are revolutionizing climate science. Big data and associated algorithms, coalesced under the field of Machine Learning (ML), offer the opportunity to study the physics of the climate system in ways, and with an amount of detail, infeasible few years ago. The inference provided by ML has allowed to ask causal questions and improve prediction skills beyond classical barriers. Furthermore, when paired with modeling experiments or robust research in model parameterizations, ML is accelerating computations, increasing accuracy and allowing for generating very large ensembles at a fraction of the cost. In light of the urgency imposed by climate change and the rapidly growing role of ML, we review its broader accomplishments in climate physics. Decades long standing problems in observational data reconstruction, representation of sub-grid scale phenomena and climate (and weather) prediction are being tackled with new and justified optimism. Ultimately, this review aims at providing a perspective on the benefits and major challenges of exploiting ML in studying complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09627v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annalisa Bracco, Julien Brajard, Henk A. Dijkstra, Pedram Hassanzadeh, Christian Lessig, Claire Monteleoni</dc:creator>
    </item>
    <item>
      <title>Propagating the prior from shallow to deep with a pre-trained velocity-model Generative Transformer network</title>
      <link>https://arxiv.org/abs/2408.09767</link>
      <description>arXiv:2408.09767v1 Announce Type: cross 
Abstract: Building subsurface velocity models is essential to our goals in utilizing seismic data for Earth discovery and exploration, as well as monitoring. With the dawn of machine learning, these velocity models (or, more precisely, their distribution) can be stored accurately and efficiently in a generative model. These stored velocity model distributions can be utilized to regularize or quantify uncertainties in inverse problems, like full waveform inversion. However, most generators, like normalizing flows or diffusion models, treat the image (velocity model) uniformly, disregarding spatial dependencies and resolution changes with respect to the observation locations. To address this weakness, we introduce VelocityGPT, a novel implementation that utilizes Transformer decoders trained autoregressively to generate a velocity model from shallow subsurface to deep. Owing to the fact that seismic data are often recorded on the Earth's surface, a top-down generator can utilize the inverted information in the shallow as guidance (prior) to generating the deep. To facilitate the implementation, we use an additional network to compress the velocity model. We also inject prior information, like well or structure (represented by a migration image) to generate the velocity model. Using synthetic data, we demonstrate the effectiveness of VelocityGPT as a promising approach in generative model applications for seismic velocity model building.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09767v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Randy Harsuko, Shijun Cheng, Tariq Alkhalifah</dc:creator>
    </item>
    <item>
      <title>Symplectic Neural Networks Based on Dynamical Systems</title>
      <link>https://arxiv.org/abs/2408.09821</link>
      <description>arXiv:2408.09821v1 Announce Type: cross 
Abstract: We present and analyze a framework for designing symplectic neural networks (SympNets) based on geometric integrators for Hamiltonian differential equations. The SympNets are universal approximators in the space of Hamiltonian diffeomorphisms, interpretable and have a non-vanishing gradient property. We also give a representation theory for linear systems, meaning the proposed P-SympNets can exactly parameterize any symplectic map corresponding to quadratic Hamiltonians. Extensive numerical tests demonstrate increased expressiveness and accuracy -- often several orders of magnitude better -- for lower training cost over existing architectures. Lastly, we show how to perform symbolic Hamiltonian regression with SympNets for polynomial systems using backward error analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09821v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin K Tapley</dc:creator>
    </item>
    <item>
      <title>Machine Learning with Physics Knowledge for Prediction: A Survey</title>
      <link>https://arxiv.org/abs/2408.09840</link>
      <description>arXiv:2408.09840v1 Announce Type: cross 
Abstract: This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09840v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joe Watson, Chen Song, Oliver Weeger, Theo Gruner, An T. Le, Kay Hansel, Ahmed Hendawy, Oleg Arenz, Will Trojak, Miles Cranmer, Carlo D'Eramo, Fabian B\"ulow, Tanmay Goyal, Jan Peters, Martin W. Hoffman</dc:creator>
    </item>
    <item>
      <title>Recent advancements in atomic many-body methods for high-precision studies of isotope shifts</title>
      <link>https://arxiv.org/abs/2408.09959</link>
      <description>arXiv:2408.09959v1 Announce Type: cross 
Abstract: The development of atomic many-body methods, capable of incorporating electron correlation effects accurately, is required for isotope shift (IS) studies. In combination with precise measurements, such calculations help to extract nuclear charge radii differences, and to probe for signatures of physics beyond the Standard Model of particle physics. We review here a few recently-developed methods in the relativistic many-body perturbation theory (RMBPT) and relativistic coupled-cluster (RCC) theory frameworks for calculations of IS factors in the highly charged ions (HCIs), and neutral or singly-charged ions, respectively. The results are presented for a wide range of atomic systems in order to demonstrate the interplay between quantum electrodynamics (QED) and electron correlation effects. In view of this, we start our discussions with the RMBPT calculations for a few HCIs by rigorously treating QED effects; then we outline methods to calculate IS factors in the one-valence atomic systems using two formulations of the RCC approach. Then we present calculations for two valence atomic systems, by employing the Fock-space RCC methods. For completeness, we briefly discuss theoretical input required for the upcoming experiments, their possibilities to probe nuclear properties and implications to fundamental physics studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09959v1</guid>
      <category>physics.atom-ph</category>
      <category>nucl-th</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. K. Sahoo, S. Blundell, A. V. Oleynichenko, R. F. Garcia Ruiz, L. V. Skripnikov, B. Ohayon</dc:creator>
    </item>
    <item>
      <title>KAN 2.0: Kolmogorov-Arnold Networks Meet Science</title>
      <link>https://arxiv.org/abs/2408.10205</link>
      <description>arXiv:2408.10205v1 Announce Type: cross 
Abstract: A major challenge of AI + Science lies in their inherent incompatibility: today's AI is primarily based on connectionism, while science depends on symbolism. To bridge the two worlds, we propose a framework to seamlessly synergize Kolmogorov-Arnold Networks (KANs) and science. The framework highlights KANs' usage for three aspects of scientific discovery: identifying relevant features, revealing modular structures, and discovering symbolic formulas. The synergy is bidirectional: science to KAN (incorporating scientific knowledge into KANs), and KAN to science (extracting scientific insights from KANs). We highlight major new functionalities in the pykan package: (1) MultKAN: KANs with multiplication nodes. (2) kanpiler: a KAN compiler that compiles symbolic formulas into KANs. (3) tree converter: convert KANs (or any neural networks) to tree graphs. Based on these tools, we demonstrate KANs' capability to discover various types of physical laws, including conserved quantities, Lagrangians, symmetries, and constitutive laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10205v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziming Liu, Pingchuan Ma, Yixuan Wang, Wojciech Matusik, Max Tegmark</dc:creator>
    </item>
    <item>
      <title>The Steepest Slope toward a Quantum Few-body Solution: Gradient Variational Methods for the Quantum Few-body Problem</title>
      <link>https://arxiv.org/abs/2408.08522</link>
      <description>arXiv:2408.08522v2 Announce Type: replace 
Abstract: Quantum few-body systems are deceptively simple. Indeed, with the notable exception of a few special cases, their associated Schrodinger equation cannot be solved analytically for more than two particles. One has to resort to approximation methods to tackle quantum few-body problems. In particular, variational methods have been proposed to ease numerical calculations and obtain precise solutions. One such method is the Stochastic Variational Method, which employs a stochastic search to determine the number and parameters of correlated Gaussian basis functions used to construct an ansatz of the wave function. Stochastic methods, however, face numerical and optimization challenges as the number of particles increases.
  We introduce a family of gradient variational methods that replace stochastic search with gradient optimization. We comparatively and empirically evaluate the performance of the baseline Stochastic Variational Method, several instances of the gradient variational method family, and some hybrid methods for selected few-body problems. We show that gradient and hybrid methods can be more efficient and effective than the Stochastic Variational Method. We discuss the role of singularities, oscillations, and gradient optimization strategies in the performance of the respective methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08522v2</guid>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Paolo Recchia, Debabrota Basu, Mario Gattobigio, Christian Miniatura, St\'ephane Bressan</dc:creator>
    </item>
    <item>
      <title>Balanced Binary Tree Schemes for Computing Zernike Radial Polynomials</title>
      <link>https://arxiv.org/abs/2212.02495</link>
      <description>arXiv:2212.02495v4 Announce Type: replace-cross 
Abstract: Zernike radial polynomials (ZRP) play a significant role in application areas such as optics design, imaging systems, and image processing systems. Currently, there are two kinds of numerical schemes for computing the ZRP automatically with computer programs: one is based on the definition in which the factorial operations may lead to the overflow problem and the high order derivatives are troublesome, and the other is based on recursion which is either unstable or with high computational complexity. In this paper, our emphasis is focused on exploring the balanced binary tree (BBT) schemes for computing the ZRP: firstly an elegant formulae for computation is established; secondly the recursive and iterative algorithms based-on BBT are proposed; thirdly the computational complexity of the algorithms are analyzed rigorously; finally the performance of BBT schemes by testing the running time is verified and validated. Theoretical analysis shows that the computational complexity of balanced binary tree recursive algorithm (BBRTA) and iterative algorithm are exponential and quadratic respectively, which coincides with the running time test very well. Experiments show that the time consumption is about $1\sim 10$ microseconds with different computation platforms for the balanced binary tree iterative algorithm (BBTIA), which is stable and efficient for real-time applications. In the sense of STEM education, the connection of the BBT and ZRP exhibits the beauty and applications of discrete mathematical structure behind the engineering problem, which is worthy of introducing to the college students, computer programmers and optics engineers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02495v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2023.3312717</arxiv:DOI>
      <arxiv:journal_reference>IEEE Access, 11(10):106567-106579, 2023</arxiv:journal_reference>
      <dc:creator>Hong-Yan Zhang, Yu Zhou, Zhi-Qiang Feng</dc:creator>
    </item>
    <item>
      <title>Systematic Analysis of Biomolecular Conformational Ensembles with PENSA</title>
      <link>https://arxiv.org/abs/2212.02714</link>
      <description>arXiv:2212.02714v2 Announce Type: replace-cross 
Abstract: Atomic-level simulations are widely used to study biomolecules and their dynamics. A common goal in such studies is to compare simulations of a molecular system under several conditions -- for example, with various mutations or bound ligands -- in order to identify differences between the molecular conformations adopted under these conditions. However, the large amount of data produced by simulations of ever larger and more complex systems often renders it difficult to identify the structural features that are relevant for a particular biochemical phenomenon. We present a flexible software package named PENSA that enables a comprehensive and thorough investigation into biomolecular conformational ensembles. It provides featurizations and feature transformations that allow for a complete representation of biomolecules like proteins and nucleic acids, including water and ion binding sites, thus avoiding bias that would come with manual feature selection. PENSA implements methods to systematically compare the distributions of molecular features across ensembles to find the significant differences between them and identify regions of interest. It also includes a novel approach to quantify the state-specific information between two regions of a biomolecule, which allows, e.g., tracing information flow to identify allosteric pathways. PENSA also comes with convenient tools for loading data and visualizing results, making them quick to process and easy to interpret. PENSA is an open-source Python library maintained at https://github.com/drorlab/pensa along with an example workflow and a tutorial. We demonstrate its usefulness in real-world examples by showing how it helps to determine molecular mechanisms efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02714v2</guid>
      <category>q-bio.BM</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin V\"ogele, Neil J. Thomson, Sang T. Truong, Jasper McAvity, Ulrich Zachariae, Ron O. Dror</dc:creator>
    </item>
    <item>
      <title>CosmoFlow: Python Package for Cosmological Correlators</title>
      <link>https://arxiv.org/abs/2402.03693</link>
      <description>arXiv:2402.03693v2 Announce Type: replace-cross 
Abstract: Cosmological correlators hold the key to high-energy physics as they probe the earliest moments of our Universe, and conceal hidden mathematical structures. However, even at tree-level, perturbative calculations are limited by technical difficulties absent in flatspace Feynman diagrammatics. In this paper, we introduce CosmoFlow: a new accurate open source Python code that computes tree-level cosmological correlators by tracing their time flow. This code is specifically designed to offer a simple, intuitive and flexible coding environment to theorists, primordial and late-time cosmologists. It can typically serve to complement analytical computations, to provide physical intuition when studying various inflationary theories, and to obtain exact results in regimes that are analytically out of reach. This paper presents the basic structure of CosmoFlow, leads the reader through an in-depth user-guide, and illustrates how it can be used with a series of worked examples. Our hope is that this first building block sets the stage for a bank of theoretical data, which can be nurtured and enhanced collaboratively by the community. CosmoFlow is publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03693v2</guid>
      <category>astro-ph.CO</category>
      <category>gr-qc</category>
      <category>hep-ph</category>
      <category>hep-th</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-6382/ad6740</arxiv:DOI>
      <arxiv:journal_reference>Class. Quantum Grav. 41 175015 (2024)</arxiv:journal_reference>
      <dc:creator>Denis Werth, Lucas Pinol, S\'ebastien Renaux-Petel</dc:creator>
    </item>
    <item>
      <title>Machine learning for climate physics and simulations</title>
      <link>https://arxiv.org/abs/2404.13227</link>
      <description>arXiv:2404.13227v2 Announce Type: replace-cross 
Abstract: We discuss the emerging advances and opportunities at the intersection of machine learning (ML) and climate physics, highlighting the use of ML techniques, including supervised, unsupervised, and equation discovery, to accelerate climate knowledge discoveries and simulations. We delineate two distinct yet complementary aspects: (1) ML for climate physics and (2) ML for climate simulations. While physics-free ML-based models, such as ML-based weather forecasting, have demonstrated success when data is abundant and stationary, the physics knowledge and interpretability of ML models become crucial in the small-data/non-stationary regime to ensure generalizability. Given the absence of observations, the long-term future climate falls into the small-data regime. Therefore, ML for climate physics holds a critical role in addressing the challenges of ML for climate simulations. We emphasize the need for collaboration among climate physics, ML theory, and numerical analysis to achieve reliable ML-based models for climate applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13227v2</guid>
      <category>physics.ao-ph</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <category>physics.geo-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ching-Yao Lai, Pedram Hassanzadeh, Aditi Sheshadri, Maike Sonnewald, Raffaele Ferrari, Venkatramani Balaji</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for an Efficient Normalizing Flow-Based Solution to the Electronic Schrodinger Equation</title>
      <link>https://arxiv.org/abs/2406.00047</link>
      <description>arXiv:2406.00047v2 Announce Type: replace-cross 
Abstract: A central problem in quantum mechanics involves solving the Electronic Schrodinger Equation for a molecule or material. The Variational Monte Carlo approach to this problem approximates a particular variational objective via sampling, and then optimizes this approximated objective over a chosen parameterized family of wavefunctions, known as the ansatz. Recently neural networks have been used as the ansatz, with accompanying success. However, sampling from such wavefunctions has required the use of a Markov Chain Monte Carlo approach, which is inherently inefficient. In this work, we propose a solution to this problem via an ansatz which is cheap to sample from, yet satisfies the requisite quantum mechanical properties. We prove that a normalizing flow using the following two essential ingredients satisfies our requirements: (a) a base distribution which is constructed from Determinantal Point Processes; (b) flow layers which are equivariant to a particular subgroup of the permutation group. We then show how to construct both continuous and discrete normalizing flows which satisfy the requisite equivariance. We further demonstrate the manner in which the non-smooth nature ("cusps") of the wavefunction may be captured, and how the framework may be generalized to provide induction across multiple molecules. The resulting theoretical framework entails an efficient approach to solving the Electronic Schrodinger Equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00047v2</guid>
      <category>physics.chem-ph</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Freedman, Eyal Rozenberg, Alex Bronstein</dc:creator>
    </item>
    <item>
      <title>Local divergence-free velocity interpolation for the immersed boundary method using composite B-splines</title>
      <link>https://arxiv.org/abs/2408.08280</link>
      <description>arXiv:2408.08280v2 Announce Type: replace-cross 
Abstract: This paper introduces an approach to improve volume conservation in the immersed boundary (IB) method using regularized delta functions derived from composite B-splines. These delta functions employ tensor product kernels using B-splines, whose polynomial degrees vary in normal and tangential directions based on the corresponding velocity component. Our method addresses the long-standing volume conservation issues in the conventional IB method, particularly evident in simulations of pressurized, closed membranes. We demonstrate that our approach significantly enhances volume conservation, rivaling the performance of the non-local Divergence-Free Immersed Boundary (DFIB) method introduced by Bao et al. while maintaining the local nature of the classical IB method. This avoids the computational overhead associated with the DFIB method's construction of an explicit velocity potential which requires additional Poisson solves. Numerical experiments show that sufficiently regular composite B-spline kernels can maintain initial volumes to within machine precision. We analyze the relationship between kernel regularity and the accuracy of force spreading and velocity interpolation operations. Our findings indicate that composite B-splines of at least $C^1$ regularity produce results comparable to the DFIB method in dynamic simulations, with volume conservation errors primarily dominated by the time-stepping scheme's truncation error. This work offers a computationally efficient alternative for improving volume conservation in IB methods, particularly beneficial for large-scale, three-dimensional simulations. The proposed approach requires minimal modifications to an existing IB code, making it an accessible improvement for a wide range of applications in computational fluid dynamics and fluid-structure interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08280v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cole Gruninger, Boyce E. Griffith</dc:creator>
    </item>
  </channel>
</rss>
