<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Apr 2024 19:06:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>MicroHD: An Accuracy-Driven Optimization of Hyperdimensional Computing Algorithms for TinyML systems</title>
      <link>https://arxiv.org/abs/2404.00039</link>
      <description>arXiv:2404.00039v1 Announce Type: new 
Abstract: Hyperdimensional computing (HDC) is emerging as a promising AI approach that can effectively target TinyML applications thanks to its lightweight computing and memory requirements. Previous works on HDC showed that limiting the standard 10k dimensions of the hyperdimensional space to much lower values is possible, reducing even more HDC resource requirements. Similarly, other studies demonstrated that binary values can be used as elements of the generated hypervectors, leading to significant efficiency gains at the cost of some degree of accuracy degradation. Nevertheless, current optimization attempts do not concurrently co-optimize HDC hyper-parameters, and accuracy degradation is not directly controlled, resulting in sub-optimal HDC models providing several applications with unacceptable output qualities. In this work, we propose MicroHD, a novel accuracy-driven HDC optimization approach that iteratively tunes HDC hyper-parameters, reducing memory and computing requirements while ensuring user-defined accuracy levels. The proposed method can be applied to HDC implementations using different encoding functions, demonstrates good scalability for larger HDC workloads, and achieves compression and efficiency gains up to 200x when compared to baseline implementations for accuracy degradations lower than 1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00039v1</guid>
      <category>cs.PF</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Flavio Ponzina, Tajana Rosing</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Scheduling of Multiple Parallelizable Job Classes</title>
      <link>https://arxiv.org/abs/2404.00346</link>
      <description>arXiv:2404.00346v1 Announce Type: new 
Abstract: Many modern computing workloads are composed of parallelizable jobs. A single parallelizable job can be completed more quickly if it is run on additional servers, however each job is typically limited in the number of servers it can run on (its parallelizability level). A job's parallelizability level is determined by the type of computation the job performs and how it was implemented. As a result, a single workload of parallelizable jobs generally consists of multiple $\textit{job classes}$, where jobs from different classes may have different parallelizability levels. The inherent sizes of jobs from different classes may also be vastly different.
  This paper considers the important, practical problem of how to schedule an arbitrary number of classes of parallelizable jobs. Here, each class of jobs has an associated job size distribution and parallelizability level. Given a limited number of servers, $k$, we ask how to allocate the $k$ servers across a stream of arriving jobs in order to minimize the $\textit{mean response time}$ -- the average time from when a job arrives to the system until it is completed.
  The problem of optimal scheduling in multiserver systems is known to be difficult, even when jobs are not parallelizable. To solve the harder problem of scheduling multiple classes of parallelizable jobs, we turn to asymptotic scaling regimes. We find that in lighter-load regimes (i.e., Sub-Halfin-Whitt), the optimal allocation algorithm is Least-Parallelizable-First (LPF), a policy that prioritizes jobs from the least parallelizable job classes. By contrast, we also find that in the heavier-load regimes (i.e., Super-NDS), the optimal allocation algorithm prioritizes the jobs with the Shortest Expected Remaining Processing Time (SERPT). We also develop scheduling policies that perform optimally when the scaling regime is not known to the system a priori.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00346v1</guid>
      <category>cs.PF</category>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Berg, Benjamin Moseley, Weina Wang, Mor Harchol-Balter</dc:creator>
    </item>
    <item>
      <title>Evaluatology: The Science and Engineering of Evaluation</title>
      <link>https://arxiv.org/abs/2404.00021</link>
      <description>arXiv:2404.00021v1 Announce Type: cross 
Abstract: Evaluation is a crucial aspect of human existence and plays a vital role in various fields. However, it is often approached in an empirical and ad-hoc manner, lacking consensus on universal concepts, terminologies, theories, and methodologies. This lack of agreement has significant repercussions. This article aims to formally introduce the discipline of evaluatology, which encompasses the science and engineering of evaluation. We propose a universal framework for evaluation, encompassing concepts, terminologies, theories, and methodologies that can be applied across various disciplines.
  Our research reveals that the essence of evaluation lies in conducting experiments that intentionally apply a well-defined evaluation condition to diverse subjects and infer the impact of different subjects by measuring and/or testing. Derived from the essence of evaluation, we propose five axioms focusing on key aspects of evaluation outcomes as the foundational evaluation theory. These axioms serve as the bedrock upon which we build universal evaluation theories and methodologies. When evaluating a single subject, it is crucial to create evaluation conditions with different levels of equivalency. By applying these conditions to diverse subjects, we can establish reference evaluation models. These models allow us to alter a single independent variable at a time while keeping all other variables as controls. When evaluating complex scenarios, the key lies in establishing a series of evaluation models that maintain transitivity. Building upon the science of evaluation, we propose a formal definition of a benchmark as a simplified and sampled evaluation condition that guarantees different levels of equivalency. This concept serves as the cornerstone for a universal benchmark-based engineering approach to evaluation across various disciplines, which we refer to as benchmarkology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00021v1</guid>
      <category>cs.HC</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jianfeng Zhan, Lei Wang, Wanling Gao, Hongxiao Li, Chenxi Wang, Yunyou Huang, Yatao Li, Zhengxin Yang, Guoxin Kang, Chunjie Luo, Hainan Ye, Shaopeng Dai, Zhifei Zhang</dc:creator>
    </item>
    <item>
      <title>Green AI: Exploring Carbon Footprints, Mitigation Strategies, and Trade Offs in Large Language Model Training</title>
      <link>https://arxiv.org/abs/2404.01157</link>
      <description>arXiv:2404.01157v1 Announce Type: cross 
Abstract: Prominent works in the field of Natural Language Processing have long attempted to create new innovative models by improving upon previous model training approaches, altering model architecture, and developing more in-depth datasets to better their performance. However, with the quickly advancing field of NLP comes increased greenhouse gas emissions, posing concerns over the environmental damage caused by training LLMs. Gaining a comprehensive understanding of the various costs, particularly those pertaining to environmental aspects, that are associated with artificial intelligence serves as the foundational basis for ensuring safe AI models. Currently, investigations into the CO2 emissions of AI models remain an emerging area of research, and as such, in this paper, we evaluate the CO2 emissions of well-known large language models, which have an especially high carbon footprint due to their significant amount of model parameters. We argue for the training of LLMs in a way that is responsible and sustainable by suggesting measures for reducing carbon emissions. Furthermore, we discuss how the choice of hardware affects CO2 emissions by contrasting the CO2 emissions during model training for two widely used GPUs. Based on our results, we present the benefits and drawbacks of our proposed solutions and make the argument for the possibility of training more environmentally safe AI models without sacrificing their robustness and performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01157v1</guid>
      <category>cs.CL</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivian Liu, Yiqiao Yin</dc:creator>
    </item>
    <item>
      <title>Age of Information in a Single-Source Generate-at-Will Dual-Server Status Update System</title>
      <link>https://arxiv.org/abs/2404.01229</link>
      <description>arXiv:2404.01229v1 Announce Type: cross 
Abstract: We study age of information (AoI) in a single-source dual-server status update system for the generate at will (GAW) scenario, consisting of an information source, dual servers, and a monitor. For this system, the method of stochastic hybrid systems (SHS) was used to obtain the mean AoI for the work-conserving ZW (zero wait) policy with out-of-order packet discarding at the monitor. In this paper, we propose a non-work-conserving F/P (freeze/preempt) policy for which the sampling and transmission process is frozen for an Erlang distributed amount of time upon each transmission, and out-of-order packets are preempted immediately at the source, rather than being discarded at the monitor upon reception. We use the absorbing Markov chain (AMC) method to obtain the exact distributions of AoI and also the peak AoI (PAoI) processes, for both ZW and F/P policies. Numerical results are presented for the validation of the proposed analytical model and a comparative evaluation of ZW and F/P policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01229v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nail Akar, Sennur Ulukus</dc:creator>
    </item>
  </channel>
</rss>
