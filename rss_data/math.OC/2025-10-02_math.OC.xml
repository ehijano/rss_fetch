<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DeMuon: A Decentralized Muon for Matrix Optimization over Graphs</title>
      <link>https://arxiv.org/abs/2510.01377</link>
      <description>arXiv:2510.01377v1 Announce Type: new 
Abstract: In this paper, we propose DeMuon, a method for decentralized matrix optimization over a given communication topology. DeMuon incorporates matrix orthogonalization via Newton-Schulz iterations-a technique inherited from its centralized predecessor, Muon-and employs gradient tracking to mitigate heterogeneity among local functions. Under heavy-tailed noise conditions and additional mild assumptions, we establish the iteration complexity of DeMuon for reaching an approximate stochastic stationary point. This complexity result matches the best-known complexity bounds of centralized algorithms in terms of dependence on the target tolerance. To the best of our knowledge, DeMuon is the first direct extension of Muon to decentralized optimization over graphs with provable complexity guarantees. We conduct preliminary numerical experiments on decentralized transformer pretraining over graphs with varying degrees of connectivity. Our numerical results demonstrate a clear margin of improvement of DeMuon over other popular decentralized algorithms across different network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01377v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Shuyi Ren, Jingwei Mao, Erik G. Larsson</dc:creator>
    </item>
    <item>
      <title>Optimal gas withdrawal strategy in reconstructed ring-type pipelines under unsteady flow conditions</title>
      <link>https://arxiv.org/abs/2510.01443</link>
      <description>arXiv:2510.01443v1 Announce Type: new 
Abstract: This paper presents an analytical and computational framework for optimizing gas withdrawal in reconstructed ring-type pipeline systems under unsteady flow conditions. As urban and industrial energy demands grow, repurposing existing pipeline infrastructure offers a cost-effective alternative to full-scale expansion. The proposed model identifies the hydraulic coupling point (where the pressure gradient vanishes) as the optimal location for connecting new consumers. By employing a one-dimensional unsteady gas flow model with time-dependent mass extraction represented via a Heaviside step function, the system's dynamic response is captured in detail. Numerical simulations demonstrate that connecting additional loads at the pressure maximum ensures stability while minimizing operational disruptions. The model's validation through benchmark comparison and pressure tolerance thresholds confirms its practical applicability. Economic analysis reveals substantial savings over conventional expansion methods. The approach provides a scalable solution for smart gas network design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01443v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Journal on Technical and Physical Problems of Engineering, Vol17, No3, Sep.,2025 Technical and Physical Problems of Engineering</arxiv:journal_reference>
      <dc:creator>I. G. Aliyev, A. M. Isayev, M. Z. Yusifov, A. J. Mammadov, A. S. Mammadov</dc:creator>
    </item>
    <item>
      <title>Optimization by Directional Attacks: Solving Problems with Neural Network Surrogates</title>
      <link>https://arxiv.org/abs/2510.01461</link>
      <description>arXiv:2510.01461v1 Announce Type: new 
Abstract: This paper tackles optimization problems whose objective and constraints involve a trained Neural Network (NN), where the goal is to maximize $f(\Phi(x))$ subject to $c(\Phi(x)) \leq 0$, with $f$ smooth, $c$ general and non-stringent, and $\Phi$ an already trained and possibly nonwhite-box NN. We address two challenges regarding this problem: identifying ascent directions for local search, and ensuring reliable convergence towards relevant local solutions. To this end, we re-purpose the notion of directional NN attacks as efficient optimization subroutines, since directional NN attacks use the neural structure of $\Phi$ to compute perturbations of $x$ that steer $\Phi(x)$ in prescribed directions. Precisely, we develop an attack operator that computes attacks of $\Phi$ at any $x$ along the direction $\nabla f(\Phi(x))$. Then, we propose a hybrid algorithm combining the attack operator with derivative-free optimization (DFO) techniques, designed for numerical reliability by remaining oblivious to the structure of the problem. We consider the cDSM algorithm, which offers asymptotic guarantees to converge to a local solution under mild assumptions on the problem. The resulting method alternates between attack-based steps for heuristic yet fast local intensification and cDSM steps for certified convergence and numerical reliability. Experiments on three problems show that this hybrid approach consistently outperforms standard DFO baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01461v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre-Yves Bouchet, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>A Sensitivity-Based Method for Bilevel Optimization Problems: Theoretical Analysis and Computational Performance</title>
      <link>https://arxiv.org/abs/2510.01487</link>
      <description>arXiv:2510.01487v1 Announce Type: new 
Abstract: Bilevel optimization provides a powerful framework for modeling hierarchical decision-making systems. This work presents a novel sensitivity-based algorithm that directly addresses the bilevel structure by treating the lower-level optimal solution as an implicit function of the upper-level variables, thus avoiding classical single-level reformulations. This implicit problem is solved within a robust Augmented Lagrangian framework, where the inner subproblems are managed by a quasi-Newton (L-BFGS-B) solver to handle the ill-conditioned and non-smooth landscapes that can arise. The validity of the proposed method is established through both theoretical convergence guarantees and extensive computational experiments. These experiments demonstrate the algorithm's efficiency and robustness and validate the use of a pragmatic dual-criterion stopping condition to address the practical challenge of asymmetric primal-dual convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01487v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Nolasco, Ross D. King, Vassilios S. Vassiliadis</dc:creator>
    </item>
    <item>
      <title>Exponential convergence of a distributed divide-and-conquer algorithm for constrained convex optimization on networks</title>
      <link>https://arxiv.org/abs/2510.01511</link>
      <description>arXiv:2510.01511v1 Announce Type: new 
Abstract: We propose a divide-and-conquer (DAC) algorithm for constrained convex optimization over networks, where the global objective is the sum of local objectives attached to individual agents. The algorithm is fully distributed: each iteration solves local subproblems around selected fusion centers and coordinates only with neighboring fusion centers. Under standard assumptions of smoothness, strong convexity, and locality on the objective function, together with polynomial growth conditions on the underlying graph, we establish exponential convergence of the DAC iterations and derive explicit bounds for both exact and inexact local solvers. Numerical experiments on three representative losses ($L_2$ distance, quadratic, and entropy) confirm the theory and demonstrate scalability and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01511v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nazar Emirov, Guohui Song, Qiyu Sun</dc:creator>
    </item>
    <item>
      <title>Tightness of SDP and Burer-Monteiro Factorization for Phase Synchronization in High-Noise Regime</title>
      <link>https://arxiv.org/abs/2510.01522</link>
      <description>arXiv:2510.01522v1 Announce Type: new 
Abstract: We study the difference between the maximum likelihood estimation (MLE) and its semi-definite programming (SDP) relaxation for the phase synchronization problem, where $n$ latent phases are estimated based on pairwise observations corrupted by Gaussian noise at a level $\sigma$. While previous studies have established that SDP coincides with the MLE when $\sigma \lesssim \sqrt{n / \log n}$, the behavior in the high-noise regime $\sigma \gtrsim \sqrt{n / \log n}$ remains unclear. We address this gap by quantifying the deviation between the SDP and the MLE in the high-noise regime as $\exp(-c \frac{n}{\sigma^2})$, indicating an exponentially small discrepancy. In fact, we establish more general results for the Burer-Monteiro (BM) factorization that covers the SDP as a special case: it has the exponentially small deviation from the MLE in the high-noise regime and coincides with the MLE when $\sigma$ is small. To obtain our results, we develop a refined entrywise analysis of the MLE that is beyond the existing $\ell_\infty$ analysis in literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01522v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anderson Ye Zhang</dc:creator>
    </item>
    <item>
      <title>On Error Bounds for Rank-Constrained Affine Matrix Sets</title>
      <link>https://arxiv.org/abs/2510.01709</link>
      <description>arXiv:2510.01709v1 Announce Type: new 
Abstract: Rank-constrained matrix problems appear frequently across science and engineering. The convergence analysis of iterative algorithms developed for these problems often hinges on local error bounds, which correlate the distance to the feasible set with a measure of how much the constraints are violated. Foundational results in semi-algebraic geometry guarantee that such bounds exist, yet the associated exponents are generally not explicitly determined. This paper establishes a local H\"olderian error bound with an explicit exponent for the canonical rank-constrained affine feasibility set. This paper proves that, on any compact set, the distance to the feasible set is bounded by a power of a natural residual function capturing violations in both the rank and affine constraints. The exponent in this bound is given explicitly in terms of the problem's dimensions. This provides a fundamental quantitative result on the geometry of the solution set, paving the way for the convergence analysis of a broad class of numerical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01709v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoning Chen, Defeng Sun, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>An extension of the mean value theorem</title>
      <link>https://arxiv.org/abs/2510.01726</link>
      <description>arXiv:2510.01726v1 Announce Type: new 
Abstract: Let ($\Omega$, $\mu$) be a measure space with $\Omega$ $\subset$ R d and $\mu$ a finite measure on $\Omega$. We provide an extension of the Mean Value Theorem (MVT) in the form  It is valid for non compact sets $\Omega$ and f is only required to be integrable with respect to $\mu$. It also contains as a special case the MVT in the form f d$\mu$ = $\mu$($\Omega$)f (x 0 ) for some x 0 $\in$ $\Omega$, valid for compact connected set $\Omega$ and continuous f . It is a direct consequence of Richter's theorem which in turn is a non trivial (overlooked) generalization of Tchakaloff's theorem, and even published earlier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01726v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean B Lasserre (LAAS-POP, TSE-R)</dc:creator>
    </item>
    <item>
      <title>Irrationality as a mean of regularization in Bayesian Persuasion</title>
      <link>https://arxiv.org/abs/2510.01759</link>
      <description>arXiv:2510.01759v1 Announce Type: new 
Abstract: We study a regularized variant of the Bayesian Persuasion problem, where the receiver's decision process includes a divergence-based penalty that accounts for deviations from perfect rationality. This modification smooths the underlying optimization landscape and mitigates key theoretical issues, such as measurability and ill-posedness, commonly encountered in the classical formulation. It also enables the use of scalable second-order optimization methods to compute numerically the optimal signaling scheme in a setting known to be NP-hard. We present theoretical results comparing the regularized and original models, including convergence guarantees and structural properties of optimal signaling schemes. Analytical examples and numerical simulations illustrate how this framework accommodates complex environments while remaining tractable and robust. A companion Python library, BASIL, makes use of all the practical insights from this article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01759v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romain Duboscq (IMT, INSA Toulouse), Fr\'ed\'eric de Gournay (IMT, INSA Toulouse)</dc:creator>
    </item>
    <item>
      <title>Robust MPC for Large-scale Linear Systems</title>
      <link>https://arxiv.org/abs/2510.01794</link>
      <description>arXiv:2510.01794v1 Announce Type: new 
Abstract: State-of-the-art approaches of Robust Model Predictive Control (MPC) are restricted to linear systems of relatively small scale, i.e., with no more than about 5 states. The main reason is the computational burden of determining a robust positively invariant (RPI) set, whose complexity suffers from the curse of dimensionality. The recently proposed approach of Deadbeat Robust Model Predictive Control (DRMPC) is the first that does not rely on an RPI set. Yet it comes with the full set of essential system theoretic guarantees. DRMPC is hence a viable option, in particular, for large-scale systems. This paper introduces a detailed design procedure for DRMPC. It is shown that the optimal control problem generated for DRMPC has exactly the same computational complexity as Nominal MPC. A numerical study validates its applicability to randomly generated large-scale linear systems of various dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01794v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg Schildbach</dc:creator>
    </item>
    <item>
      <title>Central Path Art</title>
      <link>https://arxiv.org/abs/2510.01933</link>
      <description>arXiv:2510.01933v1 Announce Type: new 
Abstract: The central path revolutionized the study of optimization in the 1980s and 1990s due to its favorable convergence properties, and as such, it has been investigated analytically, algorithmically, and computationally. Past pursuits have primarily focused on linking iterative approximation algorithms to the central path in the design of efficient algorithms to solve large, and sometimes novel, optimization problems. This algorithmic intent has meant that the central path has rarely been celebrated as an aesthetic entity in low dimensions, with the only meager exceptions being illustrative examples in textbooks. We undertake this low dimensional investigation and illustrate the artistic use of the central path to create aesthetic tilings and flower-like constructs in two and three dimensions, an endeavor that combines mathematical rigor and artistic sensibilities. The result is a fanciful and enticing collection of patterns that, beyond computer generated images, supports math-aesthetic designs for novelties and museum-quality pieces of art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01933v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thor Catteau, Benjamin Glancy, Allen Holder, Angela Milkowski, Alexa Renner, Connor Tasik, Rebecca Testa</dc:creator>
    </item>
    <item>
      <title>Smooth Quasar-Convex Optimization with Constraints</title>
      <link>https://arxiv.org/abs/2510.01943</link>
      <description>arXiv:2510.01943v1 Announce Type: new 
Abstract: Quasar-convex functions form a broad nonconvex class with applications to linear dynamical systems, generalized linear models, and Riemannian optimization, among others. Current nearly optimal algorithms work only in affine spaces due to the loss of one degree of freedom when working with general convex constraints. Obtaining an accelerated algorithm that makes nearly optimal $\widetilde{O}(1/(\gamma\sqrt{\epsilon}))$ first-order queries to a $\gamma$-quasar convex smooth function \emph{with constraints} was independently asked as an open problem in Mart\'inez-Rubio (2022); Lezane, Langer, and Koolen (2024). In this work, we solve this question by designing an inexact accelerated proximal point algorithm that we implement using a first-order method achieving the aforementioned rate and, as a consequence, we improve the complexity of the accelerated geodesically Riemannian optimization solution in Mart\'inez-Rubio (2022). We also analyze projected gradient descent and Frank-Wolfe algorithms in this constrained quasar-convex setting. To the best of our knowledge, our work provides the first analyses of first-order methods for quasar-convex smooth functions with general convex constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01943v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Mart\'inez-Rubio</dc:creator>
    </item>
    <item>
      <title>LLM-Enhanced, Data-Driven Personalized and Equitable Clinician Scheduling: A Predict-then-Optimize Approach</title>
      <link>https://arxiv.org/abs/2510.02047</link>
      <description>arXiv:2510.02047v1 Announce Type: new 
Abstract: Clinician scheduling remains a persistent challenge due to limited clinical resources and fluctuating demands. This complexity is especially acute in large academic anesthesiology departments as physicians balance responsibilities across multiple clinical sites with conflicting priorities. Further, scheduling must account for individual clinical and lifestyle preferences to ensure job satisfaction and well-being. Traditional approaches, often based on statistical or rule-based optimization models, rely on structured data and explicit domain knowledge. However, these methods often overlook unstructured information, e.g., free-text notes from routinely administered clinician well-being surveys and scheduling platforms. These notes may reveal implicit and underutilized clinical resources. Neglecting such information can lead to misaligned schedules, increased burnout, overlooked staffing flexibility, and suboptimal utilization of available resources. To address this gap, we propose a predict-then-optimize framework that integrates classification-based clinician availability predictions with a mixed-integer programming schedule optimization model. Large language models (LLMs) are employed to extract actionable preferences and implicit constraints from unstructured schedule notes, enhancing the reliability of availability predictions. These predictions then inform the schedule optimization considering four objectives: first, ensuring clinical full-time equivalent compliance, second, reducing workload imbalances by enforcing equitable proportions of shift types, third, maximizing clinician availability for assigned shifts, and fourth, schedule consistency. By combining the interpretive power of LLMs with the rigor of mathematical optimization, our framework provides a robust, data-driven solution that enhances operational efficiency while supporting equity and clinician well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02047v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anjali Jha, Wanqing Chen, Maxim Eckmann, Ian Stockwell, Jianwu Wang, Kai Sun</dc:creator>
    </item>
    <item>
      <title>Dynamic Random Bipartite Matching under Spatiotemporal Heterogeneity: General Models and Application to Mobility Services</title>
      <link>https://arxiv.org/abs/2510.02118</link>
      <description>arXiv:2510.02118v1 Announce Type: new 
Abstract: This paper explores a variant of bipartite matching problem, referred to as the Spatiotemporal Random Bipartite Matching Problem (ST-RBMP), that accommodates randomness and heterogeneity in the spatial distributions and temporal arrivals of bipartite vertices. This type of problem can be applied to many location-based services, such as shared mobility systems, where randomly arriving customers and vehicles must be matched dynamically. This paper proposes a new modeling framework to address ST-RBMP's challenges associated with the spatiotemporal heterogeneity, dynamics, and stochastic decision-making. The objective is to dynamically determine the optimal vehicle/customer pooling intervals and maximum matching radii that minimize the system-wide matching costs, including customer and vehicle waiting times and matching distances. Closed-form formulas for estimating the expected matching distances under a maximum matching radius are developed for static and homogeneous RBMPs, and then extended to accommodate spatial heterogeneity via continuum approximation. The ST-RBMP is then formulated as an optimal control problem where optimal values of pooling intervals and matching radii are solved over time and space. A series of experiments with simulated data are conducted to demonstrate that the proposed formulas for static RBMPs under matching radius and spatial heterogeneity yield very accurate results on estimating matching probabilities and distances. Additional numerical results are presented to demonstrate the effectiveness of the proposed ST-RBMP modeling framework in designing dynamic matching strategies for mobility services under various demand and supply patterns, which offers key managerial insights for mobility service operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02118v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiyu Shen, Yanfeng Ouyang</dc:creator>
    </item>
    <item>
      <title>On the (almost) Global Exponential Convergence of the Overparameterized Policy Optimization for the LQR Problem</title>
      <link>https://arxiv.org/abs/2510.02140</link>
      <description>arXiv:2510.02140v1 Announce Type: new 
Abstract: In this work we study the convergence of gradient methods for nonconvex optimization problems -- specifically the effect of the problem formulation to the convergence behavior of the solution of a gradient flow. We show through a simple example that, surprisingly, the gradient flow solution can be exponentially or asymptotically convergent, depending on how the problem is formulated. We then deepen the analysis and show that a policy optimization strategy for the continuous-time linear quadratic regulator (LQR) (which is known to present only asymptotic convergence globally) presents almost global exponential convergence if the problem is overparameterized through a linear feed-forward neural network (LFFNN). We prove this qualitative improvement always happens for a simplified version of the LQR problem and derive explicit convergence rates for the gradient flow. Finally, we show that both the qualitative improvement and the quantitative rate gains persist in the general LQR through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02140v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moh Kamalul Wafi, Arthur Castello B. de Oliveira, Eduardo D. Sontag</dc:creator>
    </item>
    <item>
      <title>Probabilistic Control Barrier Functions: Safety in Probability for Discrete-Time Stochastic Systems</title>
      <link>https://arxiv.org/abs/2510.01501</link>
      <description>arXiv:2510.01501v1 Announce Type: cross 
Abstract: Control systems operating in the real world face countless sources of unpredictable uncertainties. These random disturbances can render deterministic guarantees inapplicable and cause catastrophic safety failures. To overcome this, this paper proposes a method for designing safe controllers for discrete-time stochastic systems that retain probabilistic guarantees of safety. To do this we modify the traditional notion of a control barrier function (CBF) to explicitly account for these stochastic uncertainties and call these new modified functions probabilistic CBFs. We show that probabilistic CBFs can be used to design controllers that guarantee safety over a finite number of time steps with a prescribed probability. Next, by leveraging various uncertainty quantification methods, such as concentration inequalities, the scenario approach, and conformal prediction, we provide a variety of sufficient conditions that result in computationally tractable controllers with tunable probabilistic guarantees across a plethora of practical scenarios. Finally, we showcase the applicability of our results in simulation and hardware for the control of a quadruped robot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01501v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Blake Werner, Ryan K. Cosner, Aaron D. Ames</dc:creator>
    </item>
    <item>
      <title>On Integer Programming for the Binarized Neural Network Verification Problem</title>
      <link>https://arxiv.org/abs/2510.01525</link>
      <description>arXiv:2510.01525v1 Announce Type: cross 
Abstract: Binarized neural networks (BNNs) are feedforward neural networks with binary weights and activation functions. In the context of using a BNN for classification, the verification problem seeks to determine whether a small perturbation of a given input can lead it to be misclassified by the BNN, and the robustness of the BNN can be measured by solving the verification problem over multiple inputs. The BNN verification problem can be formulated as an integer programming (IP) problem. However, the natural IP formulation is often challenging to solve due to a large integrality gap induced by big-$M$ constraints. We present two techniques to improve the IP formulation. First, we introduce a new method for obtaining a linear objective for the multi-class setting. Second, we introduce a new technique for generating valid inequalities for the IP formulation that exploits the recursive structure of BNNs. We find that our techniques enable verifying BNNs against a higher range of input perturbation than existing IP approaches within a limited time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01525v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Woojin Kim, James R. Luedtke</dc:creator>
    </item>
    <item>
      <title>Data selection: at the interface of PDE-based inverse problem and randomized linear algebra</title>
      <link>https://arxiv.org/abs/2510.01567</link>
      <description>arXiv:2510.01567v1 Announce Type: cross 
Abstract: All inverse problems rely on data to recover unknown parameters, yet not all data are equally informative. This raises the central question of data selection. A distinctive challenge in PDE-based inverse problems is their inherently infinite-dimensional nature: both the parameter space and the design space are infinite, which greatly complicates the selection process. Somewhat unexpectedly, randomized numerical linear algebra (RNLA), originally developed in very different contexts, has provided powerful tools for addressing this challenge. These methods are inherently probabilistic, with guarantees typically stating that information is preserved with probability at least 1-p when using N randomly selected, weighted samples. Here, the notion of information can take different mathematical forms depending on the setting. In this review, we survey the problem of data selection in PDE-based inverse problems, emphasize its unique infinite-dimensional aspects, and highlight how RNLA strategies have been adapted and applied in this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01567v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kathrin Hellmuth, Ruhui Jin, Qin Li, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>NPN: Non-Linear Projections of the Null-Space for Imaging Inverse Problems</title>
      <link>https://arxiv.org/abs/2510.01608</link>
      <description>arXiv:2510.01608v1 Announce Type: cross 
Abstract: Imaging inverse problems aims to recover high-dimensional signals from undersampled, noisy measurements, a fundamentally ill-posed task with infinite solutions in the null-space of the sensing operator. To resolve this ambiguity, prior information is typically incorporated through handcrafted regularizers or learned models that constrain the solution space. However, these priors typically ignore the task-specific structure of that null-space. In this work, we propose \textit{Non-Linear Projections of the Null-Space} (NPN), a novel class of regularization that, instead of enforcing structural constraints in the image domain, promotes solutions that lie in a low-dimensional projection of the sensing matrix's null-space with a neural network. Our approach has two key advantages: (1) Interpretability: by focusing on the structure of the null-space, we design sensing-matrix-specific priors that capture information orthogonal to the signal components that are fundamentally blind to the sensing process. (2) Flexibility: NPN is adaptable to various inverse problems, compatible with existing reconstruction frameworks, and complementary to conventional image-domain priors. We provide theoretical guarantees on convergence and reconstruction accuracy when used within plug-and-play methods. Empirical results across diverse sensing matrices demonstrate that NPN priors consistently enhance reconstruction fidelity in various imaging inverse problems, such as compressive sensing, deblurring, super-resolution, computed tomography, and magnetic resonance imaging, with plug-and-play methods, unrolling networks, deep image prior, and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01608v1</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Jacome, Romario Gualdr\'on-Hurtado, Leon Suarez, Henry Arguello</dc:creator>
    </item>
    <item>
      <title>Improved $\ell_{p}$ Regression via Iteratively Reweighted Least Squares</title>
      <link>https://arxiv.org/abs/2510.01729</link>
      <description>arXiv:2510.01729v1 Announce Type: cross 
Abstract: We introduce fast algorithms for solving $\ell_{p}$ regression problems using the iteratively reweighted least squares (IRLS) method. Our approach achieves state-of-the-art iteration complexity, outperforming the IRLS algorithm by Adil-Peng-Sachdeva (NeurIPS 2019) and matching the theoretical bounds established by the complex algorithm of Adil-Kyng-Peng-Sachdeva (SODA 2019, J. ACM 2024) via a simpler lightweight iterative scheme. This bridges the existing gap between theoretical and practical algorithms for $\ell_{p}$ regression. Our algorithms depart from prior approaches, using a primal-dual framework, in which the update rule can be naturally derived from an invariant maintained for the dual objective. Empirically, we show that our algorithms significantly outperform both the IRLS algorithm by Adil-Peng-Sachdeva and MATLAB/CVX implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01729v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alina Ene, Ta Duy Nguyen, Adrian Vladu</dc:creator>
    </item>
    <item>
      <title>Learning Regularization Functionals for Inverse Problems: A Comparative Study</title>
      <link>https://arxiv.org/abs/2510.01755</link>
      <description>arXiv:2510.01755v1 Announce Type: cross 
Abstract: In recent years, a variety of learned regularization frameworks for solving inverse problems in imaging have emerged. These offer flexible modeling together with mathematical insights. The proposed methods differ in their architectural design and training strategies, making direct comparison challenging due to non-modular implementations. We address this gap by collecting and unifying the available code into a common framework. This unified view allows us to systematically compare the approaches and highlight their strengths and limitations, providing valuable insights into their future potential. We also provide concise descriptions of each method, complemented by practical guidelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01755v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Hertrich, Hok Shing Wong, Alexander Denker, Stanislas Ducotterd, Zhenghan Fang, Markus Haltmeier, \v{Z}eljko Kereta, Erich Kobler, Oscar Leong, Mohammad Sadegh Salehi, Carola-Bibiane Sch\"onlieb, Johannes Schwab, Zakhar Shumaylov, Jeremias Sulam, German Sh\^ama Wache, Martin Zach, Yasi Zhang, Matthias J. Ehrhardt, Sebastian Neumayer</dc:creator>
    </item>
    <item>
      <title>Exactly or Approximately Wasserstein Distributionally Robust Estimation According to Wasserstein Radii Being Small or Large</title>
      <link>https://arxiv.org/abs/2510.01763</link>
      <description>arXiv:2510.01763v1 Announce Type: cross 
Abstract: This paper primarily considers the robust estimation problem under Wasserstein distance constraints on the parameter and noise distributions in the linear measurement model with additive noise, which can be formulated as an infinite-dimensional nonconvex minimax problem. We prove that the existence of a saddle point for this problem is equivalent to that for a finite-dimensional minimax problem, and give a counterexample demonstrating that the saddle point may not exist. Motivated by this observation, we present a verifiable necessary and sufficient condition whose parameters can be derived from a convex problem and its dual. Additionally, we also introduce a simplified sufficient condition, which intuitively indicates that when the Wasserstein radii are small enough, the saddle point always exists. In the absence of the saddle point, we solve an finite-dimensional nonconvex minimax problem, obtained by restricting the estimator to be linear. Its optimal value establishes an upper bound on the robust estimation problem, while its optimal solution yields a robust linear estimator. Numerical experiments are also provided to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01763v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Ding, Enbin Song, Dunbiao Niu, Zhujun Cao, Qingjiang Shi</dc:creator>
    </item>
    <item>
      <title>A Linear Programming Approach to Estimate the Core in Cooperative Games</title>
      <link>https://arxiv.org/abs/2510.01766</link>
      <description>arXiv:2510.01766v1 Announce Type: cross 
Abstract: This paper proposes a novel algorithm to approximate the core of transferable utility (TU) cooperative games via linear programming. Given the computational hardness of determining the full core, our approach provides a tractable approximation by sampling extreme points through randomized linear problems (LPs). We analyze its convergence and computational complexity, and validate its effectiveness through extensive simulations on various game models. Our results show that the method is scalable and achieves high accuracy in terms of core reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01766v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J Camacho, JC Gon\c{c}alves-Dosantos, J S\'anchez-Soriano</dc:creator>
    </item>
    <item>
      <title>Lower Bounds on Adversarial Robustness for Multiclass Classification with General Loss Functions</title>
      <link>https://arxiv.org/abs/2510.01969</link>
      <description>arXiv:2510.01969v1 Announce Type: cross 
Abstract: We consider adversarially robust classification in a multiclass setting under arbitrary loss functions and derive dual and barycentric reformulations of the corresponding learner-agnostic robust risk minimization problem. We provide explicit characterizations for important cases such as the cross-entropy loss, loss functions with a power form, and the quadratic loss, extending in this way available results for the 0-1 loss. These reformulations enable efficient computation of sharp lower bounds for adversarial risks and facilitate the design of robust classifiers beyond the 0-1 loss setting. Our paper uncovers interesting connections between adversarial robustness, $\alpha$-fair packing problems, and generalized barycenter problems for arbitrary positive measures where Kullback-Leibler and Tsallis entropies are used as penalties. Our theoretical results are accompanied with illustrative numerical experiments where we obtain tighter lower bounds for adversarial risks with the cross-entropy loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01969v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Camilo Andr\'es Garc\'ia Trillos, Nicol\'as Garc\'ia Trillos</dc:creator>
    </item>
    <item>
      <title>Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation</title>
      <link>https://arxiv.org/abs/2510.01986</link>
      <description>arXiv:2510.01986v1 Announce Type: cross 
Abstract: Driving simulators are increasingly used in research and development. However, simulators often cause motion sickness due to downscaled motion and unscaled veridical visuals. In this paper, a motion cueing algorithm is proposed that reduces motion sickness as predicted by the subjective vertical conflict (SVC) model using model predictive control (MPC). Both sensory conflict and specific force errors are penalised in the cost function, allowing the algorithm to jointly optimise fidelity and comfort.
  Human-in-the-loop experiments were conducted to compare four simulator motion settings: two variations of our MPC-based algorithm, one focused on pure specific force tracking and the second compromising specific force tracking and motion sickness minimisation, as well as reference adaptive washout and no motion cases. The experiments were performed on a hexapod driving simulator with participants exposed to passive driving.
  Experimental motion sickness results closely matched the sickness model predictions. As predicted by the model, the no motion condition yielded the lowest sickness levels. However, it was rated lowest in terms of fidelity. The compromise solution reduced sickness by over 50% (average MISC level 3 to 1.5) compared to adaptive washout and the algorithm focusing on specific force tracking, without any significant reduction in fidelity rating.
  The proposed approach for developing MCA that takes into account both the simulator dynamics and time evolution of motion sickness offers a significant advancement in achieving an optimal control of motion sickness and specific force recreation in driving simulators, supporting broader simulator use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01986v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Varun Kotian, Vishrut Jain, Andrea Michelle Rios Lazcano, Daan Marinus Pool, Riender Happee, Barys Shyrokau</dc:creator>
    </item>
    <item>
      <title>Universal vector and matrix optimal transport</title>
      <link>https://arxiv.org/abs/2510.02039</link>
      <description>arXiv:2510.02039v1 Announce Type: cross 
Abstract: In this paper we propose a gauge-theoretic approach to the problems of optimal mass transport for vector and matrix densities. This resolves both the issues of positivity and action transitivity constraints. Bures-type metrics on the corresponding semi-direct product groups of diffeomorphisms and gauge transformations are related to Wasserstein-type metrics on vector half-densities and matrix densities via Riemannian submersions. We also describe their relation to Poisson geometry and demonstrate how the momentum map allows one to prove the Riemannian submersion properties. The obtained geodesic equations turn out to be vector versions of the Burgers equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02039v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris Khesin, Klas Modin</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning with Action-Triggered Observations</title>
      <link>https://arxiv.org/abs/2510.02149</link>
      <description>arXiv:2510.02149v1 Announce Type: cross 
Abstract: We study reinforcement learning problems where state observations are stochastically triggered by actions, a constraint common in many real-world applications. This framework is formulated as Action-Triggered Sporadically Traceable Markov Decision Processes (ATST-MDPs), where each action has a specified probability of triggering a state observation. We derive tailored Bellman optimality equations for this framework and introduce the action-sequence learning paradigm in which agents commit to executing a sequence of actions until the next observation arrives. Under the linear MDP assumption, value-functions are shown to admit linear representations in an induced action-sequence feature map. Leveraging this structure, we propose off-policy estimators with statistical error guarantees for such feature maps and introduce ST-LSVI-UCB, a variant of LSVI-UCB adapted for action-triggered settings. ST-LSVI-UCB achieves regret $\widetilde O(\sqrt{Kd^3(1-\gamma)^{-3}})$, where $K$ is the number of episodes, $d$ the feature dimension, and $\gamma$ the discount factor (per-step episode non-termination probability). Crucially, this work establishes the theoretical foundation for learning with sporadic, action-triggered observations while demonstrating that efficient learning remains feasible under such observation constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02149v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Ryabchenko, Wenlong Mou</dc:creator>
    </item>
    <item>
      <title>Flatness-Aware Stochastic Gradient Langevin Dynamics</title>
      <link>https://arxiv.org/abs/2510.02174</link>
      <description>arXiv:2510.02174v1 Announce Type: cross 
Abstract: Generalization in deep learning is closely tied to the pursuit of flat minima in the loss landscape, yet classical Stochastic Gradient Langevin Dynamics (SGLD) offers no mechanism to bias its dynamics toward such low-curvature solutions. This work introduces Flatness-Aware Stochastic Gradient Langevin Dynamics (fSGLD), designed to efficiently and provably seek flat minima in high-dimensional nonconvex optimization problems. At each iteration, fSGLD uses the stochastic gradient evaluated at parameters perturbed by isotropic Gaussian noise, commonly referred to as Random Weight Perturbation (RWP), thereby optimizing a randomized-smoothing objective that implicitly captures curvature information. Leveraging these properties, we prove that the invariant measure of fSGLD stays close to a stationary measure concentrated on the global minimizers of a loss function regularized by the Hessian trace whenever the inverse temperature and the scale of random weight perturbation are properly coupled. This result provides a rigorous theoretical explanation for the benefits of random weight perturbation. In particular, we establish non-asymptotic convergence guarantees in Wasserstein distance with the best known rate and derive an excess-risk bound for the Hessian-trace regularized objective. Extensive experiments on noisy-label and large-scale vision tasks, in both training-from-scratch and fine-tuning settings, demonstrate that fSGLD achieves superior or comparable generalization and robustness to baseline algorithms while maintaining the computational cost of SGD, about half that of SAM. Hessian-spectrum analysis further confirms that fSGLD converges to significantly flatter minima.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02174v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Bruno, Youngsik Hwang, Jaehyeon An, Sotirios Sabanis, Dong-Young Lim</dc:creator>
    </item>
    <item>
      <title>Computing Control Lyapunov-Barrier Functions: Softmax Relaxation and Smooth Patching with Formal Guarantees</title>
      <link>https://arxiv.org/abs/2510.02223</link>
      <description>arXiv:2510.02223v1 Announce Type: cross 
Abstract: We present a computational framework for synthesizing a single smooth Lyapunov function that certifies both asymptotic stability and safety. We show that the existence of a strictly compatible pair of control barrier and control Lyapunov functions (CBF-CLF) guarantees the existence of such a function on the exact safe set certified by the barrier. To maximize the certifiable safe domain while retaining differentiability, we employ a log-sum-exp (softmax) relaxation of the nonsmooth maximum barrier, together with a counterexample-guided refinement that inserts half-space cuts until a strict barrier condition is verifiable. We then patch the softmax barrier with a CLF via an explicit smooth bump construction, which is always feasible under the strict compatibility condition. All conditions are formally verified using a satisfiability modulo theories (SMT) solver, enabled by a reformulation of Farkas' lemma for encoding strict compatibility. On benchmark systems, including a power converter, we show that the certified safe stabilization regions obtained with the proposed approach are often less conservative than those achieved by state-of-the-art sum-of-squares (SOS) compatible CBF-CLF designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02223v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Liu, Maxwell Fitzsimmons</dc:creator>
    </item>
    <item>
      <title>Drop-Muon: Update Less, Converge Faster</title>
      <link>https://arxiv.org/abs/2510.02239</link>
      <description>arXiv:2510.02239v1 Announce Type: cross 
Abstract: Conventional wisdom in deep learning optimization dictates updating all layers at every step-a principle followed by all recent state-of-the-art optimizers such as Muon. In this work, we challenge this assumption, showing that full-network updates can be fundamentally suboptimal, both in theory and in practice. We introduce a non-Euclidean Randomized Progressive Training method-Drop-Muon-a simple yet powerful framework that updates only a subset of layers per step according to a randomized schedule, combining the efficiency of progressive training with layer-specific non-Euclidean updates for top-tier performance. We provide rigorous convergence guarantees under both layer-wise smoothness and layer-wise $(L^0, L^1)$-smoothness, covering deterministic and stochastic gradient settings, marking the first such results for progressive training in the stochastic and non-smooth regime. Our cost analysis further reveals that full-network updates are not optimal unless a very specific relationship between layer smoothness constants holds. Through controlled CNN experiments, we empirically demonstrate that Drop-Muon consistently outperforms full-network Muon, achieving the same accuracy up to $1.4\times$ faster in wall-clock time. Together, our results suggest a shift in how large-scale models can be efficiently trained, challenging the status quo and offering a highly efficient, theoretically grounded alternative to full-network updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02239v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kaja Gruntkowska, Yassine Maziane, Zheng Qu, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>A Novel State-Centric Necessary Condition for Time-Optimal Control of Controllable Linear Systems Based on Augmented Switching Laws (Extended Version)</title>
      <link>https://arxiv.org/abs/2404.08943</link>
      <description>arXiv:2404.08943v3 Announce Type: replace 
Abstract: Most existing necessary conditions for optimal control based on adjoining methods require both state and costate information, yet the unobservability of costates for a given feasible trajectory impedes the determination of optimality in practice. This paper establishes a novel theoretical framework for time-optimal control of controllable linear systems with a single input, proposing the augmented switching law (ASL) that represents the input control and the feasibility in a compact form. Given a feasible trajectory, the perturbed trajectory under the constraints of ASL is guaranteed to be feasible, resulting in a novel state-centric necessary condition without dependence on costate information. A first-order necessary condition is proposed that the Jacobian matrix of the ASL is not of full row rank, which also results in a potential approach to optimizing a given feasible trajectory with the preservation of arc structures. The proposed necessary condition is applied to high-order chain-of-integrator systems with full box constraints, contributing to some theoretical results challenging to reason by costate-based conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08943v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunan Wang, Chuxiong Hu, Yujie Lin, Zeyang Li, Shize Lin, Suqin He</dc:creator>
    </item>
    <item>
      <title>R2 v2: The Pareto-compliant R2 Indicator for Better Benchmarking in Bi-objective Optimization</title>
      <link>https://arxiv.org/abs/2407.01504</link>
      <description>arXiv:2407.01504v2 Announce Type: replace 
Abstract: In multi-objective optimization, set-based quality indicators are a cornerstone of benchmarking and performance assessment. They capture the quality of a set of trade-off solutions by reducing it to a scalar number. One of the most commonly used set-based metrics is the R2 indicator, which describes the expected utility of a solution set to a decision-maker under a distribution of utility functions. Typically, this indicator is applied by discretizing the latter distribution, yielding a weakly Pareto-compliant indicator. In consequence, adding a nondominated or dominating solution to a solution set may -- but does not have to -- improve the indicator's value.
  In this paper, we reinvestigate the R2 indicator under the premise that we have a continuous, uniform distribution of (Tchebycheff) utility functions. We analyze its properties in detail, demonstrating that this continuous variant is indeed Pareto-compliant -- that is, any beneficial solution will improve the metric's value. Additionally, we provide efficient computational procedures that (a) compute this metric for bi-objective problems in $\mathcal O (N \log N)$, and (b) can perform incremental updates to the indicator whenever solutions are added to (or removed from) the current set of solutions, without needing to recompute the indicator for the entire set. As a result, this work contributes to the state-of-the-art Pareto-compliant unary performance metrics, such as the hypervolume indicator, offering an efficient and promising alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01504v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lennart Sch\"apermeier, Pascal Kerschke</dc:creator>
    </item>
    <item>
      <title>Adaptive Gradient Normalization and Independent Sampling for (Stochastic) Generalized-Smooth Optimization</title>
      <link>https://arxiv.org/abs/2410.14054</link>
      <description>arXiv:2410.14054v4 Announce Type: replace 
Abstract: Recent studies have shown that many nonconvex machine learning problems satisfy a generalized-smooth condition that extends beyond traditional smooth nonconvex optimization. However, the existing algorithms are not fully adapted to such generalized-smooth nonconvex geometry and encounter significant technical limitations on their convergence analysis. In this work, we first analyze the convergence of adaptively normalized gradient descent under function geometries characterized by generalized-smoothness and generalized P{\L} condition, revealing the advantage of adaptive gradient normalization. Our results provide theoretical insights into adaptive normalization across various scenarios.For stochastic generalized-smooth nonconvex optimization, we propose \textbf{I}ndependent-\textbf{A}daptively \textbf{N}ormalized \textbf{S}tochastic \textbf{G}radient \textbf{D}escent algorithm, which leverages adaptive gradient normalization, independent sampling, and gradient clipping to achieve an $\mathcal{O}(\epsilon^{-4})$ sample complexity under relaxed noise assumptions. Experiments on large-scale nonconvex generalized-smooth problems demonstrate the fast convergence of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14054v4</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research (TMLR), 07/2025</arxiv:journal_reference>
      <dc:creator>Yufeng Yang, Erin Tripp, Yifan Sun, Shaofeng Zou, Yi Zhou</dc:creator>
    </item>
    <item>
      <title>A Three-Operator Splitting Scheme Derived from Three-Block ADMM</title>
      <link>https://arxiv.org/abs/2411.00166</link>
      <description>arXiv:2411.00166v3 Announce Type: replace 
Abstract: This work presents a new three-operator splitting method to handle monotone inclusion and convex optimization problems. The proposed splitting serves as another natural extension of the Douglas-Rachford splitting technique to problems involving three operators. For solving a composite convex minimization of a sum of three functions, its formula resembles but is different from Davis-Yin splitting and the dual formulation of the classical three-block ADMM. Numerical tests suggest that such a splitting scheme is robust in the sense of allowing larger step sizes. When two functions have orthogonal domains, the splitting operator can be proven 1/2-averaged, which implies convergence of the iteration scheme using any positive step size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00166v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anshika Anshika, Jiaxing Li, Debdas Ghosh, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Robust Capacity Expansion Modelling for Renewable Energy Systems</title>
      <link>https://arxiv.org/abs/2504.06750</link>
      <description>arXiv:2504.06750v3 Announce Type: replace 
Abstract: Future greenhouse gas neutral energy systems will be dominated by renewable energy technologies whose energy output and utilisation is subject to uncertain weather conditions. This work proposes an algorithm for capacity expansion planning if only uncertain data is available for a year's operative parameters. When faced with multiple possible operating years, the quality of a solution derived on a single operating year's data is evaluated for all years, and the optimisation problem is iteratively modified whenever supply gaps are detected. These modifications lead to solutions with sufficient back-up capacity to overcome periods of cold dark lulls, and sufficient total annual energy supply across all years. A computational study on an energy system model of Germany for 40 different operating years shows that the iterative algorithm finds solutions that guarantee security of supply for all considered years increasing the total annual cost by 1.6-2.9% compared to a lower bound. Results also underline the importance of assessing the feasibility of energy system models using atypical time-series, combining dark lull and cold period effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06750v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Kebrich, Felix Engelhardt, David Franzmann, Christina B\"using, Jochen Lin{\ss}en, Heidi Heinrichs</dc:creator>
    </item>
    <item>
      <title>AdGT: Decentralized Gradient Tracking with Tuning-free Per-Agent Stepsize</title>
      <link>https://arxiv.org/abs/2504.15196</link>
      <description>arXiv:2504.15196v2 Announce Type: replace 
Abstract: In decentralized optimization, the choice of stepsize plays a critical role in algorithm performance. A common approach is to use a shared stepsize across all agents to ensure convergence. However, selecting an optimal stepsize often requires careful tuning, which can be time-consuming and may lead to slow convergence, especially when there is significant variation in the smoothness (L-smoothness) of local objective functions across agents. Individually tuning stepsizes per agent is also impractical, particularly in large-scale networks. To address these limitations, we propose AdGT, an adaptive gradient tracking method that enables each agent to adjust its stepsize based on the smoothness of its local objective. We prove that AdGT achieves linear convergence to the global optimal solution. Through numerical experiments, we compare AdGT with fixed-stepsize gradient tracking methods and demonstrate its superior performance. Additionally, we compare AdGT with adaptive gradient descent (AdGD) in a centralized setting and observe that fully adaptive stepsizes offer greater benefits in decentralized networks than in centralized ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15196v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diyako Ghaderyan, Stefan Werner</dc:creator>
    </item>
    <item>
      <title>How to optimise tournament draws: The case of the FIFA World Cup</title>
      <link>https://arxiv.org/abs/2505.13106</link>
      <description>arXiv:2505.13106v2 Announce Type: replace 
Abstract: The organisers of major sports competitions use different policies with respect to constraints in the group draw. Our paper aims to rationalise these choices by analysing the trade-off between attractiveness (the number of games played by teams from the same geographic zone) and fairness (the departure of the draw mechanism from a uniform distribution). A parametric optimisation model is formulated and applied to the 2018 and 2022 FIFA World Cup draws. A flaw of the draw procedure is identified: the pre-assignment of the host to a group unnecessarily increases the distortions. All Pareto efficient sets of draw constraints are determined via simulations. The proposed framework can be used to find the optimal draw rules and justify the non-uniformity of the draw procedure for the stakeholders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13106v2</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>A Markovian Approach for Cross-Category Complementarity in Choice Modeling</title>
      <link>https://arxiv.org/abs/2508.18566</link>
      <description>arXiv:2508.18566v2 Announce Type: replace 
Abstract: While single-purchase choice models have been widely studied in assortment optimization, customers in modern retail and e-commerce environments often purchase multiple items across distinct product categories, exhibiting both substitution and complementarity. We consider the cross-category assortment optimization problem where retailers jointly determine assortments across categories to maximize expected revenue. Most prior work on the topic either overlooks complementarity or proposes models that lead to intractable optimization problems, despite being based on the multinomial logit (MNL) choice model. We propose a sequential multi-purchase choice model for cross-category choice that incorporates complementarity through a Markovian transition structure across categories, while allowing general Random Utility Maximization (RUM)-based choice models to capture the within-category substitution. We develop an Expectation-Maximization algorithm for estimation, and a polynomial-time algorithm for unconstrained assortment optimization that yields the optimal solution when the within-category substitution follows a Markov chain choice model. Furthermore, we introduce an empirical metric to quantify complementarity strength across product categories and conduct extensive numerical experiments on both synthetic data and a large-scale transaction-level dataset from a major US grocery store. Our model yields improvements in predictive accuracy, model fit, and expected revenue in setting with complementarity, and it reveals intuitive market structures such as brand-loyal cross-category purchasing. Overall, we believe that our model provides a theoretically-grounded and practical framework for modeling complementarity and making better cross-category assortment decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18566v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar El Housni, Shuo Sun, Rajan Udwani</dc:creator>
    </item>
    <item>
      <title>Stochastic Origin Frank-Wolfe for traffic assignment</title>
      <link>https://arxiv.org/abs/2509.23840</link>
      <description>arXiv:2509.23840v2 Announce Type: replace 
Abstract: In this paper, we present the Stochastic Origin Frank-Wolfe (SOFW) method, which is a special case of the block-coordinate Frank-Wolfe algorithm, applied to the problem of finding equilibrium flow distributions. By significantly reducing the computational complexity of the minimization oracle, the method improves overall efficiency at the cost of increased memory consumption. Its key advantage lies in minimizing the number of shortest path computations.
  We refer to existing theoretical convergence guarantees for generalized coordinate Frank-Wolfe methods and, in addition, extend the analysis by providing a convergence proof for a batched version of the Block-Coordinate Frank-Wolfe algorithm, which was not covered in the original work. We also demonstrate the practical effectiveness of our approach through experimental results. In particular, our findings show that the proposed method significantly outperforms the classical Frank-Wolfe algorithm and its variants on large-scale datasets. On smaller datasets, SOFW also remains effective, though the performance gap relative to classical methods becomes less pronounced. In such cases, there is a trade-off between solution quality, iteration time complexity, and memory usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23840v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Ignashin, Demyan Yarmoshik, Andrei Raigorodskii</dc:creator>
    </item>
    <item>
      <title>Tree-based formulation for the multi-commodity flow problem</title>
      <link>https://arxiv.org/abs/2509.24656</link>
      <description>arXiv:2509.24656v2 Announce Type: replace 
Abstract: We introduce a tree-based formulation for the minimum-cost multi-commodity flow problem that addresses large-scale instances. The method decomposes the source-based model by representing flows as convex combinations of trees rooted at source nodes, and solves the resulting formulation with column generation. The number of demand constraints now depends on the number of sources $|S|$, not commodities $|K|$, yielding a compact master problem when $|S| \ll |K|$. We conduct a computational study comparing tree-based decomposition against path-based column generation and direct LP solving. The results show speed-ups of up to one order of magnitude over direct LP solving, and improved scalability compared to path-based formulations. Tree-based decomposition enables solving instances with millions of commodities and hundreds of thousands of nodes. This makes it well-suited for applications in transportation and logistics networks where multiple demands often share common origins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24656v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Spoorendonk, Bj{\o}rn Petersen</dc:creator>
    </item>
    <item>
      <title>Robust dividend policy: Equivalence of Epstein-Zin and Maenhout preferences</title>
      <link>https://arxiv.org/abs/2406.12305</link>
      <description>arXiv:2406.12305v3 Announce Type: replace-cross 
Abstract: In a continuous-time economy, this paper formulates the Epstein-Zin preference for discounted dividends received by an investor as an Epstein-Zin singular control utility. We introduce a backward stochastic differential equation with an aggregator integrated with respect to a singular control, prove its well-posedness, and show that it coincides with the Epstein-Zin singular control utility. We then establish that this formulation is equivalent to a robust dividend policy chosen by the firm's executive under the Maenhout's ambiguity-averse preference. In particular, the robust dividend policy takes the form of a threshold strategy on the firm's surplus process, where the threshold level is characterized as the free boundary of a Hamilton-Jacobi-Bellman variational inequality. Therefore, dividend-caring investors can choose firms that match their preferences by examining stock's dividend policies and financial statements, whereas executives can make use of dividend to signal their confidence, in the form of ambiguity aversion, on realizing the earnings implied by their financial statements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12305v3</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.GN</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kexin Chen, Kyunghyun Park, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>Accuracy of Discretely Sampled Stochastic Policies in Continuous-time Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.09981</link>
      <description>arXiv:2503.09981v2 Announce Type: replace-cross 
Abstract: Stochastic policies (also known as relaxed controls) are widely used in continuous-time reinforcement learning algorithms. However, executing a stochastic policy and evaluating its performance in a continuous-time environment remain open challenges. This work introduces and rigorously analyzes a policy execution framework that samples actions from a stochastic policy at discrete time points and implements them as piecewise constant controls. We prove that as the sampling mesh size tends to zero, the controlled state process converges weakly to the dynamics with coefficients aggregated according to the stochastic policy. We explicitly quantify the convergence rate based on the regularity of the coefficients and establish an optimal first-order convergence rate for sufficiently regular coefficients. Additionally, we prove a $1/2$-order weak convergence rate that holds uniformly over the sampling noise with high probability, and establish a $1/2$-order pathwise convergence for each realization of the system noise in the absence of volatility control. Building on these results, we analyze the bias and variance of various policy evaluation and policy gradient estimators based on discrete-time observations. Our results provide theoretical justification for the exploratory stochastic control framework in [H. Wang, T. Zariphopoulou, and X.Y. Zhou, J. Mach. Learn. Res., 21 (2020), pp. 1-34].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09981v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanwei Jia, Du Ouyang, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>On Speedups for Convex Optimization via Quantum Dynamics</title>
      <link>https://arxiv.org/abs/2503.24332</link>
      <description>arXiv:2503.24332v2 Announce Type: replace-cross 
Abstract: We explore the potential for quantum speedups in convex optimization using discrete simulations of the Quantum Hamiltonian Descent (QHD) framework, as proposed by Leng et al., and establish the first rigorous query complexity bounds. We develop enhanced analyses for quantum simulation of Schr\"odinger operators with black-box potential via the pseudo-spectral method, providing explicit resource estimates independent of wavefunction assumptions. These bounds are applied to assess the complexity of optimization through QHD. Our findings pertain to unconstrained convex optimization in $d$ dimensions. In continuous time, we demonstrate that QHD, with suitable parameters, can achieve arbitrarily fast convergence rates. The optimization speed limit arises solely from the discretization of the dynamics, mirroring a property of the classical dynamics underlying QHD. Considering this cost, we show that a $G$-Lipschitz convex function can be optimized to an error of $\epsilon$ with $\widetilde{\mathcal{O}}(d^{1.5}G^2 R^2/\epsilon^2)$ queries. Moreover, under reasonable assumptions on the complexity of Hamiltonian simulation, $\widetilde{\Omega}(d/\epsilon^2)$ queries are necessary. Thus, QHD does not offer a speedup over classical zeroth order methods with exact oracles. However, we demonstrate that the QHD algorithm tolerates $\widetilde{\mathcal{O}}(\epsilon^3/d^{1.5}G^2 R^2)$ noise in function evaluation. We show that QHD offers a super-quadratic query advantage over all known classical algorithms tolerating this level of evaluation noise in the high-dimension regime. Additionally, we design a quantum algorithm for stochastic convex optimization that provides a super-quadratic speedup over all known classical algorithms in the high-dimension regime. To our knowledge, these results represent the first rigorous quantum speedups for convex optimization achieved through a dynamical algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24332v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shouvanik Chakrabarti, Dylan Herman, Jacob Watkins, Enrico Fontana, Brandon Augustino, Junhyung Lyle Kim, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>Canonical Frames for Bracket Generating Rank 2 Distributions which are not Goursat</title>
      <link>https://arxiv.org/abs/2508.09307</link>
      <description>arXiv:2508.09307v3 Announce Type: replace-cross 
Abstract: We complete a uniform construction of canonical absolute parallelism for bracket generating rank $2$ distributions with $5$-dimensional cube on $n$-dimensional manifold with $n\geq 5$ by showing that the condition of maximality of class that was assumed previously by Doubrov-Zelenko for such a construction holds automatically at generic points. This also gives analogous constructions in the case when the cube is not $5$-dimensional but the distribution is not Goursat through the procedure of iterative Cartan deprolongation. This together with the classical theory of Goursat distributions covers in principle the local geometry of all bracket generating rank 2 distributions in a neighborhood of generic points. As a byproduct, for any $n\geq 5$ we describe the maximally symmetric germs among bracket generating rank $2$ distributions with $5$-dimensional cube, as well as among those which reduce to such a distribution under a fixed number of Cartan deprolongations. Another consequence of our results on maximality of class is for optimal control problems with constraint given by a rank $2$ distribution with $5$-dimensional cube: it implies that for a generic point $q_0$ of $M$, there are plenty abnormal extremal trajectories of corank $1$ (which is the minimal possible corank) starting at $q_0$. The set of such points contains all points where the distribution is equiregular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09307v3</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicklas Day, Igor Zelenko</dc:creator>
    </item>
    <item>
      <title>Stabilizability and lower spectral radius for linear switched systems with singular matrices</title>
      <link>https://arxiv.org/abs/2509.17799</link>
      <description>arXiv:2509.17799v2 Announce Type: replace-cross 
Abstract: We investigate the stabilizability of linear discrete-time switched systems with singular matrices, focusing on the spectral radius in this context. A new lower bound of the stabilizability radius is proposed, which is applicable to any matrix set. Based on this lower bound, more relationships between the stabilizability radius and joint spectral subradius are established. Detailed analysis of the stabilizability radius of a special kind of two-dimensional switched system, consisting of a singular matrix and a rotation matrix, is presented. The Hausdorff dimensions of the parameter sets such that the stabilizability radius of these systems equals a constant are also presented. Other properties of switched systems with singular matrices are also discussed along with examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17799v2</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carl P. Dettmann, Chenmiao Zhang</dc:creator>
    </item>
  </channel>
</rss>
