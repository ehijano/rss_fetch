<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Mar 2024 04:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Control of Reduced Left-Invariant Hybrid Control Systems</title>
      <link>https://arxiv.org/abs/2403.15610</link>
      <description>arXiv:2403.15610v1 Announce Type: new 
Abstract: Optimal control is ubiquitous in many fields of engineering. A common technique to find candidate solutions is via Pontryagin's maximum principle. An unfortunate aspect of this method is that the dimension of system doubles. When the system evolves on a Lie group and the system is invariant under left (or right) translations, Lie-Poisson reduction can be applied to eliminate half of the dimensions (and returning the dimension of the problem to the back to the original number).
  Hybrid control systems are an extension of (continuous) control systems by allowing for sudden changes to the state. Examples of such systems include the bouncing ball - the velocity instantaneously jumps during a bounce, the thermostat - controls switch to on or off, and a sailboat undergoing tacking. The goal of this work is to extend the idea of Lie-Poisson reduction to the optimal control of these systems. If $n$ is the dimension of the original system, $2n$ is the dimension of the system produced by the maximum principle. In the case of classical Lie-Poisson reduction, the dimension drops back down to $n$. This, unfortunately, is impossible in hybrid systems as there must be an auxiliary variable encoding whether or not an event occurs. As such, the analogous hybrid Lie-Poisson reduction results in a $n+1$ dimensional system. The purpose of this work is to develop and present this technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15610v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Clark, Maria Oprea</dc:creator>
    </item>
    <item>
      <title>Data-Driven Approximation of Stationary Nonlinear Filters with Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2403.15630</link>
      <description>arXiv:2403.15630v1 Announce Type: new 
Abstract: The nonlinear filtering problem is concerned with finding the conditional probability distribution (posterior) of the state of a stochastic dynamical system, given a history of partial and noisy observations. This paper presents a data-driven nonlinear filtering algorithm for the case when the state and observation processes are stationary. The posterior is approximated as the push-forward of an optimal transport (OT) map from a given distribution, that is easy to sample from, to the posterior conditioned on a truncated observation window. The OT map is obtained as the solution to a stochastic optimization problem that is solved offline using recorded trajectory data from the state and observations. An error analysis of the algorithm is presented under the stationarity and filter stability assumptions, which decomposes the error into two parts related to the truncation window during training and the error due to the optimization procedure. The performance of the proposed method, referred to as optimal transport data-driven filter (OT-DDF), is evaluated for several numerical examples, highlighting its significant computational efficiency during the online stage while maintaining the flexibility and accuracy of OT methods in nonlinear filtering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15630v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Al-Jarrah, Bamdad Hosseini, Amirhossein Taghvaei</dc:creator>
    </item>
    <item>
      <title>Fourier Galerkin approximation of mean field control problems</title>
      <link>https://arxiv.org/abs/2403.15642</link>
      <description>arXiv:2403.15642v1 Announce Type: new 
Abstract: The purpose of this work is to provide a finite dimensional approximation of the solution to a mean field optimal control problem set on the $d$-dimensional torus. The approximation is obtained by means of a Fourier-Galerkin method, the main principle of which is to convolve probability measures on the torus by the Dirichlet kernel or, equivalently, to truncate the Fourier expansion of probability measures on the torus. However, this operation has the main feature not to leave the space of probability measures invariant, which drawback is know as \textit{Gibbs}' phenomenon. In spite of this, we manage to prove that, for initial conditions in the `interior' of the space of probability measures and for sufficiently large levels of truncation, the Fourier-Galerkin method induces a new finite dimensional control problem whose trajectories take values in the space of probability measures with a finite number of Fourier coefficients. Our main result asserts that, whenever the cost functionals are smooth and convex, the distance between the optimal trajectories of the original and approximating control problems decreases at a polynomial rate as the index of truncation in the Fourier-Galerkin method tends to $\infty$. A similar result holds for the distance between the corresponding value functions. From a practical point of view, our approach provides an efficient strategy to approximate mean field control optimizers by finite dimensional parameters and opens new perspectives for the numerical analysis of mean field control problems. It may be also applied to discretize more general mean field game systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15642v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Delarue, Mattia Martini</dc:creator>
    </item>
    <item>
      <title>Constraint Preconditioning and Parameter Selection for a First-Order Primal-Dual Method applied to Model Predictive Control</title>
      <link>https://arxiv.org/abs/2403.15656</link>
      <description>arXiv:2403.15656v1 Announce Type: new 
Abstract: Many techniques for real-time trajectory optimization and control require the solution of optimization problems at high frequencies. However, ill-conditioning in the optimization problem can significantly reduce the speed of first-order primal-dual optimization algorithms. We introduce a preconditioning technique and step-size heuristic for Proportional-Integral Projected Gradient (PIPG), a first-order primal-dual algorithm. The preconditioning technique, based on the QR factorization, aims to reduce the condition number of the KKT matrix associated with the optimization problem. Our step-size selection heuristic chooses step-sizes to minimize the upper bound on the convergence of the primal-dual gap for the optimization problem. These algorithms are tested on two model predictive control problem examples and show a solve-time reduction of at least 3.6x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15656v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Govind M. Chari, Yue Yu, Beh\c{c}et A\c{c}{\i}kme\c{s}e</dc:creator>
    </item>
    <item>
      <title>Review of Large-Scale Simulation Optimization</title>
      <link>https://arxiv.org/abs/2403.15669</link>
      <description>arXiv:2403.15669v1 Announce Type: new 
Abstract: Large-scale simulation optimization (SO) problems encompass both large-scale ranking-and-selection problems and high-dimensional discrete or continuous SO problems, presenting significant challenges to existing SO theories and algorithms. This paper begins by providing illustrative examples that highlight the differences between large-scale SO problems and those of a more moderate scale. Subsequently, it reviews several widely employed techniques for addressing large-scale SO problems, such as divide and conquer, dimension reduction, and gradient-based algorithms. Additionally, the paper examines parallelization techniques leveraging widely accessible parallel computing environments to facilitate the resolution of large-scale SO problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15669v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiwei Fan, L. Jeff Hong, Guangxin Jiang, Jun Luo</dc:creator>
    </item>
    <item>
      <title>Robust pointwise second order necessary conditions for singular stochastic optimal control with model uncertainty</title>
      <link>https://arxiv.org/abs/2403.15703</link>
      <description>arXiv:2403.15703v1 Announce Type: new 
Abstract: We study the singular stochastic optimal control problem with model uncertainty, where the necessary conditions determined by the corresponding maximum principle are trivial. Robust integral form and pointwise second order necessary optimality conditions under certain compactness conditions are derived. Both the drift and diffusion terms are control dependent but the control region are assumed to be convex. The convex variational method is employed, because linear structure is essential in deriving the weak limit of uncertainty measures. Other main technical ingredients in obtaining the integral type conditions are compact analysis and minimax theorem, while for the pointwise ones it is Clark-Ocone formula and Lebesgue differentiation type theorem. Besides, a compendious example is given to illustrate the motivation and effectiveness of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15703v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangdong Jing</dc:creator>
    </item>
    <item>
      <title>Properties for transposition solutions to operator-valued BSEEs, and applications to robust second order necessary conditions for controlled SEEs</title>
      <link>https://arxiv.org/abs/2403.15710</link>
      <description>arXiv:2403.15710v1 Announce Type: new 
Abstract: This article is concerned with the second order necessary conditions for the stochastic optimal control problem of stochastic evolution equation with model uncertainty when the traditional Pontryagin-type maximum principle holds trivially and do not provide any information depicting the optimal control. The diffusion term of the state equation is allowed to be control dependent with convex control constraints. Transposition method is adopted to deal with the adjoint operator-valued backward stochastic evolution equations, especially the correction terms. Besides, weak convergence arguments are performed to obtain the optimal uncertainty measure, among which the regularities of the state processes, variational processes, and adjoint processes (in the transposition sense) are carefully characterized. Malliavin calculus is applied to pave the way for Lebesgue differentiation theorem to deduce the pointwise robust optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15710v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangdong Jing</dc:creator>
    </item>
    <item>
      <title>Fast Consensus Topology Design via Minimizing Laplacian Energy</title>
      <link>https://arxiv.org/abs/2403.15745</link>
      <description>arXiv:2403.15745v1 Announce Type: new 
Abstract: This paper characterizes the graphical properties of an optimal topology with minimal Laplacian energy under the constraint of fixed numbers of vertices and edges, and devises an algorithm to construct such connected optimal graphs. These constructed graphs possess maximum vertex and edge connectivity, and more importantly, exhibit large algebraic connectivity of an optimal order provided they are not sparse. These properties guarantee fast and resilient consensus processes over these graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15745v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susie Lu, Ji Liu</dc:creator>
    </item>
    <item>
      <title>Horoballs and the subgradient method</title>
      <link>https://arxiv.org/abs/2403.15749</link>
      <description>arXiv:2403.15749v1 Announce Type: new 
Abstract: To explore convex optimization on Hadamard spaces, we consider an iteration in the style of a subgradient algorithm. Traditionally, such methods assume that the underlying spaces are manifolds and that the objectives are geodesically convex: the methods are described using tangent spaces and exponential maps. By contrast, our iteration applies in a general Hadamard space, is framed in the underlying space itself, and relies instead on horospherical convexity of the objective level sets. For this restricted class of objectives, we prove a complexity result of the usual form. Notably, the complexity does not depend on a lower bound on the space curvature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15749v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian S. Lewis, Genaro Lopez-Acedo, Adriana Nicolae</dc:creator>
    </item>
    <item>
      <title>GPU-accelerated nonlinear model predictive control with ExaModels and MadNLP</title>
      <link>https://arxiv.org/abs/2403.15913</link>
      <description>arXiv:2403.15913v1 Announce Type: new 
Abstract: We investigate the potential of Graphics Processing Units (GPUs) to solve large-scale nonlinear model predictive control (NMPC) problems. We accelerate the solution of the constrained nonlinear programs in the NMPC algorithm using the GPU-accelerated automatic differentiation tool ExaModels with the interior-point solver MadNLP. The sparse linear systems formulated in the interior-point method is solved on the GPU using a hybrid solver combining an iterative method with a sparse Cholesky factorization, which harness the newly released NVIDIA cuDSS solver. Our results on the classical distillation column instance show that despite a significant pre-processing time, the hybrid solver allows to reduce the time per iteration by a factor of 25 for the largest instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15913v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Pacaud, Sungho Shin</dc:creator>
    </item>
    <item>
      <title>Michell Truss and From 1-beam to k-beam</title>
      <link>https://arxiv.org/abs/2403.15915</link>
      <description>arXiv:2403.15915v1 Announce Type: new 
Abstract: This paper generalizes the Michell Truss problem and Gangbo's paper from 1-dimension to higher dimensions using geometric measure theory.
  Given an elastic surface $S$ made of $(k-1)$-beams under an equilibriated system $F$ of external forces, then we ask the following two questions:
  1. What are the necessary and sufficient conditions for the existence of an elastic body made of $k$-beams whose forces on the surface balance $F$ and whose surfaces consist of $S$.
  2. What is an optimal design so that the total cost is a minimum?
  We've solved the existence question completely; and research is still in progress for the minimal question. In particular when $k=1$, it involves a system of beams joining a given finite collection of pointed forces. It was first introduced by A. Michell in 1904, then used in mechanical engineering, and recently popularized in many pure mathematics works by W. Gangbo, Prager, and others. Here we are going to generalize them to higher dimensional cases. We have already found the minimal solutions in terms of the flat chain complex and vector-valued currents. Right now we are studying the Calibration theory for future directions. I appreciate the discussion with Prof. Robert Hardt!</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15915v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chengcheng Yang</dc:creator>
    </item>
    <item>
      <title>Infinite dimensional open-loop linear quadratic stochastic optimal control problems and related games</title>
      <link>https://arxiv.org/abs/2403.15988</link>
      <description>arXiv:2403.15988v1 Announce Type: new 
Abstract: We investigate the linear quadratic stochastic optimal control problems in infinite dimension without Markovian restriction for coefficients. The necessary and sufficient conditions for open-loop optimal controls are presented. We prove the Fr\'echet differentiable of the cost functional with respect to the control variable, and the Fr\'echet derivatives are characterized in detail by operators derived from dual analysis, which are proven to be the stationary conditions. Transposition methods are adopted to deal with the adjoint equations. As applications, we employ the results to study open-loop Nash equilibria for two-person stochastic differential games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15988v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangdong Jing</dc:creator>
    </item>
    <item>
      <title>Output Feedback Control of Suspended Sediment Load Entrainment in Water Canals and Reservoirs</title>
      <link>https://arxiv.org/abs/2403.15998</link>
      <description>arXiv:2403.15998v1 Announce Type: new 
Abstract: This paper addresses the management of water flow in a rectangular open channel, considering the dynamic nature of both the channel's bathymetry and the suspended sediment particles caused by entrainment and deposition effects. The control-oriented model under study is a set of coupled nonlinear partial differential equations (PDEs) describing conservation of mass and momentum while accounting for constitutive relations that govern sediment erosion and deposition phenomena. The proposed boundary control problem presents a fresh perspective in water canal management and expands Saint-Venant Exner (SVE) control frameworks by integrating dynamics related to the transport of fine particles. After linearization, PDE backstepping design is employed to stabilize both the bathymetry, the water dynamics together with the concentration of suspended sediment particles. Two underflow sluice gates are used for flow control at the upstream and downstream boundaries with only the downstream component being actuated. An observer-based backstepping control design is carried out for the downstream gate using state measurement at the upstream gate to globally exponentially stabilize the linearized system to a desired equilibrium point in $\mathscr{L}^2$ sense. The stability analysis is performed on the linearized model which is a system of four coupled PDEs, three of which are rightward convecting and one leftward. The proposed control design has the potential to facilitate efficient reservoir flushing operations. Consistent simulation results are presented to illustrate the feasibility of the designed control law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15998v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eranda Somathilake, Mamadou Diagne</dc:creator>
    </item>
    <item>
      <title>Stochastic maximum principle for weighted mean-field system with jump</title>
      <link>https://arxiv.org/abs/2403.16000</link>
      <description>arXiv:2403.16000v1 Announce Type: new 
Abstract: In this article, we consider a weighted mean-field control problem with jump-diffusion as its state process. The main difficulty is from the non-Lipschitz property of the coefficients. We overcome this difficulty by an $L_{p,q}$-estimate of the solution processes with a suitably chosen $p$ and $q$. Convex pertubation method combining with the aforementioned $L_{p,q}$-estimation method is utilized to derive the stochastic maximum principle for this control problem. A sufficient condition for the optimality is also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16000v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanyan Tang, Jie Xiong</dc:creator>
    </item>
    <item>
      <title>Planning Charging Stations and Service Operations of Dockless Electric Micromobility Systems</title>
      <link>https://arxiv.org/abs/2403.16029</link>
      <description>arXiv:2403.16029v1 Announce Type: new 
Abstract: Dockless electric micro-mobility services (e.g., shared e-scooters and e-bikes) have been increasingly popular in the recent decade, and a variety of charging technologies have emerged for these services. The use of charging stations, to/from which service vehicles are transported by the riders for charging, poses as a promising approach because it reduces the need for dedicated staff or contractors. However, unique challenges also arise, such as how to incentivize riders to drop off vehicles at stations and how to efficiently utilize the vehicles being charged at the stations. This paper focuses on dockless e-scooters as an example and develops a new spatial queuing network model to capture the steady-state scooter service cycles, battery consumption and charging processes, and the associated pricing and management mechanisms. Building upon this model, a system of closed-form equations is formulated and incorporated into a constrained nonlinear program to optimize the deployment of the service fleet, the design of charging stations (i.e., number, location, and capacity), user-based charging price promotions and priorities, and repositioning truck operations (i.e., headway and truck load). The proposed queuing network model is found to match very well with agent-based simulations. It is applied to a series of numerical experiments to draw insights into the optimal designs and the system performance. The numerical results reveal strong advantages of using charging stations for shared dockless electric micro-mobility services as compared to state-of-the-art alternatives. The proposed model can also be used to analyze other micromobility services and other charging approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16029v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yining Liu, Yanfeng Ouyang</dc:creator>
    </item>
    <item>
      <title>Exponential mixing of constrained random dynamical systems via controllability conditions</title>
      <link>https://arxiv.org/abs/2403.16058</link>
      <description>arXiv:2403.16058v1 Announce Type: new 
Abstract: We provide deterministic controllability conditions that imply exponential mixing properties for randomly forced constrained dynamical systems with possibly unbounded state space. As an application, new ergodicity results are obtained for non-smooth models in elasto-plasticity driven by various types of noise, including white noise. It is thereby illustrated how tools from control theory can be utilized to tackle regularity issues that commonly arise in the qualitative study of constrained systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16058v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Mertz, Vahagn Nersesyan, Manuel Rissel</dc:creator>
    </item>
    <item>
      <title>On the Bailout Dividend Problem with Periodic Dividend Payments and Fixed Transaction Costs</title>
      <link>https://arxiv.org/abs/2403.16077</link>
      <description>arXiv:2403.16077v1 Announce Type: new 
Abstract: We study the optimal bailout dividend problem with transaction costs for an insurance company, where shareholder payouts align with the arrival times of an independent Poisson process. In this scenario, the underlying risk model follows a spectrally negative L\'evy process. Our analysis confirms the optimality of a periodic $(b_{1},b_{2})$-barrier policy with classical reflection at zero. This strategy involves reducing the surplus to $b_1$ when it exceeds $b_{2}$ at the Poisson arrival times and pushes the surplus to 0 whenever it goes below zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16077v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harold A. Moreno-Franco, Jose-Luis P\'erez</dc:creator>
    </item>
    <item>
      <title>An instability result of Hamiltonian systems related to optimal swing-up control of a pendulum</title>
      <link>https://arxiv.org/abs/2403.16156</link>
      <description>arXiv:2403.16156v1 Announce Type: new 
Abstract: This paper presents an instability result of Hamiltonian systems associated with optimal swing-up control for a pendulum. The systems possess weak (higher-order) instability at the initial point of the swing-up control, the analysis for which requires techniques from celestial mechanics. The obtained result may have relationships with the previously obtained numerical studies for the existence of multiple locally optimal solutions and the non-existence conjecture of the optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16156v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noboru Sakamoto</dc:creator>
    </item>
    <item>
      <title>Input-to-State Stability of Newton Methods for Generalized Equations in Nonlinear Optimization</title>
      <link>https://arxiv.org/abs/2403.16165</link>
      <description>arXiv:2403.16165v1 Announce Type: new 
Abstract: We show that Newton methods for generalized equations are input-to-state stable with respect to disturbances such as due to inexact computations. We then use this result to obtain convergence and robustness of a multistep Newton-type method for multivariate generalized equations. We demonstrate the usefulness of the results with other applications to nonlinear optimization. In particular, we provide a new proof for (robust) local convergence of the augmented Lagrangian method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16165v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Torbj{\o}rn Cunis, Ilya Kolmanovsky</dc:creator>
    </item>
    <item>
      <title>A robust optimization approach model for a multi-vaccine multi-echelon supply chain</title>
      <link>https://arxiv.org/abs/2403.16173</link>
      <description>arXiv:2403.16173v1 Announce Type: new 
Abstract: This research investigates a multi-product, multi-echelon, and multi-period vaccine supply chain network model under uncertainty and quality inspection errors. The objective function seeks optimizing the total cost of the supply chain. Moreover, the proposed model is formulated as a mixed integer linear programming problem under multiple sources of uncertain parameters including demand, inspection errors, vaccine waste generated in healthcare centers, and defective treatment rate of vaccine waste. To provide meaningful solutions that are robust against future fluctuation of parameters, the robust optimization approach is utilized to incorporate the decision maker risk attitude under different type of uncertainty sets. Namely, box, polyhedral and combination of interval polyhedral. The performance of the proposed model is demonstrated through an illustrative example. The results show the effect of different types of uncertainties on the overall objective function. Managerial insights and research implications in terms of vaccine supply chain is advised and future research directions are proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16173v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abderrahmen Bochenine, Ismail Almaraj</dc:creator>
    </item>
    <item>
      <title>Unbiased Extremum Seeking Based on Lie Bracket Averaging</title>
      <link>https://arxiv.org/abs/2403.16294</link>
      <description>arXiv:2403.16294v1 Announce Type: new 
Abstract: Extremum seeking is an online, model-free optimization algorithm traditionally known for its practical stability. This paper introduces an extremum seeking algorithm designed for unbiased convergence to the extremum asymptotically, allowing users to define the convergence rate. Unlike conventional extremum seeking approaches utilizing constant gains, our algorithms employ time-varying parameters. These parameters reduce perturbation amplitudes towards zero in an asymptotic manner, while incorporating asymptotically growing controller gains. The stability analysis is based on state transformation, achieved through the multiplication of the input state by asymptotic growth function, and Lie bracket averaging applied to the transformed system. The averaging ensures the practical stability of the transformed system, which, in turn, leads to the asymptotic stability of the original system. Moreover, for strongly convex maps, we achieve exponentially fast convergence. The numerical simulations validate the feasibility of the introduced designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16294v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cemal Tugrul Yilmaz, Mamadou Diagne, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained Gaussian Mixture Steering to a Terminal Gaussian Distribution</title>
      <link>https://arxiv.org/abs/2403.16302</link>
      <description>arXiv:2403.16302v1 Announce Type: new 
Abstract: We address the problem of finite-horizon control of a discrete-time linear system, where the initial state distribution follows a Gaussian mixture model, the terminal state must follow a specified Gaussian distribution, and the state and control inputs must obey chance constraints. We show that, throughout the time horizon, the state and control distributions are fully characterized by Gaussian mixtures. We then formulate the cost, distributional terminal constraint, and affine/2-norm chance constraints on the state and control, as convex functions of the decision variables. This is leveraged to formulate the chance-constrained path planning problem as a single semidefinite programming problem. A numerical example demonstrates the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16302v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoya Kumagai, Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Optimization on a Finer Scale: Bounded Local Subgradient Variation Perspective</title>
      <link>https://arxiv.org/abs/2403.16317</link>
      <description>arXiv:2403.16317v1 Announce Type: new 
Abstract: We initiate the study of nonsmooth optimization problems under bounded local subgradient variation, which postulates bounded difference between (sub)gradients in small local regions around points, in either average or maximum sense. The resulting class of objective functions encapsulates the classes of objective functions traditionally studied in optimization, which are defined based on either Lipschitz continuity of the objective or H\"{o}lder/Lipschitz continuity of its gradient. Further, the defined class contains functions that are neither Lipschitz continuous nor have a H\"{o}lder continuous gradient. When restricted to the traditional classes of optimization problems, the parameters defining the studied classes lead to more fine-grained complexity bounds, recovering traditional oracle complexity bounds in the worst case but generally leading to lower oracle complexity for functions that are not ``worst case.'' Some highlights of our results are that: (i) it is possible to obtain complexity results for both convex and nonconvex problems with the (local or global) Lipschitz constant being replaced by a constant of local subgradient variation and (ii) mean width of the subdifferential set around the optima plays a role in the complexity of nonsmooth optimization, particularly in parallel settings. A consequence of (ii) is that for any error parameter $\epsilon &gt; 0$, parallel oracle complexity of nonsmooth Lipschitz convex optimization is lower than its sequential oracle complexity by a factor $\tilde{\Omega}\big(\frac{1}{\epsilon}\big)$ whenever the objective function is piecewise linear with polynomially many pieces in the input size. This is particularly surprising as existing parallel complexity lower bounds are based on such classes of functions. The seeming contradiction is resolved by considering the region in which the algorithm is allowed to query the objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16317v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jelena Diakonikolas, Crist\'obal Guzm\'an</dc:creator>
    </item>
    <item>
      <title>Unbiased Extremum Seeking for PDEs</title>
      <link>https://arxiv.org/abs/2403.16462</link>
      <description>arXiv:2403.16462v1 Announce Type: new 
Abstract: There have been recent efforts that combine seemingly disparate methods, extremum seeking (ES) optimization and partial differential equation (PDE) backstepping, to address the problem of model-free optimization with PDE actuator dynamics. In contrast to prior PDE-compensating ES designs, which only guarantee local stability around the extremum, we introduce unbiased ES that compensates for delay and diffusion PDE dynamics while ensuring exponential and unbiased convergence to the optimum. Our method leverages exponentially decaying/growing signals within the modulation/demodulation stages and carefully selected design parameters. The stability analysis of our designs relies on a state transformation, infinite-dimensional averaging, local exponential stability of the averaged system, local stability of the transformed system, and local exponential stability of the original system. Numerical simulations are presented to demonstrate the efficacy of the developed designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16462v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cemal Tugrul Yilmaz, Mamadou Diagne, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Data-Driven Extrusion Force Control Tuning for 3D Printing</title>
      <link>https://arxiv.org/abs/2403.16470</link>
      <description>arXiv:2403.16470v1 Announce Type: new 
Abstract: The quality of 3D prints often varies due to different conditions inherent to each print, such as filament type, print speed, and nozzle size. Closed-loop process control methods improve the accuracy and repeatability of 3D prints. However, optimal tuning of controllers for given process parameters and design geometry is often a challenge with manually tuned controllers resulting in inconsistent and suboptimal results. This work employs Bayesian optimization to identify the optimal controller parameters. Additionally, we explore transfer learning in the context of 3D printing by leveraging prior information from past trials. By integrating optimized extrusion force control and transfer learning, we provide a novel framework for closed-loop 3D printing and propose an automated calibration routine that produces high-quality prints for a desired combination of print settings, material, and shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16470v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xavier Guidetti, Ankita Mukne, Marvin Rueppel, Yannick Nagel, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Low-rank quaternion tensor completion for color video inpainting via a novel factorization strategy</title>
      <link>https://arxiv.org/abs/2403.16480</link>
      <description>arXiv:2403.16480v1 Announce Type: new 
Abstract: Recently, a quaternion tensor product named Qt-product was proposed, and then the singular value decomposition and the rank of a third-order quaternion tensor were given. From a more applicable perspective, we extend the Qt-product and propose a novel multiplication principle for third-order quaternion tensor named gQt-product. With the gQt-product, we introduce a brand-new singular value decomposition for third-order quaternion tensors named gQt-SVD and then define gQt-rank and multi-gQt-rank. We prove that the optimal low-rank approximation of a third-order quaternion tensor exists and some numerical experiments demonstrate the low-rankness of color videos. So, we apply the low-rank quaternion tensor completion to color video inpainting problems and present alternating least-square algorithms to solve the proposed low gQt-rank and multi-gQt-rank quaternion tensor completion models. The convergence analyses of the proposed algorithms are established and some numerical experiments on various color video datasets show the high recovery accuracy and computational efficiency of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16480v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenzhi Qin, Zhenyu Ming, Defeng Sun, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>Extremality of collections of sets with respect to general perturbations</title>
      <link>https://arxiv.org/abs/2403.16511</link>
      <description>arXiv:2403.16511v1 Announce Type: new 
Abstract: The paper proposes another extension of the extremal principle. A new extremality model involving arbitrary families of perturbations (deformations) of the given sets is studied. It generalizes the conventional model based on linear translations of the sets as well as its set-valued extensions. This approach leads to a more general and simpler version of fuzzy separation. We demonstrate the applicability of the new model to set-valued optimization problems, weakening the assumptions of the known results and streamlining their proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16511v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Duy Cuong, Alexander Y. Kruger, Nguyen Hieu Thao</dc:creator>
    </item>
    <item>
      <title>Identification of Cyclists' Route Choice Criteria</title>
      <link>https://arxiv.org/abs/2403.16580</link>
      <description>arXiv:2403.16580v1 Announce Type: new 
Abstract: The behavior of cyclists when choosing the path to follow along a road network is not uniform. Some of them are mostly interested in minimizing the travelled distance, but some others may also take into account other features such as safety of the roads or pollution. Individuating the different groups of users, estimating the numerical consistency of each of these groups, and reporting the weights assigned by each group to different characteristics of the road network, is quite relevant. Indeed, when decision makers need to assign some budget for infrastructural interventions, they need to know the impact of their decisions, and this is strictly related to the way users perceive different features of the road network. In this paper, we propose an optimization approach to detect the weights assigned to different road features by various user groups, leveraging knowledge of the true paths followed by them, accessible, for example, through data collected by bike-sharing services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16580v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano Ardizzoni, Mattia Laurini, Rafael Praxedes, Luca Consolini, Marco Locatelli</dc:creator>
    </item>
    <item>
      <title>A nonlocal approach to graded surface modeling in topology optimization</title>
      <link>https://arxiv.org/abs/2403.16587</link>
      <description>arXiv:2403.16587v1 Announce Type: new 
Abstract: Additively manufactured structures often exhibit a correlation between their mechanical properties, such as stiffness, strength, and porosity, and their wall thickness. This correlation stems from the interplay between the manufacturing process and the properties of the filler material. In this study, we investigate the thickness-dependent effect on structural stiffness and propose a nonlocal integral model that introduces surface grading of Young's modulus to capture this phenomenon. We incorporate this model into topology optimization for designing structures with optimized compliance subject to a volume constraint. Notably, elastically degraded surfaces penalize excessively thin features, effectively eliminating them from the optimized design. We showcase the efficacy of our proposed framework by optimizing the design of a two-dimensional cantilever beam and a bridge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16587v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sukhminder Singh, Lukas Pflug, Fabian Wein, Michael Stingl</dc:creator>
    </item>
    <item>
      <title>Improving the Optimization in Model Predictive Controllers: Scheduling Large Groups of Electric Vehicles</title>
      <link>https://arxiv.org/abs/2403.16622</link>
      <description>arXiv:2403.16622v1 Announce Type: new 
Abstract: In parking lots with large groups of electric vehicles (EVs), charging has to happen in a coordinated manner, among others, due to the high load per vehicle and the limited capacity of the electricity grid. To achieve such coordination, model predictive control can be applied, thereby repeatedly solving an optimization problem. Due to its repetitive nature and its dependency on the time granularity, optimization has to be (computationally) efficient. The work presented here focuses on that optimization subroutine, its computational efficiency and how to speed up the optimization for large groups of EVs. In particular, we adapt FOCS, an algorithm that can solve the underlying optimization problem, to better suit the repetitive set-up of model predictive control by adding a pre-mature stop feature. Based on real-world data, we empirically show that the added feature speeds up the median computation time for 1-minute granularity by up to 44%. Furthermore, since FOCS is an algorithm that uses maximum flow methods as a subroutine, the impact of choosing various maximum flow methods on the runtime is investigated. Finally, we compare FOCS to a commercially available solver, concluding that FOCS outperforms the state-of-the-art when making a full-day schedule for large groups of EVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16622v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leoni Winschermann, Marco E. T. Gerards, Johann Hurink</dc:creator>
    </item>
    <item>
      <title>Optimal Mass Transport of Nonlinear Systems under Input and Density Constraints</title>
      <link>https://arxiv.org/abs/2403.16683</link>
      <description>arXiv:2403.16683v1 Announce Type: new 
Abstract: We investigate optimal mass transport problem of affine-nonlinear dynamical systems with input and density constraints. Three algorithms are proposed to tackle this problem, including two Uzawa-type methods and a splitting algorithm based on the Douglas-Rachford algorithm. Some preliminary simulation results are presented to demonstrate the effectiveness of our approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16683v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongjun Wu, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Anderson Acceleration Without Restart: A Novel Method with $n$-Step Super Quadratic Convergence Rate</title>
      <link>https://arxiv.org/abs/2403.16734</link>
      <description>arXiv:2403.16734v1 Announce Type: new 
Abstract: In this paper, we propose a novel Anderson's acceleration method to solve nonlinear equations, which does \emph{not} require a restart strategy to achieve numerical stability. We propose the greedy and random versions of our algorithm. Specifically, the greedy version selects the direction to maximize a certain measure of progress for approximating the current Jacobian matrix. In contrast, the random version chooses the random Gaussian vector as the direction to update the approximate Jacobian. Furthermore, our algorithm, including both greedy and random versions, has an $n$-step super quadratic convergence rate, where $n$ is the dimension of the objective problem. For example, the explicit convergence rate of the random version can be presented as $ \norm{\vx_{k+n+1} - \vx_*} / \norm{\vx_k- \vx_*}^2 = \cO\left(\left(1-\frac{1}{n}\right)^{kn}\right)$ for any $k\geq 0$ where $\vx_*$ is the optimum of the objective problem. This kind of convergence rate is new to Anderson's acceleration and quasi-Newton methods. The experiments also validate the fast convergence rate of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16734v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haishan Ye, Dachao Lin, Xiangyu Chang, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Models, constructive heuristics, and benchmark instances for the flexible job shop scheduling problem with sequencing flexibility and position-based learning effect</title>
      <link>https://arxiv.org/abs/2403.16766</link>
      <description>arXiv:2403.16766v1 Announce Type: new 
Abstract: This paper addresses the flexible job shop scheduling problem with sequencing flexibility and position-based learning effect. In this variant of the flexible job shop scheduling problem, precedence constraints of the operations constituting a job are given by an arbitrary directed acyclic graph, in opposition to the classical case in which a total order is imposed. Additionally, it is assumed that the processing time of an operation in a machine is subject to a learning process such that the larger the position of the operation in the machine, the faster the operation is processed. Mixed integer programming and constraint programming models are presented and compared in the present work. In addition, constructive heuristics are introduced to provide an initial solution to the models' solvers. Sets of benchmark instances are also introduced. The problem considered corresponds to modern problems of great relevance in the printing industry. The models and instances presented are intended to support the development of new heuristic and metaheuristics methods for this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16766v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kennedy A. G. Ara\'ujo, Ernesto G. Birgin, D\'ebora P. Ronconi</dc:creator>
    </item>
    <item>
      <title>Stochastic Inertial Dynamics Via Time Scaling and Averaging</title>
      <link>https://arxiv.org/abs/2403.16775</link>
      <description>arXiv:2403.16775v1 Announce Type: new 
Abstract: Our work is part of the close link between continuous-time dissipative dynamical systems and optimization algorithms, and more precisely here, in the stochastic setting. We aim to study stochastic convex minimization problems through the lens of stochastic inertial differential inclusions that are driven by the subgradient of a convex objective function. This will provide a general mathematical framework for analyzing the convergence properties of stochastic second-order inertial continuous-time dynamics involving vanishing viscous damping and measurable stochastic subgradient selections. Our chief goal in this paper is to develop a systematic and unified way that transfers the properties recently studied for first-order stochastic differential equations to second-order ones involving even subgradients in lieu of gradients. This program will rely on two tenets: time scaling and averaging, following an approach recently developed in the literature by one of the co-authors in the deterministic case.
  Under a mild integrability assumption involving the diffusion term and the viscous damping, our first main result shows that almost surely, there is weak convergence of the trajectory towards a minimizer of the objective function and fast convergence of the values and gradients. We also provide a comprehensive complexity analysis by establishing several new pointwise and ergodic convergence rates in expectation for the convex, strongly convex, and (local) Polyak-Lojasiewicz case. Finally, using Tikhonov regularization with a properly tuned vanishing parameter, we can obtain almost sure strong convergence of the trajectory towards the minimum norm solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16775v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Hedy Attouch, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Local search and trajectory metaheuristics for the flexible job shop scheduling problem with sequencing flexibility and position-based learning effect</title>
      <link>https://arxiv.org/abs/2403.16787</link>
      <description>arXiv:2403.16787v1 Announce Type: new 
Abstract: The flexible job shop scheduling problem with sequencing flexibility and position-based learning effect is considered in the present work. In [K. A. G. Araujo, E. G. Birgin, and D. P. Ronconi, Technical Report MCDO02022024, 2024], models, constructive heuristics, and benchmark instances for the same problem were introduced. In the present work, we are concerned with the development of effective and efficient methods for its resolution. For this purpose, a local search method and four trajectory metaheuristics are considered. In the local search, we show that the classical strategy of only reallocating operations that are part of the critical path can miss better quality neighbors, as opposed to what happens in the case where there is no learning effect. Consequently, we analyze an alternative type of neighborhood reduction that eliminates only neighbors that are not better than the current solution. In addition, we also suggest a neighborhood cut and experimentally verify that this significantly reduces the neighborhood size, bringing efficiency, with minimal loss in effectiveness. Extensive numerical experiments with the local search and the metaheuristics are carried on. The experiments show that tabu search, built on the reduced neighborhood, when applied to large-sized instances, stands out in relation to other the other three metaheuristics, namely, iterated local search, greedy randomized adaptive search procedure, and simulating annealing. Experiments with classical instances without sequencing flexibility show that the introduced methods also stand out in relation to methods from the literature. All the methods introduced, as well as the instances and solutions found, are freely available. As a whole, we build a test suite that can be used in future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16787v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kennedy A. G. Ara\'ujo, Ernesto G. Birgin, D\'ebora P. Ronconi</dc:creator>
    </item>
    <item>
      <title>Improved convergence rates for the Difference-of-Convex algorithm</title>
      <link>https://arxiv.org/abs/2403.16864</link>
      <description>arXiv:2403.16864v1 Announce Type: new 
Abstract: We consider a difference-of-convex formulation where one of the terms is allowed to be hypoconvex (or weakly convex). We first examine the precise behavior of a single iteration of the Difference-of-Convex algorithm (DCA), giving a tight characterization of the objective function decrease. This requires distinguishing between eight distinct parameter regimes.
  Our proofs are inspired by the performance estimation framework, but are much simplified compared to similar previous work.
  We then derive sublinear DCA convergence rates towards critical points, distinguishing between cases where at least one of the functions is smooth and where both functions are nonsmooth. We conjecture the tightness of these rates for four parameter regimes, based on strong numerical evidence obtained via performance estimation, as well as the leading constant in the asymptotic sublinear rate for two more regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16864v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teodor Rotaru, Panagiotis Patrinos, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>Algebraic Constraints on Common Lines with Applications to Community Detection in Cryo-EM</title>
      <link>https://arxiv.org/abs/2403.16879</link>
      <description>arXiv:2403.16879v1 Announce Type: new 
Abstract: We revisit the topic of common lines between 2D class averages in single particle cryo-electron microscopy (cryo-EM). We derive a novel low-rank constraint on a certain $2n \times n$ matrix storing properly-scaled basis vectors for the common lines between $n$ tomographic images of one molecular conformation. Using this constraint and others, we introduce an optimization algorithm to denoise the common lines of one conformation. As a main application, we develop a clustering algorithm to partition a set of noisy common lines into homogeneous communities, in the case of discrete heterogeneity in cryo-EM. We demonstrate the methods on synthetic and experimental datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16879v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tommi Muller, Adriana L. Duncan, Eric J. Verbeke, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>An $\alpha$-potential game framework for $N$-player games</title>
      <link>https://arxiv.org/abs/2403.16962</link>
      <description>arXiv:2403.16962v1 Announce Type: new 
Abstract: This paper proposes and studies a general form of dynamic $N$-player non-cooperative games called $\alpha$-potential games, where the change of a player's value function upon her unilateral deviation from her strategy is equal to the change of an $\alpha$-potential function up to an error $\alpha$. Analogous to the static potential game (which corresponds to $\alpha=0$), the $\alpha$-potential game framework is shown to reduce the challenging task of finding approximate Nash equilibria for a dynamic game to minimizing the $\alpha$-potential function. Moreover, an analytical characterization of $\alpha$-potential functions is established, with $\alpha$ represented in terms of the magnitude of the asymmetry of value functions' second-order derivatives. For stochastic differential games in which the state dynamic is a controlled diffusion, $\alpha$ is explicitly identified in terms of the number of players, the choice of admissible strategies, and the intensity of interactions, and the level of heterogeneity among players. This is achieved by introducing a suitable linear derivative of the value functions with respect to unilateral deviations of strategies and via analyzing the sensitivity processes of state dynamics with respect to controls.
  For games with mean-field type interactions, $\alpha$ is shown to decay to zero as the number of players goes to infinity, even with heterogeneity in state dynamics, cost functions, and admissible strategy classes. For distributed games, if a static potential function can be derived from the cost functions, then $\alpha=0$. For crowd aversion games, $\alpha$ is capable of capturing the subtle difference between the choice of admissible strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16962v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Guo, Xinyu Li, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Unsupervised Feature Selection via Nonnegative Orthogonal Constrained Regularized Minimization</title>
      <link>https://arxiv.org/abs/2403.16966</link>
      <description>arXiv:2403.16966v1 Announce Type: new 
Abstract: Unsupervised feature selection has drawn wide attention in the era of big data since it is a primary technique for dimensionality reduction. However, many existing unsupervised feature selection models and solution methods were presented for the purpose of application, and lack of theoretical support, e.g., without convergence analysis. In this paper, we first establish a novel unsupervised feature selection model based on regularized minimization with nonnegative orthogonal constraints, which has advantages of embedding feature selection into the nonnegative spectral clustering and preventing overfitting. An effective inexact augmented Lagrangian multiplier method is proposed to solve our model, which adopts the proximal alternating minimization method to solve subproblem at each iteration. We show that the sequence generated by our method globally converges to a Karush-Kuhn-Tucker point of our model. Extensive numerical experiments on popular datasets demonstrate the stability and robustness of our method. Moreover, comparison results of algorithm performance show that our method outperforms some existing state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16966v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Li, Defeng Sun, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>An Optimal Solution to Infinite Horizon Nonlinear Control Problems: Part II</title>
      <link>https://arxiv.org/abs/2403.16979</link>
      <description>arXiv:2403.16979v1 Announce Type: new 
Abstract: This paper considers the infinite horizon optimal control problem for nonlinear systems. Under the condition of nonlinear controllability of the system to any terminal set containing the origin and forward invariance of the terminal set, we establish a regularized solution approach consisting of a ``finite free final time" optimal transfer problem to the terminal set which renders the set globally asymptotically stable. Further, we show that the approximations converge to the optimal infinite horizon cost as the size of the terminal set decreases to zero. We also perform the analysis for the discounted problem and show that the terminal set is asymptotically stable only for a subset of the state space and not globally. The theory is empirically evaluated on various nonholonomic robotic systems to show that the cost of our approximate problem converges and the transfer time into the terminal set is dependent on the initial state of the system, necessitating the free final time formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16979v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Naveed Gul Mohamed, Aayushman Sharma, Raman Goyal, Suman Chakravorty</dc:creator>
    </item>
    <item>
      <title>Fuzzy hyperparameters update in a second order optimization</title>
      <link>https://arxiv.org/abs/2403.15416</link>
      <description>arXiv:2403.15416v1 Announce Type: cross 
Abstract: This research will present a hybrid approach to accelerate convergence in a second order optimization. An online finite difference approximation of the diagonal Hessian matrix will be introduced, along with fuzzy inferencing of several hyperparameters. Competitive results have been achieved</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15416v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abdelaziz Bensadok, Muhammad Zeeshan Babar</dc:creator>
    </item>
    <item>
      <title>Sparse additive function decompositions facing basis transforms</title>
      <link>https://arxiv.org/abs/2403.15563</link>
      <description>arXiv:2403.15563v1 Announce Type: cross 
Abstract: High-dimensional real-world systems can often be well characterized by a small number of simultaneous low-complexity interactions. The analysis of variance (ANOVA) decomposition and the anchored decomposition are typical techniques to find sparse additive decompositions of functions. In this paper, we are interested in a setting, where these decompositions are not directly spare, but become so after an appropriate basis transform. Noting that the sparsity of those additive function decompositions is equivalent to the fact that most of its mixed partial derivatives vanish, we can exploit a connection to the underlying function graphs to determine an orthogonal transform that realizes the appropriate basis change. This is done in three steps: we apply singular value decomposition to minimize the number of vertices of the function graph, and joint block diagonalization techniques of families of matrices followed by sparse minimization based on relaxations of the zero ''norm'' for minimizing the number of edges. For the latter one, we propose and analyze minimization techniques over the manifold of special orthogonal matrices. Various numerical examples illustrate the reliability of our approach for functions having, after a basis transform, a sparse additive decomposition into summands with at most two variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15563v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatima Antarou Ba, Oleh Melnyk, Christian Wald, Gabriele Steidl</dc:creator>
    </item>
    <item>
      <title>A Triangular Normal Form for x-Flat Control-Affine Two-Input Systems</title>
      <link>https://arxiv.org/abs/2403.15592</link>
      <description>arXiv:2403.15592v1 Announce Type: cross 
Abstract: This paper is devoted to normal forms for x-flat control-affine systems with two inputs. We propose a general triangular normal form which contains several other normal forms discussed in the literature as special cases. We derive conditions under which a system with given x-flat output can be transformed into the proposed triangular form. Based on the triangular form we motivate a simple algorithm for identifying candidates for flat outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15592v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conrad Gst\"ottner, Bernd Kolar, Markus Sch\"oberl</dc:creator>
    </item>
    <item>
      <title>The Effectiveness of Local Updates for Decentralized Learning under Data Heterogeneity</title>
      <link>https://arxiv.org/abs/2403.15654</link>
      <description>arXiv:2403.15654v1 Announce Type: cross 
Abstract: We revisit two fundamental decentralized optimization methods, Decentralized Gradient Tracking (DGT) and Decentralized Gradient Descent (DGD), with multiple local updates. We consider two settings and demonstrate that incorporating $K &gt; 1$ local update steps can reduce communication complexity. Specifically, for $\mu$-strongly convex and $L$-smooth loss functions, we proved that local DGT achieves communication complexity $\tilde{\mathcal{O}} \Big(\frac{L}{\mu K} + \frac{\delta}{\mu (1 - \rho)} + \frac{\rho }{(1 - \rho)^2} \cdot \frac{L+ \delta}{\mu}\Big)$, where $\rho$ measures the network connectivity and $\delta$ measures the second-order heterogeneity of the local loss. Our result reveals the tradeoff between communication and computation and shows increasing $K$ can effectively reduce communication costs when the data heterogeneity is low and the network is well-connected. We then consider the over-parameterization regime where the local losses share the same minimums, we proved that employing local updates in DGD, even without gradient correction, can yield a similar effect as DGT in reducing communication complexity. Numerical experiments validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15654v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongle Wu, Ying Sun</dc:creator>
    </item>
    <item>
      <title>Conservative Surrogate Models for Optimization with the Active Subspace Method</title>
      <link>https://arxiv.org/abs/2403.15678</link>
      <description>arXiv:2403.15678v1 Announce Type: cross 
Abstract: We are interested in building low-dimensional surrogate models to reduce optimization costs, while having theoretical guarantees that the optimum will satisfy the constraints of the full-size model, by making conservative approximations. The surrogate model is constructed using a Gaussian process regression (GPR). To ensure conservativeness, two new approaches are proposed: the first one using bootstrapping, and the second one using concentration inequalities. Those two techniques are based on a stochastic argument and thus will only enforce conservativeness up to a user-defined probability threshold. The method has applications in the context of optimization using the active subspace method for dimensionality reduction of the objective function and the constraints, addressing recorded issues about constraint violations. The resulting algorithms are tested on a toy optimization problem in thermal design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15678v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philippe-Andr\'e Luneau</dc:creator>
    </item>
    <item>
      <title>Causal Tracking of Distributions in Wasserstein Space: A Model Predictive Control Scheme</title>
      <link>https://arxiv.org/abs/2403.15702</link>
      <description>arXiv:2403.15702v1 Announce Type: cross 
Abstract: We consider the problem of optimal swarm tracking which can be formulated as a tracking problem for distributions in the Wasserstein metric. Optimal control solutions to this problem are non-causal and require knowing the time-trajectory of the distribution to be tracked in advance. We propose a scheme where these non-causal solutions can be used together with a predictive model for the reference to achieve causal tracking control of a priori-unknown references. We develop the resulting model-predictive control scheme in the simple case where the reference is predicted to be constant-in-time. A computational algorithm based on particle methods and discrete optimal mass transport is presented, and numerical simulations are provided for various classes of reference signals. The results demonstrate that the proposed control algorithm achieves reasonable performance even when using simple predictive models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15702v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Emerick, Jared Jonas, Bassam Bamieh</dc:creator>
    </item>
    <item>
      <title>Optimal Hospital Capacity Management During Demand Surges</title>
      <link>https://arxiv.org/abs/2403.15738</link>
      <description>arXiv:2403.15738v1 Announce Type: cross 
Abstract: Effective hospital capacity management is pivotal for enhancing patient care quality, operational efficiency, and healthcare system resilience, notably during demand spikes like those seen in the COVID-19 pandemic. However, devising optimal capacity strategies is complicated by fluctuating demand, conflicting objectives, and multifaceted practical constraints. This study presents a data-driven framework to optimize capacity management decisions within hospital systems during surge events. Two key decisions are optimized over a tactical planning horizon: allocating dedicated capacity to surge patients and transferring incoming patients between emergency departments (EDs) of hospitals to better distribute demand. The optimization models are formulated as robust mixed-integer linear programs, enabling efficient computation of optimal decisions that are robust against demand uncertainty. The models incorporate practical constraints and costs, including setup times and costs for adding surge capacity, restrictions on ED patient transfers, and relative costs of different decisions that reflect impacts on care quality and operational efficiency. The methodology is evaluated retrospectively in a hospital system during the height of the COVID-19 pandemic to demonstrate the potential impact of the recommended decisions. The results show that optimally allocating beds and transferring just 30 patients over a 63 day period around the peak, less than one transfer every two days, could have reduced the need for surge capacity in the hospital system by approximately 98%. Overall, this work introduces a practical tool to transform capacity management decision-making, enabling proactive planning and the use of data-driven recommendations to improve outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15738v1</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Parker, Fardin Ganjkhanloo, Diego A. Mart\'inez, Kimia Ghobadi</dc:creator>
    </item>
    <item>
      <title>Divergence conforming DG method for the optimal control of the Oseen equation with variable viscosity</title>
      <link>https://arxiv.org/abs/2403.15783</link>
      <description>arXiv:2403.15783v1 Announce Type: cross 
Abstract: This study introduces the divergence-conforming discontinuous Galerkin finite element method (DGFEM) for numerically approximating optimal control problems with distributed constraints, specifically those governed by stationary generalized Oseen equations. We provide optimal a priori error estimates in energy norms for such problems using the divergence-conforming DGFEM approach. Moreover, we thoroughly analyze $L^2$ error estimates for scenarios dominated by diffusion and convection. Additionally, we establish the new reliable and efficient a posteriori error estimators for the optimal control of the Oseen equation with variable viscosity. Theoretical findings are validated through numerical experiments conducted in both two and three dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15783v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harpal Singh, Arbaz Khan</dc:creator>
    </item>
    <item>
      <title>Semi-on-Demand Hybrid Transit Route Design with Shared Autonomous Mobility Services</title>
      <link>https://arxiv.org/abs/2403.15804</link>
      <description>arXiv:2403.15804v1 Announce Type: cross 
Abstract: This study examines the route design of a semi-on-demand hybrid route directional service in the public transit network, offering on-demand flexible route service in low-density areas and fixed route service in higher-density areas with Shared Autonomous Mobility Service (SAMS). The study develops analytically tractable cost expressions that capture access, waiting, and riding costs for users, and distance-based operating and time-based vehicle costs for operators. Two formulations are presented for strategic and tactical decisions in flexible route portion, fleet size, headway, and vehicle size optimization, enabling the determination of route types between fixed, hybrid, and flexible routes based on demand, cost, and operational parameters. The practical applications and benefits of semi-on-demand feeders are demonstrated with numerical examples and a large-scale case study in the Chicago metropolitan area. Findings reveal scenarios in which flexible route portions serving passengers located further away reduce total costs, particularly user costs. Lower operating costs in lower-demand areas favor more flexible routes, whereas higher demand densities favor more traditional line-based operations. On two studied lines, a current cost forecast favors smaller vehicles with flexible routes, but operating constraints and higher operating costs would favor bigger vehicles with hybrid routes. The study provides an analytical tool to design SAMS as directional services and transit feeders, and tractable continuous approximation formulations for future research in transit network design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15804v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Max T. M. Ng, Florian Dandl, Hani S. Mahmassani, Klaus Bogenberger</dc:creator>
    </item>
    <item>
      <title>Putting all eggs in one basket: some insights from a correlation inequality</title>
      <link>https://arxiv.org/abs/2403.15957</link>
      <description>arXiv:2403.15957v1 Announce Type: cross 
Abstract: We give examples of situations -- stochastic production, military tactics, corporate merger -- where it is beneficial to concentrate risk rather than to diversify it, that is, to put all eggs in one basket. Our examples admit a dual interpretation: as optimal strategies of a single player (the `principal') or, alternatively, as dominant strategies in a non-cooperative game with multiple players (the `agents').
  The key mathematical result can be formulated in terms of a convolution structure on the set of increasing functions on a Boolean lattice (the lattice of subsets of a finite set). This generalizes the well-known Harris inequality from statistical physics and discrete mathematics; we give a simple self-contained proof of this result, and prove a further generalization based on the game-theoretic approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15957v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pradeep Dubey, Siddhartha Sahi, Guanyang Wang</dc:creator>
    </item>
    <item>
      <title>Risk-Calibrated Human-Robot Interaction via Set-Valued Intent Prediction</title>
      <link>https://arxiv.org/abs/2403.15959</link>
      <description>arXiv:2403.15959v1 Announce Type: cross 
Abstract: Tasks where robots must cooperate with humans, such as navigating around a cluttered home or sorting everyday items, are challenging because they exhibit a wide range of valid actions that lead to similar outcomes. Moreover, zero-shot cooperation between human-robot partners is an especially challenging problem because it requires the robot to infer and adapt on the fly to a latent human intent, which could vary significantly from human to human. Recently, deep learned motion prediction models have shown promising results in predicting human intent but are prone to being confidently incorrect. In this work, we present Risk-Calibrated Interactive Planning (RCIP), which is a framework for measuring and calibrating risk associated with uncertain action selection in human-robot cooperation, with the fundamental idea that the robot should ask for human clarification when the risk associated with the uncertainty in the human's intent cannot be controlled. RCIP builds on the theory of set-valued risk calibration to provide a finite-sample statistical guarantee on the cumulative loss incurred by the robot while minimizing the cost of human clarification in complex multi-step settings. Our main insight is to frame the risk control problem as a sequence-level multi-hypothesis testing problem, allowing efficient calibration using a low-dimensional parameter that controls a pre-trained risk-aware policy. Experiments across a variety of simulated and real-world environments demonstrate RCIP's ability to predict and adapt to a diverse set of dynamic human intents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15959v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Lidard, Hang Pham, Ariel Bachman, Bryan Boateng, Anirudha Majumdar</dc:creator>
    </item>
    <item>
      <title>Digital control of negative imaginary systems: a discrete-time hybrid integrator-gain system approach</title>
      <link>https://arxiv.org/abs/2403.16046</link>
      <description>arXiv:2403.16046v1 Announce Type: cross 
Abstract: A hybrid integrator-gain system (HIGS) is a control element that switches between an integrator and a gain, which overcomes some inherent limitations of linear controllers. In this paper, we consider using discrete-time HIGS controllers for the digital control of negative imaginary (NI) systems. We show that the discrete-time HIGS themselves are step-advanced negative imaginary systems. For a minimal linear NI system, there always exists a HIGS controller that can asymptotically stablize it. An illustrative example is provided, where we use the proposed HIGS control method to stabilize a discrete-time mass-spring system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16046v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanghong Shi, Ian R. Petersen</dc:creator>
    </item>
    <item>
      <title>Manifold Regularization Classification Model Based On Improved Diffusion Map</title>
      <link>https://arxiv.org/abs/2403.16059</link>
      <description>arXiv:2403.16059v1 Announce Type: cross 
Abstract: Manifold regularization model is a semi-supervised learning model that leverages the geometric structure of a dataset, comprising a small number of labeled samples and a large number of unlabeled samples, to generate classifiers. However, the original manifold norm limits the performance of models to local regions. To address this limitation, this paper proposes an approach to improve manifold regularization based on a label propagation model. We initially enhance the probability transition matrix of the diffusion map algorithm, which can be used to estimate the Neumann heat kernel, enabling it to accurately depict the label propagation process on the manifold. Using this matrix, we establish a label propagation function on the dataset to describe the distribution of labels at different time steps. Subsequently, we extend the label propagation function to the entire data manifold. We prove that the extended label propagation function converges to a stable distribution after a sufficiently long time and can be considered as a classifier. Building upon this concept, we propose a viable improvement to the manifold regularization model and validate its superiority through experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16059v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongfu Guo, Wencheng Zou, Zeyu Zhang, Shuishan Zhang, Ruitong Wang, Jintao Zhang</dc:creator>
    </item>
    <item>
      <title>Towards a MATLAB Toolbox to compute backstepping kernels using the power series method</title>
      <link>https://arxiv.org/abs/2403.16070</link>
      <description>arXiv:2403.16070v1 Announce Type: cross 
Abstract: In this paper, we extend our previous work on the power series method for computing backstepping kernels. Our first contribution is the development of initial steps towards a MATLAB toolbox dedicated to backstepping kernel computation. This toolbox would exploit MATLAB's linear algebra and sparse matrix manipulation features for enhanced efficiency; our initial findings show considerable improvements in computational speed with respect to the use of symbolical software without loss of precision at high orders. Additionally, we tackle limitations observed in our earlier work, such as slow convergence (due to oscillatory behaviors) and non-converging series (due to loss of analiticity at some singular points). To overcome these challenges, we introduce a technique that mitigates this behaviour by computing the expansion at different points, denoted as localized power series. This approach effectively navigates around singularities, and can also accelerates convergence by using more local approximations. Basic examples are provided to demonstrate these enhancements. Although this research is still ongoing, the significant potential and simplicity of the method already establish the power series approach as a viable and versatile solution for solving backstepping kernel equations, benefiting both novel and experienced practitioners in the field. We anticipate that these developments will be particularly beneficial in training the recently introduced neural operators that approximate backstepping kernels and gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16070v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xin Lin, Rafael Vazquez, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>A Coupled Optimization Framework for Correlated Equilibria in Normal-Form Game</title>
      <link>https://arxiv.org/abs/2403.16223</link>
      <description>arXiv:2403.16223v1 Announce Type: cross 
Abstract: In competitive multi-player interactions, simultaneous optimality is a key requirement for establishing strategic equilibria. This property is explicit when the game-theoretic equilibrium is the simultaneously optimal solution of coupled optimization problems. However, no such optimization problems exist for the correlated equilibrium, a strategic equilibrium where the players can correlate their actions. We address the lack of a coupled optimization framework for the correlated equilibrium by introducing an {unnormalized game} -- an extension of normal-form games in which the player strategies are lifted to unnormalized measures over the joint actions. We show that the set of fully mixed generalized Nash equilibria of this unnormalized game is a subset of the correlated equilibrium of the normal-form game. Furthermore, we introduce an entropy regularization to the unnormalized game and prove that the entropy-regularized generalized Nash equilibrium is a sub-optimal correlated equilibrium of the normal form game where the degree of sub-optimality depends on the magnitude of regularization. We prove that the entropy-regularized unnormalized game has a closed-form solution, and empirically verify its computational efficacy at approximating the correlated equilibrium of normal-form games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16223v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah H. Q. Li, Yue Yu, Florian D\"orfler, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Mean Field Game of Mutual Holding with common noise</title>
      <link>https://arxiv.org/abs/2403.16232</link>
      <description>arXiv:2403.16232v1 Announce Type: cross 
Abstract: We consider the mean field game of cross--holding introduced in \citeauthor*{DjeteTouzi} \cite{DjeteTouzi} in the context where the equity value dynamics are affected by a common noise. In contrast with \cite{DjeteTouzi}, the problem exhibits the standard paradigm of mean--variance trade off. Our crucial observation is to search for equilibrium solutions of our mean field game among those models which satisfy an appropriate notion of no--arbitrage. Under this condition, it follows that the representative agent optimization step is reduced to a standard portfolio optimization problem with random endowment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16232v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leila Bassou, Mao Fabrice Djete, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Low Rank Groupwise Deformations for Motion Tracking in Cardiac Cine MRI</title>
      <link>https://arxiv.org/abs/2403.16240</link>
      <description>arXiv:2403.16240v1 Announce Type: cross 
Abstract: Diffeomorphic image registration is a commonly used method to deform one image to resemble another. While warping a single image to another is useful, it can be advantageous to warp multiple images simultaneously, such as in tracking the motion of the heart across a sequence of images. In this paper, our objective is to propose a novel method capable of registering a group or sequence of images to a target image, resulting in registered images that appear identical and therefore have a low rank. Moreover, we aim for these registered images to closely resemble the target image. Through experimental evidence, we will demonstrate our method's superior efficacy in producing low-rank groupwise deformations compared to other state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16240v1</guid>
      <category>cs.CV</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sean Rendell, Jinming Duan</dc:creator>
    </item>
    <item>
      <title>Algorithms of constrained uniform approximation</title>
      <link>https://arxiv.org/abs/2403.16330</link>
      <description>arXiv:2403.16330v1 Announce Type: cross 
Abstract: We address the problem of the best uniform approximation of a continuous function on a convex domain. The approximation is by linear combinations of a finite system of functions (not necessarily Chebyshev) under arbitrary linear constraints. By modifying the concept of alternance and of the Remez iterative procedure we present a method, which demonstrates its efficiency in numerical problems. The linear rate of convergence is proved under some favourable assumptions. A special attention is paid to systems of complex exponents, Gaussian functions, lacunar algebraic and trigonometric polynomials. Applications to signal processing, linear ODE, switching dynamical systems, and to Markov-Bernstein type inequalities are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16330v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vladimir Yu. Protasov, Rinat Kamalov</dc:creator>
    </item>
    <item>
      <title>On solution of tropical discrete best approximation problems</title>
      <link>https://arxiv.org/abs/2403.16337</link>
      <description>arXiv:2403.16337v1 Announce Type: cross 
Abstract: We consider a discrete best approximation problem formulated in the framework of tropical algebra, which deals with the theory and applications of algebraic systems with idempotent operations. Given a set of samples of input and output of an unknown function, the problem is to construct a generalized tropical Puiseux polynomial that best approximates the function in the sense of a tropical distance function. The construction of an approximate polynomial involves the evaluation of both unknown coefficient and exponent of each monomial in the polynomial. To solve the approximation problem, we first reduce the problem to an equation in unknown vector of coefficients, which is given by a matrix with entries parameterized by unknown exponents. We derive a best approximate solution of the equation, which yields both vector of coefficients and approximation error parameterized by the exponents. Optimal values of exponents are found by minimization of the approximation error, which is reduced to a minimization of a function of exponents over all partitions of a finite set. We solve this minimization problem in terms of max-plus algebra (where addition is defined as maximum and multiplication as arithmetic addition) by using a computational procedure based on the agglomerative clustering technique. This solution is extended to the minimization problem of finding optimal exponents in the polynomial in terms of max-algebra (where addition is defined as maximum). The results obtained are applied to develop new solutions for conventional problems of discrete best approximation of real functions by piecewise linear functions and piecewise Puiseux polynomials. We discuss computational complexity of the proposed solution and estimate upper bounds on the computational time. We demonstrate examples of approximation problems solved in terms of max-plus and max-algebra, and give graphical illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16337v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolai Krivulin</dc:creator>
    </item>
    <item>
      <title>Augmented Lagrangian method for coupled-cluster</title>
      <link>https://arxiv.org/abs/2403.16381</link>
      <description>arXiv:2403.16381v1 Announce Type: cross 
Abstract: We propose to improve the convergence properties of the single-reference coupled cluster (CC) method through an augmented Lagrangian formalism. The conventional CC method changes a linear high-dimensional eigenvalue problem with exponential size into a problem of determining the roots of a nonlinear system of equations that has a manageable size. However, current numerical procedures for solving this system of equations to get the lowest eigenvalue suffer from two practical issues: First, solving the CC equations may not converge, and second, when converging, they may converge to other -- potentially unphysical -- states, which are stationary points of the CC energy expression. We show that both issues can be dealt with when a suitably defined energy is minimized in addition to solving the original CC equations. We further propose an augmented Lagrangian method for coupled cluster (alm-CC) to solve the resulting constrained optimization problem. We numerically investigate the proposed augmented Lagrangian formulation showing that the convergence towards the ground state is significantly more stable and that the optimization procedure is less susceptible to local minima. Furthermore, the computational cost of alm-CC is comparable to the conventional CC method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16381v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian M. Faulstich, Yuehaw Khoo, Kangbo Li</dc:creator>
    </item>
    <item>
      <title>A Novel Loss Function-based Support Vector Machine for Binary Classification</title>
      <link>https://arxiv.org/abs/2403.16654</link>
      <description>arXiv:2403.16654v1 Announce Type: cross 
Abstract: The previous support vector machine(SVM) including $0/1$ loss SVM, hinge loss SVM, ramp loss SVM, truncated pinball loss SVM, and others, overlooked the degree of penalty for the correctly classified samples within the margin. This oversight affects the generalization ability of the SVM classifier to some extent. To address this limitation, from the perspective of confidence margin, we propose a novel Slide loss function ($\ell_s$) to construct the support vector machine classifier($\ell_s$-SVM). By introducing the concept of proximal stationary point, and utilizing the property of Lipschitz continuity, we derive the first-order optimality conditions for $\ell_s$-SVM. Based on this, we define the $\ell_s$ support vectors and working set of $\ell_s$-SVM. To efficiently handle $\ell_s$-SVM, we devise a fast alternating direction method of multipliers with the working set ($\ell_s$-ADMM), and provide the convergence analysis. The numerical experiments on real world datasets confirm the robustness and effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16654v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Li, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>SIS epidemics on open networks: A replacement-based approximation</title>
      <link>https://arxiv.org/abs/2403.16727</link>
      <description>arXiv:2403.16727v1 Announce Type: cross 
Abstract: In this paper we analyze continuous-time SIS epidemics subject to arrivals and departures of agents, by using an approximated process based on replacements. In defining the SIS dynamics in an open network, we consider a stochastic setting in which arrivals and departures take place according to Poisson processes with similar rates, and the new value of the infection probability of an arriving agent is drawn from a continuous distribution. Since the system size changes with time, we define an approximated process, in which replacements take place instead of arrivals and departures, and we focus on the evolution of an aggregate measure of the level of infection. So long as the reproduction number is less than one, the long-term behavior of this function measures the impact of the changes of the set of agents in the epidemic. We derive upper bounds for the expectation and variance of this function and we include a numerical example to show that the approximated process is close to the original SIS process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16727v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renato Vizuete, Paolo Frasca, Elena Panteley</dc:creator>
    </item>
    <item>
      <title>The stability of the multivariate geometric Brownian motion as a bilinear matrix inequality problem</title>
      <link>https://arxiv.org/abs/2403.16765</link>
      <description>arXiv:2403.16765v1 Announce Type: cross 
Abstract: In this manuscript, we study the stability of the origin for the multivariate geometric Brownian motion. More precisely, under suitable sufficient conditions, we construct a Lyapunov function such that the origin of the multivariate geometric Brownian motion is globally asymptotically stable in probability. Moreover, we show that such conditions can be rewritten as a Bilinear Matrix Inequality (BMI) feasibility problem. We stress that no commutativity relations between the drift matrix and the noise dispersion matrices are assumed and therefore the so-called Magnus representation of the solution of the multivariate geometric Brownian motion is complicated. In addition, we exemplify our method in numerous specific models from the literature such as random linear oscillators, satellite dynamics, inertia systems, diagonal noise systems, cancer self-remission and smoking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16765v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gerardo Barrera, Eyleifur Bjarkason, Sigurdur Hafstein</dc:creator>
    </item>
    <item>
      <title>Weak Convergence Analysis of Online Neural Actor-Critic Algorithms</title>
      <link>https://arxiv.org/abs/2403.16825</link>
      <description>arXiv:2403.16825v1 Announce Type: cross 
Abstract: We prove that a single-layer neural network trained with the online actor critic algorithm converges in distribution to a random ordinary differential equation (ODE) as the number of hidden units and the number of training steps $\rightarrow \infty$. In the online actor-critic algorithm, the distribution of the data samples dynamically changes as the model is updated, which is a key challenge for any convergence analysis. We establish the geometric ergodicity of the data samples under a fixed actor policy. Then, using a Poisson equation, we prove that the fluctuations of the model updates around the limit distribution due to the randomly-arriving data samples vanish as the number of parameter updates $\rightarrow \infty$. Using the Poisson equation and weak convergence techniques, we prove that the actor neural network and critic neural network converge to the solutions of a system of ODEs with random initial conditions. Analysis of the limit ODE shows that the limit critic network will converge to the true value function, which will provide the actor an asymptotically unbiased estimate of the policy gradient. We then prove that the limit actor network will converge to a stationary point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16825v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Chun-Hei Lam, Justin Sirignano, Ziheng Wang</dc:creator>
    </item>
    <item>
      <title>Optimality of spherical codes via exact semidefinite programming bounds</title>
      <link>https://arxiv.org/abs/2403.16874</link>
      <description>arXiv:2403.16874v1 Announce Type: cross 
Abstract: We show that the spectral embeddings of all known triangle-free strongly regular graphs are optimal spherical codes (the new cases are $56$ points in $20$ dimensions, $50$ points in $21$ dimensions, and $77$ points in $21$ dimensions), as are certain mutually unbiased basis arrangements constructed using Kerdock codes in up to $1024$ dimensions (namely, $2^{4k} + 2^{2k+1}$ points in $2^{2k}$ dimensions for $2 \le k \le 5$). As a consequence of the latter, we obtain optimality of the Kerdock binary codes of block length $64$, $256$, and $1024$, as well as uniqueness for block length $64$. We also prove universal optimality for $288$ points on a sphere in $16$ dimensions. To prove these results, we use three-point semidefinite programming bounds, for which only a few sharp cases were known previously. To obtain rigorous results, we develop improved techniques for rounding approximate solutions of semidefinite programs to produce exact optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16874v1</guid>
      <category>math.MG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Cohn, David de Laat, Nando Leijenhorst</dc:creator>
    </item>
    <item>
      <title>State-Augmented Linear Games with Antagonistic Error for High-Dimensional, Nonlinear Hamilton-Jacobi Reachability</title>
      <link>https://arxiv.org/abs/2403.16982</link>
      <description>arXiv:2403.16982v1 Announce Type: cross 
Abstract: Hamilton-Jacobi Reachability (HJR) is a popular method for analyzing the liveness and safety of a dynamical system with bounded control and disturbance. The corresponding HJ value function offers a robust controller and characterizes the reachable sets, but is traditionally solved with Dynamic Programming (DP) and limited to systems of dimension less than six. Recently, the space-parallelizeable, generalized Hopf formula has been shown to also solve the HJ value with a nearly three-log increase in dimension limit, but is limited to linear systems. To extend this potential, we demonstrate how state-augmented (SA) spaces, which are well-known for their improved linearization accuracy, may be used to solve tighter, conservative approximations of the value function with any linear model in this SA space. Namely, we show that with a representation of the true dynamics in the SA space, a series of inequalities confirms that the value of a SA linear game with antagonistic error is a conservative envelope of the true value function. It follows that if the optimal controller for the HJ SA linear game with error may succeed, it will also succeed in the true system. Unlike previous methods, this result offers the ability to safely approximate reachable sets and their corresponding controllers with the Hopf formula in a non-convex manner. Finally, we demonstrate this in the slow manifold system for clarity, and in the controlled Van der Pol system with different lifting functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16982v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Will Sharpless, Yat Tin Chow, Sylvia Herbert</dc:creator>
    </item>
    <item>
      <title>Tight Convergence Rate Bounds for Optimization Under Power Law Spectral Conditions</title>
      <link>https://arxiv.org/abs/2202.00992</link>
      <description>arXiv:2202.00992v3 Announce Type: replace 
Abstract: Performance of optimization on quadratic problems sensitively depends on the low-lying part of the spectrum. For large (effectively infinite-dimensional) problems, this part of the spectrum can often be naturally represented or approximated by power law distributions, resulting in power law convergence rates for iterative solutions of these problems by gradient-based algorithms. In this paper, we propose a new spectral condition providing tighter upper bounds for problems with power law optimization trajectories. We use this condition to build a complete picture of upper and lower bounds for a wide range of optimization algorithms -- Gradient Descent, Steepest Descent, Heavy Ball, and Conjugate Gradients -- with an emphasis on the underlying schedules of learning rate and momentum. In particular, we demonstrate how an optimally accelerated method, its schedule, and convergence upper bound can be obtained in a unified manner for a given shape of the spectrum. Also, we provide first proofs of tight lower bounds for convergence rates of Steepest Descent and Conjugate Gradients under spectral power laws with general exponents. Our experiments show that the obtained convergence bounds and acceleration strategies are not only relevant for exactly quadratic optimization problems, but also fairly accurate when applied to the training of neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.00992v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maksim Velikanov, Dmitry Yarotsky</dc:creator>
    </item>
    <item>
      <title>Extremely Fast Convergence Rates for Extremum Seeking Control with Polyak-Ruppert Averaging</title>
      <link>https://arxiv.org/abs/2206.00814</link>
      <description>arXiv:2206.00814v2 Announce Type: replace 
Abstract: Stochastic approximation is a foundation for many algorithms found in machine learning and optimization. It is in general slow to converge: the mean square error vanishes as $O(n^{-1})$. A deterministic counterpart known as quasi-stochastic approximation is a viable alternative in many applications, including gradient-free optimization and reinforcement learning. It was assumed in prior research that the optimal achievable convergence rate is $O(n^{-2})$. It is shown in this paper that through design it is possible to obtain far faster convergence, of order $O(n^{-4+\delta})$, with $\delta&gt;0$ arbitrary. Two techniques are introduced for the first time to achieve this rate of convergence. The theory is also specialized within the context of gradient-free optimization, and tested on standard benchmarks. The main results are based on a combination of novel application of results from number theory and techniques adapted from stochastic approximation theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.00814v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caio Kalil Lauand, Sean Meyn</dc:creator>
    </item>
    <item>
      <title>Learning Acceptability Criteria from Good and Bad Decisions: An Inverse Optimization Approach</title>
      <link>https://arxiv.org/abs/2207.02894</link>
      <description>arXiv:2207.02894v2 Announce Type: replace 
Abstract: Conventional inverse optimization inputs a solution and finds the parameters of an optimization model that render a given solution optimal. The literature mostly focuses on inferring the objective function in linear problems when acceptable solutions are provided as input. In this paper, we propose an inverse optimization model that inputs several accepted and rejected solutions and recovers the underlying convex optimization model that can be used to generate such solutions. The novelty of our model is three-fold: First, while most literature focuses on inferring the objective function, we focus on inferring the feasible region. Second, our model can infer the constraints of general convex optimization models. Third, the proposed model learns from accepted (good) and rejected (bad) observations in inferring the constraint set. The resulting inverse model is a mixed-integer nonlinear problem that is complex to solve. To mitigate the inverse problem complexity, we employ variational inequalities and the theoretical properties of the solutions to derive a reduced formulation that retains the complexity of its forward counterpart. We demonstrate that our inverse model can utilize a subset of past good and bad treatment plans to infer planning criteria that can lead to nearly guaranteed clinically acceptable plans for future patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.02894v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Houra Mahmoudzadeh, Kimia Ghobadi</dc:creator>
    </item>
    <item>
      <title>An adjoint-free algorithm for conditional nonlinear optimal perturbations (CNOPs) via sampling</title>
      <link>https://arxiv.org/abs/2208.00956</link>
      <description>arXiv:2208.00956v5 Announce Type: replace 
Abstract: In this paper, we propose a sampling algorithm based on state-of-the-art statistical machine learning techniques to obtain conditional nonlinear optimal perturbations (CNOPs), which is different from traditional (deterministic) optimization methods.1 Specifically, the traditional approach is unavailable in practice, which requires numerically computing the gradient (first-order information) such that the computation cost is expensive, since it needs a large number of times to run numerical models. However, the sampling approach directly reduces the gradient to the objective function value (zeroth-order information), which also avoids using the adjoint technique that is unusable for many atmosphere and ocean models and requires large amounts of storage. We show an intuitive analysis for the sampling algorithm from the law of large numbers and further present a Chernoff-type concentration inequality to rigorously characterize the degree to which the sample average probabilistically approximates the exact gradient. The experiments are implemented to obtain the CNOPs for two numerical models, the Burgers equation with small viscosity and the Lorenz-96 model. We demonstrate the CNOPs obtained with their spatial patterns, objective values, computation times, and nonlinear error growth. Compared with the performance of the three approaches, all the characters for quantifying the CNOPs are nearly consistent, while the computation time using the sampling approach with fewer samples is much shorter. In other words, the new sampling algorithm shortens the computation time to the utmost at the cost of losing little accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.00956v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>nlin.CD</category>
      <category>physics.ao-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.5194/npg-30-263-2023</arxiv:DOI>
      <arxiv:journal_reference>Nonlin. Processes Geophys.,30,263-276,2023</arxiv:journal_reference>
      <dc:creator>Bin Shi, Guodong Sun</dc:creator>
    </item>
    <item>
      <title>Aerial Base Station Placement via Propagation Radio Maps</title>
      <link>https://arxiv.org/abs/2301.04966</link>
      <description>arXiv:2301.04966v4 Announce Type: replace 
Abstract: The deployment of aerial base stations (ABSs) on unmanned aerial vehicles (UAVs) presents a promising solution for extending cellular connectivity to areas where terrestrial infrastructure is overloaded, damaged, or absent. A pivotal challenge in this domain is to decide the locations of a set of ABSs to effectively serve ground-based users. Most existing approaches oversimplify this problem by assuming that the channel gain between two points is a function of solely distance and, sometimes, also the elevation angle. In turn, this paper leverages propagation radio maps to account for arbitrary air-to-ground channel gains. This methodology enables the identification of an approximately minimal set of locations where ABSs need to be deployed to ensure that all ground terminals achieve a target service rate, while adhering to backhaul capacity limitations and avoiding designated no-fly zones. Relying on a convex relaxation technique and the alternating direction method of multipliers (ADMM), this paper puts forth a scalable solver whose computational complexity scales linearly with the number of ground terminals. Convergence is established analytically and an extensive set of simulations corroborate the merits of the proposed scheme relative to conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.04966v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Romero, Pham Q. Viet, Raju Shrestha</dc:creator>
    </item>
    <item>
      <title>A single player and a mass of agents: a pursuit evasion-like game</title>
      <link>https://arxiv.org/abs/2302.05742</link>
      <description>arXiv:2302.05742v2 Announce Type: replace 
Abstract: We study a finite-horizon differential game of pursuit-evasion like, between a single player and a mass of agents. The player and the mass directly control their own evolution, which for the mass is given by a first order PDE of transport equation type. Using also an adapted concept of non-anticipating strategies, we derive an infinite dimensional Isaacs equation, and by dynamic programming techniques we prove that the value function is the unique viscosity solution on a suitable invariant subset of a Hilbert space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.05742v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1051/cocv/2024009</arxiv:DOI>
      <arxiv:journal_reference>ESAIM: Control, Optimisation and Calculus of Variations, 30, 17 (2024)</arxiv:journal_reference>
      <dc:creator>Fabio Bagagiolo, Rossana Capuani, Luciano Marzufero</dc:creator>
    </item>
    <item>
      <title>The chain control set of discrete-time linear system on the affine two-dimensional Lie group</title>
      <link>https://arxiv.org/abs/2304.08705</link>
      <description>arXiv:2304.08705v4 Announce Type: replace 
Abstract: In this paper, we present conditions for the existence and uniqueness of chain control sets of discrete-time linear systems on the affine two-dimensional Lie group. More specifically, we prove that these chain control sets are given by the union of an infinite number of control sets with empty interiors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08705v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thiago Cavalheiro, Alexandre Santana, Jo\~ao Cossich</dc:creator>
    </item>
    <item>
      <title>Adaptive Softassign via Hadamard-Equipped Sinkhorn</title>
      <link>https://arxiv.org/abs/2309.13855</link>
      <description>arXiv:2309.13855v2 Announce Type: replace 
Abstract: Softassign is a pivotal method in graph matching and other learning tasks. Many softassign-based algorithms exhibit performance sensitivity to a parameter in the softassign. However, tuning the parameter is challenging and almost done empirically. This paper proposes an adaptive softassign method for graph matching by analyzing the relationship between the objective score and the parameter. This method can automatically tune the parameter based on a given error bound to guarantee accuracy. The Hadamard-Equipped Sinkhorn formulas introduced in this study significantly enhance the efficiency and stability of the adaptive softassign. Moreover, these formulas can also be used in optimal transport problems. The resulting adaptive softassign graph matching algorithm enjoys significantly higher accuracy than previous state-of-the-art large graph matching algorithms while maintaining comparable efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13855v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binrui Shen, Qiang Niu, Shengxin Zhu</dc:creator>
    </item>
    <item>
      <title>Combining Learning and Control in Linear Systems</title>
      <link>https://arxiv.org/abs/2310.14409</link>
      <description>arXiv:2310.14409v3 Announce Type: replace 
Abstract: In this paper, we provide a theoretical framework that separates the control and learning tasks in a linear system. This separation allows us to combine offline model-based control with online learning approaches and thus circumvent current challenges in deriving optimal control strategies in applications where a large volume of data is added to the system gradually in real time and not altogether in advance. We provide an analytical example to illustrate the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14409v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas A. Malikopoulos</dc:creator>
    </item>
    <item>
      <title>Best of Both Worlds Guarantees for Smoothed Online Quadratic Optimization</title>
      <link>https://arxiv.org/abs/2311.00181</link>
      <description>arXiv:2311.00181v2 Announce Type: replace 
Abstract: We study the smoothed online quadratic optimization (SOQO) problem where, at each round $t$, a player plays an action $x_t$ in response to a quadratic hitting cost and an additional squared $\ell_2$-norm cost for switching actions. This problem class has strong connections to a wide range of application domains including smart grid management, adaptive control, and data center management, where switching-efficient algorithms are highly sought after. We study the SOQO problem in both adversarial and stochastic settings, and in this process, perform the first stochastic analysis of this class of problems. We provide the online optimal algorithm when the minimizers of the hitting cost function evolve as a general stochastic process, which, for the case of martingale process, takes the form of a distribution-agnostic dynamic interpolation algorithm (LAI). Next, we present the stochastic-adversarial trade-off by proving an $\Omega(T)$ expected regret for the adversarial optimal algorithm in the literature (ROBD) with respect to LAI and, a sub-optimal competitive ratio for LAI in the adversarial setting. Finally, we present a best-of-both-worlds algorithm that obtains a robust adversarial performance while simultaneously achieving a near-optimal stochastic performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00181v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neelkamal Bhuyan, Debankur Mukherjee, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>An equivalent reformulation and multi-proximity gradient algorithms for a class of nonsmooth fractional programming</title>
      <link>https://arxiv.org/abs/2311.00957</link>
      <description>arXiv:2311.00957v2 Announce Type: replace 
Abstract: In this paper, we consider a class of structured fractional programs, where the numerator part is the sum of a block-separable (possibly nonsmooth nonconvex) function and a locally Lipschitz differentiable (possibly nonconvex) function, while the denominator is a convex (possibly nonsmooth) function. We first present a novel reformulation for the original problem and show the relationship between optimal solutions, critical points and KL exponents of these two problems. Inspired by the reformulation, we propose a flexible framework of multi-proximity gradient algorithms (MPGA), which computes the proximity operator with respect to the Fenchel conjugate associated with the convex denominator of the original problem rather than evaluating its subgradient as in the existing methods. Also, MPGA employs a nonmonotone linear-search scheme in its gradient descent step, since the smooth part in the numerator of the original problem is not globally Lipschitz differentiable. Based on the framework of MPGA, we develop two specific algorithms, namely, cyclic MPGA and randomized MPGA, and establish their subsequential convergence under mild conditions. Moreover, the sequential convergence of cyclic MPGA with the monotone line-search (CMPGA_ML) is guaranteed if the extended objective associated with the reformulated problem satisfies the Kurdyka-{\L}ojasiewicz (KL) property and some other mild assumptions. In particular, we prove that the corresponding KL exponents are 1/2 for several special cases of the fractional programs, and so, CMPGA_ML exhibits a linear convergence rate. Finally, some preliminary numerical experiments are performed to demonstrate the efficiency of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00957v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junpeng Zhou, Na Zhang, Qia Li</dc:creator>
    </item>
    <item>
      <title>Non-convex potential games for finding global solutions to sensor network localization</title>
      <link>https://arxiv.org/abs/2311.03326</link>
      <description>arXiv:2311.03326v2 Announce Type: replace 
Abstract: Sensor network localization (SNL) problems require determining the physical coordinates of all sensors in a network. This process relies on the global coordinates of anchors and the available measurements between non-anchor and anchor nodes. Attributed to the intrinsic non-convexity, obtaining a globally optimal solution to SNL is challenging, as well as implementing corresponding algorithms. In this paper, we formulate a non-convex multi-player potential game for a generic SNL problem to investigate the identification condition of the global Nash equilibrium (NE) therein, where the global NE represents the global solution of SNL. We employ canonical duality theory to transform the non-convex game into a complementary dual problem. Then we develop a conjugation-based algorithm to compute the stationary points of the complementary dual problem. On this basis, we show an identification condition of the global NE: the stationary point of the proposed algorithm satisfies a duality relation. Finally, simulation results are provided to validate the effectiveness of the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03326v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gehui Xu, Guanpu Chen, Yiguang Hong, Baris Fidan, Thomas Parisini, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Peak Estimation of Rational Systems using Convex Optimization</title>
      <link>https://arxiv.org/abs/2311.08321</link>
      <description>arXiv:2311.08321v2 Announce Type: replace 
Abstract: This paper presents algorithms that upper-bound the peak value of a state function along trajectories of a continuous-time system with rational dynamics. The finite-dimensional but nonconvex peak estimation problem is cast as a convex infinite-dimensional linear program in occupation measures. This infinite-dimensional program is then truncated into finite-dimensions using the moment-Sum-of-Squares (SOS) hierarchy of semidefinite programs. Prior work on treating rational dynamics using the moment-SOS approach involves clearing dynamics to common denominators or adding lifting variables to handle reciprocal terms under new equality constraints. Our solution method uses a sum-of-rational method based on absolute continuity of measures. The Moment-SOS truncations of our program possess lower computational complexity and (empirically demonstrated) higher accuracy of upper bounds on example systems as compared to prior approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08321v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Roy S. Smith</dc:creator>
    </item>
    <item>
      <title>Policy Evaluation in Distributional LQR (Extended Version)</title>
      <link>https://arxiv.org/abs/2401.10240</link>
      <description>arXiv:2401.10240v2 Announce Type: replace 
Abstract: Distributional reinforcement learning (DRL) enhances the understanding of the effects of the randomness in the environment by letting agents learn the distribution of a random return, rather than its expected value as in standard reinforcement learning. Meanwhile, a challenge in DRL is that the policy evaluation typically relies on the representation of the return distribution, which needs to be carefully designed. In this paper, we address this challenge for the special class of DRL problems that rely on a discounted linear quadratic regulator (LQR), which we call \emph{distributional LQR}. Specifically, we provide a closed-form expression for the distribution of the random return, which is applicable for all types of exogenous disturbance as long as it is independent and identically distributed (i.i.d.). We show that the variance of the random return is bounded if the fourth moment of the exogenous disturbance is bounded. Furthermore, we investigate the sensitivity of the return distribution to model perturbations. While the proposed exact return distribution consists of infinitely many random variables, we show that this distribution can be well approximated by a finite number of random variables. The associated approximation error can be analytically bounded under mild assumptions. When the model is unknown, we propose a model-free approach for estimating the return distribution, supported by sample complexity guarantees. Finally, we extend our approach to partially observable linear systems. Numerical experiments are provided to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10240v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifan Wang, Yulong Gao, Siyi Wang, Michael M. Zavlanos, Alessandro Abate, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Decentralized Finite-Sum Optimization over Time-Varying Networks</title>
      <link>https://arxiv.org/abs/2402.02490</link>
      <description>arXiv:2402.02490v2 Announce Type: replace 
Abstract: We consider decentralized time-varying stochastic optimization problems where each of the functions held by the nodes has a finite sum structure. Such problems can be efficiently solved using variance reduction techniques. Our aim is to explore the lower complexity bounds (for communication and number of stochastic oracle calls) and find optimal algorithms. The paper studies strongly convex and nonconvex scenarios. To the best of our knowledge, variance reduced schemes and lower bounds for time-varying graphs have not been studied in the literature. For nonconvex objectives, we obtain lower bounds and develop an optimal method GT-PAGE. For strongly convex objectives, we propose the first decentralized time-varying variance-reduction method ADOM+VR and establish lower bound in this scenario, highlighting the open question of matching the algorithms complexity and lower bounds even in static network case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02490v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Metelev, Savelii Chezhegov, Alexander Rogozin, Aleksandr Beznosikov, Alexander Sholokhov, Alexander Gasnikov, Dmitry Kovalev</dc:creator>
    </item>
    <item>
      <title>Tikhonov Regularization for Stochastic Non-Smooth Convex Optimization in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2403.06708</link>
      <description>arXiv:2403.06708v2 Announce Type: replace 
Abstract: To solve non-smooth convex optimization problems with a noisy gradient input, we analyze the global behavior of subgradient-like flows under stochastic errors. The objective function is composite, being equal to the sum of two convex functions, one being differentiable and the other potentially non-smooth. We then use stochastic differential inclusions where the drift term is minus the subgradient of the objective function, and the diffusion term is either bounded or square-integrable. In this context, under Lipschitz's continuity of the differentiable term and a growth condition of the non-smooth term, our first main result shows almost sure weak convergence of the trajectory process towards a minimizer of the objective function. Then, using Tikhonov regularization with a properly tuned vanishing parameter, we can obtain almost sure strong convergence of the trajectory towards the minimum norm solution. We find an explicit tuning of this parameter when our objective function satisfies a local error-bound inequality. We also provide a comprehensive complexity analysis by establishing several new pointwise and ergodic convergence rates in expectation for the convex and strongly convex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06708v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Hedy Attouch</dc:creator>
    </item>
    <item>
      <title>A Low-Rank ADMM Splitting Approach for Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2403.09133</link>
      <description>arXiv:2403.09133v2 Announce Type: replace 
Abstract: We introduce a new first-order method for solving general semidefinite programming problems, based on the alternating direction method of multipliers (ADMM) and a matrix-splitting technique. Our algorithm has an advantage over the Burer-Monteiro approach as it only involves much easier quadratically regularized subproblems in each iteration. For a linear objective, the subproblems are well-conditioned quadratic programs that can be efficiently solved by the standard conjugate gradient method. We show that the ADMM algorithm achieves sublinear or linear convergence rates to the KKT solutions under different conditions. Building on this theoretical development, we present LoRADS, a new solver for linear SDP based on the Low-Rank ADMM Splitting approach. LoRADS incorporates several strategies that significantly increase its efficiency. Firstly, it initiates with a warm-start phase that uses the Burer-Monteiro approach. Moreover, motivated by the SDP low-rank theory [So et al. 2008], LoRADS chooses an initial rank of logarithmic order and then employs a dynamic approach to increase the rank. Numerical experiments indicate that LoRADS exhibits promising performance on various SDP problems. A noteworthy achievement of LoRADS is its successful solving of a matrix completion problem with $15,694,167$ constraints and a matrix variable of size $40,000 \times 40,000$ in $351$ seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09133v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushi Han, Chenxi Li, Zhenwei Lin, Caihua Chen, Qi Deng, Dongdong Ge, Huikang Liu, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Markovian lifting and optimal control for integral stochastic Volterra equations with completely monotone kernels</title>
      <link>https://arxiv.org/abs/2403.12875</link>
      <description>arXiv:2403.12875v2 Announce Type: replace 
Abstract: In this paper, we focus on solving the optimal control problem for integral stochastic Volterra equations in a finite dimensional setting. In our setting, the noise term is driven by a pure jump L\'evy noise and the control acts on the intensity of the jumps.
  We use recent techniques proposed by Hamaguchi, where a crucial requirement is that the convolution kernel should be a completely monotone function. This allows us to use Bernstein's representation and the machinery of Laplace transform to obtain a Markovian lift.
  It is natural that the Markovian lift, in whatever form constructed, transforms the state equation into a stochastic differential equation in an infinite-dimensional space. This space should be large enough to contain all the information about the history of the process. Hence, although the original equation is taken in a finite dimensional space, the resulting lift is always infinite dimensional.
  We solve the problem by using the forward-backward approach in the infinite-dimensional setting and prove the existence of the optimal control for the original problem. Under additional assumptions on the coefficients, we see that a control in closed-loop form can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12875v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Bonaccorsi, Fulvia Confortola</dc:creator>
    </item>
    <item>
      <title>Consensus-Based Optimization Methods Converge Globally</title>
      <link>https://arxiv.org/abs/2103.15130</link>
      <description>arXiv:2103.15130v5 Announce Type: replace-cross 
Abstract: In this paper we study consensus-based optimization (CBO), which is a multi-agent metaheuristic derivative-free optimization method that can globally minimize nonconvex nonsmooth functions and is amenable to theoretical analysis. Based on an experimentally supported intuition that, on average, CBO performs a gradient descent of the squared Euclidean distance to the global minimizer, we devise a novel technique for proving the convergence to the global minimizer in mean-field law for a rich class of objective functions. The result unveils internal mechanisms of CBO that are responsible for the success of the method. In particular, we prove that CBO performs a convexification of a large class of optimization problems as the number of optimizing agents goes to infinity. Furthermore, we improve prior analyses by requiring mild assumptions about the initialization of the method and by covering objectives that are merely locally Lipschitz continuous. As a core component of this analysis, we establish a quantitative nonasymptotic Laplace principle, which may be of independent interest. From the result of CBO convergence in mean-field law, it becomes apparent that the hardness of any global optimization problem is necessarily encoded in the rate of the mean-field approximation, for which we provide a novel probabilistic quantitative estimate. The combination of these results allows to obtain probabilistic global convergence guarantees of the numerical CBO method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.15130v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Massimo Fornasier, Timo Klock, Konstantin Riedl</dc:creator>
    </item>
    <item>
      <title>Convergence of Anisotropic Consensus-Based Optimization in Mean-Field Law</title>
      <link>https://arxiv.org/abs/2111.08136</link>
      <description>arXiv:2111.08136v2 Announce Type: replace-cross 
Abstract: In this paper we study anisotropic consensus-based optimization (CBO), a multi-agent metaheuristic derivative-free optimization method capable of globally minimizing nonconvex and nonsmooth functions in high dimensions. CBO is based on stochastic swarm intelligence, and inspired by consensus dynamics and opinion formation. Compared to other metaheuristic algorithms like particle swarm optimization, CBO is of a simpler nature and therefore more amenable to theoretical analysis. By adapting a recently established proof technique, we show that anisotropic CBO converges globally with a dimension-independent rate for a rich class of objective functions under minimal assumptions on the initialization of the method. Moreover, the proof technique reveals that CBO performs a convexification of the optimization problem as the number of agents goes to infinity, thus providing an insight into the internal CBO mechanisms responsible for the success of the method. To motivate anisotropic CBO from a practical perspective, we further test the method on a complicated high-dimensional benchmark problem, which is well understood in the machine learning literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.08136v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-02462-7_46</arxiv:DOI>
      <arxiv:journal_reference>Applications of Evolutionary Computation. EvoApplications 2022. Lecture Notes in Computer Science, vol 13224, pages 738-754, 2022</arxiv:journal_reference>
      <dc:creator>Massimo Fornasier, Timo Klock, Konstantin Riedl</dc:creator>
    </item>
    <item>
      <title>Exponential Concentration in Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2208.07243</link>
      <description>arXiv:2208.07243v4 Announce Type: replace-cross 
Abstract: We analyze the behavior of stochastic approximation algorithms where iterates, in expectation, progress towards an objective at each step. When progress is proportional to the step size of the algorithm, we prove exponential concentration bounds. These tail-bounds contrast asymptotic normality results, which are more frequently associated with stochastic approximation. The methods that we develop rely on a geometric ergodicity proof. This extends a result on Markov chains due to Hajek (1982) to the area of stochastic approximation algorithms. We apply our results to several different Stochastic Approximation algorithms, specifically Projected Stochastic Gradient Descent, Kiefer-Wolfowitz and Stochastic Frank-Wolfe algorithms. When applicable, our results prove faster $O(1/t)$ and linear convergence rates for Projected Stochastic Gradient Descent with a non-vanishing gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07243v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kody Law, Neil Walton, Shangda Yang</dc:creator>
    </item>
    <item>
      <title>A Tikhonov theorem for McKean-Vlasov two-scale systems and a new application to mean field optimal control problems</title>
      <link>https://arxiv.org/abs/2212.12293</link>
      <description>arXiv:2212.12293v2 Announce Type: replace-cross 
Abstract: We provide a new version of the Tikhonov theorem for both two-scale forward systems and also two-scale forward-backward systems of stochastic differential equations, which also covers the McKean-Vlasov case. Differently from what is usually done in the literature, we prove a type of convergence for the ''fast'' variable, which allows the limiting process to be discontinuous. This is relevant for the second part of the paper, where we present a new application of this theory to the approximation of the solution of mean field control problems. Towards this aim, we construct a two-scale system whose ''fast'' component converges to the optimal control process, while the ''slow'' component converges to the optimal state process. The interest in such a procedure is that it allows to approximate the solution of the control problem avoiding the usual step of the minimization of the Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12293v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Burzoni, Alekos Cecchin, Andrea Cosso</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Stochastic Gradient Descent with MCMC Estimators</title>
      <link>https://arxiv.org/abs/2303.10599</link>
      <description>arXiv:2303.10599v2 Announce Type: replace-cross 
Abstract: Understanding stochastic gradient descent (SGD) and its variants is essential for machine learning. However, most of the preceding analyses are conducted under amenable conditions such as unbiased gradient estimator and bounded objective functions, which does not encompass many sophisticated applications, such as variational Monte Carlo, entropy-regularized reinforcement learning and variational inference. In this paper, we consider the SGD algorithm that employ the Markov Chain Monte Carlo (MCMC) estimator to compute the gradient, called MCMC-SGD. Since MCMC reduces the sampling complexity significantly, it is an asymptotically convergent biased estimator in practice. Moreover, by incorporating a general class of unbounded functions, it is much more difficult to analyze the MCMC sampling error. Therefore, we assume that the function is sub-exponential and use the Bernstein inequality for non-stationary Markov chains to derive error bounds of the MCMC estimator. Consequently, MCMC-SGD is proven to have a first order convergence rate $O(\log K/\sqrt{n K})$ with $K$ iterations and a sample size $n$. It partially explains how MCMC influences the behavior of SGD. Furthermore, we verify the correlated negative curvature condition under reasonable assumptions. It is shown that MCMC-SGD escapes from saddle points and reaches $(\epsilon,\epsilon^{1/4})$ approximate second order stationary points or $\epsilon^{1/2}$-variance points at least $O(\epsilon^{-11/2}\log^{2}(1/\epsilon) )$ steps with high probability. Our analysis unveils the convergence pattern of MCMC-SGD across a broad class of stochastic optimization problems, and interprets the convergence phenomena observed in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.10599v2</guid>
      <category>stat.ML</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyou Li, Fan Chen, Huajie Chen, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Exact controllability of incompressible ideal magnetohydrodynamics in $2$D</title>
      <link>https://arxiv.org/abs/2306.03712</link>
      <description>arXiv:2306.03712v2 Announce Type: replace-cross 
Abstract: This work examines the controllability of planar incompressible ideal magnetohydrodynamics (MHD). Interior controls are obtained for problems posed in doubly-connected regions; simply-connected configurations are driven by boundary controls. Up to now, only straight channels regulated at opposing walls have been studied. Hence, the present program adds to the literature an exploration of interior controllability, extends the known boundary controllability results, and contributes ideas for treating general domains. To transship obstacles stemming from the MHD coupling and the magnetic field topology, a divide-and-control strategy is proposed. This leads to a family of nonlinear velocity-controlled sub-problems which are solved using J.-M. Coron's return method. The latter is here developed based on a reference trajectory in the domain's first cohomology space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03712v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Rissel</dc:creator>
    </item>
    <item>
      <title>PowerSimulationsDynamics.jl -- An Open Source Modeling Package for Modern Power Systems with Inverter-Based Resources</title>
      <link>https://arxiv.org/abs/2308.02921</link>
      <description>arXiv:2308.02921v3 Announce Type: replace-cross 
Abstract: In this paper we present the development of an open-source simulation toolbox, PowerSimulationsDynamics.jl, to study the dynamic response of power systems, focusing on the requirements to model systems with high penetrations of Inverter-Based Resources (IBRs). PowerSimulationsDynamics.jl is implemented in Julia and features a rich library of synchronous generator, inverter, and load models. In addition, it allows the study of quasi-static phasors and electromagnetic dq models that use a dynamic network representation. Case studies and validation exercises show that PowerSimulationsDynamics.jl results closely match other commercial and open-source simulation tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02921v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Daniel Lara, Rodrigo Henriquez-Auba, Matthew Bossart, Duncan S. Callaway, Clayton Barrows</dc:creator>
    </item>
    <item>
      <title>A Traffic Management Framework for On-Demand Urban Air Mobility Systems</title>
      <link>https://arxiv.org/abs/2309.07139</link>
      <description>arXiv:2309.07139v2 Announce Type: replace-cross 
Abstract: Urban Air Mobility (UAM) offers a solution to current traffic congestion by providing on-demand air mobility in urban areas. Effective traffic management is crucial for efficient operation of UAM systems, especially for high-demand scenarios. In this paper, we present a centralized traffic management framework for on-demand UAM systems. Specifically, we provide a scheduling policy, called VertiSync, which schedules the aircraft for either servicing trip requests or rebalancing in the system subject to aircraft safety margins and energy requirements. We characterize the system-level throughput of VertiSync, which determines the demand threshold at which passenger waiting times transition from being stabilized to being increasing over time. We show that the proposed policy is able to maximize throughput for sufficiently large fleet sizes. We demonstrate the performance of VertiSync through a case study for the city of Los Angeles, and show that it significantly reduces passenger waiting times compared to a first-come first-serve scheduling policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07139v2</guid>
      <category>cs.NI</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Milad Pooladsanj, Ketan Savla, Petros A. Ioannou</dc:creator>
    </item>
    <item>
      <title>Latent assimilation with implicit neural representations for unknown dynamics</title>
      <link>https://arxiv.org/abs/2309.09574</link>
      <description>arXiv:2309.09574v2 Announce Type: replace-cross 
Abstract: Data assimilation is crucial in a wide range of applications, but it often faces challenges such as high computational costs due to data dimensionality and incomplete understanding of underlying mechanisms. To address these challenges, this study presents a novel assimilation framework, termed Latent Assimilation with Implicit Neural Representations (LAINR). By introducing Spherical Implicit Neural Representations (SINR) along with a data-driven uncertainty estimator of the trained neural networks, LAINR enhances efficiency in assimilation process. Experimental results indicate that LAINR holds certain advantage over existing methods based on AutoEncoders, both in terms of accuracy and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09574v2</guid>
      <category>cs.LG</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>physics.ao-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2024.112953</arxiv:DOI>
      <dc:creator>Zhuoyuan Li, Bin Dong, Pingwen Zhang</dc:creator>
    </item>
    <item>
      <title>Hybrid physics-informed metabolic cybergenetics: process rates augmented with machine-learning surrogates informed by flux balance analysis</title>
      <link>https://arxiv.org/abs/2401.00670</link>
      <description>arXiv:2401.00670v2 Announce Type: replace-cross 
Abstract: Metabolic cybergenetics is a promising concept that interfaces gene expression and cellular metabolism with computers for real-time dynamic metabolic control. The focus is on control at the transcriptional level, serving as a means to modulate intracellular metabolic fluxes. Recent strategies in this field have employed constraint-based dynamic models for process optimization, control, and estimation. However, this results in bilevel dynamic optimization problems, which pose considerable numerical and conceptual challenges. In this study, we present an alternative hybrid physics-informed dynamic modeling framework for metabolic cybergenetics, aimed at simplifying optimization, control, and estimation tasks. By utilizing machine-learning surrogates, our approach effectively embeds the physics of metabolic networks into the process rates of structurally simpler macro-kinetic models coupled with gene expression. These surrogates, informed by flux balance analysis, link the domains of manipulatable intracellular enzymes to metabolic exchange fluxes. This ensures that critical knowledge captured by the system's metabolic network is preserved. The resulting models can be integrated into metabolic cybergenetic schemes involving single-level optimizations. Additionally, the hybrid modeling approach maintains the number of system states at a necessary minimum, easing the burden of process monitoring and estimation. Our hybrid physics-informed metabolic cybergenetic framework is demonstrated using a computational case study on the optogenetically-assisted production of itaconate by $\textit{Escherichia coli}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00670v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebasti\'an Espinel-R\'ios, Jos\'e L. Avalos</dc:creator>
    </item>
    <item>
      <title>Stochastic Hessian Fittings on Lie Groups</title>
      <link>https://arxiv.org/abs/2402.11858</link>
      <description>arXiv:2402.11858v2 Announce Type: replace-cross 
Abstract: This paper studies the fitting of Hessian or its inverse for stochastic optimizations using a Hessian fitting criterion from the preconditioned stochastic gradient descent (PSGD) method, which is intimately related to many commonly used second order and adaptive gradient optimizers, e.g., BFGS, Gaussian-Newton and natural gradient descent, AdaGrad, etc. Our analyses reveal the efficiency and reliability differences among a wide range of preconditioner fitting methods, from closed-form to iterative solutions, using Hessian-vector products or stochastic gradients only, with Hessian fittings in the Euclidean space, the manifold of symmetric positive definite (SPL) matrices, or a variety of Lie groups. The most intriguing discovery is that the Hessian fitting itself as an optimization problem is strongly convex under mild conditions on a specific yet general enough Lie group. This discovery turns Hessian fitting into a well behaved optimization problem, and facilitates the designs of highly efficient and elegant Lie group sparse preconditioner fitting methods for large scale stochastic optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11858v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi-Lin Li</dc:creator>
    </item>
    <item>
      <title>Performance-Guaranteed Solutions for Multi-Agent Optimal Coverage Problems using Submodularity, Curvature, and Greedy Algorithms</title>
      <link>https://arxiv.org/abs/2403.14028</link>
      <description>arXiv:2403.14028v2 Announce Type: replace-cross 
Abstract: We consider a class of multi-agent optimal coverage problems in which the goal is to determine the optimal placement of a group of agents in a given mission space so that they maximize a coverage objective that represents a blend of individual and collaborative event detection capabilities. This class of problems is extremely challenging due to the non-convex nature of the mission space and of the coverage objective. With this motivation, greedy algorithms are often used as means of getting feasible coverage solutions efficiently. Even though such greedy solutions are suboptimal, the submodularity (diminishing returns) property of the coverage objective can be exploited to provide performance bound guarantees. Moreover, we show that improved performance bound guarantees (beyond the standard (1-1/e) performance bound) can be established using various curvature measures of the coverage problem. In particular, we provide a brief review of all existing popular applicable curvature measures, including a recent curvature measure that we proposed, and discuss their effectiveness and computational complexity, in the context of optimal coverage problems. We also propose novel computationally efficient techniques to estimate some curvature measures. Finally, we provide several numerical results to support our findings and propose several potential future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14028v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shirantha Welikala, Christos G. Cassandras</dc:creator>
    </item>
  </channel>
</rss>
