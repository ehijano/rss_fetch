<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Jan 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Some Applications envisaged for the new generation of communications networks 6G</title>
      <link>https://arxiv.org/abs/2501.14117</link>
      <description>arXiv:2501.14117v1 Announce Type: new 
Abstract: Future applications such as intelligent vehicles, the Internet of Things and holographic telepresence are already highlighting the limits of existing fifth-generation (5G) mobile networks. These limitations relate to data throughput, latency, reliability, availability, processing, connection density and global coverage, whether terrestrial, submarine or space-based. To remedy this, research institutes have begun to look beyond IMT2020, and as a result, 6G should provide effective solutions to 5G shortcomings. 6G will offer high quality of service and energy efficiency to meet the demands of future applications that are unimaginable to most people. In this article, we present the future applications and services promised by 6G.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14117v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The 1st National Conference on Electronics, Electrical Engineering, Telecommunications, and Computer Vision 11/6/2023 Boumerdes, Algeria</arxiv:journal_reference>
      <dc:creator>Sofiane Latreche, Hocine Bellahsene, Abdelmalik Taleb-Ahmed</dc:creator>
    </item>
    <item>
      <title>Serving Long-Context LLMs at the Mobile Edge: Test-Time Reinforcement Learning-based Model Caching and Inference Offloading</title>
      <link>https://arxiv.org/abs/2501.14205</link>
      <description>arXiv:2501.14205v1 Announce Type: new 
Abstract: Large Language Models (LLMs) can perform zero-shot learning on unseen tasks and few-shot learning on complex reasoning tasks. However, resource-limited mobile edge networks struggle to support long-context LLM serving for LLM agents during multi-round interactions with users. Unlike stateless computation offloading and static service offloading in edge computing, optimizing LLM serving at edge servers is challenging because LLMs continuously learn from context which raises accuracy, latency, and resource consumption dynamics. In this paper, we propose a joint model caching and inference offloading framework that utilizes test-time deep reinforcement learning (T2DRL) to optimize deployment and execution strategies for long-context LLM serving. In this framework, we analyze the performance convergence and design an optimization problem considering the utilization of context windows in LLMs. Furthermore, the T2DRL algorithm can learn in both the training phase and the testing phase to proactively manage cached models and service requests and adapt to context changes and usage patterns during execution. To further enhance resource allocation efficiency, we propose a double Dutch auction (DDA) mechanism, which dynamically matches supply and demand while maximizing social welfare. Finally, experimental results demonstrate that the T2DRL algorithm can reduce system costs by at least 30% compared to baselines while guaranteeing the performance of LLM agents in real-world perception and reasoning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14205v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minrui Xu, Dusit Niyato, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Joint System Latency and Data Freshness Optimization for Cache-enabled Mobile Crowdsensing Networks</title>
      <link>https://arxiv.org/abs/2501.14367</link>
      <description>arXiv:2501.14367v1 Announce Type: new 
Abstract: Mobile crowdsensing (MCS) networks enable large-scale data collection by leveraging the ubiquity of mobile devices. However, frequent sensing and data transmission can lead to significant resource consumption. To mitigate this issue, edge caching has been proposed as a solution for storing recently collected data. Nonetheless, this approach may compromise data freshness. In this paper, we investigate the trade-off between re-using cached task results and re-sensing tasks in cache-enabled MCS networks, aiming to minimize system latency while maintaining information freshness. To this end, we formulate a weighted delay and age of information (AoI) minimization problem, jointly optimizing sensing decisions, user selection, channel selection, task allocation, and caching strategies. The problem is a mixed-integer non-convex programming problem which is intractable. Therefore, we decompose the long-term problem into sequential one-shot sub-problems and design a framework that optimizes system latency, task sensing decision, and caching strategy subproblems. When one task is re-sensing, the one-shot problem simplifies to the system latency minimization problem, which can be solved optimally. The task sensing decision is then made by comparing the system latency and AoI. Additionally, a Bayesian update strategy is developed to manage the cached task results. Building upon this framework, we propose a lightweight and time-efficient algorithm that makes real-time decisions for the long-term optimization problem. Extensive simulation results validate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14367v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Shi, Yaru Fu, Yongna Guo, Fu Lee Wang, Yan Zhang</dc:creator>
    </item>
    <item>
      <title>Application-Aware Resource Allocation and Data Management for MEC-assisted IoT Service Providers</title>
      <link>https://arxiv.org/abs/2501.14387</link>
      <description>arXiv:2501.14387v1 Announce Type: new 
Abstract: To support the growing demand for data-intensive and low-latency IoT applications, Multi-Access Edge Computing (MEC) is emerging as an effective edge-computing approach enabling the execution of delay-sensitive processing tasks close to end-users. However, most of the existing works on resource allocation and service placement in MEC systems overlook the unique characteristics of new IoT use cases. For instance, many IoT applications require the periodic execution of computing tasks on real-time data streams that originate from devices dispersed over a wide area. Thus, users requesting IoT services are typically distant from the data producers. To fill this gap, the contribution of this work is two-fold. Firstly, we propose a MEC-compliant architectural solution to support the operation of multiple IoT service providers over a common MEC platform deployment, which enables the steering and shaping of IoT data transport within the platform. Secondly, we model the problem of service placement and data management in the proposed MEC-based solution taking into account the dependencies at the data level between IoT services and sensing resources. Our model also considers that caches can be deployed on MEC hosts, to allow the sharing of the same data between different IoT services with overlapping geographical scope, and provides support for IoT services with heterogeneous QoS requirements, such as different frequencies of periodic task execution. Due to the complexity of the optimisation problem, a heuristic algorithm is proposed using linear relaxation and rounding techniques. Extensive simulation results demonstrate the efficiency of the proposed approach, especially when traffic demands generated by the service requests are not uniform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14387v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jnca.2021.103020</arxiv:DOI>
      <arxiv:journal_reference>Journal of Network and Computer Applications, Volume 181, 1 May 2021, 103020</arxiv:journal_reference>
      <dc:creator>Simone Bolettieri, Raffaele Bruno, Enzo Mingozzi</dc:creator>
    </item>
    <item>
      <title>Empirical Line-of-Sight Probability Modeling for UAVs in Random Urban Layouts</title>
      <link>https://arxiv.org/abs/2501.14389</link>
      <description>arXiv:2501.14389v1 Announce Type: new 
Abstract: Accurate Probability of Line-of-Sight (PLoS) modeling is important in evaluating the performance of Unmanned Aerial Vehicle (UAV)-based communication systems in urban environments, where real-time communication and low latency are often major requirements. Existing PLoS models often rely on simplified Manhattan grid layouts using International Telecommunication Union (ITU)-defined built-up parameters, which may not reflect the randomness of real cities. Therefore, this paper introduces the Urban LoS Simulator (ULS) to model PLoS for three random city layouts with varying building sizes and shapes constructed using ITU built-up parameters. Based on the ULS simulated data, we obtained the empirical PLoS for four standard urban environments across three different city layouts. Finally, we analyze how well Manhattan grid-based models replicate PLoS results from random and real-world layouts, providing insights into their applicability for time-critical communication systems in urban IoT networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14389v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul Saboor, Zhuangzhuang Cui, Evgenii Vinogradov, Sofie Pollin</dc:creator>
    </item>
    <item>
      <title>Path Loss Modelling for UAV Communications in Urban Scenarios with Random Obstacles</title>
      <link>https://arxiv.org/abs/2501.14411</link>
      <description>arXiv:2501.14411v1 Announce Type: new 
Abstract: Path Loss (PL) is vital to evaluate the performance of Unmanned Aerial Vehicles (UAVs) as Aerial Base Stations (ABSs), particularly in urban environments with complex propagation due to various obstacles. Accurately modeling PL requires a generalized Probability of Line-of-Sight (PLoS) that can consider multiple obstructions. While the existing PLoS models mostly assume a simplified Manhattan grid with uniform building sizes and spacing, they overlook the real-world variability in building dimensions. Furthermore, such models do not consider other obstacles, such as trees and streetlights, which may also impact the performance, especially in millimeter-wave (mmWave) bands. This paper introduces a Manhattan Random Simulator (MRS) to estimate PLoS for UAV-based communications in urban areas by incorporating irregular building shapes, non-uniform spacing, and additional random obstacles to create a more realistic environment. Lastly, we present the PL differences with and without obstacles for standard urban environments and derive the empirical PL for these environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14411v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul Saboor, Zhuangzhuang Cui, Evgenii Vinogradov, Sofie Pollin</dc:creator>
    </item>
    <item>
      <title>Next-Generation Wireless: Tracking the Evolutionary Path of 6G Mobile Communication</title>
      <link>https://arxiv.org/abs/2501.14552</link>
      <description>arXiv:2501.14552v1 Announce Type: new 
Abstract: The mobile communications industry is lighting-fast machinery, and discussions about 6G technologies have already begun. In this article, we intend to take the readers on a journey to discover 6G and its evolutionary stages. The journey starts with an overview of the technical constraints of 5G prompting the need for a new generation of mobile systems. The initial discussion is followed by an examination of the 6G vision, use cases, technical requirements, technology enablers, and potential network architecture. We conclude the discussion by reviewing the transformative opportunities of this technology in society, businesses and industries, along with the anticipated technological limitations of the network that will drive the development of further mobile generations. Our goal is to deliver a friendly, informative, precise, and engaging narrative that could give readers a panoramic overview of this important topic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14552v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ekram Hossain, Angelo Vera-Rivera</dc:creator>
    </item>
    <item>
      <title>COMIX: Generalized Conflict Management in O-RAN xApps -- Architecture, Workflow, and a Power Control case</title>
      <link>https://arxiv.org/abs/2501.14619</link>
      <description>arXiv:2501.14619v1 Announce Type: new 
Abstract: Open Radio Access Network (O-RAN) is transforming the telecommunications landscape by enabling flexible, intelligent, and multi-vendor networks. Central to its architecture are xApps hosted on the Near-Real-Time RAN Intelligent Controller (Near-RT RIC), which optimize network functions in real time. However, the concurrent operation of multiple xApps with conflicting objectives can lead to suboptimal performance. This paper introduces a generalized Conflict Management scheme for Multi-Channel Power Control in O-RAN xApps (COMIX), designed to detect and resolve conflicts between xApps. To demonstrate COMIX, we focus on two Deep Reinforcement Learning (DRL)-based xApps for power control: one maximizes the data rare across UEs, and the other optimizes system-level energy efficiency. COMIX employs a standardized Conflict Mitigation Framework (CMF) for conflict detection and resolution and leverages the Network Digital Twin (NDT) to evaluate the impact of conflicting actions before applying them to the live network. We validate the framework using a realistic multi-channel power control scenario under various conflict resolution policies, demonstrating its effectiveness in balancing antagonistic objectives. Our results highlight significant network energy savings achieved through the conflict management scheme compared to baseline CMF-free methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14619v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anastasios Giannopoulos, Sotirios Spantideas, Levis George, Kalafatelis Alexandros, Panagiotis Trakadas</dc:creator>
    </item>
    <item>
      <title>Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models</title>
      <link>https://arxiv.org/abs/2501.14406</link>
      <description>arXiv:2501.14406v1 Announce Type: cross 
Abstract: Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on mobile devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data leads to significant performance degradation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Federated Adaptive Rank Allocation for parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated singular value decomposition (SVD) adaptation to enhance flexibility and expressiveness, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to remove inactive modules, steadily reducing local training time and peak memory usage in each round. Extensive experiments show that FedARA consistently outperforms weak baselines by an average of 8.49\% and strong baselines by 6.95\% across various datasets under data heterogeneity while significantly improving communication efficiency by 2.40\(\times\). Moreover, experiments on AGX Orin, Orin Nano and Raspberry Pi 5 devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90\% and 46.95\%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14406v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</dc:creator>
    </item>
    <item>
      <title>An Attentive Graph Agent for Topology-Adaptive Cyber Defence</title>
      <link>https://arxiv.org/abs/2501.14700</link>
      <description>arXiv:2501.14700v1 Announce Type: cross 
Abstract: As cyber threats grow increasingly sophisticated, reinforcement learning is emerging as a promising technique to create intelligent, self-improving defensive systems. However, most existing autonomous defensive agents have overlooked the inherent graph structure of computer networks subject to cyber attacks, potentially missing critical information. To address this gap, we developed a custom version of the Cyber Operations Research Gym (CybORG) environment that encodes the observable network state as a directed graph, utilizing realistic and interpretable low-level features. %, like number of open ports and unexpected detected connections. We leverage a Graph Attention Network (GAT) architecture to process node, edge, and global features, and modify its output to be compatible with policy gradient methods in reinforcement learning. GAT policies offer several advantages over standard approaches based on simplistic flattened state observations. They can handle the changes in network topology that occur at runtime when dynamic connections between hosts appear. Policies can be deployed to networks that differ in size to the ones seen during training, enabling a degree of generalisation inaccessible with alternative approaches. Furthermore, the graph neural network policies outputs are explainable in terms of tangible network properties, providing enhanced interpretability of defensive actions. We verify that our low-level graph observations are meaningful enough to train GAT defensive policies that are able to adapt to changing topologies. We evaluate how our trained policies perform when deployed on networks of varying sizes with the same subnetwork structure, comparing them against policies specifically trained for each network configuration. Our study contributes to the development of robust cyber defence systems that can better adapt to real-world network security challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14700v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilya Orson Sandoval, Isaac Symes Thompson, Vasilios Mavroudis, Chris Hicks</dc:creator>
    </item>
    <item>
      <title>Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks</title>
      <link>https://arxiv.org/abs/2402.16201</link>
      <description>arXiv:2402.16201v3 Announce Type: replace 
Abstract: Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and peer consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\geq50\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16201v3</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunqi Zhang, Shaileshh Bojja Venkatakrishnan</dc:creator>
    </item>
    <item>
      <title>Goal-Oriented Status Updating for Real-time Remote Inference over Networks with Two-Way Delay</title>
      <link>https://arxiv.org/abs/2410.08706</link>
      <description>arXiv:2410.08706v3 Announce Type: replace 
Abstract: We study a setting where an intelligent model (e.g., a pre-trained neural network) predicts the real-time value of a target signal using data samples transmitted from a remote source according to a scheduling policy. The scheduler decides on i) the age of the samples to be sent, ii) when to send them, and iii) the length of each packet (i.e., the number of samples contained in each packet). The dependence of inference quality on the Age of Information (AoI) for a given packet length is modeled by a general relationship. Previous work assumed i.i.d. transmission delays with immediate feedback or were restricted to the case where inference performance degrades as the input data ages. Our formulation, in addition to capturing non-monotone age dependence, also covers Markovian delay on both forward and feedback links. We model this as an infinite-horizon average-cost Semi-Markov Decision Process. We obtain a closed-form solution that decides on (i) and (ii) for any constant packet length. The solution for when to send is an index-based threshold policy, where the index function is expressed in terms of the delay state and AoI at the receiver. The age of the packet selected is a function of the delay state. We separately optimize the value of the constant length. We also develop an index-based threshold policy for the variable length case, which allows a complexity reduction. In simulation results, we observe that our goal-oriented scheduler drops inference error down to one sixth with respect to age-based scheduling of unit-length packets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08706v3</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cagri Ari, Md Kamran Chowdhury Shisher, Yin Sun, Elif Uysal</dc:creator>
    </item>
    <item>
      <title>Globalping: A Community-Driven, Open-Source Platform for Scalable, Real-Time Network Measurements</title>
      <link>https://arxiv.org/abs/2411.00124</link>
      <description>arXiv:2411.00124v2 Announce Type: replace 
Abstract: We present Globalping, an open-source, community-driven platform for scalable, real-time global network measurements. It democratizes access to network diagnostics by offering every user, including non-technicals, technicals, and companies, the ability to perform ping, traceroute, and DNS lookups from a globally distributed network of user-hosted probes using either the intuitive Globalping front-end or REST API. Unlike solutions like RIPE Atlas, official integrations with other platforms, such as Slack and GitHub, make Globalping even more effective in real-time monitoring and collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00124v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Berkay Kaplan</dc:creator>
    </item>
    <item>
      <title>PyroGuardian: An IoT-Enabled System for Health and Location Monitoring in High-Risk Firefighting Environments</title>
      <link>https://arxiv.org/abs/2411.03654</link>
      <description>arXiv:2411.03654v2 Announce Type: replace 
Abstract: First responders risk their lives to reduce property damage and prevent injuries during disasters. Among first responders, firefighters work with fires in residential properties, forests, or other locations where fire occurs. We built the PyroGuardian system that uses wearable modules to transmit unit information over Long Range (LoRa) to an Android tablet. The tablet runs our application, PyroPortal, to assign each firefighter's stats, such as body temperature, heart rate, and GPS location. PyroPortal displays this information on unit dashboards, and markers on Google Maps represent the firefighter's location and the direction they are facing. These dashboards can help the incident commander (IC) make more informed decisions on mission control operations and remove specific units whose health stats, such as oximeter and pulse, passed certain thresholds. PyroGuardian completes all these tasks at an affordable cost and in an impressive maximum range between the units and IC. In addition, PyroGuardian has various application scenarios, such as law enforcement and military operations, besides firefighting. We also conducted a sample mission inside a burning building while real firefighters watched. After the demonstration, they completed a survey on system usability and PyroGuardian's potential to meet their requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03654v2</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Berkay Kaplan, Buhe Li</dc:creator>
    </item>
    <item>
      <title>Cost Optimization for Serverless Edge Computing with Budget Constraints using Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2501.12783</link>
      <description>arXiv:2501.12783v2 Announce Type: replace 
Abstract: Serverless computing adopts a pay-as-you-go billing model where applications are executed in stateless and shortlived containers triggered by events, resulting in a reduction of monetary costs and resource utilization. However, existing platforms do not provide an upper bound for the billing model which makes the overall cost unpredictable, precluding many organizations from managing their budgets. Due to the diverse ranges of serverless functions and the heterogeneous capacity of edge devices, it is challenging to receive near-optimal solutions for deployment cost in a polynomial time. In this paper, we investigated the function scheduling problem with a budget constraint for serverless computing in wireless networks. Users and IoT devices are sending requests to edge nodes, improving the latency perceived by users. We propose two online scheduling algorithms based on reinforcement learning, incorporating several important characteristics of serverless functions. Via extensive simulations, we justify the superiority of the proposed algorithm by comparing with an ILP solver (Midaco). Our results indicate that the proposed algorithms efficiently approximate the results of Midaco within a factor of 1.03 while our decision-making time is 5 orders of magnitude less than that of Midaco.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12783v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Chen, Peiyuan Guan, Ziru Chen, Amir Taherkordi, Fen Hou, Lin X. Cai</dc:creator>
    </item>
    <item>
      <title>Certificates in P and Subquadratic-Time Computation of Radius, Diameter, and all Eccentricities in Graphs</title>
      <link>https://arxiv.org/abs/1803.04660</link>
      <description>arXiv:1803.04660v4 Announce Type: replace-cross 
Abstract: In the context of fine-grained complexity, we investigate the notion of certificate enabling faster polynomial-time algorithms. We specifically target radius (minimum eccentricity), diameter (maximum eccentricity), and all-eccentricity computations for which quadratic-time lower bounds are known under plausible conjectures. In each case, we introduce a notion of certificate as a specific set of nodes from which appropriate bounds on all eccentricities can be derived in subquadratic time when this set has sublinear size. The existence of small certificates is a barrier against SETH-based lower bounds for these problems. We indeed prove that for graph classes with small certificates, there exist randomized subquadratic-time algorithms for computing the radius, the diameter, and all eccentricities respectively.Moreover, these notions of certificates are tightly related to algorithms probing the graph through one-to-all distance queries and allow to explain the efficiency of practical radius and diameter algorithms from the literature. Our formalization enables a novel primal-dual analysis of a classical approach for diameter computation that leads to algorithms for radius, diameter and all eccentricities with theoretical guarantees with respect to certain graph parameters. This is complemented by experimental results on various types of real-world graphs showing that these parameters appear to be low in practice. Finally, we obtain refined results for several graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:1803.04660v4</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978322.70</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), Jan 2025, New Orleans (LA), United States. pp.2157-2193</arxiv:journal_reference>
      <dc:creator>Feodor F. Dragan (UniBuc, ICI), Guillaume Ducoffe (UniBuc, ICI), Michel Habib (IRIF), Laurent Viennot (DI-ENS, ARGO)</dc:creator>
    </item>
    <item>
      <title>Asynchronous Federated Reinforcement Learning with Policy Gradient Updates: Algorithm Design and Convergence Analysis</title>
      <link>https://arxiv.org/abs/2404.08003</link>
      <description>arXiv:2404.08003v5 Announce Type: replace-cross 
Abstract: To improve the efficiency of reinforcement learning (RL), we propose a novel asynchronous federated reinforcement learning (FedRL) framework termed AFedPG, which constructs a global model through collaboration among $N$ agents using policy gradient (PG) updates. To address the challenge of lagged policies in asynchronous settings, we design a delay-adaptive lookahead technique \textit{specifically for FedRL} that can effectively handle heterogeneous arrival times of policy gradients. We analyze the theoretical global convergence bound of AFedPG, and characterize the advantage of the proposed algorithm in terms of both the sample complexity and time complexity. Specifically, our AFedPG method achieves $O(\frac{{\epsilon}^{-2.5}}{N})$ sample complexity for global convergence at each agent on average. Compared to the single agent setting with $O(\epsilon^{-2.5})$ sample complexity, it enjoys a linear speedup with respect to the number of agents. Moreover, compared to synchronous FedPG, AFedPG improves the time complexity from $O(\frac{t_{\max}}{N})$ to $O({\sum_{i=1}^{N} \frac{1}{t_{i}}})^{-1}$, where $t_{i}$ denotes the time consumption in each iteration at agent $i$, and $t_{\max}$ is the largest one. The latter complexity $O({\sum_{i=1}^{N} \frac{1}{t_{i}}})^{-1}$ is always smaller than the former one, and this improvement becomes significant in large-scale federated settings with heterogeneous computing powers ($t_{\max}\gg t_{\min}$). Finally, we empirically verify the improved performance of AFedPG in four widely used MuJoCo environments with varying numbers of agents. We also demonstrate the advantages of AFedPG in various computing heterogeneity scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08003v5</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangchen Lan, Dong-Jun Han, Abolfazl Hashemi, Vaneet Aggarwal, Christopher G. Brinton</dc:creator>
    </item>
  </channel>
</rss>
