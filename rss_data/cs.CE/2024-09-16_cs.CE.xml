<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Sep 2024 04:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sequential infinite-dimensional Bayesian optimal experimental design with derivative-informed latent attention neural operator</title>
      <link>https://arxiv.org/abs/2409.09141</link>
      <description>arXiv:2409.09141v1 Announce Type: new 
Abstract: In this work, we develop a new computational framework to solve sequential Bayesian experimental design (SBOED) problems constrained by large-scale partial differential equations with infinite-dimensional random parameters. We propose an adaptive terminal formulation of the optimality criteria for SBOED to achieve adaptive global optimality. We also establish an equivalent optimization formulation to achieve computational simplicity enabled by Laplace and low-rank approximations of the posterior. To accelerate the solution of the SBOED problem, we develop a derivative-informed latent attention neural operator (LANO), a new neural network surrogate model that leverages (1) derivative-informed dimension reduction for latent encoding, (2) an attention mechanism to capture the dynamics in the latent space, (3) an efficient training in the latent space augmented by projected Jacobian, which collectively lead to an efficient, accurate, and scalable surrogate in computing not only the parameter-to-observable (PtO) maps but also their Jacobians. We further develop the formulation for the computation of the MAP points, the eigenpairs, and the sampling from posterior by LANO in the reduced spaces and use these computations to solve the SBOED problem. We demonstrate the superior accuracy of LANO compared to two other neural architectures and the high accuracy of LANO compared to the finite element method (FEM) for the computation of MAP points in solving the SBOED problem with application to the experimental design of the time to take MRI images in monitoring tumor growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09141v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jinwoo Go, Peng Chen</dc:creator>
    </item>
    <item>
      <title>A differentiable structural analysis framework for high-performance design optimization</title>
      <link>https://arxiv.org/abs/2409.09247</link>
      <description>arXiv:2409.09247v1 Announce Type: new 
Abstract: Fast, gradient-based structural optimization has long been limited to a highly restricted subset of problems -- namely, density-based compliance minimization -- for which gradients can be analytically derived. For other objective functions, constraints, and design parameterizations, computing gradients has remained inaccessible, requiring the use of derivative-free algorithms that scale poorly with problem size. This has restricted the applicability of optimization to abstracted and academic problems, and has limited the uptake of these potentially impactful methods in practice. In this paper, we bridge the gap between computational efficiency and the freedom of problem formulation through a differentiable analysis framework designed for general structural optimization. We achieve this through leveraging Automatic Differentiation (AD) to manage the complex computational graph of structural analysis programs, and implementing specific derivation rules for performance critical functions along this graph. This paper provides a complete overview of gradient computation for arbitrary structural design objectives, identifies the barriers to their practical use, and derives key intermediate derivative operations that resolves these bottlenecks. Our framework is then tested against a series of structural design problems of increasing complexity: two highly constrained minimum volume problem, a multi-stage shape and section design problem, and an embodied carbon minimization problem. We benchmark our framework against other common optimization approaches, and show that our method outperforms others in terms of speed, stability, and solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09247v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keith J. Lee, Yijiang Huang, Caitlin T. Mueller</dc:creator>
    </item>
    <item>
      <title>Gene and RNA Editing: Methods, Enabling Technologies, Applications, and Future Directions</title>
      <link>https://arxiv.org/abs/2409.09057</link>
      <description>arXiv:2409.09057v1 Announce Type: cross 
Abstract: Gene and RNA editing methods, technologies, and applications are emerging as innovative forms of therapy and medicine, offering more efficient implementation compared to traditional pharmaceutical treatments. Current trends emphasize the urgent need for advanced methods and technologies to detect public health threats, including diseases and viral agents. Gene and RNA editing techniques enhance the ability to identify, modify, and ameliorate the effects of genetic diseases, disorders, and disabilities. Viral detection and identification methods present numerous opportunities for enabling technologies, such as CRISPR, applicable to both RNA and gene editing through the use of specific Cas proteins. This article explores the distinctions and benefits of RNA and gene editing processes, emphasizing their contributions to the future of medical treatment. CRISPR technology, particularly its adaptation via the Cas13 protein for RNA editing, is a significant advancement in gene editing. The article will delve into RNA and gene editing methodologies, focusing on techniques that alter and modify genetic coding. A-to-I and C-to-U editing are currently the most predominant methods of RNA modification. CRISPR stands out as the most cost-effective and customizable technology for both RNA and gene editing. Unlike permanent changes induced by cutting an individual's DNA genetic code, RNA editing offers temporary modifications by altering nucleoside bases in RNA strands, which can then attach to DNA strands as temporary modifiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09057v1</guid>
      <category>q-bio.GN</category>
      <category>cs.CE</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammed Aledhari, Mohamed Rahouti</dc:creator>
    </item>
    <item>
      <title>Analysis of Centrifugal Clutches in Two-Speed Automatic Transmissions with Deep Learning-Based Engagement Prediction</title>
      <link>https://arxiv.org/abs/2409.09755</link>
      <description>arXiv:2409.09755v1 Announce Type: cross 
Abstract: This paper presents a comprehensive numerical analysis of centrifugal clutch systems integrated with a two-speed automatic transmission, a key component in automotive torque transfer. Centrifugal clutches enable torque transmission based on rotational speed without external controls. The study systematically examines various clutch configurations effects on transmission dynamics, focusing on torque transfer, upshifting, and downshifting behaviors under different conditions. A Deep Neural Network (DNN) model predicts clutch engagement using parameters such as spring preload and shoe mass, offering an efficient alternative to complex simulations. The integration of deep learning and numerical modeling provides critical insights for optimizing clutch designs, enhancing transmission performance and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09755v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bo-Yi Lin, Kai Chun Lin</dc:creator>
    </item>
    <item>
      <title>Assessing the Impact of Sanctions in the Crypto Ecosystem: Effective Measures or Ineffective Deterrents?</title>
      <link>https://arxiv.org/abs/2409.10031</link>
      <description>arXiv:2409.10031v1 Announce Type: cross 
Abstract: Regulatory authorities aim to tackle illegal activities by targeting the economic incentives that drive such behaviour. This is typically achieved through the implementation of financial sanctions against the entities involved in the crimes. However, the rise of cryptocurrencies has presented new challenges, allowing entities to evade these sanctions and continue criminal operations. Consequently, enforcement measures have been expanded to include crypto assets information of sanctioned entities. Yet, due to the nature of the crypto ecosystem, blocking or freezing these digital assets is harder and, in some cases, such as with Bitcoin, unfeasible. Therefore, sanctions serve merely as deterrents. For this reason, in this study, we aim to assess the impact of these sanctions on entities' crypto activities, particularly those related to the Bitcoin ecosystem. Our objective is to shed light on the validity and effectiveness (or lack thereof) of such countermeasures. Specifically, we analyse the transactions and the amount of USD moved by punished entities that possess crypto addresses after being sanctioned by the authority agency. Results indicate that while sanctions have been effective for half of the examined entities, the others continue to move funds through sanctioned addresses. Furthermore, punished entities demonstrate a preference for utilising rapid exchange services to convert their funds, rather than employing dedicated money laundering services. To the best of our knowledge, this study offers valuable insights into how entities use crypto assets to circumvent sanctions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10031v1</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Zola, Jon Ander Medina, Raul Orduna</dc:creator>
    </item>
    <item>
      <title>Evaluating the Efficacy of Instance Incremental vs. Batch Learning in Delayed Label Environments: An Empirical Study on Tabular Data Streaming for Fraud Detection</title>
      <link>https://arxiv.org/abs/2409.10111</link>
      <description>arXiv:2409.10111v1 Announce Type: cross 
Abstract: Real-world tabular learning production scenarios typically involve evolving data streams, where data arrives continuously and its distribution may change over time. In such a setting, most studies in the literature regarding supervised learning favor the use of instance incremental algorithms due to their ability to adapt to changes in the data distribution. Another significant reason for choosing these algorithms is \textit{avoid storing observations in memory} as commonly done in batch incremental settings. However, the design of instance incremental algorithms often assumes immediate availability of labels, which is an optimistic assumption. In many real-world scenarios, such as fraud detection or credit scoring, labels may be delayed. Consequently, batch incremental algorithms are widely used in many real-world tasks. This raises an important question: "In delayed settings, is instance incremental learning the best option regarding predictive performance and computational efficiency?" Unfortunately, this question has not been studied in depth, probably due to the scarcity of real datasets containing delayed information. In this study, we conduct a comprehensive empirical evaluation and analysis of this question using a real-world fraud detection problem and commonly used generated datasets. Our findings indicate that instance incremental learning is not the superior option, considering on one side state-of-the-art models such as Adaptive Random Forest (ARF) and other side batch learning models such as XGBoost. Additionally, when considering the interpretability of the learning systems, batch incremental solutions tend to be favored. Code: \url{https://github.com/anselmeamekoe/DelayedLabelStream}</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10111v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kodjo Mawuena Amekoe, Mustapha Lebbah, Gregoire Jaffre, Hanene Azzag, Zaineb Chelly Dagdia</dc:creator>
    </item>
    <item>
      <title>Data-free Non-intrusive Model Reduction for Nonlinear Finite Element Models via Spectral Submanifolds</title>
      <link>https://arxiv.org/abs/2409.10126</link>
      <description>arXiv:2409.10126v1 Announce Type: cross 
Abstract: The theory of spectral submanifolds (SSMs) has emerged as a powerful tool for constructing rigorous, low-dimensional reduced-order models (ROMs) of high-dimensional nonlinear mechanical systems. A direct computation of SSMs requires explicit knowledge of nonlinear coefficients in the equations of motion, which limits their applicability to generic finite-element (FE) solvers. Here, we propose a non-intrusive algorithm for the computation of the SSMs and the associated ROMs up to arbitrary polynomial orders. This non-intrusive algorithm only requires system nonlinearity as a black box and hence, enables SSM-based model reduction via generic finite-element software. Our expressions and algorithms are valid for systems with up to cubic-order nonlinearities, including velocity-dependent nonlinear terms, asymmetric damping, and stiffness matrices, and hence work for a large class of mechanics problems. We demonstrate the effectiveness of the proposed non-intrusive approach over a variety of FE examples of increasing complexity, including a micro-resonator FE model containing more than a million degrees of freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10126v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingwu Li, Thomas Thurnher, Zhenwei Xu, Shobhit Jain</dc:creator>
    </item>
    <item>
      <title>Improving the Adaptive Moment Estimation (ADAM) stochastic optimizer through an Implicit-Explicit (IMEX) time-stepping approach</title>
      <link>https://arxiv.org/abs/2403.13704</link>
      <description>arXiv:2403.13704v2 Announce Type: replace 
Abstract: The Adam optimizer, often used in Machine Learning for neural network training, corresponds to an underlying ordinary differential equation (ODE) in the limit of very small learning rates. This work shows that the classical Adam algorithm is a first-order implicit-explicit (IMEX) Euler discretization of the underlying ODE. Employing the time discretization point of view, we propose new extensions of the Adam scheme obtained by using higher-order IMEX methods to solve the ODE. Based on this approach, we derive a new optimization algorithm for neural network training that performs better than classical Adam on several regression and classification problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13704v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1615/JMachLearnModelComput.2024053508</arxiv:DOI>
      <dc:creator>Abhinab Bhattacharjee, Andrey A. Popov, Arash Sarshar, Adrian Sandu</dc:creator>
    </item>
    <item>
      <title>Latent diffusion models for parameterization and data assimilation of facies-based geomodels</title>
      <link>https://arxiv.org/abs/2406.14815</link>
      <description>arXiv:2406.14815v3 Announce Type: replace-cross 
Abstract: Geological parameterization entails the representation of a geomodel using a small set of latent variables and a mapping from these variables to grid-block properties such as porosity and permeability. Parameterization is useful for data assimilation (history matching), as it maintains geological realism while reducing the number of variables to be determined. Diffusion models are a new class of generative deep-learning procedures that have been shown to outperform previous methods, such as generative adversarial networks, for image generation tasks. Diffusion models are trained to "denoise", which enables them to generate new geological realizations from input fields characterized by random noise. Latent diffusion models, which are the specific variant considered in this study, provide dimension reduction through use of a low-dimensional latent variable. The model developed in this work includes a variational autoencoder for dimension reduction and a U-net for the denoising process. Our application involves conditional 2D three-facies (channel-levee-mud) systems. The latent diffusion model is shown to provide realizations that are visually consistent with samples from geomodeling software. Quantitative metrics involving spatial and flow-response statistics are evaluated, and general agreement between the diffusion-generated models and reference realizations is observed. Stability tests are performed to assess the smoothness of the parameterization method. The latent diffusion model is then used for ensemble-based data assimilation. Two synthetic "true" models are considered. Significant uncertainty reduction, posterior P$_{10}$-P$_{90}$ forecasts that generally bracket observed data, and consistent posterior geomodels, are achieved in both cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14815v3</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guido Di Federico, Louis J. Durlofsky</dc:creator>
    </item>
  </channel>
</rss>
