<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Mar 2024 14:39:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Mar 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hilbert Space-Valued LQG Mean Field Games: An Infinite-Dimensional Analysis</title>
      <link>https://arxiv.org/abs/2403.01012</link>
      <description>arXiv:2403.01012v1 Announce Type: new 
Abstract: This paper presents a comprehensive study of Hilbert space-valued Linear-Quadratic-Gaussian (LQG) mean field games (MFGs), generalizing the classic LQG mean field game theory to scenarios where the state equations are driven by infinite-dimensional stochastic equations. In this framework, state and control processes take values in separable Hilbert spaces. Moreover, the state equations involve infinite dimensional noises, namely $Q$-Wiener processes. All agents are coupled through the average state of the population appearing in their linear dynamics and quadratic cost functional. In addition, the diffusion coefficient of each agent involves the state, control, and the average state processes. We first study the well-posedness of a system of coupled infinite-dimensional stochastic evolution equations, which forms the foundation of MFGs in Hilbert spaces. Next, we develop the Nash Certainty Equivalence principle and obtain a unique Nash equilibrium for the limiting Hilbert space-valued MFG. Finally, we establish the $\epsilon$-Nash property for the finite-player game in Hilbert space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01012v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hanchao Liu, Dena Firoozi</dc:creator>
    </item>
    <item>
      <title>LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation</title>
      <link>https://arxiv.org/abs/2403.01131</link>
      <description>arXiv:2403.01131v1 Announce Type: new 
Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior optimization performance compared to GPT-4 Turbo and the other competitors across both synthetic and realistic problem sets. The fine-tuned model and the usage instructions are available at https://anonymous.4open.science/r/LLaMoCo-722A.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01131v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyuan Ma, Hongshu Guo, Jiacheng Chen, Guojun Peng, Zhiguang Cao, Yining Ma, Yue-Jiao Gong</dc:creator>
    </item>
    <item>
      <title>Semismooth Newton Method for Boundary Bilinear Control</title>
      <link>https://arxiv.org/abs/2403.01135</link>
      <description>arXiv:2403.01135v1 Announce Type: new 
Abstract: We study a control-constrained optimal control problem governed by a semilinear elliptic equation. The control acts in a bilinear way on the boundary, and can be interpreted as a heat transfer coefficient. A detailed study of the state equation is performed and differentiability properties of the control-to-state mapping are shown. First and second order optimality conditions are derived. Our main result is the proof of superlinear convergence of the semismooth Newton method to local solutions satisfying no-gap second order sufficient optimality conditions as well as a strict complementarity condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01135v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2023.3337747</arxiv:DOI>
      <arxiv:journal_reference>IEEE Control Systems Letters, 7 (2023) 3549--3554</arxiv:journal_reference>
      <dc:creator>Eduardo Casas, Konstantinos Chrysafinos, Mariano Mateos</dc:creator>
    </item>
    <item>
      <title>A Composite Decomposition Method for Large-Scale Global Optimization</title>
      <link>https://arxiv.org/abs/2403.01192</link>
      <description>arXiv:2403.01192v1 Announce Type: new 
Abstract: Cooperative co-evolution (CC) algorithms, based on the divide-and-conquer strategy, have emerged as the predominant approach to solving large-scale global optimization (LSGO) problems. The efficiency and accuracy of the grouping stage significantly impact the performance of the optimization process. While the general separability grouping (GSG) method has overcome the limitation of previous differential grouping (DG) methods by enabling the decomposition of non-additively separable functions, it suffers from high computational complexity. To address this challenge, this article proposes a composite separability grouping (CSG) method, seamlessly integrating DG and GSG into a problem decomposition framework to utilize the strengths of both approaches. CSG introduces a step-by-step decomposition framework that accurately decomposes various problem types using fewer computational resources. By sequentially identifying additively, multiplicatively and generally separable variables, CSG progressively groups non-separable variables by recursively considering the interactions between each non-separable variable and the formed non-separable groups. Furthermore, to enhance the efficiency and accuracy of CSG, we introduce two innovative methods: a multiplicatively separable variable detection method and a non-separable variable grouping method. These two methods are designed to effectively detect multiplicatively separable variables and efficiently group non-separable variables, respectively. Extensive experimental results demonstrate that CSG achieves more accurate variable grouping with lower computational complexity compared to GSG and state-of-the-art DG series designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01192v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maojiang Tian, Minyang Chen, Wei Du, Yang Tang, Yaochu Jin, Gary G. Yen</dc:creator>
    </item>
    <item>
      <title>Decentralized Implicit Differentiation</title>
      <link>https://arxiv.org/abs/2403.01260</link>
      <description>arXiv:2403.01260v1 Announce Type: new 
Abstract: The ability to differentiate through optimization problems has unlocked numerous applications, from optimization-based layers in machine learning models to complex design problems formulated as bilevel programs. It has been shown that exploiting problem structure can yield significant computation gains for optimization and, in some cases, enable distributed computation. One should expect that this structure can be similarly exploited for gradient computation. In this work, we discuss a decentralized framework for computing gradients of constraint-coupled optimization problems. First, we show that this framework results in significant computational gains, especially for large systems, and provide sufficient conditions for its validity. Second, we leverage exponential decay of sensitivities in graph-structured problems towards building a fully distributed algorithm with convergence guarantees. Finally, we use the methodology to rigorously estimate marginal emissions rates in power systems models. Specifically, we demonstrate how the distributed scheme allows for accurate and efficient estimation of these important emissions metrics on large dynamic power system models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01260v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Fuentes Valenzuela, Robin Brown, Marco Pavone</dc:creator>
    </item>
    <item>
      <title>A Communication-Efficient Stochastic Gradient Descent Algorithm for Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2403.01322</link>
      <description>arXiv:2403.01322v1 Announce Type: new 
Abstract: This paper studies distributed nonconvex optimization problems with stochastic gradients for a multi-agent system, in which each agent aims to minimize the sum of all agents' cost functions by using local compressed information exchange. We propose a distributed stochastic gradient descent (SGD) algorithm, suitable for a general class of compressors. We show that the proposed algorithm achieves the linear speedup convergence rate $\mathcal{O}(1/\sqrt{nT})$ for smooth nonconvex functions, where $T$ and $n$ are the number of iterations and agents, respectively. If the global cost function additionally satisfies the Polyak--{\L}ojasiewicz condition, the proposed algorithm can linearly converge to a neighborhood of the global optimum, regardless of whether the stochastic gradient is unbiased or not. Numerical experiments are carried out to verify the efficiency of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01322v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antai Xie, Xinlei Yi, Xiaofan Wang, Ming Cao, Xiaoqiang Ren</dc:creator>
    </item>
    <item>
      <title>Distributed Least-Squares Optimization Solvers with Differential Privacy</title>
      <link>https://arxiv.org/abs/2403.01435</link>
      <description>arXiv:2403.01435v1 Announce Type: new 
Abstract: This paper studies the distributed least-squares optimization problem with differential privacy requirement of local cost functions, for which two differentially private distributed solvers are proposed. The first is established on the distributed gradient tracking algorithm, by appropriately perturbing the initial values and parameters that contain the privacy-sensitive data with Gaussian and truncated Laplacian noises, respectively. Rigorous proofs are established to show the achievable trade-off between the ({\epsilon}, {\delta})-differential privacy and the computation accuracy. The second solver is established on the combination of the distributed shuffling mechanism and the average consensus algorithm, which enables each agent to obtain a noisy version of parameters characterizing the global gradient. As a result, the least-squares optimization problem can be eventually solved by each agent locally in such a way that any given ({\epsilon}, {\delta})-differential privacy requirement can be preserved while the solution may be computed with the accuracy independent of the network size, which makes the latter more suitable for large-scale distributed least-squares problems. Numerical simulations are presented to show the effectiveness of both solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01435v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weijia Liu, Lei Wang, Fanghong Guo, Zhengguang Wu, Hongye Su</dc:creator>
    </item>
    <item>
      <title>Distributed Discrete-time Dynamic Outer Approximation of the Intersection of Ellipsoids</title>
      <link>https://arxiv.org/abs/2403.01478</link>
      <description>arXiv:2403.01478v1 Announce Type: new 
Abstract: This paper presents the first discrete-time distributed algorithm to track the tightest ellipsoids that outer approximates the global dynamic intersection of ellipsoids. The ellipsoids are defined as time-varying positive definite matrices. On the other hand, given an undirected network, each node is equipped with one of these ellipsoids. The solution is based on a novel distributed reformulation of the original centralized semi-definite outer L\"owner-John program, characterized by a non-separable objective function and global constraints. We prove finite-time convergence to the global minima of the centralized problem in the static case and finite-time bounded tracking error in the dynamic case. Moreover, we prove boundedness of estimation in the tracking of the global optimum and robustness in the estimation against time-varying inputs. As a by-product, the proposed algorithm extends min/max dynamic consensus algorithms to positive definite matrices. We illustrate the properties of the algorithm with different simulated examples, including a distributed estimation showcase where our proposal is integrated into a distributed Kalman filter to surpass the state-of-the-art in mean square error performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01478v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Sebasti\'an, Rodrigo Aldana-L\'opez, Rosario Arag\"u\'es, Eduardo Montijano, Carlos Sag\"u\'es</dc:creator>
    </item>
    <item>
      <title>Generalized pair-wise logit dynamic and its connection to a mean field game: theoretical and computational investigations focusing on resource management</title>
      <link>https://arxiv.org/abs/2403.01657</link>
      <description>arXiv:2403.01657v1 Announce Type: new 
Abstract: Logit dynamics are evolution equations that describe transitions to equilibria of actions among many players. We formulate a pair-wise logit dynamic in a continuous action space with a generalized exponential function, which we call a generalized pair-wise logit dynamic, depicted by a new evolution equation nonlocal in space. We prove the well-posedness and approximability of the generalized pair-wise logit dynamic to show that it is computationally implementable. We also show that this dynamic has an explicit connection to a mean field game of a controlled pure-jump process, with which the two different mathematical models can be understood in a unified way. Particularly, we show that the generalized pair-wise logit dynamic is derived as a myopic version of the corresponding mean field game, and that the conditions to guarantee the existence of unique solutions are different from each other. The key in this procedure is to find the objective function to be optimized in the mean field game based on the logit function. The monotonicity of the utility is unnecessary for the generalized pair-wise logit dynamic but crucial for the mean field game. Finally, we present applications of the two approaches to fisheries management problems with collected data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01657v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka, Motoh Tsujimura</dc:creator>
    </item>
    <item>
      <title>Tsallis Entropy Regularization for Linearly Solvable MDP and Linear Quadratic Regulator</title>
      <link>https://arxiv.org/abs/2403.01805</link>
      <description>arXiv:2403.01805v1 Announce Type: new 
Abstract: Shannon entropy regularization is widely adopted in optimal control due to its ability to promote exploration and enhance robustness, e.g., maximum entropy reinforcement learning known as Soft Actor-Critic. In this paper, Tsallis entropy, which is a one-parameter extension of Shannon entropy, is used for the regularization of linearly solvable MDP and linear quadratic regulators. We derive the solution for these problems and demonstrate its usefulness in balancing between exploration and sparsity of the obtained control law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01805v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yota Hashizume, Koshi Oishi, Kenji Kashima</dc:creator>
    </item>
    <item>
      <title>Output feedback stabilisation of bilinear systems via control templates</title>
      <link>https://arxiv.org/abs/2403.01869</link>
      <description>arXiv:2403.01869v1 Announce Type: new 
Abstract: We establish a separation principle for the output feedback stabilisation of state-affine systems that are observable at the stabilization target. Relying on control templates (recently introduced in [4]), that allow to approximate a feedback control while maintaining observability, we design a closed loop hybrid state-observer system that we show to be semi-globally asymptotically stable. Under assumption of polynomiality of the system with respect to the control, we give an explicit construction of control templates. We illustrate the results of the paper with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01869v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovic SacchelliMcTAO, Lucas BrivadisL2S, Ulysse SerresLAGEPP, Ita\"i Ben YaacovAGL</dc:creator>
    </item>
    <item>
      <title>Activity estimation via distributed measurements in an orientation sensitive neural fields model of the visual cortex</title>
      <link>https://arxiv.org/abs/2403.01906</link>
      <description>arXiv:2403.01906v1 Announce Type: new 
Abstract: This paper investigates the online estimation of neural activity within the primary visual cortex (V1) in the framework of observability theory. We focus on a low-dimensional neural fields modeling hypercolumnar activity to describe activity in V1. We utilize the average cortical activity over V1 as measurement. Our contributions include detailing the model's observability singularities and developing a hybrid high-gain observer that achieves, under specific excitation conditions, practical convergence while maintaining asymptotic convergence in cases of biological relevance. The study emphasizes the intrinsic link between the model's non-linear nature and its observability. We also present numerical experiments highlighting the different properties of the observer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01906v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adel Malik Annabi, Dario Prandi, Jean-Baptiste Pomet, Ludovic Sacchelli</dc:creator>
    </item>
    <item>
      <title>Optimal control of diffusion processes: $\infty$-order variational analysis and numerical solution</title>
      <link>https://arxiv.org/abs/2403.01945</link>
      <description>arXiv:2403.01945v1 Announce Type: new 
Abstract: We tackle a nonlinear optimal control problem for a stochastic differential equation in Euclidean space and its state-linear counterpart for the Fokker-Planck-Kolmogorov equation in the space of probabilities. Our approach is founded on a novel concept of local optimality surpassing Pontryagin's minimum, originally crafted for deterministic optimal ensemble control problems. A key practical outcome is a rapidly converging numerical algorithm, which proves its feasibility for problems involving Markovian and open-loop strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01945v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Chertovskih, Nikolay Pogodaev, Maxim Staritsyn, A. Pedro Aguiar</dc:creator>
    </item>
    <item>
      <title>A Unified Inexact Stochastic ADMM for Composite Nonconvex and Nonsmooth Optimization</title>
      <link>https://arxiv.org/abs/2403.02015</link>
      <description>arXiv:2403.02015v1 Announce Type: new 
Abstract: In this paper, we propose a unified framework of inexact stochastic Alternating Direction Method of Multipliers (ADMM) for solving nonconvex problems subject to linear constraints, whose objective comprises an average of finite-sum smooth functions and a nonsmooth but possibly nonconvex function. The new framework is highly versatile. Firstly, it not only covers several existing algorithms such as SADMM, SVRG-ADMM, and SPIDER-ADMM but also guides us to design a novel accelerated hybrid stochastic ADMM algorithm, which utilizes a new hybrid estimator to trade-off variance and bias. Second, it enables us to exploit a more flexible dual stepsize in the convergence analysis. Under some mild conditions, our unified framework preserves $\mathcal{O}(1/T)$ sublinear convergence. Additionally, we establish the linear convergence under error bound conditions. Finally, numerical experiments demonstrate the efficacy of the new algorithm for some nonsmooth and nonconvex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02015v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Zeng, Jianchao Bai, Shengjia Wang, Zhiguo Wang</dc:creator>
    </item>
    <item>
      <title>Homotopy Methods for Convex Optimization</title>
      <link>https://arxiv.org/abs/2403.02095</link>
      <description>arXiv:2403.02095v1 Announce Type: new 
Abstract: Convex optimization encompasses a wide range of optimization problems, containing many efficiently solvable subclasses. Interior point methods are currently the state-of-the-art approach for solving such problems, particularly effective for classes like semidefinite programming, quadratic programming, and geometric programming. However, their success hinges on the construction of self-concordant barrier functions for the feasible sets. In this work, we introduce an alternative method for tackling convex optimization problems, employing a homotopy. With this technique, the feasible set of a trivial optimization problem is continuously transformed into the target one, while tracking the solutions. We conduct an analysis of this approach, focusing on its application to semidefinite programs, hyperbolic programs, and convex optimization problems with a single convexity constraint. Moreover, we demonstrate that our approach numerically outperforms state-of-the-art methods in several interesting cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02095v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Klingler, Tim Netzer</dc:creator>
    </item>
    <item>
      <title>Some optimality conditions of set-valued optimization problems in locally convex topological vector spaces</title>
      <link>https://arxiv.org/abs/2403.02101</link>
      <description>arXiv:2403.02101v1 Announce Type: new 
Abstract: In this article, we work with set-valued optimization problems in locally convex topological vector spaces. We prove the equivalencies of some definitions of generalized convex maps introduced by Jeyakumar, Yang, Yang &amp; Yang &amp; Chen, as well as Zeng. And then, we discuss the conditions of weakly efficient solutions, proper efficient solutions, and optimal solutions of set-valued optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02101v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renying Zeng</dc:creator>
    </item>
    <item>
      <title>Shape optimization in the space of piecewise-smooth shapes for the Bingham flow variational inequality</title>
      <link>https://arxiv.org/abs/2403.02106</link>
      <description>arXiv:2403.02106v1 Announce Type: new 
Abstract: This paper sets up an approach for shape optimization problems constrained by variational inequalities (VI) in an appropriate shape space. In contrast to classical VI, where no explicit dependence on the domain is given, VI constrained shape optimization problems are in particular highly challenging because of two main reasons: Firstly, one needs to operate in inherently non-linear, non-convex and infinite-dimensional shape spaces. Secondly, the problem cannot be solved directly without any regularization techniques in general because, e.g., one cannot expect the existence of the shape derivative for an arbitrary shape functional depending on solutions to VI. This paper introduces a specific shape manifold and presents an optimization technique to handle the non-differentiabilities on this shape manifold. In particular, we formulate an optimization system based on G\^ateaux semiderivatives and Eulerian derivatives for a shape optimization problem constrained by the Bingham flow variational inequality. Numerical results show the applicability and efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02106v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim SuchanHelmut-Schmidt-Universit\"at/Universit\"at der Bundeswehr Hamburg, Germany, Volker SchulzUniversit\"at Trier, Germany, Kathrin WelkerTU Bergakademie Freiberg, Germany</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Inverse Non-Cooperative Linear-Quadratic Output-feedback Differential Games</title>
      <link>https://arxiv.org/abs/2403.02146</link>
      <description>arXiv:2403.02146v1 Announce Type: new 
Abstract: In this paper, we address the inverse problem for linear-quadratic differential non-cooperative games with output-feedback. Given players' stabilizing feedback laws, the goal is to find cost function parameters that lead to a game for which the observed game dynamics are at a Nash equilibrium. Using the given feedback laws, we introduce a model-based algorithm that generates cost function parameters solving the above inverse problem. We introduce a correction procedure that at each iteration of the algorithm guarantees the existence of the feedback laws, which addresses a key challenge of output-feedback control designs. As an intermediate stage of the algorithm, we have developed a procedure for the initial stabilization of the multiple-input system with output-feedback information structure. We prove convergence and stability of the algorithm, and show the way to generate new games with necessary properties without requiring to run the complete algorithm repeatedly. Then the algorithm is extended to a model-free version that uses data samples generated by unknown dynamics and has the same converging and stabilizing properties as the model-based version. Finally, we show how the inverse problem can be solved in a distributed manner and provide possible extensions. Simulation results validate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02146v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emin Martirosyan, Ming Cao</dc:creator>
    </item>
    <item>
      <title>Approximate Controllability for Nonautonomous Integrodifferential Equations with State-dependent Delay</title>
      <link>https://arxiv.org/abs/2403.02326</link>
      <description>arXiv:2403.02326v1 Announce Type: new 
Abstract: In this work, we study the existence of mild solutions and the approximate controllability for nonautonomous integrodifferential equations with state-dependent delay. We assume the approximate controllability of the linear part, then we use the resolvent operators theory to prove the approximate controllability of the nonlinear case. An example of one-dimensional heat equation with memory is given to illustrate our basic results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02326v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mamadou Abdoul Diop, Mohammed Elghandouri, Khalil Ezzinbi</dc:creator>
    </item>
    <item>
      <title>The Algorithm Configuration Problem</title>
      <link>https://arxiv.org/abs/2403.00898</link>
      <description>arXiv:2403.00898v1 Announce Type: cross 
Abstract: The field of algorithmic optimization has significantly advanced with the development of methods for the automatic configuration of algorithmic parameters. This article delves into the Algorithm Configuration Problem, focused on optimizing parametrized algorithms for solving specific instances of decision/optimization problems. We present a comprehensive framework that not only formalizes the Algorithm Configuration Problem, but also outlines different approaches for its resolution, leveraging machine learning models and heuristic strategies. The article categorizes existing methodologies into per-instance and per-problem approaches, distinguishing between offline and online strategies for model construction and deployment. By synthesizing these approaches, we aim to provide a clear pathway for both understanding and addressing the complexities inherent in algorithm configuration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00898v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-030-54621-2_749-1</arxiv:DOI>
      <arxiv:journal_reference>In: Pardalos, P.M., Prokopyev, O.A. (eds) Encyclopedia of Optimization. Springer, Cham. (2023)</arxiv:journal_reference>
      <dc:creator>Gabriele Iommazzo, Claudia D'Ambrosio, Antonio Frangioni, Leo Liberti</dc:creator>
    </item>
    <item>
      <title>Iterative Methods for Navier--Stokes Inverse Problems</title>
      <link>https://arxiv.org/abs/2403.00937</link>
      <description>arXiv:2403.00937v1 Announce Type: cross 
Abstract: Even when the partial differential equation underlying a physical process can be evolved forward in time, the retrospective (backward in time) inverse problem often has its own challenges and applications. Direct Adjoint Looping (DAL) is the defacto approach for solving retrospective inverse problems, but it has not been applied to deterministic retrospective Navier--Stokes inverse problems in 2D or 3D. In this paper, we demonstrate that DAL is ill-suited for solving retrospective 2D Navier--Stokes inverse problems. Alongside DAL, we study two other iterative methods: Simple Backward Integration (SBI) and the Quasi-Reversible Method (QRM). Our iterative SBI approach is novel while iterative QRM has previously been used. Using these three iterative methods, we solve two retrospective inverse problems: 1D Korteweg--de Vries--Burgers (decaying nonlinear wave) and 2D Navier--Stokes (unstratified Kelvin--Helmholtz vortex). In both cases, SBI and QRM reproduce the target final states more accurately and in fewer iterations than DAL. We attribute this performance gap to additional terms present in SBI and QRM's respective backward integrations which are absent in DAL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00937v1</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Liam O'Connor, Daniel Lecoanet, Evan H. Anders, Kyle C. Augustson, Keaton J. Burns, Geoffrey M. Vasil, Jeffrey S. Oishi, Benjamin P. Brown</dc:creator>
    </item>
    <item>
      <title>Policy Optimization for PDE Control with a Warm Start</title>
      <link>https://arxiv.org/abs/2403.01005</link>
      <description>arXiv:2403.01005v1 Announce Type: cross 
Abstract: Dimensionality reduction is crucial for controlling nonlinear partial differential equations (PDE) through a "reduce-then-design" strategy, which identifies a reduced-order model and then implements model-based control solutions. However, inaccuracies in the reduced-order modeling can substantially degrade controller performance, especially in PDEs with chaotic behavior. To address this issue, we augment the reduce-then-design procedure with a policy optimization (PO) step. The PO step fine-tunes the model-based controller to compensate for the modeling error from dimensionality reduction. This augmentation shifts the overall strategy into reduce-then-design-then-adapt, where the model-based controller serves as a warm start for PO. Specifically, we study the state-feedback tracking control of PDEs that aims to align the PDE state with a specific constant target subject to a linear-quadratic cost. Through extensive experiments, we show that a few iterations of PO can significantly improve the model-based controller performance. Our approach offers a cost-effective alternative to PDE control using end-to-end reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01005v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangyuan Zhang, Saviz Mowlavi, Mouhacine Benosman, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features</title>
      <link>https://arxiv.org/abs/2403.01046</link>
      <description>arXiv:2403.01046v1 Announce Type: cross 
Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01046v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emi Zeger, Yifei Wang, Aaron Mishkin, Tolga Ergen, Emmanuel Cand\`es, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Quantifying Maximum Actuator Degradation for a Given $H_2/H_{\infty}$ Performance with Full-State Feedback Control</title>
      <link>https://arxiv.org/abs/2403.01333</link>
      <description>arXiv:2403.01333v1 Announce Type: cross 
Abstract: In this paper, we address the issue of quantifying maximum actuator degradation in linear time-invariant dynamical systems. We present a new unified framework for computing the state-feedback controller gain that meets a user-defined closed-loop performance criterion while also maximizing actuator degradation. This degradation is modeled as a first-order filter with additive noise. Our approach involves two novel convex optimization formulations that concurrently determine the controller gain, maximize actuator degradation, and maintain the desired closed-loop performance in both the $H_2$ and $H_{\infty}$ system norms. The results are limited to open-loop stable systems. We demonstrate the application of our results through the design of a full-state feedback controller for a model representing the longitudinal motion of the F-16 aircraft.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01333v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hrishav Das, Eliot Nychka, Raktim Bhattacharya</dc:creator>
    </item>
    <item>
      <title>The Implicit Bias of Heterogeneity towards Invariance and Causality</title>
      <link>https://arxiv.org/abs/2403.01420</link>
      <description>arXiv:2403.01420v1 Announce Type: cross 
Abstract: It is observed empirically that the large language models (LLM), trained with a variant of regression loss using numerous corpus from the Internet, can unveil causal associations to some extent. This is contrary to the traditional wisdom that ``association is not causation'' and the paradigm of traditional causal inference in which prior causal knowledge should be carefully incorporated into the design of methods. It is a mystery why causality, in a higher layer of understanding, can emerge from the regression task that pursues associations. In this paper, we claim the emergence of causality from association-oriented training can be attributed to the coupling effects from the heterogeneity of the source data, stochasticity of training algorithms, and over-parameterization of the learning models. We illustrate such an intuition using a simple but insightful model that learns invariance, a quasi-causality, using regression loss. To be specific, we consider multi-environment low-rank matrix sensing problems where the unknown r-rank ground-truth d*d matrices diverge across the environments but contain a lower-rank invariant, causal part. In this case, running pooled gradient descent will result in biased solutions that only learn associations in general. We show that running large-batch Stochastic Gradient Descent, whose each batch being linear measurement samples randomly selected from a certain environment, can successfully drive the solution towards the invariant, causal solution under certain conditions. This step is related to the relatively strong heterogeneity of the environments, the large step size and noises in the optimization algorithm, and the over-parameterization of the model. In summary, we unveil another implicit bias that is a result of the symbiosis between the heterogeneity of data and modern algorithms, which is, to the best of our knowledge, first in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01420v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Xu, Yihong Gu, Cong Fang</dc:creator>
    </item>
    <item>
      <title>Soft-constrained Schrodinger Bridge: a Stochastic Control Approach</title>
      <link>https://arxiv.org/abs/2403.01717</link>
      <description>arXiv:2403.01717v1 Announce Type: cross 
Abstract: Schr\"{o}dinger bridge can be viewed as a continuous-time stochastic control problem where the goal is to find an optimally controlled diffusion process with a pre-specified terminal distribution $\mu_T$. We propose to generalize this stochastic control problem by allowing the terminal distribution to differ from $\mu_T$ but penalizing the Kullback-Leibler divergence between the two distributions. We call this new control problem soft-constrained Schr\"{o}dinger bridge (SSB). The main contribution of this work is a theoretical derivation of the solution to SSB, which shows that the terminal distribution of the optimally controlled process is a geometric mixture of $\mu_T$ and some other distribution. This result is further extended to a time series setting. One application of SSB is the development of robust generative diffusion models. We propose a score matching-based algorithm for sampling from geometric mixtures and showcase its use via a numerical example for the MNIST data set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01717v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jhanvi Garg, Xianyang Zhang, Quan Zhou</dc:creator>
    </item>
    <item>
      <title>Statistical Mechanics of Dynamical System Identification</title>
      <link>https://arxiv.org/abs/2403.01723</link>
      <description>arXiv:2403.01723v1 Announce Type: cross 
Abstract: Recovering dynamical equations from observed noisy data is the central challenge of system identification. We develop a statistical mechanical approach to analyze sparse equation discovery algorithms, which typically balance data fit and parsimony through a trial-and-error selection of hyperparameters. In this framework, statistical mechanics offers tools to analyze the interplay between complexity and fitness, in analogy to that done between entropy and energy. To establish this analogy, we define the optimization procedure as a two-level Bayesian inference problem that separates variable selection from coefficient values and enables the computation of the posterior parameter distribution in closed form. A key advantage of employing statistical mechanical concepts, such as free energy and the partition function, is in the quantification of uncertainty, especially in in the low-data limit; frequently encountered in real-world applications. As the data volume increases, our approach mirrors the thermodynamic limit, leading to distinct sparsity- and noise-induced phase transitions that delineate correct from incorrect identification. This perspective of sparse equation discovery, is versatile and can be adapted to various other equation discovery algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01723v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei A. Klishin, Joseph Bakarji, J. Nathan Kutz, Krithika Manohar</dc:creator>
    </item>
    <item>
      <title>How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems</title>
      <link>https://arxiv.org/abs/2403.01757</link>
      <description>arXiv:2403.01757v1 Announce Type: cross 
Abstract: Recently, large language models (LLMs) have notably positioned them as capable tools for addressing complex optimization challenges. Despite this recognition, a predominant limitation of existing LLM-based optimization methods is their struggle to capture the relationships among decision variables when relying exclusively on numerical text prompts, especially in high-dimensional problems. Keeping this in mind, we first propose to enhance the optimization performance using multimodal LLM capable of processing both textual and visual prompts for deeper insights of the processed optimization problem. This integration allows for a more comprehensive understanding of optimization problems, akin to human cognitive processes. We have developed a multimodal LLM-based optimization framework that simulates human problem-solving workflows, thereby offering a more nuanced and effective analysis. The efficacy of this method is evaluated through extensive empirical studies focused on a well-known combinatorial optimization problem, i.e., capacitated vehicle routing problem. The results are compared against those obtained from the LLM-based optimization algorithms that rely solely on textual prompts, demonstrating the significant advantages of our multimodal approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01757v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiao Huang, Wenjie Zhang, Liang Feng, Xingyu Wu, Kay Chen Tan</dc:creator>
    </item>
    <item>
      <title>A Safe Screening Rule with Bi-level Optimization of $\nu$ Support Vector Machine</title>
      <link>https://arxiv.org/abs/2403.01769</link>
      <description>arXiv:2403.01769v1 Announce Type: cross 
Abstract: Support vector machine (SVM) has achieved many successes in machine learning, especially for a small sample problem. As a famous extension of the traditional SVM, the $\nu$ support vector machine ($\nu$-SVM) has shown outstanding performance due to its great model interpretability. However, it still faces challenges in training overhead for large-scale problems. To address this issue, we propose a safe screening rule with bi-level optimization for $\nu$-SVM (SRBO-$\nu$-SVM) which can screen out inactive samples before training and reduce the computational cost without sacrificing the prediction accuracy. Our SRBO-$\nu$-SVM is strictly deduced by integrating the Karush-Kuhn-Tucker (KKT) conditions, the variational inequalities of convex problems and the $\nu$-property. Furthermore, we develop an efficient dual coordinate descent method (DCDM) to further improve computational speed. Finally, a unified framework for SRBO is proposed to accelerate many SVM-type models, and it is successfully applied to one-class SVM. Experimental results on 6 artificial data sets and 30 benchmark data sets have verified the effectiveness and safety of our proposed methods in supervised and unsupervised tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01769v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiji Yang, Wanyi Chen, Huan Zhang, Yitian Xu, Lei Shi, Jianhua Zhao</dc:creator>
    </item>
    <item>
      <title>HOSCF: Efficient decoupling algorithms for finding the best rank-one approximation of higher-order tensors</title>
      <link>https://arxiv.org/abs/2403.01778</link>
      <description>arXiv:2403.01778v1 Announce Type: cross 
Abstract: Best rank-one approximation is one of the most fundamental tasks in tensor computation. In order to fully exploit modern multi-core parallel computers, it is necessary to develop decoupling algorithms for computing the best rank-one approximation of higher-order tensors at large scales. In this paper, we first build a bridge between the rank-one approximation of tensors and the eigenvector-dependent nonlinear eigenvalue problem (NEPv), and then develop an efficient decoupling algorithm, namely the higher-order self-consistent field (HOSCF) algorithm, inspired by the famous self-consistent field (SCF) iteration frequently used in computational chemistry. The convergence theory of the HOSCF algorithm and an estimation of the convergence speed are further presented. In addition, we propose an improved HOSCF (iHOSCF) algorithm that incorporates the Rayleigh quotient iteration, which can significantly accelerate the convergence of HOSCF. Numerical experiments show that the proposed algorithms can efficiently converge to the best rank-one approximation of both synthetic and real-world tensors and can scale with high parallel scalability on a modern parallel computer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01778v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuanfu Xiao, Zeyu Li, Chao Yang</dc:creator>
    </item>
    <item>
      <title>Progressive Smoothing for Motion Planning in Real-Time NMPC</title>
      <link>https://arxiv.org/abs/2403.01830</link>
      <description>arXiv:2403.01830v1 Announce Type: cross 
Abstract: Nonlinear model predictive control (NMPC) is a popular strategy for solving motion planning problems, including obstacle avoidance constraints, in autonomous driving applications. Non-smooth obstacle shapes, such as rectangles, introduce additional local minima in the underlying optimization problem. Smooth over-approximations, e.g., ellipsoidal shapes, limit the performance due to their conservativeness. We propose to vary the smoothness and the related over-approximation by a homotopy. Instead of varying the smoothness in consecutive sequential quadratic programming iterations, we use formulations that decrease the smooth over-approximation from the end towards the beginning of the prediction horizon. Thus, the real-time iterations algorithm is applicable to the proposed NMPC formulation. Different formulations are compared in simulation experiments and shown to successfully improve performance indicators without increasing the computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01830v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rudolf Reiter, Katrin Baumg\"artner, Rien Quirynen, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities</title>
      <link>https://arxiv.org/abs/2403.02004</link>
      <description>arXiv:2403.02004v1 Announce Type: cross 
Abstract: We prove non-asymptotic error bounds for particle gradient descent (PGD)~(Kuntz et al., 2023), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that, for models satisfying a condition generalizing both the log-Sobolev and the Polyak--{\L}ojasiewicz inequalities (LSI and P{\L}I, respectively), the flow converges exponentially fast to the set of minimizers of the free energy. We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the P{\L}I implies the so-called quadratic growth condition), and applying it to our new setting. We also generalize the Bakry--\'Emery Theorem and show that the LSI/P{\L}I generalization holds for models with strongly concave log-likelihoods. For such models, we further control PGD's discretization error, obtaining non-asymptotic error bounds. While we are motivated by the study of PGD, we believe that the inequalities and results we extend may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02004v1</guid>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rocco Caprio, Juan Kuntz, Samuel Power, Adam M. Johansen</dc:creator>
    </item>
    <item>
      <title>Time-Reversal of Stochastic Maximum Principle</title>
      <link>https://arxiv.org/abs/2403.02044</link>
      <description>arXiv:2403.02044v1 Announce Type: cross 
Abstract: Stochastic maximum principle (SMP) specifies a necessary condition for the solution of a stochastic optimal control problem. The condition involves a coupled system of forward and backward stochastic differential equations (FBSDE) for the state and the adjoint processes. Numerical solution of the FBSDE is challenging because the boundary condition of the adjoint process is specified at the terminal time, while the solution should be adaptable to the forward in time filtration of a Wiener process. In this paper, a "time-reversal" of the FBSDE system is proposed that involves integration with respect to a backward in time Wiener process. The time-reversal is used to propose an iterative Monte-Carlo procedure to solves the FBSDE system and its time-reversal simultaneously. The procedure involves approximating the {F\"ollmer's drift} and solving a regression problem between the state and its adjoint at each time. The procedure is illustrated for the linear quadratic (LQ) optimal control problem with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02044v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirhossein Taghvaei</dc:creator>
    </item>
    <item>
      <title>On Efficient Approximation of the Maximum Distance to A Point Over an Intersection of Balls</title>
      <link>https://arxiv.org/abs/2403.02071</link>
      <description>arXiv:2403.02071v1 Announce Type: cross 
Abstract: In this paper we study the NP-Hard problem of maximizing the distance over an intersection of balls to a given point. We expand the results found in \cite{funcos1}, where the authors characterize the farthest in an intersection of balls $\mathcal{Q}$ to the given point $C_0$ by constructing some intersection of halfspaces. In this paper, by slightly modifying the technique found in literature, we characterize the farthest in an intersection of balls $\mathcal{Q}$ with another intersection of balls $\mathcal{Q}_1$. As such, going backwards, we are naturally able to find the given intersection of balls $\mathcal{Q}$ as the max indicator intersection of balls of another one $\mathcal{Q}_{-1}$. By repeating the process, we find a sequence of intersection of balls $(\mathcal{Q}_{i})_{i \in \mathbb{Z}}$, which has $\mathcal{Q}$ as an element, namely $\mathcal{Q}_{0}$ and show that $\mathcal{Q}_{-\infty} = \mathcal{B}(C_0,R_0)$ where $R_0$ is the maximum distance from $C_0$ to a point in $\mathcal{Q}$. As a final application of the proposed theory we give a polynomial algorithm for computing the maximum distance under an oracle which returns the volume of an intersection of balls, showing that the later is NP-Hard. Finally, we present a randomized method %of polynomial complexity which allows an approximation of the maximum distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02071v1</guid>
      <category>cs.CG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beniamin Costandin, Marius Costandin</dc:creator>
    </item>
    <item>
      <title>The ultimate upper bound on the injectivity radius of the Stiefel manifold</title>
      <link>https://arxiv.org/abs/2403.02079</link>
      <description>arXiv:2403.02079v1 Announce Type: cross 
Abstract: We exhibit conjugate points on the Stiefel manifold endowed with any member of the family of Riemannian metrics introduced by H\"uper et al. (2021). This family contains the well-known canonical and Euclidean metrics. An upper bound on the injectivity radius of the Stiefel manifold in the considered metric is then obtained as the minimum between the length of the geodesic along which the points are conjugate and the length of certain geodesic loops. Numerical experiments support the conjecture that the obtained upper bound is in fact equal to the injectivity radius.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02079v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. -A. Absil, Simon Mataigne</dc:creator>
    </item>
    <item>
      <title>Transformers Provably Learn Feature-Position Correlations in Masked Image Modeling</title>
      <link>https://arxiv.org/abs/2403.02233</link>
      <description>arXiv:2403.02233v1 Announce Type: cross 
Abstract: Masked image modeling (MIM), which predicts randomly masked patches from unmasked ones, has emerged as a promising approach in self-supervised vision pretraining. However, the theoretical understanding of MIM is rather limited, especially with the foundational architecture of transformers. In this paper, to the best of our knowledge, we provide the first end-to-end theory of learning one-layer transformers with softmax attention in MIM self-supervised pretraining. On the conceptual side, we posit a theoretical mechanism of how transformers, pretrained with MIM, produce empirically observed local and diverse attention patterns on data distributions with spatial structures that highlight feature-position correlations. On the technical side, our end-to-end analysis of the training dynamics of softmax-based transformers accommodates both input and position embeddings simultaneously, which is developed based on a novel approach to track the interplay between the attention of feature-position and position-wise correlations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02233v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Huang, Zixin Wen, Yuejie Chi, Yingbin Liang</dc:creator>
    </item>
    <item>
      <title>Graphical Quadratic Algebra</title>
      <link>https://arxiv.org/abs/2403.02284</link>
      <description>arXiv:2403.02284v1 Announce Type: cross 
Abstract: We introduce Graphical Quadratic Algebra (GQA), a string diagrammatic calculus extending the language of Graphical Affine Algebra with a new generator characterised by invariance under rotation matrices. We show that GQA is a sound and complete axiomatisation for three different models: quadratic relations, which are a compositional formalism for least-squares problems, Gaussian stochastic processes, and Gaussian stochastic processes extended with non-determinisms. The equational theory of GQA sheds light on the connections between these perspectives, giving an algebraic interpretation to the interplay of stochastic behaviour, relational behaviour, non-determinism, and conditioning. As applications, we discuss various case studies, including linear regression, probabilistic programming, and electrical circuits with realistic (noisy) components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02284v1</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dario Stein, Fabio Zanasi, Richard Samuelson, Robin Piedeleu</dc:creator>
    </item>
    <item>
      <title>Koopman-Assisted Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2403.02290</link>
      <description>arXiv:2403.02290v1 Announce Type: cross 
Abstract: The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman (HJB) equation, are ubiquitous in reinforcement learning (RL) and control theory. However, these equations quickly become intractable for systems with high-dimensional states and nonlinearity. This paper explores the connection between the data-driven Koopman operator and Markov Decision Processes (MDPs), resulting in the development of two new RL algorithms to address these limitations. We leverage Koopman operator techniques to lift a nonlinear system into new coordinates where the dynamics become approximately linear, and where HJB-based methods are more tractable. In particular, the Koopman operator is able to capture the expectation of the time evolution of the value function of a given system via linear dynamics in the lifted coordinates. By parameterizing the Koopman operator with the control actions, we construct a ``Koopman tensor'' that facilitates the estimation of the optimal value function. Then, a transformation of Bellman's framework in terms of the Koopman tensor enables us to reformulate two max-entropy RL algorithms: soft value iteration and soft actor-critic (SAC). This highly flexible framework can be used for deterministic or stochastic systems as well as for discrete or continuous-time dynamics. Finally, we show that these Koopman Assisted Reinforcement Learning (KARL) algorithms attain state-of-the-art (SOTA) performance with respect to traditional neural network-based SAC and linear quadratic regulator (LQR) baselines on four controlled dynamical systems: a linear state-space system, the Lorenz system, fluid flow past a cylinder, and a double-well potential with non-isotropic stochastic forcing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02290v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Preston Rozwood, Edward Mehrez, Ludger Paehler, Wen Sun, Steven L. Brunton</dc:creator>
    </item>
    <item>
      <title>Byzantine-Resilient Distributed Optimization of Multi-Dimensional Functions</title>
      <link>https://arxiv.org/abs/2003.09038</link>
      <description>arXiv:2003.09038v5 Announce Type: replace 
Abstract: The problem of distributed optimization requires a group of agents to reach agreement on a parameter that minimizes the average of their local cost functions using information received from their neighbors. While there are a variety of distributed optimization algorithms that can solve this problem, they are typically vulnerable to malicious (or ``Byzantine'') agents that do not follow the algorithm. Recent attempts to address this issue focus on single dimensional functions, or provide analysis under certain assumptions on the statistical properties of the functions at the agents. In this paper, we propose a resilient distributed optimization algorithm for multi-dimensional convex functions. Our scheme involves two filtering steps at each iteration of the algorithm: (1) distance-based and (2) component-wise removal of extreme states. We show that this algorithm can mitigate the impact of up to $F$ Byzantine agents in the neighborhood of each regular node, without knowing the identities of the Byzantine agents in advance. In particular, we show that if the network topology satisfies certain conditions, all of the regular states are guaranteed to asymptotically converge to a bounded region that contains the global minimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2003.09038v5</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.23919/ACC45564.2020.9147396</arxiv:DOI>
      <dc:creator>Kananart Kuwaranancharoen, Lei Xin, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>Accelerated first-order methods for a class of semidefinite programs</title>
      <link>https://arxiv.org/abs/2206.00224</link>
      <description>arXiv:2206.00224v2 Announce Type: replace 
Abstract: This paper introduces a new storage-optimal first-order method (FOM), CertSDP, for solving a special class of semidefinite programs (SDPs) to high accuracy. The class of SDPs that we consider, the exact QMP-like SDPs, is characterized by low-rank solutions, a priori knowledge of the restriction of the SDP solution to a small subspace, and standard regularity assumptions such as strict complementarity. Crucially, we show how to use a certificate of strict complementarity to construct a low-dimensional strongly convex minimax problem whose optimizer coincides with a factorization of the SDP optimizer. From an algorithmic standpoint, we show how to construct the necessary certificate and how to solve the minimax problem efficiently. We accompany our theoretical results with preliminary numerical experiments suggesting that CertSDP significantly outperforms current state-of-the-art methods on large sparse exact QMP-like SDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.00224v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex L. Wang, Fatma Kilinc-Karzan</dc:creator>
    </item>
    <item>
      <title>The effect of smooth parametrizations on nonconvex optimization landscapes</title>
      <link>https://arxiv.org/abs/2207.03512</link>
      <description>arXiv:2207.03512v5 Announce Type: replace 
Abstract: We develop new tools to study landscapes in nonconvex optimization. Given one optimization problem, we pair it with another by smoothly parametrizing the domain. This is either for practical purposes (e.g., to use smooth optimization algorithms with good guarantees) or for theoretical purposes (e.g., to reveal that the landscape satisfies a strict saddle property). In both cases, the central question is: how do the landscapes of the two problems relate? More precisely: how do desirable points such as local minima and critical points in one problem relate to those in the other problem? A key finding in this paper is that these relations are often determined by the parametrization itself, and are almost entirely independent of the cost function. Accordingly, we introduce a general framework to study parametrizations by their effect on landscapes. The framework enables us to obtain new guarantees for an array of problems, some of which were previously treated on a case-by-case basis in the literature. Applications include: optimizing low-rank matrices and tensors through factorizations; solving semidefinite programs via the Burer-Monteiro approach; training neural networks by optimizing their weights and biases; and quotienting out symmetries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.03512v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-024-02058-3</arxiv:DOI>
      <arxiv:journal_reference>Math. Program. (2024)</arxiv:journal_reference>
      <dc:creator>Eitan Levin, Joe Kileel, Nicolas Boumal</dc:creator>
    </item>
    <item>
      <title>Convergence of policy gradient methods for finite-horizon exploratory linear-quadratic control problems</title>
      <link>https://arxiv.org/abs/2211.00617</link>
      <description>arXiv:2211.00617v3 Announce Type: replace 
Abstract: We study the global linear convergence of policy gradient (PG) methods for finite-horizon continuous-time exploratory linear-quadratic control (LQC) problems. The setting includes stochastic LQC problems with indefinite costs and allows additional entropy regularisers in the objective. We consider a continuous-time Gaussian policy whose mean is linear in the state variable and whose covariance is state-independent. Contrary to discrete-time problems, the cost is noncoercive in the policy and not all descent directions lead to bounded iterates. We propose geometry-aware gradient descents for the mean and covariance of the policy using the Fisher geometry and the Bures-Wasserstein geometry, respectively. The policy iterates are shown to satisfy an a-priori bound, and converge globally to the optimal policy with a linear rate. We further propose a novel PG method with discrete-time policies. The algorithm leverages the continuous-time analysis, and achieves a robust linear convergence across different action frequencies. A numerical experiment confirms the convergence and robustness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00617v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Giegrich, Christoph Reisinger, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth Nonconvex Minimax Problems with Coupled Linear Constraints</title>
      <link>https://arxiv.org/abs/2212.04672</link>
      <description>arXiv:2212.04672v3 Announce Type: replace 
Abstract: Nonconvex minimax problems have attracted wide attention in machine learning, signal processing and many other fields in recent years. In this paper, we propose a primal-dual alternating proximal gradient (PDAPG) algorithm and a primal-dual proximal gradient (PDPG-L) algorithm for solving nonsmooth nonconvex-(strongly) concave and nonconvex-linear minimax problems with coupled linear constraints, respectively. The iteration complexity of the two algorithms are proved to be $\mathcal{O}\left( \varepsilon ^{-2} \right)$ (resp. $\mathcal{O}\left( \varepsilon ^{-4} \right)$) under nonconvex-strongly concave (resp. nonconvex-concave) setting and $\mathcal{O}\left( \varepsilon ^{-3} \right)$ under nonconvex-linear setting to reach an $\varepsilon$-stationary point, respectively. To our knowledge, they are the first two algorithms with iteration complexity guarantees for solving the nonconvex minimax problems with coupled linear constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04672v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiling Zhang, Junlin Wang, Zi Xu, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>Slater conditions without interior points for programs in Lebesgue spaces with pointwise bounds and finitely many constraints</title>
      <link>https://arxiv.org/abs/2212.11249</link>
      <description>arXiv:2212.11249v2 Announce Type: replace 
Abstract: We consider optimization problems in Lebesgue spaces with pointwise box constraints and finitely many additional linear constraints. We prove that the existence of a Slater point which lies strictly between the pointwise bounds and which satisfies the linear constraints is sufficient for the existence of Lagrange multipliers. Surprisingly, the Slater point is also necessary for the existence of Lagrange multipliers in a certain sense. We also demonstrate how to handle additional finitely many nonlinear constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11249v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Simultaneously recovering running cost and Hamiltonian in Mean Field Games system</title>
      <link>https://arxiv.org/abs/2303.13096</link>
      <description>arXiv:2303.13096v3 Announce Type: replace 
Abstract: We propose and study several inverse problems for the mean field games (MFG) system in a bounded domain. Our focus is on simultaneously recovering the running cost and the Hamiltonian within the MFG system by the associated boundary observation. There are several technical novelties that make the study intriguing and challenging. First, the MFG system couples two nonlinear parabolic PDEs with one moving forward and the other one moving backward in time. Second, there is a probability density constraint on the population distribution of the agents. Third, the simultaneous recovery of two coupling factors within the MFG system is technically far from being trivial. Fourth, we consider both cases that the running cost depends on the population density locally and non-locally, and the two cases present different technical challenges for the inverse problem study. We develop two mathematical strategies that can ensure the probability constraint as well as effectively tackle the inverse problems, which are respectively termed as high-order variation and successive linearisation. In particular, the high-order variation method is new to the literature, which demonstrates a novel concept to examine the inverse problems by non-negative inputs only. We believe the methods developed can find applications to inverse problems in other contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13096v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Liu, Shen Zhang</dc:creator>
    </item>
    <item>
      <title>On the convergence of proximal gradient methods for convex simple bilevel optimization</title>
      <link>https://arxiv.org/abs/2305.03559</link>
      <description>arXiv:2305.03559v3 Announce Type: replace 
Abstract: This paper studies proximal gradient iterations for solving simple bilevel optimization problems where both the upper and the lower level cost functions are split as the sum of differentiable and (possibly nonsmooth) proximable functions. We develop a novel convergence recipe for iteration varying stepsizes that relies on Barzilai-Borwein type local estimates for the differentiable terms. Leveraging the convergence recipe, under global Lipschitz gradient continuity, we establish convergence for a nonadaptive stepsize sequence, without requiring any strong convexity or linesearch. In the locally Lipschitz differentiable setting, we develop an adaptive linesearch method that introduces a systematic adaptive scheme enabling large and nonmonotonic stepsize sequences while being insensitive to the choice of hyperparameters and initialization. Numerical simulations are provided showcasing favorable convergence speed of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03559v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Puya Latafat, Andreas Themelis, Silvia Villa, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>(Rectified Version) Push-LSVRG-UP: Distributed Stochastic Optimization over Unbalanced Directed Networks with Uncoordinated Triggered Probabilities</title>
      <link>https://arxiv.org/abs/2305.09181</link>
      <description>arXiv:2305.09181v4 Announce Type: replace 
Abstract: Distributed stochastic optimization, arising in the crossing and integration of traditional stochastic optimization, distributed computing and storage, and network science, has advantages of high efficiency and a low per-iteration computational complexity in resolving large-scale optimization problems. This paper concentrates on resolving a large-scale convex finite-sum optimization problem in a multi-agent system over unbalanced directed networks. To tackle this problem in an efficient way, a distributed consensus optimization algorithm, adopting the push-sum technique and a distributed loopless stochastic variance-reduced gradient (LSVRG) method with uncoordinated triggered probabilities, is developed and named Push-LSVRG-UP. Each agent under this algorithmic framework performs only local computation and communicates only with its neighbors without leaking their private information. The convergence analysis of Push-LSVRG-UP is relied on analyzing the contraction relationships between four error terms associated with the multi-agent system. Theoretical results provide an explicit feasible range of the constant step-size, a linear convergence rate, and an iteration complexity of Push-LSVRG-UP when achieving the globally optimal solution. It is shown that Push-LSVRG-UP achieves the superior characteristics of accelerated linear convergence, fewer storage costs, and a lower per-iteration computational complexity than most existing works. Meanwhile, the introduction of an uncoordinated probabilistic triggered mechanism allows Push-LSVRG-UP to facilitate the independence and flexibility of agents in computing local batch gradients. In simulations, the practicability and improved performance of Push-LSVRG-UP are manifested via resolving two distributed learning problems based on real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09181v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNSE.2022.3225229</arxiv:DOI>
      <arxiv:journal_reference>IEEE TRANSACTIONS ON NETWORK SCIENCE AND ENGINEERING, VOL. 10, NO. 2, 2023, PP. 934-950</arxiv:journal_reference>
      <dc:creator>Jinhui Hu, Guo Chen, Huaqing Li, Zixiang Shen, Weidong Zhang</dc:creator>
    </item>
    <item>
      <title>Symmetric Stair Preconditioning of Linear Systems for Parallel Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2309.06427</link>
      <description>arXiv:2309.06427v2 Announce Type: replace 
Abstract: There has been a growing interest in parallel strategies for solving trajectory optimization problems. One key step in many algorithmic approaches to trajectory optimization is the solution of moderately-large and sparse linear systems. Iterative methods are particularly well-suited for parallel solves of such systems. However, fast and stable convergence of iterative methods is reliant on the application of a high-quality preconditioner that reduces the spread and increase the clustering of the eigenvalues of the target matrix. To improve the performance of these approaches, we present a new parallel-friendly symmetric stair preconditioner. We prove that our preconditioner has advantageous theoretical properties when used in conjunction with iterative methods for trajectory optimization such as a more clustered eigenvalue spectrum. Numerical experiments with typical trajectory optimization problems reveal that as compared to the best alternative parallel preconditioner from the literature, our symmetric stair preconditioner provides up to a 34% reduction in condition number and up to a 25% reduction in the number of resulting linear system solver iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06427v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xueyi Bu, Brian Plancher</dc:creator>
    </item>
    <item>
      <title>Maximum principle for a Markovian regime switching system with partial information under model uncertainty</title>
      <link>https://arxiv.org/abs/2309.10454</link>
      <description>arXiv:2309.10454v3 Announce Type: replace 
Abstract: In this paper, we study a stochastic optimal control problem for a Markovian regime switching system, where the coefficients of the state equation and the cost functional are uncertain. First, we obtain the variational inequality by showing the continuity of solutions to variational equations with respect to the uncertainty parameter $\theta$. Second, using the linearization and weak convergence techniques, we prove the necessary stochastic maximum principle of the stochastic optimal control. Finally, as an application, a risk-minimizing portfolio selection problem is studied. In addition, $L^\beta$-solutions and $L^\beta$-estimates of stochastic differential equations with regime switching are given for $\beta=2k$ with $k\in \mathbb{N}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10454v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Hao, Jiaqiang Wen, Jie Xiong</dc:creator>
    </item>
    <item>
      <title>Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization</title>
      <link>https://arxiv.org/abs/2310.03234</link>
      <description>arXiv:2310.03234v4 Announce Type: replace 
Abstract: This paper investigates new families of compositional optimization problems, called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\epsilon$-stationary point of the Moreau envelop of the objective function. Additionally, we also extend the algorithm to solving novel non-smooth weakly-convex tri-level finite-sum coupled compositional optimization problems, which feature a nested arrangement of three functions. Lastly, we explore the applications of our algorithms in deep learning for two-way partial AUC maximization and multi-instance two-way partial AUC maximization, using empirical studies to showcase the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03234v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quanqi Hu, Dixian Zhu, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Inverse linear-quadratic nonzero-sum differential games</title>
      <link>https://arxiv.org/abs/2310.05631</link>
      <description>arXiv:2310.05631v2 Announce Type: replace 
Abstract: $ $This paper addresses the inverse problem for Linear-Quadratic (LQ) nonzero-sum $N$-player differential games, where the goal is to learn parameters of an unknown cost function for the game, called observed, given the demonstrated trajectories that are known to be generated by stationary linear feedback Nash equilibrium laws. Towards this end, using the demonstrated data, a synthesized game needs to be constructed, which is required to be equivalent to the observed game in the sense that the trajectories generated by the equilibrium feedback laws of the $N$ players in the synthesized game are the same as those demonstrated trajectories. We show a model-based algorithm that can accomplish this task using the given trajectories. We then extend this model-based algorithm to a model-free setting to solve the same problem in the case when the system's matrices are unknown. The algorithms combine both inverse optimal control and reinforcement learning methods making extensive use of gradient descent optimization for the latter. The analysis of the algorithm focuses on the proof of its convergence and stability. To further illustrate possible solution characterization, we show how to generate an infinite number of equivalent games, not requiring to run repeatedly the complete algorithm. Simulation results validate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05631v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Martirosyan, M. Cao</dc:creator>
    </item>
    <item>
      <title>Tight Bounds for the Maximum Distance Over a Polytope to a Given Point</title>
      <link>https://arxiv.org/abs/2310.06185</link>
      <description>arXiv:2310.06185v2 Announce Type: replace 
Abstract: In this paper we study the problem of maximizing the distance to a given point $C_0$ over a polytope $\mathcal{P}$. Assuming that the polytope is circumscribed by a known ball we construct an intersection of balls which preserves the vertices of the polytope on the boundary of this ball, and show that the intersection of balls approximates the polytope arbitrarily well. Then, we use some known results regarding the maximization of distances to a given point over an intersection of balls to create a new polytope which preserves the maximizers to the original problem. Next, a new intersection of balls is obtained in a similar fashion, and as such, after a finite number of iterations, we conjecture, we end up with an intersection of balls over which we can maximize the distance to the given point. The obtained distance is shown to be a non trivial upper bound to the original distance. Tests are made with maximizing the distance to a random point over the unit hypercube up to dimension $n = 100$. Several detailed 2-d examples are also shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06185v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Costandin, Beniamin Costandin</dc:creator>
    </item>
    <item>
      <title>Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments</title>
      <link>https://arxiv.org/abs/2311.00123</link>
      <description>arXiv:2311.00123v2 Announce Type: replace 
Abstract: As a primary contribution, we present a convergence theorem for stochastic iterations, and in particular, Q-learning iterates, under a general, possibly non-Markovian, stochastic environment. Our conditions for convergence involve an ergodicity and a positivity criterion. We provide a precise characterization on the limit of the iterates and conditions on the environment and initializations for convergence. As our second contribution, we discuss the implications and applications of this theorem to a variety of stochastic control problems with non-Markovian environments involving (i) quantized approximations of fully observed Markov Decision Processes (MDPs) with continuous spaces (where quantization break down the Markovian structure), (ii) quantized approximations of belief-MDP reduced partially observable MDPS (POMDPs) with weak Feller continuity and a mild version of filter stability (which requires the knowledge of the model by the controller), (iii) finite window approximations of POMDPs under a uniform controlled filter stability (which does not require the knowledge of the model), and (iv) for multi-agent models where convergence of learning dynamics to a new class of equilibria, subjective Q-learning equilibria, will be studied. In addition to the convergence theorem, some implications of the theorem above are new to the literature and others are interpreted as applications of the convergence theorem. Some open problems are noted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00123v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Devran Kara, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Invariance Proximity: Closed-Form Error Bounds for Finite-Dimensional Koopman-Based Models</title>
      <link>https://arxiv.org/abs/2311.13033</link>
      <description>arXiv:2311.13033v3 Announce Type: replace 
Abstract: A popular way to approximate the Koopman operator's action on a finite-dimensional subspace of functions is via orthogonal projections. The quality of the projected model directly depends on the selected subspace, specifically on how close it is to being invariant under the Koopman operator. The notion of invariance proximity provides a tight upper bound on the worst-case relative prediction error of the finite-dimensional model. However, its direct calculation is computationally challenging. This paper leverages the geometric structure behind the definition of invariance proximity to provide a closed-form expression in terms of Jordan principal angles on general inner product spaces. Unveiling this connection allows us to exploit specific isomorphisms to circumvent the computational challenges associated with spaces of functions and enables the use of existing efficient numerical routines to compute invariance proximity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13033v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Masih Haseli, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>Everything is possible: constructing spectrahedra with prescribed facial dimensions</title>
      <link>https://arxiv.org/abs/2312.04419</link>
      <description>arXiv:2312.04419v2 Announce Type: replace 
Abstract: Given any finite set of nonnegative integers, there exists a closed convex set whose facial dimension signature coincides with this set of integers, that is, the dimensions of its nonempty faces comprise exactly this set of integers. In this work, we show that such sets can be realised as solution sets of systems of finitely many convex quadratic inequalities, and hence are representable via second-order cone programming problems, and are, in particular, spectrahedral. It also follows that these sets are facially exposed, in contrast to earlier constructions. We obtain a lower bound on the minimum number of convex quadratic inequalities needed to represent a closed convex set with prescribed facial dimension signature, and show that our bound is tight for some special cases. Finally, we relate the question of finding efficient representations with indecomposability of integer sequences and other topics, and discuss a substantial number of open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04419v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vera Roshchina, Levent Tun\c{c}el</dc:creator>
    </item>
    <item>
      <title>Higher-order Riemannian splines and the interpolation problem: an approach of gradient flows</title>
      <link>https://arxiv.org/abs/2312.10513</link>
      <description>arXiv:2312.10513v3 Announce Type: replace 
Abstract: In this article, we demonstrate that spline interpolation problems on smooth Riemannian manifolds can be resolved by applying the method of gradient flows proposed here. Our approach appears to be novel in addressing such problems and can be extended to the spline interpolation problem on Lie groups, which are commonly implicated in formulations of mechanical optimal control theory. This approach seems innovative in both optimal and geometric control theory. We provide the existence of global solutions in H\"{o}lder spaces for the gradient flow, whose asymptotic limits establish the existence of Riemannian splines, thereby offering solutions to spline interpolation problems on smooth Riemannian manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10513v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chun-Chi Lin, Dung The Tran</dc:creator>
    </item>
    <item>
      <title>Distributed fixed-point algorithms for dynamic convex optimization over decentralized and unbalanced wireless networks</title>
      <link>https://arxiv.org/abs/2401.18030</link>
      <description>arXiv:2401.18030v3 Announce Type: replace 
Abstract: We consider problems where agents in a network seek a common quantity, measured independently and periodically by each agent through a local time-varying process. Numerous solvers addressing such problems have been developed in the past, featuring various adaptations of the local processing and the consensus step. However, existing solvers still lack support for advanced techniques, such as superiorization and over-the-air function computation (OTA-C). To address this limitation, we introduce a comprehensive framework for the analysis of distributed algorithms by characterizing them using the quasi-Fej\'er type algorithms and an extensive communication model. Under weak assumptions, we prove almost sure convergence of the algorithm to a common estimate for all agents. Moreover, we develop a specific class of algorithms within this framework to tackle distributed optimization problems with time-varying objectives, and, assuming that a time-invariant solution exists, prove its convergence to a solution. We also present a novel OTA-C protocol for consensus step in large decentralized networks, reducing communication overhead and enhancing network autonomy as compared to the existing protocols. The effectiveness of the algorithm, featuring superiorization and OTA-C, is demonstrated in a real-world application of distributed supervised learning over time-varying wireless networks, highlighting its low-latency and energy-efficiency compared to standard approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.18030v3</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Navneet Agrawal, Renato L. G. Cavalcante, S{\l}awomir Sta\'nczak</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Mean Field Games in Hilbert spaces</title>
      <link>https://arxiv.org/abs/2402.14935</link>
      <description>arXiv:2402.14935v2 Announce Type: replace 
Abstract: This paper represents the first attempt to develop a theory for linear-quadratic mean field games in possibly infinite dimensional Hilbert spaces. As a starting point, we study the case, considered in most finite dimensional contributions on the topic, where the dependence on the distribution enters just in the objective functional through the mean. This feature allows, similarly to the finite dimensional case, to reduce the usual mean field game system to a Riccati equation and a forward-backward coupled system of abstract evolution equations. Such system is completely new in infinite dimension and no results have been proved on it so far. We show existence and uniqueness of solutions for such system, applying a delicate approximation procedure. We apply the results to a production output planning problem with delay in the control variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14935v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salvatore Federico, Fausto Gozzi, Daria Ghilli</dc:creator>
    </item>
    <item>
      <title>Identity Concealment Games: How I Learned to Stop Revealing and Love the Coincidences</title>
      <link>https://arxiv.org/abs/2105.05377</link>
      <description>arXiv:2105.05377v2 Announce Type: replace-cross 
Abstract: In an adversarial environment, a hostile player performing a task may behave like a non-hostile one in order not to reveal its identity to an opponent. To model such a scenario, we define identity concealment games: zero-sum stochastic reachability games with a zero-sum objective of identity concealment. To measure the identity concealment of the player, we introduce the notion of an average player. The average player's policy represents the expected behavior of a non-hostile player. We show that there exists an equilibrium policy pair for every identity concealment game and give the optimality equations to synthesize an equilibrium policy pair. If the player's opponent follows a non-equilibrium policy, the player can hide its identity better. For this reason, we study how the hostile player may learn the opponent's policy. Since learning via exploration policies would quickly reveal the hostile player's identity to the opponent, we consider the problem of learning a near-optimal policy for the hostile player using the game runs collected under the average player's policy. Consequently, we propose an algorithm that provably learns a near-optimal policy and give an upper bound on the number of sample runs to be collected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.05377v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Karabag, Mustafa O., Melkior Ornik, and Ufuk Topcu. "Identity concealment games: How I learned to stop revealing and love the coincidences." Automatica 161 (2024): 111482</arxiv:journal_reference>
      <dc:creator>Mustafa O. Karabag, Melkior Ornik, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient adaptive algorithms for neural networks</title>
      <link>https://arxiv.org/abs/2105.13937</link>
      <description>arXiv:2105.13937v3 Announce Type: replace-cross 
Abstract: We present a new class of Langevin based algorithms, which overcomes many of the known shortcomings of popular adaptive optimizers that are currently used for the fine tuning of deep learning models. Its underpinning theory relies on recent advances of Euler's polygonal approximations for stochastic differential equations (SDEs) with monotone coefficients. As a result, it inherits the stability properties of tamed algorithms, while it addresses other known issues, e.g. vanishing gradients in neural networks. In particular, we provide a nonasymptotic analysis and full theoretical guarantees for the convergence properties of an algorithm of this novel class, which we named TH$\varepsilon$O POULA (or, simply, TheoPouLa). Finally, several experiments are presented with different types of deep learning models, which show the superior performance of TheoPouLa over many popular adaptive optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.13937v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong-Young Lim, Sotirios Sabanis</dc:creator>
    </item>
    <item>
      <title>Enhancing Digital Health Services: A Machine Learning Approach to Personalized Exercise Goal Setting</title>
      <link>https://arxiv.org/abs/2204.00961</link>
      <description>arXiv:2204.00961v3 Announce Type: replace-cross 
Abstract: The utilization of digital health has increased recently, and these services provide extensive guidance to encourage users to exercise frequently by setting daily exercise goals to promote a healthy lifestyle. These comprehensive guides evolved from the consideration of various personalized behavioral factors. Nevertheless, existing approaches frequently neglect the users dynamic behavior and the changing in their health conditions. This study aims to fill this gap by developing a machine learning algorithm that dynamically updates auto-suggestion exercise goals using retrospective data and realistic behavior trajectory. We conducted a methodological study by designing a deep reinforcement learning algorithm to evaluate exercise performance, considering fitness-fatigue effects. The deep reinforcement learning algorithm combines deep learning techniques to analyse time series data and infer user exercise behavior. In addition, we use the asynchronous advantage actor-critic algorithm for reinforcement learning to determine the optimal exercise intensity through exploration and exploitation. The personalized exercise data and biometric data used in this study were collected from publicly available datasets, encompassing walking, sports logs, and running. In our study, we conducted The statistical analyses/inferential tests to compare the effectiveness of machine learning approach in exercise goal setting across different exercise goal setting strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.00961v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1177/20552076241233247</arxiv:DOI>
      <dc:creator>Ji Fang, Vincent CS Lee, Hao Ji, Haiyan Wang</dc:creator>
    </item>
    <item>
      <title>Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2305.18436</link>
      <description>arXiv:2305.18436v3 Announce Type: replace-cross 
Abstract: $K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the $K$-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves substantially smaller mis-clustering errors compared to the existing state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18436v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yubo Zhuang, Xiaohui Chen, Yun Yang, Richard Y. Zhang</dc:creator>
    </item>
    <item>
      <title>Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning</title>
      <link>https://arxiv.org/abs/2306.04815</link>
      <description>arXiv:2306.04815v2 Announce Type: replace-cross 
Abstract: In this paper, we first present an explanation regarding the common occurrence of spikes in the training loss when neural networks are trained with stochastic gradient descent (SGD). We provide evidence that the spikes in the training loss of SGD are "catapults", an optimization phenomenon originally observed in GD with large learning rates in [Lewkowycz et al. 2020]. We empirically show that these catapults occur in a low-dimensional subspace spanned by the top eigenvectors of the tangent kernel, for both GD and SGD. Second, we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04815v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Libin Zhu, Chaoyue Liu, Adityanarayanan Radhakrishnan, Mikhail Belkin</dc:creator>
    </item>
    <item>
      <title>A Global Method for Relaxation for Multi-levelled Structured Deformations</title>
      <link>https://arxiv.org/abs/2309.09307</link>
      <description>arXiv:2309.09307v3 Announce Type: replace-cross 
Abstract: We prove an integral representation result for a class of variational functionals appearing in the framework of hierarchical systems of structured deformations via a global method for relaxation. Some applications to specific relaxation problems are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09307v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ana Cristina Barroso, Jos\'e Matias, Elvira Zappale</dc:creator>
    </item>
    <item>
      <title>Orlicz regrets to consistently bound statistics of random variables with an application to environmental indicators</title>
      <link>https://arxiv.org/abs/2310.05168</link>
      <description>arXiv:2310.05168v2 Announce Type: replace-cross 
Abstract: Evaluating environmental variables that vary stochastically is the principal topic for designing better environmental management and restoration schemes. Both the upper and lower estimates of these variables, such as water quality indices and flood and drought water levels, are important and should be consistently evaluated within a unified mathematical framework. We propose a novel pair of Orlicz regrets to consistently bound the statistics of random variables both from below and above. Here, consistency indicates that the upper and lower bounds are evaluated with common coefficients and parameter values being different from some of the risk measures proposed thus far. Orlicz regrets can flexibly evaluate the statistics of random variables based on their tail behavior. The explicit linkage between Orlicz regrets and divergence risk measures was exploited to better comprehend them. We obtain sufficient conditions to pose the Orlicz regrets as well as divergence risk measures, and further provide gradient descent-type numerical algorithms to compute them. Finally, we apply the proposed mathematical framework to the statistical evaluation of 31-year water quality data as key environmental indicators in a Japanese river environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05168v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka, Yumi Yoshioka</dc:creator>
    </item>
    <item>
      <title>A connection between Tempering and Entropic Mirror Descent</title>
      <link>https://arxiv.org/abs/2310.11914</link>
      <description>arXiv:2310.11914v2 Announce Type: replace-cross 
Abstract: This paper explores the connections between tempering (for Sequential Monte Carlo; SMC) and entropic mirror descent to sample from a target probability distribution whose unnormalized density is known. We establish that tempering SMC corresponds to entropic mirror descent applied to the reverse Kullback-Leibler (KL) divergence and obtain convergence rates for the tempering iterates. Our result motivates the tempering iterates from an optimization point of view, showing that tempering can be seen as a descent scheme of the KL divergence with respect to the Fisher-Rao geometry, in contrast to Langevin dynamics that perform descent of the KL with respect to the Wasserstein-2 geometry. We exploit the connection between tempering and mirror descent iterates to justify common practices in SMC and derive adaptive tempering rules that improve over other alternative benchmarks in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11914v2</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Chopin, Francesca R. Crucinio, Anna Korba</dc:creator>
    </item>
    <item>
      <title>Bounded weak solutions for Keller-Segel equations with generalized diffusion and logistic source via an unbalanced Optimal Transport splitting scheme</title>
      <link>https://arxiv.org/abs/2401.08188</link>
      <description>arXiv:2401.08188v2 Announce Type: replace-cross 
Abstract: We consider a parabolic-elliptic type of Keller-Segel equations with generalized diffusion and logistic source under homogeneous Neumann-Neumann boundary conditions. We construct bounded weak solutions globally in time in an unbalanced optimal transport framework, provided that the magnitude of the chemotactic sensitivity can be restricted depending on parameters. In the case of subquadratic degradation of the logistic source, we quantify the chemotactic sensitivity, in particular, in terms of the power of degradation and the pointwise bound of the initial density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08188v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyungkeun Kang, Hwa Kil Kim, Geuntaek Seo</dc:creator>
    </item>
    <item>
      <title>On the optimal objective value of random linear programs</title>
      <link>https://arxiv.org/abs/2401.17530</link>
      <description>arXiv:2401.17530v3 Announce Type: replace-cross 
Abstract: We consider the problem of maximizing $\langle c,x \rangle$ subject to the constraints $Ax \leq \mathbf{1}$, where $x\in{\mathbb R}^n$, $A$ is an $m\times n$ matrix with mutually independent centered subgaussian entries of unit variance, and $c$ is a cost vector of unit Euclidean length. In the asymptotic regime $n\to\infty$, $\frac{m}{n}\to\infty$, and under some additional assumptions on $c$, we prove that the optimal objective value $z^*$ of the linear program satisfies $$ \lim\limits_{n\to\infty}\sqrt{2\log(m/n)}\,z^*= 1\quad \mbox{almost surely}. $$ In the context of high-dimensional convex geometry, our findings imply sharp asymptotic bounds on the spherical mean width of the random convex polyhedron $P=\{x\in{\mathbb R}^n:\; Ax\leq \mathbf{1}\}$. We provide numerical experiments as supporting data for the theoretical predictions. Further, we carry out numerical studies of the limiting distribution and the standard deviation of $z^*$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17530v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marzieh Bakhshi, James Ostrowski, Konstantin Tikhomirov</dc:creator>
    </item>
    <item>
      <title>Can We Remove the Square-Root in Adaptive Gradient Methods? A Second-Order Perspective</title>
      <link>https://arxiv.org/abs/2402.03496</link>
      <description>arXiv:2402.03496v3 Announce Type: replace-cross 
Abstract: Adaptive gradient optimizers like Adam(W) are the default training algorithms for many deep learning architectures, such as transformers. Their diagonal preconditioner is based on the gradient outer product which is incorporated into the parameter update via a square root. While these methods are often motivated as approximate second-order methods, the square root represents a fundamental difference. In this work, we investigate how the behavior of adaptive methods changes when we remove the root, i.e. strengthen their second-order motivation. Surprisingly, we find that such square-root-free adaptive methods close the generalization gap to SGD on convolutional architectures, while maintaining their root-based counterpart's performance on transformers. The second-order perspective also has practical benefits for the development of adaptive methods with non-diagonal preconditioner. In contrast to root-based counterparts like Shampoo, they do not require numerically unstable matrix square roots and therefore work well in low precision, which we demonstrate empirically. This raises important questions regarding the currently overlooked role of adaptivity for the success of adaptive methods since the success is often attributed to sign descent induced by the root.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03496v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wu Lin, Felix Dangel, Runa Eschenhagen, Juhan Bae, Richard E. Turner, Alireza Makhzani</dc:creator>
    </item>
    <item>
      <title>Multi-Player Resource-Sharing Games with Fair Reward Allocation</title>
      <link>https://arxiv.org/abs/2402.05300</link>
      <description>arXiv:2402.05300v2 Announce Type: replace-cross 
Abstract: This paper considers a multi-player resource-sharing game with a fair reward allocation model. Multiple players choose from a collection of resources. Each resource brings a random reward equally divided among the players who choose it. We consider two settings. The first setting is a one-slot game where the mean rewards of the resources are known to all the players, and the objective of player 1 is to maximize their worst-case expected utility. Certain special cases of this setting have explicit solutions. These cases provide interesting yet non-intuitive insights into the problem. The second setting is an online setting, where the game is played over a finite time horizon, where the mean rewards are unknown to the first player. Instead, the first player receives, as feedback, the rewards of the resources they chose after the action. We develop a novel Upper Confidence Bound (UCB) algorithm that minimizes the worst-case regret of the first player using the feedback received.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05300v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mevan Wijewardena, Michael. J Neely</dc:creator>
    </item>
    <item>
      <title>Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation</title>
      <link>https://arxiv.org/abs/2402.18839</link>
      <description>arXiv:2402.18839v2 Announce Type: replace-cross 
Abstract: The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated diffusion models, with the guidance-based classifier-free method taking the lead. However, the theory of the guidance-based method not only requires the user to fine-tune the "guidance strength," but its target vector field does not necessarily correspond to the conditional distribution used in training. In this paper, we develop the theory of conditional generation based on Flow Matching, a current strong contender of diffusion methods. Motivated by the interpretation of a probability path as a distribution on path space, we establish a novel theory of flow-based generation of conditional distribution by employing the mathematical framework of generalized continuity equation instead of the continuity equation in flow matching. This theory naturally derives a method that aims to match the matrix field as opposed to the vector field. Our framework ensures the continuity of the generated conditional distribution through the existence of flow between conditional distributions. We will present our theory through experiments and mathematical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18839v2</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noboru Isobe, Masanori Koyama, Kohei Hayashi, Kenji Fukumizu</dc:creator>
    </item>
  </channel>
</rss>
