<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Jun 2024 03:12:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the randomized Euler scheme for SDEs with integral-form drift</title>
      <link>https://arxiv.org/abs/2405.20481</link>
      <description>arXiv:2405.20481v1 Announce Type: new 
Abstract: In this paper, we investigate the problem of strong approximation of the solution of SDEs in the case when the drift coefficient is given in the integral form. Such drift often appears when analyzing stochastic dynamics of optimization procedures in machine learning problems. We discuss connections of the defined randomized Euler approximation scheme with the perturbed version of the stochastic gradient descent (SGD) algorithm. We investigate its upper error bounds, in terms of the discretization parameter n and the size M of the random sample drawn at each step of the algorithm, in different subclasses of coefficients of the underlying SDE. Finally, the results of numerical experiments performed by using GPU architecture are also reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20481v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pawe{\l} Przyby{\l}owicz, Micha{\l} Sobieraj</dc:creator>
    </item>
    <item>
      <title>CPAFT: A Consistent Parallel Advancing Front Technique for Unstructured Triangular/Tetrahedral Mesh Generation</title>
      <link>https://arxiv.org/abs/2405.20618</link>
      <description>arXiv:2405.20618v1 Announce Type: new 
Abstract: Compared with the remarkable progress made in parallel numerical solvers of partial differential equations,the development of algorithms for generating unstructured triangular/tetrahedral meshes has been relatively sluggish. In this paper, we propose a novel, consistent parallel advancing front technique (CPAFT) by combining the advancing front technique, the domain decomposition method based on space-filling curves, the distributed forest-of-overlapping-trees approach, and the consistent parallel maximal independent set algorithm. The newly proposed CPAFT algorithm can mathematically ensure that the generated unstructured triangular/tetrahedral meshes are independent of the number of processors and the implementation of domain decomposition. Several numerical tests are conducted to validate the parallel consistency and outstanding parallel efficiency of the proposed algorithm, which scales effectively up to two thousand processors. This is, as far as we know, the first parallel unstructured triangular/tetrahedral mesh generator with scalability to O(1,000) CPU processors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20618v1</guid>
      <category>math.NA</category>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengdi Ma, Jizu Huang, Hao Luo, Chao Yang</dc:creator>
    </item>
    <item>
      <title>Solving partial differential equations with sampled neural networks</title>
      <link>https://arxiv.org/abs/2405.20836</link>
      <description>arXiv:2405.20836v1 Announce Type: new 
Abstract: Approximation of solutions to partial differential equations (PDE) is an important problem in computational science and engineering. Using neural networks as an ansatz for the solution has proven a challenge in terms of training time and approximation accuracy. In this contribution, we discuss how sampling the hidden weights and biases of the ansatz network from data-agnostic and data-dependent probability distributions allows us to progress on both challenges. In most examples, the random sampling schemes outperform iterative, gradient-based optimization of physics-informed neural networks regarding training time and accuracy by several orders of magnitude. For time-dependent PDE, we construct neural basis functions only in the spatial domain and then solve the associated ordinary differential equation with classical methods from scientific computing over a long time horizon. This alleviates one of the greatest challenges for neural PDE solvers because it does not require us to parameterize the solution in time. For second-order elliptic PDE in Barron spaces, we prove the existence of sampled networks with $L^2$ convergence to the solution. We demonstrate our approach on several time-dependent and static PDEs. We also illustrate how sampled networks can effectively solve inverse problems in this setting. Benefits compared to common numerical schemes include spectral convergence and mesh-free construction of basis functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20836v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chinmay Datar, Taniya Kapoor, Abhishek Chandra, Qing Sun, Iryna Burak, Erik Lien Bolager, Anna Veselovska, Massimo Fornasier, Felix Dietrich</dc:creator>
    </item>
    <item>
      <title>Influx ratio preserving coupling conditions for the networked Lighthill-Whitham-Richards model</title>
      <link>https://arxiv.org/abs/2405.21005</link>
      <description>arXiv:2405.21005v1 Announce Type: new 
Abstract: A new coupling rule for the Lighthill-Whitham-Richards model at merging junctions is introduced that imposes the preservation of the ratio between inflow from a given road to the total inflow into the junction. This rule is considered both in the context of the original traffic flow model and a relaxation setting giving rise to two different Riemann solvers that are discussed for merging 2-to-1 junctions. Numerical experiments are shown suggesting that the relaxation based Riemann solver is capable of suitable predictions of both, free-flow and congestion scenarios without relying on flow maximization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.21005v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niklas Kolbe</dc:creator>
    </item>
    <item>
      <title>Quantitative Convergences of Lie Group Momentum Optimizers</title>
      <link>https://arxiv.org/abs/2405.20390</link>
      <description>arXiv:2405.20390v1 Announce Type: cross 
Abstract: Explicit, momentum-based dynamics that optimize functions defined on Lie groups can be constructed via variational optimization and momentum trivialization. Structure preserving time discretizations can then turn this dynamics into optimization algorithms. This article investigates two types of discretization, Lie Heavy-Ball, which is a known splitting scheme, and Lie NAG-SC, which is newly proposed. Their convergence rates are explicitly quantified under $L$-smoothness and local strong convexity assumptions. Lie NAG-SC provides acceleration over the momentumless case, i.e. Riemannian gradient descent, but Lie Heavy-Ball does not. When compared to existing accelerated optimizers for general manifolds, both Lie Heavy-Ball and Lie NAG-SC are computationally cheaper and easier to implement, thanks to their utilization of group structure. Only gradient oracle and exponential map are required, but not logarithm map or parallel transport which are computational costly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20390v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingkai Kong, Molei Tao</dc:creator>
    </item>
    <item>
      <title>Oscillations and differences in Besov-Morrey and Besov-type spaces</title>
      <link>https://arxiv.org/abs/2405.20662</link>
      <description>arXiv:2405.20662v1 Announce Type: cross 
Abstract: In this paper we investigate Besov-Morrey spaces $\mathcal{N}^{s}_{u,p,q}(\Omega)$ and Besov-type spaces $B^{s,\tau}_{p,q}(\Omega)$ of positive smoothness defined on Lipschitz domains $\Omega \subset \mathbb{R}^d$ as well as on $\mathbb{R}^d$. We combine the Hedberg-Netrusov approach to function spaces with distinguished kernel representations due to Triebel, in order to derive novel characterizations of these scales in terms of local oscillations provided that some standard conditions concerning the parameters are fulfilled. In connection with that we also obtain new characterizations of $\mathcal{N}^{s}_{u,p,q}(\Omega)$ and $B^{s,\tau}_{p,q}(\Omega)$ via differences of higher order. By the way we recover and extend corresponding results for the scale of classical Besov spaces $B^{s}_{p,q}(\Omega)$.
  Key words: Besov-Morrey space, Besov-type space, Morrey space, Lipschitz domain, oscillations, higher order differences</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20662v1</guid>
      <category>math.FA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Hovemann, Markus Weimar</dc:creator>
    </item>
    <item>
      <title>Spectral ACMS: A robust localized Approximated Component Mode Synthesis Method</title>
      <link>https://arxiv.org/abs/1709.04044</link>
      <description>arXiv:1709.04044v2 Announce Type: replace 
Abstract: We consider finite element methods of multiscale type to approximate solutions for two-dimensional symmetric elliptic partial differential equations with heterogeneous $L^\infty$ coefficients. The methods are of Galerkin type and follow the Variational Multiscale and Localized Orthogonal Decomposition--LOD approaches in the sense that it decouples spaces into \emph{multiscale} and \emph{fine} subspaces. In a first method, the multiscale basis functions are obtained by mapping coarse basis functions, based on corners used on primal iterative substructuring methods, to functions of global minimal energy. This approach delivers quasi-optimal a priori error energy approximation with respect to the mesh size, but it is not robust with respect to high-contrast coefficients. In a second method, edge modes based on local generalized eigenvalue problems are added to the corner modes. As a result, optimal a priori error energy estimate is achieved which is mesh and contrast independent. The methods converge at optimal rate even if the solution has minimum regularity, belonging only to the Sobolev space $H^1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:1709.04044v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre L. Madureira, Marcus Sarkis</dc:creator>
    </item>
    <item>
      <title>Mathematical Modelling of Neuroblast Chemotaxis Migration towards the Olfactory Bulb</title>
      <link>https://arxiv.org/abs/2211.06166</link>
      <description>arXiv:2211.06166v3 Announce Type: replace 
Abstract: This article is devoted to the mathematical modeling of migration of neuroblasts, precursor cells of neurons, along the pathway they usually follow before maturing. This pathway is determined mainly by chemotaxis and the heterogeneous mobility of neuroblasts in different regions of the brain. In numerical simulations, the application of novel discontinuous Galerkin methods allows to maintain the properties of the continuous model such as the maximum principle. We present some successful computer tests including parameter adjust to fit real data from rodent brains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06166v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Acosta-Soba, Carmen Castro-Gonz\'alez, Noelia Geribaldi-Dold\'an, Francisco Guill\'en-Gonz\'alez, Pedro N\'u\~nez-Abades, Noelia Ortega-Rom\'an, Patricia P\'erez-Garc\'ia, J. Rafael Rodr\'iguez-Galv\'an</dc:creator>
    </item>
    <item>
      <title>Generalized Convolution Quadrature for non smooth sectorial problems</title>
      <link>https://arxiv.org/abs/2211.13862</link>
      <description>arXiv:2211.13862v5 Announce Type: replace 
Abstract: We consider the application of the generalized Convolution Quadrature (gCQ) to approximate the solution of an important class of sectorial problems. The gCQ is a generalization of Lubich's Convolution Quadrature (CQ) that allows for variable steps. The available stability and convergence theory for the gCQ requires non realistic regularity assumptions on the data, which do not hold in many applications of interest, such as the approximation of subdiffusion equations. It is well known that for non smooth enough data the original CQ, with uniform steps, presents an order reduction close to the singularity. We generalize the analysis of the gCQ to data satisfying realistic regularity assumptions and provide sufficient conditions for stability and convergence on arbitrary sequences of time points. We consider the particular case of graded meshes and show how to choose them optimally, according to the behaviour of the data. An important advantage of the gCQ method is that it allows for a fast and memory reduced implementation. We describe how the fast and oblivious gCQ can be implemented and illustrate our theoretical results with several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.13862v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Guo, Maria Lopez-Fernandez</dc:creator>
    </item>
    <item>
      <title>Robust boundary integral equations for the solution of elastic scattering problems via Helmholtz decompositions</title>
      <link>https://arxiv.org/abs/2211.16168</link>
      <description>arXiv:2211.16168v2 Announce Type: replace 
Abstract: Helmholtz decompositions of the elastic fields open up new avenues for the solution of linear elastic scattering problems via boundary integral equations (BIE) [Dong, Lai, Li, Mathematics of Computation,2021]. The main appeal of this approach is that the ensuing systems of BIE feature only integral operators associated with the Helmholtz equation. However, these BIE involve non standard boundary integral operators that do not result after the application of either the Dirichlet or the Neumann trace to Helmholtz single and double layer potentials. Rather, the Helmholtz decomposition approach leads to BIE formulations of elastic scattering problems with Neumann boundary conditions that involve boundary traces of the Hessians of Helmholtz layer potential. As a consequence, the classical combined field approach applied in the framework of the Helmholtz decompositions leads to BIE formulations which, although robust, are not of the second kind. Following the regularizing methodology introduced in [Boubendir, Dominguez, Levadoux, Turc, SIAM Journal on Applied Mathematics 2015] we design and analyze novel robust Helmholtz decomposition BIE for the solution of elastic scattering that are of the second kind in the case of smooth scatterers in two dimensions. We present a variety of numerical results based on Nystrom discretizations that illustrate the good performance of the second kind regularized formulations in connections to iterative solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.16168v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Dominguez, C. Turc</dc:creator>
    </item>
    <item>
      <title>Ensemble-localized Kernel Density Estimation with Applications to the Ensemble Gaussian Mixture Filter</title>
      <link>https://arxiv.org/abs/2308.14143</link>
      <description>arXiv:2308.14143v2 Announce Type: replace-cross 
Abstract: The ensemble Gaussian mixture filter (EnGMF) is a non-linear filter suited to data assimilation of highly non-Gaussian and non-linear models that has practical utility in the case of a small number of samples, and theoretical convergence to full Bayesian inference in the ensemble limit. We aim to increase the utility of the EnGMF by introducing an ensemble-local notion of covariance into the kernel density estimation (KDE) step for the prior distribution. We prove that in the Gaussian case, our new ensemble-localized KDE technique is exactly the same as more traditional KDE techniques. We also show an example of a non-Gaussian distribution that can fail to be approximated by canonical KDE methods, but can be approximated well by our new KDE technique. We showcase our new KDE technique on a simple bivariate problem, showing that it has nice qualitative and quantitative properties, and significantly improves the estimate of the prior and posterior distributions for all ensemble sizes tested. We additionally show the utility of the proposed methodology for sequential filtering for the Lorenz '63 equations, achieving a significant reduction in error, and less conservative behavior in the uncertainty estimate with respect to traditional techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14143v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey A. Popov, Enrico M. Zucchelli, Renato Zanetti</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of the transformed gradient projection algorithms on compact matrix manifolds</title>
      <link>https://arxiv.org/abs/2404.19392</link>
      <description>arXiv:2404.19392v2 Announce Type: replace-cross 
Abstract: In this paper, to address the optimization problem on a compact matrix manifold, we introduce a novel algorithmic framework called the Transformed Gradient Projection (TGP) algorithm, using the projection onto this compact matrix manifold. Compared with the existing algorithms, the key innovation in our approach lies in the utilization of a new class of search directions and various stepsizes, including the Armijo, nonmonotone Armijo, and fixed stepsizes, to guide the selection of the next iterate. Our framework offers flexibility by encompassing the classical gradient projection algorithms as special cases, and intersecting the retraction-based line-search algorithms. Notably, our focus is on the Stiefel or Grassmann manifold, revealing that many existing algorithms in the literature can be seen as specific instances within our proposed framework, and this algorithmic framework also induces several new special cases. Then, we conduct a thorough exploration of the convergence properties of these algorithms, considering various search directions and stepsizes. To achieve this, we extensively analyze the geometric properties of the projection onto compact matrix manifolds, allowing us to extend classical inequalities related to retractions from the literature. Building upon these insights, we establish the weak convergence, convergence rate, and global convergence of TGP algorithms under three distinct stepsizes. In cases where the compact matrix manifold is the Stiefel or Grassmann manifold, our convergence results either encompass or surpass those found in the literature. Finally, through a series of numerical experiments, we observe that the TGP algorithms, owing to their increased flexibility in choosing search directions, outperform classical gradient projection and retraction-based line-search algorithms in several scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19392v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wentao Ding, Jianze Li, Shuzhong Zhang</dc:creator>
    </item>
  </channel>
</rss>
