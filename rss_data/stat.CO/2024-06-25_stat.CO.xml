<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Jun 2024 01:47:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Approximate Bayesian Computation sequential Monte Carlo via random forests</title>
      <link>https://arxiv.org/abs/2406.15865</link>
      <description>arXiv:2406.15865v1 Announce Type: new 
Abstract: Approximate Bayesian Computation (ABC) is a popular inference method when likelihoods are hard to come by. Practical bottlenecks of ABC applications include selecting statistics that summarize the data without losing too much information or introducing uncertainty, and choosing distance functions and tolerance thresholds that balance accuracy and computational efficiency. Recent studies have shown that ABC methods using random forest (RF) methodology perform well while circumventing many of ABC's drawbacks. However, RF construction is computationally expensive for large numbers of trees and model simulations, and there can be high uncertainty in the posterior if the prior distribution is uninformative. Here we adapt distributional random forests to the ABC setting, and introduce Approximate Bayesian Computation sequential Monte Carlo with random forests (ABC-SMC-(D)RF). This updates the prior distribution iteratively to focus on the most likely regions in the parameter space. We show that ABC-SMC-(D)RF can accurately infer posterior distributions for a wide range of deterministic and stochastic models in different scientific areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15865v1</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khanh N. Dinh, Zijin Xiang, Zhihan Liu, Simon Tavar\'e</dc:creator>
    </item>
    <item>
      <title>Efficient Multivariate Initial Sequence Estimators for MCMC</title>
      <link>https://arxiv.org/abs/2406.15874</link>
      <description>arXiv:2406.15874v1 Announce Type: new 
Abstract: Estimating Monte Carlo error is critical to valid simulation results in Markov chain Monte Carlo (MCMC) and initial sequence estimators were one of the first methods introduced for this. Over the last few years, focus has been on multivariate assessment of simulation error, and many multivariate generalizations of univariate methods have been developed. The multivariate initial sequence estimator is known to exhibit superior finite-sample performance compared to its competitors. However, the multivariate initial sequence estimator can be prohibitively slow, limiting its widespread use. We provide an efficient alternative to the multivariate initial sequence estimator that inherits both its asymptotic properties as well as the finite-sample superior performance. The effectiveness of the proposed estimator is shown via some MCMC example implementations. Further, we also present univariate and multivariate initial sequence estimators for when parallel MCMC chains are run and demonstrate their effectiveness over popular alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15874v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arka Banerjee, Dootika Vats</dc:creator>
    </item>
    <item>
      <title>Recursive variational Gaussian approximation with the Whittle likelihood for linear non-Gaussian state space models</title>
      <link>https://arxiv.org/abs/2406.15998</link>
      <description>arXiv:2406.15998v1 Announce Type: new 
Abstract: Parameter inference for linear and non-Gaussian state space models is challenging because the likelihood function contains an intractable integral over the latent state variables. Exact inference using Markov chain Monte Carlo is computationally expensive, particularly for long time series data. Variational Bayes methods are useful when exact inference is infeasible. These methods approximate the posterior density of the parameters by a simple and tractable distribution found through optimisation. In this paper, we propose a novel sequential variational Bayes approach that makes use of the Whittle likelihood for computationally efficient parameter inference in this class of state space models. Our algorithm, which we call Recursive Variational Gaussian Approximation with the Whittle Likelihood (R-VGA-Whittle), updates the variational parameters by processing data in the frequency domain. At each iteration, R-VGA-Whittle requires the gradient and Hessian of the Whittle log-likelihood, which are available in closed form for a wide class of models. Through several examples using a linear Gaussian state space model and a univariate/bivariate non-Gaussian stochastic volatility model, we show that R-VGA-Whittle provides good approximations to posterior distributions of the parameters and is very computationally efficient when compared to asymptotically exact methods such as Hamiltonian Monte Carlo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15998v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bao Anh Vu, David Gunawan, Andrew Zammit-Mangion</dc:creator>
    </item>
    <item>
      <title>Sparse Bayesian multidimensional scaling(s)</title>
      <link>https://arxiv.org/abs/2406.15573</link>
      <description>arXiv:2406.15573v1 Announce Type: cross 
Abstract: Bayesian multidimensional scaling (BMDS) is a probabilistic dimension reduction tool that allows one to model and visualize data consisting of dissimilarities between pairs of objects. Although BMDS has proven useful within, e.g., Bayesian phylogenetic inference, its likelihood and gradient calculations require a burdensome order of $N^2$ floating-point operations, where $N$ is the number of data points. Thus, BMDS becomes impractical as $N$ grows large. We propose and compare two sparse versions of BMDS (sBMDS) that apply log-likelihood and gradient computations to subsets of the observed dissimilarity matrix data. Landmark sBMDS (L-sBMDS) extracts columns, while banded sBMDS (B-sBMDS) extracts diagonals of the data. These sparse variants let one specify a time complexity between $N^2$ and $N$. Under simplified settings, we prove posterior consistency for subsampled distance matrices. Through simulations, we examine the accuracy and computational efficiency across all models using both the Metropolis-Hastings and Hamiltonian Monte Carlo algorithms. We observe approximately 3-fold, 10-fold and 40-fold speedups with negligible loss of accuracy, when applying the sBMDS likelihoods and gradients to 500, 1,000 and 5,000 data points with 50 bands (landmarks); these speedups only increase with the size of data considered. Finally, we apply the sBMDS variants to the phylogeographic modeling of multiple influenza subtypes to better understand how these strains spread through global air transportation networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15573v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ami Sheth, Aaron Smith, Andrew J. Holbrook</dc:creator>
    </item>
    <item>
      <title>Graphical copula GARCH modeling with dynamic conditional dependence</title>
      <link>https://arxiv.org/abs/2406.15582</link>
      <description>arXiv:2406.15582v1 Announce Type: cross 
Abstract: Modeling returns on large portfolios is a challenging problem as the number of parameters in the covariance matrix grows as the square of the size of the portfolio. Traditional correlation models, for example, the dynamic conditional correlation (DCC)-GARCH model, often ignore the nonlinear dependencies in the tail of the return distribution. In this paper, we aim to develop a framework to model the nonlinear dependencies dynamically, namely the graphical copula GARCH (GC-GARCH) model. Motivated from the capital asset pricing model, to allow modeling of large portfolios, the number of parameters can be greatly reduced by introducing conditional independence among stocks given some risk factors. The joint distribution of the risk factors is factorized using a directed acyclic graph (DAG) with pair-copula construction (PCC) to enhance the modeling of the tails of the return distribution while offering the flexibility of having complex dependent structures. The DAG induces topological orders to the risk factors, which can be regarded as a list of directions of the flow of information. The conditional distributions among stock returns are also modeled using PCC. Dynamic conditional dependence structures are incorporated to allow the parameters in the copulas to be time-varying. Three-stage estimation is used to estimate parameters in the marginal distributions, the risk factor copulas, and the stock copulas. The simulation study shows that the proposed estimation procedure can estimate the parameters and the underlying DAG structure accurately. In the investment experiment of the empirical study, we demonstrate that the GC-GARCH model produces more precise conditional value-at-risk prediction and considerably higher cumulative portfolio returns than the DCC-GARCH model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15582v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lupe Shun Hin Chan, Amanda Man Ying Chu, Mike Ka Pui So</dc:creator>
    </item>
    <item>
      <title>Genealogical processes of non-neutral population models under rapid mutation</title>
      <link>https://arxiv.org/abs/2406.16465</link>
      <description>arXiv:2406.16465v1 Announce Type: cross 
Abstract: We show that genealogical trees arising from a broad class of non-neutral models of population evolution converge to the Kingman coalescent under a suitable rescaling of time. As well as non-neutral biological evolution, our results apply to genetic algorithms encompassing the prominent class of sequential Monte Carlo (SMC) methods. The time rescaling we need differs slightly from that used in classical results for convergence to the Kingman coalescent, which has implications for the performance of different resampling schemes in SMC algorithms. In addition, our work substantially simplifies earlier proofs of convergence to the Kingman coalescent, and corrects an error common to several earlier results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16465v1</guid>
      <category>math.PR</category>
      <category>q-bio.PE</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jere Koskela, Paul A. Jenkins, Adam M. Johansen, Dario Spano</dc:creator>
    </item>
    <item>
      <title>Conditional Bayesian Quadrature</title>
      <link>https://arxiv.org/abs/2406.16530</link>
      <description>arXiv:2406.16530v1 Announce Type: cross 
Abstract: We propose a novel approach for estimating conditional or parametric expectations in the setting where obtaining samples or evaluating integrands is costly. Through the framework of probabilistic numerical methods (such as Bayesian quadrature), our novel approach allows to incorporates prior information about the integrands especially the prior smoothness knowledge about the integrands and the conditional expectation. As a result, our approach provides a way of quantifying uncertainty and leads to a fast convergence rate, which is confirmed both theoretically and empirically on challenging tasks in Bayesian sensitivity analysis, computational finance and decision making under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16530v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:journal_reference>Conference on Uncertainty in Artificial Intelligence (UAI) 2024</arxiv:journal_reference>
      <dc:creator>Zonghao Chen, Masha Naslidnyk, Arthur Gretton, Fran\c{c}ois-Xavier Briol</dc:creator>
    </item>
    <item>
      <title>Simultaneous computation of Kendall's tau and its jackknife variance</title>
      <link>https://arxiv.org/abs/2206.04019</link>
      <description>arXiv:2206.04019v2 Announce Type: replace 
Abstract: We present efficient algorithms for simultaneously computing Kendall's tau and the jackknife estimator of its variance. For the classical pairwise tau, we describe a modification of Knight's algorithm (originally designed to compute only tau) that does so while preserving its $O(n \log_2 n)$ runtime in the number of observations $n$. We also introduce a novel algorithm computing a multivariate extension of tau and its jackknife variance in $O(n \log_2^p n)$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.04019v2</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.spl.2024.110181</arxiv:DOI>
      <dc:creator>Samuel Perreault</dc:creator>
    </item>
    <item>
      <title>Exact and Approximate Conformal Inference for Multi-Output Regression</title>
      <link>https://arxiv.org/abs/2210.17405</link>
      <description>arXiv:2210.17405v2 Announce Type: replace-cross 
Abstract: It is common in machine learning to estimate a response $y$ given covariate information $x$. However, these predictions alone do not quantify any uncertainty associated with said predictions. One way to overcome this deficiency is with conformal inference methods, which construct a set containing the unobserved response $y$ with a prescribed probability. Unfortunately, even with a one-dimensional response, conformal inference is computationally expensive despite recent encouraging advances. In this paper, we explore multi-output regression, delivering exact derivations of conformal inference $p$-values when the predictive model can be described as a linear function of $y$. Additionally, we propose \texttt{unionCP} and a multivariate extension of \texttt{rootCP} as efficient ways of approximating the conformal prediction region for a wide array of multi-output predictors, both linear and nonlinear, while preserving computational advantages. We also provide both theoretical and empirical evidence of the effectiveness of these methods using both real-world and simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.17405v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chancellor Johnstone, Eugene Ndiaye</dc:creator>
    </item>
    <item>
      <title>Scalable Composite Likelihood Estimation of Probit Models with Crossed Random Effects</title>
      <link>https://arxiv.org/abs/2308.15681</link>
      <description>arXiv:2308.15681v2 Announce Type: replace-cross 
Abstract: Crossed random effects structures arise in many scientific contexts. They raise severe computational problems with likelihood computations scaling like $N^{3/2}$ or worse for $N$ data points. In this paper we develop a new composite likelihood approach for crossed random effects probit models. For data arranged in R rows and C columns, the likelihood function includes a very difficult R + C dimensional integral. The composite likelihood we develop uses the marginal distribution of the response along with two hierarchical models. The cost is reduced to $\mathcal{O}(N)$ and it can be computed with $R + C$ one dimensional integrals. We find that the commonly used Laplace approximation has a cost that grows superlinearly. We get consistent estimates of the probit slope and variance components from our composite likelihood algorithm. We also show how to estimate the covariance of the estimated regression coefficients. The algorithm scales readily to a data set of five million observations from Stitch Fix with $R + C &gt; 700{,}000$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15681v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruggero Bellio, Swarnadip Ghosh, Art B. Owen, Cristiano Varin</dc:creator>
    </item>
  </channel>
</rss>
