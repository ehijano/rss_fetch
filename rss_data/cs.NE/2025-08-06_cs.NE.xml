<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Aug 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>VCNet: Recreating High-Level Visual Cortex Principles for Robust Artificial Vision</title>
      <link>https://arxiv.org/abs/2508.02995</link>
      <description>arXiv:2508.02995v1 Announce Type: new 
Abstract: Despite their success in image classification, modern convolutional neural networks (CNNs) exhibit fundamental limitations, including data inefficiency, poor out-of-distribution generalization, and vulnerability to adversarial perturbations. The primate visual system, in contrast, demonstrates superior efficiency and robustness, suggesting that its architectural principles may offer a blueprint for more capable artificial vision systems. This paper introduces Visual Cortex Network (VCNet), a novel neural network architecture whose design is informed by the macro-scale organization of the primate visual cortex. VCNet emulates key biological mechanisms, including hierarchical processing across distinct cortical areas, dual-stream information segregation, and top-down predictive feedback. We evaluate VCNet on two specialized benchmarks: the Spots-10 animal pattern dataset and a light field image classification task. Our results show that VCNet achieves a classification accuracy of 92.1\% on Spots-10 and 74.4\% on the light field dataset, surpassing contemporary models of comparable size. This work demonstrates that integrating neuroscientific principles into network design can lead to more efficient and robust models, providing a promising direction for addressing long-standing challenges in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02995v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brennen A. Hill, Zhang Xinyu, Timothy Putra Prasetio</dc:creator>
    </item>
    <item>
      <title>Fitness and Overfitness: Implicit Regularization in Evolutionary Dynamics</title>
      <link>https://arxiv.org/abs/2508.03187</link>
      <description>arXiv:2508.03187v1 Announce Type: cross 
Abstract: A common assumption in evolutionary thought is that adaptation drives an increase in biological complexity. However, the rules governing evolution of complexity appear more nuanced. Evolution is deeply connected to learning, where complexity is much better understood, with established results on optimal complexity appropriate for a given learning task. In this work, we suggest a mathematical framework for studying the relationship between evolved organismal complexity and enviroenmntal complexity by leveraging a mathematical isomorphism between evolutionary dynamics and learning theory. Namely, between the replicator equation and sequential Bayesian learning, with evolving types corresponding to competing hypotheses and fitness in a given environment to likelihood of observed evidence. In Bayesian learning, implicit regularization prevents overfitting and drives the inference of hypotheses whose complexity matches the learning challenge. We show how these results naturally carry over to the evolutionary setting, where they are interpreted as organism complexity evolving to match the complexity of the environment, with too complex or too simple organisms suffering from \textit{overfitness} and \textit{underfitness}, respectively. Other aspects, peculiar to evolution and not to learning, reveal additional trends. One such trend is that frequently changing environments decrease selected complexity, a result with potential implications to both evolution and learning. Together, our results suggest that the balance between over-adaptation to transient environmental features, and insufficient flexiblity in responding to environmental challenges, drives the emergence of optimal complexity, reflecting environmental structure. This framework offers new ways of thinking about biological complexity, suggesting new potential causes for it to increase or decrease in different environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03187v1</guid>
      <category>q-bio.PE</category>
      <category>cs.NE</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hagai Rappeport, Mor Nitzan</dc:creator>
    </item>
    <item>
      <title>Live Demonstration: Neuromorphic Radar for Gesture Recognition</title>
      <link>https://arxiv.org/abs/2508.03324</link>
      <description>arXiv:2508.03324v1 Announce Type: cross 
Abstract: We present a neuromorphic radar framework for real-time, low-power hand gesture recognition (HGR) using an event-driven architecture inspired by biological sensing. Our system comprises a 24 GHz Doppler radar front-end and a custom neuromorphic sampler that converts intermediate-frequency (IF) signals into sparse spike-based representations via asynchronous sigma-delta encoding. These events are directly processed by a lightweight neural network deployed on a Cortex-M0 microcontroller, enabling low-latency inference without requiring spectrogram reconstruction. Unlike conventional radar HGR pipelines that continuously sample and process data, our architecture activates only when meaningful motion is detected, significantly reducing memory, power, and computation overhead. Evaluated on a dataset of five gestures collected from seven users, our system achieves &gt; 85% real-time accuracy. To the best of our knowledge, this is the first work that employs bio-inspired asynchronous sigma-delta encoding and an event-driven processing framework for radar-based HGR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03324v1</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satyapreet Singh Yadav, Chandra Sekhar Seelamantula, Chetan Singh Thakur</dc:creator>
    </item>
    <item>
      <title>A Genetic Algorithm Framework for Optimizing Three-Impulse Orbital Transfers with Poliastro Simulation</title>
      <link>https://arxiv.org/abs/2508.03466</link>
      <description>arXiv:2508.03466v1 Announce Type: cross 
Abstract: Orbital maneuver planning is a critical aspect of mission design, aimed at minimizing propellant consumption, which is directly correlated with the total velocity change ($\Delta V$). While analytical solutions like the Hohmann and Bi-elliptic transfers offer optimal strategies for specific cases, they lack the flexibility for more general optimization problems. This paper presents a computational framework that couples a Genetic Algorithm (GA) with the Poliastro orbital mechanics library to autonomously discover fuel-optimal, three-impulse transfer trajectories between coplanar circular orbits. We validate this framework across two distinct scenarios: a low-energy transfer from Low Earth Orbit (LEO) to a Geostationary Orbit (GEO), and a high-energy transfer to a distant orbit with a radius 20 times that of LEO. Our results demonstrate the framework's remarkable adaptability. For the LEO-to-GEO transfer, the GA precisely converges to the classical Hohmann transfer, achieving an identical $\Delta V$ of 3853.96 m/s and validating the method's accuracy. Conversely, for the high-energy transfer, the GA identifies a superior Bi-elliptic trajectory that yields a significant $\Delta V$ saving of 213.47 m/s compared to the Hohmann transfer. This fuel efficiency, however, necessitates a trade-off, extending the mission duration from approximately 1 day to over 140 years. This work demonstrates an accessible and powerful toolchain for the rapid prototyping of optimal trajectories, showcasing how combining evolutionary algorithms with open-source libraries provides a robust method for solving complex astrodynamics problems and quantifying their critical design trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03466v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.NE</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phuc Hao Do, Tran Duc Le</dc:creator>
    </item>
    <item>
      <title>Why Evolve When You Can Adapt? Post-Evolution Adaptation of Genetic Memory for On-the-Fly Control</title>
      <link>https://arxiv.org/abs/2508.03600</link>
      <description>arXiv:2508.03600v1 Announce Type: cross 
Abstract: Imagine a robot controller with the ability to adapt like human synapses, dynamically rewiring itself to overcome unforeseen challenges in real time. This paper proposes a novel zero-shot adaptation mechanism for evolutionary robotics, merging a standard Genetic Algorithm (GA) controller with online Hebbian plasticity. Inspired by biological systems, the method separates learning and memory, with the genotype acting as memory and Hebbian updates handling learning. In our approach, the fitness function is leveraged as a live scaling factor for Hebbian learning, enabling the robot's neural controller to adjust synaptic weights on-the-fly without additional training. This adds a dynamic adaptive layer that activates only during runtime to handle unexpected environmental changes. After the task, the robot 'forgets' the temporary adjustments and reverts to the original weights, preserving core knowledge. We validate this hybrid GA-Hebbian controller on an e-puck robot in a T-maze navigation task with changing light conditions and obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03600v1</guid>
      <category>cs.RO</category>
      <category>cs.NE</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamze Hammami, Eva Denisa Barbulescu, Talal Shaikh, Mouayad Aldada, Muhammad Saad Munawar</dc:creator>
    </item>
    <item>
      <title>Minimal Convolutional RNNs Accelerate Spatiotemporal Learning</title>
      <link>https://arxiv.org/abs/2508.03614</link>
      <description>arXiv:2508.03614v1 Announce Type: cross 
Abstract: We introduce MinConvLSTM and MinConvGRU, two novel spatiotemporal models that combine the spatial inductive biases of convolutional recurrent networks with the training efficiency of minimal, parallelizable RNNs. Our approach extends the log-domain prefix-sum formulation of MinLSTM and MinGRU to convolutional architectures, enabling fully parallel training while retaining localized spatial modeling. This eliminates the need for sequential hidden state updates during teacher forcing - a major bottleneck in conventional ConvRNN models. In addition, we incorporate an exponential gating mechanism inspired by the xLSTM architecture into the MinConvLSTM, which further simplifies the log-domain computation. Our models are structurally minimal and computationally efficient, with reduced parameter count and improved scalability. We evaluate our models on two spatiotemporal forecasting tasks: Navier-Stokes dynamics and real-world geopotential data. In terms of training speed, our architectures significantly outperform standard ConvLSTMs and ConvGRUs. Moreover, our models also achieve lower prediction errors in both domains, even in closed-loop autoregressive mode. These findings demonstrate that minimal recurrent structures, when combined with convolutional input aggregation, offer a compelling and efficient alternative for spatiotemporal sequence modeling, bridging the gap between recurrent simplicity and spatial complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03614v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Co\c{s}ku Can Horuz, Sebastian Otte, Martin V. Butz, Matthias Karlbauer</dc:creator>
    </item>
    <item>
      <title>Cascading CMA-ES Instances for Generating Input-diverse Solution Batches</title>
      <link>https://arxiv.org/abs/2502.13730</link>
      <description>arXiv:2502.13730v2 Announce Type: replace 
Abstract: Rather than obtaining a single good solution for a given optimization problem, users often seek alternative design choices, because the best-found solution may perform poorly with respect to additional objectives or constraints that are difficult to capture into the modeling process.
  Aiming for batches of diverse solutions of high quality is often desirable, as it provides flexibility to accommodate post-hoc user preferences. At the same time, it is crucial that the quality of the best solution found is not compromised.
  One particular problem setting balancing high quality and diversity is fixing the required minimum distance between solutions while simultaneously obtaining the best possible fitness. Recent work by Santoni et al. [arXiv 2024] revealed that this setting is not well addressed by state-of-the-art algorithms, performing in par or worse than pure random sampling.
  Driven by this important limitation, we propose a new approach, where parallel runs of the covariance matrix adaptation evolution strategy (CMA-ES) inherit tabu regions in a cascading fashion. We empirically demonstrate that our CMA-ES-Diversity Search (CMA-ES-DS) algorithm generates trajectories that allow to extract high-quality solution batches that respect a given minimum distance requirement, clearly outperforming those obtained from off-the-shelf random sampling, multi-modal optimization algorithms, and standard CMA-ES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13730v2</guid>
      <category>cs.NE</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Laura Santoni, Christoph D\"urr, Carola Doerr, Mike Preuss, Elena Raponi</dc:creator>
    </item>
    <item>
      <title>Vertical Federated Continual Learning via Evolving Prototype Knowledge</title>
      <link>https://arxiv.org/abs/2502.09152</link>
      <description>arXiv:2502.09152v2 Announce Type: replace-cross 
Abstract: Vertical Federated Learning (VFL) has garnered significant attention as a privacy-preserving machine learning framework for sample-aligned feature federation. However, traditional VFL approaches do not address the challenges of class and feature continual learning, resulting in catastrophic forgetting of knowledge from previous tasks. To address the above challenge, we propose a novel vertical federated continual learning method, named Vertical Federated Continual Learning via Evolving Prototype Knowledge (V-LETO), which primarily facilitates the transfer of knowledge from previous tasks through the evolution of prototypes. Specifically, we propose an evolving prototype knowledge method, enabling the global model to retain both previous and current task knowledge. Furthermore, we introduce a model optimization technique that mitigates the forgetting of previous task knowledge by restricting updates to specific parameters of the local model, thereby enhancing overall performance. Extensive experiments conducted in both CIL and FIL settings demonstrate that our method, V-LETO, outperforms the other state-of-the-art methods. For example, our method outperforms the state-of-the-art method by 10.39% and 35.15% for CIL and FIL tasks, respectively. Our code is available at https://anonymous.4open.science/r/V-LETO-0108/README.md.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09152v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Wang, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu</dc:creator>
    </item>
  </channel>
</rss>
