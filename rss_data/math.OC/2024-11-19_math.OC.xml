<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Nov 2024 02:47:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Gradient-Based Stochastic Extremum-Seeking Control for Multivariable Systems with Distinct Input Delays</title>
      <link>https://arxiv.org/abs/2411.10580</link>
      <description>arXiv:2411.10580v1 Announce Type: new 
Abstract: This paper addresses the design and analysis of a multivariable gradient-based stochastic extremum-seeking control method for multi-input systems with arbitrary input delays. The approach accommodates systems with distinct time delays across input channels and achieves local exponential stability of the closed-loop system, guaranteeing convergence to a small neighborhood around the extremum point. By incorporating phase compensation for dither signals and a novel predictor-feedback mechanism with averaging-based estimates of the unknown gradient and Hessian, the proposed method overcomes traditional challenges associated with arbitrary, distinct input delays. Unlike previous work on deterministic multiparameter extremum-seeking with distinct input delays, this stability analysis is achieved without using backstepping transformations, simplifying the predictor design and enabling a more straightforward implementation. Specifically, the direct application of Artstein's reduction approach results in delay- and system-dimension-independent convergence rates, enhancing practical applicability. A numerical example illustrates the robust performance and advantages of the proposed delay-compensated stochastic extremum-seeking method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10580v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Cesar Souza Silva, Paulo Cesar Pellanda, Tiago Roux Oliveira</dc:creator>
    </item>
    <item>
      <title>A Systematic LMI Approach to Design Multivariable Sliding Mode Controllers</title>
      <link>https://arxiv.org/abs/2411.10592</link>
      <description>arXiv:2411.10592v1 Announce Type: new 
Abstract: This paper deals with sliding mode control for multivariable polytopic uncertain systems. We provide systematic procedures to design variable structure controllers (VSCs) and unit-vector controllers (UVCs). Based on suitable representations for the closed-loop system, we derive sufficient conditions in the form of linear matrix inequalities (LMIs) to design the robust sliding mode controllers such that the origin of the closed-loop system is globally stable in finite time. Moreover, by noticing that the reaching time depends on the initial condition and the decay rate, we provide convex optimization problems to design robust controllers by considering the minimization of the reaching time associated with a given set of initial conditions. Two examples illustrate the effectiveness of the proposed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10592v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Henrique Silva Coutinho, Iury Bessa, Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization Method Based On Optimal Control</title>
      <link>https://arxiv.org/abs/2411.10658</link>
      <description>arXiv:2411.10658v1 Announce Type: new 
Abstract: In this paper, a novel distributed optimization framework has been proposed. The key idea is to convert optimization problems into optimal control problems where the objective of each agent is to design the current control input minimizing the original objective function of itself and updated size for the future time instant. Compared with the existing distributed optimization problem for optimizing a sum of convex objective functions corresponding to multiple agents, we present a distributed optimization algorithm for multi-agents system based on the results from the maximum principle. Moreover, the convergence and superlinear convergence rate are also analyzed stringently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10658v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyuan Guo, Yue Sun, Yeming Xu, Liping Zhang, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Approximate Controllability of Fractional Differential Systems with Nonlocal Conditions of Order $q\in ]1,2[$</title>
      <link>https://arxiv.org/abs/2411.10766</link>
      <description>arXiv:2411.10766v1 Announce Type: new 
Abstract: This manuscript is concerned with the approximate controllability of fractional nonlinear differential equations with nonlocal conditions of order $1&lt;q&lt;2$ in Banach spaces. As far as we know, few articles have investigated this issue. The idea is to see under which sufficient conditions the proposed control problem is approximately controllable. The discussion is based on the theory of resolvent operator, fractional calculus techniques and Krasnoselskii's fixed point theorem under the assumption that the associated linear system is approximately controllable. The obtained results improve some existing analogous ones on this topic. Finally, an example is provided to illustrate the applications of the obtained results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10766v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Aberqi, Zoubida Echchaffani, Touria Karite</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Linear Quadratic Regulation Control of Discrete-time Systems with Delay and Quadratic Constraints</title>
      <link>https://arxiv.org/abs/2411.10795</link>
      <description>arXiv:2411.10795v1 Announce Type: new 
Abstract: This article explores the discrete-time stochastic optimal LQR control with delay and quadratic constraints. The inclusion of delay, compared to delay-free optimal LQR control with quadratic constraints, significantly increases the complexity of the problem. Using Lagrangian duality, the optimal control is obtained by solving the Riccati-ZXL equation in conjunction with a gradient ascent algorithm. Specifically, the parameterized optimal controller and cost function are derived by solving the Riccati-ZXL equation, with a gradient ascent algorithm determining the optimal parameter. The primary contribution of this work is presenting the optimal control as a feedback mechanism based on the state's conditional expectation, wherein the gain is determined using the Riccati-ZXL equation and the gradient ascent algorithm. Numerical examples demonstrate the effectiveness of the obtained results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10795v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dawei Liu, Juanjuan Xu, huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>FISTA Iterates Converge Linearly for Denoiser-Driven Regularization</title>
      <link>https://arxiv.org/abs/2411.10808</link>
      <description>arXiv:2411.10808v1 Announce Type: new 
Abstract: The effectiveness of denoising-driven regularization for image reconstruction has been widely recognized. Two prominent algorithms in this area are Plug-and-Play ($\texttt{PnP}$) and Regularization-by-Denoising ($\texttt{RED}$). We consider two specific algorithms $\texttt{PnP-FISTA}$ and $\texttt{RED-APG}$, where regularization is performed by replacing the proximal operator in the $\texttt{FISTA}$ algorithm with a powerful denoiser. The iterate convergence of $\texttt{FISTA}$ is known to be challenging with no universal guarantees. Yet, we show that for linear inverse problems and a class of linear denoisers, global linear convergence of the iterates of $\texttt{PnP-FISTA}$ and $\texttt{RED-APG}$ can be established through simple spectral analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10808v1</guid>
      <category>math.OC</category>
      <category>eess.IV</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arghya Sinha, Kunal N. Chaudhury</dc:creator>
    </item>
    <item>
      <title>Small-signal stability of power systems with voltage droop</title>
      <link>https://arxiv.org/abs/2411.10832</link>
      <description>arXiv:2411.10832v1 Announce Type: new 
Abstract: The small-signal stability of power grids is a well-studied topic. In this work, we give new sufficient conditions for highly heterogeneous mixes of grid-forming inverters (and other machines) that implement a $V$-$q$ droop to stabilize viable operating states of lossless grids. Assuming the edges are not overloaded, and static voltage limits are satisfied, our conditions are fully local: They can be evaluated bus by bus without information on the rest of the grid. Other than the presence of $V$-$q$ droop, we make no model assumptions. In particular, we do not assume a specific control strategy of the inverters, the number, or type, of their internal degrees of freedom, or that the control is homogeneous throughout the system.
  We achieve this by recasting the dynamics of the nodes as a complex frequency reaction to an active and reactive power signal coming from the grid. By working directly in terms of the node's linearized complex frequency response, the transfer functions capturing the linear response do not depend on arbitrary phases. Further, they are easily interpretable as the frequency/amplitude reaction to active/reactive power imbalance, and correspond directly to the typical design considerations for grid-forming control. By exploiting the presence of the $V$-$q$ droop, we can ensure that the grid's active/reactive power response to a frequency/amplitude change is semi-sectorial. This allows us to use an adapted small phase theorem to obtain local sufficient stability conditions for edges and nodes, which also yields novel results for established control designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10832v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob Niehues, Robin Delabays, Frank Hellmann</dc:creator>
    </item>
    <item>
      <title>Leveraging Hamiltonian Structure for Accurate Uncertainty Propagation</title>
      <link>https://arxiv.org/abs/2411.10900</link>
      <description>arXiv:2411.10900v1 Announce Type: new 
Abstract: In this work, we leverage the Hamiltonian kind structure for accurate uncertainty propagation through a nonlinear dynamical system. The developed approach utilizes the fact that the stationary probability density function is purely a function of the Hamiltonian of the system. This fact is exploited to define the basis functions for approximating the solution of the Fokker-Planck-Kolmogorov equation. This approach helps in curtailing the growth of basis functions with the state dimension. Furthermore, sparse approximation tools have been utilized to automatically select appropriate basis functions from an over-complete dictionary. A nonlinear oscillator and two-body problem are considered to show the efficacy of the proposed approach. Simulation results show that such an approach is effective in accurately propagating uncertainty through non-conservative as well as conservative systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10900v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Jain, Puneet Singla, Roshan Eapen</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Algorithms for Multichannel Spectral Super-Resolution</title>
      <link>https://arxiv.org/abs/2411.10938</link>
      <description>arXiv:2411.10938v1 Announce Type: new 
Abstract: This paper studies the problem of multichannel spectral super-resolution with either constant amplitude (CA) or not. We propose two optimization problems based on low-rank Hankel-Toeplitz matrix factorization. The two problems effectively leverage the multichannel and CA structures, while also enabling the design of low-complexity gradient descent algorithms for their solutions. Extensive simulations show the superior performance of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10938v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xunmeng Wu, Zai Yang, Zongben Xu</dc:creator>
    </item>
    <item>
      <title>Efficient Estimation of Relaxed Model Parameters for Robust UAV Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2411.10941</link>
      <description>arXiv:2411.10941v1 Announce Type: new 
Abstract: Online trajectory optimization and optimal control methods are crucial for enabling sustainable unmanned aerial vehicle (UAV) services, such as agriculture, environmental monitoring, and transportation, where available actuation and energy are limited. However, optimal controllers are highly sensitive to model mismatch, which can occur due to loaded equipment, packages to be delivered, or pre-existing variability in fundamental structural and thrust-related parameters. To circumvent this problem, optimal controllers can be paired with parameter estimators to improve their trajectory planning performance and perform adaptive control. However, UAV platforms are limited in terms of onboard processing power, oftentimes making nonlinear parameter estimation too computationally expensive to consider. To address these issues, we propose a relaxed, affine-in-parameters multirotor model along with an efficient optimal parameter estimator. We convexify the nominal Moving Horizon Parameter Estimation (MHPE) problem into a linear-quadratic form (LQ-MHPE) via an affine-in-parameter relaxation on the nonlinear dynamics, resulting in fast quadratic programs (QPs) that facilitate adaptive Model Predictve Control (MPC) in real time. We compare this approach to the equivalent nonlinear estimator in Monte Carlo simulations, demonstrating a decrease in average solve time and trajectory optimality cost by 98.2% and 23.9-56.2%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10941v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D. Fan, D. A. Copp</dc:creator>
    </item>
    <item>
      <title>Stability of Nonhomogeneous Split Equality and Split Feasibility Problems with Possibly Nonconvex Constraint Sets</title>
      <link>https://arxiv.org/abs/2411.11019</link>
      <description>arXiv:2411.11019v1 Announce Type: new 
Abstract: By applying some techniques of set-valued and variational analysis, we study solution stability of nonhomogeneous split equality problems and nonhomogeneous split feasibility problems, where the constraint sets need not be convex. Necessary and sufficient conditions for the Lipschitz-likeness of the solution maps of the problems are given and illustrated by concrete examples. The obtained results complement those given in [Huong VT, Xu HK, Yen ND. Stability analysis of split equality and split feasibility problems. arXiv:2410.16856.], where classical split equality problems and split feasibility problems have been considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11019v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vu Thi Huong, Hong-Kun Xu, Nguyen Dong Yen</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming: Optimality at a Point Implies Optimality Everywhere</title>
      <link>https://arxiv.org/abs/2411.11062</link>
      <description>arXiv:2411.11062v1 Announce Type: new 
Abstract: In the theory of dynamic programming, an optimal policy is a policy whose lifetime value dominates that of all other policies at every point in the state space. This raises a natural question: under what conditions does optimality at a single state imply optimality at every state? We show that, in a general setting, the irreducibility of the transition kernel under a feasible policy is a sufficient condition for extending optimality from one state to all states. These results have important implications for dynamic optimization algorithms based on gradient methods, which are routinely applied in reinforcement learning and other large scale applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11062v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Stachurski, Jingni Yang, Ziyue Yang</dc:creator>
    </item>
    <item>
      <title>Numerical Methods for Optimal Control Problems with SPDEs</title>
      <link>https://arxiv.org/abs/2411.11239</link>
      <description>arXiv:2411.11239v1 Announce Type: new 
Abstract: This paper investigates numerical methods for solving stochastic linear quadratic (SLQ) optimal control problems governed by stochastic partial differential equations (SPDEs). Two distinct approaches, the open-loop and closed-loop ones, are developed to ensure convergence rates in the fully discrete setting. The open-loop approach, utilizing the finite element method for spatial discretization and the Euler method for temporal discretization, addresses the complexities of coupled forward-backward SPDEs and employs a gradient descent framework suited for high-dimensional spaces. Separately, the closed-loop approach applies a feedback strategy, focusing on Riccati equation for spatio-temporal discretization. Both approaches are rigorously designed to handle the challenges of fully discrete SLQ problems, providing rigorous convergence rates and computational frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11239v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Prohl, Yanqing Wang</dc:creator>
    </item>
    <item>
      <title>Quasi-Newton method of Optimization is proved to be a steepest descent method under the ellipsoid norm</title>
      <link>https://arxiv.org/abs/2411.11286</link>
      <description>arXiv:2411.11286v1 Announce Type: new 
Abstract: Optimization problems, arise in many practical applications, from the view points of both theory and numerical methods. Especially, significant improvement in deep learning training came from the Quasi-Newton methods. Quasi-Newton search directions provide an attractive alternative to Newton's method in that they do not require computation of the Hessian and yet still attain a super linear rate of convergence. In Quasi-Newton method, we require Hessian approximation to satisfy the secant equation. In this paper, the Classical Cauchy-Schwartz Inequality is introduced, then more generalization are proposed. And it is seriously proved that Quasi-Newton method is a steepest descent method under the ellipsoid norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11286v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiongcheng Li</dc:creator>
    </item>
    <item>
      <title>A distributed Douglas-Rachford splitting method for solving linear constrained multi-block weakly convex problems</title>
      <link>https://arxiv.org/abs/2411.11486</link>
      <description>arXiv:2411.11486v1 Announce Type: new 
Abstract: In recent years, a distributed Douglas-Rachford splitting method (DDRSM) has been proposed to tackle multi-block separable convex optimization problems. This algorithm offers relatively easier subproblems and greater efficiency for large-scale problems compared to various augmented-Lagrangian-based parallel algorithms. Building upon this, we explore the extension of DDRSM to weakly convex cases. By assuming weak convexity of the objective function and introducing an error bound assumption, we demonstrate the linear convergence rate of DDRSM. Some promising numerical experiments involving compressed sensing and robust alignment of structures across images (RASL) show that DDRSM has advantages over augmented-Lagrangian-based algorithms, even in weakly convex scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11486v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leyu Hu, Jiaxin Xie, Xingju Cai, Deren Han</dc:creator>
    </item>
    <item>
      <title>Optimal Control of 1D Semilinear Heat Equations with Moment-SOS Relaxations</title>
      <link>https://arxiv.org/abs/2411.11528</link>
      <description>arXiv:2411.11528v1 Announce Type: new 
Abstract: We use moment-SOS (Sum Of Squares) relaxations to address the optimal control problem of the 1D heat equation perturbed with a nonlinear term. We extend the current framework of moment-based optimal control of PDEs to consider a quadratic cost on the control. We develop a new method to extract a nonlinear controller from approximate moments of the solution. The control law acts on the boundary of the domain and depends on the solution over the whole domain. Our method is validated numerically and compared to a linear-quadratic controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11528v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charlie Lebarb\'e, Emilien Flayac, Michel Fourni\'e, Didier Henrion, Milan Korda</dc:creator>
    </item>
    <item>
      <title>Data-Driven Structured Robust Control of Linear Systems</title>
      <link>https://arxiv.org/abs/2411.11542</link>
      <description>arXiv:2411.11542v1 Announce Type: new 
Abstract: Static structured control refers to the task of designing a state-feedback controller such that the control gain satisfies a subspace constraint. Structured control has applications in control of communication-inhibited dynamical systems, such as systems in networked environments. This work performs $H_2$-suboptimal regulation under a common structured state-feedback controller for a class of data-consistent plants. The certification of $H_2$-performance is attained through a combination of standard $H_2$ LMIs, convex sufficient conditions for structured control, and a matrix S-lemma for set-membership. The resulting convex optimization problems are linear matrix inequalities whose size scales independently of the number of data samples collected. Data-driven structured $H_2$-regulation control is demonstrated on example systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11542v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Jaap Eising, Florian D\"orfler, Roy S. Smith</dc:creator>
    </item>
    <item>
      <title>Linear Convergence of the Proximal Gradient Method for Composite Optimization Under the Polyak-{\L}ojasiewicz Inequality and Its Variant</title>
      <link>https://arxiv.org/abs/2411.11628</link>
      <description>arXiv:2411.11628v1 Announce Type: new 
Abstract: We study the linear convergence rates of the proximal gradient method for composite functions satisfying two classes of Polyak-{\L}ojasiewicz (PL) inequality: the PL inequality, the variant of PL inequality defined by the proximal map-based residual. Using the performance estimation problem, we either provide new explicit linear convergence rates or improve existing complexity bounds for minimizing composite functions under the two classes of PL inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11628v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyuan Kong, Rujun Jiang, Yihan He</dc:creator>
    </item>
    <item>
      <title>Trade-off Invariance Principle for minimizers of regularized functionals</title>
      <link>https://arxiv.org/abs/2411.11639</link>
      <description>arXiv:2411.11639v1 Announce Type: new 
Abstract: In this paper, we consider functionals of the form $H_\alpha(u)=F(u)+\alpha G(u)$ with $\alpha\in[0,+\infty)$, where $u$ varies in a set $U\neq\emptyset$ (without further structure). We first show that, excluding at most countably many values of $\alpha$, we have that $\inf_{H_\alpha^\star}G= \sup_{H_\alpha^\star}G$, where $H_\alpha^\star := \arg \min_U H_\alpha$, which is assumed to be non-empty. We further prove a stronger result that concerns the {invariance of the} limiting value of the functional $G$ along minimizing sequences for $H_\alpha$. This fact in turn implies an unexpected consequence for functionals regularized with uniformly convex norms: excluding again at most countably many values of $\alpha$, it turns out that for a minimizing sequence, convergence to a minimizer in the weak or strong sense is equivalent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11639v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Fornasier, Jona Klemenc, Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>Block Coordinate DC Programming</title>
      <link>https://arxiv.org/abs/2411.11664</link>
      <description>arXiv:2411.11664v1 Announce Type: new 
Abstract: We introduce an extension of the Difference of Convex Algorithm (DCA) in the form of a block coordinate approach for problems with separable structure. For $n$ coordinate-blocks and $k$ iterations, our main result proves a non-asymptotic convergence rate of $O(n/k)$ for the proposed method. Furthermore, leveraging the connection between DCA and Expectation Maximization (EM), we propose a block coordinate EM algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11664v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoomaan Maskan, Paniz Halvachi, Suvrit Sra, Alp Yurtsever</dc:creator>
    </item>
    <item>
      <title>Solving convex QPs with structured sparsity under indicator conditions</title>
      <link>https://arxiv.org/abs/2411.11722</link>
      <description>arXiv:2411.11722v1 Announce Type: new 
Abstract: We study convex optimization problems where disjoint blocks of variables are controlled by binary indicator variables that are also subject to conditions, e.g., cardinality. Several classes of important examples can be formulated in such a way that both the objective and the constraints are separable convex quadratics. We describe a family of polynomial-time approximation algorithms and negative complexity results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11722v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Bienstock, Tongtong Chen</dc:creator>
    </item>
    <item>
      <title>Distributed Asynchronous Time-Varying Quadratic Programming with Asynchronous Objective Sampling</title>
      <link>https://arxiv.org/abs/2411.11732</link>
      <description>arXiv:2411.11732v1 Announce Type: new 
Abstract: We present a distributed algorithm to track the fixed points of time-varying quadratic programs when agents can (i) sample their objective function asynchronously, (ii) compute new iterates asynchronously, and (iii) communicate asynchronously. We show that even for a time-varying strongly convex quadratic program, asynchronous sampling of objectives can cause agents to minimize a certain form of nonconvex "aggregate" objective function. Then, we show that by minimizing the aggregate objective, agents still track the solution of the original quadratic program to within an error ball dependent upon (i) agents' tracking error when solving the aggregate problem, and (ii) the time variation of the original quadratic objective. Lastly, we show that this work generalizes existing work, in the sense that synchronizing the agents' behaviors recovers existing convergence results (up to constants). Simulations show the robustness of our algorithm to asynchrony.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11732v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Behrendt, Zachary I. Bell, Matthew Hale</dc:creator>
    </item>
    <item>
      <title>Anisotropic Gaussian Smoothing for Gradient-based Optimization</title>
      <link>https://arxiv.org/abs/2411.11747</link>
      <description>arXiv:2411.11747v1 Announce Type: new 
Abstract: This article introduces a novel family of optimization algorithms - Anisotropic Gaussian Smoothing Gradient Descent (AGS-GD), AGS-Stochastic Gradient Descent (AGS-SGD), and AGS-Adam - that employ anisotropic Gaussian smoothing to enhance traditional gradient-based methods, including GD, SGD, and Adam. The primary goal of these approaches is to address the challenge of optimization methods becoming trapped in suboptimal local minima by replacing the standard gradient with a non-local gradient derived from averaging function values using anisotropic Gaussian smoothing. Unlike isotropic Gaussian smoothing (IGS), AGS adapts the smoothing directionality based on the properties of the underlying function, aligning better with complex loss landscapes and improving convergence. The anisotropy is computed by adjusting the covariance matrix of the Gaussian distribution, allowing for directional smoothing tailored to the gradient's behavior. This technique mitigates the impact of minor fluctuations, enabling the algorithms to approach global minima more effectively. We provide detailed convergence analyses that extend the results from both the original (unsmoothed) methods and the IGS case to the more general anisotropic smoothing, applicable to both convex and non-convex, L-smooth functions. In the stochastic setting, these algorithms converge to a noisy ball, with its size determined by the smoothing parameters. The article also outlines the theoretical benefits of anisotropic smoothing and details its practical implementation using Monte Carlo estimation, aligning with established zero-order optimization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11747v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Starnes, Guannan Zhang, Viktor Reshniak, Clayton Webster</dc:creator>
    </item>
    <item>
      <title>A characterization of unimodular hypergraphs with disjoint hyperedges</title>
      <link>https://arxiv.org/abs/2411.10593</link>
      <description>arXiv:2411.10593v1 Announce Type: cross 
Abstract: Grossman et al. show that the subdeterminants of the incidence matrix of a graph can be characterized using the graph's odd cycle packing number. In particular, a graph's incidence matrix is totally unimodular if and only if the graph is bipartite. We extend the characterization of total unimodularity to disjoint hypergraphs, i.e., hypergraphs whose hyperedges of size at least four are pairwise disjoint. Disjoint hypergraphs interpolate between graphs and hypergraphs, which correspond to arbitrary {0,1}-matrices. We prove that total unimodularity for disjoint hypergraphs is equivalent to forbidding both odd cycles and a structure we call an ''odd tree house''. Our result extends to disjoint directed hypergraphs, i.e., those whose incidence matrices allow for {-1,0, 1}-entries. As a corollary, we resolve a conjecture on almost totally unimodular matrices, formulated by Padberg (1988) and Cornu\'ejols &amp; Zuluaga (2000), in the special case where columns with at least four non-zero elements have pairwise disjoint supports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10593v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marco Caoduro, Meike Neuwohner, Joseph Paat</dc:creator>
    </item>
    <item>
      <title>Series Expansion of Probability of Correct Selection for Improved Finite Budget Allocation in Ranking and Selection</title>
      <link>https://arxiv.org/abs/2411.10695</link>
      <description>arXiv:2411.10695v1 Announce Type: cross 
Abstract: This paper addresses the challenge of improving finite sample performance in Ranking and Selection by developing a Bahadur-Rao type expansion for the Probability of Correct Selection (PCS). While traditional large deviations approximations captures PCS behavior in the asymptotic regime, they can lack precision in finite sample settings. Our approach enhances PCS approximation under limited simulation budgets, providing more accurate characterization of optimal sampling ratios and optimality conditions dependent of budgets. Algorithmically, we propose a novel finite budget allocation (FCBA) policy, which sequentially estimates the optimality conditions and accordingly balances the sampling ratios. We illustrate numerically on toy examples that our FCBA policy achieves superior PCS performance compared to tested traditional methods. As an extension, we note that the non-monotonic PCS behavior described in the literature for low-confidence scenarios can be attributed to the negligence of simultaneous incorrect binary comparisons in PCS approximations. We provide a refined expansion and a tailored allocation strategy to handle low-confidence scenarios, addressing the non-monotonicity issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10695v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinbo Shi, Yijie Peng, Bruno Tuffin</dc:creator>
    </item>
    <item>
      <title>Differentiable Extensions with Rounding Guarantees for Combinatorial Optimization over Permutations</title>
      <link>https://arxiv.org/abs/2411.10707</link>
      <description>arXiv:2411.10707v1 Announce Type: cross 
Abstract: We present Birkhoff Extension (BE), an almost-everywhere-differentiable continuous polytime-computable extension of any real-valued function on permutations to doubly stochastic matrices. Our approach is based on Birkhoff decomposition (also referred to as Birkhoff von-Neumann decomposition) which allows construction of an extension that is always a convex combination of the objective's values at permutations. We show how to construct a specific family of Birkhoff decompositions that are continuous. In addition to continuity, our extension has several nice properties making it appealing for optimization problems. First, BE provides a rounding guarantee, namely any solution to the extension can be efficiently rounded to a permutation without increasing the function value. Furthermore, an approximate solution in the relaxed case (with extension) will give rise to an approximate solution in the space of permutations. Second, using BE, any real-valued optimization objective on permutations can be extended to an almost everywhere differentiable objective function over the space of doubly stochastic matrices. This makes our BE amenable to not only gradient-descent based optimizations, but also unsupervised neural combinatorial optimization where training often requires a differentiable loss. Third, based on the above properties, we present a simple optimization procedure which can be readily combined with existing optimization approaches to offer local improvements (i.e., the quality of the final solution is no worse than the initial solution). We present preliminary experimental results to verify our theoretical results on several combinatorial optimization problems related to permutations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10707v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Robert R. Nerem, Zhishang Luo, Akbar Rafiey, Yusu Wang</dc:creator>
    </item>
    <item>
      <title>Classical optimization with imaginary time block encoding on quantum computers: The MaxCut problem</title>
      <link>https://arxiv.org/abs/2411.10737</link>
      <description>arXiv:2411.10737v1 Announce Type: cross 
Abstract: Finding ground state solutions of diagonal Hamiltonians is relevant for both theoretical as well as practical problems of interest in many domains such as finance, physics and computer science. These problems are typically very hard to tackle by classical computing and quantum computing could help in speeding up computations and efficiently tackling larger problems. Here we use imaginary time evolution through a new block encoding scheme to obtain the ground state of such problems and apply our method to MaxCut as an illustration. Our method, which for simplicity we call ITE-BE, requires no variational parameter optimization as all the parameters in the procedure are expressed as analytical functions of the couplings of the Hamiltonian. We demonstrate that our method can be successfully combined with other quantum algorithms such as quantum approximate optimization algorithm (QAOA). We find that the QAOA ansatz increases the post-selection success of ITE-BE, and shallow QAOA circuits, when boosted with ITE-BE, achieve better performance than deeper QAOA circuits. For the special case of the transverse initial state, we adapt our block encoding scheme to allow for a deterministic application of the first layer of the circuit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10737v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dawei Zhong, Akhil Francis, Ermal Rrapaj</dc:creator>
    </item>
    <item>
      <title>One-Layer Transformer Provably Learns One-Nearest Neighbor In Context</title>
      <link>https://arxiv.org/abs/2411.10830</link>
      <description>arXiv:2411.10830v1 Announce Type: cross 
Abstract: Transformers have achieved great success in recent years. Interestingly, transformers have shown particularly strong in-context learning capability -- even without fine-tuning, they are still able to solve unseen tasks well purely based on task-specific prompts. In this paper, we study the capability of one-layer transformers in learning one of the most classical nonparametric estimators, the one-nearest neighbor prediction rule. Under a theoretical framework where the prompt contains a sequence of labeled training data and unlabeled test data, we show that, although the loss function is nonconvex when trained with gradient descent, a single softmax attention layer can successfully learn to behave like a one-nearest neighbor classifier. Our result gives a concrete example of how transformers can be trained to implement nonparametric machine learning algorithms, and sheds light on the role of softmax attention in transformer models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10830v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zihao Li, Yuan Cao, Cheng Gao, Yihan He, Han Liu, Jason M. Klusowski, Jianqing Fan, Mengdi Wang</dc:creator>
    </item>
    <item>
      <title>Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities</title>
      <link>https://arxiv.org/abs/2411.10868</link>
      <description>arXiv:2411.10868v1 Announce Type: cross 
Abstract: Social influence plays an important role in shaping individual opinions and actions, particularly in our digitally connected world. AI-generated, personalized content has led to serious and well-founded concerns, including United States Supreme Court Cases regarding the potential for the radicalization of individuals based on social influence. Motivated by these developments, we present a case study investigating the effects of small but intentional perturbations on the integrity of a simple social network. We employ Taylor's classic model of social influence and use tools from robust control theory (most notably the Dynamic Structure Function (DSF)), to identify precisely the perturbations that are sufficient to qualitatively alter the system's equilibrium and also minimal in norm. In particular, we examine two scenarios: perturbations to an existing link and perturbations taking the form of the addition of a new link to the network. In each case, we identify destabilizing perturbations and simulate their effects. Remarkably, we find that even small alterations to network structure may cause sentiments to grow in magnitude without bound, indicating the potential for large-scale shifts in collective behavior to be triggered by minor adjustments in social influence. Our findings emphasize the imperative need for further investigation into vulnerabilities in real-world social networks, where such dynamics may already exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10868v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lane H. Rogers, Emma J. Reid, Robert A. Bridges</dc:creator>
    </item>
    <item>
      <title>Optimizing Daily Fantasy Baseball Lineups: A Linear Programming Approach for Enhanced Accuracy</title>
      <link>https://arxiv.org/abs/2411.11012</link>
      <description>arXiv:2411.11012v1 Announce Type: cross 
Abstract: Daily fantasy baseball has shortened the life cycle of an entire fantasy season into a single day. As of today, it has become familiar with more than 10 million people around the world who participate in online fantasy. As daily fantasy continues to grow, the importance of selecting a winning lineup becomes more valuable. The purpose of this paper is to determine how accurate FanDuel current daily fantasy strategy of optimizing daily lineups are and utilize python and linear programming to build a lineup optimizer for daily fantasy sports with the goal of proposing a more accurate model to assist daily fantasy participants select a winning lineup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11012v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Grody, Sandeep Bansal, Huthaifa I. Ashqar</dc:creator>
    </item>
    <item>
      <title>Operator Splitting Covariance Steering for Safe Stochastic Nonlinear Control</title>
      <link>https://arxiv.org/abs/2411.11211</link>
      <description>arXiv:2411.11211v1 Announce Type: cross 
Abstract: Most robotics applications are typically accompanied with safety restrictions that need to be satisfied with a high degree of confidence even in environments under uncertainty. Controlling the state distribution of a system and enforcing such specifications as distribution constraints is a promising approach for meeting such requirements. In this direction, covariance steering (CS) is an increasingly popular stochastic optimal control (SOC) framework for designing safe controllers via explicit constraints on the system covariance. Nevertheless, a major challenge in applying CS methods to systems with the nonlinear dynamics and chance constraints common in robotics is that the approximations needed are conservative and highly sensitive to the point of approximation. This can cause sequential convex programming methods to converge to poor local minima or incorrectly report problems as infeasible due to shifting constraints. This paper presents a novel algorithm for solving chance-constrained nonlinear CS problems that directly addresses this challenge. Specifically, we propose an operator-splitting approach that temporarily separates the main problem into subproblems that can be solved in parallel. The benefit of this relaxation lies in the fact that it does not require all iterates to satisfy all constraints simultaneously prior to convergence, thus enhancing the exploration capabilities of the algorithm for finding better solutions. Simulation results verify the ability of the proposed method to find higher quality solutions under stricter safety constraints than standard methods on a variety of robotic systems. Finally, the applicability of the algorithm on real systems is confirmed through hardware demonstrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11211v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Ratheesh, Vincent Pacelli, Augustinos D. Saravanos, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Don't Be So Positive: Negative Step Sizes in Second-Order Methods</title>
      <link>https://arxiv.org/abs/2411.11224</link>
      <description>arXiv:2411.11224v1 Announce Type: cross 
Abstract: The value of second-order methods lies in the use of curvature information. Yet, this information is costly to extract and once obtained, valuable negative curvature information is often discarded so that the method is globally convergent. This limits the effectiveness of second-order methods in modern machine learning. In this paper, we show that second-order and second-order-like methods are promising optimizers for neural networks provided that we add one ingredient: negative step sizes. We show that under very general conditions, methods that produce ascent directions are globally convergent when combined with a Wolfe line search that allows both positive and negative step sizes. We experimentally demonstrate that using negative step sizes is often more effective than common Hessian modification methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11224v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Betty Shea, Mark Schmidt</dc:creator>
    </item>
    <item>
      <title>Mirror Descent on Reproducing Kernel Banach Spaces</title>
      <link>https://arxiv.org/abs/2411.11242</link>
      <description>arXiv:2411.11242v1 Announce Type: cross 
Abstract: Recent advances in machine learning have led to increased interest in reproducing kernel Banach spaces (RKBS) as a more general framework that extends beyond reproducing kernel Hilbert spaces (RKHS). These works have resulted in the formulation of representer theorems under several regularized learning schemes. However, little is known about an optimization method that encompasses these results in this setting. This paper addresses a learning problem on Banach spaces endowed with a reproducing kernel, focusing on efficient optimization within RKBS. To tackle this challenge, we propose an algorithm based on mirror descent (MDA). Our approach involves an iterative method that employs gradient steps in the dual space of the Banach space using the reproducing kernel.
  We analyze the convergence properties of our algorithm under various assumptions and establish two types of results: first, we identify conditions under which a linear convergence rate is achievable, akin to optimization in the Euclidean setting, and provide a proof of the linear rate; second, we demonstrate a standard convergence rate in a constrained setting. Moreover, to instantiate this algorithm in practice, we introduce a novel family of RKBSs with $p$-norm ($p \neq 2$), characterized by both an explicit dual map and a kernel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11242v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akash Kumar, Mikhail Belkin, Parthe Pandit</dc:creator>
    </item>
    <item>
      <title>The ballistic limit of the log-Sobolev constant equals the Polyak-{\L}ojasiewicz constant</title>
      <link>https://arxiv.org/abs/2411.11415</link>
      <description>arXiv:2411.11415v1 Announce Type: cross 
Abstract: The Polyak-Lojasiewicz (PL) constant of a function $f \colon \mathbb{R}^d \to \mathbb{R}$ characterizes the best exponential rate of convergence of gradient flow for $f$, uniformly over initializations. Meanwhile, in the theory of Markov diffusions, the log-Sobolev (LS) constant plays an analogous role, governing the exponential rate of convergence for the Langevin dynamics from arbitrary initialization in the Kullback-Leibler divergence. We establish a new connection between optimization and sampling by showing that the low temperature limit $\lim_{t\to 0^+} t^{-1} C_{\mathsf{LS}}(\mu_t)$ of the LS constant of $\mu_t \propto \exp(-f/t)$ is exactly the PL constant of $f$, under mild assumptions. In contrast, we show that the corresponding limit for the Poincar\'e constant is the inverse of the smallest eigenvalue of $\nabla^2 f$ at the minimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11415v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sinho Chewi, Austin J. Stromme</dc:creator>
    </item>
    <item>
      <title>Robust Markov Decision Processes: A Place Where AI and Formal Methods Meet</title>
      <link>https://arxiv.org/abs/2411.11451</link>
      <description>arXiv:2411.11451v1 Announce Type: cross 
Abstract: Markov decision processes (MDPs) are a standard model for sequential decision-making problems and are widely used across many scientific areas, including formal methods and artificial intelligence (AI). MDPs do, however, come with the restrictive assumption that the transition probabilities need to be precisely known. Robust MDPs (RMDPs) overcome this assumption by instead defining the transition probabilities to belong to some uncertainty set. We present a gentle survey on RMDPs, providing a tutorial covering their fundamentals. In particular, we discuss RMDP semantics and how to solve them by extending standard MDP methods such as value iteration and policy iteration. We also discuss how RMDPs relate to other models and how they are used in several contexts, including reinforcement learning and abstraction techniques. We conclude with some challenges for future work on RMDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11451v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marnix Suilen, Thom Badings, Eline M. Bovy, David Parker, Nils Jansen</dc:creator>
    </item>
    <item>
      <title>Stability and decay rate estimates for a nonlinear dispersed flow reactor model with boundary control</title>
      <link>https://arxiv.org/abs/2411.11550</link>
      <description>arXiv:2411.11550v1 Announce Type: cross 
Abstract: We investigate a nonlinear parabolic partial differential equation whose boundary conditions contain a single control input. This model describes a chemical reaction of the type ''$A \to $ product'', occurring in a dispersed flow tubular reactor. The existence and uniqueness of solutions to the nonlinear Cauchy problem under consideration are established by applying the theory of strongly continuous semigroups of operators. Using Lyapunov's direct method, a feedback control design that ensures the exponential stability of the steady state is proposed, and the exponential decay rate of solutions is evaluated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11550v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yevgeniia Yevgenieva, Alexander Zuyev, Peter Benner</dc:creator>
    </item>
    <item>
      <title>A Linear Differential Inclusion for Contraction Analysis to Known Trajectories</title>
      <link>https://arxiv.org/abs/2411.11587</link>
      <description>arXiv:2411.11587v1 Announce Type: cross 
Abstract: Infinitesimal contraction analysis provides exponential convergence rates between arbitrary pairs of trajectories of a system by studying the system's linearization. An essentially equivalent viewpoint arises through stability analysis of a linear differential inclusion (LDI) encompassing the incremental behavior of the system. In this note, we study contraction of a system to a particular known trajectory, deriving a new LDI characterizing the error between arbitrary trajectories and this known trajectory. As with classical contraction analysis, this new inclusion is constructed via first partial derivatives of the system's vector field, and contraction rates are obtained with familiar tools: uniform bounding of the logarithmic norm and LMI-based Lyapunov conditions. Our LDI is guaranteed to outperform a usual contraction analysis in two special circumstances: i) when the bound on the logarithmic norm arises from an interval overapproximation of the Jacobian matrix, and ii) when the norm considered is the $\ell_1$ norm. Finally, we demonstrate how the proposed approach strictly improves an existing framework for ellipsoidal reachable set computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11587v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Harapanahalli, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>Approximate predictive control barrier function for discrete-time systems</title>
      <link>https://arxiv.org/abs/2411.11610</link>
      <description>arXiv:2411.11610v1 Announce Type: cross 
Abstract: We propose integrating an explicit approximation of a predictive control barrier function (PCBF) in a safety filter framework. The approximated PCBF is implicitly defined through an optimal control problem and allows guaranteeing invariance of an implicitly defined safe set as well as stability of this safe set within a larger domain of attraction. By extending existing theoretical analysis of the PCBF, we establish inherent robustness of the original algorithm and translate the guarantees to input-to-state stability of the proposed algorithm with respect to possible approximation errors, recovering the same guarantees in the absence of approximation errors. The proposed algorithm allows certifying inputs with respect to state constraint satisfaction through a single function evaluation and filtering unsafe inputs through a control barrier function based safety filter, which is independent of the time horizon of the original predictive optimisation problem, resulting in significant online computational benefits. We demonstrate the stability properties of the proposed algorithm on a linear system example as well as its use a fast safety filter for miniature race cars in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11610v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Didier, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Cardinal Optimizer (COPT) User Guide</title>
      <link>https://arxiv.org/abs/2208.14314</link>
      <description>arXiv:2208.14314v3 Announce Type: replace 
Abstract: Cardinal Optimizer is a high-performance mathematical programming solver for efficiently solving largescale optimization problem. This documentation provides basic introduction to the Cardinal Optimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.14314v3</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongdong Ge, Qi Huangfu, Zizhuo Wang, Jian Wu, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>On stochastic control under Poisson observations: optimality of a barrier strategy in a general L\'evy model</title>
      <link>https://arxiv.org/abs/2210.00501</link>
      <description>arXiv:2210.00501v2 Announce Type: replace 
Abstract: We study a version of the stochastic control problem of minimizing the sum of running and controlling costs, where control opportunities are restricted to independent Poisson arrival times. Under a general setting driven by a general L\'evy process, we show the optimality of a periodic barrier strategy, which moves the process upward to the barrier whenever it is observed to be below it. The convergence of the optimal solutions to those in the continuous-observation case is also shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00501v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kei Noba, Kazutoshi Yamazaki</dc:creator>
    </item>
    <item>
      <title>Finite adaptability in two-stage robust optimization: asymptotic optimality and tractability</title>
      <link>https://arxiv.org/abs/2305.05399</link>
      <description>arXiv:2305.05399v3 Announce Type: replace 
Abstract: Two-stage robust optimization is a fundamental paradigm for modeling and solving optimization problems with uncertain parameters. A now classical method within this paradigm is {\em finite adaptability}, introduced by Bertsimas and Caramanis (\emph{IEEE Transactions on Automatic Control}, 2010). It consists in restricting the recourse to a finite number $k$ of possible values. In this work, we point out that the continuity assumption they stated to ensure the convergence of the method when $k$ goes to infinity is not correct, and we propose an alternative assumption for which we prove the desired convergence. Bertsimas and Caramanis also established that finite adaptability is NP-hard, even in the special case when $k=2$, the variables are continuous, and only specific parameters are subject to uncertainty. We provide a theorem showing that this special case becomes polynomial when the uncertainty set is a polytope with a bounded number of vertices, and we extend this theorem for $k=3$ as well. On our way, we establish new geometric results on coverings of polytopes with convex sets, which might be interesting for their own sake.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05399v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Safia Kedad-Sidhoum, Anton Medvedev, Fr\'ed\'eric Meunier</dc:creator>
    </item>
    <item>
      <title>Global stabilization of a Sterile Insect Technique model by feedback laws</title>
      <link>https://arxiv.org/abs/2307.00846</link>
      <description>arXiv:2307.00846v2 Announce Type: replace 
Abstract: This work concerns feedback global stabilization of the sterile insect technique dynamics. The Sterile Insect Technique (SIT) is presently one of the most ecological methods for controlling insect pests responsible for crop destruction and disease transmission worldwide. This technique consists in releasing sterile males among the insect pest population, the aim being to reduce fertility and, consequently, reduce significantly the wild insect population after a few generations.&lt;/p&gt;&lt;p&gt;In this work, we study the global stabilization of a pest population at extinction equilibrium by the SIT method and construct explicit feedback laws that stabilize the model. Numerical simulations show the efficiency of our feedback laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00846v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kala Agbo Bidi (LJLL, SU, CaGE), Lu\'is Almeida (LJLL, SU), Jean-Michel Coron (LJLL, SU, CaGE)</dc:creator>
    </item>
    <item>
      <title>An adaptively inexact first-order method for bilevel optimization with application to hyperparameter learning</title>
      <link>https://arxiv.org/abs/2308.10098</link>
      <description>arXiv:2308.10098v3 Announce Type: replace 
Abstract: Various tasks in data science are modeled utilizing the variational regularization approach, where manually selecting regularization parameters presents a challenge. The difficulty gets exacerbated when employing regularizers involving a large number of hyperparameters. To overcome this challenge, bilevel learning can be employed to learn such parameters from data. However, neither exact function values nor exact gradients with respect to the hyperparameters are attainable, necessitating methods that only rely on inexact evaluation of such quantities. State-of-the-art inexact gradient-based methods a priori select a sequence of the required accuracies and cannot identify an appropriate step size since the Lipschitz constant of the hypergradient is unknown. In this work, we propose an algorithm with backtracking line search that only relies on inexact function evaluations and hypergradients and show convergence to a stationary point. Furthermore, the proposed algorithm determines the required accuracy dynamically rather than manually selected before running it. Our numerical experiments demonstrate the efficiency and feasibility of our approach for hyperparameter estimation on a range of relevant problems in imaging and data science such as total variation and field of experts denoising and multinomial logistic regression. Particularly, the results show that the algorithm is robust to its own hyperparameters such as the initial accuracies and step size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10098v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>A hierarchy of eigencomputations for polynomial optimization on the sphere</title>
      <link>https://arxiv.org/abs/2310.17827</link>
      <description>arXiv:2310.17827v2 Announce Type: replace 
Abstract: We introduce a convergent hierarchy of lower bounds on the minimum value of a real form over the unit sphere. The main practical advantage of our hierarchy over the real sum-of-squares (RSOS) hierarchy is that the lower bound at each level of our hierarchy is obtained by a minimum eigenvalue computation, as opposed to the full semidefinite program (SDP) required at each level of RSOS. In practice, this allows us to compute bounds on much larger forms than are computationally feasible for RSOS. Our hierarchy outperforms previous alternatives to RSOS, both asymptotically and in numerical experiments. We obtain our hierarchy by proving a reduction from real optimization on the sphere to Hermitian optimization on the sphere, and invoking the Hermitian sum-of-squares (HSOS) hierarchy. This opens the door to using other Hermitian optimization techniques for real optimization, and gives a path towards developing spectral hierarchies for more general constrained real optimization problems. To this end, we use our techniques to develop a hierarchy of eigencomputations for computing the real tensor spectral norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17827v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.AG</category>
      <category>quant-ph</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Lovitz, Nathaniel Johnston</dc:creator>
    </item>
    <item>
      <title>Improved Performance of Stochastic Gradients with Gaussian Smoothing</title>
      <link>https://arxiv.org/abs/2311.00531</link>
      <description>arXiv:2311.00531v3 Announce Type: replace 
Abstract: This paper formalizes and analyzes Gaussian smoothing applied to two prominent optimization methods: Stochastic Gradient Descent (GSmoothSGD) and Adam (GSmoothAdam) in deep learning. By attenuating small fluctuations, Gaussian smoothing lowers the risk of gradient-based algorithms converging to poor local minima. These methods simplify the loss landscape while boosting robustness to noise and improving generalization, helping base algorithms converge more effectively to global minima. Existing approaches often rely on zero-order approximations, which increase training time due to inefficiencies in automatic differentiation. To address this, we derive Gaussian-smoothed loss functions for feedforward and convolutional networks, improving computational efficiency. Numerical experiments demonstrate the enhanced performance of our smoothing algorithms over unsmoothed counterparts, confirming the theoretical benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00531v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Starnes, Clayton Webster</dc:creator>
    </item>
    <item>
      <title>Sparse factorization of the square all-ones matrix of arbitrary order</title>
      <link>https://arxiv.org/abs/2401.14596</link>
      <description>arXiv:2401.14596v2 Announce Type: replace 
Abstract: In this paper, we study sparse factorization of the (scaled) square all-ones matrix $J$ of arbitrary order. We introduce the concept of hierarchically banded matrices and propose two types of hierarchically banded factorization of $J$: the reduced hierarchically banded (RHB) factorization and the doubly stochastic hierarchically banded (DSHB) factorization. Based on the DSHB factorization, we propose the sequential doubly stochastic (SDS) factorization, in which~$J$ is decomposed as a product of sparse, doubly stochastic matrices. Finally, we discuss the application of the proposed sparse factorizations to the decentralized average consensus problem and decentralized optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14596v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Jiang, Edward Duc Hien Nguyen, C\'esar A. Uribe, Bicheng Ying</dc:creator>
    </item>
    <item>
      <title>Non-convex Stochastic Composite Optimization with Polyak Momentum</title>
      <link>https://arxiv.org/abs/2403.02967</link>
      <description>arXiv:2403.02967v3 Announce Type: replace 
Abstract: The stochastic proximal gradient method is a powerful generalization of the widely used stochastic gradient descent (SGD) method and has found numerous applications in Machine Learning. However, it is notoriously known that this method fails to converge in non-convex settings where the stochastic noise is significant (i.e. when only small or bounded batch sizes are used). In this paper, we focus on the stochastic proximal gradient method with Polyak momentum. We prove this method attains an optimal convergence rate for non-convex composite optimization problems, regardless of batch size. Additionally, we rigorously analyze the variance reduction effect of the Polyak momentum in the composite optimization setting and we show the method also converges when the proximal step can only be solved inexactly. Finally, we provide numerical experiments to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02967v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Memetic Differential Evolution Methods for Semi-Supervised Clustering</title>
      <link>https://arxiv.org/abs/2403.04322</link>
      <description>arXiv:2403.04322v2 Announce Type: replace 
Abstract: In this paper, we propose an extension for semi-supervised Minimum Sum-of-Squares Clustering (MSSC) problems of MDEClust, a memetic framework based on the Differential Evolution paradigm for unsupervised clustering. In semi-supervised MSSC, background knowledge is available in the form of (instance-level) "must-link" and "cannot-link" constraints, each of which indicating if two dataset points should be associated to the same or to a different cluster, respectively. The presence of such constraints makes the problem at least as hard as its unsupervised version and, as a consequence, some framework operations need to be carefully designed to handle this additional complexity: for instance, it is no more true that each point is associated to its nearest cluster center. As far as we know, our new framework, called S-MDEClust, represents the first memetic methodology designed to generate a (hopefully) optimal feasible solution for semi-supervised MSSC problems. Results of thorough computational experiments on a set of well-known as well as synthetic datasets show the effectiveness and efficiency of our proposal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04322v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierluigi Mansueto, Fabio Schoen</dc:creator>
    </item>
    <item>
      <title>Learning-Based Pricing and Matching for Two-Sided Queues</title>
      <link>https://arxiv.org/abs/2403.11093</link>
      <description>arXiv:2403.11093v2 Announce Type: replace 
Abstract: We consider a dynamic system with multiple types of customers and servers. Each type of waiting customer or server joins a separate queue, forming a bipartite graph with customer-side queues and server-side queues. The platform can match the servers and customers if their types are compatible. The matched pairs then leave the system. The platform will charge a customer a price according to their type when they arrive and will pay a server a price according to their type. The arrival rate of each queue is determined by the price according to some unknown demand or supply functions. Our goal is to design pricing and matching algorithms to maximize the profit of the platform with unknown demand and supply functions, while keeping queue lengths of both customers and servers below a predetermined threshold. This system can be used to model two-sided markets such as ride-sharing markets with passengers and drivers. The difficulties of the problem include simultaneous learning and decision making, and the tradeoff between maximizing profit and minimizing queue length. We use a longest-queue-first matching algorithm and propose a learning-based pricing algorithm, which combines gradient-free stochastic projected gradient ascent with bisection search. We prove that our proposed algorithm yields a sublinear regret $\tilde{O}(T^{5/6})$ and anytime queue-length bound $\tilde{O}(T^{1/6})$, where $T$ is the time horizon. We further establish a tradeoff between the regret bound and the queue-length bound: $\tilde{O}(T^{1-\gamma})$ versus $\tilde{O}(T^{\gamma})$ for $\gamma \in (0, 1/6].$</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11093v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixian Yang, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Problem-Driven Scenario Reduction Framework for Power System Stochastic Operation</title>
      <link>https://arxiv.org/abs/2404.07810</link>
      <description>arXiv:2404.07810v3 Announce Type: replace 
Abstract: Scenario reduction (SR) aims to identify a small yet representative scenario set to depict the underlying uncertainty, which is critical to scenario-based stochastic optimization (SBSO) of power systems. Existing SR techniques commonly aim to achieve statistical approximation to the original scenario set. However, SR and SBSO are commonly considered as two distinct and decoupled processes, which cannot guarantee a superior approximation of the original optimality. Instead, this paper incorporates the SBSO problem structure into the SR process and introduces a novel problem-driven scenario reduction (PDSR) framework. Specifically, we project the original scenario set in distribution space onto the mutual decision applicability between scenarios in problem space. Subsequently, the SR process, embedded by a distinctive problem-driven distance metric, is rendered as a mixed-integer linear programming formulation to obtain the representative scenario set while minimizing the optimality gap. Furthermore, &lt;i&gt;ex-ante&lt;i&gt; and &lt;i&gt;ex-post&lt;i&gt; problem-driven evaluation indices are proposed to evaluate the SR performance. Numerical experiments on two two-stage stochastic economic dispatch problems validate the effectiveness of PDSR, and demonstrate that PDSR significantly outperforms existing SR methods by identifying salient (e.g., worst-case) scenarios, and achieving an optimality gap of less than 0.1% within acceptable computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07810v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingrui Zhuang, Lin Cheng, Ning Qi, Mads R. Almassalkhi, Feng Liu</dc:creator>
    </item>
    <item>
      <title>ADMM for Nonconvex Optimization under Minimal Continuity Assumption</title>
      <link>https://arxiv.org/abs/2405.03233</link>
      <description>arXiv:2405.03233v3 Announce Type: replace 
Abstract: This paper introduces a novel approach to solving multi-block nonconvex composite optimization problems through a proximal linearized Alternating Direction Method of Multipliers (ADMM). This method incorporates an Increasing Penalization and Decreasing Smoothing (IPDS) strategy. Distinguishing itself from existing ADMM-style algorithms, our approach (denoted IPDS-ADMM) imposes a less stringent condition, specifically requiring continuity in just one block of the objective function. IPDS-ADMM requires that the penalty increases and the smoothing parameter decreases, both at a controlled pace. When the associated linear operator is bijective, IPDS-ADMM uses an over-relaxation stepsize for faster convergence; however, when the linear operator is surjective, IPDS-ADMM uses an under-relaxation stepsize for global convergence. We devise a novel potential function to facilitate our convergence analysis and prove an oracle complexity $\O(\epsilon^{-3})$ to achieve an $\epsilon$-approximate critical point. To the best of our knowledge, this is the first complexity result for using ADMM to solve this class of nonsmooth nonconvex problems. Finally, some experiments on the sparse PCA problem are conducted to demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03233v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking is Stable for Scalar Maps that are Strictly but Not Strongly Convex</title>
      <link>https://arxiv.org/abs/2405.12908</link>
      <description>arXiv:2405.12908v2 Announce Type: replace 
Abstract: For a map that is strictly but not strongly convex, model-based gradient extremum seeking has an eigenvalue of zero at the extremum, i.e., it fails at exponential convergence. Interestingly, perturbation-based model-free extremum seeking has a negative Jacobian, in the average, meaning that its (practical) convergence is exponential, even though the map's Hessian is zero at the extremum. While these observations for the gradient algorithm are not trivial, we focus in this paper on an even more nontrivial study of the same phenomenon for Newton-based extremum seeking control (NESC).
  NESC is a second-order method which corrects for the unknown Hessian of the unknown map, not only in order to speed up parameter convergence, but also (1) to make the convergence rate user-assignable in spite of the unknown Hessian, and (2) to equalize the convergence rates in different directions for multivariable maps. Previous NESC work established stability only for maps whose Hessians are strictly positive definite everywhere, so the Hessian is invertible everywhere. For a scalar map, we establish the rather unexpected property that, even when the map behind is strictly convex but not strongly convex, i.e., when the Hessian may be zero, NESC guarantees practical asymptotic stability, semiglobally. While a model-based Newton-based algorithm would run into non-invertibility of the Hessian, the perturbation-based NESC, surprisingly, avoids this challenge by leveraging the fact that the average of the perturbation-based Hessian estimate is always positive, even though the actual Hessian may be zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12908v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick McNamee, Miroslav Krsti\'c, Zahra Nili Ahmadabadi</dc:creator>
    </item>
    <item>
      <title>The Non-Substitution Theorem, Uniqueness of Solution and Convex combinations of basic optimal solutions for linear optimization</title>
      <link>https://arxiv.org/abs/2408.14150</link>
      <description>arXiv:2408.14150v4 Announce Type: replace 
Abstract: Our first result is a statement of a somewhat general form of a non-substitution theorem for linear programming problems, along with a very easy proof of the same. Subsequently, we provide an easy proof of theorem 1 in a 1979 paper of Olvi L. Mangasarian, based on a new result in terms of two statements that are each equivalent to a given solution of a linear programming problem being its unique solution. We also provide a simple proof of the result that states that the set of optimal solutions of a bounded linear optimization problem is the set of all convex combinations of its basic optimal solutions and the set of basic optimal solutions are the extreme points of the set of optimal solutions. We do so by appealing to the lemma due to Farkas and the well-known result that states that if a linear optimization problem has an optimal solution, it has at least one basic optimal solution. Both results we appeal to have easy proofs. We do not appeal to any version of the Klein-Milman Theorem or any result in advanced polyhedral combinatorics to obtain our results. As an application of this result, we obtain a simple proof of the Birkhoff-von Neumann Theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14150v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>Constraining Genetic Symbolic Regression via Semantic Backpropagation</title>
      <link>https://arxiv.org/abs/2409.07369</link>
      <description>arXiv:2409.07369v2 Announce Type: replace 
Abstract: Evolutionary symbolic regression approaches are powerful tools that can approximate an explicit mapping between input features and observation for various problems. However, ensuring that explored expressions maintain consistency with domain-specific constraints remains a crucial challenge. While neural networks are able to employ additional information like conservation laws to achieve more appropriate and robust approximations, the potential remains unrealized within genetic algorithms. This disparity is rooted in the inherent discrete randomness of recombining and mutating to generate new mapping expressions, making it challenging to maintain and preserve inferred constraints or restrictions in the course of the exploration. To address this limitation, we propose an approach centered on semantic backpropagation incorporated into the Gene Expression Programming (GEP), which integrates domain-specific properties in a vector representation as corrective feedback during the evolutionary process. By creating backward rules akin to algorithmic differentiation and leveraging pre-computed subsolutions, the mechanism allows the enforcement of any constraint within an expression tree by determining the misalignment and propagating desired changes back. To illustrate the effectiveness of constraining GEP through semantic backpropagation, we take the constraint of physical dimension as an example. This framework is applied to discovering physical equations from the Feynman lectures. Results have shown not only an increased likelihood of recovering the original equation but also notable robustness in the presence of noisy data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07369v2</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Reissmann, Yuan Fang, Andrew Ooi, Richard Sandberg</dc:creator>
    </item>
    <item>
      <title>Importance sampling-based gradient method for dimension reduction in Poisson log-normal model</title>
      <link>https://arxiv.org/abs/2410.00476</link>
      <description>arXiv:2410.00476v3 Announce Type: replace 
Abstract: High-dimensional count data poses significant challenges for statistical analysis, necessitating effective methods that also preserve explainability. We focus on a low rank constrained variant of the Poisson log-normal model, which relates the observed data to a latent low-dimensional multivariate Gaussian variable via a Poisson distribution. Variational inference methods have become a golden standard solution to infer such a model. While computationally efficient, they usually lack theoretical statistical properties with respect to the model. To address this issue we propose a projected stochastic gradient scheme that directly maximizes the log-likelihood. We prove the convergence of the proposed method when using importance sampling for estimating the gradient. Specifically, we obtain a rate of convergence of $O(T^{\nicefrac{-1}{2}} + N^{-1})$ with $T$ the number of iterations and $N$ the number of Monte Carlo draws. The latter follows from a novel descent lemma for non convex $L$-smooth objective functions, and random biased gradient estimate. We also demonstrate numerically the efficiency of our solution compared to its variational competitor. Our method not only scales with respect to the number of observed samples but also provides access to the desirable properties of the maximum likelihood estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00476v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bastien Batardi\`ere (MIA Paris-Saclay), Julien Chiquet (MIA Paris-Saclay), Joon Kwon (MIA Paris-Saclay), Julien Stoehr (CEREMADE)</dc:creator>
    </item>
    <item>
      <title>Detection of Undeclared EV Charging Events in a Green Energy Certification Scheme</title>
      <link>https://arxiv.org/abs/2410.18971</link>
      <description>arXiv:2410.18971v2 Announce Type: replace 
Abstract: The green potential of electric vehicles (EVs) can be fully realized only if their batteries are charged using energy generated from renewable (i.e. green) sources. For logistic or economic reasons, however, EV drivers may be tempted to avoid charging stations certified as providing green energy, instead opting for conventional ones, where only a fraction of the available energy is green. This behaviour may slow down the achievement of decarbonisation targets of the road transport sector. In this paper, we use GPS data to infer whether an undeclared charging event has occurred. Specifically, we construct a Bayesian hypothesis test for the charging behaviour of the EV. Extensive simulations are carried out for an area of London, using the mobility simulator, SUMO, and exploring various operating conditions. Excellent detection rates for undeclared charging events are reported. We explain how the algorithm can serve as the basis for an incentivization scheme, encouraging compliance by drivers with green charging policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18971v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca Domenico Loiacono, Anthony Quinn, Emanuele Crisostomi, Robert Shorten</dc:creator>
    </item>
    <item>
      <title>A preconditioned second-order convex splitting algorithm with a difference of varying convex functions and line search</title>
      <link>https://arxiv.org/abs/2411.07661</link>
      <description>arXiv:2411.07661v2 Announce Type: replace 
Abstract: This paper introduces a preconditioned convex splitting algorithm enhanced with line search techniques for nonconvex optimization problems. The algorithm utilizes second-order backward differentiation formulas (BDF) for the implicit and linear components and the Adams-Bashforth scheme for the nonlinear and explicit parts of the gradient flow in variational functions. The proposed algorithm, resembling a generalized difference-of-convex-function approach, involves a changing set of convex functions in each iteration. It integrates the Armijo line search strategy to improve performance. The study also discusses classical preconditioners such as symmetric Gauss-Seidel, Jacobi, and Richardson within this context. The global convergence of the algorithm is established through the Kurdyka-{\L}ojasiewicz properties, ensuring convergence within a finite number of preconditioned iterations. Numerical experiments demonstrate the superiority of the proposed second-order convex splitting with line search over conventional difference-of-convex-function algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07661v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinhua Shen, Zaijiu Shang, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>Barriers for recent methods in geodesic optimization</title>
      <link>https://arxiv.org/abs/2102.06652</link>
      <description>arXiv:2102.06652v3 Announce Type: replace-cross 
Abstract: We study a class of optimization problems including matrix scaling, matrix balancing, multidimensional array scaling, operator scaling, and tensor scaling that arise frequently in theory and in practice. Some of these problems, such as matrix and array scaling, are convex in the Euclidean sense, but others such as operator scaling and tensor scaling are geodesically convex on a different Riemannian manifold. Trust region methods, which include box-constrained Newton's method, are known to produce high precision solutions very quickly for matrix scaling and matrix balancing (Cohen et. al., FOCS 2017, Allen-Zhu et. al. FOCS 2017), and result in polynomial time algorithms for some geodesically convex problems like operator scaling (Garg et. al. STOC 2018, B\"urgisser et. al. FOCS 2019). One is led to ask whether these guarantees also hold for multidimensional array scaling and tensor scaling.
  We show that this is not the case by exhibiting instances with exponential diameter bound: we construct polynomial-size instances of 3-dimensional array scaling and 3-tensor scaling whose approximate solutions all have doubly exponential condition number. Moreover, we study convex-geometric notions of complexity known as margin and gap, which are used to bound the running times of all existing optimization algorithms for such problems. We show that margin and gap are exponentially small for several problems including array scaling, tensor scaling and polynomial scaling. Our results suggest that it is impossible to prove polynomial running time bounds for tensor scaling based on diameter bounds alone. Therefore, our work motivates the search for analogues of more sophisticated algorithms, such as interior point methods, for geodesically convex optimization that do not rely on polynomial diameter bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.06652v3</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.CCC.2021.13</arxiv:DOI>
      <dc:creator>Cole Franks, Philipp Reichenbach</dc:creator>
    </item>
    <item>
      <title>Asymptotics of Proximity Operator for Squared Loss and Performance Prediction of Nonconvex Sparse Signal Recovery</title>
      <link>https://arxiv.org/abs/2103.10300</link>
      <description>arXiv:2103.10300v3 Announce Type: replace-cross 
Abstract: Proximal splitting-based convex optimization is a promising approach to linear inverse problems because we can use some prior knowledge of the unknown variables explicitly. An understanding of the behavior of the optimization algorithms would be important for the tuning of the parameters and the development of new algorithms. In this paper, we first analyze the asymptotic property of the proximity operator for the squared loss function, which appears in the update equations of some proximal splitting methods for linear inverse problems. Our analysis shows that the output of the proximity operator can be characterized with a scalar random variable in the large system limit. Moreover, we apply the asymptotic result to the prediction of optimization algorithms for compressed sensing. Simulation results demonstrate that the MSE performance of the Douglas-Rachford algorithm can be well predicted in compressed sensing with the $\ell_{1}$ optimization. We also examine the behavior of the prediction for the case with nonconvex smoothly clipped absolute deviation (SCAD) regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.10300v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryo Hayakawa</dc:creator>
    </item>
    <item>
      <title>Smooth Non-Stationary Bandits</title>
      <link>https://arxiv.org/abs/2301.12366</link>
      <description>arXiv:2301.12366v3 Announce Type: replace-cross 
Abstract: In many applications of online decision making, the environment is non-stationary and it is therefore crucial to use bandit algorithms that handle changes. Most existing approaches are designed to protect against non-smooth changes, constrained only by total variation or Lipschitzness over time. However, in practice, environments often change {\em smoothly}, so such algorithms may incur higher-than-necessary regret. We study a non-stationary bandits problem where each arm's mean reward sequence can be embedded into a $\beta$-H\"older function, i.e., a function that is $(\beta-1)$-times Lipschitz-continuously differentiable. The non-stationarity becomes more smooth as $\beta$ increases. When $\beta=1$, this corresponds to the non-smooth regime, where \cite{besbes2014stochastic} established a minimax regret of $\tilde \Theta(T^{2/3})$. We show the first separation between the smooth (i.e., $\beta\ge 2$) and non-smooth (i.e., $\beta=1$) regimes by presenting a policy with $\tilde O(k^{4/5} T^{3/5})$ regret on any $k$-armed, $2$-H\"older instance. We complement this result by showing that the minimax regret on the $\beta$-H\"older family of instances is $\Omega(T^{(\beta+1)/(2\beta+1)})$ for any integer $\beta\ge 1$. This matches our upper bound for $\beta=2$ up to logarithmic factors. Furthermore, we validated the effectiveness of our policy through a comprehensive numerical study using real-world click-through rate data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12366v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Su Jia, Qian Xie, Nathan Kallus, Peter I. Frazier</dc:creator>
    </item>
    <item>
      <title>Stochastic Nonlinear Control via Finite-dimensional Spectral Dynamic Embedding</title>
      <link>https://arxiv.org/abs/2304.03907</link>
      <description>arXiv:2304.03907v4 Announce Type: replace-cross 
Abstract: This paper presents an approach, Spectral Dynamics Embedding Control (SDEC), to optimal control for nonlinear stochastic systems. This method leverages an infinite-dimensional feature to linearly represent the state-action value function and exploits finite-dimensional truncation approximation for practical implementation. To characterize the effectiveness of these finite dimensional approximations, we provide an in-depth theoretical analysis to characterize the approximation error induced by the finite-dimension truncation and statistical error induced by finite-sample approximation in both policy evaluation and policy optimization. Our analysis includes two prominent kernel approximation methods: truncations onto random features and Nystrom features. We also empirically test the algorithm and compare the performance with Koopman-based, iLQR, and energy-based methods on a few benchmark problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03907v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Ren, Tongzheng Ren, Haitong Ma, Na Li, Bo Dai</dc:creator>
    </item>
    <item>
      <title>Flexibility of Integrated Power and Gas Systems: Gas Flow Modeling and Solution Choices Matter</title>
      <link>https://arxiv.org/abs/2311.05744</link>
      <description>arXiv:2311.05744v2 Announce Type: replace-cross 
Abstract: Due to their slow gas flow dynamics, natural gas pipelines function as short-term storage, the so-called linepack. By efficiently utilizing linepack, the natural gas system can provide flexibility to the power system through the flexible operation of gas-fired power plants. This requires accurately representing the gas flow physics governed by partial differential equations. Although several modeling and solution choices have been proposed in the literature, their impact on the flexibility provision of gas networks to power systems has not been thoroughly analyzed and compared. This paper bridges this gap by first developing a unified framework. We harmonize existing approaches and demonstrate their derivation from and application to the partial differential equations. Secondly, based on the proposed framework, we numerically analyze the implications of various modeling and solution choices on the flexibility provision from gas networks to power systems. One key conclusion is that relaxation-based approaches allow charging and discharging the linepack at physically infeasible high rates, ultimately overestimating the flexibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05744v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enrica Raheli, Yannick Werner, Jalal Kazempour</dc:creator>
    </item>
    <item>
      <title>Challenges and Opportunities in Quantum Optimization</title>
      <link>https://arxiv.org/abs/2312.02279</link>
      <description>arXiv:2312.02279v3 Announce Type: replace-cross 
Abstract: Recent advances in quantum computers are demonstrating the ability to solve problems at a scale beyond brute force classical simulation. As such, a widespread interest in quantum algorithms has developed in many areas, with optimization being one of the most pronounced domains. Across computer science and physics, there are a number of different approaches for major classes of optimization problems, such as combinatorial optimization, convex optimization, non-convex optimization, and stochastic extensions. This work draws on multiple approaches to study quantum optimization. Provably exact versus heuristic settings are first explained using computational complexity theory - highlighting where quantum advantage is possible in each context. Then, the core building blocks for quantum optimization algorithms are outlined to subsequently define prominent problem classes and identify key open questions that, if answered, will advance the field. The effects of scaling relevant problems on noisy quantum devices are also outlined in detail, alongside meaningful benchmarking problems. We underscore the importance of benchmarking by proposing clear metrics to conduct appropriate comparisons with classical optimization techniques. Lastly, we highlight two domains - finance and sustainability - as rich sources of optimization problems that could be used to benchmark, and eventually validate, the potential real-world impact of quantum optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02279v3</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s42254-024-00770-9</arxiv:DOI>
      <arxiv:journal_reference>Nat Rev Phys (2024)</arxiv:journal_reference>
      <dc:creator>Amira Abbas, Andris Ambainis, Brandon Augustino, Andreas B\"artschi, Harry Buhrman, Carleton Coffrin, Giorgio Cortiana, Vedran Dunjko, Daniel J. Egger, Bruce G. Elmegreen, Nicola Franco, Filippo Fratini, Bryce Fuller, Julien Gacon, Constantin Gonciulea, Sander Gribling, Swati Gupta, Stuart Hadfield, Raoul Heese, Gerhard Kircher, Thomas Kleinert, Thorsten Koch, Georgios Korpas, Steve Lenk, Jakub Marecek, Vanio Markov, Guglielmo Mazzola, Stefano Mensa, Naeimeh Mohseni, Giacomo Nannicini, Corey O'Meara, Elena Pe\~na Tapia, Sebastian Pokutta, Manuel Proissl, Patrick Rebentrost, Emre Sahin, Benjamin C. B. Symons, Sabine Tornow, Victor Valls, Stefan Woerner, Mira L. Wolf-Bauwens, Jon Yard, Sheir Yarkoni, Dirk Zechiel, Sergiy Zhuk, Christa Zoufal</dc:creator>
    </item>
    <item>
      <title>The Implicit Bias of Heterogeneity towards Invariance: A Study of Multi-Environment Matrix Sensing</title>
      <link>https://arxiv.org/abs/2403.01420</link>
      <description>arXiv:2403.01420v3 Announce Type: replace-cross 
Abstract: Models are expected to engage in invariance learning, which involves distinguishing the core relations that remain consistent across varying environments to ensure the predictions are safe, robust and fair. While existing works consider specific algorithms to realize invariance learning, we show that model has the potential to learn invariance through standard training procedures. In other words, this paper studies the implicit bias of Stochastic Gradient Descent (SGD) over heterogeneous data and shows that the implicit bias drives the model learning towards an invariant solution. We call the phenomenon the implicit invariance learning. Specifically, we theoretically investigate the multi-environment low-rank matrix sensing problem where in each environment, the signal comprises (i) a lower-rank invariant part shared across all environments; and (ii) a significantly varying environment-dependent spurious component. The key insight is, through simply employing the large step size large-batch SGD sequentially in each environment without any explicit regularization, the oscillation caused by heterogeneity can provably prevent model learning spurious signals. The model reaches the invariant solution after certain iterations. In contrast, model learned using pooled SGD over all data would simultaneously learn both the invariant and spurious signals. Overall, we unveil another implicit bias that is a result of the symbiosis between the heterogeneity of data and modern algorithms, which is, to the best of our knowledge, first in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01420v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Xu, Yihong Gu, Cong Fang</dc:creator>
    </item>
    <item>
      <title>On solution of tropical discrete best approximation problems</title>
      <link>https://arxiv.org/abs/2403.16337</link>
      <description>arXiv:2403.16337v3 Announce Type: replace-cross 
Abstract: We consider a discrete best approximation problem formulated in the framework of tropical algebra, which deals with the theory and applications of algebraic systems with idempotent operations. Given a set of samples of input and output of an unknown function, the problem is to construct a generalized tropical Puiseux polynomial that best approximates the function in the sense of a tropical distance function. The construction of an approximate polynomial involves the evaluation of both unknown coefficient and exponent of each monomial in the polynomial. To solve the approximation problem, we first reduce the problem to an equation in unknown vector of coefficients, which is given by a matrix with entries parameterized by unknown exponents. We derive a best approximate solution of the equation, which yields both vector of coefficients and approximation error parameterized by the exponents. Optimal values of exponents are found by minimization of the approximation error, which is transformed into minimization of a function of exponents over all partitions of a finite set. We solve this minimization problem in terms of max-plus algebra (where addition is defined as maximum and multiplication as arithmetic addition) by using a computational procedure based on the agglomerative clustering technique. This solution is extended to the minimization problem of finding optimal exponents in the polynomial in terms of max-algebra (where addition is defined as maximum). The results obtained are applied to develop new solutions for conventional problems of discrete best Chebyshev approximation of real functions by piecewise linear functions and piecewise Puiseux polynomials. We discuss computational complexity of the proposed solution and estimate upper bounds on the computational time. We demonstrate examples of approximation problems solved in terms of max-plus and max-algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16337v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00500-024-09940-4</arxiv:DOI>
      <arxiv:journal_reference>Soft Comput. 2024. Vol.28, N20. P.12097-12112</arxiv:journal_reference>
      <dc:creator>Nikolai Krivulin</dc:creator>
    </item>
    <item>
      <title>Fair Generalized Linear Mixed Models</title>
      <link>https://arxiv.org/abs/2405.09273</link>
      <description>arXiv:2405.09273v5 Announce Type: replace-cross 
Abstract: When using machine learning for automated prediction, it is important to account for fairness in the prediction. Fairness in machine learning aims to ensure that biases in the data and model inaccuracies do not lead to discriminatory decisions. E.g., predictions from fair machine learning models should not discriminate against sensitive variables such as sexual orientation and ethnicity. The training data often in obtained from social surveys. In social surveys, oftentimes the data collection process is a strata sampling, e.g. due to cost restrictions. In strata samples, the assumption of independence between the observation is not fulfilled. Hence, if the machine learning models do not account for the strata correlations, the results may be biased. Especially high is the bias in cases where the strata assignment is correlated to the variable of interest. We present in this paper an algorithm that can handle both problems simultaneously, and we demonstrate the impact of stratified sampling on the quality of fair machine learning predictions in a reproducible simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09273v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Pablo Burgard, Jo\~ao Vitor Pamplona</dc:creator>
    </item>
    <item>
      <title>4+3 Phases of Compute-Optimal Neural Scaling Laws</title>
      <link>https://arxiv.org/abs/2405.15074</link>
      <description>arXiv:2405.15074v2 Announce Type: replace-cross 
Abstract: We consider the solvable neural scaling model with three parameters: data complexity, target complexity, and model-parameter-count. We use this neural scaling model to derive new predictions about the compute-limited, infinite-data scaling law regime. To train the neural scaling model, we run one-pass stochastic gradient descent on a mean-squared loss. We derive a representation of the loss curves which holds over all iteration counts and improves in accuracy as the model parameter count grows. We then analyze the compute-optimal model-parameter-count, and identify 4 phases (+3 subphases) in the data-complexity/target-complexity phase-plane. The phase boundaries are determined by the relative importance of model capacity, optimizer noise, and embedding of the features. We furthermore derive, with mathematical proof and extensive numerical evidence, the scaling-law exponents in all of these phases, in particular computing the optimal model-parameter-count as a function of floating point operation budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15074v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elliot Paquette, Courtney Paquette, Lechao Xiao, Jeffrey Pennington</dc:creator>
    </item>
    <item>
      <title>Sub-Riemannian geodesics on the Heisenberg 3D nil-manifold</title>
      <link>https://arxiv.org/abs/2406.16065</link>
      <description>arXiv:2406.16065v3 Announce Type: replace-cross 
Abstract: We study the projection of the left-invariant sub-Riemannian structure on the 3D Heisenberg group $G$ to the Heisenberg 3D nil-manifold $M$ -- the compact homogeneous space of $G$ by the discrete Heisenberg group.
  First we describe dynamical properties of the geodesic flow for $M$: periodic and dense orbits, and a dynamical characterization of the normal Hamiltonian flow of Pontryagin maximum principle. Then we obtain sharp twoside bounds of sub-Riemannian balls and distance in $G$, and on this basis we estimate the cut time for sub-Riemannian geodesics in $M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16065v3</guid>
      <category>math.DG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Glutsyuk, Yu. Sachkov</dc:creator>
    </item>
    <item>
      <title>Bayesian inverse Navier-Stokes problems: joint flow field reconstruction and parameter learning</title>
      <link>https://arxiv.org/abs/2406.18464</link>
      <description>arXiv:2406.18464v2 Announce Type: replace-cross 
Abstract: We formulate and solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilates velocimetry data in order to jointly reconstruct a 3D flow field and learn the unknown N-S parameters, including the boundary position. By hardwiring a generalised N-S problem, and regularising its unknown parameters using Gaussian prior distributions, we learn the most likely parameters in a collapsed search space. The most likely flow field reconstruction is then the N-S solution that corresponds to the learned parameters. We develop the method in the variational setting and use a stabilised Nitsche weak form of the N-S problem that permits the control of all N-S parameters. To regularise the inferred the geometry, we use a viscous signed distance field (vSDF) as an auxiliary variable, which is given as the solution of a viscous Eikonal boundary value problem. We devise an algorithm that solves this inverse problem, and numerically implement it using an adjoint-consistent stabilised cut-cell finite element method. We then use this method to reconstruct magnetic resonance velocimetry (flow-MRI) data of a 3D steady laminar flow through a physical model of an aortic arch for two different Reynolds numbers and signal-to-noise ratio (SNR) levels (low/high). We find that the method can accurately i) reconstruct the low SNR data by filtering out the noise/artefacts and recovering flow features that are obscured by noise, and ii) reproduce the high SNR data without overfitting. Although the framework that we develop applies to 3D steady laminar flows in complex geometries, it readily extends to time-dependent laminar and Reynolds-averaged turbulent flows, as well as non-Newtonian (e.g. viscoelastic) fluids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18464v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandros Kontogiannis, Scott V. Elgersma, Andrew J. Sederman, Matthew P. Juniper</dc:creator>
    </item>
    <item>
      <title>Optimal decentralized wavelength control in light sources for lithography</title>
      <link>https://arxiv.org/abs/2409.04721</link>
      <description>arXiv:2409.04721v2 Announce Type: replace-cross 
Abstract: Pulsed light sources are a critical component of modern lithography, with fine light beam wavelength control paramount for wafer etching accuracy. We study optimal wavelength control by casting it as a decentralized linear quadratic Gaussian (LQG) problem in presence of time-delays. In particular, we consider the multi-optics module (optics and actuators) used for generating the requisite wavelength in light sources as cooperatively interacting systems defined over a directed acyclic graph (DAG). We show that any measurement and other continuous time-delays can be exactly compensated, and the resulting optimal controller implementation at the individual optics-level outperforms any existing wavelength control techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04721v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mruganka Kashyap</dc:creator>
    </item>
    <item>
      <title>Confronting Project Conflicts into Success: a Complex Systems Design Approach to Resolving Stalemates</title>
      <link>https://arxiv.org/abs/2409.10549</link>
      <description>arXiv:2409.10549v2 Announce Type: replace-cross 
Abstract: In today's complex projects development, stakeholders are often involved too late. There is also in many cases a one-sided technical focus that only focuses on the system's behaviour and does not integrate the individual stakeholder preferences. This locks stakeholders into a 'technical' conflict instead of being able to emerge from it 'socially'. Moreover, stakeholders are often involved a-posteriori in a multi-faceted development process which is untransparent, leading to stalemates or even artefacts that nobody ever wants. There is thus a need for a purely associative and a-priori design-supported approach that integrates both system's reality and stakeholder's interests within a joint agreement and technical framework. The state-of-the-art Preferendus, the computer-aided design engine embedded within the proven Open Design Systems (Odesys) methodology, is a neutral tool in confronting complexity into success. The Preferendus is deployed to co-creatively generate a best-fit-for-common-purpose solution for a number of wind farm related degrees of freedom, project constraints and given a number of stakeholder objective functions. Since, the Preferendus design potential for a stalemate depends strongly on stakeholder interest, importance and trust, in this paper an structured stakeholder judgement approach is introduced to transparently arrive at individual stakeholder weights using a choice-based conjoint analysis (CBCA) method. This method also allows for obtaining an initial estimate for the individual stakeholder preference functions. By modelling disputable exogenous factors as endogenous design parameters, it is also shown for which factors the stalemate problem is indeed both technically and socially (un)solvable, while interests and reality are conjoined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10549v2</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L. G. Teuber, A. R. M. Wolfert</dc:creator>
    </item>
    <item>
      <title>Optimal Denial-of-Service Attacks Against Partially-Observable Real-Time Monitoring Systems</title>
      <link>https://arxiv.org/abs/2409.16794</link>
      <description>arXiv:2409.16794v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate the impact of denial-of-service attacks on the status updating of a cyber-physical system with one or more sensors connected to a remote monitor via unreliable channels. We approach the problem from the perspective of an adversary that can strategically jam a subset of the channels. The sources are modeled as Markov chains, and the performance of status updating is measured based on the age of incorrect information at the monitor. Our objective is to derive jamming policies that strike a balance between the degradation of the system's performance and the conservation of the adversary's energy. For a single-source scenario, we formulate the problem as a partially-observable Markov decision process, and rigorously prove that the optimal jamming policy is of a threshold form. We then extend the problem to a multi-source scenario. We formulate this problem as a restless multi-armed bandit, and provide a jamming policy based on the Whittle's index. Our numerical results highlight the performance of our policies compared to baseline policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16794v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saad Kriouile, Mohamad Assaad, Amira Alloum, Touraj Soleymani</dc:creator>
    </item>
    <item>
      <title>X-arability of mixed quantum states</title>
      <link>https://arxiv.org/abs/2409.18948</link>
      <description>arXiv:2409.18948v2 Announce Type: replace-cross 
Abstract: The problem of determining when entanglement is present in a quantum system is one of the most active areas of research in quantum physics. Depending on the setting at hand, different notions of entanglement (or lack thereof) become relevant. Examples include separability (of bosons, fermions, and distinguishable particles), Schmidt number, biseparability, entanglement depth, and bond dimension. In this work, we propose and study a unified notion of separability, which we call X-arability, that captures a wide range of applications including these. For a subset (more specifically, an algebraic variety) of pure states X, we say that a mixed quantum state is X-arable if it lies in the convex hull of X. We develop unified tools and provable guarantees for X-arability, which already give new results for the standard separability problem. Our results include:
  -- An X-tensions hierarchy of semidefinite programs for X-arability (generalizing the symmetric extensions hierarchy for separability), and a new de Finetti theorem for fermionic separability.
  -- A hierarchy of eigencomputations for optimizing a Hermitian operator over X, with applications to X-tanglement witnesses and polynomial optimization.
  -- A hierarchy of linear systems for the X-tangled subspace problem, with improved polynomial time guarantees even for the standard entangled subspace problem, in both the generic and worst case settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18948v2</guid>
      <category>quant-ph</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harm Derksen, Nathaniel Johnston, Benjamin Lovitz</dc:creator>
    </item>
    <item>
      <title>Scalable spectral representations for multi-agent reinforcement learning in network MDPs</title>
      <link>https://arxiv.org/abs/2410.17221</link>
      <description>arXiv:2410.17221v2 Announce Type: replace-cross 
Abstract: Network Markov Decision Processes (MDPs), a popular model for multi-agent control, pose a significant challenge to efficient learning due to the exponential growth of the global state-action space with the number of agents. In this work, utilizing the exponential decay property of network dynamics, we first derive scalable spectral local representations for network MDPs, which induces a network linear subspace for the local $Q$-function of each agent. Building on these local spectral representations, we design a scalable algorithmic framework for continuous state-action network MDPs, and provide end-to-end guarantees for the convergence of our algorithm. Empirically, we validate the effectiveness of our scalable representation-based approach on two benchmark problems, and demonstrate the advantages of our approach over generic function approximation approaches to representing the local $Q$-functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17221v2</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Ren, Runyu Zhang, Bo Dai, Na Li</dc:creator>
    </item>
    <item>
      <title>Loss Aversion and State-Dependent Linear Utility Functions for Monetary Returns</title>
      <link>https://arxiv.org/abs/2410.19030</link>
      <description>arXiv:2410.19030v3 Announce Type: replace-cross 
Abstract: We present a theory of expected utility with state-dependent linear utility functions for monetary returns, that incorporates the possibility of loss-aversion. Our results relate to first order stochastic dominance, mean-preserving spread, increasing-concave linear utility profiles and risk aversion. As an application of the expected utility theory developed here, we analyze the contract that a monopolist would offer in an insurance market that allowed for partial coverage of loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19030v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>General monotonicity</title>
      <link>https://arxiv.org/abs/2411.04212</link>
      <description>arXiv:2411.04212v2 Announce Type: replace-cross 
Abstract: This article employs techniques from convex analysis to present characterizations of (maximal) $n-$monotonicity, similar to the well-established characterizations of (maximal) monotonicity found in the existing literature. These characterizations are further illustrated through examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04212v2</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>M. D. Voisei</dc:creator>
    </item>
    <item>
      <title>Degree Matrix Comparison for Graph Alignment</title>
      <link>https://arxiv.org/abs/2411.07475</link>
      <description>arXiv:2411.07475v2 Announce Type: replace-cross 
Abstract: Graph alignment considers the optimal node correspondence across networks. To advance unsupervised graph alignment algorithms on plain graphs, we propose Degree Matrix Comparison (DMC). Through extensive experiments and mathematical motivations, we demonstrate the potential of this method. Remarkably, DMC achieves up to 99% correct node alignment for 90%-overlap graphs and 100% accuracy for isomorphic graphs. Additionally, we propose a reduced version of DMC (Greedy DMC) that provides a solution to the graph alignment problem with lower time complexity. DMC could significantly impact graph alignment, offering a reliable solution for the task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07475v2</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Wang, Peter Chin</dc:creator>
    </item>
  </channel>
</rss>
