<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2024 04:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Subjective Equilibria under Beliefs of Exogenous Uncertainty: Linear Quadratic Case</title>
      <link>https://arxiv.org/abs/2404.10920</link>
      <description>arXiv:2404.10920v1 Announce Type: new 
Abstract: We consider a stochastic dynamic game where players have their own linear state dynamics and quadratic cost functions. Players are coupled through some environment variables, generated by another linear system driven by the states and decisions of all players. Each player observes his own states realized up to the current time as well as the past realizations of his own decisions and the environment variables. Each player (incorrectly) believes that the environment variables are generated by an independent exogenous stochastic process. In this setup, we study the notion of ``subjective equilibrium under beliefs of exogenous uncertainty (SEBEU)'' introduced in our recent work arXiv:2005.01640. At an SEBEU, each player's strategy is optimal with respect to his subjective belief; moreover, the objective probability distribution of the environment variables is consistent with players' subjective beliefs. We construct an SEBEU in pure strategies, where each player strategy is an affine function of his own state and his estimate of the system state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10920v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>G\"urdal Arslan, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>A preconditioner for solving linear programming problems with dense columns</title>
      <link>https://arxiv.org/abs/2404.10930</link>
      <description>arXiv:2404.10930v1 Announce Type: new 
Abstract: The Interior-Point Methods are a class for solving linear programming problems that rely upon the solution of linear systems. At each iteration, it becomes important to determine how to solve these linear systems when the constraint matrix of the linear programming problem includes dense columns. In this paper, we propose a preconditioner to handle linear programming problems with dense columns, and we prove theoretically that the final linear system to solve is uniformly bounded when the Interior-Point Method is converging to an optimal solution. This result is illustrated through computational experiments, which show that our proposed method is robust and competitive in terms of running time and/or number of iterations compared with existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10930v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Catalina J. Villalba, Aurelio R. L. Oliveira</dc:creator>
    </item>
    <item>
      <title>A Relative Inexact Proximal Gradient Method With an Explicit Linesearch</title>
      <link>https://arxiv.org/abs/2404.10987</link>
      <description>arXiv:2404.10987v1 Announce Type: new 
Abstract: This paper presents and investigates an inexact proximal gradient method for solving composite convex optimization problems characterized by an objective function composed of a sum of a full domain differentiable convex function and a non-differentiable convex function. We introduce an explicit linesearch strategy that requires only a relative inexact solution of the proximal subproblem per iteration. We prove the convergence of the sequence generated by our scheme and establish its iteration complexity, considering both the functional values and a residual associated with first-order stationary solutions. Additionally, we provide numerical experiments to illustrate the practical efficacy of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10987v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunier Bello-Cruz, Max L. N. Gon\c{c}alves, Jefferson G. Melo, Cassandra Mohr</dc:creator>
    </item>
    <item>
      <title>A Proximal Gradient Method with an Explicit Line search for Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2404.10993</link>
      <description>arXiv:2404.10993v1 Announce Type: new 
Abstract: We present a proximal gradient method for solving convex multiobjective optimization problems, where each objective function is the sum of two convex functions, with one assumed to be continuously differentiable. The algorithm incorporates a backtracking line search procedure that requires solving only one proximal subproblem per iteration, and is exclusively applied to the differentiable part of the objective functions. Under mild assumptions, we show that the sequence generated by the method convergences to a weakly Pareto optimal point of the problem. Additionally, we establish an iteration complexity bound by showing that the method finds an $\varepsilon$-approximate weakly Pareto point in at most ${\cal O}(1/\varepsilon)$ iterations. Numerical experiments illustrating the practical behavior of the method is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10993v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunier Bello-Cruz, J. G. Melo, L. F. Prudente, R. V. G. Serra</dc:creator>
    </item>
    <item>
      <title>Clipped SGD Algorithms for Privacy Preserving Performative Prediction: Bias Amplification and Remedies</title>
      <link>https://arxiv.org/abs/2404.10995</link>
      <description>arXiv:2404.10995v1 Announce Type: new 
Abstract: Clipped stochastic gradient descent (SGD) algorithms are among the most popular algorithms for privacy preserving optimization that reduces the leakage of users' identity in model training. This paper studies the convergence properties of these algorithms in a performative prediction setting, where the data distribution may shift due to the deployed prediction model. For example, the latter is caused by strategical users during the training of loan policy for banks. Our contributions are two-fold. First, we show that the straightforward implementation of a projected clipped SGD (PCSGD) algorithm may converge to a biased solution compared to the performative stable solution. We quantify the lower and upper bound for the magnitude of the bias and demonstrate a bias amplification phenomenon where the bias grows with the sensitivity of the data distribution. Second, we suggest two remedies to the bias amplification effect. The first one utilizes an optimal step size design for PCSGD that takes the privacy guarantee into account. The second one uses the recently proposed DiceSGD algorithm [Zhang et al., 2024]. We show that the latter can successfully remove the bias and converge to the performative stable solution. Numerical experiments verify our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10995v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Michal Yemini, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>An Adaptive Regularized Proximal Newton-Type Methods for Composite Optimization over the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2404.11112</link>
      <description>arXiv:2404.11112v1 Announce Type: new 
Abstract: Recently, the proximal Newton-type method and its variants have been generalized to solve composite optimization problems over the Stiefel manifold whose objective function is the summation of a smooth function and a nonsmooth function. In this paper, we propose an adaptive quadratically regularized proximal quasi-Newton method, named ARPQN, to solve this class of problems. Under some mild assumptions, the global convergence, the local linear convergence rate and the iteration complexity of ARPQN are established. Numerical experiments and comparisons with other state-of-the-art methods indicate that ARPQN is very promising. We also propose an adaptive quadratically regularized proximal Newton method, named ARPN. It is shown the ARPN method has a local superlinear convergence rate under certain reasonable assumptions, which demonstrates attractive convergence properties of regularized proximal Newton methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11112v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinsi Wang, Wei Hong Yang</dc:creator>
    </item>
    <item>
      <title>Approximability of the Containment Problem for Zonotopes and Ellipsotopes</title>
      <link>https://arxiv.org/abs/2404.11185</link>
      <description>arXiv:2404.11185v1 Announce Type: new 
Abstract: The zonotope containment problem, i.e., whether one zonotope is contained in another, is a central problem in control theory to compute invariant sets, obtain fixed points of reachable sets, detect faults, and robustify controllers. Despite the inherent co-NP-hardness of this problem, an approximation algorithm developed by S. Sadraddini and R. Tedrake has gained widespread recognition for its swift execution and consistent reliability in practical scenarios. In our study, we substantiate the precision of the algorithm with a definitive proof, elucidating the empirical accuracy observed in practice. Our proof hinges on establishing a connection between the containment problem and the computation of matrix norms, thereby enabling the extension of the approximation algorithm to encompass ellipsotopes, a broader class of sets derived from zonotopes. Moreover, we explore the computational complexity of the ellipsotope containment problem, focusing on approximability. Finally, we present new methods to calculate robust control invariant sets for linear dynamical systems, demonstrating the practical relevance of approximations to the ellipsotope containment problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11185v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Kulmburg, Lukas Sch\"afer, Matthias Althoff</dc:creator>
    </item>
    <item>
      <title>Simultaneous compensation of input delay and state/input quantization for linear systems via switched predictor feedback</title>
      <link>https://arxiv.org/abs/2404.11194</link>
      <description>arXiv:2404.11194v1 Announce Type: new 
Abstract: We develop a switched predictor-feedback law, which achieves global asymptotic stabilization of linear systems with input delay and with the plant and actuator states available only in (almost) quantized form. The control design relies on a quantized version of the nominal predictor-feedback law for linear systems, in which quantized measurements of the plant and actuator states enter the predictor state formula. A switching strategy is constructed to dynamically adjust the tunable parameter of the quantizer (in a piecewise constant manner), in order to initially increase the range and subsequently decrease the error of the quantizers. The key element in the proof of global asymptotic stability in the supremum norm of the actuator state is derivation of solutions' estimates combining a backstepping transformation with small-gain and input-to-state stability arguments, for addressing the error due to quantization. We extend this result to the input quantization case and illustrate our theory with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11194v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florent Koudohode, Nikolaos Bekiaris-Liberis</dc:creator>
    </item>
    <item>
      <title>Distributed Fractional Bayesian Learning for Adaptive Optimization</title>
      <link>https://arxiv.org/abs/2404.11354</link>
      <description>arXiv:2404.11354v1 Announce Type: new 
Abstract: This paper considers a distributed adaptive optimization problem, where all agents only have access to their local cost functions with a common unknown parameter, whereas they mean to collaboratively estimate the true parameter and find the optimal solution over a connected network. A general mathematical framework for such a problem has not been studied yet. We aim to provide valuable insights for addressing parameter uncertainty in distributed optimization problems and simultaneously find the optimal solution. Thus, we propose a novel Prediction while Optimization scheme, which utilizes distributed fractional Bayesian learning through weighted averaging on the log-beliefs to update the beliefs of unknown parameters, and distributed gradient descent for renewing the estimation of the optimal solution. Then under suitable assumptions, we prove that all agents' beliefs and decision variables converge almost surely to the true parameter and the optimal solution under the true parameter, respectively. We further establish a sublinear convergence rate for the belief sequence. Finally, numerical experiments are implemented to corroborate the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11354v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaqun Yang, Jinlong Lei, Guanghui Wen, Yiguang Hong</dc:creator>
    </item>
    <item>
      <title>A New Algorithm With Lower Complexity for Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2404.11377</link>
      <description>arXiv:2404.11377v1 Announce Type: new 
Abstract: Many stochastic algorithms have been proposed to solve the bilevel optimization problem, where the lower level function is strongly convex and the upper level value function is nonconvex. In particular, exising Hessian inverse-free algorithms that utilize momentum recursion or variance reduction technqiues can reach an $\epsilon$-stationary point with a complexity of $\tilde{O}(\epsilon^{-1.5})$ under usual smoothness conditions. However, $\tilde{O}(\epsilon^{-1.5})$ is a complexity higher than $O(\epsilon^{-1.5})$. How to make a Hessian inverse-free algorithm achieve the complexity of $O(\epsilon^{-1.5})$ under usual smoothness conditions remains an unresolved problem. In this paper, we propose a new Hessian inverse-free algorithm based on the projected stochastic gradient descent method and variance reduction technique of SPIDER. This algorithm can achieve a complexity of $O(\epsilon^{-1.5})$ under usual smoothness conditions whether it runs in a fully single loop or double loop structure. Finally, we validate our theoretical results through synthetic experiments and demonstrate the efficiency of our algorithm in some machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11377v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haimei Huo, Zhixun Su</dc:creator>
    </item>
    <item>
      <title>Convergence of Policy Gradient for Stochastic Linear-Quadratic Control Problem in Infinite Horizon</title>
      <link>https://arxiv.org/abs/2404.11382</link>
      <description>arXiv:2404.11382v1 Announce Type: new 
Abstract: With the outstanding performance of policy gradient (PG) method in the reinforcement learning field, the convergence theory of it has aroused more and more interest recently. Meanwhile, the significant importance and abundant theoretical researches make the stochastic linear quadratic (SLQ) control problem a starting point for studying PG in model-based learning setting. In this paper, we study the PG method for the SLQ problem in infinite horizon and take a step towards providing rigorous guarantees for gradient methods. Although the cost functional of linear-quadratic problem is typically nonconvex, we still overcome the difficulty based on gradient domination condition and L-smoothness property, and prove exponential/linear convergence of gradient flow/descent algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11382v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinpei Zhang, Guangyan Jia</dc:creator>
    </item>
    <item>
      <title>Multi-layer continuous carbon fiber pattern optimization and a spline based path planning interpretation</title>
      <link>https://arxiv.org/abs/2404.11404</link>
      <description>arXiv:2404.11404v1 Announce Type: new 
Abstract: A novel approach for creating tool paths for continuous carbon fiber-reinforced thermoplastic 3D printing is introduced. The aim is to enable load-bearing connections while avoiding non-manufacturable crossings of paths by generating layer specific patterns. We require a graph representation of the structural design with given desired continuous fiber connections. From this, optimal fiber patterns are obtained for each printing layer by solving linear integer optimization problems. Each layer may have a unique solution based on the history of the previous layers. Additionally, a path planning approach is presented which interprets the obtained layers via curves based on quadratic and cubic B\'ezier splines and their offset curves in constant distance. The single parameter for the construction of the paths is the minimal turning radius of the fibers. The path planning provides a new interpretation for the final geometry of the design to be printed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11404v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fabian Wein, Julian Mirbach, Aniket Angre, Jannis Greifenstein, Daniel H\"ubner</dc:creator>
    </item>
    <item>
      <title>An adaptive linearized alternating direction multiplier method for solving convex optimization problems</title>
      <link>https://arxiv.org/abs/2404.11435</link>
      <description>arXiv:2404.11435v1 Announce Type: new 
Abstract: This thesis proposes an adaptive linearized alternating direction multiplier method to improve the convergence rate of the algorithm by using adaptive techniques to dynamically select the regular term coefficients. The innovation of this method is to utilize the information of the current iteration point to adaptively select the appropriate parameters, thus expanding the selection of the subproblem step size and improving the convergence rate of the algorithm while ensuring convergence.The advantage of this method is that it can improve the convergence rate of the algorithm as much as possible without compromising the convergence. This is very beneficial for the solution of optimization problems because the traditional linearized alternating direction multiplier method has a trade-off in the selection of the regular term coefficients: larger coefficients ensure convergence but tend to lead to small step sizes, while smaller coefficients allow for an increase in the iterative step size but tend to lead to the algorithm's non-convergence. This balance can be better handled by adaptively selecting the parameters, thus improving the efficiency of the algorithm.Overall, the method proposed in this thesis is of great importance in the field of matrix optimization and has a positive effect on improving the convergence speed and efficiency of the algorithm. It is hoped that this adaptive idea can bring new inspiration to the development of the field of matrix optimization and promote the research and application in related fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11435v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boran Wang</dc:creator>
    </item>
    <item>
      <title>BSDE-based stochastic control for optimal reinsurance in a dynamic contagion model</title>
      <link>https://arxiv.org/abs/2404.11482</link>
      <description>arXiv:2404.11482v1 Announce Type: new 
Abstract: We investigate the optimal reinsurance problem in the risk model with jump clustering features introduced in [7]. This modeling framework is inspired by the concept initially proposed in [15], combining Hawkes and Cox processes with shot noise intensity models. Specifically, these processes describe self-exciting and externally excited jumps in the claim arrival intensity, respectively. The insurer aims to maximize the expected exponential utility of terminal wealth for general reinsurance contracts and reinsurance premiums. We discuss two different methodologies: the classical stochastic control approach based on the Hamilton-Jacobi-Bellman (HJB) equation and a backward stochastic differential equation (BSDE) approach. In a Markovian setting, differently from the classical HJB-approach, the BSDE method enables us to solve the problem without imposing any requirements for regularity on the associated value function. We provide a Verification Theorem in terms of a suitable BSDE driven by a two-dimensional marked point process and we prove an existence result relaying on the theory developed in [27] for stochastic Lipschitz generators. After discussing the optimal strategy for general reinsurance contracts and reinsurance premiums, we provide more explicit results in some relevant cases. Finally, we provide comparison results that highlight the heightened risk stemming from the self-exciting component in contrast to the externally-excited counterpart and discuss the monotonicity property of the value function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11482v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudia Ceci, Alessandra Cretarola</dc:creator>
    </item>
    <item>
      <title>Equitably allocating wildfire resilience investments for power grids: The curse of aggregation and vulnerability indices</title>
      <link>https://arxiv.org/abs/2404.11520</link>
      <description>arXiv:2404.11520v1 Announce Type: new 
Abstract: Wildfires ignited by power systems infrastructure are among the most destructive wildfires; hence some utility companies in wildfire-prone regions have pursued a proactive policy of emergency power shutoffs. These shutoffs, while mitigating the risk of disastrous ignition events, result in power outages that could negatively impacts vulnerable communities. In this paper, we consider how to equitably allocate funds to underground and effectively de-risk power lines in transmission networks. We explore the impact of the 2021 White House resource allocation policy called the Justice40 initiative, which states that 40% of the benefits of federally-funded climate-related investments should go to socially vulnerable communities. The definition of what constitutes a vulnerable community varies by organization, and we consider two major recently proposed vulnerability indices: the Justice40 index created under the 2021 White House and the Social Vulnerability Index (SVI) developed by the Center for Disease Control and Prevention (CDC). We show that allocating budget according to these two indices fails to reduce power outages for indigenous communities and those subject to high wildfire ignition risk using a high-fidelity synthetic power grid dataset that matches the key features of the Texas transmission system. We discuss how aggregation of communities and "one size fits all" vulnerability indices might be the reasons for the misalignment between the goals of vulnerability indices and their realized impact in this particular case study. We provide a method of achieving an equitable investment plan by adding group-level protections on percentage of load that is shed across each population group of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11520v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madeleine Pollack, Ryan Piansky, Swati Gupta, Alyssa Kody, Daniel Molzahn</dc:creator>
    </item>
    <item>
      <title>Corrigendum to "Applications of Strassen's theorem and Choquet theory to optimal transport problems, to uniformly convex functions and to uniformly smooth functions"</title>
      <link>https://arxiv.org/abs/2404.10797</link>
      <description>arXiv:2404.10797v1 Announce Type: cross 
Abstract: In [K.J. Ciosmak, Applications of Strassen's theorem and Choquet theory to optimal transport problems, to uniformly convex functions and to uniformly smooth functions, Nonlinear Anal. 232 (2023), Paper No. 113267, 32 pp.], Theorem 2.3. does not suffice for its applications. We strengthen Theorem 2.1. and Theorem 2.3., so that they imply their claimed consequences. Moreover, we correct a minor flaw in the proof of Proposition 2.4..</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10797v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.na.2024.113542</arxiv:DOI>
      <dc:creator>Krzysztof Jan Ciosmak</dc:creator>
    </item>
    <item>
      <title>Decoupled Weight Decay for Any $p$ Norm</title>
      <link>https://arxiv.org/abs/2404.10824</link>
      <description>arXiv:2404.10824v1 Announce Type: cross 
Abstract: With the success of deep neural networks (NNs) in a variety of domains, the computational and storage requirements for training and deploying large NNs have become a bottleneck for further improvements. Sparsification has consequently emerged as a leading approach to tackle these issues. In this work, we consider a simple yet effective approach to sparsification, based on the Bridge, or $L_p$ regularization during training. We introduce a novel weight decay scheme, which generalizes the standard $L_2$ weight decay to any $p$ norm. We show that this scheme is compatible with adaptive optimizers, and avoids the gradient divergence associated with $0&lt;p&lt;1$ norms. We empirically demonstrate that it leads to highly sparse networks, while maintaining generalization performance comparable to standard $L_2$ regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10824v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadav Joseph Outmezguine, Noam Levi</dc:creator>
    </item>
    <item>
      <title>Geometric Neural Operators (GNPs) for Data-Driven Deep Learning of Non-Euclidean Operators</title>
      <link>https://arxiv.org/abs/2404.10843</link>
      <description>arXiv:2404.10843v1 Announce Type: cross 
Abstract: We introduce Geometric Neural Operators (GNPs) for accounting for geometric contributions in data-driven deep learning of operators. We show how GNPs can be used (i) to estimate geometric properties, such as the metric and curvatures, (ii) to approximate Partial Differential Equations (PDEs) on manifolds, (iii) learn solution maps for Laplace-Beltrami (LB) operators, and (iv) to solve Bayesian inverse problems for identifying manifold shapes. The methods allow for handling geometries of general shape including point-cloud representations. The developed GNPs provide approaches for incorporating the roles of geometry in data-driven learning of operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10843v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Blaine Quackenbush, Paul J. Atzberger</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of the Linear Quadratic Regulator: A Reinforcement Learning Lens</title>
      <link>https://arxiv.org/abs/2404.10851</link>
      <description>arXiv:2404.10851v1 Announce Type: cross 
Abstract: We provide the first known algorithm that provably achieves $\varepsilon$-optimality within $\widetilde{\mathcal{O}}(1/\varepsilon)$ function evaluations for the discounted discrete-time LQR problem with unknown parameters, without relying on two-point gradient estimates. These estimates are known to be unrealistic in many settings, as they depend on using the exact same initialization, which is to be selected randomly, for two different policies. Our results substantially improve upon the existing literature outside the realm of two-point gradient estimates, which either leads to $\widetilde{\mathcal{O}}(1/\varepsilon^2)$ rates or heavily relies on stability assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10851v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Amirreza Neshaei Moghaddam, Alex Olshevsky, Bahman Gharesifard</dc:creator>
    </item>
    <item>
      <title>Differentially Private Optimization with Sparse Gradients</title>
      <link>https://arxiv.org/abs/2404.10881</link>
      <description>arXiv:2404.10881v1 Announce Type: cross 
Abstract: Motivated by applications of large embedding models, we study differentially private (DP) optimization problems under sparsity of individual gradients. We start with new near-optimal bounds for the classic mean estimation problem but with sparse data, improving upon existing algorithms particularly for the high-dimensional regime. Building on this, we obtain pure- and approximate-DP algorithms with almost optimal rates for stochastic convex optimization with sparse gradients; the former represents the first nearly dimension-independent rates for this problem. Finally, we study the approximation of stationary points for the empirical loss in approximate-DP optimization and obtain rates that depend on sparsity instead of dimension, modulo polylogarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10881v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Badih Ghazi, Crist\'obal Guzm\'an, Pritish Kamath, Ravi Kumar, Pasin Manurangsi</dc:creator>
    </item>
    <item>
      <title>Nonnegative tensor train for the multicomponent Smoluchowski equation</title>
      <link>https://arxiv.org/abs/2404.10898</link>
      <description>arXiv:2404.10898v1 Announce Type: cross 
Abstract: We propose an efficient implementation of the numerical tensor-train (TT) based algorithm solving the multicomponent coagulation equation preserving the nonnegativeness of solution. Unnatural negative elements in the constructed approximation arise due to the errors of the low-rank decomposition and discretization scheme. In this work, we propose to apply the rank-one corrections in the TT-format proportional to the minimal negative element. Such an element can be found via application of the global optimization methods that can be fully implemented within efficient operations in the tensor train format. We incorporate this trick into the time-integration scheme for the multicomponent coagulation equation and also use it for post-processing of the stationary solution for the problem with the source of particles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10898v1</guid>
      <category>math.NA</category>
      <category>cond-mat.soft</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey A. Matveev, Ilya Tretyak</dc:creator>
    </item>
    <item>
      <title>It\=o and It\=o-Wentzell chain rule for flows of conditional laws of continuous semimartingales: an easy approach</title>
      <link>https://arxiv.org/abs/2404.11010</link>
      <description>arXiv:2404.11010v1 Announce Type: cross 
Abstract: We provide a general It\=o\,-Wentzell formula for a random field of maps on the Wasserstein space of probability measures, defined by continuous semimartingales, and evaluated along the flow of conditional distributions of another continuous semimartingale. Our method follows standard arguments of It\=o calculus, and thus bypasses the approximation by empirical measures commonly used in the existing literature. As an application, we derive the dynamic programming equation for a mean field stochastic control problem with common noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11010v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Assil Fadle, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Control Theoretic Approach to Fine-Tuning and Transfer Learning</title>
      <link>https://arxiv.org/abs/2404.11013</link>
      <description>arXiv:2404.11013v1 Announce Type: cross 
Abstract: Given a training set in the form of a paired $(\mathcal{X},\mathcal{Y})$, we say that the control system $\dot{x} = f(x,u)$ has learned the paired set via the control $u^*$ if the system steers each point of $\mathcal{X}$ to its corresponding target in $\mathcal{Y}$. Most existing methods for finding a control function $u^*$ require learning of a new control function if the training set is updated. To overcome this limitation, we introduce the concept of $\textit{tuning without forgetting}$. We develop $\textit{an iterative algorithm}$ to tune the control function $u^*$ when the training set expands, whereby points already in the paired set are still matched, and new training samples are learned. More specifically, at each update of our method, the control $u^*$ is projected onto the kernel of the end-point mapping generated by the controlled dynamics at the learned samples. It ensures keeping the end points for the previously learned samples constant while iteratively learning additional samples. Our work contributes to the scalability of control methods, offering a novel approach to adaptively handle training set expansions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11013v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erkan Bayram, Shenyu Liu, Mohamed-Ali Belabbas, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Learning epidemic trajectories through Kernel Operator Learning: from modelling to optimal control</title>
      <link>https://arxiv.org/abs/2404.11130</link>
      <description>arXiv:2404.11130v1 Announce Type: cross 
Abstract: Since infectious pathogens start spreading into a susceptible population, mathematical models can provide policy makers with reliable forecasts and scenario analyses, which can be concretely implemented or solely consulted. In these complex epidemiological scenarios, machine learning architectures can play an important role, since they directly reconstruct data-driven models circumventing the specific modelling choices and the parameter calibration, typical of classical compartmental models. In this work, we discuss the efficacy of Kernel Operator Learning (KOL) to reconstruct population dynamics during epidemic outbreaks, where the transmission rate is ruled by an input strategy. In particular, we introduce two surrogate models, named KOL-m and KOL-$\partial$, which reconstruct in two different ways the evolution of the epidemics. Moreover, we evaluate the generalization performances of the two approaches with different kernels, including the Neural Tangent Kernels, and compare them with a classical neural network model learning method. Employing synthetic but semi-realistic data, we show how the two introduced approaches are suitable for realizing fast and robust forecasts and scenario analyses, and how these approaches are competitive for determining optimal intervention strategies with respect to specific performance measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11130v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Ziarelli, Nicola Parolini, Marco Verani</dc:creator>
    </item>
    <item>
      <title>Reconstruction of the local contractility of the cardiac muscle from deficient apparent kinematics</title>
      <link>https://arxiv.org/abs/2404.11137</link>
      <description>arXiv:2404.11137v1 Announce Type: cross 
Abstract: Active solids are a large class of materials, including both living soft tissues and artificial matter, that share the ability to undergo strain even in absence of external loads. While in engineered materials the actuation is typically designed a priori, in natural materials it is an unknown of the problem. In such a framework, the identification of inactive regions in active materials is of particular interest. An example of paramount relevance is cardiac mechanics and the assessment of regions of the cardiac muscle with impaired contractility. The impossibility to measure the local active forces directly, suggests us to develop a novel methodology exploiting kinematic data from clinical images by a variational approach to reconstruct the local contractility in the cardiac muscle. Introducing a suitable cost functional and effective regularization methods, we minimize the discrepancy between observed and simulated displacement and we recover the contractility map of the muscle. Numerical experiments, including severe conditions with added noise to model uncertainties, and data knowledge limited to the boundary, demonstrate the effectiveness of our approach. Unlike other methods, we provide a spatially continuous recovery of the contractility map at a low computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11137v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulia Pozzi, Davide Ambrosi, Simone Pezzuto</dc:creator>
    </item>
    <item>
      <title>Control Barrier Functions for Stochastic Systems and Safety-critical Control Designs</title>
      <link>https://arxiv.org/abs/2209.08728</link>
      <description>arXiv:2209.08728v5 Announce Type: replace 
Abstract: In recent years, the analysis of a control barrier function has received considerable attention because it is helpful for the safety-critical control required in many control application problems. While the extension of the analysis to a stochastic system studied by many researchers, it remains a challenging issue. In this paper, we consider sufficient conditions for reciprocal and zeroing control barrier functions ensuring safety with probability one and design a control law using the functions. Then, we propose another version of a stochastic zeroing control barrier function to evaluate a probability of a sample path staying in a safe set and confirm the convergence of a specific expectation related to the attractiveness of a safe set. We also show a way of deisgning a safety-critical control law based on our stochastic zeroing control barrier function. Finally, we confirm the validity of the proposed control design and the analysis using the control barrier functions via simple examples with their numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.08728v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Nishimura, Kenta Hoshino</dc:creator>
    </item>
    <item>
      <title>Distributed Random Reshuffling Methods with Improved Convergence</title>
      <link>https://arxiv.org/abs/2306.12037</link>
      <description>arXiv:2306.12037v2 Announce Type: replace 
Abstract: This paper proposes two distributed random reshuffling methods, namely Gradient Tracking with Random Reshuffling (GT-RR) and Exact Diffusion with Random Reshuffling (ED-RR), to solve the distributed optimization problem over a connected network, where a set of agents aim to minimize the average of their local cost functions. Both algorithms invoke random reshuffling (RR) update for each agent, inherit favorable characteristics of RR for minimizing smooth nonconvex objective functions, and improve the performance of previous distributed random reshuffling methods both theoretically and empirically. Specifically, both GT-RR and ED-RR achieve the convergence rate of $O(1/[(1-\lambda)^{1/3}m^{1/3}T^{2/3}])$ in driving the (minimum) expected squared norm of the gradient to zero, where $T$ denotes the number of epochs, $m$ is the sample size for each agent, and $1-\lambda$ represents the spectral gap of the mixing matrix. When the objective functions further satisfy the Polyak-{\L}ojasiewicz (PL) condition, we show GT-RR and ED-RR both achieve $O(1/[(1-\lambda)mT^2])$ convergence rate in terms of the averaged expected differences between the agents' function values and the global minimum value. Notably, both results are comparable to the convergence rates of centralized RR methods (up to constant factors depending on the network topology) and outperform those of previous distributed random reshuffling algorithms. Moreover, we support the theoretical findings with a set of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12037v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Huang, Linli Zhou, Shi Pu</dc:creator>
    </item>
    <item>
      <title>Improved guarantees for optimal Nash equilibrium seeking and bilevel variational inequalities</title>
      <link>https://arxiv.org/abs/2307.12511</link>
      <description>arXiv:2307.12511v3 Announce Type: replace 
Abstract: We consider a class of hierarchical variational inequality (VI) problems that subsumes VI-constrained optimization and several other important problem classes including the optimal solution selection problem and the optimal Nash equilibrium (NE) seeking problem. Our main contributions are threefold. (i) We consider bilevel VIs with monotone and Lipschitz continuous mappings and devise a single-timescale iteratively regularized extragradient method, named IR-EG$_{{\texttt{m,m}}}$. We improve the existing iteration complexity results for addressing both bilevel VI and VI-constrained convex optimization problems. (ii) Under the strong monotonicity of the outer level mapping, we develop a method named IR-EG$_{{\texttt{s,m}}}$ and derive faster guarantees than those in (i). We also study the iteration complexity of this method under a constant regularization parameter. These results appear to be new for both bilevel VIs and VI-constrained optimization. (iii) To our knowledge, complexity guarantees for computing the optimal NE in nonconvex settings do not exist. Motivated by this lacuna, we consider VI-constrained nonconvex optimization problems and devise an inexactly-projected gradient method, named IPR-EG, where the projection onto the unknown set of equilibria is performed using IR-EG$_{{\texttt{s,m}}}$ with a prescribed termination criterion and an adaptive regularization parameter. We obtain new complexity guarantees in terms of a residual map and an infeasibility metric for computing a stationary point. We validate the theoretical findings using preliminary numerical experiments for computing the best and the worst Nash equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12511v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepideh Samadi, Farzad Yousefian</dc:creator>
    </item>
    <item>
      <title>An Adaptive Phase-Field Method for Structural Topology Optimization</title>
      <link>https://arxiv.org/abs/2308.06756</link>
      <description>arXiv:2308.06756v2 Announce Type: replace 
Abstract: In this work, we develop an adaptive algorithm for the efficient numerical solution of the minimum compliance problem in topology optimization. The algorithm employs the phase field approximation and continuous density field. The adaptive procedure is driven by two residual type a posteriori error estimators, one for the state variable and the other for the first-order optimality condition of the objective functional. The adaptive algorithm is provably convergent in the sense that the sequence of numerical approximations generated by the adaptive algorithm contains a subsequence convergent to a solution of the continuous first-order optimality system. We provide several numerical simulations to show the distinct features of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06756v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2024.112932</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Physics, 2024</arxiv:journal_reference>
      <dc:creator>Bangti Jin, Jing Li, Yifeng Xu, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems</title>
      <link>https://arxiv.org/abs/2311.04161</link>
      <description>arXiv:2311.04161v2 Announce Type: replace 
Abstract: We consider stochastic optimization problems with heavy-tailed noise with structured density. For such problems, we show that it is possible to get faster rates of convergence than $\mathcal{O}(K^{-2(\alpha - 1)/\alpha})$, when the stochastic gradients have finite moments of order $\alpha \in (1, 2]$. In particular, our analysis allows the noise norm to have an unbounded expectation. To achieve these results, we stabilize stochastic gradients, using smoothed medians of means. We prove that the resulting estimates have negligible bias and controllable variance. This allows us to carefully incorporate them into clipped-SGD and clipped-SSTM and derive new high-probability complexity bounds in the considered setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04161v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Puchkin, Eduard Gorbunov, Nikolay Kutuzov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Eigenvalue programming beyond matrices</title>
      <link>https://arxiv.org/abs/2311.04637</link>
      <description>arXiv:2311.04637v2 Announce Type: replace 
Abstract: In this paper we analyze and solve eigenvalue programs, which consist of the task of minimizing a function subject to constraints on the "eigenvalues" of the decision variable. Here, by making use of the FTvN systems framework introduced by Gowda, we interpret "eigenvalues" in a broad fashion going beyond the usual eigenvalues of matrices. This allows us to shed new light on classical problems such as inverse eigenvalue problems and also leads to new applications. In particular, after analyzing and developing a simple projected gradient algorithm for general eigenvalue programs, we show that eigenvalue programs can be used to express what we call vanishing quadratic constraints. A vanishing quadratic constraint requires that a given system of convex quadratic inequalities be satisfied and at least a certain number of those inequalities must be tight. As a particular case, this includes the problem of finding a point $x$ in the intersection of $m$ ellipsoids in such a way that $x$ is also in the boundary of at least $\ell$ of the ellipsoids, for some fixed $\ell &gt; 0$. At the end, we also present some numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04637v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masaru Ito, Bruno F. Louren\c{c}o</dc:creator>
    </item>
    <item>
      <title>Risk-Aware Security-Constrained Unit Commitment: Taming the Curse of Real-Time Volatility and Consumer Exposure</title>
      <link>https://arxiv.org/abs/2311.17254</link>
      <description>arXiv:2311.17254v2 Announce Type: replace 
Abstract: We propose an enhancement to wholesale electricity markets whereby the exposure of consumers to increasingly large and volatile consumer payments arising as a byproduct of volatile real-time net loads -- i.e., loads minus renewable outputs -- and prices, both compared to day-ahead cleared values. We incorporate a robust estimate of such excess payments into the day-ahead computation and specifically seek to account for volatility in real-time net loads and renewable generation. Our model features a data-driven uncertainty set based on principal component analysis, which accommodates both load and wind production volatility and captures locational correlation of uncertain data. To solve the model more efficiently, we develop a decomposition algorithm that can handle nonconvex subproblems. Our extensive experiments on a realistic NYISO data set show that the risk-aware model protects the consumers from potential high costs caused by adverse circumstances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17254v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Bienstock, Yury Dvorkin, Cheng Guo, Robert Mieth, Jiayi Wang</dc:creator>
    </item>
    <item>
      <title>Approximation with Random Shallow ReLU Networks with Applications to Model Reference Adaptive Control</title>
      <link>https://arxiv.org/abs/2403.17142</link>
      <description>arXiv:2403.17142v2 Announce Type: replace 
Abstract: Neural networks are regularly employed in adaptive control of nonlinear systems and related methods of reinforcement learning. A common architecture uses a neural network with a single hidden layer (i.e. a shallow network), in which the weights and biases are fixed in advance and only the output layer is trained. While classical results show that there exist neural networks of this type that can approximate arbitrary continuous functions over bounded regions, they are non-constructive, and the networks used in practice have no approximation guarantees. Thus, the approximation properties required for control with neural networks are assumed, rather than proved. In this paper, we aim to fill this gap by showing that for sufficiently smooth functions, ReLU networks with randomly generated weights and biases achieve $L_{\infty}$ error of $O(m^{-1/2})$ with high probability, where $m$ is the number of neurons. It suffices to generate the weights uniformly over a sphere and the biases uniformly over an interval. We show how the result can be used to get approximations of required accuracy in a model reference adaptive control application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17142v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Lamperski, Tyler Lekang</dc:creator>
    </item>
    <item>
      <title>Incremental data compression for PDE-constrained optimization with a data assimilation application</title>
      <link>https://arxiv.org/abs/2404.09323</link>
      <description>arXiv:2404.09323v2 Announce Type: replace 
Abstract: This paper proposes and analyzes an inexact gradient method based on incremental proper orthogonal decomposition (iPOD) to address the data storage difficulty in time-dependent PDE-constrained optimization, particularly for a data assimilation problem as a detailed demonstration for the key ideas. The proposed method is proved robust by rigorous analysis. We first derive a sharp data compression error estimate of the iPOD with the help of Hilbert-Schmidt operators. Then we demonstrate a numerical PDE analysis to show how to properly choose Hilbert space for the iPOD data compression so that the gradient error is under control. We further prove that for a convex problem with appropriately bounded gradient error, the inexact gradient method achieves the accuracy level of the optimal solution while not hurting the convergence rate compared with the usual gradient method. Finally, numerical experiments are provided to verify the theoretical results and validate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09323v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuejian Li, John R. Singler, Xiaoming He</dc:creator>
    </item>
    <item>
      <title>Drift Control of High-Dimensional RBM: A Computational Method Based on Neural Networks</title>
      <link>https://arxiv.org/abs/2309.11651</link>
      <description>arXiv:2309.11651v3 Announce Type: replace-cross 
Abstract: Motivated by applications in queueing theory, we consider a stochastic control problem whose state space is the $d$-dimensional positive orthant. The controlled process $Z$ evolves as a reflected Brownian motion whose covariance matrix is exogenously specified, as are its directions of reflection from the orthant's boundary surfaces. A system manager chooses a drift vector $\theta(t)$ at each time $t$ based on the history of $Z$, and the cost rate at time $t$ depends on both $Z(t)$ and $\theta(t)$. In our initial problem formulation, the objective is to minimize expected discounted cost over an infinite planning horizon, after which we treat the corresponding ergodic control problem. Extending earlier work by Han et al. (Proceedings of the National Academy of Sciences, 2018, 8505-8510), we develop and illustrate a simulation-based computational method that relies heavily on deep neural network technology. For test problems studied thus far, our method is accurate to within a fraction of one percent, and is computationally feasible in dimensions up to at least $d=30$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11651v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baris Ata, J. Michael Harrison, Nian Si</dc:creator>
    </item>
    <item>
      <title>Singular Control of (Reflected) Brownian Motion: A Computational Method Suitable for Queueing Applications</title>
      <link>https://arxiv.org/abs/2312.11823</link>
      <description>arXiv:2312.11823v3 Announce Type: replace-cross 
Abstract: Motivated by applications in queueing theory, we consider a class of singular stochastic control problems whose state space is the d-dimensional positive orthant. The original problem is approximated by a drift control problem, to which we apply a recently developed computational method that is feasible for dimensions up to d=30 or more. To show that nearly optimal solutions are obtainable using this method, we present computational results for a variety of examples, including queueing network examples that have appeared previously in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11823v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baris Ata, J. Michael Harrison, Nian Si</dc:creator>
    </item>
  </channel>
</rss>
