<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Apr 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Minimum Cost Nowhere-zero Flows and Cut-balanced Orientations</title>
      <link>https://arxiv.org/abs/2504.18767</link>
      <description>arXiv:2504.18767v1 Announce Type: new 
Abstract: Flows and colorings are disparate concepts in graph algorithms -- the former is tractable while the latter is intractable. Tutte introduced the concept of nowhere-zero flows to unify these two concepts. Jaeger showed that nowhere-zero flows are equivalent to cut-balanced orientations. Motivated by connections between nowhere-zero flows, cut-balanced orientations, Nash-Williams' well-balanced orientations, and postman problems, we study optimization versions of nowhere-zero flows and cut-balanced orientations. Given a bidirected graph with asymmetric costs on two orientations of each edge, we study the min cost nowhere-zero $k$-flow problem and min cost $k$-cut-balanced orientation problem. We show that both problems are NP-hard to approximate within any finite factor. Given the strong inapproximability result, we design bicriteria approximations for both problems: we obtain a $(6,6)$-approximation to the min cost nowhere-zero $k$-flow and a $(k,6)$-approximation to the min cost $k$-cut-balanced orientation. For the case of symmetric costs (where the costs of both orientations are the same for every edge), we show that the nowhere-zero $k$-flow problem remains NP-hard and admits a $3$-approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18767v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthekeyan Chandrasekaran, Siyue Liu, R. Ravi</dc:creator>
    </item>
    <item>
      <title>Min-CSPs on Complete Instances II: Polylogarithmic Approximation for Min-NAE-3-SAT</title>
      <link>https://arxiv.org/abs/2504.19051</link>
      <description>arXiv:2504.19051v1 Announce Type: new 
Abstract: This paper studies complete $k$-Constraint Satisfaction Problems (CSPs), where an $n$-variable instance has exactly one nontrivial constraint for each subset of $k$ variables, i.e., it has $\binom{n}{k}$ constraints. A recent work started a systematic study of complete $k$-CSPs [Anand, Lee, Sharma, SODA'25], and showed a quasi-polynomial time algorithm that decides if there is an assignment satisfying all the constraints of any complete Boolean-alphabet $k$-CSP, algorithmically separating complete instances from dense instances.
  The tractability of this decision problem is necessary for any nontrivial (multiplicative) approximation for the minimization version, whose goal is to minimize the number of violated constraints. The same paper raised the question of whether it is possible to obtain nontrivial approximation algorithms for complete Min-$k$-CSPs with $k \geq 3$.
  In this work, we make progress in this direction and show a quasi-polynomial time $\text{polylog}(n)$-approximation to Min-NAE-3-SAT on complete instances, which asks to minimize the number of $3$-clauses where all the three literals equal the same bit. To the best of our knowledge, this is the first known example of a CSP whose decision version is NP-Hard in general (and dense) instances while admitting a $\text{polylog}(n)$-approximation in complete instances. Our algorithm presents a new iterative framework for rounding a solution from the Sherali-Adams hierarchy, where each iteration interleaves the two well-known rounding tools: the conditioning procedure, in order to almost fix many variables, and the thresholding procedure, in order to completely fix them.
  Finally, we improve the running time of the decision algorithms of Anand, Lee, and Sharma and show a simple algorithm that decides any complete Boolean-alphabet $k$-CSP in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19051v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Anand, Euiwoong Lee, Davide Mazzali, Amatya Sharma</dc:creator>
    </item>
    <item>
      <title>Entrywise Approximate Matrix Inversion</title>
      <link>https://arxiv.org/abs/2504.19054</link>
      <description>arXiv:2504.19054v1 Announce Type: new 
Abstract: We study the bit complexity of inverting diagonally dominant matrices, which are associated with random walk quantities such as hitting times and escape probabilities. Such quantities can be exponentially small, even on undirected unit-weighted graphs. However, their nonnegativity suggests that they can be approximated entrywise, leading to a stronger notion of approximation than vector norm-based error.
  Under this notion of error, existing Laplacian solvers and fast matrix multiplication approaches have bit complexities of $mn^2$ and $n^{\omega+1}$, respectively, where $m$ is the number of nonzero entries in the matrix, $n$ is its size, and $\omega$ is the matrix multiplication exponent.
  We present algorithms that compute entrywise $\exp(\epsilon)$-approximate inverses of row diagonally dominant $L$-matrices (RDDL) in two settings: (1) when the matrix entries are given in floating-point representation; (2) when they are given in fixed-point representation.
  For floating-point inputs, we present a cubic-time algorithm and show that it has an optimal running time under the all-pairs shortest paths (APSP) conjecture.
  For fixed-point inputs, we present several algorithms for solving linear systems and inverting RDDL and SDDM matrices, all with high probability.
  Omitting logarithmic factors:
  (1) For SDDM matrices, we provide an algorithm for solving a linear system with entrywise approximation guarantees using $\tilde{O}(m\sqrt{n})$ bit operations, and another for computing an entrywise approximate inverse using $\tilde{O}(mn)$ bit operations.
  (2) For RDDL matrices, we present an algorithm for solving a linear system using $\tilde{O}(mn^{1+o(1)})$ bit operations, and two algorithms for computing an entrywise approximate inverse: one using $\tilde{O}(n^{\omega+0.5})$ bit operations, and the other using $\tilde{O}(mn^{1.5+o(1)})$ bit operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19054v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehrdad Ghadiri, Junzhao Yang</dc:creator>
    </item>
    <item>
      <title>Fast and memory-efficient BWT construction of repetitive texts using Lyndon grammars</title>
      <link>https://arxiv.org/abs/2504.19123</link>
      <description>arXiv:2504.19123v1 Announce Type: new 
Abstract: The Burrows-Wheeler Transform (BWT) serves as the basis for many important sequence indexes. On very large datasets (e.g. genomic databases), classical BWT construction algorithms are often infeasible because they usually need to have the entire dataset in main memory. Fortunately, such large datasets are often highly repetitive. It can thus be beneficial to compute the BWT from a compressed representation. We propose an algorithm for computing the BWT via the Lyndon straight-line program, a grammar based on the standard factorization of Lyndon words. Our algorithm can also be used to compute the extended BWT (eBWT) of a multiset of sequences. We empirically evaluate our implementation and find that we can compute the BWT and eBWT of very large datasets faster and/or with less memory than competing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19123v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannik Olbrich</dc:creator>
    </item>
    <item>
      <title>The Trichotomy of Regular Property Testing</title>
      <link>https://arxiv.org/abs/2504.19152</link>
      <description>arXiv:2504.19152v1 Announce Type: new 
Abstract: Property testing is concerned with the design of algorithms making a sublinear number of queries to distinguish whether the input satisfies a given property or is far from having this property. A seminal paper of Alon, Krivelevich, Newman, and Szegedy in 2001 introduced property testing of formal languages: the goal is to determine whether an input word belongs to a given language, or is far from any word in that language. They constructed the first property testing algorithm for the class of all regular languages. This opened a line of work with improved complexity results and applications to streaming algorithms. In this work, we show a trichotomy result: the class of regular languages can be divided into three classes, each associated with an optimal query complexity. Our analysis yields effective characterizations for all three classes using so-called minimal blocking sequences, reasoning directly and combinatorially on automata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19152v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Bathie, Nathana\"el Fijalkow, Corto Mascle</dc:creator>
    </item>
    <item>
      <title>(Almost-)Optimal FPT Algorithm and Kernel for $T$-Cycle on Planar Graphs</title>
      <link>https://arxiv.org/abs/2504.19301</link>
      <description>arXiv:2504.19301v1 Announce Type: new 
Abstract: Research of cycles through specific vertices is a central topic in graph theory. In this context, we focus on a well-studied computational problem, \textsc{$T$-Cycle}: given an undirected $n$-vertex graph $G$ and a set of $k$ vertices $T\subseteq V(G)$ termed \textit{terminals}, the objective is to determine whether $G$ contains a simple cycle $C$ through all the terminals. Our contribution is twofold: (i) We provide a $2^{O(\sqrt{k}\log k)}\cdot n$-time fixed-parameter deterministic algorithm for \textsc{$T$-Cycle} on planar graphs; (ii) We provide a $k^{O(1)}\cdot n$-time deterministic kernelization algorithm for \textsc{$T$-Cycle} on planar graphs where the produced instance is of size $k\log^{O(1)}k$.
  Both of our algorithms are optimal in terms of both $k$ and $n$ up to (poly)logarithmic factors in $k$ under the ETH. In fact, our algorithms are the first subexponential-time fixed-parameter algorithm for \textsc{$T$-Cycle} on planar graphs, as well as the first polynomial kernel for \textsc{$T$-Cycle} on planar graphs. This substantially improves upon/expands the known literature on the parameterized complexity of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19301v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harmender Gahlawat, Abhishek Rathod, Meirav Zehavi</dc:creator>
    </item>
    <item>
      <title>Optimal Static Fully Indexable Dictionaries</title>
      <link>https://arxiv.org/abs/2504.19350</link>
      <description>arXiv:2504.19350v1 Announce Type: new 
Abstract: Fully indexable dictionaries (FID) store sets of integer keys while supporting rank/select queries. They serve as basic building blocks in many succinct data structures. Despite the great importance of FIDs, no known FID is succinct with efficient query time when the universe size $U$ is a large polynomial in the number of keys $n$, which is the conventional parameter regime for dictionary problems. In this paper, we design an FID that uses $\log \binom{U}{n} + \frac{n}{(\log U / t)^{\Omega(t)}}$ bits of space, and answers rank/select queries in $O(t + \log \log n)$ time in the worst case, for any parameter $1 \le t \le \log n / \log \log n$, provided $U = n^{1 + \Theta(1)}$. This time-space trade-off matches known lower bounds for FIDs [P\v{a}tra\c{s}cu &amp; Thorup STOC 2006; P\v{a}tra\c{s}cu &amp; Viola SODA 2010] when $t \le \log^{0.99} n$.
  Our techniques also lead to efficient succinct data structures for the fundamental problem of maintaining $n$ integers each of $\ell = \Theta(\log n)$ bits and supporting partial-sum queries, with a trade-off between $O(t)$ query time and $n\ell + n / (\log n / t)^{\Omega(t)}$ bits of space. Prior to this work, no known data structure for the partial-sum problem achieves constant query time with $n \ell + o(n)$ bits of space usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19350v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingxun Liang, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Dynamic r-index: An Updatable Self-Index for Highly Repetitive Strings</title>
      <link>https://arxiv.org/abs/2504.19482</link>
      <description>arXiv:2504.19482v1 Announce Type: new 
Abstract: A self-index is a compressed data structure that supports locate queries-reporting all positions where a given pattern occurs in a string. While many self-indexes have been proposed, developing dynamically updatable ones supporting string insertions and deletions remains a challenge. The r-index (Gagie et al., SODA'18) is a representative static self-index based on the run-length Burrows-Wheeler transform (RLBWT), designed for highly repetitive strings - those with many repeated substrings. We present the dynamic r-index, an extension of the r-index that supports locate queries in $\mathcal{O}((m + \occ) \log n)$ time using $\mathcal{O}(r)$ words, where $n$ is the length of the string $T$, $m$ is the pattern length, $\occ$ is the number of occurrences, and $r$ is the number of runs in the RLBWT of $T$. It supports string insertions and deletions in $\mathcal{O}((m + L_{\max}) \log n)$ time, where $L_{\max}$ is the maximum value in the LCP array of $T$. The average running time is $\mathcal{O}((m + L_{\avg}) \log n)$, where $L_{\avg}$ is the average LCP value. We experimentally evaluated the dynamic r-index on various highly repetitive strings and demonstrated its practicality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19482v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takaaki Nishimoto, Yasuo Tabei</dc:creator>
    </item>
    <item>
      <title>Space-Efficient Depth-First Search via Augmented Succinct Graph Encodings</title>
      <link>https://arxiv.org/abs/2504.19547</link>
      <description>arXiv:2504.19547v1 Announce Type: new 
Abstract: We call a graph $G$ separable if a balanced separator can be computed for $G$ of size $O(n^c)$ with $c&lt;1$. Many real-world graphs are separable such as graphs of bounded genus, graphs of constant treewidth, and graphs excluding a fixed minor $H$. In particular, the well-known planar graphs are separable. We present a succinct encoding of separable graphs $G$ such that any number of depth-first searches DFS can be performed, from any given start vertex, each in $o(n)$ time with $o(n)$ additional bits. After the execution of a DFS, the succinct encoding of $G$ is augmented such that the DFS tree is encoded inside the encoding. Afterward, the encoding provides common DFS-related queries in constant time. These queries include queries such as lowest-common ancestor of two given vertices in the DFS tree or queries that output the lowpoint of a given vertex in the DFS tree. Furthermore, for planar graphs, we show that the succinct encoding can be computed in $O(n)$ bits and expected linear time, and a compact variant can be constructed in $O(n)$ time and bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19547v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Elberfeld, Frank Kammer, Johannes Meintrup</dc:creator>
    </item>
    <item>
      <title>Faster Dynamic $(\Delta+1)$-Coloring Against Adaptive Adversaries</title>
      <link>https://arxiv.org/abs/2504.19729</link>
      <description>arXiv:2504.19729v1 Announce Type: new 
Abstract: We consider the problem of maintaining a proper $(\Delta + 1)$-vertex coloring in a graph on $n$-vertices and maximum degree $\Delta$ undergoing edge insertions and deletions. We give a randomized algorithm with amortized update time $\widetilde{O}( n^{2/3} )$ against adaptive adversaries, meaning that updates may depend on past decisions by the algorithm. This improves on the very recent $\widetilde{O}( n^{8/9} )$-update-time algorithm by Behnezhad, Rajaraman, and Wasim (SODA 2025) and matches a natural barrier for dynamic $(\Delta+1)$-coloring algorithms. The main improvements are in the densest regions of the graph, where we use structural hints from the study of distributed graph algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19729v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxime Flin, Magn\'us M. Halld\'orsson</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Minimum Cuts in Hypergraphs at Scale</title>
      <link>https://arxiv.org/abs/2504.19842</link>
      <description>arXiv:2504.19842v1 Announce Type: new 
Abstract: The hypergraph minimum cut problem aims to partition its vertices into two blocks while minimizing the total weight of the cut hyperedges. This fundamental problem arises in network reliability, VLSI design, and community detection. We present HeiCut, a scalable algorithm for computing near-optimal minimum cuts in both unweighted and weighted hypergraphs. HeiCut aggressively reduces the hypergraph size through a sequence of provably exact reductions that preserve the minimum cut, along with an optional heuristic contraction based on label propagation. It then solves a relaxed Binary Integer Linear Program (BIP) on the reduced hypergraph to compute a near-optimal minimum cut. Our extensive evaluation on over 500 real-world hypergraphs shows that HeiCut computes the exact minimum cut in over 85% of instances using our exact reductions alone, and offers the best solution quality across all instances. It solves over twice as many instances as the state-of-the-art within set computational limits, and is up to five orders of magnitude faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19842v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adil Chhabra, Christian Schulz, Bora U\c{c}ar, Loris Wilwert</dc:creator>
    </item>
    <item>
      <title>Revisiting Directed Disjoint Paths on tournaments (and relatives)</title>
      <link>https://arxiv.org/abs/2504.19957</link>
      <description>arXiv:2504.19957v1 Announce Type: new 
Abstract: In the Directed Disjoint Paths problem ($k$-DDP), we are given a digraph $k$ pairs of terminals, and the goal is to find $k$ pairwise vertex-disjoint paths connecting each pair of terminals. Bang-Jensen and Thomassen [SIAM J. Discrete Math. 1992] claimed that $k$-DDP is NP-complete on tournaments, and this result triggered a very active line of research about the complexity of the problem on tournaments and natural superclasses. We identify a flaw in their proof, which has been acknowledged by the authors, and provide a new NP-completeness proof. From an algorithmic point of view, Fomin and Pilipczuk [J. Comb. Theory B 2019] provided an FPT algorithm for the edge-disjoint version of the problem on semicomplete digraphs, and showed that their technique cannot work for the vertex-disjoint version. We overcome this obstacle by showing that the version of $k$-DDP where we allow congestion $c$ on the vertices is FPT on semicomplete digraphs provided that $c$ is greater than $k/2$. This is based on a quite elaborate irrelevant vertex argument inspired by the edge-disjoint version, and we show that our choice of $c$ is best possible for this technique, with a counterexample with no irrelevant vertices when $c \leq k/2$. We also prove that $k$-DDP on digraphs that can be partitioned into $h$ semicomplete digraphs is $W[1]$-hard parameterized by $k+h$, which shows that the XP algorithm presented by Chudnovsky, Scott, and Seymour [J. Comb. Theory B 2019] is essentially optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19957v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilherme C. M. Gomes, Raul Lopes, Ignasi Sau</dc:creator>
    </item>
    <item>
      <title>Engineering Minimal k-Perfect Hash Functions</title>
      <link>https://arxiv.org/abs/2504.20001</link>
      <description>arXiv:2504.20001v1 Announce Type: new 
Abstract: Given a set S of n keys, a k-perfect hash function (kPHF) is a data structure that maps the keys to the first m integers, where each output integer can be hit by at most k input keys. When m=n/k, the resulting function is called a minimal k-perfect hash function (MkPHF). Applications of kPHFs can be found in external memory data structures or to create efficient 1-perfect hash functions, which in turn have a wide range of applications from databases to bioinformatics. Several papers from the 1980s look at external memory data structures with small internal memory indexes. However, actual k-perfect hash functions are surprisingly rare, and the area has not seen a lot of research recently. At the same time, recent research in 1-perfect hashing shows that there is a lack of efficient kPHFs. In this paper, we revive the area of k-perfect hashing, presenting four new constructions. Our implementations simultaneously dominate older approaches in space consumption, construction time, and query time. We see this paper as a possible starting point of an active line of research, similar to the area of 1-perfect hashing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20001v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Hermann, Sebastian Kirmayer, Hans-Peter Lehmann, Peter Sanders, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>All-Subsets Important Separators with Applications to Sample Sets, Balanced Separators and Vertex Sparsifiers in Directed Graphs</title>
      <link>https://arxiv.org/abs/2504.20027</link>
      <description>arXiv:2504.20027v1 Announce Type: new 
Abstract: Given a directed graph $G$ with $n$ vertices and $m$ edges, a parameter $k$ and two disjoint subsets $S,T \subseteq V(G)$, we show that the number of all-subsets important separators, which is the number of $A$-$B$ important vertex separators of size at most $k$ over all $A \subseteq S$ and $B \subseteq T$, is at most $\beta(|S|, |T|, k) = 4^k {|S| \choose \leq k} {|T| \choose \leq 2k}$, where ${x \choose \leq c} = \sum_{i = 1}^c {x \choose i}$, and that they can be enumerated in time $O(\beta(|S|,|T|,k)k^2(m+n))$. This is a generalization of the folklore result stating that the number of $A$-$B$ important separators for two fixed sets $A$ and $B$ is at most $4^k$ (first implicitly shown by Chen, Liu and Lu Algorithmica '09). From this result, we obtain the following applications: We give a construction for detection sets and sample sets in directed graphs, generalizing the results of Kleinberg (Internet Mathematics' 03) and Feige and Mahdian (STOC' 06) to directed graphs. Via our new sample sets, we give the first FPT algorithm for finding balanced separators in directed graphs parameterized by $k$, the size of the separator. Our algorithm runs in time $2^{O(k)} (m + n)$. We also give a $O({\sqrt{\log k}})$ approximation algorithm for the same problem. Finally, we present new results on vertex sparsifiers for preserving small cuts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20027v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Anand, Euiwoong Lee, Jason Li, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>Optimization of Next-Day Delivery Coverage using Constraint Programming and Random Key Optimizers</title>
      <link>https://arxiv.org/abs/2504.18749</link>
      <description>arXiv:2504.18749v1 Announce Type: cross 
Abstract: We consider the logistics network of an e-commerce retailer, specifically the so-called "middle mile" network, that routes inventory from supply warehouses to distribution stations to be ingested into the terminal ("last mile") delivery network. The speed of packages through this middle mile network is a key determinant for the ultimate delivery speed to the end user. An important target for a retailer is to maximize the fraction of user orders that can be serviced within one day, i.e., next-day delivery. As such, we formulate the maximization of expected next-day delivery coverage within the middle-mile network as an optimization problem, involving a set of temporal and capacity-based constraints on the network and requiring the use of a black-box model to evaluate the objective function. We design both exact constraint programming (CP) and heuristic random-key optimizer (RKO) approaches, the former of which uses a proxy objective function. We perform experiments on large-scale, real-world problem instances and show that both approaches have merit, in that they can match or outperform the baseline solution, a bespoke greedy solver with integrated local search, in expected next-day delivery coverage. Our experiments focus on two high-level problem definitions, starting with a base problem and then adding more complexity, and also explore the generalization of the solvers across a range of problem instance sizes. We find that a hybrid model using RKO and a bespoke local search protocol performs best on the full problem definition with respect to expected next-day delivery (increase of +50 basis points [bps] over baseline) but can take days to run, whereas the hybrid model using CP and local search is slightly less competitive (+20 bps) but takes only hours to run.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18749v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle Brubaker, Kyle E. C. Booth, Martin J. A. Schuetz, Philipp Loick, Jian Shen, Arun Ramamurthy, Georgios Paschos</dc:creator>
    </item>
    <item>
      <title>Faithful universal graphs for minor-closed classes</title>
      <link>https://arxiv.org/abs/2504.19582</link>
      <description>arXiv:2504.19582v1 Announce Type: cross 
Abstract: It was proved by Huynh, Mohar, \v{S}\'amal, Thomassen and Wood in 2021 that any countable graph containing every countable planar graph as a subgraph has an infinite clique minor. We prove a finite, quantitative version of this result: for fixed $t$, if a graph $G$ is $K_t$-minor-free and contains every $n$-vertex planar graph as a subgraph, then $G$ has $2^{\Omega(\sqrt{n})}$ vertices. If $G$ contains every $n$-vertex toroidal graph instead, then $G$ has $2^{\Omega(n)}$ vertices. On the other hand, we construct a polynomial size $K_4$-minor-free graph containing every $n$-vertex tree as an induced subgraph, and a polynomial size $K_7$-minor-free graph containing every $n$-vertex $K_4$-minor-free graph as induced subgraph. This answers several problems raised recently by Bergold, Ir\v{s}i\v{c}, Lauff, Orthaber, Scheucher and Wesolek.
  We study more generally the order of universal graphs for various classes (of graphs of bounded degree, treedepth, pathwidth, or treewidth), if the universal graphs retain some of the structure of the original class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19582v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Bastide, Louis Esperet, Carla Groenland, Claire Hilaire, Cl\'ement Rambaud, Alexandra Wesolek</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Identifying Groups without Abelian Normal Subgroups: Parallel, First Order, and GI-Hardness</title>
      <link>https://arxiv.org/abs/2504.19777</link>
      <description>arXiv:2504.19777v1 Announce Type: cross 
Abstract: In this paper, we exhibit an $\textsf{AC}^{3}$ isomorphism test for groups without Abelian normal subgroups (a.k.a. Fitting-free groups), a class for which isomorphism testing was previously known to be in $\mathsf{P}$ (Babai, Codenotti, and Qiao; ICALP '12). Here, we leverage the fact that $G/\text{PKer}(G)$ can be viewed as permutation group of degree $O(\log |G|)$. As $G$ is given by its multiplication table, we are able to implement the solution for the corresponding instance of Twisted Code Equivalence in $\textsf{AC}^{3}$.
  In sharp contrast, we show that when our groups are specified by a generating set of permutations, isomorphism testing of Fitting-free groups is at least as hard as Graph Isomorphism and Linear Code Equivalence (the latter being $\textsf{GI}$-hard and having no known subexponential-time algorithm).
  Lastly, we show that any Fitting-free group of order $n$ is identified by $\textsf{FO}$ formulas (without counting) using only $O(\log \log n)$ variables. This is in contrast to the fact that there are infinite families of Abelian groups that are not identified by $\textsf{FO}$ formulas with $o(\log n)$ variables (Grochow &amp; Levet, FCT '23).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19777v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <category>math.GR</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua A. Grochow, Dan Johnson, Michael Levet</dc:creator>
    </item>
    <item>
      <title>TurboQuant: Online Vector Quantization with Near-optimal Distortion Rate</title>
      <link>https://arxiv.org/abs/2504.19874</link>
      <description>arXiv:2504.19874v1 Announce Type: cross 
Abstract: Vector quantization, a problem rooted in Shannon's source coding theory, aims to quantize high-dimensional Euclidean vectors while minimizing distortion in their geometric structure. We propose TurboQuant to address both mean-squared error (MSE) and inner product distortion, overcoming limitations of existing methods that fail to achieve optimal distortion rates. Our data-oblivious algorithms, suitable for online applications, achieve near-optimal distortion rates (within a small constant factor) across all bit-widths and dimensions. TurboQuant achieves this by randomly rotating input vectors, inducing a concentrated Beta distribution on coordinates, and leveraging the near-independence property of distinct coordinates in high dimensions to simply apply optimal scalar quantizers per each coordinate. Recognizing that MSE-optimal quantizers introduce bias in inner product estimation, we propose a two-stage approach: applying an MSE quantizer followed by a 1-bit Quantized JL (QJL) transform on the residual, resulting in an unbiased inner product quantizer. We also provide a formal proof of the information-theoretic lower bounds on best achievable distortion rate by any vector quantizer, demonstrating that TurboQuant closely matches these bounds, differing only by a small constant ($\approx 2.7$) factor. Experimental results validate our theoretical findings, showing that for KV cache quantization, we achieve absolute quality neutrality with 3.5 bits per channel and marginal quality degradation with 2.5 bits per channel. Furthermore, in nearest neighbor search tasks, our method outperforms existing product quantization techniques in recall while reducing indexing time to virtually zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19874v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Zandieh, Majid Daliri, Majid Hadian, Vahab Mirrokni</dc:creator>
    </item>
    <item>
      <title>Acceleration Meets Inverse Maintenance: Faster $\ell_{\infty}$-Regression</title>
      <link>https://arxiv.org/abs/2409.20030</link>
      <description>arXiv:2409.20030v2 Announce Type: replace 
Abstract: We propose a randomized multiplicative weight update (MWU) algorithm for $\ell_{\infty}$ regression that runs in $\widetilde{O}\left(n^{2+1/22.5} \text{poly}(1/\epsilon)\right)$ time when $\omega = 2+o(1)$, improving upon the previous best $\widetilde{O}\left(n^{2+1/18} \text{poly} \log(1/\epsilon)\right)$ runtime in the low-accuracy regime. Our algorithm combines state-of-the-art inverse maintenance data structures with acceleration. In order to do so, we propose a novel acceleration scheme for MWU that exhibits {\it stabiliy} and {\it robustness}, which are required for the efficient implementations of the inverse maintenance data structures.
  We also design a faster {\it deterministic} MWU algorithm that runs in $\widetilde{O}\left(n^{2+1/12}\text{poly}(1/\epsilon)\right))$ time when $\omega = 2+o(1)$, improving upon the previous best $\widetilde{O}\left(n^{2+1/6} \text{poly} \log(1/\epsilon)\right)$ runtime in the low-accuracy regime. We achieve this by showing a novel stability result that goes beyond previously known works based on interior point methods (IPMs).
  Our work is the first to use acceleration and inverse maintenance together efficiently, finally making the two most important building blocks of modern structured convex optimization compatible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20030v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deeksha Adil, Shunhua Jiang, Rasmus Kyng</dc:creator>
    </item>
    <item>
      <title>Deterministic complexity analysis of Hermitian eigenproblems</title>
      <link>https://arxiv.org/abs/2410.21550</link>
      <description>arXiv:2410.21550v2 Announce Type: replace 
Abstract: In this work we revisit the arithmetic and bit complexity of Hermitian eigenproblems. Recently, [BGVKS, FOCS 2020] proved that a (non-Hermitian) matrix can be diagonalized with a randomized algorithm in $O(n^{\omega}\log^2(n/\epsilon))$ arithmetic operations, where $\omega\lesssim 2.371$ is the square matrix multiplication exponent, and [Shah, SODA 2025] significantly improved the bit complexity for the Hermitian case. Our main goal is to obtain similar deterministic complexity bounds for various Hermitian eigenproblems. In the Real RAM model, we show that a Hermitian matrix can be diagonalized deterministically in $O(n^{\omega}\log(n)+n^2\mathrm{polylog}(n/\epsilon))$ arithmetic operations, improving the classic deterministic $\widetilde O(n^3)$ algorithms, and derandomizing the aforementioned state-of-the-art. The main technical step is a complete, detailed analysis of a well-known divide-and-conquer tridiagonal eigensolver of Gu and Eisenstat [GE95], when accelerated with the Fast Multipole Method, asserting that it can accurately diagonalize a symmetric tridiagonal matrix in nearly-$O(n^2)$ operations. In finite precision, we show that an algorithm by Sch\"onhage [Sch72] to reduce a Hermitian matrix to tridiagonal form is stable in the floating point model, using $O(\log(n/\epsilon))$ bits of precision. This leads to a deterministic algorithm to compute all the eigenvalues of a Hermitian matrix in $O\left(n^{\omega}\mathcal{F}\left(\log(n/\epsilon)\right)+n^2\mathrm{polylog}(n/\epsilon)\right)$ bit operations, where $\mathcal{F}(b)\in\widetilde O(b)$ is the bit complexity of a single floating point operation on $b$ bits. This improves the best known $\widetilde{O}(n^3)$ deterministic and $O\left(n^{\omega}\log^2(n/\epsilon)\mathcal{F}\left(\log(n/\epsilon)\right)\right)$ randomized complexities. We conclude with some other useful subroutines and with open problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21550v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aleksandros Sobczyk</dc:creator>
    </item>
    <item>
      <title>Improved parallel derandomization via finite automata with applications</title>
      <link>https://arxiv.org/abs/2411.18028</link>
      <description>arXiv:2411.18028v2 Announce Type: replace 
Abstract: A central approach to algorithmic derandomization is the construction of small-support probability distributions that "fool" randomized algorithms, often enabling efficient parallel (NC) implementations. An abstraction of this idea is fooling polynomial-space statistical tests computed via finite automata (Sivakumar 2002); this encompasses a wide range of properties including $k$-wise independence and sums of random variables.
  We present new parallel algorithms to fool finite-state automata, with significantly reduced processor complexity. Briefly, our approach is to iteratively sparsify distributions using a work-efficient lattice rounding routine and maintain accuracy by tracking an aggregate weighted error that is determined by the Lipschitz value of the statistical tests being fooled.
  We illustrate with improved applications to the Gale-Berlekamp Switching Game and to approximate MAX-CUT via SDP rounding. These involve further several optimizations, including truncating the state space of the automata and using FFT-based convolutions to compute transition probabilities efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18028v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeff Giliberti, David G. Harris</dc:creator>
    </item>
    <item>
      <title>Complexity of Minimal Faithful Permutation Degree for Fitting-free Groups</title>
      <link>https://arxiv.org/abs/2501.16039</link>
      <description>arXiv:2501.16039v3 Announce Type: replace 
Abstract: In this paper, we investigate the complexity of computing the minimal faithful permutation degree for groups without abelian normal subgroups. When our groups are given as quotients of permutation groups, we establish that this problem is in $\textsf{P}$. Furthermore, in the setting of permutation groups, we obtain an upper bound of $\textsf{NC}$ for this problem. This improves upon the work of Das and Thakkar (STOC 2024), who established a Las Vegas polynomial-time algorithm for this class in the setting of permutation groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16039v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.GR</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Levet, Pranjal Srivastava, Dhara Thakkar</dc:creator>
    </item>
    <item>
      <title>One-Shot Learning for k-SAT</title>
      <link>https://arxiv.org/abs/2502.07135</link>
      <description>arXiv:2502.07135v2 Announce Type: replace 
Abstract: Consider a $k$-SAT formula $\Phi$ where every variable appears at most $d$ times, and let $\sigma$ be a satisfying assignment of $\Phi$ sampled proportionally to $e^{\beta m(\sigma)}$ where $m(\sigma)$ is the number of variables set to true and $\beta$ is a real parameter. Given $\Phi$ and $\sigma$, can we learn the value of $\beta$ efficiently?
  This problem falls into a recent line of works about single-sample ("one-shot") learning of Markov random fields. The $k$-SAT setting we consider here was recently studied by Galanis, Kandiros, and Kalavasis (SODA'24) where they showed that single-sample learning is possible when roughly $d\leq 2^{k/6.45}$ and impossible when $d\geq (k+1) 2^{k-1}$. Crucially, for their impossibility results they used the existence of unsatisfiable instances which, aside from the gap in $d$, left open the question of whether the feasibility threshold for one-shot learning is dictated by the satisfiability threshold of $k$-SAT formulas of bounded degree.
  Our main contribution is to answer this question negatively. We show that one-shot learning for $k$-SAT is infeasible well below the satisfiability threshold; in fact, we obtain impossibility results for degrees $d$ as low as $k^2$ when $\beta$ is sufficiently large, and bootstrap this to small values of $\beta$ when $d$ scales exponentially with $k$, via a probabilistic construction. On the positive side, we simplify the analysis of the learning algorithm and obtain significantly stronger bounds on $d$ in terms of $\beta$. In particular, for the uniform case $\beta\rightarrow 0$ that has been studied extensively in the sampling literature, our analysis shows that learning is possible under the condition $d\lesssim 2^{k/2}$. This is nearly optimal (up to constant factors) in the sense that it is known that sampling a uniformly-distributed satisfying assignment is NP-hard for $d\gtrsim 2^{k/2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07135v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Galanis, Leslie Ann Goldberg, Xusheng Zhang</dc:creator>
    </item>
    <item>
      <title>Cost Preserving Dependent Rounding for Allocation Problems</title>
      <link>https://arxiv.org/abs/2502.08267</link>
      <description>arXiv:2502.08267v2 Announce Type: replace 
Abstract: We present a dependent randomized rounding scheme, which rounds fractional solutions to integral solutions satisfying certain hard constraints on the output while preserving Chernoff-like concentration properties. In contrast to previous dependent rounding schemes, our algorithm guarantees that the cost of the rounded integral solution does not exceed that of the fractional solution. Our algorithm works for a class of assignment problems with restrictions similar to those of prior works.
  In a non-trivial combination of our general result with a classical approach from Shmoys and Tardos [Math. Programm.'93] and more recent linear programming techniques developed for the restricted assignment variant by Bansal, Sviridenko [STOC'06] and Davies, Rothvoss, Zhang [SODA'20], we derive a O(log n)-approximation algorithm for the Budgeted Santa Claus Problem. In this new variant, the goal is to allocate resources with different values to players, maximizing the minimum value a player receives, and satisfying a budget constraint on player-resource allocation costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08267v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars Rohwedder, Arman Rouhani, Leo Wennmann</dc:creator>
    </item>
    <item>
      <title>Automating the Search for Small Hard Examples to Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2504.04738</link>
      <description>arXiv:2504.04738v2 Announce Type: replace 
Abstract: Given an approximation algorithm $A$, we want to find the input with the worst approximation ratio, i.e., the input for which $A$'s output's objective value is the worst possible compared to the optimal solution's objective value. Such hard examples shed light on the approximation algorithm's weaknesses, and could help us design better approximation algorithms. When the inputs are discrete (e.g., unweighted graphs), one can find hard examples for small input sizes using brute-force enumeration. However, it's not obvious how to do this when the input space is continuous, as in makespan minimization or bin packing.
  We develop a technique for finding small hard examples for a large class of approximation algorithms. Our algorithm works by constructing a decision tree representation of the approximation algorithm and then running a linear program for each leaf node of the decision tree. We implement our technique in Python, and demonstrate it on the longest-processing-time (LPT) heuristic for makespan minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04738v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eklavya Sharma</dc:creator>
    </item>
    <item>
      <title>A New Impossibility Result for Online Bipartite Matching Problems</title>
      <link>https://arxiv.org/abs/2504.14251</link>
      <description>arXiv:2504.14251v2 Announce Type: replace 
Abstract: Online Bipartite Matching with random user arrival is a fundamental problem in the online advertisement ecosystem. Over the last 30 years, many algorithms and impossibility results have been developed for this problem. In particular, the latest impossibility result was established by Manshadi, Oveis Gharan and Saberi in 2011. Since then, several algorithms have been published in an effort to narrow the gap between the upper and the lower bounds on the competitive ratio.
  In this paper we show that no algorithm can achieve a competitive ratio better than $1- \frac e{e^e} = 0.82062\ldots$, improving upon the $0.823$ upper bound presented in (Manshadi, Oveis Gharan and Saberi, SODA 2011). Our construction is simple to state, accompanied by a fully analytic proof, and yields a competitive ratio bound intriguingly similar to $1 - \frac1e$, the optimal competitive ratio for the fully adversarial Online Bipartite Matching problem.
  Although the tightness of our upper bound remains an open question, we show that our construction is extremal in a natural class of instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14251v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Flavio Chierichetti, Mirko Giacchini, Alessandro Panconesi, Andrea Vattani</dc:creator>
    </item>
    <item>
      <title>Online metric TSP</title>
      <link>https://arxiv.org/abs/2504.17716</link>
      <description>arXiv:2504.17716v2 Announce Type: replace 
Abstract: In the online metric traveling salesperson problem, $n$ points of a metric space arrive one by one and have to be placed (immediately and irrevocably) into empty cells of a size-$n$ array. The goal is to minimize the sum of distances between consecutive points in the array. This problem was introduced by Abrahamsen, Bercea, Beretta, Klausen, and Kozma [ESA'24] as a generalization of the online sorting problem, which was introduced by Aamand, Abrahamsen, Beretta, and Kleist [SODA'23] as a tool in their study of online geometric packing problems.
  Online metric TSP has been studied for a range of fixed metric spaces. For 1-dimensional Euclidean space, the problem is equivalent to online sorting, where an optimal competitive ratio of $\Theta(\sqrt n)$ is known. For $d$-dimensional Euclidean space, the best-known upper bound is $O(2^{d} \sqrt{dn\log n})$, leaving a gap to the $\Omega(\sqrt n)$ lower bound. Finally, for the uniform metric, where all distances are 0 or 1, the optimal competitive ratio is known to be $\Theta(\log n)$.
  We study the problem for a general metric space, presenting an algorithm with competitive ratio $O(\sqrt n)$. In particular, we close the gap for $d$-dimensional Euclidean space, completely removing the dependence on dimension. One might hope to simultaneously guarantee competitive ratio $O(\sqrt n)$ in general and $O(\log n)$ for the uniform metric, but we show that this is impossible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17716v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Bertram</dc:creator>
    </item>
    <item>
      <title>Fast algorithms for least square problems with Kronecker lower subsets</title>
      <link>https://arxiv.org/abs/2209.05662</link>
      <description>arXiv:2209.05662v2 Announce Type: replace-cross 
Abstract: While leverage score sampling provides powerful tools for approximating solutions to large least squares problems, the cost of computing exact scores and sampling often prohibits practical application. This paper addresses this challenge by developing a new and efficient algorithm for exact leverage score sampling applicable to matrices that are lower column subsets of Kronecker product matrices. We synthesize relevant approximation guarantees and detail the algorithm that specifically leverages this structural property for computational efficiency. Through numerical examples, we demonstrate that utilizing efficiently computed exact leverage scores via our methods significantly reduces approximation errors, as compared to established approximate leverage score sampling strategies when applied to this important class of structured matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.05662v2</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Osman Asif Malik, Yiming Xu, Nuojin Cheng, Stephen Becker, Alireza Doostan, Akil Narayan</dc:creator>
    </item>
    <item>
      <title>Improved Decoding of Tanner Codes</title>
      <link>https://arxiv.org/abs/2501.12293</link>
      <description>arXiv:2501.12293v3 Announce Type: replace-cross 
Abstract: In this paper, we present improved decoding algorithms for expander-based Tanner codes.
  We begin by developing a randomized linear-time decoding algorithm that, under the condition that $ \delta d_0 &gt; 2 $, corrects up to $ \alpha n $ errors for a Tanner code $ T(G, C_0) $, where $ G $ is a $ (c, d, \alpha, \delta) $-bipartite expander with $n$ left vertices, and $ C_0 \subseteq \mathbb{F}_2^d $ is a linear inner code with minimum distance $ d_0 $. This result improves upon the previous work of Cheng, Ouyang, Shangguan, and Shen (RANDOM 2024), which required $ \delta d_0 &gt; 3 $.
  We further derandomize the algorithm to obtain a deterministic linear-time decoding algorithm with the same decoding radius. Our algorithm improves upon the previous deterministic algorithm of Cheng et al. by achieving a decoding radius of $ \alpha n $, compared with the previous radius of $ \frac{2\alpha}{d_0(1 + 0.5c\delta) }n$.
  Additionally, we investigate the size-expansion trade-off introduced by the recent work of Chen, Cheng, Li, and Ouyang (IEEE TIT 2023), and use it to provide new bounds on the minimum distance of Tanner codes. Specifically, we prove that the minimum distance of a Tanner code $T(G,C_0)$ is approximately $f_\delta^{-1} \left( \frac{1}{d_0} \right) \alpha n $, where $ f_\delta(\cdot) $ is the Size-Expansion Function. As another application, we improve the decoding radius of our decoding algorithms from $\alpha n$ to approximately $f_\delta^{-1}\left(\frac{2}{d_0}\right)\alpha n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12293v3</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaienhe Zhou, Zeyu Guo</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Differentially Private Regret Bounds in Linear MDPs</title>
      <link>https://arxiv.org/abs/2504.09339</link>
      <description>arXiv:2504.09339v2 Announce Type: replace-cross 
Abstract: We study regret minimization under privacy constraints in episodic inhomogeneous linear Markov Decision Processes (MDPs), motivated by the growing use of reinforcement learning (RL) in personalized decision-making systems that rely on sensitive user data. In this setting, both transition probabilities and reward functions are assumed to be linear in a feature mapping $\phi(s, a)$, and we aim to ensure privacy through joint differential privacy (JDP), a relaxation of differential privacy suited to online learning. Prior work has established suboptimal regret bounds by privatizing the LSVI-UCB algorithm, which achieves $\widetilde{O}(\sqrt{d^3 H^4 K})$ regret in the non-private setting. Building on recent advances that improve this to near minimax optimal regret $\widetilde{O}(d\sqrt{H^{3}K})$ via LSVI-UCB++ with Bernstein-style bonuses, we design a new differentially private algorithm by privatizing LSVI-UCB++ and adapting techniques for variance-aware analysis from offline RL. Our algorithm achieves a regret bound of $\widetilde{O}(d \sqrt{H^3 K} + H^{15/4} d^{7/6} K^{1/2} / \epsilon)$, improving over previous private methods. Empirical results show that our algorithm retains near-optimal utility compared to non-private baselines, indicating that privacy can be achieved with minimal performance degradation in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09339v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sharan Sahu</dc:creator>
    </item>
  </channel>
</rss>
