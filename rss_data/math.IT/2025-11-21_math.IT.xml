<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 05:02:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fluid Reconfigurable Intelligent Surface (FRIS) Enabling Secure Wireless Communications</title>
      <link>https://arxiv.org/abs/2511.15860</link>
      <description>arXiv:2511.15860v1 Announce Type: new 
Abstract: The concept of fluid reconfigurable intelligent surface (FRIS) upgrades the conventional reconfigurable intelligent surface (RIS) paradigm by empowering its reflecting elements with positioning reconfigurability. This letter aims to investigate the use of FRIS to enhance physical-layer security in a system, in which a multi-antenna access point (AP) communicates with a legitimate user device in the presence of an eavesdropper. Unlike RIS with fixed-position elements, FRIS can dynamically select an optimal subset of elements from a larger array of candidate locations. We aim to maximize the secrecy rate by jointly optimizing the AP's transmit beamforming, the selection of FRIS activated elements, and their discrete phase shifts. The resulting problem is a challenging mixed-integer nonlinear program (MINLP), which is NP-hard. To address this, we propose an efficient algorithm based on an alternating optimization (AO) framework. Within this framework, the beamforming subproblem is optimally solved in closed form using the generalized eigenvalue method, while the combinatorial subproblem of joint element selection and discrete phase design is handled via the cross-entropy optimization (CEO) method. Simulation results show that the proposed FRIS design significantly outperforms the conventional RIS counterpart and other baselines, demonstrating the substantial security gains by element positioning as the new degree of freedom (DoF).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15860v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xusheng Zhu, Kai-Kit Wong, Boyi Tang, Wen Chen, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Attention-Based Feature Online Conformal Prediction for Time Series</title>
      <link>https://arxiv.org/abs/2511.15838</link>
      <description>arXiv:2511.15838v1 Announce Type: cross 
Abstract: Online conformal prediction (OCP) wraps around any pre-trained predictor to produce prediction sets with coverage guarantees that hold irrespective of temporal dependencies or distribution shifts. However, standard OCP faces two key limitations: it operates in the output space using simple nonconformity (NC) scores, and it treats all historical observations uniformly when estimating quantiles. This paper introduces attention-based feature OCP (AFOCP), which addresses both limitations through two key innovations. First, AFOCP operates in the feature space of pre-trained neural networks, leveraging learned representations to construct more compact prediction sets by concentrating on task-relevant information while suppressing nuisance variation. Second, AFOCP incorporates an attention mechanism that adaptively weights historical observations based on their relevance to the current test point, effectively handling non-stationarity and distribution shifts. We provide theoretical guarantees showing that AFOCP maintains long-term coverage while provably achieving smaller prediction intervals than standard OCP under mild regularity conditions. Extensive experiments on synthetic and real-world time series datasets demonstrate that AFOCP consistently reduces the size of prediction intervals by as much as $88\%$ as compared to OCP, while maintaining target coverage levels, validating the benefits of both feature-space calibration and attention-based adaptive weighting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15838v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meiyi Zhu, Caili Guo, Chunyan Feng, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Generalized ovals, 2.5-dimensional additive codes, and multispreads</title>
      <link>https://arxiv.org/abs/2511.15843</link>
      <description>arXiv:2511.15843v1 Announce Type: cross 
Abstract: We present constructions and bounds for additive codes over a finite field in terms of their geometric counterpart, i.e.\ projective systems. It is known that the maximum number of $(l-1)$-spaces in $\operatorname{PG}(2,q)$, such that no hyperplane contains three, is given by $q^l+1$ if $q$ is odd. Those geometric objects are called generalized ovals. We show that cardinality $q^l+2$ is possible if we decrease the dimension a bit. We completely determine the minimum possible lengths of additive codes over $\mathbb{F}_9$ of dimension $2.5$ and give improved constructions for other small parameters. As an application, we consider multispreads in $\operatorname{PG}(4,q)$, in particular, completing the characterization of parameters of $\mathbb{F}_4$-linear $64$-ary one-weight codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15843v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denis S. Krotov, Sascha Kurz</dc:creator>
    </item>
    <item>
      <title>Neural Positioning Without External Reference</title>
      <link>https://arxiv.org/abs/2511.16352</link>
      <description>arXiv:2511.16352v1 Announce Type: cross 
Abstract: Channel state information (CSI)-based user equipment (UE) positioning with neural networks -- referred to as neural positioning -- is a promising approach for accurate off-device UE localization. Most existing methods train their neural networks with ground-truth position labels obtained from external reference positioning systems, which requires costly hardware and renders label acquisition difficult in large areas. In this work, we propose a novel neural positioning pipeline that avoids the need for any external reference positioning system. Our approach trains the positioning network only using CSI acquired off-device and relative displacement commands executed on commercial off-the-shelf (COTS) robot platforms, such as robotic vacuum cleaners -- such an approach enables inexpensive training of accurate neural positioning functions over large areas. We evaluate our method in three real-world scenarios, ranging from small line-of-sight (LoS) areas to larger non-line-of-sight (NLoS) environments, using CSI measurements acquired in IEEE 802.11 Wi-Fi and 5G New Radio (NR) systems. Our experiments demonstrate that the proposed neural positioning pipeline achieves UE localization accuracies close to state-of-the-art methods that require externally acquired high-precision ground-truth position labels for training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16352v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Till-Yannic M\"uller, Frederik Zumegen, Reinhard Wiesmayr, Emre G\"on\"ulta\c{s}, Christoph Studer</dc:creator>
    </item>
    <item>
      <title>Variational Quantum Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2511.16597</link>
      <description>arXiv:2511.16597v1 Announce Type: cross 
Abstract: The integration of sensing and communication functionalities within a common system is one of the main innovation drivers for next-generation networks. In this paper, we introduce a quantum integrated sensing and communication (QISAC) protocol that leverages entanglement in quantum carriers of information to enable both superdense coding and quantum sensing. The proposed approach adaptively optimizes encoding and quantum measurement via variational circuit learning, while employing classical machine learning-based decoders and estimators to process the measurement outcomes. Numerical results for qudit systems demonstrate that the proposed QISAC protocol can achieve a flexible trade-off between classical communication rate and accuracy of parameter estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16597v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivana Nikoloska, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Bayesian Learning for Pilot Decontamination in Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2508.11791</link>
      <description>arXiv:2508.11791v2 Announce Type: replace 
Abstract: Pilot contamination (PC) arises when the pilot sequences assigned to user equipments (UEs) are not mutually orthogonal, eventually due to their reuse. In this work, we propose a novel expectation propagation (EP)-based joint channel estimation and data detection (JCD) algorithm specifically designed to mitigate the effects of PC in the uplink of cell-free massive multiple-input multiple-output (CF-MaMIMO) systems. This modified bilinear-EP algorithm is distributed, scalable, demonstrates strong robustness to PC, and outperforms state-of-the-art Bayesian learning algorithms. Through a comprehensive performance evaluation, we assess the performance of Bayesian learning algorithms for different pilot sequences and observe that the use of non-orthogonal pilots can lead to better performance compared to shared orthogonal sequences. Motivated by this analysis, we introduce a new metric to quantify PC at the UE level. We show that the performance of the considered algorithms degrades monotonically with respect to this metric, providing a valuable theoretical and practical tool for understanding and managing PC via iterative JCD algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11791v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/WSA65299.2025.11202775</arxiv:DOI>
      <arxiv:journal_reference>2025 28th International Workshop on Smart Antennas (WSA)</arxiv:journal_reference>
      <dc:creator>Christian Forsch, Zilu Zhao, Dirk Slock, Laura Cottatellucci</dc:creator>
    </item>
    <item>
      <title>Probabilistic Guarantees to Explicit Constructions: Local Properties of Linear Codes</title>
      <link>https://arxiv.org/abs/2510.06185</link>
      <description>arXiv:2510.06185v2 Announce Type: replace 
Abstract: We present a general framework for derandomizing random linear codes with respect to a broad class of properties, known as local properties, which encompass several standard notions such as distance, list-decoding, list-recovery, and perfect hashing. Our approach extends the classical Alon-Edmonds-Luby (AEL) construction through a modified formalism of local coordinate-wise linear (LCL) properties, introduced by Levi, Mosheiff, and Shagrithaya (2025). The main theorem demonstrates that if random linear codes satisfy the complement of an LCL property $\mathcal{P}$ with high probability, then one can construct explicit codes satisfying the complement of $\mathcal{P}$ as well, with an enlarged yet constant alphabet size. This gives the first explicit constructions for list recovery, as well as special cases (e.g., list recovery with erasures, zero-error list recovery, perfect hash matrices), with parameters matching those of random linear codes. More broadly, our constructions realize the full range of parameters associated with these properties at the same level of optimality as in the random setting, thereby offering a systematic pathway from probabilistic guarantees to explicit codes that attain them. Furthermore, our derandomization of random linear codes also admits efficient (list) decoding via recently developed expander-based decoders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06185v2</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Granha Jeronimo, Nikhil Shagrithaya</dc:creator>
    </item>
    <item>
      <title>Non-Linear Precoding via Dirty Paper Coding for Near-Field Downlink MISO Communications</title>
      <link>https://arxiv.org/abs/2510.13485</link>
      <description>arXiv:2510.13485v2 Announce Type: replace 
Abstract: In 6G systems, extremely large-scale antenna arrays operating at terahertz frequencies extend the near-field region to typical user distances from the base station, enabling near-field communication (NFC) with fine spatial resolution through beamfocusing. Existing multiuser NFC systems predominantly employ linear precoding techniques such as zero-forcing (ZF), which suffer from performance degradation due to the high transmit power required to suppress interference. This paper proposes a nonlinear precoding framework based on Dirty Paper Coding (DPC), which pre-cancels known interference to maximize the sum-rate performance. We formulate and solve the corresponding sum-rate maximization problems, deriving optimal power allocation strategies for both DPC and ZF schemes. Extensive simulations demonstrate that DPC achieves substantial sum-rate gains over ZF across various near-field configurations, with the most pronounced improvements observed for closely spaced users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13485v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Kulkarni, Rajshekhar V Bhat</dc:creator>
    </item>
    <item>
      <title>Overlapped-repetition Shor codes achieving fourfold asymptotic rate</title>
      <link>https://arxiv.org/abs/2510.21030</link>
      <description>arXiv:2510.21030v2 Announce Type: replace 
Abstract: Introducing controlled overlap among a few repetition blocks yields a fourfold asymptotic rate improvement while preserving an average stabilizer weight of \(4\). Substituting the overlapped outer layer with an LDPC code further produces a family of constructions with asymptotic rate \(2/d\). We also describe a constant-excitation variant that suppresses collective coherent errors without additional overhead, as well as a bosonic generalization that extends the framework to oscillator encodings. The resulting family achieves a code rate intermediate between that of the rotated surface code (average stabilizer weight \(4\)) and the BB code (average stabilizer weight \(6\)), while remaining free of the performance degradation typical of iterative decoders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21030v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>En-Jui Chang</dc:creator>
    </item>
    <item>
      <title>A Construction of Infinite Families of Self-Orthogonal Quasi-Cyclic Codes Using Constituent Codes.pdf</title>
      <link>https://arxiv.org/abs/2511.02813</link>
      <description>arXiv:2511.02813v2 Announce Type: replace 
Abstract: Quasi-cyclic codes have been recently employed in the constructions of quantum error-correcting codes. In this paper, we propose a construction of infinite families of quasi-cyclic codes which are self-orthogonal with respect to the Euclidean and Hermitian inner products. In particular, their dimension and a lower bound for their minimum distance are computed using their constituent codes defined over field extensions of $\mathbb{F}_q$. We also show that the lower bound for the minimum distance satisfies the square-root-like lower bound and also show how self-dual quasi-cyclic codes can arise from our construction. Using the CSS construction, we show the existence of quantum error-correcting codes with good parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02813v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gustavo Terra Bastos, Angelynn \'Alvarez, Cameron Williams</dc:creator>
    </item>
    <item>
      <title>Guessing Decoding of Short Blocklength Codes</title>
      <link>https://arxiv.org/abs/2511.12108</link>
      <description>arXiv:2511.12108v2 Announce Type: replace 
Abstract: Future beyond-5G and 6G systems demand ultra-reliable, low-latency communication with short blocklengths, motivating the development of universal decoding algorithms. Guessing decoding, which infers the noise or codeword candidate in order of decreasing (exact or approximate) likelihood, offers a universal framework applicable to short codes. In this paper, we present a unified treatment of two prominent recent families of guessing decoding: guessing random additive noise decoding (GRAND) and guessing codeword decoding (GCD). For each, we (i) present algorithmic implementations and ordering strategies; (ii) prove maximum-likelihood (ML) optimality under appropriate stopping criteria; (iii) derive saddle-point approximations for the average number of queries; and (iv) validate theoretical predictions with simulations. We further analyze the performance degradation due to limited search budgets relative to ML performance, compare key metrics (worst-case and average complexity, hardware considerations), and highlight how advances in one approach transfer naturally to the other. Our results clarify the operating regimes where GRAND and GCD demonstrate superior performance. This work provides both theoretical insights and practical guidelines for deploying universal guessing decoders in next-generation short-blocklength communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12108v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianfan Wang, Jifan Liang, Peihong Yuan, Ken R. Duffy, Muriel M\'edard, Xiao Ma</dc:creator>
    </item>
    <item>
      <title>Measuring and Controlling Solution Degeneracy across Task-Trained Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2410.03972</link>
      <description>arXiv:2410.03972v3 Announce Type: replace-cross 
Abstract: Task-trained recurrent neural networks (RNNs) are widely used in neuroscience and machine learning to model dynamical computations. To gain mechanistic insight into how neural systems solve tasks, prior work often reverse-engineers individual trained networks. However, different RNNs trained on the same task and achieving similar performance can exhibit strikingly different internal solutions, a phenomenon known as solution degeneracy. Here, we develop a unified framework to systematically quantify and control solution degeneracy across three levels: behavior, neural dynamics, and weight space. We apply this framework to 3,400 RNNs trained on four neuroscience-relevant tasks: flip-flop memory, sine wave generation, delayed discrimination, and path integration, while systematically varying task complexity, learning regime, network size, and regularization. We find that higher task complexity and stronger feature learning reduce degeneracy in neural dynamics but increase it in weight space, with mixed effects on behavior. In contrast, larger networks and structural regularization reduce degeneracy at all three levels. These findings empirically validate the Contravariance Principle and provide practical guidance for researchers seeking to tune the variability of RNN solutions, either to uncover shared neural mechanisms or to model the individual variability observed in biological systems. This work provides a principled framework for quantifying and controlling solution degeneracy in task-trained RNNs, offering new tools for building more interpretable and biologically grounded models of neural computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03972v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ann Huang, Satpreet H. Singh, Flavio Martinelli, Kanaka Rajan</dc:creator>
    </item>
    <item>
      <title>Theoretical Guarantees for AOA-based Localization: Consistency and Asymptotic Efficiency</title>
      <link>https://arxiv.org/abs/2507.07647</link>
      <description>arXiv:2507.07647v2 Announce Type: replace-cross 
Abstract: We study the problem of signal source localization using angle of arrival (AOA) measurements. We begin by presenting verifiable geometric conditions for sensor deployment that ensure the model's asymptotic localizability. Then we establish the consistency and asymptotic efficiency of the maximum likelihood (ML) estimator. However, obtaining the ML estimator is challenging due to its association with a non-convex optimization problem. To address this, we propose an asymptotically efficient two-step estimator that matches the ML estimator's asymptotic properties while achieving low computational complexity (linear in the number of measurements). The primary challenge lies in obtaining a consistent estimator in the first step. To achieve this, we construct a linear least squares problem through algebraic operations on the measurement nonlinear model to first obtain a biased closed-form solution. We then eliminate the bias using the data to yield an asymptotically unbiased and consistent estimator. In the second step, we perform a single Gauss-Newton iteration using the preliminary consistent estimator as the initial value, achieving the same asymptotic properties as the ML estimator. Finally, simulation results demonstrate the superior performance of the proposed two-step estimator for large sample sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07647v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenghua Hu, Guangyang Zeng, Wenchao Xue, Haitao Fang, Biqiang Mu</dc:creator>
    </item>
    <item>
      <title>Credible Uncertainty Quantification under Noise and System Model Mismatch</title>
      <link>https://arxiv.org/abs/2509.03311</link>
      <description>arXiv:2509.03311v4 Announce Type: replace-cross 
Abstract: State estimators often provide self-assessed uncertainty metrics, such as covariance matrices, whose credibility is critical for downstream tasks. However, these self-assessments can be misleading due to underlying modeling violations like noise model mismatch (NMM) or system model misspecification (SMM). This letter addresses this problem by developing a unified, multi-metric framework that integrates noncredibility index (NCI), negative log-likelihood (NLL), and energy score (ES) metrics, featuring an empirical location test (ELT) to detect system model bias and a directional probing technique that uses the metrics' asymmetric sensitivities to distinguish NMM from SMM. Monte Carlo simulations reveal that the proposed method achieves excellent diagnosis accuracy (80-100%) and significantly outperforms single-metric diagnosis methods. The effectiveness of the proposed method is further validated on a real-world UWB positioning dataset. This framework provides a practical tool for turning patterns of credibility indicators into actionable diagnoses of model deficiencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03311v4</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Penggao Ya, Li-Ta Hsu, Rui Sun</dc:creator>
    </item>
  </channel>
</rss>
