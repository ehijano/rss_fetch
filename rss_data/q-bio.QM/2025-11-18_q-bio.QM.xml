<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Nov 2025 02:48:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Protein Structure Tokenization via Geometric Byte Pair Encoding</title>
      <link>https://arxiv.org/abs/2511.11758</link>
      <description>arXiv:2511.11758v1 Announce Type: new 
Abstract: Protein structure is central to biological function, and enabling multimodal protein models requires joint reasoning over sequence, structure, and function. A key barrier is the lack of principled protein structure tokenizers (PSTs): existing approaches fix token size or rely on continuous vector codebooks, limiting interpretability, multi-scale control, and transfer across architectures. We introduce GeoBPE, a geometry-grounded PST that transforms continuous, noisy, multi-scale backbone conformations into discrete ``sentences'' of geometry while enforcing global constraints. Analogous to byte-pair encoding, GeoBPE generates a hierarchical vocabulary of geometric primitives by iteratively (i) clustering Geo-Pair occurrences with k-medoids to yield a resolution-controllable vocabulary; (ii) quantizing each Geo-Pair to its closest medoid prototype; and (iii) reducing drift through differentiable inverse kinematics that optimizes boundary glue angles under an $\mathrm{SE}(3)$ end-frame loss. GeoBPE offers compression ($&gt;$10x reduction in bits-per-residue at similar distortion rate), data efficiency ($&gt;$10x less training data), and generalization (maintains test/train distortion ratio of $1.0-1.1$). It is architecture-agnostic: (a) its hierarchical vocabulary provides a strong inductive bias for coarsening residue-level embeddings from large PLMs into motif- and protein-level representations, consistently outperforming leading PSTs across $12$ tasks and $24$ test splits; (b) paired with a transformer, GeoBPE supports unconditional backbone generation via language modeling; and (c) tokens align with CATH functional families and support expert-interpretable case studies, offering functional meaning absent in prior PSTs. Code is available at https://github.com/shiningsunnyday/PT-BPE/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11758v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Sun, Weize Yuan, Gang Liu, Wojciech Matusik, Marinka Zitnik</dc:creator>
    </item>
    <item>
      <title>SarcGraph for High-Throughput Regional Analysis of Sarcomere Organization and Contractile Function in 2D Cardiac Muscle Bundles</title>
      <link>https://arxiv.org/abs/2511.11913</link>
      <description>arXiv:2511.11913v1 Announce Type: new 
Abstract: Timelapse images of human induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) provide rich information on cell structure and contractile function. However, it is challenging to reproducibly generate tissue samples and conduct scalable experiments with these cells. The two-dimensional cardiac muscle bundle (2DMB) platform helps address these limitations by standardizing tissue geometry, resulting in physiologic, uniaxial contractions of discrete tissues on an elastomeric substrate with stiffness similar to the heart. 2DMBs are highly conducive to sarcomere imaging using fluorescent reporters, but, due to their larger and more physiologic sarcomere displacements and velocities, prior sarcomere-tracking pipelines have been unreliable. Here, we present adaptations to SarcGraph, an open-source Python package for sarcomere detection and tracking, that enable automated analysis of high-frame-rate 2DMB recordings. Key modifications to the pipeline include: 1) switching to a frame-by-frame sarcomere detection approach and automating tissue segmentation with spatial partitioning, 2) performing Gaussian Process Regression for signal denoising, and 3) incorporating an automatic contractile phase detection pipeline. These enhancements enable the extraction of structural organization and functional contractility metrics for both the whole 2DMB tissue and distinct tissue regions, both in a fully automated manner. We complement this software release with a dataset of 130 example movies of baseline and drug-treated samples disseminated through the Harvard Dataverse. By providing open-source tools and datasets, we aim to enable high-throughput analysis of engineered cardiac tissues and advance collective progress within the hiPSC-CM research community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11913v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saeed Mohammadzadeh, Yao-Chang Tsan, Aaron Renberg, Hiba Kobeissi, Adam Helms, Emma Lejeune</dc:creator>
    </item>
    <item>
      <title>Explainable deep learning framework for cancer therapeutic target prioritization leveraging PPI centrality and node embeddings</title>
      <link>https://arxiv.org/abs/2511.12463</link>
      <description>arXiv:2511.12463v1 Announce Type: new 
Abstract: We developed an explainable deep learning framework integrating protein-protein interaction (PPI) network centrality metrics with node embeddings for cancer therapeutic target prioritization. A high-confidence PPI network was constructed from STRING database interactions, computing six centrality metrics: degree, strength, betweenness, closeness, eigenvector centrality, and clustering coefficient. Node2Vec embeddings captured latent network topology. Combined features trained XGBoost and neural network classifiers using DepMap CRISPR essentiality scores as ground truth. Model interpretability was assessed through GradientSHAP analysis quantifying feature contributions. We developed a novel blended scoring approach combining model probability predictions with SHAP attribution magnitudes for enhanced gene prioritization. Our framework achieved state-of-the-art performance with AUROC of 0.930 and AUPRC of 0.656 for identifying the top 10\% most essential genes. GradientSHAP analysis revealed centrality measures contributed significantly to predictions, with degree centrality showing strongest correlation ($\rho$ = -0.357) with gene essentiality. The blended scoring approach created robust gene prioritization rankings, successfully identifying known essential genes including ribosomal proteins (RPS27A, RPS17, RPS6) and oncogenes (MYC). This study presents a human-based, combinatorial \textit{in silico} framework successfully integrating network biology with explainable AI for therapeutic target discovery. The framework provides mechanistic transparency through feature attribution analysis while maintaining state-of-the-art predictive performance. Its reproducible design and reliance on human molecular datasets demonstrate a reduction-to-practice example of next-generation, animal-free modeling for cancer therapeutic target discovery and prioritization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12463v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adham M. Alkhadrawi, Kyungsu Kim, Arif M. Rahman</dc:creator>
    </item>
    <item>
      <title>Brain Networks Flow-Topology via Variance Minimization in the Wasserstein Space</title>
      <link>https://arxiv.org/abs/2511.12990</link>
      <description>arXiv:2511.12990v1 Announce Type: new 
Abstract: This work introduces a novel framework for testing topological variability in weighted networks by combining Hodge decomposition with Wasserstein variance minimization. Traditional approaches that analyze raw edge weights are susceptible to noise driven perturbations, limiting their ability to detect meaningful structural differences between network populations. Network signals are decomposed into various components using combinatorial Hodge theory, then topological disparity is quantified via the 2-Wasserstein distance between persistence diagrams. The test statistic measures variance reduction when comparing within group to between group dispersions in the Wasserstein space. Simulations demonstrate that the proposed method suppresses small random perturbations while maintaining sensitivity to genuine topological differences, particularly when applied to Hodge decomposed flows rather than raw edge weights. The framework is applied to functional brain networks from the Multimodal Treatment of ADHD dataset, comparing cannabis users and non-users</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12990v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sixtus Dakurah</dc:creator>
    </item>
    <item>
      <title>Bridging the genotype-phenotype gap with generative artificial intelligence</title>
      <link>https://arxiv.org/abs/2511.13141</link>
      <description>arXiv:2511.13141v1 Announce Type: new 
Abstract: The genotype-phenotype gap is a persistent barrier to complex trait genetic dissection, worsened by the explosive growth of genomic data (1.5 billion variants identified in the UK Biobank WGS study) alongside persistently scarce and subjective human-defined phenotypes. Digital phenotyping offers a potential solution, yet existing tools fail to balance scalable non-manual phenotype generation and biological interpretability of these quantitative traits. Here we report AIPheno, the first generative AI-driven "phenotype sequencer" that bridges this gap. It enables high-throughput, unsupervised extraction of digital phenotypes from imaging data and unlocks their biological meaning via generative network analysis. AIPheno transforms imaging modalities into a rich source of quantitative traits, dramatically enhancing cross-species genetic discovery, including novel loci such as CCBE1 (humans), KITLG-TMTC3 (domestic pigeons), and SOD2-IGF2R (swine). Critically, its generative module decodes AI-derived phenotypes by synthesizing variant-specific images to yield actionable biological insights. For example, it clarifies how the OCA2-HERC2 locus pleiotropically links pigmentation to retinal vascular traits via vascular visibility modulation. Integrating scalable non-manual phenotyping, enhanced genetic discovery power, and generative mechanistic decoding, AIPheno establishes a transformative closed-loop paradigm. This work addresses the longstanding genotype-phenotype imbalance, redefines digital phenotype utility, and accelerates translation of genetic associations into actionable understanding with profound implications for human health and agriculture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13141v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangfan Liu, Xiong Xiong, Yong Liao, Mingli Qin, Zhen Huang, Shilin Zhu, Lilin Yin, Yuhua Fu, Haohao Zhang, Jingya Xu, Dong Yin, Xin Huang, Yuan Quan, Xuan Li, Tengfei Jiang, Wanneng Yang, Xiaohui Yuan, Laurent Frantz, Xinyun Li, Xiaolei Liu, Shuhong Zhao</dc:creator>
    </item>
    <item>
      <title>Causal Inference, Biomarker Discovery, Graph Neural Network, Feature Selection</title>
      <link>https://arxiv.org/abs/2511.13295</link>
      <description>arXiv:2511.13295v1 Announce Type: new 
Abstract: Biomarker discovery from high-throughput transcriptomic data is crucial for advancing precision medicine. However, existing methods often neglect gene-gene regulatory relationships and lack stability across datasets, leading to conflation of spurious correlations with genuine causal effects. To address these issues, we develop a causal graph neural network (Causal-GNN) method that integrates causal inference with multi-layer graph neural networks (GNNs). The key innovation is the incorporation of causal effect estimation for identifying stable biomarkers, coupled with a GNN-based propensity scoring mechanism that leverages cross-gene regulatory networks. Experimental results demonstrate that our method achieves consistently high predictive accuracy across four distinct datasets and four independent classifiers. Moreover, it enables the identification of more stable biomarkers compared to traditional methods. Our work provides a robust, efficient, and biologically interpretable tool for biomarker discovery, demonstrating strong potential for broad application across medical disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13295v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaowang Lan, Jingxin Wu, Yulong Yuan, Chuxun Liu, Huangyi Kang, Caihua Liu</dc:creator>
    </item>
    <item>
      <title>Socrates-Mol: Self-Oriented Cognitive Reasoning through Autonomous Trial-and-Error with Empirical-Bayesian Screening for Molecules</title>
      <link>https://arxiv.org/abs/2511.11769</link>
      <description>arXiv:2511.11769v1 Announce Type: cross 
Abstract: Molecular property prediction is fundamental to chemical engineering applications such as solvent screening. We present Socrates-Mol, a framework that transforms language models into empirical Bayesian reasoners through context engineering, addressing cold start problems without model fine-tuning. The system implements a reflective-prediction cycle where initial outputs serve as priors, retrieved molecular cases provide evidence, and refined predictions form posteriors, extracting reusable chemical rules from sparse data. We introduce ranking tasks aligned with industrial screening priorities and employ cross-model self-consistency across five language models to reduce variance. Experiments on amine solvent LogP prediction reveal task-dependent patterns: regression achieves 72% MAE reduction and 112% R-squared improvement through self-consistency, while ranking tasks show limited gains due to systematic multi-model biases. The framework reduces deployment costs by over 70% compared to full fine-tuning, providing a scalable solution for molecular property prediction while elucidating the task-adaptive nature of self-consistency mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11769v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangru Wang, Zekun Jiang, Heng Yang, Cheng Tan, Xingying Lan, Chunming Xu, Tianhang Zhou</dc:creator>
    </item>
    <item>
      <title>The Probabilistic Foundations of Surveillance Failure: From False Alerts to Structural Bias</title>
      <link>https://arxiv.org/abs/2511.12459</link>
      <description>arXiv:2511.12459v1 Announce Type: cross 
Abstract: For decades, forensic statisticians have debated whether searching large DNA databases undermines the evidential value of a match. Modern surveillance faces an exponentially harder problem: screening populations across thousands of attributes using threshold rules rather than exact matching. Intuition suggests that requiring many coincidental matches should make false alerts astronomically unlikely. This intuition fails.
  Consider a system that monitors 1,000 attributes, each with a 0.5 percent innocent match rate. Matching 15 pre-specified attributes has probability \(10^{-35}\), one in 30 decillion, effectively impossible. But operational systems require no such specificity. They might flag anyone who matches \emph{any} 15 of the 1,000. In a city of one million innocent people, this produces about 226 false alerts. A seemingly impossible event becomes all but guaranteed. This is not an implementation flaw but a mathematical consequence of high-dimensional screening.
  We identify fundamental probabilistic limits on screening reliability. Systems undergo sharp transitions from reliable to unreliable with small increases in data scale, a fragility worsened by data growth and correlations. As data accumulate and correlation collapses effective dimensionality, systems enter regimes where alerts lose evidential value even when individual coincidences remain vanishingly rare. This framework reframes the DNA database controversy as a shift between operational regimes. Unequal surveillance exposures magnify failure, making ``structural bias'' mathematically inevitable. These limits are structural: beyond a critical scale, failure cannot be prevented through threshold adjustment or algorithmic refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12459v1</guid>
      <category>stat.ME</category>
      <category>cs.CY</category>
      <category>math.PR</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Pollanen</dc:creator>
    </item>
    <item>
      <title>Departures: Distributional Transport for Single-Cell Perturbation Prediction with Neural Schr\"odinger Bridges</title>
      <link>https://arxiv.org/abs/2511.13124</link>
      <description>arXiv:2511.13124v1 Announce Type: cross 
Abstract: Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schr\"odinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13124v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changxi Chi, Yufei Huang, Jun Xia, Jiangbin Zheng, Yunfan Liu, Zelin Zang, Stan Z. Li</dc:creator>
    </item>
    <item>
      <title>BIOMERO 2.0: end-to-end FAIR infrastructure for bioimaging data import, analysis, and provenance</title>
      <link>https://arxiv.org/abs/2511.13611</link>
      <description>arXiv:2511.13611v1 Announce Type: cross 
Abstract: We present BIOMERO 2.0, a major evolution of the BIOMERO framework that transforms OMERO into a FAIR-compliant (findable, accessible, interoperable, and reusable), provenance-aware bioimaging platform. BIOMERO 2.0 integrates data import, preprocessing, analysis, and workflow monitoring through an OMERO.web plugin and containerized components. The importer subsystem facilitates in-place import using containerized preprocessing and metadata enrichment via forms, while the analyzer subsystem coordinates and tracks containerized analyses on high-performance computing systems via the BIOMERO Python library. All imports and analyses are recorded with parameters, versions, and results, ensuring real-time provenance accessible through integrated dashboards. This dual approach places OMERO at the heart of the bioimaging analysis process: the importer ensures provenance from image acquisition through preprocessing and import into OMERO, while the analyzer records it for downstream processing. These integrated layers enhance OMEROs FAIRification, supporting traceable, reusable workflows for image analysis that bridge the gap between data import, analysis, and sharing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13611v1</guid>
      <category>cs.SE</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Torec T. Luik (Amsterdam UMC, Department of Medical Biology, Amsterdam, The Netherlands), Joost de Folter (Amsterdam UMC, Department of Medical Biology, Amsterdam, The Netherlands, The Francis Crick Institute, London, United Kingdom), Rodrigo Rosas-Bertolini (Independent Researcher, Brussels, Belgium), Eric A. J. Reits (Amsterdam UMC, Department of Medical Biology, Amsterdam, The Netherlands), Ron A. Hoebe (Amsterdam UMC, Department of Medical Biology, Amsterdam, The Netherlands), Przemek M. Krawczyk (Amsterdam UMC, Department of Medical Biology, Amsterdam, The Netherlands)</dc:creator>
    </item>
    <item>
      <title>Fractal Geometry and Fractional Calculus for Integrative Morphological Mapping of Breast Cancer Complexity</title>
      <link>https://arxiv.org/abs/2505.07338</link>
      <description>arXiv:2505.07338v2 Announce Type: replace 
Abstract: Breast cancer exhibits intricate morphological and dynamical heterogeneity across cellular, tissue, and tumor scales, posing challenges to conventional modeling approaches that fail to capture its nonlinear, self-similar, or self-affine, and memory-dependent behavior. Despite increasing applications of fractal geometry and fractional calculus in cancer modeling, their methodological integration and biological interpretation remain insufficiently consolidated. This review aims to synthesize these frameworks within an integrative morphological perspective to elucidate their collective potential for quantitative characterization of breast cancer complexity. Fractal geometry-based analyses quantify spatial and temporal irregularities along with spatiotemporal morphodynamics, while fractional calculus introduces non-local and memory-dependent formulations describing tumor growth. Together, these frameworks establish a mathematical link between fractal structure and fractional dynamics. Nevertheless, their application remains hindered by inconsistent methodologies and a lack of reproducible standards. This review consolidates existing evidence, delineates methodological interrelations between fractal geometry and fractional calculus, and outlines reproducibility requirements, including standardized preprocessing, parameter reporting, and benchmark datasets. Collectively, the findings emphasize that reproducible and biologically interpretable integration of these two approaches is fundamental to achieving clinically relevant modeling of breast cancer morphology and dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07338v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhijeet Das, Ramray Bhat, Mohit Kumar Jolly</dc:creator>
    </item>
    <item>
      <title>Phospho-Proteomics Method Optimization and Application to Stimulated Jurkat Cells</title>
      <link>https://arxiv.org/abs/2511.02932</link>
      <description>arXiv:2511.02932v2 Announce Type: replace 
Abstract: In clinical proteomics, available input is often limited. In addition, phospho-proteomics is of particular interest since the dysregulation of these post-translational modifications (PTMs) has been implicated in various diseases such as cancer. We therefore assessed the feasibility of low input phospho-proteomics via phospho-bulk titration and low-input starting material. We found that there was identification of more phospho-peptides through phospho-bulk titration because of sample loss during preparation of low input starting material. Additionally, we explored various lysis buffers and boiling times for efficiency of decrosslinking formalin-fixed cells since cells and tissues are often fixed for preservation and sorting via FACS. We found that boiling in 0.05M Tris pH 7.6 with 5% SDS for 60 min yielded the highest number of phospho-peptides. Lastly, we applied Evotips Pure and phospho-bulk titration to treated Jurkat cells and identified 7 phospho-sites involved in T-cell stimulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02932v2</guid>
      <category>q-bio.QM</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Teresia Ndungu, Jana Zecha, Lisa Cazares, Sonja Hess</dc:creator>
    </item>
    <item>
      <title>Unlocking tropical forest complexity: How tree assemblages in secondary forests boost biodiversity conservation</title>
      <link>https://arxiv.org/abs/2503.02523</link>
      <description>arXiv:2503.02523v2 Announce Type: replace-cross 
Abstract: Secondary forests now dominate tropical landscapes and play a crucial role in achieving COP15 conservation objectives. This study develops a replicable national approach to identifying and characterising forest ecosystems, with a focus on the role of secondary forests. We hypothesised that dominant tree species in the forest canopy serve as reliable indicators for delineating forest ecosystems and untangling biodiversity complexity. Using national inventories, we identified in situ clusters through hierarchical clustering based on dominant species abundance dissimilarity, determined using the Importance Variable Index. These clusters were characterised by analysing species assemblages and their interactions. We then applied object-oriented Random Forest modelling, segmenting the national forest cover using NDVI to identify the forest ecosystems derived from in situ clusters. Freely available spectral (Sentinel-2) and environmental data were used in the model to delineate and characterise key forest ecosystems. We finished with an assessment of distribution of secondary and old-growth forests within ecosystems. In Costa Rica, 495 dominant tree species defined 10 in situ clusters, with 7 main clusters successfully modelled. The modelling (F1-score: 0.73, macro F1-score: 0.58) and species-based characterisation highlighted the main ecological trends of these ecosystems, which are distinguished by specific species dominance, topography, climate, and vegetation dynamics, aligning with local forest classifications. The analysis of secondary forest distribution provided an initial assessment of ecosystem vulnerability by evaluating their role in forest maintenance and dynamics. This approach also underscored the major challenge of in situ data acquisition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02523v2</guid>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/ece3.72428</arxiv:DOI>
      <arxiv:journal_reference>Ecology &amp; Evolution 15, e72428 (2025)</arxiv:journal_reference>
      <dc:creator>Ma\"iri Souza Oliveira, Maxime Lenormand, Sandra Luque, Nelson A. Zamora, Samuel Alleaume, Adriana C. Aguilar Porras, Marvin U. Castillo, Eduardo Chac\'on-Madrigal, Diego Delgado, Luis Gustavo Hern\'andez S\'anchez, Marie-Ange Ngo Bieng, Ruperto M. Quesada, Gilberth S. Solano, Pedro M. Z\'u\~niga</dc:creator>
    </item>
    <item>
      <title>A practical identifiability criterion leveraging weak-form parameter estimation</title>
      <link>https://arxiv.org/abs/2506.17373</link>
      <description>arXiv:2506.17373v3 Announce Type: replace-cross 
Abstract: In this work, we define a practical identifiability criterion, (e, q)-identifiability, based on a parameter e, reflecting the noise in observed variables, and a parameter q, reflecting the mean-square error of the parameter estimator. This criterion is better able to encompass changes in the quality of the parameter estimate due to increased noise in the data (compared to existing criteria based solely on average relative errors). Furthermore, we leverage a weak-form equation error-based method of parameter estimation for systems with unobserved variables to assess practical identifiability far more quickly in comparison to output error-based parameter estimation. We do so by generating weak-form input-output equations using differential algebra techniques, as previously proposed by Boulier et al [1], and then applying Weak form Estimation of Nonlinear Dynamics (WENDy) to obtain parameter estimates. This method is computationally efficient and robust to noise, as demonstrated through two classical biological modelling examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17373v3</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nora Heitzman-Breen, Vanja Dukic, David M. Bortz</dc:creator>
    </item>
    <item>
      <title>A cautionary tale of model misspecification and identifiability</title>
      <link>https://arxiv.org/abs/2507.04894</link>
      <description>arXiv:2507.04894v3 Announce Type: replace-cross 
Abstract: Mathematical models are routinely applied to interpret biological data, with common goals that include both prediction and parameter estimation. A challenge in mathematical biology, in particular, is that models are often complex and non-identifiable, while data are limited. Rectifying identifiability through simplification can seemingly yield more precise parameter estimates, albeit, as we explore in this perspective, at the potentially catastrophic cost of introducing model misspecification and poor accuracy. We demonstrate how uncertainty in model structure can be propagated through to uncertainty in parameter estimates using a semi-parametric Gaussian process approach that delineates parameters of interest from uncertainty in model terms. Specifically, we study generalised logistic growth with an unknown crowding function, and a spatially resolved process described by a partial differential equation with a time-dependent diffusivity parameter. Allowing for structural model uncertainty yields more robust and accurate parameter estimates, and a better quantification of remaining uncertainty. We conclude our perspective by discussing the connections between identifiability and model misspecification, and alternative approaches to dealing with model misspecification in mathematical biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04894v3</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander P Browning, Jennifer A Flegg, Ryan J Murphy</dc:creator>
    </item>
    <item>
      <title>A nonparametric approach to practical identifiability of nonlinear mixed effects models</title>
      <link>https://arxiv.org/abs/2507.20288</link>
      <description>arXiv:2507.20288v2 Announce Type: replace-cross 
Abstract: Mathematical modelling is a widely used approach to understand and interpret clinical trial data. This modelling typically involves fitting mechanistic mathematical models to data from individual trial participants. Despite the widespread adoption of this individual-based fitting, it is becoming increasingly common to take a hierarchical approach to parameter estimation, where modellers characterize the population parameter distributions, rather than considering each individual independently. This hierarchical parameter estimation is standard in pharmacometric modelling. However, many of the existing techniques for parameter identifiability do not immediately translate from the individual-based fitting to the hierarchical setting. Here, we propose a nonparametric approach to study practical identifiability within a hierarchical parameter estimation framework. We focus on the commonly used nonlinear mixed effects framework and investigate two well-studied examples from the pharmacometrics and viral dynamics literature to illustrate the potential utility of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20288v2</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tyler Cassidy, Stuart T. Johnston, Michael Plank, Imke Botha, Jennifer A. Flegg, Ryan J. Murphy, Sara Hamis</dc:creator>
    </item>
    <item>
      <title>Integrating Genomics into Multimodal EHR Foundation Models</title>
      <link>https://arxiv.org/abs/2510.23639</link>
      <description>arXiv:2510.23639v3 Announce Type: replace-cross 
Abstract: This paper introduces an innovative Electronic Health Record (EHR) foundation model that integrates Polygenic Risk Scores (PRS) as a foundational data modality, moving beyond traditional EHR-only approaches to build more holistic health profiles. Leveraging the extensive and diverse data from the All of Us (AoU) Research Program, this multimodal framework aims to learn complex relationships between clinical data and genetic predispositions. The methodology extends advancements in generative AI to the EHR foundation model space, enhancing predictive capabilities and interpretability. Evaluation on AoU data demonstrates the model's predictive value for the onset of various conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay between PRS and EHR data. The work also explores transfer learning for custom classification tasks, showcasing the architecture's versatility and efficiency. This approach is pivotal for unlocking new insights into disease prediction, proactive health management, risk stratification, and personalized treatment strategies, laying the groundwork for more personalized, equitable, and actionable real-world evidence generation in healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23639v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jonathan Amar, Edward Liu, Alessandra Breschi, Liangliang Zhang, Pouya Kheradpour, Sylvia Li, Lisa Soleymani Lehmann, Alessandro Giulianelli, Matt Edwards, Yugang Jia, David Nola, Raghav Mani, Pankaj Vats, Jesse Tetreault, T. J. Chen, Cory Y. McLean</dc:creator>
    </item>
  </channel>
</rss>
