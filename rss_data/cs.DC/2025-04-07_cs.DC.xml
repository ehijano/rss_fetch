<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Apr 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Distributed Locking: Performance Analysis and Optimization Strategies</title>
      <link>https://arxiv.org/abs/2504.03073</link>
      <description>arXiv:2504.03073v1 Announce Type: new 
Abstract: Distributed locking mechanisms are fundamental to ensuring data consistency and integrity in distributed systems. This paper presents a comprehensive analysis of distributed locking algorithms, focusing on their performance characteristics under various workload conditions. We compare traditional centralized locking approaches with modern distributed protocols, evaluating them based on throughput, latency, and scalability metrics. Our experimental results demonstrate that optimized distributed locking protocols can achieve up to 68\% better performance compared to centralized approaches in high-contention scenarios, while maintaining strong consistency guarantees. Furthermore, we propose novel optimizations for distributed locking that significantly reduce coordination overhead in geo-distributed deployments. The findings contribute to the growing body of knowledge on designing efficient concurrency control mechanisms for modern distributed systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03073v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Andre Rodriguez, William Osborn</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Distributed Delta Coloring</title>
      <link>https://arxiv.org/abs/2504.03080</link>
      <description>arXiv:2504.03080v1 Announce Type: new 
Abstract: The $\Delta$-vertex coloring problem has become one of the prototypical problems for understanding the complexity of local distributed graph problems on constant-degree graphs. The major open problem is whether the problem can be solved deterministically in logarithmic time, which would match the lower bound [Chang et al., FOCS'16]. Despite recent progress in the design of efficient $\Delta$-coloring algorithms, there is currently a polynomial gap between the upper and lower bounds.
  In this work we present a $O(\log n)$-round deterministic $\Delta$-coloring algorithm for dense constant-degree graphs, matching the lower bound for the problem on general graphs. For general $\Delta$ the algorithms' complexity is $\min\{\widetilde{O}(\log^{5/3}n),O(\Delta+\log n)\}$. All recent distributed and sublinear graph coloring algorithms (also for coloring with more than $\Delta$ colors) decompose the graph into sparse and dense parts. Our algorithm works for the case that this decomposition has no sparse vertices. Ironically, in recent (randomized) $\Delta$-coloring algorithms, dealing with sparse parts was relatively easy and these dense parts arguably posed the major hurdle. We present a solution that addresses the dense parts and may have the potential for extension to sparse parts.
  Our approach is fundamentally different from prior deterministic algorithms and hence hopefully contributes towards designing an optimal algorithm for the general case. Additionally, we leverage our result to also obtain a randomized $\min\{\widetilde{O}(\log^{5/3}\log n), O(\Delta+\log\log n)\}$-round algorithm for $\Delta$-coloring dense graphs that also matches the lower bound for the problem on general constant-degree graphs [Brandt et al.; STOC'16].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03080v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Jakob, Yannic Maus</dc:creator>
    </item>
    <item>
      <title>LLMSched: Uncertainty-Aware Workload Scheduling for Compound LLM Applications</title>
      <link>https://arxiv.org/abs/2504.03444</link>
      <description>arXiv:2504.03444v1 Announce Type: new 
Abstract: Developing compound Large Language Model (LLM) applications is becoming an increasingly prevalent approach to solving real-world problems. In these applications, an LLM collaborates with various external modules, including APIs and even other LLMs, to realize complex intelligent services. However, we reveal that the intrinsic duration and structural uncertainty in compound LLM applications pose great challenges for LLM service providers in serving and scheduling them efficiently. In this paper, we propose LLMSched, an uncertainty-aware scheduling framework for emerging compound LLM applications. In LLMSched, we first design a novel DAG-based model to describe the uncertain compound LLM applications. Then, we adopt the Bayesian network to comprehensively profile compound LLM applications and identify uncertainty-reducing stages, along with an entropy-based mechanism to quantify their uncertainty reduction. Combining an uncertainty reduction strategy and a job completion time (JCT)-efficient scheme, we further propose an efficient scheduler to reduce the average JCT. Evaluation of both simulation and testbed experiments on various representative compound LLM applications shows that compared to existing state-of-the-art scheduling schemes, LLMSched can reduce the average JCT by 14~79%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03444v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Botao Zhu, Chen Chen, Xiaoyi Fan, Yifei Zhu</dc:creator>
    </item>
    <item>
      <title>An overview of the efficiency and censorship-resistance guarantees of widely-used consensus protocols</title>
      <link>https://arxiv.org/abs/2504.03588</link>
      <description>arXiv:2504.03588v1 Announce Type: new 
Abstract: Censorship resistance with short-term inclusion guarantees is an important feature of decentralized systems, missing from many state-of-the-art and even deployed consensus protocols. In leader-based protocols the leader arbitrarily selects the transactions to be included in the new block, and so does a block builder in protocols such as Bitcoin and Ethereum.
  In a different line of work, since the redundancy of consensus for implementing distributed payments was formally proven, consensusless protocols have been described in theory and deployed in the real world. This has resulted in blockchains and payment systems that are more efficient, and at the same time avoid the centralized role of a leader or block builder.
  In this report we review existing consensus and consensusless protocols with regard to their censorship-resistance, efficiency, and other properties. Moreover, we present an approach for new constructions with these properties in mind, building on existing leader-based protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03588v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Orestis Alpos, Bernardo David, Nikolas Kamarinakis, Dionysis Zindros</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of HPC applications on the Aurora Supercomputer: Exploring the Impact of HBM-Enabled Intel Xeon Max CPUs</title>
      <link>https://arxiv.org/abs/2504.03632</link>
      <description>arXiv:2504.03632v1 Announce Type: new 
Abstract: The Aurora supercomputer is an exascale-class system designed to tackle some of the most demanding computational workloads. Equipped with both High Bandwidth Memory (HBM) and DDR memory, it provides unique trade-offs in performance, latency, and capacity. This paper presents a comprehensive analysis of the memory systems on the Aurora supercomputer, with a focus on evaluating the trade-offs between HBM and DDR memory systems. We explore how different memory configurations, including memory modes (Flat and Cache) and clustering modes (Quad and SNC4), influence key system performance metrics such as memory bandwidth, latency, CPU-GPU PCIe bandwidth, and MPI communication bandwidth. Additionally, we examine the performance of three representative HPC applications -- HACC, QMCPACK, and BFS -- each illustrating the impact of memory configurations on performance. By using microbenchmarks and application-level analysis, we provide insights into how to select the optimal memory system and configuration to maximize performance based on the application characteristics. The findings presented in this paper offer guidance for users of the Aurora system and similar exascale systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03632v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huda Ibeid, Vikram Narayana, Jeongnim Kim, Anthony Nguyen, Vitali Morozov, Ye Luo</dc:creator>
    </item>
    <item>
      <title>Extending Data Spatial Semantics for Scale Agnostic Programming</title>
      <link>https://arxiv.org/abs/2504.03109</link>
      <description>arXiv:2504.03109v1 Announce Type: cross 
Abstract: We introduce extensions to Data Spatial Programming (DSP) that enable scale-agnostic programming for application development. Building on DSP's paradigm shift from data-to-compute to compute-to-data, we formalize additional intrinsic language constructs that abstract persistent state, multi-user contexts, multiple entry points, and cross-machine distribution for applications. By introducing a globally accessible root node and treating walkers as potential entry points, we demonstrate how programs can be written once and executed across scales, from single-user to multi-user, from local to distributed, without modification. These extensions allow developers to focus on domain logic while delegating runtime concerns of persistence, multi-user support, distribution, and API interfacing to the execution environment. Our approach makes scale-agnostic programming a natural extension of the topological semantics of DSP, allowing applications to seamlessly transition from single-user to multi-user scenarios, from ephemeral to persistent execution contexts, and from local to distributed execution environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03109v1</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.OS</category>
      <category>cs.SE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jason Mars</dc:creator>
    </item>
    <item>
      <title>PPFPL: Cross-silo Privacy-preserving Federated Prototype Learning Against Data Poisoning Attacks on Non-IID Data</title>
      <link>https://arxiv.org/abs/2504.03173</link>
      <description>arXiv:2504.03173v1 Announce Type: cross 
Abstract: Privacy-Preserving Federated Learning (PPFL) allows multiple clients to collaboratively train a deep learning model by submitting hidden model updates. Nonetheless, PPFL is vulnerable to data poisoning attacks due to the distributed training nature of clients. Existing solutions have struggled to improve the performance of cross-silo PPFL in poisoned Non-IID data. To address the issues, this paper proposes a privacy-preserving federated prototype learning framework, named PPFPL, which enhances the cross-silo FL performance in poisoned Non-IID data while effectively resisting data poisoning attacks. Specifically, we adopt prototypes as client-submitted model updates to eliminate the impact of tampered data distribution on federated learning. Moreover, we utilize two servers to achieve Byzantine-robust aggregation by secure aggregation protocol, which greatly reduces the impact of malicious clients. Theoretical analyses confirm the convergence of PPFPL, and experimental results on publicly available datasets show that PPFPL is effective for resisting data poisoning attacks with Non-IID conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03173v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongliang Zhang, Jiguo Yu, Fenghua Xu, Chunqiang Hu, Yongzhao Zhang, Xiaofen Wang, Zhongyuan Yu, Xiaosong Zhang</dc:creator>
    </item>
    <item>
      <title>Programming Distributed Collective Processes in the eXchange Calculus</title>
      <link>https://arxiv.org/abs/2401.11212</link>
      <description>arXiv:2401.11212v3 Announce Type: replace 
Abstract: Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calculus (XC), a core functional language based on neighbouring values (maps from neighbours to values) where state and interaction is handled through a single primitive, exchange, and provide a corresponding implementation in the FCPP language. Then, we exercise distributed collective processes using two case studies: multi-hop message propagation and distributed monitoring of spatial properties. Finally, we discuss the features of the abstraction and its suitability for different kinds of distributed computing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11212v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.PL</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giorgio Audrito, Roberto Casadei, Ferruccio Damiani, Gianluca Torta, Mirko Viroli</dc:creator>
    </item>
    <item>
      <title>Pod: An Optimal-Latency, Censorship-Free, and Accountable Generalized Consensus Layer</title>
      <link>https://arxiv.org/abs/2501.14931</link>
      <description>arXiv:2501.14931v2 Announce Type: replace 
Abstract: This work addresses the inherent issues of high latency in blockchains and low scalability in traditional consensus protocols. We present pod, a novel notion of consensus whose first priority is to achieve the physically optimal latency of one round trip time, i.e., requiring only one round for writing a new transaction and one round for reading it. To accomplish this, we first eliminate inter-replica communication. Instead, clients send transactions directly to all replicas, which independently process transactions and append them to local logs. Replicas assigns a timestamp and a sequence number to each transaction in their logs, allowing clients to extract valuable metadata about the transactions and the system state. Later on, clients retrieve these logs and extract transactions (and associated metadata) from them.
  Necessarily, this construction achieves weaker properties than a total-order broadcast protocol, due to existing lower bounds. Our work models the primitive of pod and defines its security properties. We then show pod-core, a protocol that satisfies properties such as transaction confirmation within $2\delta$, censorship resistance against Byzantine replicas, and accountability for safety violations. We show that single-shot auctions can be realized using the pod notion and observe that it is also sufficient for other popular applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14931v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Orestis Alpos, Bernardo David, Jakov Mitrovski, Odysseas Sofikitis, Dionysis Zindros</dc:creator>
    </item>
    <item>
      <title>AMP4EC: Adaptive Model Partitioning Framework for Efficient Deep Learning Inference in Edge Computing Environments</title>
      <link>https://arxiv.org/abs/2504.00407</link>
      <description>arXiv:2504.00407v2 Announce Type: replace 
Abstract: Edge computing facilitates deep learning in resource-constrained environments, but challenges such as resource heterogeneity and dynamic constraints persist. This paper introduces AMP4EC, an Adaptive Model Partitioning framework designed to optimize deep learning inference in edge environments through real-time resource monitoring, dynamic model partitioning, and adaptive task scheduling. AMP4EC features a resource-aware model partitioner that splits deep learning models based on device capabilities, a task scheduler that ensures efficient load balancing using a weighted scoring mechanism, and a Docker-based deployment environment for validation. Experimental results show up to a 78% reduction in latency and a 414% improvement in throughput compared to baseline methods. The framework achieves consistent performance with low scheduling overhead across varying resource profiles, demonstrating adaptability in high-resource (1 CPU, 1GB RAM) and low-resource (0.4 CPU, 512MB RAM) scenarios. These results highlight AMP4EC's scalability, efficiency, and robustness for real-world edge deployments, addressing the critical need for efficient distributed inference in dynamic, resource-constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00407v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilin Zhang, Wulan Guo, Ziqi Tan, Hailong Jiang</dc:creator>
    </item>
    <item>
      <title>Local Constant Approximation for Dominating Set on Graphs Excluding Large Minors</title>
      <link>https://arxiv.org/abs/2504.01091</link>
      <description>arXiv:2504.01091v2 Announce Type: replace 
Abstract: We show that graphs excluding $K_{2,t}$ as a minor admit a $f(t)$-round $50$-approximation deterministic distributed algorithm for Minimum Dominating Set. The result extends to Minimum Vertex Cover. Though fast and approximate distributed algorithms for such problems were already known for $H$-minor-free graphs, all of them have an approximation ratio depending on the size of $H$. To the best of our knowledge, this is the first example of a large non-trivial excluded minor leading to fast and constant-approximation distributed algorithms, where the ratio is independent of the size of $H$. A new key ingredient in the analysis of these distributed algorithms is the use of asymptotic dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01091v2</guid>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marthe Bonamy, Cyril Gavoille, Timoth\'e Picavet, Alexandra Wesolek</dc:creator>
    </item>
    <item>
      <title>Federated Learning in Adversarial Environments: Testbed Design and Poisoning Resilience in Cybersecurity</title>
      <link>https://arxiv.org/abs/2409.09794</link>
      <description>arXiv:2409.09794v2 Announce Type: replace-cross 
Abstract: This paper presents the design and implementation of a Federated Learning (FL) testbed, focusing on its application in cybersecurity and evaluating its resilience against poisoning attacks. Federated Learning allows multiple clients to collaboratively train a global model while keeping their data decentralized, addressing critical needs for data privacy and security, particularly in sensitive fields like cybersecurity. Our testbed, built using Raspberry Pi and Nvidia Jetson hardware by running the Flower framework, facilitates experimentation with various FL frameworks, assessing their performance, scalability, and ease of integration. Through a case study on federated intrusion detection systems, the testbed's capabilities are shown in detecting anomalies and securing critical infrastructure without exposing sensitive network data. Comprehensive poisoning tests, targeting both model and data integrity, evaluate the system's robustness under adversarial conditions. The results show that while federated learning enhances data privacy and distributed learning, it remains vulnerable to poisoning attacks, which must be mitigated to ensure its reliability in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09794v2</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hao Jian Huang, Hakan T. Otal, M. Abdullah Canbaz</dc:creator>
    </item>
  </channel>
</rss>
