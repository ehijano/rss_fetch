<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2024 04:01:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A variational neural Bayes framework for inference on intractable posterior distributions</title>
      <link>https://arxiv.org/abs/2404.10899</link>
      <description>arXiv:2404.10899v1 Announce Type: new 
Abstract: Classic Bayesian methods with complex models are frequently infeasible due to an intractable likelihood. Simulation-based inference methods, such as Approximate Bayesian Computing (ABC), calculate posteriors without accessing a likelihood function by leveraging the fact that data can be quickly simulated from the model, but converge slowly and/or poorly in high-dimensional settings. In this paper, we propose a framework for Bayesian posterior estimation by mapping data to posteriors of parameters using a neural network trained on data simulated from the complex model. Posterior distributions of model parameters are efficiently obtained by feeding observed data into the trained neural network. We show theoretically that our posteriors converge to the true posteriors in Kullback-Leibler divergence. Our approach yields computationally efficient and theoretically justified uncertainty quantification, which is lacking in existing simulation-based neural network approaches. Comprehensive simulation studies highlight our method's robustness and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10899v1</guid>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elliot Maceda, Emily C. Hector, Amanda Lenzi, Brian J. Reich</dc:creator>
    </item>
    <item>
      <title>Sparse model identification and prediction of microglial cells during ischemic stroke</title>
      <link>https://arxiv.org/abs/2404.10915</link>
      <description>arXiv:2404.10915v1 Announce Type: cross 
Abstract: Dynamics between key neuroinflammatory components, detrimental M1 and beneficial M2 microglial cells, are not fully understood post-ischemic stroke. To discover, model, and predict these dynamics, we use a method based on sparse identification of nonlinear dynamics (SINDy). The resulting data-driven dynamical system involves constant and linear terms but does not include nonlinear interactions between cells. Results show M2 microglial cell dominance of four days. Forward predictions capture potential long-term dynamics of microglial cells and suggest a persistent inflammatory response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10915v1</guid>
      <category>q-bio.CB</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Amato, Andrea Arnold</dc:creator>
    </item>
    <item>
      <title>Interval-censored linear quantile regression</title>
      <link>https://arxiv.org/abs/2404.11125</link>
      <description>arXiv:2404.11125v1 Announce Type: cross 
Abstract: Censored quantile regression has emerged as a prominent alternative to classical Cox's proportional hazards model or accelerated failure time model in both theoretical and applied statistics. While quantile regression has been extensively studied for right-censored survival data, methodologies for analyzing interval-censored data remain limited in the survival analysis literature. This paper introduces a novel local weighting approach for estimating linear censored quantile regression, specifically tailored to handle diverse forms of interval-censored survival data. The estimation equation and the corresponding convex objective function for the regression parameter can be constructed as a weighted average of quantile loss contributions at two interval endpoints. The weighting components are nonparametrically estimated using local kernel smoothing or ensemble machine learning techniques. To estimate the nonparametric distribution mass for interval-censored data, a modified EM algorithm for nonparametric maximum likelihood estimation is employed by introducing subject-specific latent Poisson variables. The proposed method's empirical performance is demonstrated through extensive simulation studies and real data analyses of two HIV/AIDS datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11125v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taehwa Choi, Seohyeon Park, Hunyong Cho, Sangbum Choi</dc:creator>
    </item>
    <item>
      <title>Pharmacokinetic Measurements in Dose Finding Model Guided by Escalation with Overdose Control</title>
      <link>https://arxiv.org/abs/2404.11406</link>
      <description>arXiv:2404.11406v1 Announce Type: cross 
Abstract: Oncology drug development starts with a dose escalation phase to find the maximal tolerable dose (MTD). Dose limiting toxicity (DLT) is the primary endpoint for dose escalation phase. Traditionally, model-based dose escalation trial designs recommend a dose for escalation based on an assumed dose-DLT relationship. Pharmacokinetic (PK) data are often available but are currently only used by clinical teams in a subjective manner to aid decision making. Formal incorporation of PK data in dose-escalation models can make the decision process more efficient and lead to an increase in precision. In this talk we present a Bayesian joint modeling framework for incorporating PK data in Oncology dose escalation trials. This framework explores the dose-PK and PK-DLT relationships jointly for better model informed dose escalation decisions. Utility of the proposed model is demonstrated through a real-life case study along with simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11406v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Kumar Maity, Satrajit Roy Chowdhury, Ray Li, Lada Markovtsova, Roberto Bugarini</dc:creator>
    </item>
    <item>
      <title>Semi-supervised Gaussian mixture modelling with a missing-data mechanism in R</title>
      <link>https://arxiv.org/abs/2302.13206</link>
      <description>arXiv:2302.13206v3 Announce Type: replace 
Abstract: Semi-supervised learning is being extensively applied to estimate classifiers from training data in which not all the labels of the feature vectors are available. We present gmmsslm, an R package for estimating the Bayes' classifier from such partially classified data in the case where the feature vector has a multivariate Gaussian (normal) distribution in each of the predefined classes. Our package implements a recently proposed Gaussian mixture modelling framework that incorporates a missingness mechanism for the missing labels in which the probability of a missing label is represented via a logistic model with covariates that depend on the entropy of the feature vector. Under this framework, it has been shown that the accuracy of the Bayes' classifier formed from the Gaussian mixture model fitted to the partially classified training data can even have lower error rate than if it were estimated from the sample completely classified. This result was established in the particular case of two Gaussian classes with a common covariance matrix. Here, we focus on the effective implementation of an algorithm for multiple Gaussian classes with arbitrary covariance matrices. A strategy for initialising the algorithm is discussed and illustrated. The new package is demonstrated on some real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13206v3</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyang Lyu, Daniel Ahfock, Ryan Thompson, Geoffrey J. McLachlan</dc:creator>
    </item>
    <item>
      <title>glmmPen: High Dimensional Penalized Generalized Linear Mixed Models</title>
      <link>https://arxiv.org/abs/2305.08204</link>
      <description>arXiv:2305.08204v2 Announce Type: replace 
Abstract: Generalized linear mixed models (GLMMs) are widely used in research for their ability to model correlated outcomes with non-Gaussian conditional distributions. The proper selection of fixed and random effects is a critical part of the modeling process since model misspecification may lead to significant bias. However, the joint selection of fixed and random effects has historically been limited to lower-dimensional GLMMs, largely due to the use of criterion-based model selection strategies. Here we present the R package glmmPen, one of the first to select fixed and random effects in higher dimension using a penalized GLMM modeling framework. Model parameters are estimated using a Monte Carlo Expectation Conditional Minimization (MCECM) algorithm, which leverages Stan and RcppArmadillo for increased computational efficiency. Our package supports the Binomial, Gaussian, and Poisson families and multiple penalty functions. In this manuscript we discuss the modeling procedure, estimation scheme, and software implementation through application to a pancreatic cancer subtyping study. Simulation results show our method has good performance in selecting both the fixed and random effects in high dimensional GLMMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08204v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hillary M. Heiling (Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC), Naim U. Rashid (Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC), Quefeng Li (Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC), Joseph G. Ibrahim (Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC)</dc:creator>
    </item>
    <item>
      <title>Additive Covariance Matrix Models: Modelling Regional Electricity Net-Demand in Great Britain</title>
      <link>https://arxiv.org/abs/2211.07451</link>
      <description>arXiv:2211.07451v3 Announce Type: replace-cross 
Abstract: Forecasts of regional electricity net-demand, consumption minus embedded generation, are an essential input for reliable and economic power system operation, and energy trading. While such forecasts are typically performed region by region, operations such as managing power flows require spatially coherent joint forecasts, which account for cross-regional dependencies. Here, we forecast the joint distribution of net-demand across the 14 regions constituting Great Britain's electricity network. Joint modelling is complicated by the fact that the net-demand variability within each region, and the dependencies between regions, vary with temporal, socio-economical and weather-related factors. We accommodate for these characteristics by proposing a multivariate Gaussian model based on a modified Cholesky parametrisation, which allows us to model each unconstrained parameter via an additive model. Given that the number of model parameters and covariates is large, we adopt a semi-automated approach to model selection, based on gradient boosting. In addition to comparing the forecasting performance of several versions of the proposed model with that of two non-Gaussian copula-based models, we visually explore the model output to interpret how the covariates affect net-demand variability and dependencies.
  The code for reproducing the results in this paper is available at https://doi.org/10.5281/zenodo.7315105, while methods for building and fitting multivariate Gaussian additive models are provided by the SCM R package, available at https://github.com/VinGioia90/SCM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07451v3</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Gioia, M. Fasiolo, J. Browell, R. Bellio</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of High-Dimensional Penalized Generalized Linear Mixed Models by Latent Factor Modeling of the Random Effects</title>
      <link>https://arxiv.org/abs/2305.08201</link>
      <description>arXiv:2305.08201v2 Announce Type: replace-cross 
Abstract: Modern biomedical datasets are increasingly high dimensional and exhibit complex correlation structures. Generalized Linear Mixed Models (GLMMs) have long been employed to account for such dependencies. However, proper specification of the fixed and random effects in GLMMs is increasingly difficult in high dimensions, and computational complexity grows with increasing dimension of the random effects. We present a novel reformulation of the GLMM using a factor model decomposition of the random effects, enabling scalable computation of GLMMs in high dimensions by reducing the latent space from a large number of random effects to a smaller set of latent factors. We also extend our prior work to estimate model parameters using a modified Monte Carlo Expectation Conditional Minimization algorithm, allowing us to perform variable selection on both the fixed and random effects simultaneously. We show through simulation that through this factor model decomposition, our method can fit high dimensional penalized GLMMs faster than comparable methods and more easily scale to larger dimensions not previously seen in existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08201v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hillary M. Heiling (Department of Biostatistics, University of North Carolina Chapel Hill, Chapel Hill, NC), Naim U. Rashid (Department of Biostatistics, University of North Carolina Chapel Hill, Chapel Hill, NC), Quefeng Li (Department of Biostatistics, University of North Carolina Chapel Hill, Chapel Hill, NC), Xianlu L. Peng (Lineberger Comprehensive Cancer Center, University of North Carolina at Chapel Hill, Chapel Hill, NC), Jen Jen Yeh (Lineberger Comprehensive Cancer Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, Department of Surgery, University of North Carolina Chapel Hill, Chapel Hill, NC, Department of Pharmacology, University of North Carolina Chapel Hill, Chapel Hill, NC), Joseph G. Ibrahim (Department of Biostatistics, University of North Carolina Chapel Hill, Chapel Hill, NC)</dc:creator>
    </item>
    <item>
      <title>Reflection coupling for unadjusted generalized Hamiltonian Monte Carlo in the nonconvex stochastic gradient case</title>
      <link>https://arxiv.org/abs/2310.18774</link>
      <description>arXiv:2310.18774v2 Announce Type: replace-cross 
Abstract: Contraction in Wasserstein 1-distance with explicit rates is established for generalized Hamiltonian Monte Carlo with stochastic gradients under possibly nonconvex conditions. The algorithms considered include splitting schemes of kinetic Langevin diffusion. As consequence, quantitative Gaussian concentration bounds are provided for empirical averages. Convergence in Wasserstein 2-distance and total variation are also given, together with numerical bias estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18774v2</guid>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Chak, Pierre Monmarch\'e</dc:creator>
    </item>
  </channel>
</rss>
