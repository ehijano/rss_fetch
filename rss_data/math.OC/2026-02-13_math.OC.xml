<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Data-Driven Hull-Fouling Cleaning Schedule Optimization to Reduce Carbon Footprint of Vessels</title>
      <link>https://arxiv.org/abs/2602.11248</link>
      <description>arXiv:2602.11248v1 Announce Type: new 
Abstract: In response to climate change, the International Maritime Organization has introduced regulatory frameworks to reduce greenhouse gas emissions from international shipping. Compliance with these regulations is increasingly expected from individual shipping companies, compelling vessel operators to lower the CO2 emissions of their fleets while maintaining economic viability. An important step towards achieving this is performing regular hull and propeller cleaning; however, this entails significant costs. As a result, assessing whether ship performance has declined sufficiently to warrant cleaning from an environmental and economic standpoint is a critical task to ensure both long-term viability and regulatory compliance. In this paper, we address this challenge by proposing a novel data-driven dynamic programming approach to optimize vessel cleaning schedules by balancing both environmental and economic considerations. In numerical experiments, we demonstrate the usefulness of our proposed methodology based on real-world sensor data from ten tramp trading vessels. The results confirm that over a four-year period, fuel consumption can be reduced by up to 5%, even when accounting for the costs of one or two additional cleaning events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11248v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samuel Ward, Marah-Lisanne Thormann, Julian Wharton, Alain Zemkoho</dc:creator>
    </item>
    <item>
      <title>Wasserstein-enabled characterization of designs and myopic decisions in Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2602.11289</link>
      <description>arXiv:2602.11289v1 Announce Type: new 
Abstract: Impractical assumptions, an inherently myopic nature, and the crucial role of the initial design, all together contribute to making theoretical convergence proofs of little value in real-life Bayesian Optimization applications. In this paper, we propose a novel characterization of the design depending on its distributional properties, separately measured with respect to the coverage of the search space and the concentration around the best observed function value. These measures are based on the Wasserstein distance and enable a model-free evaluation of the information value of the design before deciding the next query. Then, embracing the myopic nature of Bayesian Optimization, we take an empirical approach to analyze the relation between the proposed characterization of the design and the quality of the next query. Ultimately, we provide important and useful insights that might inspire the definition of a new generation of acquisition functions in Bayesian Optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11289v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Candelieri, Francesco Archetti</dc:creator>
    </item>
    <item>
      <title>An Efficient Hybrid Heuristic for the Transmission Expansion Planning under Uncertainties</title>
      <link>https://arxiv.org/abs/2602.11490</link>
      <description>arXiv:2602.11490v1 Announce Type: new 
Abstract: We address the stochastic transmission expansion planning (STEP) problem considering uncertainties in renewable generation capacity and demand. STEP's objective is to minimize the total investment cost of new transmission lines and generation cost. To tackle the computational challenges of large-scale systems, we propose a heuristic approach that combines the progressive hedging (PH) algorithm for scenario-wise decomposition with an integrated framework for solving the resulting subproblems. The latter combines a destroy-and-repair operator, a beam search procedure, and a mixed-integer programming approach. The proposed framework is evaluated on large-scale systems from the literature, containing up to 10000 nodes, adapted to multiple scenarios based on parameters from the California test system (CATS). Compared with a non-trivial baseline algorithm that includes the integrated MIP and heuristics, the proposed PH-based framework consistently improved solution quality for the six systems considered (including CATS), achieving an average optimality gap reduction of 16.23% within a 2-hour time limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11490v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yure Rocha, Teobaldo Bulh\~oes, Anand Subramanian, Joaquim Dias Garcia</dc:creator>
    </item>
    <item>
      <title>Algorithms and Differential Game Representations for Exploring Nonconvex Pareto Fronts in High Dimensions</title>
      <link>https://arxiv.org/abs/2602.11515</link>
      <description>arXiv:2602.11515v1 Announce Type: new 
Abstract: We develop a new Hamiton-Jacobi (HJ) and differential game approach for exploring the Pareto front of (constrained) multi-objective optimization (MOO) problems. Given a preference function, we embed the scalarized MOO problem into the value function of a parameterized zero-sum game, whose upper value solves a first-order HJ equation that admits a Hopf-Lax representation formula. For each parameter value, this representation yields an inner minimizer that can be interpreted as an approximate solution to a shifted scalarization of the original MOO problem. Under mild assumptions, the resulting family of solutions maps to a dense subset of the weak Pareto front. Finally, we propose a primal-dual algorithm based on this approach for solving the corresponding optimality system. Numerical experiments show that our algorithm mitigates the curse of dimensionality (scaling polynomially with the dimension of the decision and objective spaces) and is able to expose continuous curves along nonconvex Pareto fronts in 100D in just $\sim$100 seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11515v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanqing Liu, Paula Chen, Youngkyu Lee, Jerome Darbon</dc:creator>
    </item>
    <item>
      <title>Online Electric Vehicle Charging Control with Battery Thermal Management in Cold Environments</title>
      <link>https://arxiv.org/abs/2602.11561</link>
      <description>arXiv:2602.11561v1 Announce Type: new 
Abstract: Electric vehicles (EVs) are expanding rapidly, driven by the proposal to comply with global emission reduction targets. However, EV adoption in cold regions is hindered by degraded battery performance at low temperatures, which necessitates effective battery thermal management. Hence, this work proposes a novel online EV charging control strategy, incorporating battery thermal management for cold environments. We first build queue models for both battery charging and thermal dynamics. Then, we formulate an optimization problem, which allows us to coordinate battery charging and heating through maintaining queue stability. To solve the problem, we develop an online control algorithm within the theoretical framework of Lyapunov optimization. Note that our online method is prediction-free and independent of any assumed modeling of uncertainty. We also characterize both the feasibility and optimality of the proposed control approach. Numerical results based on real-world data corroborate our theoretical findings and demonstrate the effectiveness and robustness of our control method through comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11561v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaowei Wang, Yize Chen, Yue Chen</dc:creator>
    </item>
    <item>
      <title>On a group of invariances in a class of functions</title>
      <link>https://arxiv.org/abs/2602.11566</link>
      <description>arXiv:2602.11566v1 Announce Type: new 
Abstract: A class of parametric functions formed by alternating compositions of multivariate polynomials and rectification style monomial maps is studied (the layer-wise exponents are treated as fixed hyperparameters and are not optimized). For this family, nontrivial parametric invariances are identified and characterized, i.e., distinct parameter settings that induce identical input-output maps. A constructive description of the invariance structure is provided, enabling sparse function representations, parameter obfuscation, and potential dimensionality reduction for optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11566v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shravan Mohan</dc:creator>
    </item>
    <item>
      <title>Composite Optimization using Local Models and Global Approximations</title>
      <link>https://arxiv.org/abs/2602.11594</link>
      <description>arXiv:2602.11594v1 Announce Type: new 
Abstract: This work presents a unified framework that combines global approximations with locally built models to handle challenging nonconvex and nonsmooth composite optimization problems, including cases involving extended real-valued functions. We show that near-stationary points of the approximating problems converge to stationary points of the original problem under suitable conditions. Building on this, we develop practical algorithms that use tractable convex master programs derived from local models of the approximating problems. The resulting double-loop structure improves global approximations while adapting local models, providing a flexible and implementable approach for a wide class of composite optimization problems. It also lays the groundwork for new algorithmic developments in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11594v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Welington de Oliveira, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>From Consensus-Based Optimization to Evolution Strategies: Proof of Global Convergence</title>
      <link>https://arxiv.org/abs/2602.11677</link>
      <description>arXiv:2602.11677v1 Announce Type: new 
Abstract: Consensus-based optimization (CBO) is a powerful and versatile zero-order multi-particle method designed to provably solve high-dimensional global optimization problems, including those that are genuinely nonconvex or nonsmooth. The method relies on a balance between stochastic exploration and contraction toward a consensus point, which is defined via the Laplace principle as a proxy for the global minimizer.
  In this paper, we introduce new CBO variants that address practical and theoretical limitations of the original formulation of this novel optimization methodology. First, we propose a model called $\delta$-CBO}, which incorporates nonvanishing diffusion to prevent premature collapse to suboptimal states. We also develop a numerically stable implementation, the Consensus Freezing scheme, that remains robust even for arbitrarily large time steps by freezing the consensus point over time intervals. We connect these models through appropriate asymptotic limits. Furthermore, we derive from the Consensus Freezing scheme by suitable time rescaling and asymptotics a further algorithm, the Consensus Hopping scheme, which can be interpreted as a form of $(1,\lambda)$-Evolution Strategy. For all these schemes, we characterize for the first time the invariant measures and establish global convergence results, including exponential convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11677v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Fornasier, Hui Huang, Jona Klemenc, Greta Malaspina</dc:creator>
    </item>
    <item>
      <title>An objective-function-free algorithm for general smooth constrained optimization</title>
      <link>https://arxiv.org/abs/2602.11770</link>
      <description>arXiv:2602.11770v1 Announce Type: new 
Abstract: A new algorithm for smooth constrained optimization is proposed that never computes the value of the problem's objective function and that handles both equality and inequality constraints. The algorithm uses an adaptive switching strategy between a normal step aiming at reducing constraint's infeasibility and a tangential step improving dual optimality, the latter being inspired by the AdaGrad-norm method. Its worst-case iteration complexity is analyzed, showing that the norm of the gradients generated converges to zero like O(1/\sqrt{k+1}) for problems with full-rank Jacobians. Numerical experiments show that the algorithm's performance is remarkably insensitive to noise in the objective function's gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11770v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Bellavia, S. Gratton, B. Morini, Ph. L. Toint</dc:creator>
    </item>
    <item>
      <title>Decentralized Non-convex Stochastic Optimization with Heterogeneous Variance</title>
      <link>https://arxiv.org/abs/2602.11789</link>
      <description>arXiv:2602.11789v1 Announce Type: new 
Abstract: Decentralized optimization is critical for solving large-scale machine learning problems over distributed networks, where multiple nodes collaborate through local communication. In practice, the variances of stochastic gradient estimators often differ across nodes, yet their impact on algorithm design and complexity remains unclear. To address this issue, we propose D-NSS, a decentralized algorithm with node-specific sampling, and establish its sample complexity depending on the arithmetic mean of local standard deviations, achieving tighter bounds than existing methods that rely on the worst-case or quadratic mean. We further derive a matching sample complexity lower bound under heterogeneous variance, thereby proving the optimality of this dependence. Moreover, we extend the framework with a variance reduction technique and develop D-NSS-VR, which under the mean-squared smoothness assumption attains an improved sample complexity bound while preserving the arithmetic-mean dependence. Finally, numerical experiments validate the theoretical results and demonstrate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11789v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongxu Chen, Ke Wei, Luo Luo</dc:creator>
    </item>
    <item>
      <title>Third-Order Dynamical Systems for Generalized Inverse Mixed Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2602.11817</link>
      <description>arXiv:2602.11817v1 Announce Type: new 
Abstract: In this paper, we propose and analyze a third-order dynamical system for solving a generalized inverse mixed variational inequality problem in a Hilbert space H. We establish the existence and uniqueness of the trajectories generated by the system under suitable continuity assumptions, and prove their exponential convergence to the unique solution under strong monotonicity and Lipschitz continuity conditions. Furthermore, we derive an explicit discretization of the proposed dynamical system, leading to a forward -backward algorithm with double inertial effects. We then establish the linear convergence of the generated iterates to the unique solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11817v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Van Tran</dc:creator>
    </item>
    <item>
      <title>Multi-period Newsvendor Model</title>
      <link>https://arxiv.org/abs/2602.11821</link>
      <description>arXiv:2602.11821v1 Announce Type: new 
Abstract: The newsvendor model is a well-known stochastic model for inventory management; however, it was originally developed for a single-period context and focuses on trading companies. This paper proposes an extension of the newsvendor model into a mutli-period setting, aiming to develop a decision-making tool for manufacturing firms to determine the optimal production batch size. The objective function is to maximize operating profit in accordance with generally accepted accounting principles. The model can also incorporate overhead costs, such as warehousing, shrinkage, cost of capital, and lead time between the production decision and output. Monte Carlo simulations demonstrate that the proposed model results in higher profitability compared to other newsvendor models used in our analysis, as well as the safety stock buffer approach. The key feature explaining its outperformance is better adaptability of the production batch size, that leads to fewer stock-outs relative to other newsvendor models and lower inventory levels compared to the safety stock buffer approach. The robustness analysis shows that the proposed model is quite tolerant of mismatches between the "model" and the "true" demand distributions. Finally, we provide some recommendations on selecting the appropriate "model" distribution for different SKUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11821v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentyn Khokhlov</dc:creator>
    </item>
    <item>
      <title>A High-Performance Parallel Algorithm for Multi-Objective Integer Optimization</title>
      <link>https://arxiv.org/abs/2602.11872</link>
      <description>arXiv:2602.11872v1 Announce Type: new 
Abstract: Multi-objective integer optimization problems are hard to solve, mainly because the number of nondominated images is often extremely large. We present the first exact algorithm, called PEA, that fully utilizes the multicore architecture of modern hardware. By exploiting the structure of the parameter set of the underlying scalarization, PEA can use a high number of threads while avoiding the usual pitfalls of parallel computing. It is highly scalable and easy to implement. As a result, PEA can solve much larger instances than previous state-of-the-art algorithms. Besides, PEA has a sound theoretical foundation. Unlike other existing parallel algorithms, it always solves the same number of scalarization problems as comparable sequential algorithms. We demonstrate the potential of PEA in a computational study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11872v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kathrin Prinz, Levin Nemesch, Stefan Ruzika</dc:creator>
    </item>
    <item>
      <title>Relationship Between Controllability Scoring and Optimal Experimental Design</title>
      <link>https://arxiv.org/abs/2602.11921</link>
      <description>arXiv:2602.11921v1 Announce Type: new 
Abstract: Controllability scores provide control-theoretic centrality measures that quantify the relative importance of state nodes in networked dynamical systems. We establish a structural connection between finite-time controllability scoring and approximate optimal experimental design (OED): the finite-time controllability Gramian decomposes additively across nodes, yielding an affine matrix model of the same form as the information-matrix model in OED. This yields a direct correspondence between the volumetric controllability score (VCS) and D-optimality, and between the average energy controllability score (AECS) and A-optimality, implying that the classical D/A invariance gap has a direct analogue in controllability scoring. By contrast, we point out that controllability scoring typically admits a unique optimizer, unlike approximate-OED formulations. Finally, we uncover a long-horizon phenomenon with no OED counterpart: source-like state nodes without a negative self-loop can be increasingly downweighted by AECS as the horizon grows. Two numerical examples corroborate this long-horizon downweighting behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11921v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Mixed-Integer Programming for Change-point Detection</title>
      <link>https://arxiv.org/abs/2602.11947</link>
      <description>arXiv:2602.11947v1 Announce Type: new 
Abstract: We present a new mixed-integer programming (MIP) approach for offline multiple change-point detection by casting the problem as a globally optimal piecewise linear (PWL) fitting problem. Our main contribution is a family of strengthened MIP formulations whose linear programming (LP) relaxations admit integral projections onto the segment assignment variables, which encode the segment membership of each data point. This property yields provably tighter relaxations than existing formulations for offline multiple change-point detection. We further extend the framework to two settings of active research interest: (i) multidimensional PWL models with shared change-points, and (ii) sparse change-point detection, where only a subset of dimensions undergo structural change. Extensive computational experiments on benchmark real-world datasets demonstrate that the proposed formulations achieve reductions in solution times under both $\ell_1$ and $\ell_2$ loss functions in comparison to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11947v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Apoorva Narula, Santanu S. Dey, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Insights on Muon from Simple Quadratics</title>
      <link>https://arxiv.org/abs/2602.11948</link>
      <description>arXiv:2602.11948v1 Announce Type: new 
Abstract: Muon updates weight matrices along (approximate) polar factors of the gradients and has shown strong empirical performance in large-scale training. Existing attempts at explaining its performance largely focus on single-step comparisons (on quadratic proxies) and worst-case guarantees that treat the inexactness of the polar-factor as a nuisance ``to be argued away''. We show that already on simple strongly convex functions such as $L(W)=\frac12\|W\|_{\text{F}}^2$, these perspectives are insufficient, suggesting that understanding Muon requires going beyond local proxies and pessimistic worst-case bounds. Instead, our analysis exposes two observations that already affect behavior on simple quadratics and are not well captured by prevailing abstractions: (i) approximation error in the polar step can qualitatively alter discrete-time dynamics and improve reachability and finite-time performance -- an effect practitioners exploit to tune Muon, but that existing theory largely treats as a pure accuracy compromise; and (ii) structural properties of the objective affect finite-budget constants beyond the prevailing conditioning-based explanations. Thus, any general theory covering these cases must either incorporate these ingredients explicitly or explain why they are irrelevant in the regimes of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11948v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Gonon, Andreea-Alexandra Mu\c{s}at, Nicolas Boumal</dc:creator>
    </item>
    <item>
      <title>Local convergence of mean-field Langevin dynamics: from gradient flows to linearly monotone games</title>
      <link>https://arxiv.org/abs/2602.11999</link>
      <description>arXiv:2602.11999v1 Announce Type: new 
Abstract: We study the local convergence of diffusive mean-field systems, including Wasserstein gradient flows, min-max dynamics, and multi-species games. We establish exponential local convergence in $\chi^2$-divergence with sharp rates, under two main assumptions: (i) the stationary measures satisfy a Poincar\'e inequality, and (ii) the velocity field satisfies a monotonicity condition, which reduces to linear convexity of the objective in the gradient flow case. We do not assume any form of displacement convexity or displacement monotonicity.
  In the gradient flow case, global exponential convergence is already known under our linear convexity assumption, with an asymptotic rate governed by the log-Sobolev constant of the stationary measure. Our contribution in this setting is to identify the sharp rate near equilibrium governed instead by the Poincar\'e constant. This rate coincides with the one suggested by Otto calculus (i.e. by a tight positivity estimate of the Wasserstein Hessian), and refines some results of Tamura (1984), extending them beyond quadratic objectives.
  More importantly, our proof technique extends to certain non-gradient systems, such as linearly monotone two-player and multi-player games. In this case, we obtain explicit local exponential convergence rates in $\chi^2$-divergence, thereby partially answering the open question raised by the authors at COLT 2024. While that question concerns global convergence (which remains open), even local convergence results were previously unavailable.
  At the heart of our analysis is the design of a Lyapunov functional that mixes the $\chi^2$-divergence with weighted negative Sobolev norms of the density relative to equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11999v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Wang, L\'ena\"ic Chizat</dc:creator>
    </item>
    <item>
      <title>The colored knapsack problem: structural properties and exact algorithms</title>
      <link>https://arxiv.org/abs/2602.12214</link>
      <description>arXiv:2602.12214v1 Announce Type: new 
Abstract: We introduce and study a novel generalization of the classical Knapsack Problem (KP), called the Colored Knapsack Problem (CKP). In this problem, the items are partitioned into classes of colors and the packed items need to be ordered such that no consecutive items are of the same color. We establish that the problem is weakly NP-hard and propose two exact dynamic programming algorithms with time complexities of $\mathcal{O}(bn^4)$ and $\mathcal{O}(b^2n^3)$, respectively. To enhance practical performance, we derive various dominance and fathoming rules for both approaches. From a theoretical perspective, we analyze the linear programming relaxation of the natural CKP formulation, proving that an optimal solution exists with at most two fractional items. We also show that the relaxation can be solved in $\mathcal{O}(n)$ time, matching the complexity of the classical KP. Finally, we establish a comprehensive benchmark of CKP instances, derived from the Colored Bin Packing Problem. Extensive computational experiments demonstrate that the proposed dynamic programming algorithms significantly outperform state-of-the-art MIP solvers on most of these instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12214v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Ciccarelli, Alexander Helber, Erik M\"uhmer</dc:creator>
    </item>
    <item>
      <title>Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs</title>
      <link>https://arxiv.org/abs/2602.12273</link>
      <description>arXiv:2602.12273v1 Announce Type: new 
Abstract: We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12273v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng</dc:creator>
    </item>
    <item>
      <title>Entropic vector quantile regression: Duality and Gaussian case</title>
      <link>https://arxiv.org/abs/2602.11290</link>
      <description>arXiv:2602.11290v1 Announce Type: cross 
Abstract: Vector quantile regression (VQR) is an optimal transport (OT) problem subject to a mean-independence constraint that extends classical linear quantile regression to vector response variables. Motivated by computational considerations, prior work has considered entropic relaxation of VQR, but its fundamental structural and approximation properties are still much less understood than entropic OT. The goal of this paper is to address some of these gaps. First, we study duality theory for entropic VQR and establish strong duality and dual attainment for marginals with possibly unbounded supports. In addition, when all marginals are compactly supported, we show that dual potentials are real analytic. Second, building on our duality theory, when all marginals are Gaussian, we show that entropic VQR has a closed-form optimal solution, which is again Gaussian, and establish the precise approximation rate toward unregularized VQR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11290v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Kato, Boyu Wang</dc:creator>
    </item>
    <item>
      <title>Sample-Free Safety Assessment of Neural Network Controllers via Taylor Methods</title>
      <link>https://arxiv.org/abs/2602.11332</link>
      <description>arXiv:2602.11332v1 Announce Type: cross 
Abstract: In recent years, artificial neural networks have been increasingly studied as feedback controllers for guidance problems. While effective in complex scenarios, they lack the verification guarantees found in classical guidance policies. Their black-box nature creates significant concerns regarding trustworthiness, limiting their adoption in safety-critical spaceflight applications. This work addresses this gap by developing a method to assess the safety of a trained neural network feedback controller via automatic domain splitting and polynomial bounding. The methodology involves embedding the trained neural network into the system's dynamical equations, rendering the closed-loop system autonomous. The system flow is then approximated by high-order Taylor polynomials, which are subsequently manipulated to construct polynomial maps that project state uncertainties onto an event manifold. Automatic domain splitting ensures the polynomials are accurate over their relevant subdomains, whilst also allowing an extensive state-space to be analysed efficiently. Utilising polynomial bounding techniques, the resulting event values may be rigorously constrained and analysed within individual subdomains, thereby establishing bounds on the range of possible closed-loop outcomes from using such neural network controllers and supporting safety assessment and informed operational decision-making in real-world missions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11332v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adam Evans, Roberto Armellin</dc:creator>
    </item>
    <item>
      <title>Fully First-Order Algorithms for Online Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2602.11665</link>
      <description>arXiv:2602.11665v1 Announce Type: cross 
Abstract: In this work, we study non-convex-strongly-convex online bilevel optimization (OBO). Existing OBO algorithms are mainly based on hypergradient descent, which requires access to a Hessian-vector product (HVP) oracle and potentially incurs high computational costs. By reformulating the original OBO problem as a single-level online problem with inequality constraints and constructing a sequence of Lagrangian function, we eliminate the need for HVPs arising from implicit differentiation. Specifically, we propose a fully first-order algorithm for OBO, and provide theoretical guarantees showing that it achieves regret of $O(1 + V_T + H_{2,T})$. Furthermore, we develop an improved variant with an adaptive inner-iteration scheme, which removes the dependence on the drift variation of the inner-level optimal solution and achieves regret of $O(\sqrt{T} + V_T)$. This regret have the advatange when $V_{T}\ge O(\sqrt{T})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11665v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingkai Jia, Cheng Chen</dc:creator>
    </item>
    <item>
      <title>Provable Offline Reinforcement Learning for Structured Cyclic MDPs</title>
      <link>https://arxiv.org/abs/2602.11679</link>
      <description>arXiv:2602.11679v1 Announce Type: cross 
Abstract: We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11679v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyungbok Lee, Angelica Cristello Sarteau, Michael R. Kosorok</dc:creator>
    </item>
    <item>
      <title>Optimizing edge weights in the inverse eigenvector centrality problem</title>
      <link>https://arxiv.org/abs/2602.11772</link>
      <description>arXiv:2602.11772v1 Announce Type: cross 
Abstract: In this paper we study the inverse eigenvector centrality problem on directed graphs: given a prescribed node centrality profile, we seek edge weights that realize it. Since this inverse problem generally admits infinitely many solutions, we explicitly characterize the feasible set of admissible weights and introduce six optimization problems defined over this set, each corresponding to a different weight-selection strategy. These formulations provide representative solutions of the inverse problem and enable a systematic comparison of how different strategies influence the structure of the resulting weighted networks. We illustrate our framework using several real-world social network datasets, showing that different strategies produce different weighted graph structures while preserving the prescribed centrality. The results highlight the flexibility of the proposed approach and its potential applications in network reconstruction, and network design or network manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11772v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mauro Passacantando, Fabio Raciti</dc:creator>
    </item>
    <item>
      <title>Optimal Quantization for Nonuniform Densities on Spherical Curves</title>
      <link>https://arxiv.org/abs/2602.11926</link>
      <description>arXiv:2602.11926v1 Announce Type: cross 
Abstract: We present an analysis of optimal quantization of probability measures with nonuniform densities on spherical curves. We begin by deriving the centroid condition, followed by a high-resolution asymptotic analysis to establish the point-density formula. We further quantify the asymptotic error formula for the nonuniform densities. We apply these theorems to the von Mises distributions and characterize the optimal condition. We also provide applications using the high-resolution asymptotic and its corresponding error formula. Our results can be used in geometric probability theory and quantization theory of spherical curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11926v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Silpi Saha, Sangita Jha, Mrinal Kanti Roychowdhury</dc:creator>
    </item>
    <item>
      <title>A Novel Approach to Peng's Maximum Principle for McKean-Vlasov Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2602.12006</link>
      <description>arXiv:2602.12006v1 Announce Type: cross 
Abstract: We present a novel approach to the proof of Peng's maximum principle for McKean-Vlasov stochastic differential equations (SDE). The main step is the introduction of a third adjoint equation, a conditional McKean-Vlasov backward SDE, to accommodate the dualization of quadratic terms containing two independent copies of the first-order variational process. This is an intrinsic extension of the maximum principle from Peng for standard SDE and gives a conceptually consistent proof. Our approach will be useful in further extensions to the common noise setting and the infinite dimensional setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12006v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johan Benedikt Spille, Wilhelm Stannat</dc:creator>
    </item>
    <item>
      <title>Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis</title>
      <link>https://arxiv.org/abs/2602.12047</link>
      <description>arXiv:2602.12047v1 Announce Type: cross 
Abstract: We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12047v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anutam Srinivasan, Antoine Leeman, Glen Chou</dc:creator>
    </item>
    <item>
      <title>Local Integrable Symmetries of Diffieties</title>
      <link>https://arxiv.org/abs/2602.12103</link>
      <description>arXiv:2602.12103v1 Announce Type: cross 
Abstract: In the framework of diffieties, introduced by Vinogradov, we introduce integrable infinitesimal symmetries and show that they define a one parameter pseudogroup of local diffiety morphisms. We prove some preliminary results allowing to reduce the computation of integrable infinitesimal symmetries of a given order to solving a system of partial differential equations.We provide examples for which we can reduce to a linear system that can be solved by hand computation, and investigate some consequences for the local classification of diffiety, with a special interest for testing if a diffiety is flat.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12103v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Ollivier, Yirmeyahu J. Kaminski</dc:creator>
    </item>
    <item>
      <title>Low T-Phase Rank Approximation of Third Order Tensors</title>
      <link>https://arxiv.org/abs/2602.12121</link>
      <description>arXiv:2602.12121v1 Announce Type: cross 
Abstract: We study low T-phase-rank approximation of sectorial third-order tensors $\mathscr{A}\in\mathbb{C}^{n\times n\times p}$ under the tensor T-product. We introduce canonical T-phases and T-phase rank, and formulate the approximation task as minimizing a symmetric gauge of the canonical phase vector under a T-phase-rank constraint. Our main tool is a tensor phase-majorization inequality for the geometric mean, obtained by lifting the matrix inequality through the block-circulant representation. In the positive-imaginary regime, this yields an exact optimal-value formula and an explicit optimal half-phase truncation family. We further establish tensor counterparts of classical matrix phase inequalities and derive a tensor small phase theorem for MIMO linear time-invariant systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12121v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taehyeong Kim, Hayoung Choi, Yimin Wei</dc:creator>
    </item>
    <item>
      <title>Batch-based Bayesian Optimal Experimental Design in Linear Inverse Problems</title>
      <link>https://arxiv.org/abs/2602.12234</link>
      <description>arXiv:2602.12234v1 Announce Type: cross 
Abstract: Experimental design is central to science and engineering. A ubiquitous challenge is how to maximize the value of information obtained from expensive or constrained experimental settings. Bayesian optimal experimental design (OED) provides a principled framework for addressing such questions. In this paper, we study experimental design problems such as the optimization of sensor locations over a continuous domain in the context of linear Bayesian inverse problems. We focus in particular on batch design, that is, the simultaneous optimization of multiple design variables, which leads to a notoriously difficult non-convex optimization problem. We tackle this challenge using a promising strategy recently proposed in the frequentist setting, which relaxes A-optimal design to the space of finite positive measures. Our main contribution is the rigorous identification of the Bayesian inference problem corresponding to this relaxed A-optimal OED formulation. Moreover, building on recent work, we develop a Wasserstein gradient-flow -based optimization algorithm for the expected utility and introduce novel regularization schemes that guarantee convergence to an empirical measure. These theoretical results are supported by numerical experiments demonstrating both convergence and the effectiveness of the proposed regularization strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12234v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofia M\"akinen, Andrew B. Duncan, Tapio Helin</dc:creator>
    </item>
    <item>
      <title>Accelerated projected gradient algorithms for sparsity constrained optimization problems</title>
      <link>https://arxiv.org/abs/2211.02271</link>
      <description>arXiv:2211.02271v2 Announce Type: replace 
Abstract: We consider the projected gradient algorithm for the nonconvex best subset selection problem that minimizes a given empirical loss function under an $\ell_0$-norm constraint. Through decomposing the feasible set of the given sparsity constraint as a finite union of linear subspaces, we present two acceleration schemes with global convergence guarantees, one by same-space extrapolation and the other by subspace identification. The former fully utilizes the problem structure to greatly accelerate the optimization speed with only negligible additional cost. The latter leads to a two-stage meta-algorithm that first uses classical projected gradient iterations to identify the correct subspace containing an optimal solution, and then switches to a highly-efficient smooth optimization method in the identified subspace to attain superlinear convergence. Experiments demonstrate that the proposed accelerated algorithms are magnitudes faster than their non-accelerated counterparts as well as the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02271v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>NeurIPS 2022</arxiv:journal_reference>
      <dc:creator>Jan Harold Alcantara, Ching-pei Lee</dc:creator>
    </item>
    <item>
      <title>Online Decision Making with Fairness over Time</title>
      <link>https://arxiv.org/abs/2211.03997</link>
      <description>arXiv:2211.03997v3 Announce Type: replace 
Abstract: Online platforms increasingly rely on sequential decision-making algorithms to allocate resources, match users, or control exposure, while facing growing pressure to ensure fairness over time. We study a general online decision-making framework in which a platform repeatedly makes decisions from possibly non-convex and discrete feasible sets, such as indivisible assignments or assortment choices, to maximize accumulated reward. Importantly, these decisions must jointly satisfy a set of general, $m$-dimensional, potentially unbounded but convex global constraints, which model diverse long-term fairness goals beyond simple budget caps. We develop a primal-dual algorithm that interprets fairness constraints as dynamic prices and updates them online based on observed outcomes. The algorithm is simple to implement, requiring only the solution of perturbed local optimization problems at each decision step. Under the standard random permutation model, we show that our method achieves $\tilde{O}(\sqrt{mT})$ regret in expected reward while guaranteeing $O(\sqrt{mT})$ violation of long-term fairness constraints deterministically over a horizon of $T$ steps. To capture realistic demand patterns such as periodicity or perturbation, we further extend our guarantees to a grouped random permutation model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03997v3</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Chen, Oktay Gunluk, Andrea Lodi, Guanyi Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Cross-Validation for Sparse Linear Regression</title>
      <link>https://arxiv.org/abs/2306.14851</link>
      <description>arXiv:2306.14851v4 Announce Type: replace 
Abstract: Given a high-dimensional covariate matrix and a response vector, ridge-regularized sparse linear regression selects a subset of features that explains the relationship between covariates and the response in an interpretable manner. To choose hyperparameters that control the sparsity level and amount of regularization, practitioners commonly use k-fold cross-validation. However, cross-validation substantially increases the computational cost of sparse regression as it requires solving many mixed-integer optimization problems (MIOs) for each hyperparameter combination. To address this computational burden, we derive computationally tractable relaxations of the k-fold cross-validation loss, facilitating hyperparameter selection while solving $50$--$80\%$ fewer MIOs in practice. Our computational results demonstrate, across eleven real-world UCI datasets, that exact MIO-based cross-validation can be competitive with mature software packages such as glmnet and L0Learn -particularly when the sample-to-feature ratio is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14851v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Andr\'es G\'omez</dc:creator>
    </item>
    <item>
      <title>Extended mean-field control problems with Poissonian common noise: Stochastic maximum principle and Hamiltonian-Jacobi-Bellman equation</title>
      <link>https://arxiv.org/abs/2407.05356</link>
      <description>arXiv:2407.05356v4 Announce Type: replace 
Abstract: This paper studies mean-field control problems with state-control joint law dependence and Poissonian common noise. We develop the stochastic maximum principle (SMP) and establish its connection to the Hamiltonian-Jacobi-Bellman (HJB) equation on the Wasserstein space. The presence of the conditional joint law and its discontinuity under Poissonian common noise bring new technical challenges. To develop the SMP when the control domain is not necessarily convex, we first consider a strong relaxed control formulation that allows us to perform the first-order variation. We propose the technique of extension transformation to overcome the compatibility issues arising from the joint law in the relaxed control formulation. By further establishing the equivalence between the relaxed control and the strict control formulations, we obtain the SMP for the original problem with strict controls. In the part to investigate the HJB equation, we formulate an equivalent controlled Fokker-Planck problem subjecting to a controlled measure-valued dynamics with Poisson jumps, which allows us to derive the HJB equation of the original problem under open-loop strict controls. We also establish the connection between the SMP and the HJB equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05356v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiaoli Wei, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Feature-Based Interpretable Surrogates for Optimization</title>
      <link>https://arxiv.org/abs/2409.01869</link>
      <description>arXiv:2409.01869v3 Announce Type: replace 
Abstract: For optimization models to be used in practice, it is crucial that users trust the results. A key factor in this aspect is the interpretability of the solution process. A previous framework for inherently interpretable optimization models used decision trees to map instances to solutions of the underlying optimization model. Based on this work, we investigate how we can use more general optimization rules to further increase interpretability and, at the same time, give more freedom to the decision-maker. The proposed rules do not map to a concrete solution but to a set of solutions characterized by common features. To find such optimization rules, we present an exact methodology using mixed-integer programming formulations as well as heuristics. We also outline the challenges and opportunities that these methods present. In particular, we demonstrate the improvement in solution quality that our approach offers compared to existing interpretable surrogates for optimization, and we discuss the relationship between interpretability and performance. These findings are supported by experiments using both synthetic and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01869v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Goerigk, Michael Hartisch, Sebastian Merten, Kartikey Sharma</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Orthogonally Constrained Problems Using Semidefinite Optimization</title>
      <link>https://arxiv.org/abs/2501.02942</link>
      <description>arXiv:2501.02942v3 Announce Type: replace 
Abstract: Building on the blueprint from Goemans and Williamson (1995) for the Max-Cut problem, we construct a polynomial-time approximation algorithm for orthogonally constrained quadratic optimization problems. First, we derive a semidefinite relaxation and propose a randomized rounding algorithm to generate feasible solutions from the relaxation. Second, we derive purely multiplicative approximation guarantees for our algorithm. When optimizing for $m$ orthogonal vectors in dimension $n$, we show that our algorithm achieves a performance ratio of at least $\max\left\{\tfrac{2}{\pi m}, \tfrac{1}{\pi(\log (2m)+1)}\right\}$. Our analysis is tight in the sense that we exhibit instances where our algorithm's performance is at most $O(1/\log m)$. We also show how to compute a tighter constant for finite $(n,m)$ by solving a univariate optimization problem, and this analysis is exact for any $n$ when $m=1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02942v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cory-Wright, Jean Pauphilet</dc:creator>
    </item>
    <item>
      <title>Maximum Principle of Optimal Probability Density Control</title>
      <link>https://arxiv.org/abs/2505.18362</link>
      <description>arXiv:2505.18362v2 Announce Type: replace 
Abstract: We develop a general theoretical framework for optimal probability density control on standard measure spaces, aimed at addressing large-scale multi-agent control problems. In particular, we establish a maximum principle (MP) for control problems posed on infinite-dimensional spaces of probability distributions and control vector fields. We further derive the Hamilton--Jacobi--Bellman equation for the associated value functional defined on the space of probability distributions. Both results are presented in a concise form and supported by rigorous mathematical analysis, enabling efficient numerical treatment of these problems. Building on the proposed MP, we introduce a scalable numerical algorithm that leverages deep neural networks to handle high-dimensional settings. The effectiveness of the approach is demonstrated through several multi-agent control examples involving domain obstacles and inter-agent interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18362v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Gaby, Xiaojing Ye</dc:creator>
    </item>
    <item>
      <title>Preconditioned Halpern iteration with adaptive anchoring parameters and an acceleration to Chambolle--Pock algorithm</title>
      <link>https://arxiv.org/abs/2506.22725</link>
      <description>arXiv:2506.22725v2 Announce Type: replace 
Abstract: In this article, we propose a preconditioned Halpern iteration with adaptive anchoring parameters (PHA) by integrating a preconditioner and Halpern iteration with adaptive anchoring parameters. Then we establish the strong convergence and at least $\mathcal{O}(1/k)$ convergence rate of the PHA method, and extend these convergence results to Halpern-type preconditioned proximal point method with adaptive anchoring parameters. Moreover, we develop an accelerated Chambolle--Pock algorithm that is shown to have at least $\mathcal{O}(1/k)$ convergence rate concerning the residual mapping and the primal-dual gap. Finally, numerical experiments on the minimax matrix game and LASSO problem are provided to show the performance of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22725v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fangbing Lv, Qiao-Li Dong</dc:creator>
    </item>
    <item>
      <title>A Practical Adaptive Subgame Perfect Gradient Method</title>
      <link>https://arxiv.org/abs/2510.21617</link>
      <description>arXiv:2510.21617v2 Announce Type: replace 
Abstract: We present a performant gradient method for smooth convex optimization, drawing inspiration from several recent advances in the field. Our algorithm, the Adaptive Subgame Perfect Gradient Method (ASPGM) is based on the notion of subgame perfection, attaining a dynamic strengthening of minimax optimality. At each iteration, ASPGM makes a momentum-type update, optimized dynamically based on a (limited) memory/bundle of past first-order information. ASPGM is linesearch-free, parameter-free, and adaptive due to its use of recently developed auto-conditioning, restarting, and preconditioning ideas. We show that ASPGM is competitive with state-of-the-art L-BFGS methods on a wide range of smooth convex problems. Unlike quasi-Newton methods, however, our core algorithm underlying ASPGM has strong, subgame perfect, non-asymptotic guarantees, providing certificates of solution quality, resulting in simple stopping criteria and restarting conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21617v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Luner, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Asymptotic Analysis of an Abstract Stochastic Scheme for Solving Monotone Inclusions</title>
      <link>https://arxiv.org/abs/2512.03023</link>
      <description>arXiv:2512.03023v2 Announce Type: replace 
Abstract: We propose an abstract stochastic scheme for solving a broad range of monotone operator inclusion problems in Hilbert spaces. This framework allows for the introduction of stochasticity at several levels in monotone operator splitting methods: approximation of operators, selection of coordinates and operators in block-iterative implementations, and relaxation parameters. The analysis involves an abstract reduced inclusion model with two operators. At each iteration of the proposed scheme, stochastic approximations to points in the graphs of these two operators are used to form the update. The results are applied to derive the almost sure and $L^2$ convergence of stochastic versions of the proximal point algorithm, as well as of randomized block-iterative projective splitting methods for solving systems of coupled inclusions involving a mix of set-valued, cocoercive, and Lipschitzian monotone operators combined via various monotonicity-preserving operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03023v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Javier I. Madariaga</dc:creator>
    </item>
    <item>
      <title>Tight semidefinite programming relaxations for sparse box-constrained quadratic programs</title>
      <link>https://arxiv.org/abs/2601.18545</link>
      <description>arXiv:2601.18545v2 Announce Type: replace 
Abstract: We introduce a new class of semidefinite programming (SDP) relaxations for sparse box-constrained quadratic programs, obtained by a novel integration of the Reformulation Linearization Technique into standard SDP relaxations while explicitly exploiting the sparsity of the problem. The resulting relaxations are not implied by the existing LP and SDP relaxations for this class of optimization problems. We establish a sufficient condition under which the convex hull of the feasible region of the lifted quadratic program is SDP-representable; the proof is constructive and yields an explicit extended formulation. Although the resulting SDP may be of exponential size in general, we further identify additional structural conditions on the sparsity of the optimization problem that guarantee the existence of a polynomial-size SDP-representable formulation, which can be constructed in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18545v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aida Khajavirad</dc:creator>
    </item>
    <item>
      <title>From Sequential to Parallel: Reformulating Dynamic Programming as GPU Kernels for Large-Scale Stochastic Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2602.05179</link>
      <description>arXiv:2602.05179v2 Announce Type: replace 
Abstract: A major bottleneck in scenario-based Sample Average Approximation (SAA) for stochastic programming (SP) is the cost of solving an exact second-stage problem for every scenario, especially when each scenario contains an NP-hard combinatorial structure. This has led much of the SP literature to restrict the second stage to linear or simplified models. We develop a GPU-based framework that makes full-fidelity integer second-stage models tractable at scale. The key innovation is a set of hardware-aware, scenario-batched GPU kernels that expose parallelism across scenarios, dynamic-programming (DP) layers, and route or action options, enabling Bellman updates to be executed in a single pass over more than 1,000,000 realizations. We evaluate the approach in two representative SP settings: a vectorized split operator for stochastic vehicle routing and a DP for inventory reinsertion. Implementation scales nearly linearly in the number of scenarios and achieves a one-two to four-five orders of magnitude speedup, allowing far larger scenario sets and reliably stronger first-stage decisions. The computational leverage directly improves decision quality: much larger scenario sets and many more first-stage candidates can be evaluated within fixed time budgets, consistently yielding stronger SAA solutions. Our results show that full-fidelity integer second-stage models are tractable at scales previously considered impossible, providing a practical path to large-scale, realistic stochastic discrete optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05179v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyi Zhao, Linxin Yang, Haohua Zhang, Qile He, Tian Ding</dc:creator>
    </item>
    <item>
      <title>Convergence Rates for Stochastic Proximal and Projection Estimators</title>
      <link>https://arxiv.org/abs/2602.06750</link>
      <description>arXiv:2602.06750v2 Announce Type: replace 
Abstract: In this paper, we establish explicit convergence rates for the stochastic smooth approximations of infimal convolutions introduced and developed in \cite{MR4581306,MR4923371}. In particular, we quantify the convergence of the associated barycentric estimators toward proximal mappings and metric projections. We prove a dimension-explicit $\sqrt{\delta}$ bound, with explicit constants for the proximal mapping, in the $\rho$-weakly convex (possibly nonsmooth) setting, and we also obtain a dimension-explicit $\sqrt{\delta}$ rate for the metric projection onto an arbitrary convex set with nonempty interior. Under additional regularity, namely $C^{2}$ smoothness with globally Lipschitz Hessian, we derive an improved linear $O(\delta)$ rate with explicit constants, and we obtain refined projection estimates for convex sets with local $C^{2,1}$ boundary. Examples demonstrate that these rates are optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06750v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Morales, Pedro P\'erez-Aros, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>Accelerating nuclear-norm regularized low-rank matrix optimization through Burer-Monteiro decomposition</title>
      <link>https://arxiv.org/abs/2204.14067</link>
      <description>arXiv:2204.14067v4 Announce Type: replace-cross 
Abstract: This work proposes a rapid algorithm, BM-Global, for nuclear-norm-regularized convex and low-rank matrix optimization problems. BM-Global efficiently decreases the objective value via low-cost steps leveraging the nonconvex but smooth Burer-Monteiro (BM) decomposition, while effectively escapes saddle points and spurious local minima ubiquitous in the BM form to obtain guarantees of fast convergence rates to the global optima of the original nuclear-norm-regularized problem through aperiodic inexact proximal gradient steps on it. The proposed approach adaptively adjusts the rank for the BM decomposition and can provably identify an optimal rank for the BM decomposition problem automatically in the course of optimization through tools of manifold identification. BM-Global hence also spends significantly less time on parameter tuning than existing matrix-factorization methods, which require an exhaustive search for finding this optimal rank. Extensive experiments on real-world large-scale problems of recommendation systems, regularized kernel estimation, and molecular conformation confirm that BM-Global can indeed effectively escapes spurious local minima at which existing BM approaches are stuck, and is a magnitude faster than state-of-the-art algorithms for low-rank matrix optimization problems involving a nuclear-norm regularizer. Based on this research, we have released an open-source package of the proposed BM-Global at https://www.github.com/leepei/BM-Global/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.14067v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research 2024</arxiv:journal_reference>
      <dc:creator>Ching-pei Lee, Ling Liang, Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Subspace-constrained randomized coordinate descent for linear systems with good low-rank matrix approximations</title>
      <link>https://arxiv.org/abs/2506.09394</link>
      <description>arXiv:2506.09394v3 Announce Type: replace-cross 
Abstract: The randomized coordinate descent (RCD) method is a classical algorithm with simple, lightweight iterations that is widely used for various optimization problems, including the solution of positive semidefinite linear systems. As a linear solver, RCD is particularly effective when the matrix is well-conditioned; however, its convergence rate deteriorates rapidly in the presence of large spectral outliers. In this paper, we introduce the subspace-constrained randomized coordinate descent (SC-RCD) method, in which the dynamics of RCD are restricted to an affine subspace corresponding to a column Nystr\"{o}m approximation, efficiently computed using the recently analyzed RPCholesky algorithm. We prove that SC-RCD converges at a rate that is unaffected by large spectral outliers, making it an effective and memory-efficient solver for large-scale, dense linear systems with rapidly decaying spectra, such as those encountered in kernel ridge regression. Experimental validation and comparisons with related solvers based on coordinate descent and the conjugate gradient method demonstrate the efficiency of SC-RCD. Our theoretical results are derived by developing a more general subspace-constrained framework for the sketch-and-project method. This framework, which may be of independent interest, generalizes popular algorithms such as randomized Kaczmarz and coordinate descent, and provides a flexible, implicit preconditioning strategy for a variety of iterative solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09394v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackie Lok, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>On the optimization dynamics of RLVR: Gradient gap and step size thresholds</title>
      <link>https://arxiv.org/abs/2510.08539</link>
      <description>arXiv:2510.08539v3 Announce Type: replace-cross 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), which uses simple binary feedback to post-train large language models, has found significant empirical success. However, a principled understanding of why it works is lacking. This paper builds a theoretical foundation for RLVR by analyzing its training process at both the full-response (trajectory) and token levels. Central to our analysis is a new quantity called the Gradient Gap, which formalizes the direction of improvement from low-reward to high-reward regions of the response space. We prove that convergence critically depends on aligning the update direction with this Gradient Gap. Moreover, we derive a sharp step-size threshold based on the magnitude of the Gradient Gap: below it, learning converges, whereas above it, performance collapses. Our theory further predicts how the critical step size must scale with response length and the success rate, thereby explaining why practical heuristics such as length normalization improve stability and showing that, with a fixed learning rate, the success rate can stagnate strictly below $100\%$. Importantly, our theory holds flexibly for any policy-gradient algorithm and so characterizes the dynamics of popular approaches such as REINFORCE and GRPO. We validate these predictions through controlled bandit simulations and language model experiments on post-training Qwen2.5-Math-7B with GRPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08539v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joe Suk, Yaqi Duan</dc:creator>
    </item>
    <item>
      <title>Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces</title>
      <link>https://arxiv.org/abs/2602.10961</link>
      <description>arXiv:2602.10961v2 Announce Type: replace-cross 
Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10961v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Orelli, Mirko Mizzoni, Antonio Franchi</dc:creator>
    </item>
  </channel>
</rss>
