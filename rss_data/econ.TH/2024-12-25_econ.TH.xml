<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Profit Allocation in the We Media Value Chain: A Shapley Value-Based Approach</title>
      <link>https://arxiv.org/abs/2412.18130</link>
      <description>arXiv:2412.18130v1 Announce Type: new 
Abstract: The study takes the social media industry as its research subject and examines the impact of scientific innovation capabilities on profit distribution within the value chain of the social media industry. It proposes a specific solution to the profit distribution problem using an improved Shapley value method. Additionally, the AHP (Analytic Hierarchy Process) is employed to evaluate the profit distribution model, allowing the improved Shapley value method to better address the issue of profit allocation within the value chain of the social media industry. This approach ensures that each member receives a fair share of the profits, fostering strong cooperative relationships among members. Moreover, it compensates for the shortcomings of the traditional Shapley value method in addressing such problems to a certain extent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18130v1</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfei Xu, Rui Zhang, Junhui Fan</dc:creator>
    </item>
    <item>
      <title>Robust Equilibria in Generic Extensive form Games</title>
      <link>https://arxiv.org/abs/2412.18449</link>
      <description>arXiv:2412.18449v1 Announce Type: new 
Abstract: We prove the 2-player, generic extensive-form case of the conjecture of Govindan and Wilson (1997a,b) and Hauk and Hurkens (2002) stating that an equilibrium component is essential in every equivalent game if and only if the index of the component is nonzero. This provides an index-theoretic characterization of the concept of hyperstable components of equilibria in generic extensive-form games, first formulated by Kohlberg and Mertens (1986). We also illustrate how to compute hyperstable equilibria in multiple economically relevant examples and show how the predictions of hyperstability compare with other solution concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18449v1</guid>
      <category>econ.TH</category>
      <category>math.AT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Pahl, Carlos Pimienta</dc:creator>
    </item>
    <item>
      <title>Calibrating the Subjective</title>
      <link>https://arxiv.org/abs/2412.18486</link>
      <description>arXiv:2412.18486v1 Announce Type: new 
Abstract: I conduct a version of Rabin's (2000) calibration exercise in the subjective expected utility realm. I show that the rejection of some risky bet by a risk-averse agent only implies the rejection of more extreme and less desirable bets and nothing more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18486v1</guid>
      <category>econ.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Whitmeyer</dc:creator>
    </item>
    <item>
      <title>A partial-state space model of unawareness</title>
      <link>https://arxiv.org/abs/2412.00897</link>
      <description>arXiv:2412.00897v2 Announce Type: replace 
Abstract: We propose a model of unawareness that remains close to the paradigm of Aumann's model for knowledge [R. J. Aumann, International Journal of Game Theory 28 (1999) 263-300]: just as Aumann uses a correspondence on a state space to define an agent's knowledge operator on events, we use a correspondence on a state space to define an agent's awareness operator on events. This is made possible by three ideas. First, like the model of [A. Heifetz, M. Meier, and B. Schipper, Journal of Economic Theory 130 (2006) 78-94], ours is based on a space of partial specifications of the world, partially ordered by a relation of further specification or refinement, and the idea that agents may be aware of some coarser-grained specifications while unaware of some finer-grained specifications; however, our model is based on a different implementation of this idea, related to forcing in set theory. Second, we depart from a tradition in the literature, initiated by [S. Modica and A. Rustichini, Theory and Decision 37 (1994) 107-124] and adopted by Heifetz et al. and [J. Li, Journal of Economic Theory 144 (2009) 977-993], of taking awareness to be definable in terms of knowledge. Third, we show that the negative conclusion of a well-known impossibility theorem concerning unawareness in [Dekel, Lipman, and Rustichini, Econometrica 66 (1998) 159-173] can be escaped by a slight weakening of a key axiom. Together these points demonstrate that a correspondence on a partial-state space is sufficient to model unawareness of events. Indeed, we prove a representation theorem showing that any abstract Boolean algebra equipped with awareness, knowledge, and belief operators satisfying some plausible axioms is representable as the algebra of events arising from a partial-state space with awareness, knowledge, and belief correspondences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00897v2</guid>
      <category>econ.TH</category>
      <category>cs.LO</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
    <item>
      <title>Equitable Core Imputations via a New Adaptation of The Primal-Dual Framework</title>
      <link>https://arxiv.org/abs/2402.11437</link>
      <description>arXiv:2402.11437v5 Announce Type: replace-cross 
Abstract: The classic paper of Shapley and Shubik \cite{Shapley1971assignment} characterized the core of the assignment game. We observe that a sub-coalition consisting of one player (or a set of players from the same side of the bipartition) can make zero profit, and therefore its profit under a core imputation can be an arbitrary amount. Hence an arbitrary core imputation makes {\em no fairness guarantee at the level of individual agents}. Can this deficiency be addressed by picking a ``good'' core imputation?
  To arrive at an appropriate solution concept, we give specific criteria for picking a special core imputation, and we undertake a detailed comparison of four solution concepts. Leximin and leximax core imputations come out as clear winners; we define these to be {\em equitable core imputations}. These imputations achieve ``fairness'' in different ways: whereas leximin tries to make poor agents more rich, leximax tries to make rich agents less rich.
  We give combinatorial strongly polynomial algorithms for computing these imputations via a novel adaptation of the classical primal-dual paradigm. The ``engine'' driving them involves insights into core imputations obtained via complementarity. It will not be surprising if our work leads to new uses of this powerful technique. Furthermore, we expect more work on computing the leximin and leximax core imputations of other natural games, in addition to the recent follow-up work \cite{Leximin-max}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11437v5</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay V. Vazirani</dc:creator>
    </item>
  </channel>
</rss>
