<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 01:56:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Experimental Design Using Interlacing Polynomials</title>
      <link>https://arxiv.org/abs/2410.11390</link>
      <description>arXiv:2410.11390v1 Announce Type: new 
Abstract: We present a unified deterministic approach for experimental design problems using the method of interlacing polynomials. Our framework recovers the best-known approximation guarantees for the well-studied D/A/E-design problems with simple analysis. Furthermore, we obtain improved non-trivial approximation guarantee for E-design in the challenging small budget regime. Additionally, our approach provides an optimal approximation guarantee for a generalized ratio objective that generalizes both D-design and A-design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11390v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lap Chi Lau, Robert Wang, Hong Zhou</dc:creator>
    </item>
    <item>
      <title>Fully Dynamic $k$-Center Clustering Made Simple</title>
      <link>https://arxiv.org/abs/2410.11470</link>
      <description>arXiv:2410.11470v1 Announce Type: new 
Abstract: In this paper, we consider the \emph{metric $k$-center} problem in the fully dynamic setting, where we are given a metric space $(V,d)$ evolving via a sequence of point insertions and deletions and our task is to maintain a subset $S \subseteq V$ of at most $k$ points that minimizes the objective $\max_{x \in V} \min_{y \in S}d(x, y)$. We want to design our algorithm so that we minimize its \emph{approximation ratio}, \emph{recourse} (the number of changes it makes to the solution $S$) and \emph{update time} (the time it takes to handle an update).
  We give a simple algorithm for dynamic $k$-center that maintains a $O(1)$-approximate solution with $O(1)$ amortized recourse and $\tilde O(k)$ amortized update time, \emph{obtaining near-optimal approximation, recourse and update time simultaneously}. We obtain our result by combining a variant of the dynamic $k$-center algorithm of Bateni et al.~[SODA'23] with the dynamic sparsifier of Bhattacharya et al.~[NeurIPS'23].</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11470v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sayan Bhattacharya, Mart\'in Costa, Silvio Lattanzi, Nikos Parotsidis</dc:creator>
    </item>
    <item>
      <title>Hyperbolic Random Graphs: Clique Number and Degeneracy with Implications for Colouring</title>
      <link>https://arxiv.org/abs/2410.11549</link>
      <description>arXiv:2410.11549v1 Announce Type: new 
Abstract: Hyperbolic random graphs inherit many properties that are present in real-world networks. The hyperbolic geometry imposes a scale-free network with a strong clustering coefficient. Other properties like a giant component, the small world phenomena and others follow. This motivates the design of simple algorithms for hyperbolic random graphs.
  In this paper we consider threshold hyperbolic random graphs (HRGs). Greedy heuristics are commonly used in practice as they deliver a good approximations to the optimal solution even though their theoretical analysis would suggest otherwise. A typical example for HRGs are degeneracy-based greedy algorithms [Bl\"asius, Fischbeck; Transactions of Algorithms '24]. In an attempt to bridge this theory-practice gap we characterise the parameter of degeneracy yielding a simple approximation algorithm for colouring HRGs. The approximation ratio of our algorithm ranges from $(2/\sqrt{3})$ to $4/3$ depending on the power-law exponent of the model. We complement our findings for the degeneracy with new insights on the clique number of hyperbolic random graphs. We show that degeneracy and clique number are substantially different and derive an improved upper bound on the clique number. Additionally, we show that the core of HRGs does not constitute the largest clique.
  Lastly we demonstrate that the degeneracy of the closely related standard model of geometric inhomogeneous random graphs behaves inherently different compared to the one of hyperbolic random graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11549v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Baguley, Yannic Maus, Janosch Ruff, George Skretas</dc:creator>
    </item>
    <item>
      <title>Replicable Uniformity Testing</title>
      <link>https://arxiv.org/abs/2410.10892</link>
      <description>arXiv:2410.10892v1 Announce Type: cross 
Abstract: Uniformity testing is arguably one of the most fundamental distribution testing problems. Given sample access to an unknown distribution $\mathbf{p}$ on $[n]$, one must decide if $\mathbf{p}$ is uniform or $\varepsilon$-far from uniform (in total variation distance). A long line of work established that uniformity testing has sample complexity $\Theta(\sqrt{n}\varepsilon^{-2})$. However, when the input distribution is neither uniform nor far from uniform, known algorithms may have highly non-replicable behavior. Consequently, if these algorithms are applied in scientific studies, they may lead to contradictory results that erode public trust in science.
  In this work, we revisit uniformity testing under the framework of algorithmic replicability [STOC '22], requiring the algorithm to be replicable under arbitrary distributions. While replicability typically incurs a $\rho^{-2}$ factor overhead in sample complexity, we obtain a replicable uniformity tester using only $\tilde{O}(\sqrt{n} \varepsilon^{-2} \rho^{-1})$ samples. To our knowledge, this is the first replicable learning algorithm with (nearly) linear dependence on $\rho$.
  Lastly, we consider a class of ``symmetric" algorithms [FOCS '00] whose outputs are invariant under relabeling of the domain $[n]$, which includes all existing uniformity testers (including ours). For this natural class of algorithms, we prove a nearly matching sample complexity lower bound for replicable uniformity testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10892v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sihan Liu, Christopher Ye</dc:creator>
    </item>
    <item>
      <title>The Lanczos algorithm for matrix functions: a handbook for scientists</title>
      <link>https://arxiv.org/abs/2410.11090</link>
      <description>arXiv:2410.11090v1 Announce Type: cross 
Abstract: Lanczos-based methods have become standard tools for tasks involving matrix functions. Progress on these algorithms has been driven by several largely disjoint communities, resulting many innovative and important advancements which would not have been possible otherwise. However, this also has resulted in a somewhat fragmented state of knowledge and the propagation of a number of incorrect beliefs about the behavior of Lanczos-based methods in finite precision arithmetic.
  This monograph aims to provide an accessible introduction to Lanczos-based methods for matrix functions. The intended audience is scientists outside of numerical analysis, graduate students, and researchers wishing to begin work in this area. Our emphasis is on conceptual understanding, with the goal of providing a starting point to learn more about the remarkable behavior of the Lanczos algorithm. Hopefully readers will come away from this text with a better understanding of how to think about Lanczos for modern problems involving matrix functions, particularly in the context of finite precision arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11090v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen</dc:creator>
    </item>
    <item>
      <title>Comparison Theorems for the Mixing Times of Systematic and Random Scan Dynamics</title>
      <link>https://arxiv.org/abs/2410.11136</link>
      <description>arXiv:2410.11136v1 Announce Type: cross 
Abstract: A popular method for sampling from high-dimensional distributions is the Gibbs sampler, which iteratively resamples sites from the conditional distribution of the desired measure given the values of the other coordinates. But to what extent does the order of site updates matter in the mixing time? Two natural choices are (i) standard, or random scan, Glauber dynamics where the updated variable is chosen uniformly at random, and (ii) the systematic scan dynamics where variables are updated in a fixed, cyclic order. We first show that for systems of dimension $n$, one round of the systematic scan dynamics has spectral gap at most a factor of order $n$ worse than the corresponding spectral gap of a single step of Glauber dynamics, tightening existing bounds in the literature by He, et al. [NeurIPS '16] and Chlebicka, {\L}atuszy\'nski, and Miasodejow [Ann. Appl. Probab. '24]. This result is sharp even for simple spin systems by an example of Roberts and Rosenthal [Int. J. Statist. Prob. '15]. We complement this with a converse statement: if all, or even just one scan order rapidly mixes, the Glauber dynamics has a polynomially related mixing time, resolving a question of Chlebicka, {\L}atuszy\'nski, and Miasodejow. Our arguments are simple and only use elementary linear algebra and probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11136v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Gaitonde, Elchanan Mossel</dc:creator>
    </item>
    <item>
      <title>Lipschitz Continuous Algorithms for Covering Problems</title>
      <link>https://arxiv.org/abs/2307.08213</link>
      <description>arXiv:2307.08213v2 Announce Type: replace 
Abstract: Combinatorial algorithms are widely used for decision-making and knowledge discovery, and it is important to ensure that their output remains stable even when subjected to small perturbations in the input. Failure to do so can lead to several problems, including costly decisions, reduced user trust, potential security concerns, and lack of replicability. Unfortunately, many fundamental combinatorial algorithms are vulnerable to small input perturbations. To address the impact of input perturbations on algorithms for weighted graph problems, Kumabe and Yoshida (FOCS'23) recently introduced the concept of Lipschitz continuity of algorithms. This work explores this approach and designs Lipschitz continuous algorithms for covering problems, such as the minimum vertex cover, set cover, and feedback vertex set problems.
  Our algorithm for the feedback vertex set problem is based on linear programming, and in the rounding process, we develop and use a technique called cycle sparsification, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08213v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soh Kumabe, Yuichi Yoshida</dc:creator>
    </item>
  </channel>
</rss>
