<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Nov 2024 04:01:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bibliometrics effects of a new item-by-item classification system based on reference reclassification</title>
      <link>https://arxiv.org/abs/2410.23792</link>
      <description>arXiv:2410.23792v1 Announce Type: new 
Abstract: This study presents a comparative analysis between two scientific document classification systems. The first system employs the Scopus journal-based assignment method, adapted to a fractional model, while the second system uses the U1-F-0.8 classification, an item-by-item system based on reclassified references according to the origin of the citers. The study's results are divided into three different sections: the first involves comparisons at the Scopus area level, the second examines comparisons at the category level, and the third tests various bibliometric indicators to identify the variations between the two systems. Highlighting the characteristics of the U1-F-0.8 system, it offers a reduction in the number of categories to which each document is assigned, achieving higher values of single-category assignment compared to the All Science Journal Classification (ASJC). When reclassifying areas and categories, the U1-F-0.8 system tends to accentuate differences at the extreme values, increasing the size of the largest categories and reducing that of the smallest ones. Moreover, the U1-F-0.8 system provides more homogeneous distributions in normalised impacts and adjusts values related to excellence more uniformly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23792v1</guid>
      <category>cs.DL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marcos Pena-Rocha, Maria Rocio Gomez-Crisostomo, Vicente Pablo Guerrero-Bote, Felix de Moya-Anegon</dc:creator>
    </item>
    <item>
      <title>Demonstrating Linked Battery Data To Accelerate Knowledge Flow in Battery Science</title>
      <link>https://arxiv.org/abs/2410.23303</link>
      <description>arXiv:2410.23303v1 Announce Type: cross 
Abstract: Batteries are pivotal for transitioning to a climate-friendly future, leading to a surge in battery research. Scopus (Elsevier) lists 14,388 papers that mention "lithium-ion battery" in 2023 alone, making it infeasible for individuals to keep up. This paper discusses strategies based on structured, semantic, and linked data to manage this information overload. Structured data follows a predefined, machine-readable format; semantic data includes metadata for context; linked data references other semantic data, forming a web of interconnected information. We use a battery-related ontology, BattINFO to standardise terms and enable automated data extraction and analysis. Our methodology integrates full-text search and machine-readable data, enhancing data retrieval and battery testing. We aim to unify commercial cell information and develop tools for the battery community such as manufacturer-independent cycling procedure descriptions and external memory for Large Language Models. Although only a first step, this approach significantly accelerates battery research and digitalizes battery testing, inviting community participation for continuous improvement. We provide the structured data and the tools to access them as open source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23303v1</guid>
      <category>cs.IR</category>
      <category>cs.DL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Dechent, Elias Barbers, Simon Clark, Susanne Lehner, Brady Planden, Masaki Adachi, David A. Howey, Sabine Paarmann</dc:creator>
    </item>
    <item>
      <title>Benchmark Data Repositories for Better Benchmarking</title>
      <link>https://arxiv.org/abs/2410.24100</link>
      <description>arXiv:2410.24100v1 Announce Type: cross 
Abstract: In machine learning research, it is common to evaluate algorithms via their performance on standard benchmark datasets. While a growing body of work establishes guidelines for -- and levies criticisms at -- data and benchmarking practices in machine learning, comparatively less attention has been paid to the data repositories where these datasets are stored, documented, and shared. In this paper, we analyze the landscape of these $\textit{benchmark data repositories}$ and the role they can play in improving benchmarking. This role includes addressing issues with both datasets themselves (e.g., representational harms, construct validity) and the manner in which evaluation is carried out using such datasets (e.g., overemphasis on a few datasets and metrics, lack of reproducibility). To this end, we identify and discuss a set of considerations surrounding the design and use of benchmark data repositories, with a focus on improving benchmarking practices in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24100v1</guid>
      <category>cs.LG</category>
      <category>cs.DL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rachel Longjohn, Markelle Kelly, Sameer Singh, Padhraic Smyth</dc:creator>
    </item>
  </channel>
</rss>
