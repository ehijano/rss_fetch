<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Sep 2024 01:47:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Video-based Analysis Reveals Atypical Social Gaze in People with Autism Spectrum Disorder</title>
      <link>https://arxiv.org/abs/2409.00664</link>
      <description>arXiv:2409.00664v1 Announce Type: new 
Abstract: In this study, we present a quantitative and comprehensive analysis of social gaze in people with autism spectrum disorder (ASD). Diverging from traditional first-person camera perspectives based on eye-tracking technologies, this study utilizes a third-person perspective database from the Autism Diagnostic Observation Schedule, 2nd Edition (ADOS-2) interview videos, encompassing ASD participants and neurotypical individuals as a reference group. Employing computational models, we extracted and processed gaze-related features from the videos of both participants and examiners. The experimental samples were divided into three groups based on the presence of social gaze abnormalities and ASD diagnosis. This study quantitatively analyzed four gaze features: gaze engagement, gaze variance, gaze density map, and gaze diversion frequency. Furthermore, we developed a classifier trained on these features to identify gaze abnormalities in ASD participants. Together, we demonstrated the effectiveness of analyzing social gaze in people with ASD in naturalistic settings, showcasing the potential of third-person video perspectives in enhancing ASD diagnosis through gaze analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00664v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangxu Yu, Mindi Ruan, Chuanbo Hu, Wenqi Li, Lynn K. Paul, Xin Li, Shuo Wang</dc:creator>
    </item>
    <item>
      <title>Real-Time Machine Learning Strategies for a New Kind of Neuroscience Experiments</title>
      <link>https://arxiv.org/abs/2409.01280</link>
      <description>arXiv:2409.01280v1 Announce Type: new 
Abstract: Function and dysfunctions of neural systems are tied to the temporal evolution of neural states. The current limitations in showing their causal role stem largely from the absence of tools capable of probing the brain's internal state in real-time. This gap restricts the scope of experiments vital for advancing both fundamental and clinical neuroscience. Recent advances in real-time machine learning technologies, particularly in analyzing neural time series as nonlinear stochastic dynamical systems, are beginning to bridge this gap. These technologies enable immediate interpretation of and interaction with neural systems, offering new insights into neural computation. However, several significant challenges remain. Issues such as slow convergence rates, high-dimensional data complexities, structured noise, non-identifiability, and a general lack of inductive biases tailored for neural dynamics are key hurdles. Overcoming these challenges is crucial for the full realization of real-time neural data analysis for the causal investigation of neural computation and advanced perturbation based brain machine interfaces. In this paper, we provide a comprehensive perspective on the current state of the field, focusing on these persistent issues and outlining potential paths forward. We emphasize the importance of large-scale integrative neuroscience initiatives and the role of meta-learning in overcoming these challenges. These approaches represent promising research directions that could redefine the landscape of neuroscience experiments and brain-machine interfaces, facilitating breakthroughs in understanding brain function, and treatment of neurological disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01280v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayesha Vermani, Matthew Dowling, Hyungju Jeon, Ian Jordan, Josue Nassar, Yves Bernaerts, Yuan Zhao, Steven Van Vaerenbergh, Il Memming Park</dc:creator>
    </item>
    <item>
      <title>Quantum panprotopsychism and the structure and subject-summing combination problem</title>
      <link>https://arxiv.org/abs/2409.01368</link>
      <description>arXiv:2409.01368v1 Announce Type: new 
Abstract: In a previous paper, we have shown that an ontology of quantum mechanics in terms of states and events with internal phenomenal aspects, that is, a form of panprotopsychism, is well suited to explaining the phenomenal aspects of consciousness. We have proved there that the palette and grain combination problems of panpsychism and panprotopsychism arise from implicit hypotheses based on classical physics about supervenience that are inappropriate at the quantum level, where an exponential number of emergent properties and states arise. In this article, we address what is probably the first and most important combination problem of panpsychism: the subject-summing problem originally posed by William James. We begin by identifying the physical counterparts of the subjects of experience within the quantum panprotopsychic approach presented in that article. To achieve this, we turn to the notion of subject of experience inspired by the idea of prehension proposed by Whitehead and show that this notion can be adapted to the quantum ontology of objects and events. Due to the indeterminacy of quantum mechanics and its causal openness, this ontology also seems to be suitable for the analysis of the remaining aspects of the structure combination problem, which shows how the structuration of consciousness could have evolved from primitive animals to humans. The analysis imposes conditions on possible implementations of quantum cognition mechanisms in the brain and suggests new problems and strategies to address them. In particular, with regard to the structuring of experiences in animals with different degrees of evolutionary development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01368v1</guid>
      <category>q-bio.NC</category>
      <category>physics.hist-ph</category>
      <category>quant-ph</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodolfo Gambini, Jorge Pullin</dc:creator>
    </item>
    <item>
      <title>Deep multivariate autoencoder for capturing complexity in Brain Structure and Behaviour Relationships</title>
      <link>https://arxiv.org/abs/2409.01638</link>
      <description>arXiv:2409.01638v1 Announce Type: new 
Abstract: &lt;div&gt;&lt;p&gt;Diffusion MRI is a powerful tool that serves as a bridge between brain microstructure and cognition. Recent advancements in cognitive neuroscience have highlighted the persistent challenge of understanding how individual differences in brain structure influence behavior, especially in healthy people. While traditional linear models like Canonical Correlation Analysis (CCA) and Partial Least Squares (PLS) have been fundamental in this analysis, they face limitations, particularly with high-dimensional data analysis outside the training sample. To address these issues, we introduce a novel approach using deep learninga multivariate autoencoder model-to explore the complex non-linear relationships between brain microstructure and cognitive functions. The model's architecture involves separate encoder modules for brain structure and cognitive data, with a shared decoder, facilitating the analysis of multivariate patterns across these domains. Both encoders were trained simultaneously, before the decoder, to ensure a good latent representation that captures the phenomenon. Using data from the Human Connectome Project, our study centres on the insula's role in cognitive processes. Through rigorous validation, including 5 sample analyses for out-of-sample analysis, our results demonstrate that the multivariate autoencoder model outperforms traditional methods in capturing and generalizing correlations between brain and behavior beyond the training sample. These findings underscore the potential of deep learning models to enhance our understanding of brain-behavior relationships in cognitive neuroscience, offering more accurate and comprehensive insights despite the complexities inherent in neuroimaging studies.&lt;/p&gt;&lt;/div&gt;</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01638v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Workshop on Computational Diffusion MRI (CDMRI) 2024, International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), Oct 2024, Marrakech (Morocco), France</arxiv:journal_reference>
      <dc:creator>Gabriela G\'omez Jim\'enez (MIND), Demian Wassermann (MIND)</dc:creator>
    </item>
    <item>
      <title>Decoding finger velocity from cortical spike trains with recurrent spiking neural networks</title>
      <link>https://arxiv.org/abs/2409.01762</link>
      <description>arXiv:2409.01762v1 Announce Type: new 
Abstract: Invasive cortical brain-machine interfaces (BMIs) can significantly improve the life quality of motor-impaired patients. Nonetheless, externally mounted pedestals pose an infection risk, which calls for fully implanted systems. Such systems, however, must meet strict latency and energy constraints while providing reliable decoding performance. While recurrent spiking neural networks (RSNNs) are ideally suited for ultra-low-power, low-latency processing on neuromorphic hardware, it is unclear whether they meet the above requirements. To address this question, we trained RSNNs to decode finger velocity from cortical spike trains (CSTs) of two macaque monkeys. First, we found that a large RSNN model outperformed existing feedforward spiking neural networks (SNNs) and artificial neural networks (ANNs) in terms of their decoding accuracy. We next developed a tiny RSNN with a smaller memory footprint, low firing rates, and sparse connectivity. Despite its reduced computational requirements, the resulting model performed substantially better than existing SNN and ANN decoders. Our results thus demonstrate that RSNNs offer competitive CST decoding performance under tight resource constraints and are promising candidates for fully implanted ultra-low-power BMIs with the potential to revolutionize patient care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01762v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tengjun Liu, Julia Gygax, Julian Rossbroich, Yansong Chua, Shaomin Zhang, Friedemann Zenke</dc:creator>
    </item>
    <item>
      <title>Anti-seizure medication load is not correlated with early termination of seizure spread</title>
      <link>https://arxiv.org/abs/2409.01767</link>
      <description>arXiv:2409.01767v1 Announce Type: new 
Abstract: Anti-seizure medications (ASMs) are the mainstay of treatment for epilepsy, yet their effect on seizure spread is not fully understood. Higher ASM doses have been associated with shorter and less severe seizures. Our objective was to test if this effect was due to limiting seizure spread through early termination of otherwise unchanged seizures.
  We retrospectively examined intracranial EEG (iEEG) recordings in 15 subjects that underwent ASM tapering during pre-surgical monitoring. We estimated ASM plasma concentrations based on pharmaco-kinetic modelling. In each subject, we identified seizures that followed the same onset and initial spread patterns, but some seizures terminated early (truncated seizures), and other seizures continued to spread (continuing seizures). We compared ASM concentrations at the times of truncated seizures and continuing seizures.
  We found no substantial difference between ASM concentrations when truncated vs. continuing seizures occurred (Mean difference = 4%, sd = 29%, p=0.6).
  Our results indicate that ASM did not appear to halt established seizures in this cohort. Further research is needed to understand how ASM may modulate seizure duration and severity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01767v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Evans, Sarah J. Gascoigne, Guillermo M. Besne, Chris Thornton, Gabrielle M. Schroeder, Fahmida A Chowdhury, Beate Diehl, John S Duncan, Andrew W McEvoy, Anna Miserocchi, Jane de Tisi, Peter N. Taylor, Yujiang Wang</dc:creator>
    </item>
    <item>
      <title>Connectivity structure and dynamics of nonlinear recurrent neural networks</title>
      <link>https://arxiv.org/abs/2409.01969</link>
      <description>arXiv:2409.01969v1 Announce Type: new 
Abstract: We develop a theory to analyze how structure in connectivity shapes the high-dimensional, internally generated activity of nonlinear recurrent neural networks. Using two complementary methods -- a path-integral calculation of fluctuations around the saddle point, and a recently introduced two-site cavity approach -- we derive analytic expressions that characterize important features of collective activity, including its dimensionality and temporal correlations. To model structure in the coupling matrices of real neural circuits, such as synaptic connectomes obtained through electron microscopy, we introduce the random-mode model, which parameterizes a coupling matrix using random input and output modes and a specified spectrum. This model enables systematic study of the effects of low-dimensional structure in connectivity on neural activity. These effects manifest in features of collective activity, that we calculate, and can be undetectable when analyzing only single-neuron activities. We derive a relation between the effective rank of the coupling matrix and the dimension of activity. By extending the random-mode model, we compare the effects of single-neuron heterogeneity and low-dimensional connectivity. We also investigate the impact of structured overlaps between input and output modes, a feature of biological coupling matrices. Our theory provides tools to relate neural-network architecture and collective dynamics in artificial and biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01969v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David G. Clark, Owen Marschall, Alexander van Meegen, Ashok Litwin-Kumar</dc:creator>
    </item>
    <item>
      <title>FedMinds: Privacy-Preserving Personalized Brain Visual Decoding</title>
      <link>https://arxiv.org/abs/2409.02044</link>
      <description>arXiv:2409.02044v1 Announce Type: new 
Abstract: Exploring the mysteries of the human brain is a long-term research topic in neuroscience. With the help of deep learning, decoding visual information from human brain activity fMRI has achieved promising performance. However, these decoding models require centralized storage of fMRI data to conduct training, leading to potential privacy security issues. In this paper, we focus on privacy preservation in multi-individual brain visual decoding. To this end, we introduce a novel framework called FedMinds, which utilizes federated learning to protect individuals' privacy during model training. In addition, we deploy individual adapters for each subject, thus allowing personalized visual decoding. We conduct experiments on the authoritative NSD datasets to evaluate the performance of the proposed framework. The results demonstrate that our framework achieves high-precision visual decoding along with privacy protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02044v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>eess.IV</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangyin Bao, Duoqian Miao</dc:creator>
    </item>
    <item>
      <title>Anatomical Connections of Primate Mediodorsal and Motor Thalamic Nuclei with the Cortex</title>
      <link>https://arxiv.org/abs/2409.02065</link>
      <description>arXiv:2409.02065v1 Announce Type: new 
Abstract: Non-sensory thalamic nuclei interact with the cortex through thalamocortical and cortico-basal ganglia-thalamocortical loops. Reciprocal connections between the mediodorsal thalamus (MD) and the prefrontal cortex are particularly important in cognition, while the reciprocal connections of the ventromedial (VM), ventral anterior (VA), and ventrolateral (VL) thalamus with the prefrontal and motor cortex are necessary for sensorimotor information processing. However, limited and often oversimplified understanding of the connectivity of the MD, VA, and VL nuclei in primates have hampered development of accurate models that explain their contribution to cognitive and sensorimotor functions. The current prevalent view suggests that the MD connects with the prefrontal cortex, while the VA and VL primarily connect with the premotor and motor cortices. However, past studies have also reported diverse connections that enable these nuclei to integrate information across a multitude of brain systems. In this review, we provide a comprehensive overview of the anatomical connectivity of the primate MD, VA, and VL with the cortex. By synthesizing recent findings, we aim to offer a valuable resource for students, newcomers to the field, and experts developing new theories or models of thalamic function. Our review highlights the complexity of these connections and underscores the need for further research to fully understand the diverse roles of these thalamic nuclei in primates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02065v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bianca Sieveritz, Roozbeh Kiani</dc:creator>
    </item>
    <item>
      <title>Cognitive Networks and Performance Drive fMRI-Based State Classification Using DNN Models</title>
      <link>https://arxiv.org/abs/2409.00003</link>
      <description>arXiv:2409.00003v1 Announce Type: cross 
Abstract: Deep neural network (DNN) models have demonstrated impressive performance in various domains, yet their application in cognitive neuroscience is limited due to their lack of interpretability. In this study we employ two structurally different and complementary DNN-based models, a one-dimensional convolutional neural network (1D-CNN) and a bidirectional long short-term memory network (BiLSTM), to classify individual cognitive states from fMRI BOLD data, with a focus on understanding the cognitive underpinnings of the classification decisions. We show that despite the architectural differences, both models consistently produce a robust relationship between prediction accuracy and individual cognitive performance, such that low performance leads to poor prediction accuracy. To achieve model explainability, we used permutation techniques to calculate feature importance, allowing us to identify the most critical brain regions influencing model predictions. Across models, we found the dominance of visual networks, suggesting that task-driven state differences are primarily encoded in visual processing. Attention and control networks also showed relatively high importance, however, default mode and temporal-parietal networks demonstrated negligible contribution in differentiating cognitive states. Additionally, we observed individual trait-based effects and subtle model-specific differences, such that 1D-CNN showed slightly better overall performance, while BiLSTM showed better sensitivity for individual behavior; these initial findings require further research and robustness testing to be fully established. Our work underscores the importance of explainable DNN models in uncovering the neural mechanisms underlying cognitive state transitions, providing a foundation for future work in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00003v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Murat Kucukosmanoglu, Javier O. Garcia, Justin Brooks, Kanika Bansal</dc:creator>
    </item>
    <item>
      <title>EEG Right &amp; Left Voluntary Hand Movement-based Virtual Brain-Computer Interfacing Keyboard with Machine Learning and a Hybrid Bi-Directional LSTM-GRU Model</title>
      <link>https://arxiv.org/abs/2409.00035</link>
      <description>arXiv:2409.00035v1 Announce Type: cross 
Abstract: This study focuses on EEG-based BMI for detecting voluntary keystrokes, aiming to develop a reliable brain-computer interface (BCI) to simulate and anticipate keystrokes, especially for individuals with motor impairments. The methodology includes extensive segmentation, event alignment, ERP plot analysis, and signal analysis. Different deep learning models are trained to classify EEG data into three categories -- `resting state' (0), `d' key press (1), and `l' key press (2). Real-time keypress simulation based on neural activity is enabled through integration with a tkinter-based graphical user interface. Feature engineering utilized ERP windows, and the SVC model achieved 90.42% accuracy in event classification. Additionally, deep learning models -- MLP (89% accuracy), Catboost (87.39% accuracy), KNN (72.59%), Gaussian Naive Bayes (79.21%), Logistic Regression (90.81% accuracy), and a novel Bi-Directional LSTM-GRU hybrid model (89% accuracy) -- were developed for BCI keyboard simulation. Finally, a GUI was created to predict and simulate keystrokes using the trained MLP model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00035v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biplov Paneru, Bishwash Paneru, Sanjog Chhetri Sapkota</dc:creator>
    </item>
    <item>
      <title>Statistical mechanics for networks of real neurons</title>
      <link>https://arxiv.org/abs/2409.00412</link>
      <description>arXiv:2409.00412v1 Announce Type: cross 
Abstract: Perceptions and actions, thoughts and memories result from coordinated activity in hundreds or even thousands of neurons in the brain. It is an old dream of the physics community to provide a statistical mechanics description for these and other emergent phenomena of life. These aspirations appear in a new light because of developments in our ability to measure the electrical activity of the brain, sampling thousands of individual neurons simultaneously over hours or days. We review the progress that has been made in bringing theory and experiment together, focusing on maximum entropy methods and a phenomenological renormalization group. These approaches have uncovered new, quantitatively reproducible collective behaviors in networks of real neurons, and provide examples of rich parameter--free predictions that agree in detail with experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00412v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leenoy Meshulam, William Bialek</dc:creator>
    </item>
    <item>
      <title>Mechanisms underlying the response of mouse cortical networks to optogenetic manipulation</title>
      <link>https://arxiv.org/abs/1907.00816</link>
      <description>arXiv:1907.00816v2 Announce Type: replace 
Abstract: GABAergic interneurons can be subdivided into three subclasses: parvalbumin positive (PV), somatostatin positive (SOM) and serotonin positive neurons. With principal cells (PCs) they form complex networks. We examine PCs and PV responses in mouse anterior lateral motor cortex (ALM) and barrel cortex (S1) upon PV photostimulation in vivo. In layer 5, the PV response is paradoxical: photoexcitation reduces their activity. This is not the case in ALM layer 2/3. We combine analytical calculations and numerical simulations to investigate how these results constrain the architecture. Two-population models cannot account for the results. Networks with three inhibitory populations and V1-like architecture account for the data in ALM layer 2/3. Our data in layer 5 can be accounted for if SOM neurons receive inputs only from PCs and PV neurons. In both four-population models, the paradoxical effect implies not too strong recurrent excitation. It is not evidence for stabilization by inhibition.</description>
      <guid isPermaLink="false">oai:arXiv.org:1907.00816v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Mahrach, Guang Chen, Nuo Li, Carl van Vreeswijk, David Hansel</dc:creator>
    </item>
    <item>
      <title>Network Structure Governs Drosophila Brain Functionality</title>
      <link>https://arxiv.org/abs/2404.17128</link>
      <description>arXiv:2404.17128v4 Announce Type: replace 
Abstract: How intelligence emerges from living beings has been a fundamental question in neuroscience. However, it remains largely unanswered due to the complex neuronal dynamics and intricate connections between neurons in real neural systems. To address this challenge, we leveraged the largest available adult Drosophila connectome data set, and constructed a comprehensive computational framework based on simplified neuronal activation mechanisms to simulate the observed activation behavior within the connectome. The results revealed that even with rudimentary neuronal activation mechanisms, models grounded in real neural network structures can generate activation patterns strikingly similar to those observed in the actual brain. A significant discovery was the consistency of activation patterns across various neuronal dynamic models. This consistency, achieved with the same network structure, underscores the pivotal role of network topology in neural information processing. These results challenge the prevailing view that solely relies on neuron count or complex individual neuron dynamics. Further analysis demonstrated a near-complete separation of the visual and olfactory systems at the network level. Moreover, we found that the network distance, rather than spatial distance, is the primary determinant of activation patterns. Additionally, our experiments revealed that a reconnect rate of at least 0.1% was sufficient to disrupt the previously observed activation patterns. We also observed synergistic effects between the brain hemispheres: Even with unilateral input stimuli, visual-related neurons in both hemispheres were activated, highlighting the importance of interhemispheric communication. These findings emphasize the crucial role of network structure in neural activation and offer novel insights into the fundamental principles governing brain functionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17128v4</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Zhang, Pengcheng Yang, Jiawei Feng, Qiang Luo, Wei Lin, Xin Lu</dc:creator>
    </item>
    <item>
      <title>Exploring neural oscillations during speech perception via surrogate gradient spiking neural networks</title>
      <link>https://arxiv.org/abs/2404.14024</link>
      <description>arXiv:2404.14024v2 Announce Type: replace-cross 
Abstract: Understanding cognitive processes in the brain demands sophisticated models capable of replicating neural dynamics at large scales. We present a physiologically inspired speech recognition architecture, compatible and scalable with deep learning frameworks, and demonstrate that end-to-end gradient descent training leads to the emergence of neural oscillations in the central spiking neural network. Significant cross-frequency couplings, indicative of these oscillations, are measured within and across network layers during speech processing, whereas no such interactions are observed when handling background noise inputs. Furthermore, our findings highlight the crucial inhibitory role of feedback mechanisms, such as spike frequency adaptation and recurrent connections, in regulating and synchronising neural activity to improve recognition performance. Overall, on top of developing our understanding of synchronisation phenomena notably observed in the human auditory pathway, our architecture exhibits dynamic and efficient information processing, with relevance to neuromorphic technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14024v2</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alexandre Bittar, Philip N. Garner</dc:creator>
    </item>
    <item>
      <title>Networks with many structural scales: a Renormalization Group perspective</title>
      <link>https://arxiv.org/abs/2406.19104</link>
      <description>arXiv:2406.19104v2 Announce Type: replace-cross 
Abstract: Scale invariance profoundly influences the dynamics and structure of complex systems, spanning from critical phenomena to network architecture. Here, we propose a precise definition of scale-invariant networks by leveraging the concept of a constant entropy loss rate across scales in a renormalization-group coarse-graining setting. This framework enables us to differentiate between scale-free and scale-invariant networks, revealing distinct characteristics within each class. Furthermore, we offer a comprehensive inventory of genuinely scale-invariant networks, both natural and artificially constructed, demonstrating, e.g., that the human connectome exhibits notable features of scale invariance. Our findings open new avenues for exploring the scale-invariant structural properties crucial in biological and socio-technological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19104v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 04 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Poggialini, Pablo Villegas, Miguel A. Mu\~noz, Andrea Gabrielli</dc:creator>
    </item>
  </channel>
</rss>
