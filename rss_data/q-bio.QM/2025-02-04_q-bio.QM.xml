<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 02:53:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Blood Glucose Level Prediction in Type 1 Diabetes Using Machine Learning</title>
      <link>https://arxiv.org/abs/2502.00065</link>
      <description>arXiv:2502.00065v1 Announce Type: new 
Abstract: Type 1 Diabetes is a chronic autoimmune condition in which the immune system attacks and destroys insulin-producing beta cells in the pancreas, resulting in little to no insulin production. Insulin helps glucose in your blood enter your muscle, fat, and liver cells so they can use it for energy or store it for later use. If insulin is insufficient, it causes sugar to build up in the blood and leads to serious health problems. People with Type 1 Diabetes need synthetic insulin every day. In diabetes management, continuous glucose monitoring is an important feature that provides near real-time blood glucose data. It is useful in deciding the synthetic insulin dose. In this research work, we used machine learning tools, deep neural networks, deep reinforcement learning, and voting and stacking regressors to predict blood glucose levels at 30-min time intervals using the latest DiaTrend dataset. Predicting blood glucose levels is useful in better diabetes management systems. The trained models were compared using several evaluation metrics. Our evaluation results demonstrate the performance of various models across different glycemic conditions for blood glucose prediction. The source codes of this work can be found in: https://github.com/soon-jynn-chu/t1d_bg_prediction</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00065v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soon Jynn Chu, Nalaka Amarasiri, Sandesh Giri, Priyata Kafle</dc:creator>
    </item>
    <item>
      <title>MorphoITH: A Framework for Deconvolving Intra-Tumor Heterogeneity Using Tissue Morphology</title>
      <link>https://arxiv.org/abs/2502.00979</link>
      <description>arXiv:2502.00979v1 Announce Type: new 
Abstract: The ability of tumors to evolve and adapt by developing subclones in different genetic and epigenetic states is a major challenge in oncology. Traditional tools like multi-regional sequencing used to study tumor evolution and the resultant intra-tumor heterogeneity (ITH) are often impractical because of their resource-intensiveness and limited scalability. Here, we present MorphoITH, a novel framework that leverages histopathology slides to deconvolve molecular ITH through tissue morphology. MorphoITH integrates a self-supervised deep learning similarity measure to capture phenotypic variation across multiple dimensions (cytology, architecture, and microenvironment) with rigorous methods to eliminate spurious sources of variation. Using a prototype of ITH, clear cell renal cell carcinoma (ccRCC), we show that MorphoITH captures clinically-significant biological features, such as vascular architecture and nuclear grades. Furthermore, we find that MorphoITH recognizes differential biological states corresponding to subclonal changes in key driver genes (BAP1/PBRM1/SETD2). Finally, by applying MorphoITH to a multi-regional sequencing experiment, we postulate evolutionary trajectories that largely recapitulate genetic evolution. In summary, MorphoITH provides a scalable phenotypic lens that bridges the gap between histopathology and genomics, advancing precision oncology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00979v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aleksandra Weronika Nielsen, Hafez Eslami Manoochehri, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jay Jasti, Mehrdad Nourani, Dinesh Rakheja, James Brugarolas, Payal Kapur, Satwik Rajaram</dc:creator>
    </item>
    <item>
      <title>Deep generative computed perfusion-deficit mapping of ischaemic stroke</title>
      <link>https://arxiv.org/abs/2502.01334</link>
      <description>arXiv:2502.01334v1 Announce Type: new 
Abstract: Focal deficits in ischaemic stroke result from impaired perfusion downstream of a critical vascular occlusion. While parenchymal lesions are traditionally used to predict clinical deficits, the underlying pattern of disrupted perfusion provides information upstream of the lesion, potentially yielding earlier predictive and localizing signals. Such perfusion maps can be derived from routine CT angiography (CTA) widely deployed in clinical practice. Analysing computed perfusion maps from 1,393 CTA-imaged-patients with acute ischaemic stroke, we use deep generative inference to localise neural substrates of NIHSS sub-scores. We show that our approach replicates known lesion-deficit relations without knowledge of the lesion itself and reveals novel neural dependents. The high achieved anatomical fidelity suggests acute CTA-derived computed perfusion maps may be of substantial clinical-and-scientific value in rich phenotyping of acute stroke. Using only hyperacute imaging, deep generative inference could power highly expressive models of functional anatomical relations in ischaemic stroke within the pre-interventional window.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01334v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chayanin Tangwiriyasakul, Pedro Borges, Guilherme Pombo, Stefano Moriconi, Michael S. Elmalem, Paul Wright, Yee-Haur Mah, Jane Rondina, Robert Gray, Sebastien Ourselin, Parashkev Nachev, M. Jorge Cardoso</dc:creator>
    </item>
    <item>
      <title>Leveraging Large Language Models to Predict Antibody Biological Activity Against Influenza A Hemagglutinin</title>
      <link>https://arxiv.org/abs/2502.00694</link>
      <description>arXiv:2502.00694v1 Announce Type: cross 
Abstract: Monoclonal antibodies (mAbs) represent one of the most prevalent FDA-approved modalities for treating autoimmune diseases, infectious diseases, and cancers. However, discovery and development of therapeutic antibodies remains a time-consuming and expensive process. Recent advancements in machine learning (ML) and artificial intelligence (AI) have shown significant promise in revolutionizing antibody discovery and optimization. In particular, models that predict antibody biological activity enable in-silico evaluation of binding and functional properties; such models can prioritize antibodies with the highest likelihoods of success in costly and time-intensive laboratory testing procedures. We here explore an AI model for predicting the binding and receptor blocking activity of antibodies against influenza A hemagglutinin (HA) antigens. Our present model is developed with the MAMMAL framework for biologics discovery to predict antibody-antigen interactions using only sequence information. To evaluate the model's performance, we tested it under various data split conditions to mimic real-world scenarios.
  Our models achieved an AUROC $\geq$ 0.91 for predicting the activity of existing antibodies against seen HAs and an AUROC of 0.9 for unseen HAs. For novel antibody activity prediction, the AUROC was 0.73, which further declined to 0.63-0.66 under stringent constraints on similarity to existing antibodies. These results demonstrate the potential of AI foundation models to transform antibody design by reducing dependence on extensive laboratory testing and enabling more efficient prioritization of antibody candidates. Moreover, our findings emphasize the critical importance of diverse and comprehensive antibody datasets to improve the generalization of prediction models, particularly for novel antibody development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00694v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ella Barkan, Ibrahim Siddiqui, Kevin J. Cheng, Alex Golts, Yoel Shoshan, Jeffrey K. Weber, Yailin Campos Mota, Michal Ozery-Flato, Giuseppe A. Sautto</dc:creator>
    </item>
    <item>
      <title>Optimizing Global Genomic Surveillance for Early Detection of Emerging SARS-CoV-2 Variants</title>
      <link>https://arxiv.org/abs/2502.00934</link>
      <description>arXiv:2502.00934v1 Announce Type: cross 
Abstract: The global spread of viruses underscores the critical need for effective genomic surveillance to detect emerging variants and guide interventions. However, high costs and uneven resource distribution hinder its global implementation. This study demonstrates that optimizing genomic surveillance by targeting resources on international travelers in travel hubs, significantly improves the early detection of SARS-CoV-2 variants. Using a metapopulation multiple-strain model calibrated with extensive data, we show that targeting travelers effectively reduces detection delays without additional costs in retrospective analyses of the Omicron variant outbreak. Further, simulations indicate that focusing surveillance on key travel hubs outperform baseline practices in detecting future variants, even with reduced resources. This approach also remains effective in future pandemic scenarios with varying reproductive numbers (R_eff) and vaccine effectiveness. These findings provide a sustainable framework for strengthening health security, offering actionable insights for optimizing genomic surveillance and improving preparedness for emerging infectious threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00934v1</guid>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haogao Gu, Jifan Li, Wanying Sun, Mengting Li, Kathy Leung, Joseph T. Wu, Hsiang-Yu Yuan, Maggie H. Wang, Bingyi Yang, Matthew R. McKay, Ning Ning, Leo L. M. Poon</dc:creator>
    </item>
    <item>
      <title>Deep Active Learning based Experimental Design to Uncover Synergistic Genetic Interactions for Host Targeted Therapeutics</title>
      <link>https://arxiv.org/abs/2502.01012</link>
      <description>arXiv:2502.01012v1 Announce Type: cross 
Abstract: Recent technological advances have introduced new high-throughput methods for studying host-virus interactions, but testing synergistic interactions between host gene pairs during infection remains relatively slow and labor intensive. Identification of multiple gene knockdowns that effectively inhibit viral replication requires a search over the combinatorial space of all possible target gene pairs and is infeasible via brute-force experiments. Although active learning methods for sequential experimental design have shown promise, existing approaches have generally been restricted to single-gene knockdowns or small-scale double knockdown datasets. In this study, we present an integrated Deep Active Learning (DeepAL) framework that incorporates information from a biological knowledge graph (SPOKE, the Scalable Precision Medicine Open Knowledge Engine) to efficiently search the configuration space of a large dataset of all pairwise knockdowns of 356 human genes in HIV infection. Through graph representation learning, the framework is able to generate task-specific representations of genes while also balancing the exploration-exploitation trade-off to pinpoint highly effective double-knockdown pairs. We additionally present an ensemble method for uncertainty quantification and an interpretation of the gene pairs selected by our algorithm via pathway analysis. To our knowledge, this is the first work to show promising results on double-gene knockdown experimental data of appreciable scale (356 by 356 matrix).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01012v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haonan Zhu, Mary Silva, Jose Cadena, Braden Soper, Micha{\l} Lisicki, Braian Peetoom, Sergio E. Baranzini, Shivshankar Sundaram, Priyadip Ray, Jeff Drocco</dc:creator>
    </item>
    <item>
      <title>Vessel segmentation for X-separation</title>
      <link>https://arxiv.org/abs/2502.01023</link>
      <description>arXiv:2502.01023v1 Announce Type: cross 
Abstract: $\chi$-separation is an advanced quantitative susceptibility mapping (QSM) method that is designed to generate paramagnetic ($\chi_{para}$) and diamagnetic ($|\chi_{dia}|$) susceptibility maps, reflecting the distribution of iron and myelin in the brain. However, vessels have shown artifacts, interfering with the accurate quantification of iron and myelin in applications. To address this challenge, a new vessel segmentation method for $\chi$-separation is developed. The method comprises three steps: 1) Seed generation from $\textit{R}_2^*$ and the product of $\chi_{para}$ and $|\chi_{dia}|$ maps; 2) Region growing, guided by vessel geometry, creating a vessel mask; 3) Refinement of the vessel mask by excluding non-vessel structures. The performance of the method was compared to conventional vessel segmentation methods both qualitatively and quantitatively. To demonstrate the utility of the method, it was tested in two applications: quantitative evaluation of a neural network-based $\chi$-separation reconstruction method ($\chi$-sepnet-$\textit{R}_2^*$) and population-averaged region of interest (ROI) analysis. The proposed method demonstrates superior performance to the conventional vessel segmentation methods, effectively excluding the non-vessel structures, achieving the highest Dice score coefficient. For the applications, applying vessel masks report notable improvements for the quantitative evaluation of $\chi$-sepnet-$\textit{R}_2^*$ and statistically significant differences in population-averaged ROI analysis. These applications suggest excluding vessels when analyzing the $\chi$-separation maps provide more accurate evaluations. The proposed method has the potential to facilitate various applications, offering reliable analysis through the generation of a high-quality vessel mask.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01023v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taechang Kim, Sooyeon Ji, Kyeongseon Min, Minjun Kim, Jonghyo Youn, Chungseok Oh, Jiye Kim, Jongho Lee</dc:creator>
    </item>
    <item>
      <title>FragmentNet: Adaptive Graph Fragmentation for Graph-to-Sequence Molecular Representation Learning</title>
      <link>https://arxiv.org/abs/2502.01184</link>
      <description>arXiv:2502.01184v1 Announce Type: cross 
Abstract: Molecular property prediction uses molecular structure to infer chemical properties. Chemically interpretable representations that capture meaningful intramolecular interactions enhance the usability and effectiveness of these predictions. However, existing methods often rely on atom-based or rule-based fragment tokenization, which can be chemically suboptimal and lack scalability. We introduce FragmentNet, a graph-to-sequence foundation model with an adaptive, learned tokenizer that decomposes molecular graphs into chemically valid fragments while preserving structural connectivity. FragmentNet integrates VQVAE-GCN for hierarchical fragment embeddings, spatial positional encodings for graph serialization, global molecular descriptors, and a transformer. Pre-trained with Masked Fragment Modeling and fine-tuned on MoleculeNet tasks, FragmentNet outperforms models with similarly scaled architectures and datasets while rivaling larger state-of-the-art models requiring significantly more resources. This novel framework enables adaptive decomposition, serialization, and reconstruction of molecular graphs, facilitating fragment-based editing and visualization of property trends in learned embeddings - a powerful tool for molecular design and optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01184v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.chem-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ankur Samanta, Rohan Gupta, Aditi Misra, Christian McIntosh Clarke, Jayakumar Rajadas</dc:creator>
    </item>
    <item>
      <title>Molecular Odor Prediction with Harmonic Modulated Feature Mapping and Chemically-Informed Loss</title>
      <link>https://arxiv.org/abs/2502.01296</link>
      <description>arXiv:2502.01296v1 Announce Type: cross 
Abstract: Molecular odor prediction has great potential across diverse fields such as chemistry, pharmaceuticals, and environmental science, enabling the rapid design of new materials and enhancing environmental monitoring. However, current methods face two main challenges: First, existing models struggle with non-smooth objective functions and the complexity of mixed feature dimensions; Second, datasets suffer from severe label imbalance, which hampers model training, particularly in learning minority class labels. To address these issues, we introduce a novel feature mapping method and a molecular ensemble optimization loss function. By incorporating feature importance learning and frequency modulation, our model adaptively adjusts the contribution of each feature, efficiently capturing the intricate relationship between molecular structures and odor descriptors. Our feature mapping preserves feature independence while enhancing the model's efficiency in utilizing molecular features through frequency modulation. Furthermore, the proposed loss function dynamically adjusts label weights, improves structural consistency, and strengthens label correlations, effectively addressing data imbalance and label co-occurrence challenges. Experimental results show that our method significantly can improves the accuracy of molecular odor prediction across various deep learning models, demonstrating its promising potential in molecular structure representation and chemoinformatics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01296v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>HongXin Xie, JianDe Sun, Yi Shao, Shuai Li, Sujuan Hou, YuLong Sun, Yuxiang Liu</dc:creator>
    </item>
    <item>
      <title>Molecular Odor Prediction Based on Multi-Feature Graph Attention Networks</title>
      <link>https://arxiv.org/abs/2502.01430</link>
      <description>arXiv:2502.01430v1 Announce Type: cross 
Abstract: Olfactory perception plays a critical role in both human and organismal interactions, yet understanding of its underlying mechanisms and influencing factors remain insufficient. Molecular structures influence odor perception through intricate biochemical interactions, and accurately quantifying structure-odor relationships presents significant challenges. The Quantitative Structure-Odor Relationship (QSOR) task, which involves predicting the associations between molecular structures and their corresponding odors, seeks to address these challenges. To this end, we propose a method for QSOR, utilizing Graph Attention Networks to model molecular structures and capture both local and global features. Unlike conventional QSOR approaches reliant on predefined descriptors, our method leverages diverse molecular feature extraction techniques to automatically learn comprehensive representations. This integration enhances the model's capacity to handle complex molecular information, improves prediction accuracy. Our approach demonstrates clear advantages in QSOR prediction tasks, offering valuable insights into the application of deep learning in cheminformatics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01430v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>HongXin Xie, JianDe Sun, Yi Shao, Shuai Li, Sujuan Hou, YuLong Sun, Jian Wang</dc:creator>
    </item>
    <item>
      <title>VisTA: Vision-Text Alignment Model with Contrastive Learning using Multimodal Data for Evidence-Driven, Reliable, and Explainable Alzheimer's Disease Diagnosis</title>
      <link>https://arxiv.org/abs/2502.01535</link>
      <description>arXiv:2502.01535v1 Announce Type: cross 
Abstract: Objective: Assessing Alzheimer's disease (AD) using high-dimensional radiology images is clinically important but challenging. Although Artificial Intelligence (AI) has advanced AD diagnosis, it remains unclear how to design AI models embracing predictability and explainability. Here, we propose VisTA, a multimodal language-vision model assisted by contrastive learning, to optimize disease prediction and evidence-based, interpretable explanations for clinical decision-making.
  Methods: We developed VisTA (Vision-Text Alignment Model) for AD diagnosis. Architecturally, we built VisTA from BiomedCLIP and fine-tuned it using contrastive learning to align images with verified abnormalities and their descriptions. To train VisTA, we used a constructed reference dataset containing images, abnormality types, and descriptions verified by medical experts. VisTA produces four outputs: predicted abnormality type, similarity to reference cases, evidence-driven explanation, and final AD diagnoses. To illustrate VisTA's efficacy, we reported accuracy metrics for abnormality retrieval and dementia prediction. To demonstrate VisTA's explainability, we compared its explanations with human experts' explanations.
  Results: Compared to 15 million images used for baseline pretraining, VisTA only used 170 samples for fine-tuning and obtained significant improvement in abnormality retrieval and dementia prediction. For abnormality retrieval, VisTA reached 74% accuracy and an AUC of 0.87 (26% and 0.74, respectively, from baseline models). For dementia prediction, VisTA achieved 88% accuracy and an AUC of 0.82 (30% and 0.57, respectively, from baseline models). The generated explanations agreed strongly with human experts' and provided insights into the diagnostic process. Taken together, VisTA optimize prediction, clinical reasoning, and explanation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01535v1</guid>
      <category>cs.CV</category>
      <category>cs.CL</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duy-Cat Can, Linh D. Dang, Quang-Huy Tang, Dang Minh Ly, Huong Ha, Guillaume Blanc, Oliver Y. Ch\'en, Binh T. Nguyen</dc:creator>
    </item>
    <item>
      <title>Advancing bioinformatics with large language models: components, applications and perspectives</title>
      <link>https://arxiv.org/abs/2401.04155</link>
      <description>arXiv:2401.04155v2 Announce Type: replace 
Abstract: Large language models (LLMs) are a class of artificial intelligence models based on deep learning, which have great performance in various tasks, especially in natural language processing (NLP). Large language models typically consist of artificial neural networks with numerous parameters, trained on large amounts of unlabeled input using self-supervised or semi-supervised learning. However, their potential for solving bioinformatics problems may even exceed their proficiency in modeling human language. In this review, we will provide a comprehensive overview of the essential components of large language models (LLMs) in bioinformatics, spanning genomics, transcriptomics, proteomics, drug discovery, and single-cell analysis. Key aspects covered include tokenization methods for diverse data types, the architecture of transformer models, the core attention mechanism, and the pre-training processes underlying these models. Additionally, we will introduce currently available foundation models and highlight their downstream applications across various bioinformatics domains. Finally, drawing from our experience, we will offer practical guidance for both LLM users and developers, emphasizing strategies to optimize their use and foster further innovation in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04155v2</guid>
      <category>q-bio.QM</category>
      <category>cs.CL</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiajia Liu, Mengyuan Yang, Yankai Yu, Haixia Xu, Tiangang Wang, Kang Li, Xiaobo Zhou</dc:creator>
    </item>
    <item>
      <title>MitraClip Device Automated Localization in 3D Transesophageal Echocardiography via Deep Learning</title>
      <link>https://arxiv.org/abs/2412.15013</link>
      <description>arXiv:2412.15013v2 Announce Type: replace 
Abstract: The MitraClip is the most widely percutaneous treatment for mitral regurgitation, typically performed under the real-time guidance of 3D transesophagel echocardiography (TEE). However, artifacts and low image contrast in echocardiography hinder accurate clip visualization. This study presents an automated pipeline for clip detection from 3D TEE images. An Attention UNet was employed to segment the device, while a DenseNet classifier predicted its configuration among ten possible states, ranging from fully closed to fully open. Based on the predicted configuration, a template model derived from computer-aided design (CAD) was automatically registered to refine the segmentation and enable quantitative characterization of the device. The pipeline was trained and validated on 196 3D TEE images acquired using a heart simulator, with ground-truth annotations refined through CAD-based templates. The Attention UNet achieved an average surface distance of 0.76 mm and 95% Hausdorff distance of 2.44 mm for segmentation, while the DenseNet achieved an average weighted F1-score of 0.75 for classification. Post-refinement, segmentation accuracy improved, with average surface distance and 95% Hausdorff distance reduced to 0.75 mm and 2.05 mm, respectively. This pipeline enhanced clip visualization, providing fast and accurate detection with quantitative feedback, potentially improving procedural efficiency and reducing adverse outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15013v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Munaf\`o, Simone Saitta, Luca Vicentini, Davide Tondi, Veronica Ruozzi, Francesco Sturla, Giacomo Ingallina, Andrea Guidotti, Eustachio Agricola, Emiliano Votta</dc:creator>
    </item>
  </channel>
</rss>
