<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Object Detection with Deep Learning for Rare Event Search in the GADGET II TPC</title>
      <link>https://arxiv.org/abs/2501.17892</link>
      <description>arXiv:2501.17892v1 Announce Type: cross 
Abstract: In the pursuit of identifying rare two-particle events within the GADGET II Time Projection Chamber (TPC), this paper presents a comprehensive approach for leveraging Convolutional Neural Networks (CNNs) and various data processing methods. To address the inherent complexities of 3D TPC track reconstructions, the data is expressed in 2D projections and 1D quantities. This approach capitalizes on the diverse data modalities of the TPC, allowing for the efficient representation of the distinct features of the 3D events, with no loss in topology uniqueness. Additionally, it leverages the computational efficiency of 2D CNNs and benefits from the extensive availability of pre-trained models. Given the scarcity of real training data for the rare events of interest, simulated events are used to train the models to detect real events. To account for potential distribution shifts when predominantly depending on simulations, significant perturbations are embedded within the simulations. This produces a broad parameter space that works to account for potential physics parameter and detector response variations and uncertainties. These parameter-varied simulations are used to train sensitive 2D CNN object detectors. When combined with 1D histogram peak detection algorithms, this multi-modal detection framework is highly adept at identifying rare, two-particle events in data taken during experiment 21072 at the Facility for Rare Isotope Beams (FRIB), demonstrating a 100% recall for events of interest. We present the methods and outcomes of our investigation and discuss the potential future applications of these techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17892v1</guid>
      <category>physics.ins-det</category>
      <category>nucl-ex</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tyler Wheeler, S. Ravishankar, C. Wrede, A. Andalib, A. Anthony, Y. Ayyad, B. Jain, A. Jaros, R. Mahajan, L. Schaedig, A. Adams, S. Ahn, J. M. Allmond, D. Bardayan, D. Bazin, K. Bosmpotinis, T. Budner, S. R. Carmichael, S. M. Cha, A. Chen, K. A. Chipps, J. M. Christie, I. Cox, J. Dopfer, M. Friedman, J. Garcia-Duarte, E. Good, T. J. Gray, A. Green, R. Grzywacz, K. Hahn, R. Jain, E. Jensen, T. King, S. Liddick, B. Longfellow, R. Lubna, C. Marshall, Y. Mishnayot, A. J. Mitchell, F. Montes, T. H. Ogunbeku, J. Owens-Fryar, S. D. Pain, J. Pereira, E. Pollacco, A. M. Rogers, M. Z. Serikow, K. Setoodehnia, L. J. Sun, J. Surbrook, A. Tsantiri, L. E. Weghorn</dc:creator>
    </item>
    <item>
      <title>Aspects of Spatially-Correlated Random Fields: Extreme-Value Statistics and Clustering Properties</title>
      <link>https://arxiv.org/abs/2501.17936</link>
      <description>arXiv:2501.17936v1 Announce Type: cross 
Abstract: Rare events of large-scale spatially-correlated exponential random fields are studied. The influence of spatial correlations on clustering and non-sphericity is investigated. The size of the performed simulations permits to study beyond-$7.5$-sigma events ($1$ in $10^{13}$). As an application, this allows to resolve individual Hubble patches which fulfill the condition for primordial black hole formation. It is argued that their mass spectrum is drastically altered due to co-collapse of clustered overdensities as well as the mutual threshold-lowering through the latter. Furthermore, the corresponding non-sphericities imply possibly large changes in the initial black hole spin distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17936v1</guid>
      <category>astro-ph.CO</category>
      <category>gr-qc</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ka Hei Choi, James Creswell, Florian Kuhnel, Dominik J. Schwarz</dc:creator>
    </item>
    <item>
      <title>DeepExtractor: Time-domain reconstruction of signals and glitches in gravitational wave data with deep learning</title>
      <link>https://arxiv.org/abs/2501.18423</link>
      <description>arXiv:2501.18423v1 Announce Type: cross 
Abstract: Gravitational wave (GW) interferometers, detect faint signals from distant astrophysical events, such as binary black hole mergers. However, their high sensitivity also makes them susceptible to background noise, which can obscure these signals. This noise often includes transient artifacts called "glitches" that can mimic astrophysical signals or mask their characteristics. Fast and accurate reconstruction of both signals and glitches is crucial for reliable scientific inference. In this study, we present DeepExtractor, a deep learning framework designed to reconstruct signals and glitches with power exceeding interferometer noise, regardless of their source. We design DeepExtractor to model the inherent noise distribution of GW interferometers, following conventional assumptions that the noise is Gaussian and stationary over short time scales. It operates by predicting and subtracting the noise component of the data, retaining only the clean reconstruction. Our approach achieves superior generalization capabilities for arbitrary signals and glitches compared to methods that directly map inputs to the clean training waveforms. We validate DeepExtractor's effectiveness through three experiments: (1) reconstructing simulated glitches injected into simulated detector noise, (2) comparing performance with the state-of-the-art BayesWave algorithm, and (3) analyzing real data from the Gravity Spy dataset to demonstrate effective glitch subtraction from LIGO strain data. DeepExtractor achieves a median mismatch of only 0.9% for simulated glitches, outperforming several deep learning baselines. Additionally, DeepExtractor surpasses BayesWave in glitch recovery, offering a dramatic computational speedup by reconstructing one glitch sample in approx. 0.1 seconds on a CPU, compared to BayesWave's processing time of approx. one hour per glitch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18423v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>physics.ins-det</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Dooney, Harsh Narola, Stefano Bromuri, R. Lyana Curier, Chris Van Den Broeck, Sarah Caudill, Daniel Stanley Tan</dc:creator>
    </item>
    <item>
      <title>Effectiveness of denoising diffusion probabilistic models for fast and high-fidelity whole-event simulation in high-energy heavy-ion experiments</title>
      <link>https://arxiv.org/abs/2406.01602</link>
      <description>arXiv:2406.01602v2 Announce Type: replace 
Abstract: Artificial intelligence (AI) generative models, such as generative adversarial networks (GANs), variational auto-encoders, and normalizing flows, have been widely used and studied as efficient alternatives for traditional scientific simulations. However, they have several drawbacks, including training instability and inability to cover the entire data distribution, especially for regions where data are rare. This is particularly challenging for whole-event, full-detector simulations in high-energy heavy-ion experiments, such as sPHENIX at the Relativistic Heavy Ion Collider and Large Hadron Collider experiments, where thousands of particles are produced per event and interact with the detector. This work investigates the effectiveness of Denoising Diffusion Probabilistic Models (DDPMs) as an AI-based generative surrogate model for the sPHENIX experiment that includes the heavy-ion event generation and response of the entire calorimeter stack. DDPM performance in sPHENIX simulation data is compared with a popular rival, GANs. Results show that both DDPMs and GANs can reproduce the data distribution where the examples are abundant (low-to-medium calorimeter energies). Nonetheless, DDPMs significantly outperform GANs, especially in high-energy regions where data are rare. Additionally, DDPMs exhibit superior stability compared to GANs. The results are consistent between both central and peripheral centrality heavy-ion collision events. Moreover, DDPMs offer a substantial speedup of approximately a factor of 100 compared to the traditional Geant4 simulation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01602v2</guid>
      <category>physics.data-an</category>
      <category>hep-ex</category>
      <category>nucl-ex</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevC.110.034912</arxiv:DOI>
      <arxiv:journal_reference>Phys.Rev.C 110 (2024) 3, 034912</arxiv:journal_reference>
      <dc:creator>Yeonju Go, Dmitrii Torbunov, Timothy Rinn, Yi Huang, Haiwang Yu, Brett Viren, Meifeng Lin, Yihui Ren, Jin Huang</dc:creator>
    </item>
    <item>
      <title>Data-driven assessment of optimal spatiotemporal resolutions for information extraction in noisy time series data</title>
      <link>https://arxiv.org/abs/2412.13741</link>
      <description>arXiv:2412.13741v3 Announce Type: replace 
Abstract: In general, comprehension of any type of complex system depends on the resolution used to examine the phenomena occurring within it. However, identifying a priori, for example, the best time frequencies/scales to study a certain system over-time, or the spatial distances at which correlations, symmetries, and fluctuations are, most often non-trivial. Here we describe an unsupervised approach that, starting solely from the data of a system, allows learning the characteristic length scales of the dominant key events/processes and the optimal spatiotemporal resolutions to characterize them. We tested this approach on time series data obtained from simulation or experimental trajectories of various example many-body complex systems ranging from the atomic to the macroscopic scale and having diverse internal dynamic complexities. Our method automatically analyzes the system data by analyzing correlations at all relevant inter-particle distances and at all possible inter-frame intervals in which their time series can be subdivided, namely, at all space and time resolutions.The optimal spatiotemporal resolution for studying a certain system thus maximizes information extraction and classification from the system's data, which we prove to be related to the characteristic spatiotemporal length scales of the local/collective physical events dominating it. This approach is broadly applicable and can be used to optimize the study of different types of data (static distributions, time series, or signals). The concept of 'optimal resolution' has a general character and provides a robust basis for characterizing any type of system based on its data, as well as to guide data analysis in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13741v3</guid>
      <category>physics.data-an</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Domiziano Doria, Simone Martino, Matteo Becchi, Giovanni M. Pavan</dc:creator>
    </item>
    <item>
      <title>An information-matching approach to optimal experimental design and active learning</title>
      <link>https://arxiv.org/abs/2411.02740</link>
      <description>arXiv:2411.02740v2 Announce Type: replace-cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02740v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonatan Kurniawan (Brigham Young University, Provo, UT, USA), Tracianne B. Neilsen (Brigham Young University, Provo, UT, USA), Benjamin L. Francis (Achilles Heel Technologies, Orem, UT, USA), Alex M. Stankovic (SLAC National Accelerator Laboratory, Menlo Park, CA, USA), Mingjian Wen (University of Houston, Houston, TX, USA), Ilia Nikiforov (University of Minnesota, Minneapolis, MN, USA), Ellad B. Tadmor (University of Minnesota, Minneapolis, MN, USA), Vasily V. Bulatov (Lawrence Livermore National Laboratory), Vincenzo Lordi (Lawrence Livermore National Laboratory), Mark K. Transtrum (Brigham Young University, Provo, UT, USA, SLAC National Accelerator Laboratory, Menlo Park, CA, USA)</dc:creator>
    </item>
    <item>
      <title>Stochastic Dynamics and Probability Analysis for a Generalized Epidemic Model with Environmental Noise</title>
      <link>https://arxiv.org/abs/2412.00405</link>
      <description>arXiv:2412.00405v2 Announce Type: replace-cross 
Abstract: In this paper we consider a stochastic SEIQR (susceptible-exposed-infected-quarantined-recovered) epidemic model with a generalized incidence function. Using the Lyapunov method, we establish the existence and uniqueness of a global positive solution to the model, ensuring that it remains well-defined over time. Through the application of Young's inequality and Chebyshev's inequality, we demonstrate the concepts of stochastic ultimate boundedness and stochastic permanence, providing insights into the long-term behavior of the epidemic dynamics under random perturbations. Furthermore, we derive conditions for stochastic extinction, which describe scenarios where the epidemic may eventually die out, and V-geometric ergodicity, which indicates the rate at which the system's state converges to its equilibrium. Finally, we perform numerical simulations to verify our theoretical results and assess the model's behavior under different parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00405v2</guid>
      <category>q-bio.PE</category>
      <category>math.DS</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brahim Boukanjime, Mohamed Maama</dc:creator>
    </item>
    <item>
      <title>Applications of machine learning in ion beam analysis of materials</title>
      <link>https://arxiv.org/abs/2412.12312</link>
      <description>arXiv:2412.12312v2 Announce Type: replace-cross 
Abstract: Ion Beam Analysis (IBA) is an established tool for material characterization, providing precise information on elemental composition, depth profiles, and structural information in the region near the surface of materials. However, traditional data processing methods can be slow and computationally intensive, limiting the efficiency and speed of the analysis. This article explores the current landscape of applying Machine Learning Algorithms (MLA) in the field of IBA, demonstrating the immense potential to optimize and accelerate processes. We present how ML has been employed to extract valuable insights from large datasets, automate repetitive tasks, and enhance the interpretability of results, with practical examples of applications in various IBA techniques, such as RBS, PIXE, and others. Finally, perspectives on using MLA to approach open problems in IBA are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12312v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tiago Fiorini da Silva</dc:creator>
    </item>
  </channel>
</rss>
