<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Jun 2025 02:20:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Convergent Methods for Koopman Operators on Reproducing Kernel Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2506.15782</link>
      <description>arXiv:2506.15782v1 Announce Type: new 
Abstract: Data-driven spectral analysis of Koopman operators is a powerful tool for understanding numerous real-world dynamical systems, from neuronal activity to variations in sea surface temperature. The Koopman operator acts on a function space and is most commonly studied on the space of square-integrable functions. However, defining it on a suitable reproducing kernel Hilbert space (RKHS) offers numerous practical advantages, including pointwise predictions with error bounds, improved spectral properties that facilitate computations, and more efficient algorithms, particularly in high dimensions. We introduce the first general, provably convergent, data-driven algorithms for computing spectral properties of Koopman and Perron--Frobenius operators on RKHSs. These methods efficiently compute spectra and pseudospectra with error control and spectral measures while exploiting the RKHS structure to avoid the large-data limits required in the $L^2$ settings. The function space is determined by a user-specified kernel, eliminating the need for quadrature-based sampling as in $L^2$ and enabling greater flexibility with finite, externally provided datasets. Using the Solvability Complexity Index hierarchy, we construct adversarial dynamical systems for these problems to show that no algorithm can succeed in fewer limits, thereby proving the optimality of our algorithms. Notably, this impossibility extends to randomized algorithms and datasets. We demonstrate the effectiveness of our algorithms on challenging, high-dimensional datasets arising from real-world measurements and high-fidelity numerical simulations, including turbulent channel flow, molecular dynamics of a binding protein, Antarctic sea ice concentration, and Northern Hemisphere sea surface height. The algorithms are publicly available in the software package $\texttt{SpecRKHS}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15782v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.SP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Boull\'e, Matthew J. Colbrook, Gustav Conradie</dc:creator>
    </item>
    <item>
      <title>Tree-based adaptive finite element methods for deformable image registration</title>
      <link>https://arxiv.org/abs/2506.15876</link>
      <description>arXiv:2506.15876v1 Announce Type: new 
Abstract: In this work we propose an adaptive Finite Element Method (FEM) formulation for the Deformable Image Registration problem (DIR) together with a residual-based a posteriori error estimator, whose efficiency and reliability are theoretically established. This estimator is used to guide Adaptive Mesh Refinement and coarsening (AMR). The nonlinear Euler-Lagrange equations associated with the minimisation of the relevant functional are solved with a pseudo time-stepping fixed-point scheme which is further accelerated using Anderson Acceleration (AA). The efficient implementation of these solvers relies on an efficient adaptive mesh data structure based on forests-of-octrees endowed with space-filling-curves. Several numerical results illustrate the performance of the proposed methods applied to adaptive DIR in application-oriented problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15876v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicol\'as A. Barnafi, Alberto F. Mart{\i}n, Ricardo Ruiz-Baier</dc:creator>
    </item>
    <item>
      <title>Reactive Transport Modeling with Physics-Informed Machine Learning for Critical Minerals Applications</title>
      <link>https://arxiv.org/abs/2506.15960</link>
      <description>arXiv:2506.15960v1 Announce Type: new 
Abstract: This study presents a physics-informed neural network (PINN) framework for reactive transport modeling for simulating fast bimolecular reactions in porous media. Accurate characterization of chemical interactions and product formation in surface and subsurface environments is essential for advancing critical mineral extraction and related geoscience applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15960v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Adhikari, Md. Lal Mamud, M. K. Mudunuru, K. B. Nakshatrala</dc:creator>
    </item>
    <item>
      <title>Preconditioning and Linearly Implicit Time Integration for the Serre-Green-Naghdi Equations</title>
      <link>https://arxiv.org/abs/2506.16045</link>
      <description>arXiv:2506.16045v1 Announce Type: new 
Abstract: The treatment of the differential PDE constraint poses a key challenge in computing the numerical solution of the Serre-Green-Naghdi (SGN) equations. In this work, we introduce a constant coefficient preconditioner for the SGN constraint operator and prove rigorous bounds on the preconditioned conditioning number. The conditioning bounds incorporate the effects of bathymetry in two dimensions, are quasi-optimal within a class of constant coefficient operators, highlight fundamental scalings for a loss of conditioning, and ensure mesh independent performance for iterative Krylov methods.
  Utilizing the conditioning bounds, we devise and test two time integration strategies for solving the full SGN equations. The first class combines classical explicit time integration schemes (4th order Runge-Kutta and 2nd--4th order Adams-Bashforth) with the new preconditioner. The second is a linearly implicit scheme where the differential constraint is split into a constant coefficient implicit part and remaining (stiff) explicit part. The linearly implicit methods require a single linear solve of a constant coefficient operator at each time step. We provide a host of computational experiments that validate the robustness of the preconditioners, as well as full solutions of the SGN equations including solitary waves traveling over an underwater shelf (in 1d) and a circular bump (in 2d).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16045v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linwan Feng, David Shirokoff, Wooyoung Choi</dc:creator>
    </item>
    <item>
      <title>General-domain FC-based shock-dynamics solver I: Basic elements</title>
      <link>https://arxiv.org/abs/2506.16076</link>
      <description>arXiv:2506.16076v1 Announce Type: new 
Abstract: This contribution, Part I in a two-part article series, presents a general-domain version of the FC-SDNN (Fourier Continuation Shock-detecting Neural Network) spectral scheme for the numerical solution of nonlinear conservation laws, which is applicable under arbitrary boundary conditions and in general domains. Like the previous simple-domain contribution (Journal of Computational Physics X 15, (2022)), the present approach relies on the use of the Fourier Continuation method for accurate spectral representation of non-periodic functions in conjunction with smooth artificial viscosity assignments localized in regions detected by means of a Shock-Detecting Neural Network (SDNN). Relying on such techniques, the present Part I paper introduces a novel multi-patch/subpatch artificial viscosity-capable domain decomposition strategy for complex domains with smooth boundaries, and it illustrates the methodology by means of a variety of computational results produced by an associated parallel implementation of the resulting shock-capturing algorithm in a present-day computing cluster. The subsequent Part II contribution then extends the algorithm to enable treatment of obstacles with non-smooth boundaries, it considers questions concerning parallelization and accuracy, and it presents comparisons with physical theory and prior experimental and computational results. The resulting multi-patch FC-SDNN algorithm does not require use of problem-dependent algorithmic parameters or positivity-preserving limiters, and, on account of its use of an overlapping-patch discretization, it is geometrically flexible and efficiently parallelized. A variety of numerical tests for the 2D Euler equations are presented, including the simulation of supersonic and hypersonic flows and shocks past physical obstacles at high speeds, such as Mach 25 re-entry flow speeds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16076v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oscar P. Bruno, Daniel V. Leibovici</dc:creator>
    </item>
    <item>
      <title>Two-dimensional greedy randomized extended Kaczmarz methods</title>
      <link>https://arxiv.org/abs/2506.16106</link>
      <description>arXiv:2506.16106v1 Announce Type: new 
Abstract: The randomized extended Kaczmarz method, proposed by Zouzias and Freris (SIAM J. Matrix Anal. Appl. 34: 773-793, 2013), is appealing for solving least-squares problems. However, its randomly selecting rows and columns of A with probability proportional to their squared norm is unattractive compared to the greedy strategy. In this paper, we first consider a novel two-dimensional greedy randomized extended Kaczmarz method for solving large linear least-squares problems. The proposed method randomly selects two rows and two columns of A by grasping two larger entries in the magnitude of the corresponding residual vector per iteration. To improve its convergence, we then propose a two-dimensional semi-randomized extended Kaczmarz method and its modified version with simple random sampling, which is particularly favorable for big data problems. The convergence analysis of which is also established. Numerical results on some practical applications illustrate the superiority of the proposed methods compared with state-of-the-art randomized extended Kaczmarz methods, especially in terms of computing time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16106v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin-Fang Zhang, Meng-Long Xiao, Tao Li</dc:creator>
    </item>
    <item>
      <title>Monolithic and Block Overlapping Schwarz Preconditioners for the Incompressible Navier--Stokes Equations</title>
      <link>https://arxiv.org/abs/2506.16179</link>
      <description>arXiv:2506.16179v1 Announce Type: new 
Abstract: Monolithic preconditioners applied to the linear systems arising during the solution of the discretized incompressible Navier--Stokes equations are typically more robust than preconditioners based on incomplete block factorizations. Lower number of iterations and a reduced sensitivity to parameters like velocity and viscosity can significantly outweigh the additional cost for their setup. Different monolithic preconditioning techniques are introduced and compared to a selection of block preconditioners. In particular, two-level additive overlapping Schwarz methods (OSM) are used to set up monolithic preconditioners and to approximate the inverses arising in the block preconditioners. GDSW-type (Generalized Dryja--Smith--Widlund) coarse spaces are used for the second level. These highly scalable, parallel preconditioners have been implemented in the solver framework \texttt{FROSch} (Fast and Robust Overlapping Schwarz), which is part of the software library \texttt{Trilinos}. The new GDSW-type coarse space GDSW\expStar{} is introduced; combining it with other techniques results in a robust algorithm. The block preconditioners PCD (Pressure Convection--Diffusion), SIMPLE (Semi-Implicit Method for Pressure Linked Equations), and LSC (Least-Squares Commutator) are considered to various degrees. The OSM for the monolithic as well as the block approach allows the optimized combination of different coarse spaces for the velocity and pressure component, enabling the use of tailored coarse spaces. The numerical and parallel performance of the different preconditioning methods for finite element discretizations of stationary as well as time-dependent incompressible fluid flow problems is investigated and compared. Their robustness is analyzed for a range of Reynolds and Courant-Friedrichs-Lewy (CFL) numbers with respect to a realistic problem setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16179v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Heinlein, Axel Klawonn, Jascha Knepper, Lea Sa{\ss}mannshausen</dc:creator>
    </item>
    <item>
      <title>From eigenvector nonlinearities to eigenvalue nonlinearities</title>
      <link>https://arxiv.org/abs/2506.16182</link>
      <description>arXiv:2506.16182v1 Announce Type: new 
Abstract: Over the past decades, transformations between different classes of eigenvalue problems have played a central role in the development of numerical methods for eigenvalue computations. One of the most well-known and successful examples of this is the companion linearization. In this paper, we construct a transformation that equivalently re-frames a specific type of eigenvalue problem with eigenvector nonlinearities (NEPv) into an eigenvalue problem with eigenvalue nonlinearities (NEP). The NEPv class considered consists of nonlinearities expressed as sums of products of matrices and scalar functions, where the scalar functions depend nonlinearly on the eigenvector. Our transformation defines the scalar nonlinearities through a polynomial system, resulting in NEP nonlinearities of algebraic type. We propose methods to solve the polynomial system, one involving a multiparameter eigenvalue problem (MEP). We adapt well-established NEP solvers to this setting, with the most effective strategy being a combination of deflation and a locally quadratically convergent iterative method. The efficiency and properties of the approach is illustrated by solving a problem related to a modification of a Gross-Pitaevskii equation (GPE). The simulations are reproducible and publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16182v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elias Jarlebring, Vilhelm P. Lithell</dc:creator>
    </item>
    <item>
      <title>A third-order finite volume semi-implicit method for the Shallow Water-Exner model</title>
      <link>https://arxiv.org/abs/2506.16287</link>
      <description>arXiv:2506.16287v1 Announce Type: new 
Abstract: In this work, third-order semi-implicit schemes on staggered meshes for the shallow water and Saint-Venant-Exner systems are presented. They are based on a third-order extension of the technique introduced in Cassulli \&amp; Cheng [1]. The stability conditions for these schemes depend on the velocity and not on the celerity, allowing us to reduce computational efforts, especially in subcritical flow simulations, which is the regime we are mainly interested in. The main novelty consists in the third-order approximation of the pressure gradient term in the momentum equation through appropriate polynomial reconstructions. Concretely, CWENO conservative reconstruction is considered for the water thickness $h$ and a centered fourth-degree polynomial is adopted interpolating the cell averages of the free surface $\eta$. For time discretization, a third-order IMEX scheme is applied. In addition, a novel time-dependent semi-analytical solution for Saint-Venant-Exner system is introduced and compared with the numerical ones. Several tests are performed, including accuracy tests showing third-order accuracy, well-balance tests, and simulations of slow bedload processes for large time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16287v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrique D. Fernandez-Nieto, Jose Garres-Diaz, Emanuele Macca, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Quasiseparable LU decay bounds for inverses of banded matrices</title>
      <link>https://arxiv.org/abs/2506.16339</link>
      <description>arXiv:2506.16339v1 Announce Type: new 
Abstract: We develop new, easily computable exponential decay bounds for inverses of banded matrices, based on the quasiseparable representation of Green matrices. The bounds rely on a diagonal dominance hypothesis and do not require explicit spectral information. Numerical experiments and comparisons show that these new bounds can be advantageous especially for nonsymmetric or symmetric indefinite matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16339v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paola Boito, Yuli Eidelman</dc:creator>
    </item>
    <item>
      <title>On a quantitative partial imaging problem in vector tomography</title>
      <link>https://arxiv.org/abs/2506.16455</link>
      <description>arXiv:2506.16455v1 Announce Type: new 
Abstract: In two dimensions, we consider the problem of reconstructing a vector field from partial knowledge of its zeroth and first moment ray transforms. Different from existing works the data is known on a subset of lines, namely the ones intersecting a given arc. The problem is non-local and, for partial data, severely ill-posed. We present a reconstruction method which recovers the vector field in the convex hull of the arc. An algorithm based on this method is implemented on some numerical experiments. While still ill-posed the discretization stabilizes the numerical reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16455v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroshi Fujiwara, Kamran Sadiq, Alexandru Tamasan</dc:creator>
    </item>
    <item>
      <title>Scientific Applications Leveraging Randomized Linear Algebra</title>
      <link>https://arxiv.org/abs/2506.16457</link>
      <description>arXiv:2506.16457v1 Announce Type: new 
Abstract: This report showcases the role of, and future directions for, the field of Randomized Numerical Linear Algebra (RNLA) in a selection of scientific applications. These applications span the domains of imaging, genomics and time-varying systems, and are thematically connected by needing to perform linear algebra routines on large-scale matrices (with up to quantillions of entries). At such scales, the linear algebra routines face typical bottlenecks: memory constraints, data access latencies, and substantial floating-point operation costs. RNLA routines are discussed at a high level to demonstrate how RNLA is able to solve the challenges faced by traditional linear algebra routines, and, consequently, address the computational problem posed in the underlying application. For each application, RNLA's open challenges and possible future directions are also presented, which broadly fall into the categories: creating structure-aware RNLA algorithms; co-designing RNLA algorithms with hardware and mixed-precision considerations; and advancing modular, composable software infrastructure. Ultimately, this report serves two purposes: it invites domain scientists to engage with RNLA; and it offers a guide for future RNLA research grounded in real applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16457v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vivak Patel, D. Adrian Maldonado, Maksim Melnichenko, Nathaniel Pritchard, Vishwas Rao, Elizaveta Rebrova, Sriram Sankararaman</dc:creator>
    </item>
    <item>
      <title>IMEX-RB: a self-adaptive IMEX time integration scheme exploiting the RB method</title>
      <link>https://arxiv.org/abs/2506.16470</link>
      <description>arXiv:2506.16470v1 Announce Type: new 
Abstract: In this work, we introduce a self-adaptive implicit-explicit (IMEX) time integration scheme, named IMEX-RB, for the numerical integration of systems of ordinary differential equations (ODEs), arising from spatial discretizations of partial differential equations (PDEs) by finite difference methods. Leveraging the Reduced Basis (RB) method, at each timestep we project the high-fidelity problem onto a suitable low-dimensional subspace and integrate its dynamics implicitly. Following the IMEX paradigm, the resulting solution then serves as an educated guess within a full-order explicit step. Notably, compared to the canonical RB method, IMEX-RB neither requires a parametrization of the underlying PDE nor features an offline-online splitting, since the reduced subspace is built dynamically, exploiting the high-fidelity solution history. We present the first-order formulation of IMEX-RB, demonstrating and showcasing its convergence and stability properties. In particular, under appropriate conditions on the method's hyperparameters, IMEX-RB is unconditionally stable. The theoretical analysis is corroborated by numerical experiments performed on representative model problems in two and three dimensions. The results demonstrate that our approach can outperform conventional time integration schemes like backward Euler. Indeed, IMEX-RB yields high-fidelity accurate solutions, provided that its main hyperparameters - namely the reduced basis size and the stability tolerance - are suitably tuned. Moreover, IMEX-RB realizes computational gains over backward Euler for a range of timestep sizes above the forward Euler stability threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16470v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micol Bassanini, Simone Deparis, Francesco Sala, Riccardo Tenderini</dc:creator>
    </item>
    <item>
      <title>Do high-order Gauss-Legendre methods admit a composition representation and a conjugate-symplectic counterpart?</title>
      <link>https://arxiv.org/abs/2506.16809</link>
      <description>arXiv:2506.16809v1 Announce Type: new 
Abstract: One of the most classical pairs of symplectic and conjugate-symplectic schemes is given by the Midpoint method (the Gauss--Runge--Kutta method of order 2) and the Trapezoidal rule. These can be interpreted as compositions of the Implicit and Explicit Euler methods, taken in direct and reverse order, respectively. This naturally raises the question of whether a similar composition structure exists for higher-order Gauss--Legendre methods. In this paper, we provide a positive answer in the case of the fourth-order method. The technique we employ also enables the derivation of a high-order dense output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16809v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Felice Iavernaro, Francesca Mazzia</dc:creator>
    </item>
    <item>
      <title>Comparison of substructured non-overlapping domain decomposition and overlapping additive Schwarz methods for large-scale Helmholtz problems with multiple sources</title>
      <link>https://arxiv.org/abs/2506.16875</link>
      <description>arXiv:2506.16875v1 Announce Type: new 
Abstract: Solving large-scale Helmholtz problems discretized with high-order finite elements is notoriously difficult, especially in 3D where direct factorization of the system matrix is very expensive and memory demanding, and robust convergence of iterative methods is difficult to obtain. Domain decomposition methods (DDM) constitute one of the most promising strategy so far, by combining direct and iterative approaches: using direct solvers on overlapping or non-overlapping subdomains, as a preconditioner for a Krylov subspace method on the original Helmholtz system or as an iterative solver on a substructured problem involving field values or Lagrange multipliers on the interfaces between the subdomains. In this work we compare the computational performance of non-overlapping substructured DDM and Optimized Restricted Additive Schwarz (ORAS) preconditioners for solving large-scale Helmholtz problems with multiple sources, as is encountered, e.g., in frequency-domain Full Waveform Inversion. We show on a realistic geophysical test-case that, when appropriately tuned, the non-overlapping methods can reduce the convergence gap sufficiently to significantly outperform the overlapping methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16875v1</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Boris Martin, Pierre Jolivet, Christophe Geuzaine</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification for Linear Inverse Problems with Besov Prior: A Randomize-Then-Optimize Method</title>
      <link>https://arxiv.org/abs/2506.16888</link>
      <description>arXiv:2506.16888v1 Announce Type: new 
Abstract: In this work, we investigate the use of Besov priors in the context of Bayesian inverse problems. The solution to Bayesian inverse problems is the posterior distribution which naturally enables us to interpret the uncertainties. Besov priors are discretization invariant and can promote sparsity in terms of wavelet coefficients. We propose the randomize-then-optimize method to draw samples from the posterior distribution with Besov priors under a general parameter setting and estimate the modes of the posterior distribution. The performance of the proposed method is studied through numerical experiments of a 1D inpainting problem, a 1D deconvolution problem, and a 2D computed tomography problem. Further, we discuss the influence of the choice of the Besov parameters and the wavelet basis in detail, and we compare the proposed method with the state-of-the-art methods. The numerical results suggest that the proposed method is an effective tool for sampling the posterior distribution equipped with general Besov priors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16888v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11222-025-10638-2</arxiv:DOI>
      <arxiv:journal_reference>Stat Comput 35, 101 (2025)</arxiv:journal_reference>
      <dc:creator>Andreas Horst, Babak Maboudi Afkham, Yiqiu Dong, Jakob Lemvig</dc:creator>
    </item>
    <item>
      <title>Magnus Methods for Stochastic Delay-Differential Equations</title>
      <link>https://arxiv.org/abs/2506.16908</link>
      <description>arXiv:2506.16908v1 Announce Type: new 
Abstract: This paper introduces Magnus-based methods for solving stochastic delay-differential equations (SDDEs). We construct Magnus--Euler--Maruyama (MEM) and Magnus--Milstein (MM) schemes by combining stochastic Magnus integrators with Taylor methods for SDDEs. These schemes are applied incrementally between multiples of the delay times. We present proofs of their convergence orders and demonstrate these rates through numerical examples and error graphs. Among the examples, we apply the MEM and MM schemes to both linear and nonlinear problems. We also apply the MEM scheme to a stochastic partial delay-differential equation (SPDDE), comparing its performance with the traditional Euler--Maruyama (EM) method. Under fine spatial discretization, the MEM scheme remains numerically stable while the EM method becomes unstable, yielding a significant computational advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16908v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mitchell T. Griggs, Kevin Burrage, Pamela M. Burrage</dc:creator>
    </item>
    <item>
      <title>Error analysis of BDF schemes for the evolutionary incompressible Navier--Stokes equations</title>
      <link>https://arxiv.org/abs/2506.16917</link>
      <description>arXiv:2506.16917v1 Announce Type: new 
Abstract: Error bounds for fully discrete schemes for the evolutionary incompressible Navier--Stokes equations are derived in this paper. For the time integration we apply BDF-$q$ methods, $q\le 5$, for which error bounds for $q\ge 3$ cannot be found in the literature. Inf-sup stable mixed finite elements are used as spatial approximation. First, we analyze the standard Galerkin method and second a grad-div stabilized method. The grad-div stabilization allows to prove error bounds with constants independent of inverse powers of the viscosity coefficient. We prove optimal bounds for the velocity and pressure with order $(\Delta t)^q$ in time for the BDF-$q$ scheme and order $h^{k+1}$ for the $L^2(\Omega)$ error of the velocity in the first case and $h^k$ in the second case, $k$ being the degree of the polynomials in finite element velocity space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16917v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bosco Garc\'ia-Archilla, V. John, Julia Novo</dc:creator>
    </item>
    <item>
      <title>Structure-preserving scheme for 1D KWC system</title>
      <link>https://arxiv.org/abs/2506.16963</link>
      <description>arXiv:2506.16963v1 Announce Type: new 
Abstract: In this paper, we consider a system of one-dimensional parabolic PDEs, known as the KWC system, as a phase-field model for grain boundary motion. A key feature of this system is that the equation for the crystalline orientation angle is described as a quasilinear diffusion equation with variable mobility. The goal of this paper is to establish a structure-preserving numerical scheme for the system, focusing on two main structural properties: $\sharp\,1)$ range preservation; and $\sharp\,2)$ energy dissipation. Under suitable assumptions, we construct a structure-preserving numerical scheme and address the following in the main theorems: (O) verification of the structural properties; (I) clarification of the convergence conditions; and (II) error estimate for the scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16963v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Makoto Okumura, Shodai Kubota, Ken Shirakawa</dc:creator>
    </item>
    <item>
      <title>Any nonincreasing convergence curves are simultaneously possible for GMRES and weighted GMRES, as well as for left and right preconditioned GMRES</title>
      <link>https://arxiv.org/abs/2506.17193</link>
      <description>arXiv:2506.17193v1 Announce Type: new 
Abstract: The convergence of the GMRES linear solver is notoriously hard to predict. A particularly enlightening result by [Greenbaum, Pt\'ak, Strako\v{s}, 1996] is that, given any convergence curve, one can build a linear system for which GMRES realizes that convergence curve. What is even more extraordinary is that the eigenvalues of the problem matrix can be chosen arbitrarily. We build upon this idea to derive novel results about weighted GMRES. We prove that for any linear system and any prescribed convergence curve, there exists a weight matrix M for which weighted GMRES (i.e., GMRES in the inner product induced by M) realizes that convergence curve, and we characterize the form of M. Additionally, we exhibit a necessary and sufficient condition on M for the simultaneous prescription of two convergence curves, one realized by GMRES in the Euclidean inner product, and the other in the inner product induced by M. These results are then applied to infer some properties of preconditioned GMRES when the preconditioner is applied either on the left or on the right. For instance, we show that any two convergence curves are simultaneously possible for left and right preconditioned GMRES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17193v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Matalon, Nicole Spillane</dc:creator>
    </item>
    <item>
      <title>Mesoscale FEM Model of Concrete: Statistical Assessment of Inherent Stress Concentrations in Dependence on Phase Heterogeneity</title>
      <link>https://arxiv.org/abs/2506.16242</link>
      <description>arXiv:2506.16242v1 Announce Type: cross 
Abstract: Concrete heterogeneity originates from its production process, which involves bonding aggregates with a binder matrix. This study presents a mesoscale finite element model (MFEM) that offers detailed insights into the fracture process at the aggregate-cement matrix interface, focusing on one of concrete's key properties: its mechanical response. Unlike discrete models, which often average out critical stress concentrations within the mesostructure, the MFEM approach captures detailed stress distributions, revealing localized effects crucial for understanding damage evolution. Although computationally more demanding, the MFEM leverages modern high-performance computing (HPC) to provide a detailed description of the stress field and material damage across different phases and interfaces. Various matrix-to-aggregate stiffness ratios are considered to evaluate the influence of material heterogeneity on the stress field. The results are based on a statistical evaluation of stress concentrations arising from variations in material stiffness. The model is applied to investigate the impact of using recycled crushed bricks as aggregates in concrete, with particular emphasis on the stiffness mismatch between the matrix and aggregates. The study examines how this stiffness contrast affects stress distribution and ultimately influences the composite's failure mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16242v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Ma\v{s}ek (Institute of Physics of Materials, Czech Academy of Sciences, Brno, Czech Republic, Institute of Structural Mechanics, Faculty of Civil Engineering, Brno University of Technology, Brno, Czech Republic), Petr Miarka (Institute of Physics of Materials, Czech Academy of Sciences, Brno, Czech Republic, Institute of Structural Mechanics, Faculty of Civil Engineering, Brno University of Technology, Brno, Czech Republic)</dc:creator>
    </item>
    <item>
      <title>Transformations of Computational Meshes</title>
      <link>https://arxiv.org/abs/2506.16341</link>
      <description>arXiv:2506.16341v1 Announce Type: cross 
Abstract: Computational meshes, as a way to partition space, form the basis of much of PDE simulation technology, for instance for the finite element and finite volume discretization methods. In complex simulations, we are often driven to modify an input mesh, for example, to refine, coarsen, extrude, change cell types, or filter it. Mesh manipulation code can be voluminous, error-prone, spread over many special cases, and hard to understand and maintain by subsequent developers. We present a simple, table-driven paradigm for mesh transformation which can execute a large variety of transformations in a performant, parallel manner, along with experiments in the open source library PETSc which can be run by the reader.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16341v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew G. Knepley</dc:creator>
    </item>
    <item>
      <title>Fast Converging Single Trace Quasi-local PMCHWT Equation for the Modelling of Composite Systems</title>
      <link>https://arxiv.org/abs/2506.16376</link>
      <description>arXiv:2506.16376v1 Announce Type: cross 
Abstract: The PMCHWT integral equation enables the modelling of scattering of time-harmonic fields by penetrable, piecewise homogeneous, systems. They have been generalised to include the modelling of composite systems that may contain junctions, i.e. lines along which three or more materials meet. Linear systems resulting upon discretisation of the PMCHWT are, because of their large dimension, typically solved by Krylov iterative methods. The number of iterations required for this solution critically depends on the eigenvalue distribution of the system matrix. For systems that do not contain junction lines, Calder\'on preconditioning, which was first applied to the electric field integral equation, has been generalised to the PMCHWT equation. When junctions are present, this approach cannot be applied. Alternative approaches, such as the global multi-trace method, conceptually remove the junction lines and as a result are amenable to Calder\'on preconditioning. This approach entails a doubling of the degrees of freedom, and the solution that is produced only approximately fulfils the continuity conditions at interfaces separating domains. In this contribution, a single trace quasi-local PMCHWT equation is introduced that requires a number of iterations for its solution that only slowly increases as the mesh size tends to zero. The method is constructed as a generalisation of the classic PMCHWT, and its discretisation is thoroughly discussed. A comprehensive suite of numerical experiments demonstrates the correctness, convergence behaviour, and efficiency of the method. The integral equation is demonstrated to be free from interior resonances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16376v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristof Cools</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo with one categorical variable</title>
      <link>https://arxiv.org/abs/2506.16582</link>
      <description>arXiv:2506.16582v1 Announce Type: cross 
Abstract: We study randomized quasi-Monte Carlo (RQMC) estimation of a multivariate integral where one of the variables takes only a finite number of values. This problem arises when the variable of integration is drawn from a mixture distribution as is common in importance sampling and also arises in some recent work on transport maps. We find that when integration error decreases at an RQMC rate that it is then beneficial to oversample the smallest mixture components instead of using a proportional allocation. We also find that for the most accurate RQMC sampling methods, it is advantageous to arrange that our $n=2^m$ randomized Sobol' points split into subsample sizes that are also powers of~$2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16582v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valerie N. P. Ho, Art B. Owen, Zexin Pan</dc:creator>
    </item>
    <item>
      <title>A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques</title>
      <link>https://arxiv.org/abs/2506.16663</link>
      <description>arXiv:2506.16663v2 Announce Type: cross 
Abstract: High-dimensional image data often require dimensionality reduction before further analysis. This paper provides a purely analytical comparison of two linear techniques-Principal Component Analysis (PCA) and Singular Value Decomposition (SVD). After the derivation of each algorithm from first principles, we assess their interpretability, numerical stability, and suitability for differing matrix shapes. building on classical and recent numerical literature, We synthesize rule-of-thumb guidelines for choosing one out of the two algorithms without empirical benchmarking, building on classical and recent numerical literature. Limitations and directions for future experimental work are outlined at the end.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16663v2</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Gyimadu, Gregory Bell, Ph. D</dc:creator>
    </item>
    <item>
      <title>Hemodynamic Simulation in the Aortic Arch Under Anemic Diabetic and Healthy Blood Flow Conditions Using Computational Fluid Dynamics</title>
      <link>https://arxiv.org/abs/2506.16763</link>
      <description>arXiv:2506.16763v1 Announce Type: cross 
Abstract: This study investigates the hemodynamic behavior of blood flow in the aortic arch across anemic, diabetic, and healthy conditions using computational fluid dynamics (CFD) simulations with a non-Newtonian Carreau viscosity model. Velocity fields, pressure distributions, and wall shear stress (WSS) patterns were analyzed to assess the impact of blood rheology and vessel geometry. Anemic blood, with low viscosity and hematocrit, produced smooth, low-resistance flow with reduced WSS and pressure gradients, potentially impairing perfusion. Diabetic blood exhibited elevated viscosity, leading to increased flow resistance, higher WSS, and localized separation at arterial branches -- conditions associated with vascular stress and remodeling. Healthy cases showed balanced hemodynamic behavior with localized flow acceleration but maintained physiological ranges. These findings highlight the mechanistic links between rheological properties and cardiovascular stress, supporting the role of CFD in non-invasive vascular risk assessment and motivating future integration of patient-specific data and structural modeling for enhanced clinical relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16763v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farzana Akter Tina, Hashnayne Ahmed, Hena Rani Biswas</dc:creator>
    </item>
    <item>
      <title>Complexity of sparse polynomial solving 3: Infinity</title>
      <link>https://arxiv.org/abs/2506.17086</link>
      <description>arXiv:2506.17086v1 Announce Type: cross 
Abstract: A theory of numerical path-following in toric varieties was suggested in two previous papers. The motivation is solving systems of polynomials with real or complex coefficients. When those polynomials are not assumed 'dense', solving them over projective space or complex space may introduce spurious, degenerate roots or components. Spurious roots may be avoided by solving over toric varieties.
  In this paper, a homotopy algorithm is locally defined on charts of the toric variety. Its complexity is bounded linearly by the condition length, that is the integral along the lifted path (coefficients and solution) of thetoric condition number. Those charts allow for stable computations near "toric infinity",which was not possible within the technology of the previous papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17086v1</guid>
      <category>math.AG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregorio Malajovich</dc:creator>
    </item>
    <item>
      <title>A block Recycled GMRES method with investigations into aspects of solver performance</title>
      <link>https://arxiv.org/abs/1604.01713</link>
      <description>arXiv:1604.01713v2 Announce Type: replace 
Abstract: We propose a block Krylov subspace version of the GCRO-DR method proposed in [Parks et al.; SISC 2005], which is an iterative method allowing for the efficient minimization of the the residual over an augmented Krylov subspace. We offer a clean derivation of our proposed method and discuss methods of selecting recycling subspaces at restart as well as implementation decisions in the context of high-performance computing. Numerical experiments are split into those demonstrating convergence properties and those demonstrating the data movement and cache efficiencies of the dominant operations of the method, measured using processor monitoring code from Intel.</description>
      <guid isPermaLink="false">oai:arXiv.org:1604.01713v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael L. Parks, Kirk M. Soodhalter, Daniel B. Szyld</dc:creator>
    </item>
    <item>
      <title>Reduced-order modeling for Ablowitz-Ladik equation</title>
      <link>https://arxiv.org/abs/2207.11130</link>
      <description>arXiv:2207.11130v2 Announce Type: replace 
Abstract: In this paper, reduced-order models (ROMs) are constructed for the Ablowitz-Ladik equation (ALE), an integrable semi-discretization of the nonlinear Schr\"odinger equation (NLSE) with and without damping. Both ALEs are non-canonical conservative and dissipative Hamiltonian systems with the Poisson matrix depending quadratically on the state variables, and with quadratic Hamiltonian. The full-order solutions are obtained with the energy preserving midpoint rule for the conservative ALE and exponential midpoint rule for the dissipative ALE. The reduced-order solutions are constructed intrusively by preserving the skew-symmetric structure of the reduced non-canonical Hamiltonian system by applying proper orthogonal decomposition (POD) with the Galerkin projection. For an efficient offline-online decomposition of the ROMs, the quadratic nonlinear terms of the Poisson matrix are approximated by the discrete empirical interpolation method (DEIM). The computation of the reduced-order solutions is further accelerated by the use of tensor techniques. Preservation of the Hamiltonian and momentum for the conservative ALE, and preservation of dissipation properties of the dissipative ALE, guarantee the long-term stability of soliton solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.11130v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.matcom.2023.06.013</arxiv:DOI>
      <arxiv:journal_reference>Mathematics and Computers in Simulation, 213 (2023), 261-273</arxiv:journal_reference>
      <dc:creator>Murat Uzunca, B\"ulent Karas\"ozen</dc:creator>
    </item>
    <item>
      <title>Reconstruction Formulae for 3D Field-Free Line Magnetic Particle Imaging</title>
      <link>https://arxiv.org/abs/2309.06254</link>
      <description>arXiv:2309.06254v3 Announce Type: replace 
Abstract: Magnetic Particle Imaging (MPI) is a promising noninvasive in vivo imaging modality that makes it possible to map the spatial distribution of superparamagnetic nanoparticles by exposing them to dynamic magnetic fields. In the Field-Free Line (FFL) scanner topology, the spatial encoding of the particle distribution is performed by applying magnetic fields vanishing on straight lines. The voltage induced in the receiving coils by the particles when exposed to the magnetic fields constitute the signal from which the particle distribution is to be reconstructed. To avoid lengthy calibration, model-based reconstruction formulae have been developed for the 2D FFL scanning topology. In this work we develop reconstruction formulae for 3D FFL. Moreover, we provide a model-based reconstruction algorithm for 3D FFL and we validate it with a numerical experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06254v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vladyslav Gapyak, Thomas M\"arz, Andreas Weinmann</dc:creator>
    </item>
    <item>
      <title>The Bivariate Normal Integral via Owen's T Function as a Modified Euler's Arctangent Series</title>
      <link>https://arxiv.org/abs/2312.00011</link>
      <description>arXiv:2312.00011v2 Announce Type: replace 
Abstract: The Owen's T function is presented in four new ways, one of them as a series similar to the Euler's arctangent series divided by $2\pi$, which is its majorant series. All possibilities enable numerically stable and fast convergent computation of the bivariate normal integral with simple recursion. When tested $\Phi_\varrho^2(x,y)$ computation on a random sample of one million parameter triplets with uniformly distributed components and using double precision arithmetic, the maximum absolute error was $3.45\cdot 10^{-16}$. In additional testing, focusing on cases with correlation coefficients close to one in absolute value, when the computation may be very sensitive to small rounding errors, the accuracy was retained. In rare potentially critical cases, a simple adjustment to the computation procedure was performed - one potentially critical computation was replaced with two equivalent non-critical ones. All new series are suitable for vector and high-precision computation, assuming they are supplemented with appropriate efficient and accurate computation of the arctangent and standard normal cumulative distribution functions. They are implemented by the R package Phi2rho, available on CRAN. Its functions allow vector arguments and are ready to work with the Rmpfr package, which enables the use of arbitrary precision instead of double precision numbers. A special test with up to 1024-bit precision computation is also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00011v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4236/ajcm.2023.134026</arxiv:DOI>
      <arxiv:journal_reference>American Journal of Computational Mathematics, 2023, Vol. 13, No. 4, 476-504</arxiv:journal_reference>
      <dc:creator>Janez Komelj</dc:creator>
    </item>
    <item>
      <title>Randomized methods for dynamical low-rank approximation</title>
      <link>https://arxiv.org/abs/2410.17091</link>
      <description>arXiv:2410.17091v2 Announce Type: replace 
Abstract: We introduce novel dynamical low-rank methods for solving large-scale matrix differential equations, motivated by algorithms from randomized numerical linear algebra. In terms of performance (cost and accuracy), our methods overperform existing dynamical low-rank techniques. Several applications to stiff differential equations demonstrate the robustness, accuracy and low variance of the new methods, despite their inherent randomness. Allowing augmentation of the range and corange, the new methods have a good potential for preserving critical physical quantities such as the energy, mass and momentum. Numerical experiments on the Vlasov-Poisson equation are particularly encouraging.
  The new methods comprise two essential steps: a range estimation step followed by a post-processing step. The range estimation is achieved through a novel dynamical rangefinder method. Subsequently, we propose two methods for post-processing, leading to two time-stepping methods: dynamical randomized singular value decomposition (DRSVD) and dynamical generalized Nystr\"om (DGN). The new methods naturally extend to the rank-adaptive framework by estimating the error via Gaussian sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17091v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benjamin Carrel</dc:creator>
    </item>
    <item>
      <title>The learned range test method for the inverse inclusion problem</title>
      <link>https://arxiv.org/abs/2411.00463</link>
      <description>arXiv:2411.00463v2 Announce Type: replace 
Abstract: We consider the inverse problem consisting of the reconstruction of an inclusion $B$ contained in a bounded domain $\Omega\subset\mathbb{R}^d$ from a single pair of Cauchy data $(u|_{\partial\Omega},\partial_\nu u|_{\partial\Omega})$, where $\Delta u=0$ in $\Omega\setminus\overline B$ and $u=0$ on $\partial B$. We show that the reconstruction algorithm based on the range test, a domain sampling method, can be written as a neural network with a specific architecture. We propose to learn the weights of this network in the framework of supervised learning, and to combine it with a pre-trained classifier, with the purpose of distinguishing the inclusions based on their distance from the boundary. The numerical simulations show that this learned range test method provides accurate and stable reconstructions of polygonal inclusions. Furthermore, the results are superior to those obtained with the standard range test method (without learning) and with an end-to-end fully connected deep neural network, a purely data-driven method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00463v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiwei Sun, Giovanni S. Alberti</dc:creator>
    </item>
    <item>
      <title>A review of low-rank methods for time-dependent kinetic simulations</title>
      <link>https://arxiv.org/abs/2412.05912</link>
      <description>arXiv:2412.05912v2 Announce Type: replace 
Abstract: Time-dependent kinetic models are ubiquitous in computational science and engineering. The underlying integro-differential equations in these models are high-dimensional, comprised of a six--dimensional phase space, making simulations of such phenomena extremely expensive. In this article we demonstrate that in many situations, the solution to kinetics problems lives on a low dimensional manifold that can be described by a low-rank matrix or tensor approximation. We then review the recent development of so-called low-rank methods that evolve the solution on this manifold. The two classes of methods we review are the dynamical low-rank (DLR) method, which derives differential equations for the low-rank factors, and a Step-and-Truncate (SAT) approach, which projects the solution onto the low-rank representation after each time step. Thorough discussions of time integrators, tensor decompositions, and method properties such as structure preservation and computational efficiency are included. We further show examples of low-rank methods as applied to particle transport and plasma dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05912v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.plasm-ph</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Einkemmer, Katharina Kormann, Jonas Kusch, Ryan G. McClarren, Jing-Mei Qiu</dc:creator>
    </item>
    <item>
      <title>Adaptive randomized pivoting for column subset selection, DEIM, and low-rank approximation</title>
      <link>https://arxiv.org/abs/2412.13992</link>
      <description>arXiv:2412.13992v2 Announce Type: replace 
Abstract: We derive a new adaptive leverage score sampling strategy for solving the Column Subset Selection Problem (CSSP). The resulting algorithm, called Adaptive Randomized Pivoting, can be viewed as a randomization of Osinsky's recently proposed deterministic algorithm for CSSP. It guarantees, in expectation, an approximation error that matches the optimal existence result in the Frobenius norm. Although the same guarantee can be achieved with volume sampling, our sampling strategy is much simpler and less expensive. To show the versatility of Adaptive Randomized Pivoting, we apply it to select indices in the Discrete Empirical Interpolation Method, in cross/skeleton approximation of general matrices, and in the Nystroem approximation of symmetric positive semi-definite matrices. In all these cases, the resulting randomized algorithms are new and they enjoy bounds on the expected error that match -- or improve -- the best known deterministic results. A derandomization of the algorithm for the Nystroem approximation results in a new deterministic algorithm with a rather favorable error bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13992v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alice Cortinovis, Daniel Kressner</dc:creator>
    </item>
    <item>
      <title>Computing Barycentres of Measures for Generic Transport Costs</title>
      <link>https://arxiv.org/abs/2501.04016</link>
      <description>arXiv:2501.04016v2 Announce Type: replace 
Abstract: Wasserstein barycentres represent average distributions between multiple probability measures for the Wasserstein distance. The numerical computation of Wasserstein barycentres is notoriously challenging. A common approach is to use Sinkhorn iterations, where an entropic regularisation term is introduced to make the problem more manageable. Another approach involves using fixed-point methods, akin to those employed for computing Fr\'echet means on manifolds. The convergence of such methods for 2-Wasserstein barycentres, specifically with a quadratic cost function and absolutely continuous measures, was studied by Alvarez-Esteban et al. (2016). In this paper, we delve into the main ideas behind this fixed-point method and explore how it can be generalised to accommodate more diverse transport costs and generic probability measures, thereby extending its applicability to a broader range of problems. We show convergence results for this approach and illustrate its numerical behaviour on several barycentre problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04016v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eloi Tanguy, Julie Delon, Natha\"el Gozlan</dc:creator>
    </item>
    <item>
      <title>Hybrid high-order methods for elasto-acoustic wave propagation in the time domain</title>
      <link>https://arxiv.org/abs/2502.10870</link>
      <description>arXiv:2502.10870v2 Announce Type: replace 
Abstract: We devise a Hybrid High-Order (HHO) method for the coupling between the acoustic and elastic wave equations in the time domain. A first-order formulation in time is considered. The HHO method can use equal-order and mixed-order settings with polynomial degree k&gt;=0 for the face unknowns, together with O(1)- and O(1/h)-stabilizations. An energy-error estimate is established in the time-continuous case. A numerical spectral analysis is performed, showing that O(1)-stabilization is required to avoid excessive CFL limitations for explicit time discretizations. Moreover, the spectral radius of the stiffness matrix is fairly independent of the geometry of the mesh cells. For analytical solutions on general meshes, optimal convergence rates of order (k+1) are shown in both equal- and mixed-order settings using O(1)-stabilization, whereas order (k+2) is achieved in the mixed-order setting using O(1/h)-stabilization. Test cases with a Ricker wavelet as an initial condition showcase the relevance of the proposed method for the simulation of elasto-acoustic wave propagation across media with contrasted material properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10870v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Romain Mottier, Alexandre Ern, Rekha Khot, Laurent Guillot</dc:creator>
    </item>
    <item>
      <title>Efficient and robust solvers for a cell-by-cell dual-poroelasticity problem</title>
      <link>https://arxiv.org/abs/2505.19157</link>
      <description>arXiv:2505.19157v2 Announce Type: replace 
Abstract: This paper presents a scalable and robust solver for a cell-by-cell dual-poroelasticity model, describing the mechanical interactions between brains cells embedded in extracellular space. Explicitly representing the complex cellular shapes, the proposed approach models both intracellular and extracellular spaces as distinct poroelastic media, separated by a permeable cell membrane which allows hydrostatic and osmotic pressure-driven fluid exchange. Based on a three-field (displacement, total pressure, and fluid pressure) formulation, the solver leverages the framework of norm equivalent preconditioning and appropriately fitted norms to ensure robustness across all material parameters of the model. Scalability for large and complex geometries is achieved through efficient Algebraic Multigrid (AMG) approximations of the preconditioners' individual blocks. Furthermore, we accommodate diverse boundary conditions, including full Dirichlet boundary conditions for displacement, which we handle efficiently using the Sherman-Morrison-Woodbury formula. Our theoretical analysis is complemented by numerical experiments demonstrating the preconditioners' robustness and performance across various parameters relevant to realistic scenarios, and a large scale example of cellular swelling on a dense reconstruction of the mouse visual cortex highlights the method's potential for investigating complex physiological processes like cellular volume regulation in detailed biological structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19157v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marius Causemann, Miroslav Kuchta</dc:creator>
    </item>
    <item>
      <title>Maximum volume coordinates for Grassmann interpolation: Lagrange, Hermite, and errors</title>
      <link>https://arxiv.org/abs/2506.01574</link>
      <description>arXiv:2506.01574v2 Announce Type: replace 
Abstract: We present a novel approach to Riemannian interpolation on the Grassmann manifold. Instead of relying on the Riemannian normal coordinates, i.e. the Riemannian exponential and logarithm maps, we approach the interpolation problem with an alternative set of local coordinates and corresponding parameterizations. A special property of these coordinates is that their calculation does not require any matrix decompositions. This is a numerical advantage over Riemann normal coordinates and many other retractions on the Grassmann manifold, especially when derivative data are to be treated. To estimate the interpolation error, we examine the conditioning of these mappings and state explicit bounds. It turns out that the parameterizations are well-conditioned, but the coordinate mappings are generally not. As a remedy, we introduce maximum-volume coordinates that are based on a search for subblocks of column-orthogonal matrices of large absolute determinant. We show that the order of magnitude of the asymptotic interpolation error on $\Gr(n,p)$ is the same as in the Euclidean space. Two numerical experiments are conducted. The first is an academic one, where we interpolate a parametric orthogonal projector $QQ^T$, where the $Q$--factor stems from a parametric compact QR--decomposition. The second experiment is in the context of parametric model reduction of dynamical systems, where we interpolate reduced subspaces that are obtained by proper orthogonal decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01574v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rasmus Jensen, Ralf Zimmermann</dc:creator>
    </item>
    <item>
      <title>Rust Implementation of Finite Element Exterior Calculus on Coordinate-Free Simplicial Complexes</title>
      <link>https://arxiv.org/abs/2506.02429</link>
      <description>arXiv:2506.02429v2 Announce Type: replace 
Abstract: This thesis presents the development of a novel finite element library in Rust based on the principles of Finite Element Exterior Calculus (FEEC). The library solves partial differential equations formulated using differential forms on abstract, coordinate-free simplicial complexes in arbitrary dimensions, employing an intrinsic Riemannian metric derived from edge lengths via Regge Calculus. We focus on solving elliptic Hodge-Laplace eigenvalue and source problems on the nD de Rham complex. We restrict ourselves to first-order Whitney basis functions. The implementation is partially verified through convergence studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02429v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.AT</category>
      <category>math.DG</category>
      <category>math.FA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Wirth</dc:creator>
    </item>
    <item>
      <title>A second-order accurate, positive-preserving and mass conservative linear scheme for the Possion-Nernst-Planck equations</title>
      <link>https://arxiv.org/abs/2506.13054</link>
      <description>arXiv:2506.13054v2 Announce Type: replace 
Abstract: The first-order linear positivity preserving schemes in time are available for the time dependent Poisson-Nernst-Planck (PNP) equations, second-order linear ones are still challenging. This paper proposes the first- and second-order exponential time differencing schemes with the finite difference spatial discretization for PNP equations, based on the $Slotboom$ transformation of the Nernst-Planck equations and linear stabilization technique. The proposed schemes are linear and preserve the mass conservation and positivity preservation of ion concentration at full discrete level without any constraints on the time step size. The corresponding energy stability analysis is also presented, demonstrating that the second-order scheme can dissipate the modified energy. Extensive numerical results are carried out to support the theoretical findings and showcase the performance of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13054v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayin Li, Jingwei Li</dc:creator>
    </item>
    <item>
      <title>Conditional a priori error estimates of finite volume and Runge-Kutta discontinuous Galerkin methods with abstract limiting for hyperbolic systems of conservation laws in 1D</title>
      <link>https://arxiv.org/abs/2506.13221</link>
      <description>arXiv:2506.13221v2 Announce Type: replace 
Abstract: We derive conditional a priori error estimates of a wide class of finite volume and Runge-Kutta discontinuous Galerkin methods with abstract limiting for hyperbolic systems of conservation laws in 1D via the verification of weak consistency and entropy stability, as recently proposed by Bressan et al.~\cite{BressanChiriShen21}. Convergence in $L^\infty L^1$ with rate $h^{1/3}$ is obtained under a time step restriction $\tau\leq ch$, provided the following conditions hold: the exact solution is piecewise Lipschitz continuous, its (finitely many and isolated) shock curves can be traced with precision $h^{2/3}$ and, outside of these shock tracing tubular neighborhoods the numerical solution -- assumed to be uniformly small in BV -- has oscillation strength $h$ across each mesh cell and cell boundary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13221v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Leotta</dc:creator>
    </item>
    <item>
      <title>Energy-consistent dynamic fracture phase field models: unilateral constraints and finite element simulations</title>
      <link>https://arxiv.org/abs/2506.14788</link>
      <description>arXiv:2506.14788v2 Announce Type: replace 
Abstract: Phase field models have emerged as a powerful and flexible framework for simulating complex interface-driven phenomena across a wide range of scientific and engineering applications. In fracture mechanics, the phase field approach--formulated as a gradient flow of the Griffith fracture energy with Ambrosio-Tortorelli regularization--has gained significant attention for its ability to capture complex crack topologies. In this study, we propose a dynamic fracture phase field model (DF-PFM) based on the elastodynamic wave equation. We further extend this framework by incorporating a unilateral contact condition, yielding a refined model suitable for simulating fault rupture under high pressure. For both models, we formally derive energy dissipation identities under mixed boundary conditions, providing insights into the energetic structure of the formulations. To validate the proposed approach, we conduct numerical experiments using linear implicit time discretization and finite element methods. Our simulations demonstrate that the unilateral contact condition is essential for accurately capturing shear-dominated crack propagation and preventing non-physical interpenetration, especially under high-compression loading scenarios relevant to seismic faulting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14788v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Mamun Miah, Ryuhei Wakida, Masato Kimura</dc:creator>
    </item>
    <item>
      <title>Optimal alignment of Lorentz orientation and generalization to matrix Lie groups</title>
      <link>https://arxiv.org/abs/2506.14994</link>
      <description>arXiv:2506.14994v2 Announce Type: replace 
Abstract: There exist elegant methods of aligning point clouds in $\mathbb R^3$. Unfortunately, these methods rely on the positive definite property of the Euclidean metric, and do not easily extend to the indefinite Minkowski metric. In this paper, we propose two solutions to the following problem: given inertial reference frames $A$ and $B$, and given (possibly noisy) measurements of a set of 4-vectors $\{v_i\}$ made in those reference frames with components $\{v_{A,i}\}$ and $\{v_{B,i}\}$, find the optimal Lorentz transformation $\Lambda$ such that $\Lambda v_{A,i}=v_{B,i}$. The method we outline is conceptually simple and easily extends to alignment problems in other matrix Lie groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14994v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Congzhou M Sha</dc:creator>
    </item>
    <item>
      <title>Discrete nonlinear elastodynamics in a port-Hamiltonian framework</title>
      <link>https://arxiv.org/abs/2306.17740</link>
      <description>arXiv:2306.17740v2 Announce Type: replace-cross 
Abstract: We provide a fully nonlinear port-Hamiltonian formulation for discrete elastodynamical systems as well as a structure-preserving time discretization. The governing equations are obtained in a variational manner and represent index-1 differential algebraic equations. Performing an index reduction one obtains the port-Hamiltonian state space model, which features the nonlinear strains as an independent state next to position and velocity. Moreover, hyperelastic material behavior is captured in terms of a nonlinear stored energy function. The model exhibits passivity and losslessness and has an underlying symmetry yielding the conservation of angular momentum. We perform temporal discretization using the midpoint discrete gradient, such that the beneficial properties are inherited by the developed time stepping scheme in a discrete sense. The numerical results obtained in a representative example are demonstrated to validate the findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17740v2</guid>
      <category>math.DS</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/pamm.202300144</arxiv:DOI>
      <arxiv:journal_reference>Proceedings in Applied Mathematics and Mechanics (2023), 23, e202300144</arxiv:journal_reference>
      <dc:creator>Philipp L. Kinon, Tobias Thoma, Peter Betsch, Paul Kotyczka</dc:creator>
    </item>
    <item>
      <title>Feynman-Kac Formula for Time-Dependent Nonlinear Schr\"odinger Equations with Applications in Numerical Approximations</title>
      <link>https://arxiv.org/abs/2409.16519</link>
      <description>arXiv:2409.16519v4 Announce Type: replace-cross 
Abstract: In this paper, we present a novel Feynman-Kac formula and investigate learning-based methods for approximating general nonlinear time-dependent Schr\"odinger equations which may be high-dimensional. Our formulation integrates both the Fisk-Stratonovich and It\^o integrals within the framework of backward stochastic differential equations (BSDEs). Utilizing this Feynman-Kac representation, we propose learning-based approaches for numerical approximations. To demonstrate the accuracy and effectiveness of the proposed method, we conduct numerical experiments in both low- and high-dimensional settings, complemented by a convergence analysis. These results address the open problem concerning deep-BSDE methods for numerical approximations of high-dimensional time-dependent nonlinear Schr\"odinger equations (cf. [Proc. Natl. Acad. Sci. 15 (2018), pp. 8505-8510] and [Frontiers Sci. Awards Math. (2024), pp. 1-14] by Han, Jentzen, and E).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16519v4</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Cheung, Jinniao Qiu, Yang Yang</dc:creator>
    </item>
    <item>
      <title>Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension</title>
      <link>https://arxiv.org/abs/2502.05075</link>
      <description>arXiv:2502.05075v5 Announce Type: replace-cross 
Abstract: Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a strong (large) student model is trained on pseudo-labels generated by a weak teacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to understand this phenomenon through the observation that FT often occurs in intrinsically low-dimensional spaces. Leveraging the low intrinsic dimensionality of FT, we analyze W2S in the ridgeless regression setting from a variance reduction perspective. For a strong student-weak teacher pair with sufficiently expressive low-dimensional feature subspaces $\mathcal{V}_s, \mathcal{V}_w$, we provide an exact characterization of the variance that dominates the generalization error of W2S. This unveils a virtue of discrepancy between the strong and weak models in W2S: the variance of the weak teacher is inherited by the strong student in $\mathcal{V}_s \cap \mathcal{V}_w$, while reduced by a factor of $\mathrm{dim}(\mathcal{V}_s)/N$ in the subspace of discrepancy $\mathcal{V}_w \setminus \mathcal{V}_s$ with $N$ pseudo-labels for W2S. Our analysis further casts light on the sample complexities and the scaling of performance gap recovery in W2S. The analysis is supported by experiments on synthetic regression problems, as well as real vision and NLP tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05075v5</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijun Dong, Yicheng Li, Yunai Li, Jason D. Lee, Qi Lei</dc:creator>
    </item>
    <item>
      <title>Patch-based learning of adaptive Total Variation parameter maps for blind image denoising</title>
      <link>https://arxiv.org/abs/2503.16010</link>
      <description>arXiv:2503.16010v2 Announce Type: replace-cross 
Abstract: We consider a patch-based learning approach defined in terms of neural networks to estimate spatially adaptive regularisation parameter maps for image denoising with weighted Total Variation (TV) and test it to situations when the noise distribution is unknown. As an example, we consider situations where noise could be either Gaussian or Poisson and perform preliminary model selection by a standard binary classification network. Then, we define a patch-based approach where at each image pixel an optimal weighting between TV regularisation and the corresponding data fidelity is learned in a supervised way using reference natural image patches upon optimisation of SSIM and in a sliding window fashion. Extensive numerical results are reported for both noise models, showing significant improvement w.r.t. results obtained by means of optimal scalar regularisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16010v2</guid>
      <category>eess.IV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudio Fantasia, Luca Calatroni, Xavier Descombes, Rim Rekik</dc:creator>
    </item>
  </channel>
</rss>
