<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Dec 2025 02:14:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Self-motion as a structural prior for coherent and robust formation of cognitive maps</title>
      <link>https://arxiv.org/abs/2512.20044</link>
      <description>arXiv:2512.20044v1 Announce Type: new 
Abstract: Most computational accounts of cognitive maps assume that stability is achieved primarily through sensory anchoring, with self-motion contributing to incremental positional updates only. However, biological spatial representations often remain coherent even when sensory cues degrade or conflict, suggesting that self-motion may play a deeper organizational role. Here, we show that self-motion can act as a structural prior that actively organizes the geometry of learned cognitive maps. We embed a path-integration-based motion prior in a predictive-coding framework, implemented using a capacity-efficient, brain-inspired recurrent mechanism combining spiking dynamics, analog modulation and adaptive thresholds. Across highly aliased, dynamically changing and naturalistic environments, this structural prior consistently stabilizes map formation, improving local topological fidelity, global positional accuracy and next-step prediction under sensory ambiguity. Mechanistic analyses reveal that the motion prior itself encodes geometrically precise trajectories under tight constraints of internal states and generalizes zero-shot to unseen environments, outperforming simpler motion-based constraints. Finally, deployment on a quadrupedal robot demonstrates that motion-derived structural priors enhance online landmark-based navigation under real-world sensory variability. Together, these results reframe self-motion as an organizing scaffold for coherent spatial representations, showing how brain-inspired principles can systematically strengthen spatial intelligence in embodied artificial agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20044v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingchao Yu, Pengfei Sun, Yaochu Jin, Kuangrong Hao, Hao Zhang, Yifeng Zhang, Wenxuan Pan, Wei Chen, Danyal Akarca, Yuchen Xiao</dc:creator>
    </item>
    <item>
      <title>Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation</title>
      <link>https://arxiv.org/abs/2512.20319</link>
      <description>arXiv:2512.20319v1 Announce Type: new 
Abstract: A major shortcoming of medical practice is the lack of an objective measure of conscious level. Impairment of consciousness is common, e.g. following brain injury and seizures, which can also interfere with sensory processing and volitional responses. This is also an important pitfall in neurophysiological methods that infer awareness via command following, e.g. using functional MRI or electroencephalography (EEG).
  Transcranial electrical stimulation (TES) can be employed to non-invasively stimulate the brain, bypassing sensory inputs, and has already showed promising results in providing reliable indicators of brain state. However, current non-invasive solutions have been limited to magnetic stimulation, which is not easily translatable to clinical settings. Our long-term vision is to develop an objective measure of brain state that can be used at the bedside, without requiring patients to understand commands or initiate motor responses.
  In this study, we demonstrated the feasibility of a framework using Deep Learning algorithms to classify EEG brain responses evoked by a defined multi-dimensional pattern of TES. We collected EEG-TES data from 11 participants and found that delivering transcranial direct current stimulation (tDCS) to posterior cortical areas targeting the angular gyrus elicited an exceptionally reliable brain response. For this paradigm, our best Convolutional Neural Network model reached a 92% classification F1-score on Holdout data from participants never seen during training, significantly surpassing human-level performance at 60-70% accuracy.
  These findings establish a framework for robust consciousness measurement for clinical use. In this spirit, we documented and open-sourced our datasets and codebase in full, to be used freely by the neuroscience and AI research communities, who may replicate our results with free tools like GitHub, Kaggle, and Colab.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20319v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexis Pomares Pastor, Ines Ribeiro Violante, Gregory Scott</dc:creator>
    </item>
    <item>
      <title>Coherence in the brain unfolds across separable temporal regimes</title>
      <link>https://arxiv.org/abs/2512.20481</link>
      <description>arXiv:2512.20481v2 Announce Type: new 
Abstract: Coherence in language requires the brain to satisfy two competing temporal demands: gradual accumulation of meaning across extended context and rapid reconfiguration of representations at event boundaries. Despite their centrality to language and thought, how these processes are implemented in the human brain during naturalistic listening remains unclear. Here, we tested whether these two processes can be captured by annotation-free drift and shift signals and whether their neural expression dissociates across large-scale cortical systems. These signals were derived from a large language model (LLM) and formalized contextual drift and event shifts directly from the narrative input. To enable high-precision voxelwise encoding models with stable parameter estimates, we densely sampled one healthy adult across more than 7 hours of listening to thirteen crime stories while collecting ultra high-field (7T) BOLD data. We then modeled the feature-informed hemodynamic response using a regularized encoding framework validated on independent stories. Drift predictions were prevalent in default-mode network hubs, whereas shift predictions were evident bilaterally in the primary auditory cortex and language association cortex. Furthermore, activity in default-mode and parietal networks was best explained by a signal capturing how meaning accumulates and gradually fades over the course of the narrative. Together, these findings show that coherence during language comprehension is implemented through dissociable neural regimes of slow contextual integration and rapid event-driven reconfiguration, offering a mechanistic entry point for understanding disturbances of language coherence in psychiatric disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20481v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Davide Stauba, Finn Rabe, Akhil Misra, Yves Pauli, Roya H\"uppi, Ni Yang, Nils Lang, Lars Michels, Victoria Edkins, Sascha Fr\"uhholz, Iris Sommer, Wolfram Hinzen, Philipp Homan</dc:creator>
    </item>
    <item>
      <title>Representation learning in cerebellum-like structures</title>
      <link>https://arxiv.org/abs/2511.10261</link>
      <description>arXiv:2511.10261v2 Announce Type: replace 
Abstract: Animals use past experiences to adapt future behavior. To enable this rapid learning, vertebrates and invertebrates have evolved analogous neural structures like the vertebrate cerebellum or insect mushroom body. A defining feature of these circuits is a large expansion layer, which re-codes sensory inputs to improve pattern separation, a prerequisite to learn non-overlapping associations between relevant sensorimotor inputs and adaptive changes in behavior. However, classical models of associative learning treat expansion layers as static, assuming that associations are learned through plasticity at the output synapses. Here, we review emerging evidence that also highlights the importance of plasticity within the expansion layer for associative learning. Because the underlying plasticity mechanisms and principles of this representation learning are only emerging, we systematically compare experimental data from two well-studied circuits for expansion coding -- the cerebellum granule layer and the mushroom body calyx. The data indicate remarkably similar interneuron circuits, dendritic morphology and plasticity mechanisms between both systems that hint at more general principles for representation learning. Moreover, the data show strong overlap with recent theoretical advances that consider interneuron circuits and dendritic computations for representation learning. However, they also hint at an interesting interaction of stimulus-induced, non-associative and reinforced, associative mechanisms of plasticity that is not well understood in current theories of representation learning. Therefore, studying expansion layer plasticity will be important to elucidate the mechanisms and full potential of representation learning for behavioral adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10261v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Rudelt, Fabian Mikulasch, Viola Priesemann, Andr\'e Ferreira Castro</dc:creator>
    </item>
    <item>
      <title>The hands of time: Moving my body to keep time order in the brain</title>
      <link>https://arxiv.org/abs/2512.16616</link>
      <description>arXiv:2512.16616v2 Announce Type: replace 
Abstract: The brain is very often viewed as a network, be it at small scale made of cells, mostly neurons, or at larger scale made of neuronal assemblies. Here we introduce a conjecture, in the spirit of a philosophical though experiment, which proposes that the present cannot be obtained from within such networks, and that this limitation imposes burdens on network efficiency in information processing. We aim to argue this conjecture imposes recurrent contacts from within the brain to outside in the physical world via behavior, which create a flow of time stamps. This though experiment may contribute to make the divide between the foci toward inside versus outside, for example opposing ecological psychology and many frameworks adopted in neurosciences, superfluous. This piece proposes an ambulation triggered by a thought experiment: What if I was a neuron listening to another one and talking to a third? It is a modest attempt to walk in the footsteps of classical thought experiments, like Molyneux problem, the imitation game and the anti-sequel Chinese room, key gedankenexperiments in an elevator in physics, or the cogito in philosophy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16616v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 24 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Julien Lagarde</dc:creator>
    </item>
  </channel>
</rss>
