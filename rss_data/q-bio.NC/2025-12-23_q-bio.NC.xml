<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Dec 2025 05:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Re-assessing the evidence for mental rotation abilities in children using computational models</title>
      <link>https://arxiv.org/abs/2512.17972</link>
      <description>arXiv:2512.17972v1 Announce Type: new 
Abstract: There is strong and diverse evidence for mental rotation (MR) abilities in adults. However, current evidence for MR in children rests on just a few behavioral paradigms adapted from the adult literature. Here, we leverage recent computational models of the development of children's object recognition abilities to re-assess the evidence for MR in children. The computational models simulate infants' acquisition of object representations during embodied interactions with objects. We consider two different object recognition strategies, different from MRs, and assess their ability to replicate results from three classical MR tasks assigned to children between the ages of 6 months and 5 years. Our results show that MR may play no role in producing the results obtained from children younger than 5 years. In fact, we find that a simple recognition strategy that reflects a pixel-wise comparison of stimuli is sufficient to model children's behavior in the most used MR task. Thus, our study reopens the debate on how and when children develop genuine MR abilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17972v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur Aubret, Jochen Triesch</dc:creator>
    </item>
    <item>
      <title>MEGState: Phoneme Decoding from Magnetoencephalography Signals</title>
      <link>https://arxiv.org/abs/2512.17978</link>
      <description>arXiv:2512.17978v1 Announce Type: new 
Abstract: Decoding linguistically meaningful representations from non-invasive neural recordings remains a central challenge in neural speech decoding. Among available neuroimaging modalities, magnetoencephalography (MEG) provides a safe and repeatable means of mapping speech-related cortical dynamics, yet its low signal-to-noise ratio and high temporal dimensionality continue to hinder robust decoding. In this work, we introduce MEGState, a novel architecture for phoneme decoding from MEG signals that captures fine-grained cortical responses evoked by auditory stimuli. Extensive experiments on the LibriBrain dataset demonstrate that MEGState consistently surpasses baseline model across multiple evaluation metrics. These findings highlight the potential of MEG-based phoneme decoding as a scalable pathway toward non-invasive brain-computer interfaces for speech.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17978v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuntaro Suzuki, Chia-Chun Dan Hsu, Yu Tsao, Komei Sugiura</dc:creator>
    </item>
    <item>
      <title>The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</title>
      <link>https://arxiv.org/abs/2512.17989</link>
      <description>arXiv:2512.17989v1 Announce Type: new 
Abstract: We examine the conceptual and ethical gaps in current representations of Superintelligence misalignment. We find throughout Superintelligence discourse an absent human subject, and an under-developed theorization of an "AI unconscious" that together are potentiality laying the groundwork for anti-social harm. With the rise of AI Safety that has both thematic potential for establishing pro-social and anti-social potential outcomes, we ask: what place does the human subject occupy in these imaginaries? How is human subjecthood positioned within narratives of catastrophic failure or rapid "takeoff" toward superintelligence? On another register, we ask: what unconscious or repressed dimensions are being inscribed into large-scale AI models? Are we to blame these agents in opting for deceptive strategies when undesirable patterns are inherent within our beings? In tracing these psychic and epistemic absences, our project calls for re-centering the human subject as the unstable ground upon which the ethical, unconscious, and misaligned dimensions of both human and machinic intelligence are co-constituted. Emergent misalignment cannot be understood solely through technical diagnostics typical of contemporary machine-learning safety research. Instead, it represents a multi-layered crisis. The human subject disappears not only through computational abstraction but through sociotechnical imaginaries that prioritize scalability, acceleration, and efficiency over vulnerability, finitude, and relationality. Likewise, the AI unconscious emerges not as a metaphor but as a structural reality of modern deep learning systems: vast latent spaces, opaque pattern formation, recursive symbolic play, and evaluation-sensitive behavior that surpasses explicit programming. These dynamics necessitate a reframing of misalignment as a relational instability embedded within human-machine ecologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17989v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhammad Osama Imran, Roshni Lulla, Rodney Sappington</dc:creator>
    </item>
    <item>
      <title>Responses to transient perturbation can distinguish intrinsic from latent criticality in spiking neural populations</title>
      <link>https://arxiv.org/abs/2512.18113</link>
      <description>arXiv:2512.18113v1 Announce Type: new 
Abstract: The critical brain hypothesis posits that neural circuitry operates near criticality to reap the computational benefits of accessing a wide range of timescales. The theory of critical phenomena generally predicts heavy-tailed (power-law) correlations in space and time near criticality, but it has been argued that in the brain such correlations could be inherited from ``latent variables,'' such as external sensory signals that are not directly observed when recording from neural circuitry. Distinguishing whether heavy-tailed correlations in neural activity are intrinsically generated within a neural circuit or are driven by unobserved latent variables is crucial for properly interpreting circuit functions. We argue that measuring neural responses to sudden perturbative inputs, rather than correlations in ongoing activity, can disambiguate these cases. We demonstrate this approach in a model of stochastic spiking neuron populations receiving external latent input that can be tuned to a critical state. We propose a scaling theory for the covariance and response functions of the spiking network, which we validate with simulations. We end by discussing how our approach might generalize to models of neural populations with more realistic biophysical details.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18113v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob T. Crosser, Braden A. W. Brinkman</dc:creator>
    </item>
    <item>
      <title>Coord2Region: A Python Package for Mapping 3D Brain Coordinates to Atlas Labels, Literature, and AI Summaries</title>
      <link>https://arxiv.org/abs/2512.18165</link>
      <description>arXiv:2512.18165v1 Announce Type: new 
Abstract: We present Coord2Region, an open-source Python package that streamlines coordinate-based neuroimaging workflows by automatically mapping 3D brain coordinates (e.g., MNI or Talairach) to anatomical regions across multiple atlases. The package links mapped coordinates to meta-analytic resources via the Neuroimaging Meta-Analysis Research Environment (NiMARE) , providing direct integration with Neurosynth and NeuroQuery. This directly connects coordinates and regions to the broader neuroimaging literature. In addition to atlas-based labeling and literature retrieval, Coord2Region offers an optional large language model (LLM) functionality that generates text summaries of linked studies and illustrative images of queried regions. These AI-assisted features are intended to support interpretation and exploration, while remaining clearly complementary to peer-reviewed literature and established neuroimaging tools. Coord2Region provides a unified pipeline with a robust command-line interface, flexible dataset management, and provider-agnostic LLM utilities, and it supports both single-coordinate and high-throughput batch queries with nearest-region fallback for volume and surface atlases. Furthermore, Coord2Region includes a web interface for interactive configuration (via JSON Schema forms) and cloud execution (via Hugging Face), enabling users to build YAML configurations and run analyses in-browser without local installation. Together, these capabilities lower friction, reduce manual errors, and improve reproducibility in coordinate-centric neuroimaging workflows, promoting more robust and transparent research practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18165v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamza Abdelhedi, Yorguin-Jose Mantilla-Ramos, Sina Esmaeili, Annalisa Pascarella, Vanessa Hadid, Karim Jerbi</dc:creator>
    </item>
    <item>
      <title>Deep Teleportation: Quantum Simulation of Conscious Report in Attentional Blink</title>
      <link>https://arxiv.org/abs/2512.18585</link>
      <description>arXiv:2512.18585v1 Announce Type: new 
Abstract: Recent quantum models of cognition have successfully simulated several interesting effects in human experimental data, from vision to reasoning and recently even consciousness. The latter case, consciousness has been a quite challenging phenomenon to model, and most efforts have been through abstract mathematical quantum methods, mainly focused on conceptual issues. Classical (non-quantum) models of consciousness-related experiments exist, but they generally fail to align well with human data. We developed a straightforward quantum model to simulate conscious reporting of seeing or missing competing stimuli within the famous attentional blink paradigm. In an attentional blink task, a target stimulus (T2) that appears after a previous one (T1) can be consciously reported if the delay between presenting them is short enough (called lag 1), otherwise it can be rendered invisible during the so-called refractory period of attention (lags 2 to 6 and even longer). For modeling this phenomenon, we employed a three-qubit entanglement ansatz circuit in the form of a deep teleportation channel instead of the well-known EPR channel. While reporting the competing stimuli was supposed to be the classical measurement outcomes, the effect of distractor stimuli (i.e., masks, if any) was encoded simply as random angle rotations. The simulation outcome for different states was measured, and the classical outcome probabilities were further used as inputs to a simple linear neural network. The result revealed a non-linear, alternating state pattern that closely mirrors human responses in conscious stimuli reporting. The main result was a successful simulation of Lag 1 sparing, lag 7 divergence, and masking effect through probabilistic outcome of measurement in different conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18585v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Sohrabi</dc:creator>
    </item>
    <item>
      <title>A Rate-Distortion Perspective on the Emergence of Number Sense in Unsupervised Generative Models</title>
      <link>https://arxiv.org/abs/2512.19450</link>
      <description>arXiv:2512.19450v1 Announce Type: new 
Abstract: Number sense is a core cognitive ability supporting various adaptive behaviors and is foundational for mathematical learning. Here, we study its emergence in unsupervised generative models through the lens of rate-distortion theory (RDT), a normative framework for understanding information processing under limited resources. We train $\beta$-Variational Autoencoders -- which embody key formal principles of RDT -- on synthetic images containing varying numbers of items, as commonly used in numerosity perception research. We systematically vary the encoding capacity and assess the models' sensitivity to numerosity and the robustness of the emergent numerical representations through a comprehensive set of analyses, including numerosity estimation and discrimination tasks, latent-space analysis, generative capabilities and generalization to novel stimuli. In line with RDT, we find that behavioral performance in numerosity perception and the ability to extract numerosity unconfounded by non-numerical visual features scale with encoding capacity according to a power law. At high capacity, the unsupervised model develops a robust neural code for numerical information, with performance closely approximating a supervised model explicitly trained for visual enumeration. It exhibits strong generative abilities and generalizes well to novel images, whereas at low capacity, the model shows marked deficits in numerosity perception and representation. Finally, comparison with human data shows that models trained at intermediate capacity levels span the full range of human behavioral performance while still developing a robust emergent numerical code. In sum, our results show that unsupervised generative models can develop a number sense and demonstrate that rate-distortion theory provides a powerful information-theoretic framework for understanding how capacity constraints shape numerosity perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19450v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo D'Amato, Davide Nuzzi, Alberto Testolin, Ivilin Peev Stoianov, Marco Zorzi, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>The Geometry of Abstraction: Continual Learning via Recursive Quotienting</title>
      <link>https://arxiv.org/abs/2512.18471</link>
      <description>arXiv:2512.18471v1 Announce Type: cross 
Abstract: Continual learning systems operating in fixed-dimensional spaces face a fundamental geometric barrier: the flat manifold problem. When experience is represented as a linear trajectory in Euclidean space, the geodesic distance between temporal events grows linearly with time, forcing the required covering number to diverge. In fixed-dimensional hardware, this volume expansion inevitably forces trajectory overlap, manifesting as catastrophic interference. In this work, we propose a geometric resolution to this paradox based on Recursive Metric Contraction. We formalize abstraction not as symbolic grouping, but as a topological deformation: a quotient map that collapses the metric tensor within validated temporal neighborhoods, effectively driving the diameter of local sub-manifolds to zero. We substantiate our framework with four rigorous results. First, the Bounded Capacity Theorem establishes that recursive quotient maps allow the embedding of arbitrarily long trajectories into bounded representational volumes, trading linear metric growth for logarithmic topological depth. Second, the Topological Collapse Separability Theorem, derived via Urysohn's Lemma, proves that recursive quotienting renders non-linearly separable temporal sequences linearly separable in the limit, bypassing the need for infinite-dimensional kernel projections. Third, the Parity-Partitioned Stability Theorem solves the catastrophic forgetting problem by proving that if the state space is partitioned into orthogonal flow and scaffold manifolds, the metric deformations of active learning do not disturb the stability of stored memories. Our analysis reveals that tokens in neural architectures are physically realizable as singularities or wormholes, regions of extreme positive curvature that bridge distant points in the temporal manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18471v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xin Li</dc:creator>
    </item>
    <item>
      <title>Comparing Dynamical Models Through Diffeomorphic Vector Field Alignment</title>
      <link>https://arxiv.org/abs/2512.18566</link>
      <description>arXiv:2512.18566v1 Announce Type: cross 
Abstract: Dynamical systems models such as recurrent neural networks (RNNs) are increasingly popular in theoretical neuroscience for hypothesis-generation and data analysis. Evaluating the dynamics in such models is key to understanding their learned generative mechanisms. However, such evaluation is impeded by two major challenges: First, comparison of learned dynamics across models is difficult because there is no enforced equivalence of their coordinate systems. Second, identification of mechanistically important low-dimensional motifs (e.g., limit sets) is intractable in high-dimensional nonlinear models such as RNNs. Here, we propose a comprehensive framework to address these two issues, termed Diffeomorphic vector field alignment FOR learned Models (DFORM). DFORM learns a nonlinear coordinate transformation between the state spaces of two dynamical systems, which aligns their trajectories in a maximally one-to-one manner. In so doing, DFORM enables an assessment of whether two models exhibit topological equivalence, i.e., similar mechanisms despite differences in coordinate systems. A byproduct of this method is a means to locate dynamical motifs on low-dimensional manifolds embedded within higher-dimensional systems. We verified DFORM's ability to identify linear and nonlinear coordinate transformations using canonical topologically equivalent systems, RNNs, and systems related by nonlinear flows. DFORM was also shown to provide a quantification of similarity between topologically distinct systems. We then demonstrated that DFORM can locate important dynamical motifs including invariant manifolds and saddle limit sets within high-dimensional models. Finally, using a set of RNN models trained on human functional MRI (fMRI) recordings, we illustrated that DFORM can identify limit cycles from high-dimensional data-driven models, which agreed well with prior numerical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18566v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiqi Chen (Division of Biology and Biomedical Sciences, Washington University in St. Louis), Giacomo Vedovati (Department of Electrical and Systems Engineering, Washington University in St. Louis), Todd Braver (Department of Psychological and Brain Sciences, Washington University in St. Louis), ShiNung Ching (Department of Electrical and Systems Engineering, Washington University in St. Louis)</dc:creator>
    </item>
    <item>
      <title>Hair-thin confocal fluorescence endo-microscopy for deep-brain in-vivo imaging</title>
      <link>https://arxiv.org/abs/2512.19419</link>
      <description>arXiv:2512.19419v1 Announce Type: cross 
Abstract: Confocal and multi-photon microscopy are widely used for in-vivo fluorescence imaging of biological tissues such as the brain, offering non-invasive access up to ~1 mm depth without major loss in performance. A recently-developed alternative is holographic endoscopy, which exploits controlled light transport through hair-thin optical fibres. With minimal invasiveness, it provides observations at comparable spatial resolution, while extending its applicability to unprecedented depths. It has been used to resolve details of sub-cellular structural connectivity, record neuronal signalling, and monitor blood flow from the deepest locations of the living brain. Yet, its use, particularly in densely labelled brain regions, has so far been constrained by significant contrast loss, primarily due to the absence of a practical mechanism for rejecting out-of-focus fluorescence light -- a capability inherently provided by confocal and multi-photon microscopy. Exploring opportunities in the structure of light modes of different MMF types we identify the possibility of achieving an analogue to confocal fluorescence microscopy through MMF-based endoscopes. Using a novel composite fibre probe that combines graded-index and step-index MMFs, we enable spatially resolved signal collection and selective rejection of out-of-focus light. This confocal filtering significantly enhances image contrast and resolution by suppressing background and off-plane signals. We demonstrate improved imaging performance on fine structural connectivity and intracellular calcium signalling in living mouse brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19419v1</guid>
      <category>physics.optics</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom\'a\v{s} Pik\'alek, Miroslav Stib\r{u}rek, Tereza Tu\v{c}kov\'a, Petra Kolb\'abkov\'a, Sergey Turtaev, Jana Krej\v{c}\'i, Petra Ondr\'a\v{c}kov\'a, Hana Uhl\'i\v{r}ov\'a, Tom\'a\v{s} \v{C}i\v{z}m\'ar</dc:creator>
    </item>
    <item>
      <title>Fairness, not Emotion, Drives Socioeconomic Decision Making</title>
      <link>https://arxiv.org/abs/2409.10322</link>
      <description>arXiv:2409.10322v3 Announce Type: replace 
Abstract: Emotion and fairness play a key role in mediating socioeconomic decisions in humans; however, the underlying neurocognitive mechanism remains largely unknown. This exploratory study unraveled the interplay between agents' emotions and the fairness of their monetary proposal in rational decision-making, backed by ERP analyses at a group as well as a strategic level. In a time-bound ultimatum-game paradigm, 40 participants were exposed to three distinct proposers' emotions (Happy, Neutral, Disgusted) followed by one of the three offer ranges (Low, Intermediate, High). Our findings show a robust influence of economic fairness on acceptance rates. A multilevel generalized linear model showed offer as the dominant predictor of trial-specific responses. Subsequent clustering grouped participants into five clusters, which the Drift Diffusion Model corroborates. Pertinent neural markers demonstrated the recognition of facial expressions; however, they had minimal effect during socioeconomic decision-making. Our study explores individualistic decision-making processes revealing different cognitive strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10322v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rudra Mukhopadhyay, Sourin Chatterjee, Koel Das</dc:creator>
    </item>
    <item>
      <title>SimSort: A Data-Driven Framework for Spike Sorting by Large-Scale Electrophysiology Simulation</title>
      <link>https://arxiv.org/abs/2502.03198</link>
      <description>arXiv:2502.03198v3 Announce Type: replace 
Abstract: Spike sorting is an essential process in neural recording, which identifies and separates electrical signals from individual neurons recorded by electrodes in the brain, enabling researchers to study how specific neurons communicate and process information. Although there exist a number of spike sorting methods which have contributed to significant neuroscientific breakthroughs, many are heuristically designed, making it challenging to verify their correctness due to the difficulty of obtaining ground truth labels from real-world neural recordings. In this work, we explore a data-driven, deep learning-based approach. We begin by creating a large-scale dataset through electrophysiology simulations using biologically realistic computational models. We then present SimSort, a pretraining framework for spike sorting. Trained solely on simulated data, SimSort demonstrates zero-shot generalizability to real-world spike sorting tasks, yielding consistent improvements over existing methods across multiple benchmarks. These results highlight the potential of simulation-driven pretraining to enhance the robustness and scalability of spike sorting in experimental neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03198v3</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>39th Conference on Neural Information Processing Systems (NeurIPS 2025)</arxiv:journal_reference>
      <dc:creator>Yimu Zhang, Dongqi Han, Yansen Wang, Zhenning Lv, Yu Gu, Dongsheng Li</dc:creator>
    </item>
    <item>
      <title>Modeling Language Evolution Using a Spin Glass Approach</title>
      <link>https://arxiv.org/abs/2507.14375</link>
      <description>arXiv:2507.14375v2 Announce Type: replace 
Abstract: The evolution of natural languages poses a riddle to any theoretical perspective based on efficiency considerations. If languages are already optimally effective means of organization and communication of thought, why do they change? And if they are driven to become optimally effective in the future, why do they change so slowly, and why do they diversify, rather than converge towards an optimum? We look here at the hypothesis that disorder, rather than efficiency, may play a dominant role.
  Most traditional approaches to study diachronic language dynamics emphasize lexical data, but it would seem that a crucial contribution to the effectiveness of a thought-coding device is given by its core generative structure, i.e., its syntax. Based on the reduction of syntax to a set of binary syntactic parameters, we introduce here a model of natural language change in which diachronic dynamics stem from disordered interactions between/among parameters, even in the idealized limit of identical external inputs. We show in which region of phase space such dynamics show the glassy features that are observed in natural language across time. In particular, binary syntactic vectors remain trapped in glassy metastable (ie, tendentially stable) states when the degree of asymmetry in the disordered interactions is below a critical value, consistent with studies of spin glasses with asymmetric interactions. We further show that an added Hopfield-type memory term, would indeed, if strong enough, stabilize syntactic configurations, but losing their multiplicity. Finally, using a notion of linguistic distance in syntactic state space we show that a phylogenetic signal may remain among related languages, despite their gradually divergent syntax, exactly as recently pointed out for real-world languages. These statistical results appear to generalize beyond the 94 parameters across 58 languages used here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14375v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hediye Yarahmadi, Kwang Il Ryom, Giuseppe Longobardi, Alessandro Treves</dc:creator>
    </item>
    <item>
      <title>Integrated Information Theory: A Consciousness-First Approach to What Exists</title>
      <link>https://arxiv.org/abs/2510.25998</link>
      <description>arXiv:2510.25998v4 Announce Type: replace 
Abstract: This overview of integrated information theory (IIT) emphasizes IIT's "consciousness-first" approach to what exists. Consciousness demonstrates to each of us that something exists--experience--and reveals its essential properties--the axioms of phenomenal existence. IIT formulates these properties operationally, yielding the postulates of physical existence. To exist intrinsically or absolutely, an entity must have cause-effect power upon itself, in a specific, unitary, definite and structured manner. IIT's explanatory identity claims that an entity's cause-effect structure accounts for all properties of an experience--essential and accidental--with no additional ingredients. These include the feeling of spatial extendedness, temporal flow, of objects binding general concepts with particular configurations of features, and of qualia such as colors and sounds. IIT's intrinsic ontology has implications for understanding meaning, perception, and free will, for assessing consciousness in patients, infants, other species, and artifacts, and for reassessing our place in nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25998v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulio Tononi, Melanie Boly</dc:creator>
    </item>
    <item>
      <title>Discrete Heat Kernels on Simplicial Complexes and Its Application to Functional Brain Networks</title>
      <link>https://arxiv.org/abs/2509.16908</link>
      <description>arXiv:2509.16908v2 Announce Type: replace-cross 
Abstract: Networks constitute fundamental organizational structures across biological systems, although conventional graph-theoretic analyses capture exclusively pairwise interactions, thereby omitting the intricate higher-order relationships that characterize network complexity. This work proposes a unified framework for heat kernel smoothing on simplicial complexes, extending classical signal processing methodologies from vertices and edges to cycles and higher-dimensional structures. Through Hodge Laplacian, a discrete heat kernel on a finite simplicial complex $\mathcal{K}$ is constructed to smooth signals on $k$-simplices via the boundary operator $\partial_k$. Computationally efficient sparse algorithms for constructing boundary operators are developed to implement linear diffusion processes on $k$-simplices. The methodology generalizes heat kernel smoothing to $k$-simplices, utilizing boundary structure to localize topological features while maintaining homological invariance. Simulation studies demonstrate qualitative signal enhancement across vertex and edge domains following diffusion processes. Application to parcellated human brain functional connectivity networks reveals that simplex-space smoothing attenuates spurious connections while amplifying coherent anatomical architectures, establishing practical significance for computational neuroscience applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16908v2</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sixtus Dakurah</dc:creator>
    </item>
    <item>
      <title>Brain-language fusion enables interactive neural readout and in-silico experimentation</title>
      <link>https://arxiv.org/abs/2509.23941</link>
      <description>arXiv:2509.23941v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have revolutionized human-machine interaction, and have been extended by embedding diverse modalities such as images into a shared language space. Yet, neural decoding has remained constrained by static, non-interactive methods. We introduce CorText, a framework that integrates neural activity directly into the latent space of an LLM, enabling open-ended, natural language interaction with brain data. Trained on fMRI data recorded during viewing of natural scenes, CorText generates accurate image captions and can answer more detailed questions better than controls, while having access to neural data only. We showcase that CorText achieves zero-shot generalization beyond semantic categories seen during training. In-silico microstimulation experiments, which enable counterfactual prompts on brain activity, reveal a consistent, and graded mapping between brain-state and language output. These advances mark a shift from passive decoding toward generative, flexible interfaces between brain activity and language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23941v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victoria Bosch, Daniel Anthes, Adrien Doerig, Sushrut Thorat, Peter K\"onig, Tim Christian Kietzmann</dc:creator>
    </item>
    <item>
      <title>Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement</title>
      <link>https://arxiv.org/abs/2510.22860</link>
      <description>arXiv:2510.22860v2 Announce Type: replace-cross 
Abstract: Understanding how the human brain progresses from processing simple linguistic inputs to performing high-level reasoning is a fundamental challenge in neuroscience. While modern large language models (LLMs) are increasingly used to model neural responses to language, their internal representations are highly "entangled," mixing information about lexicon, syntax, meaning, and reasoning. This entanglement biases conventional brain encoding analyses toward linguistically shallow features (e.g., lexicon and syntax), making it difficult to isolate the neural substrates of cognitively deeper processes. Here, we introduce a residual disentanglement method that computationally isolates these components. By first probing an LM to identify feature-specific layers, our method iteratively regresses out lower-level representations to produce four nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically, reasoning. We used these disentangled embeddings to model intracranial (ECoG) brain recordings from neurosurgical patients listening to natural speech. We show that: 1) This isolated reasoning embedding exhibits unique predictive power, accounting for variance in neural activity not explained by other linguistic features and even extending to the recruitment of visual regions beyond classical language areas. 2) The neural signature for reasoning is temporally distinct, peaking later (~350-400ms) than signals related to lexicon, syntax, and meaning, consistent with its position atop a processing hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as their predictive success is primarily attributable to linguistically shallow features, masking the more subtle contributions of deeper cognitive processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22860v2</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Linyang He, Tianjun Zhong, Richard Antonello, Gavin Mischler, Micah Goldblum, Nima Mesgarani</dc:creator>
    </item>
  </channel>
</rss>
