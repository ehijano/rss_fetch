<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 06 May 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On Smale's 17th problem over the reals</title>
      <link>https://arxiv.org/abs/2405.01735</link>
      <description>arXiv:2405.01735v1 Announce Type: new 
Abstract: We consider the problem of efficiently solving a system of $n$ non-linear equations in ${\mathbb R}^d$. Addressing Smale's 17th problem stated in 1998, we consider a setting whereby the $n$ equations are random homogeneous polynomials of arbitrary degrees. In the complex case and for $n= d-1$, Beltr\'{a}n and Pardo proved the existence of an efficient randomized algorithm and Lairez recently showed it can be de-randomized to produce a deterministic efficient algorithm. Here we consider the real setting, to which previously developed methods do not apply. We describe an algorithm that efficiently finds solutions (with high probability) for $n= d -O(\sqrt{d\log d})$. If the maximal degree is very large, we also give an algorithm that works up to $n=d-1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01735v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Montanari, Eliran Subag</dc:creator>
    </item>
    <item>
      <title>Random Subgraph Detection Using Queries</title>
      <link>https://arxiv.org/abs/2110.00744</link>
      <description>arXiv:2110.00744v5 Announce Type: replace 
Abstract: The planted densest subgraph detection problem refers to the task of testing whether in a given (random) graph there is a subgraph that is unusually dense. Specifically, we observe an undirected and unweighted graph on $n$ vertices. Under the null hypothesis, the graph is a realization of an Erd\H{o}s-R\'{e}nyi graph with edge probability (or, density) $q$. Under the alternative, there is a subgraph on $k$ vertices with edge probability $p&gt;q$. The statistical as well as the computational barriers of this problem are well-understood for a wide range of the edge parameters $p$ and $q$. In this paper, we consider a natural variant of the above problem, where one can only observe a relatively small part of the graph using adaptive edge queries. For this model, we determine the number of queries necessary and sufficient (accompanied with a quasi-polynomial optimal algorithm) for detecting the presence of the planted subgraph. We also propose a polynomial-time algorithm which is able to detect the planted subgraph, albeit with more queries compared to the above lower bound. We conjecture that in the leftover regime, no polynomial-time algorithms exist. Our results resolve two open questions posed in the past literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.00744v5</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wasim Huleihel, Arya Mazumdar, Soumyabrata Pal</dc:creator>
    </item>
    <item>
      <title>Finding Diverse Minimum s-t Cuts</title>
      <link>https://arxiv.org/abs/2303.07290</link>
      <description>arXiv:2303.07290v2 Announce Type: replace 
Abstract: Recently, many studies have been devoted to finding \textit{diverse} solutions in classical combinatorial problems, such as \textsc{Vertex Cover} (Baste et al., IJCAI'20), \textsc{Matching} (Fomin et al., ISAAC'20) and \textsc{Spanning Tree} (Hanaka et al., AAAI'21). We initiate the algorithmic study of $k$-\textsc{Diverse Minimum s-t Cuts} which, given a directed graph $G = (V, E)$, two specified vertices $s,t \in V$, and an integer $k &gt; 0$, asks for a collection of $k$ minimum $s$-$t$ cuts in $G$ that has maximum diversity. We investigate the complexity of the problem for maximizing three diversity measures that can be applied to a collection of cuts: (i) the sum of all pairwise Hamming distances, (ii) the cardinality of the union of cuts in the collection, and (iii) the minimum pairwise Hamming distance. We prove that $k$-\textsc{Diverse Minimum s-t Cuts} can be solved in strongly polynomial time for diversity measures (i) and (ii) via \textit{submodular function minimization}. We obtain this result by establishing a connection between ordered collections of minimum $s$-$t$ cuts and the theory of distributive lattices. When restricted to finding only collections of mutually disjoint solutions, we provide a more practical algorithm that finds a maximum set of pairwise disjoint minimum $s$-$t$ cuts. For graphs with small minimum $s$-$t$ cut, it runs in the time of a single \textit{max-flow} computation. Our results stand in contrast to the problem of finding $k$ diverse \textit{global} minimum cuts -- which is known to be NP-hard even for the disjoint case (Hanaka et al., AAAI'23) -- and partially answer a long-standing open question of Wagner (Networks, 1990) about improving the complexity of finding disjoint collections of minimum $s$-$t$ cuts. Lastly, we show that $k$-\textsc{Diverse Minimum s-t Cuts} subject to diversity measure (iii) is NP-hard already for $k=3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.07290v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Berg, Andr\'es L\'opez Mart\'inez, Frits Spieksma</dc:creator>
    </item>
    <item>
      <title>Zip-zip Trees: Making Zip Trees More Balanced, Biased, Compact, or Persistent</title>
      <link>https://arxiv.org/abs/2307.07660</link>
      <description>arXiv:2307.07660v2 Announce Type: replace 
Abstract: We define simple variants of zip trees, called zip-zip trees, which provide several advantages over zip trees, including overcoming a bias that favors smaller keys over larger ones. We analyze zip-zip trees theoretically and empirically, showing, e.g., that the expected depth of a node in an $n$-node zip-zip tree is at most $1.3863\log n-1+o(1)$, which matches the expected depth of treaps and binary search trees built by uniformly random insertions. Unlike these other data structures, however, zip-zip trees achieve their bounds using only $O(\log\log n)$ bits of metadata per node, w.h.p., as compared to the $\Theta(\log n)$ bits per node required by treaps. In fact, we even describe a ``just-in-time'' zip-zip tree variant, which needs just an expected $O(1)$ number of bits of metadata per node. Moreover, we can define zip-zip trees to be strongly history independent, whereas treaps are generally only weakly history independent. We also introduce \emph{biased zip-zip trees}, which have an explicit bias based on key weights, so the expected depth of a key, $k$, with weight, $w_k$, is $O(\log (W/w_k))$, where $W$ is the weight of all keys in the weighted zip-zip tree. Finally, we show that one can easily make zip-zip trees partially persistent with only $O(n)$ space overhead w.h.p.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07660v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ofek Gila (University of California, Irvine), Michael T. Goodrich (University of California, Irvine), Robert E. Tarjan (Princeton University)</dc:creator>
    </item>
    <item>
      <title>Local Lipschitz Filters for Bounded-Range Functions with Applications to Arbitrary Real-Valued Functions</title>
      <link>https://arxiv.org/abs/2308.14716</link>
      <description>arXiv:2308.14716v3 Announce Type: replace 
Abstract: We study local filters for the Lipschitz property of real-valued functions $f: V \to [0,r]$, where the Lipschitz property is defined with respect to an arbitrary undirected graph $G=(V,E)$. We give nearly optimal local Lipschitz filters both with respect to $\ell_1$-distance and $\ell_0$-distance. Previous work only considered unbounded-range functions over $[n]^d$. Jha and Raskhodnikova (SICOMP `13) gave an algorithm for such functions with lookup complexity exponential in $d$, which Awasthi et al. (ACM Trans. Comput. Theory) showed was necessary in this setting. We demonstrate that important applications of local Lipschitz filters can be accomplished with filters for functions with bounded-range. For functions $f: [n]^d\to [0,r]$, we circumvent the lower bound and achieve running time $(d^r\log n)^{O(\log r)}$ for the $\ell_1$-respecting filter and $d^{O(r)}\text{polylog } n$ for the $\ell_0$-respecting filter. Our local filters provide a novel Lipschitz extension that can be implemented locally. Furthermore, we show that our algorithms have nearly optimal dependence on $r$ for the domain $\{0,1\}^d$. In addition, our lower bound resolves an open question of Awasthi et al., removing one of the conditions necessary for their lower bound for general range. We prove our lower bound via a reduction from distribution-free Lipschitz testing and a new technique for proving hardness for adaptive algorithms. We provide two applications of our local filters to arbitrary real-valued functions. In the first application, we use them in conjunction with the Laplace mechanism for differential privacy and noisy binary search to provide mechanisms for privately releasing outputs of black-box functions, even in the presence of malicious clients. In the second application, we use our local filters to obtain the first nontrivial tolerant tester for the Lipschitz property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14716v3</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jane Lange, Ephraim Linder, Sofya Raskhodnikova, Arsen Vasilyan</dc:creator>
    </item>
  </channel>
</rss>
