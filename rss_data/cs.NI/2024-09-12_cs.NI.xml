<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2024 01:41:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Synchronization Control-Plane Protocol for Quantum Link Layer</title>
      <link>https://arxiv.org/abs/2409.07049</link>
      <description>arXiv:2409.07049v1 Announce Type: new 
Abstract: Heralded entanglement generation between nodes of a future quantum internet is a fundamental operation that unlocks the potential for quantum communication. In this paper, we propose a decentralized synchronization protocol that operates at the classical control-plane of the link layer, to navigate the coordination challenges of generating heralded entanglement across few-qubit quantum network nodes. Additionally, with quantum network simulations using NetSquid, we show that our protocol achieves lower entanglement request latencies than a naive distributed queue approach. We observe a sixfold reduction in average request latency growth as the number of quantum network links increases. The Eventual Synchronization Protocol (ESP) allows nodes to coordinate on heralded entanglement generation in a scalable manner within multi-peer quantum networks. To the best of our knowledge, this is the first decentralized synchronization protocol for managing heralded entanglement requests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07049v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Ru, Winston K. G. Seah, Alvin C. Valera</dc:creator>
    </item>
    <item>
      <title>Extensions to BIER Tree Engineering (BIER-TE) for Large Multicast Domains and 1:1 Protection: Concept, Implementation and Performance</title>
      <link>https://arxiv.org/abs/2409.07082</link>
      <description>arXiv:2409.07082v1 Announce Type: new 
Abstract: Bit Index Explicit Replication (BIER) has been proposed by the IETF as a stateless multicast transport technology. BIER adds a BIER header containing a bitstring indicating receivers of an IP multicast (IPMC) packet within a BIER domain. BIER-TE extends BIER with tree engineering capabilities, i.e., the bitstring indicates both receivers as well as links over which the packet is transmitted. As the bitstring is of limited size, e.g., 256 bits, only that number of receivers can be addressed within a BIER packet. To scale BIER to larger networks, the receivers of a BIER domain have been assigned to subsets that can be addressed by a bitstring with a subset ID. This approach is even compliant with fast reroute (FRR) mechanisms for BIER.
  In this work we tackle the challenge of scaling BIER-TE to large networks as the subset mechanism of BIER is not sufficient for that purpose. A major challenge is the support of a protection mechanism in this context. We describe how existing networking concepts like tunneling, egress protection and BIER-TE-FRR can be combined to achieve the goal. Then, we implement the relevant BIER-TE components on the P4-programmable Tofino ASIC which builds upon an existing implementation for BIER. Finally, we consider the forwarding performance of the prototype and explain how weaknesses can be improved from remedies that are well-known for BIER implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07082v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moritz Fl\"uchter, Steffen Lindner, Fabian Ihle, Michael Menth</dc:creator>
    </item>
    <item>
      <title>Extracting TCPIP Headers at High Speed for the Anonymized Network Traffic Graph Challenge</title>
      <link>https://arxiv.org/abs/2409.07374</link>
      <description>arXiv:2409.07374v1 Announce Type: new 
Abstract: Field Programmable Gate Arrays (FPGAs) play a significant role in computationally intensive network processing due to their flexibility and efficiency. Particularly with the high-level abstraction of the P4 network programming model, FPGA shows a powerful potential for packet processing. By supporting the P4 language with FPGA processing, network researchers can create customized FPGA-based network functions and execute network tasks on accelerators directly connected to the network. A feature of the P4 language is that it is stateless; however, the FPGA implementation in this research requires state information. This is accomplished using P4 externs to describe the stateful portions of the design and to implement them on the FPGA using High-Level Synthesis (HLS). This paper demonstrates using an FPGA-based SmartNIC to efficiently extract source-destination IP address information from network packets and construct anonymized network traffic matrices for further analysis. The implementation is the first example of the combination of using P4 and HLS in developing network functions on the latest AMD FPGAs. Our design achieves a processing rate of approximately 95 Gbps with the combined use of P4 and High-level Synthesis and is able to keep up with 100 Gbps traffic received directly from the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07374v1</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoyang Han, Andrew Briasco-Stewart, Michael Zink, Miriam Leeser</dc:creator>
    </item>
    <item>
      <title>Scalable Multivariate Fronthaul Quantization for Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2409.06715</link>
      <description>arXiv:2409.06715v1 Announce Type: cross 
Abstract: The conventional approach to the fronthaul design for cell-free massive MIMO system follows the compress-and-precode (CP) paradigm. Accordingly, encoded bits and precoding coefficients are shared by the distributed unit (DU) on the fronthaul links, and precoding takes place at the radio units (RUs). Previous theoretical work has shown that CP can be potentially improved by a significant margin by precode-and-compress (PC) methods, in which all baseband processing is carried out at the DU, which compresses the precoded signals for transmission on the fronthaul links. The theoretical performance gain of PC methods are particularly pronounced when the DU implements multivariate quantization (MQ), applying joint quantization across the signals for all the RUs. However, existing solutions for MQ are characterized by a computational complexity that grows exponentially with the sum-fronthaul capacity from the DU to all RUs. This work sets out to design scalable MQ strategies for PC-based cell-free massive MIMO systems. For the low-fronthaul capacity regime, we present alpha-parallel MQ (alpha-PMQ), whose complexity is exponential only in the fronthaul capacity towards an individual RU, while performing close to full MQ. alpha-PMQ tailors MQ to the topology of the network by allowing for parallel local quantization steps for RUs that do not interfere too much with each other. For the high-fronthaul capacity regime, we then introduce neural MQ, which replaces the exhaustive search in MQ with gradient-based updates for a neural-network-based decoder, attaining a complexity that grows linearly with the sum-fronthaul capacity. Numerical results demonstrate that the proposed scalable MQ strategies outperform CP for both the low and high-fronthaul capacity regimes at the cost of increased computational complexity at the DU (but not at the RUs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06715v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sangwoo Park, Ahmet Hasim Gokceoglu, Li Wang, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Echoes of Privacy: Uncovering the Profiling Practices of Voice Assistants</title>
      <link>https://arxiv.org/abs/2409.07444</link>
      <description>arXiv:2409.07444v1 Announce Type: cross 
Abstract: Many companies, including Google, Amazon, and Apple, offer voice assistants as a convenient solution for answering general voice queries and accessing their services. These voice assistants have gained popularity and can be easily accessed through various smart devices such as smartphones, smart speakers, smartwatches, and an increasing array of other devices. However, this convenience comes with potential privacy risks. For instance, while companies vaguely mention in their privacy policies that they may use voice interactions for user profiling, it remains unclear to what extent this profiling occurs and whether voice interactions pose greater privacy risks compared to other interaction modalities.
  In this paper, we conduct 1171 experiments involving a total of 24530 queries with different personas and interaction modalities over the course of 20 months to characterize how the three most popular voice assistants profile their users. We analyze factors such as the labels assigned to users, their accuracy, the time taken to assign these labels, differences between voice and web interactions, and the effectiveness of profiling remediation tools offered by each voice assistant. Our findings reveal that profiling can happen without interaction, can be incorrect and inconsistent at times, may take several days to weeks for changes to occur, and can be influenced by the interaction modality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07444v1</guid>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tina Khezresmaeilzadeh, Elaine Zhu, Kiersten Grieco, Daniel J. Dubois, Konstantinos Psounis, David Choffnes</dc:creator>
    </item>
    <item>
      <title>The Structure of Hypergraphs Arising in Cellular Mobile Communication Systems</title>
      <link>https://arxiv.org/abs/2207.00515</link>
      <description>arXiv:2207.00515v4 Announce Type: replace 
Abstract: An assumption that researchers have often used to model interference in a wireless network is the unit disk graph model. While many theoretical results and performance guarantees have been obtained under this model, an open research direction is to extend these results to hypergraph interference models. Motivated by recent results that the worst-case performance of the distributed maximal scheduling algorithm is characterized by the interference degree of the hypergraph, in the present work we investigate properties of the interference degree of the hypergraph and the structure of hypergraphs arising from physical constraints. We show that the problem of computing the interference degree of a hypergraph is NP-hard and we prove some properties and results concerning this hypergraph invariant. We investigate which hypergraphs are realizable, i.e. which hypergraphs arise in practice, based on physical constraints, as the interference model of a wireless network. In particular, a question that arises naturally is: what is the maximal value of $r$ such that the hypergraph $K_{1,r}$ is realizable? We determine this quantity for various integral and nonintegral values of the path loss exponent of signal propagation. We also investigate hypergraphs generated by line networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.00515v4</guid>
      <category>cs.NI</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Ganesan</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Survey of Wireless Time-Sensitive Networking (TSN): Architecture, Technologies, Applications, and Open Issues</title>
      <link>https://arxiv.org/abs/2312.01204</link>
      <description>arXiv:2312.01204v2 Announce Type: replace 
Abstract: Time-sensitive networking (TSN) is expected to be a key component of critical machine-type communication networks in areas such as Industry 4.0, robotics and autonomous vehicles. With rising mobility requirements in industrial applications and the prevalence of wireless networks, wireless network integration into TSN is becoming increasingly important. This survey article presents a comprehensive review of the current literature on wireless TSN, including an overview of the architecture of a wireless TSN network and an examination of the various wireless technologies and protocols that can be or are used in such networks. In addition, the article discusses industrial applications of wireless TSN, among them industrial automation, robotics, and autonomous vehicles. The article concludes by summarizing the challenges and open issues related to the integration of TSN into wireless networks, and by offering suggestions for future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01204v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kouros Zanbouri, Md. Noor-A-Rahim, Jobish John, Cormac J. Sreenan, H. Vincent Poor, Dirk Pesch</dc:creator>
    </item>
    <item>
      <title>An In-Depth Investigation of LEO Satellite Topology Design Parameters</title>
      <link>https://arxiv.org/abs/2402.08988</link>
      <description>arXiv:2402.08988v2 Announce Type: replace 
Abstract: Low Earth Orbit (LEO) satellite networks are rapidly gaining traction today. Although several real-world deployments exist, our preliminary analysis of LEO topology performance with the soon-to-be operational Inter-Satellite Links (ISLs) reveals several interesting characteristics that are difficult to explain based on our current understanding of topologies. For example, a real-world satellite shell with a low density of satellites offers better latency performance than another shell with nearly double the number of satellites. In this work, we conduct an in-depth investigation of LEO satellite topology design parameters and their impact on network performance while using the ISLs. In particular, we focus on three design parameters: the number of orbits in a shell, the inclination of orbits, and the number of satellites per orbit. Through an extensive analysis of real-world and synthetic satellite configurations, we uncover several interesting properties of satellite topologies. Notably, there exist thresholds for the number of satellites per orbit and the number of orbits below which the latency performance degrades significantly. Moreover, network delay between a pair of traffic endpoints depends on the alignment of the satellite's orbit (Inclination) with the geographic locations of endpoints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08988v2</guid>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyi Zhang, Zihan Xu, Sangeetha Abdu Jyothi</dc:creator>
    </item>
    <item>
      <title>MA-CDMR: An Intelligent Cross-domain Multicast Routing Method based on Multiagent Deep Reinforcement Learning in Multi-domain SDWN</title>
      <link>https://arxiv.org/abs/2409.05888</link>
      <description>arXiv:2409.05888v2 Announce Type: replace 
Abstract: The cross-domain multicast routing problem in a software-defined wireless network with multiple controllers is a classic NP-hard optimization problem. As the network size increases, designing and implementing cross-domain multicast routing paths in the network requires not only designing efficient solution algorithms to obtain the optimal cross-domain multicast tree but also ensuring the timely and flexible acquisition and maintenance of global network state information. However, existing solutions have a limited ability to sense the network traffic state, affecting the quality of service of multicast services. In addition, these methods have difficulty adapting to the highly dynamically changing network states and have slow convergence speeds. To this end, this paper aims to design and implement a multiagent deep reinforcement learning based cross-domain multicast routing method for SDWN with multicontroller domains. First, a multicontroller communication mechanism and a multicast group management module are designed to transfer and synchronize network information between different control domains of the SDWN, thus effectively managing the joining and classification of members in the cross-domain multicast group. Second, a theoretical analysis and proof show that the optimal cross-domain multicast tree includes an interdomain multicast tree and an intradomain multicast tree. An agent is established for each controller, and a cooperation mechanism between multiple agents is designed to effectively optimize cross-domain multicast routing and ensure consistency and validity in the representation of network state information for cross-domain multicast routing decisions. Third, a multiagent reinforcement learning-based method that combines online and offline training is designed to reduce the dependence on the real-time environment and increase the convergence speed of multiple agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05888v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miao Ye, Hongwen Hu, Xiaoli Wang, Yuping Wang, Yong Wang, Wen Peng, Jihao Zheng</dc:creator>
    </item>
    <item>
      <title>From the Beginning: Key Transitions in the First 15 Years of DNSSEC</title>
      <link>https://arxiv.org/abs/2109.08783</link>
      <description>arXiv:2109.08783v2 Announce Type: replace-cross 
Abstract: When the global rollout of the DNS Security Extensions (DNSSEC) began in 2005, a first-of-its-kind trial started: The complexity of a core Internet protocol was magnified in favor of better security for the overall Internet. Thereby, the scale of the loosely-federated delegation in DNS became an unprecedented cryptographic key management challenge. Though fundamental for current and future operational success, our community lacks a clear notion of how to empirically evaluate the process of securely transitioning keys.
  In this paper, we propose two building blocks to formally characterize and assess key transitions. First, the anatomy of key transitions, i.e., measurable and well-defined properties of key changes; and second, a novel classification model based on this anatomy for describing key transition practices in abstract terms. This abstraction allows for classifying operational behavior. We apply our proposed transition anatomy and transition classes to describe the global DNSSEC deployment. Specifically, we use measurements from the first 15 years of the DNSSEC rollout to detect and understand which key transitions have been used to what degree and which rates of errors and warnings occurred. In contrast to prior work, we consider all possible transitions and not only 1:1 key rollovers. Our results show measurable gaps between prescribed key management processes and key transitions in the wild. We also find evidence that such noncompliant transitions are needed in operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.08783v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNSM.2022.3195406</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Network and Service Management, Vol. 19, No. 4, pp. 5265-5283, Dec. 2022</arxiv:journal_reference>
      <dc:creator>Eric Osterweil, Pouyan Fotouhi Tehrani, Thomas C. Schmidt, Matthias W\"ahlisch</dc:creator>
    </item>
    <item>
      <title>Detecting 5G Narrowband Jammers with CNN, k-nearest Neighbors, and Support Vector Machines</title>
      <link>https://arxiv.org/abs/2405.09564</link>
      <description>arXiv:2405.09564v2 Announce Type: replace-cross 
Abstract: 5G cellular networks are particularly vulnerable against narrowband jammers that target specific control sub-channels in the radio signal. One mitigation approach is to detect such jamming attacks with an online observation system, based on machine learning. We propose to detect jamming at the physical layer with a pre-trained machine learning model that performs binary classification. Based on data from an experimental 5G network, we study the performance of different classification models. A convolutional neural network will be compared to support vector machines and k-nearest neighbors, where the last two methods are combined with principal component analysis. The obtained results show substantial differences in terms of classification accuracy and computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09564v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Varotto, Florian Heinrichs, Timo Schuerg, Stefano Tomasin, Stefan Valentin</dc:creator>
    </item>
    <item>
      <title>Distributed Noncoherent Joint Transmission Based on Multi-Agent Reinforcement Learning for Dense Small Cell MISO Systems</title>
      <link>https://arxiv.org/abs/2408.12067</link>
      <description>arXiv:2408.12067v2 Announce Type: replace-cross 
Abstract: We consider a dense small cell (DSC) network where multi-antenna small cell base stations (SBSs) transmit data to single-antenna users over a shared frequency band. To enhance capacity, a state-of-the-art technique known as noncoherent joint transmission (JT) is applied, enabling users to receive data from multiple coordinated SBSs. However, the sum rate maximization problem with noncoherent JT is inherently nonconvex and NP-hard. While existing optimization-based noncoherent JT algorithms can provide near-optimal performance, they require global channel state information (CSI) and multiple iterations, which makes them difficult to be implemeted in DSC networks.To overcome these challenges, we first prove that the optimal beamforming structure is the same for both the power minimization problem and the sum rate maximization problem, and then mathematically derive the optimal beamforming structure for both problems by solving the power minimization problem.The optimal beamforming structure can effectively reduces the variable dimensions.By exploiting the optimal beamforming structure, we propose a deep deterministic policy gradient-based distributed noncoherent JT scheme to maximize the system sum rate.In the proposed scheme, each SBS utilizes global information for training and uses local CSI to determine beamforming vectors. Simulation results demonstrate that the proposed scheme achieves comparable performance with considerably lower computational complexity and information overhead compared to centralized iterative optimization-based techniques, making it more attractive for practical deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12067v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaozhuang Bai, Zhenzhen Gao, Xuewen Liao</dc:creator>
    </item>
  </channel>
</rss>
