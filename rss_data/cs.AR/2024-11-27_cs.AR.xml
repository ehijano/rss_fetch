<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 02:52:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>SynDCIM: A Performance-Aware Digital Computing-in-Memory Compiler with Multi-Spec-Oriented Subcircuit Synthesis</title>
      <link>https://arxiv.org/abs/2411.16806</link>
      <description>arXiv:2411.16806v1 Announce Type: new 
Abstract: Digital Computing-in-Memory (DCIM) is an innovative technology that integrates multiply-accumulation (MAC) logic directly into memory arrays to enhance the performance of modern AI computing. However, the need for customized memory cells and logic components currently necessitates significant manual effort in DCIM design. Existing tools for facilitating DCIM macro designs struggle to optimize subcircuit synthesis to meet user-defined performance criteria, thereby limiting the potential system-level acceleration that DCIM can offer. To address these challenges and enable agile design of DCIM macros with optimal architectures, we present SynDCIM, a performance-aware DCIM compiler that employs multi-spec-oriented subcircuit synthesis. SynDCIM features an automated performance-to-layout generation process that aligns with user-defined performance expectations. This is supported by a scalable subcircuit library and a multi-spec-oriented searching algorithm for effective subcircuit synthesis. The effectiveness of SynDCIM is demonstrated through extensive experiments and validated with a test chip fabricated in a 40nm CMOS process. Testing results reveal that designs generated by SynDCIM exhibit competitive performance when compared to state-of-the-art manually designed DCIM macros.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16806v1</guid>
      <category>cs.AR</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunming Shao, Fengshi Tian, Xiaomeng Wang, Jiakun Zheng, Jia Chen, Jingyu He, Hui Wu, Jinbo Chen, Xihao Guan, Yi Deng, Fengbin Tu, Jie Yang, Mohamad Sawan, Tim Kwang-Ting Cheng, Chi-Ying Tsui</dc:creator>
    </item>
    <item>
      <title>PIM-AI: A Novel Architecture for High-Efficiency LLM Inference</title>
      <link>https://arxiv.org/abs/2411.17309</link>
      <description>arXiv:2411.17309v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have become essential in a variety of applications due to their advanced language understanding and generation capabilities. However, their computational and memory requirements pose significant challenges to traditional hardware architectures. Processing-in-Memory (PIM), which integrates computational units directly into memory chips, offers several advantages for LLM inference, including reduced data transfer bottlenecks and improved power efficiency.
  This paper introduces PIM-AI, a novel DDR5/LPDDR5 PIM architecture designed for LLM inference without modifying the memory controller or DDR/LPDDR memory PHY. We have developed a simulator to evaluate the performance of PIM-AI in various scenarios and demonstrate its significant advantages over conventional architectures. In cloud-based scenarios, PIM-AI reduces the 3-year TCO per queries-per-second by up to 6.94x compared to state-of-the-art GPUs, depending on the LLM model used. In mobile scenarios, PIM-AI achieves a 10- to 20-fold reduction in energy per token compared to state-of-the-art mobile SoCs, resulting in 25 to 45~\% more queries per second and 6.9x to 13.4x less energy per query, extending battery life and enabling more inferences per charge.
  These results highlight PIM-AI's potential to revolutionize LLM deployments, making them more efficient, scalable, and sustainable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17309v1</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristobal Ortega, Yann Falevoz, Renaud Ayrignac</dc:creator>
    </item>
    <item>
      <title>Efficient Deployment of Transformer Models in Analog In-Memory Computing Hardware</title>
      <link>https://arxiv.org/abs/2411.17367</link>
      <description>arXiv:2411.17367v1 Announce Type: new 
Abstract: Analog in-memory computing (AIMC) has emerged as a promising solution to overcome the von Neumann bottleneck, accelerating neural network computations and improving computational efficiency. While AIMC has demonstrated success with architectures such as CNNs, MLPs, and RNNs, deploying transformer-based models using AIMC presents unique challenges. Transformers are expected to handle diverse downstream tasks and adapt to new user data or instructions after deployment, which requires more flexible approaches to suit AIMC constraints.
  In this paper, we propose a novel method for deploying pre-trained transformer models onto AIMC hardware. Unlike traditional approaches requiring hardware-aware training, our technique allows direct deployment without the need for retraining the original model. Instead, we utilize lightweight, low-rank adapters -- compact modules stored in digital cores -- to adapt the model to hardware constraints. We validate our approach on MobileBERT, demonstrating accuracy on par with, or even exceeding, a traditional hardware-aware training approach. Our method is particularly appealing in multi-task scenarios, as it enables a single analog model to be reused across multiple tasks. Moreover, it supports on-chip adaptation to new hardware constraints and tasks without updating analog weights, providing a flexible and versatile solution for real-world AI applications. Code is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17367v1</guid>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Li, Corey Lammie, Manuel Le Gallo, Bipin Rajendran</dc:creator>
    </item>
    <item>
      <title>SafeLight: Enhancing Security in Optical Convolutional Neural Network Accelerators</title>
      <link>https://arxiv.org/abs/2411.16712</link>
      <description>arXiv:2411.16712v1 Announce Type: cross 
Abstract: The rapid proliferation of deep learning has revolutionized computing hardware, driving innovations to improve computationally expensive multiply-and-accumulate operations in deep neural networks. Among these innovations are integrated silicon-photonic systems that have emerged as energy-efficient platforms capable of achieving light speed computation and communication, positioning optical neural network (ONN) platforms as a transformative technology for accelerating deep learning models such as convolutional neural networks (CNNs). However, the increasing complexity of optical hardware introduces new vulnerabilities, notably the risk of hardware trojan (HT) attacks. Despite the growing interest in ONN platforms, little attention has been given to how HT-induced threats can compromise performance and security. This paper presents an in-depth analysis of the impact of such attacks on the performance of CNN models accelerated by ONN accelerators. Specifically, we show how HTs can compromise microring resonators (MRs) in a state-of-the-art non-coherent ONN accelerator and reduce classification accuracy across CNN models by up to 7.49% to 80.46% by just targeting 10% of MRs. We then propose techniques to enhance ONN accelerator robustness against these attacks and show how the best techniques can effectively recover the accuracy drops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16712v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Salma Afifi, Ishan Thakkar, Sudeep Pasricha</dc:creator>
    </item>
    <item>
      <title>Single Event Upsets characterization of 65 nm CMOS 6T and 8T SRAM cells for ground level environment</title>
      <link>https://arxiv.org/abs/2411.17198</link>
      <description>arXiv:2411.17198v1 Announce Type: cross 
Abstract: We present experimental results of the cross-section related to cosmic-ray irradiation at ground level for minimum-sized six-transistors (6T) and eight-transistors (8T) bit-cells SRAM memories implemented on a 65 nm CMOS standard technology. Results were obtained from accelerated irradiation tests performed in the mixed-field irradiation facility of the CERN High-energy Accelerator test facility (CHARM) at the European Organization for Nuclear Research in Geneva, Switzerland. A 1.45x higher SEU cross-section was observed for 6T-cell designs despite the larger area occupied by the 8T cells (1.5x for MCU). Moreover, the trend for events affecting multiple bits was higher in 6T-cells. The cross-section obtained values show that the memories have enough sensitivity to be used as a radiation monitors in high energy physics experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17198v1</guid>
      <category>physics.ins-det</category>
      <category>cs.AR</category>
      <category>hep-ex</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.microrel.2020.113696</arxiv:DOI>
      <arxiv:journal_reference>Microelectronics Reliability, Volume 110, art. no. 113696, 2020</arxiv:journal_reference>
      <dc:creator>Daniel Malagon (University of the Balearic Islands), Gabriel Torrens (University of the Balearic Islands), Jaume Segura (University of the Balearic Islands), Sebastia A. Bota (University of the Balearic Islands)</dc:creator>
    </item>
    <item>
      <title>High-Performance and Scalable Fault-Tolerant Quantum Computation with Lattice Surgery on a 2.5D Architecture</title>
      <link>https://arxiv.org/abs/2411.17519</link>
      <description>arXiv:2411.17519v1 Announce Type: cross 
Abstract: Due to the high error rate of a qubit, detecting and correcting errors on it is essential for fault-tolerant quantum computing (FTQC). Among several FTQC techniques, lattice surgery (LS) using surface code (SC) is currently promising. To demonstrate practical quantum advantage as early as possible, it is indispensable to propose a high-performance and low-overhead FTQC architecture specialized for a given FTQC scheme based on detailed analysis.
  In this study, we first categorize the factors, or hazards, that degrade LS-based FTQC performance and propose a performance evaluation methodology to decompose the impact of each hazard, inspired by the CPI stack. We propose the Bypass architecture based on the bottleneck analysis using the proposed evaluation methodology. The proposed Bypass architecture is a 2.5-dimensional architecture consisting of dense and sparse qubit layers and successfully eliminates the bottleneck to achieve high-performance and scalable LS-based FTQC. We evaluate the proposed architecture with a circuit-level stabilizer simulator and a cycle-accurate LS simulator with practical quantum phase estimation problems. The results show that the Bypass architecture improves the fidelity of FTQC and achieves both a 1.73x speedup and a 17% reduction in classical/quantum hardware resources over a conventional 2D architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17519v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yosuke Ueno, Taku Saito, Teruo Tanimoto, Yasunari Suzuki, Yutaka Tabuchi, Shuhei Tamate, Hiroshi Nakamura</dc:creator>
    </item>
    <item>
      <title>Rapid Deployment of Domain-specific Hyperspectral Image Processors with Application to Autonomous Driving</title>
      <link>https://arxiv.org/abs/2411.17543</link>
      <description>arXiv:2411.17543v1 Announce Type: cross 
Abstract: The article discusses the use of low cost System-On-Module (SOM) platforms for the implementation of efficient hyperspectral imaging (HSI) processors for application in autonomous driving. The work addresses the challenges of shaping and deploying multiple layer fully convolutional networks (FCN) for low-latency, on-board image semantic segmentation using resource- and power-constrained processing devices. The paper describes in detail the steps followed to redesign and customize a successfully trained HSI segmentation lightweight FCN that was previously tested on a high-end heterogeneous multiprocessing system-on-chip (MPSoC) to accommodate it to the constraints imposed by a low-cost SOM. This SOM features a lower-end but much cheaper MPSoC suitable for the deployment of automatic driving systems (ADS). In particular the article reports the data- and hardware-specific quantization techniques utilized to fit the FCN into a commercial fixed-point programmable AI coprocessor IP, and proposes a full customized post-training quantization scheme to reduce computation and storage costs without compromising segmentation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17543v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICECS58634.2023.10382745</arxiv:DOI>
      <arxiv:journal_reference>2023 30th IEEE International Conference on Electronics, Circuits and Systems (ICECS)</arxiv:journal_reference>
      <dc:creator>Jon Guti\'errez-Zaballa, Koldo Basterretxea, Javier Echanobe, \'Oscar Mata-Carballeira, M. Victoria Mart\'inez</dc:creator>
    </item>
    <item>
      <title>RTL-Breaker: Assessing the Security of LLMs against Backdoor Attacks on HDL Code Generation</title>
      <link>https://arxiv.org/abs/2411.17569</link>
      <description>arXiv:2411.17569v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated remarkable potential with code generation/completion tasks for hardware design. In fact, LLM-based hardware description language (HDL) code generation has enabled the industry to realize complex designs more quickly, reducing the time and effort required in the development cycle. However, the increased reliance on such automation introduces critical security risks. Notably, given that LLMs have to be trained on vast datasets of codes that are typically sourced from publicly available repositories (often without thorough validation), LLMs are susceptible to so-called data poisoning or backdoor attacks. Here, attackers inject malicious code for the training data, which can be carried over into the HDL code generated by LLMs. This threat vector can compromise the security and integrity of entire hardware systems. In this work, we propose RTL-Breaker, a novel backdoor attack framework on LLM-based HDL code generation. RTL-Breaker provides an in-depth analysis for essential aspects of this novel problem: 1) various trigger mechanisms versus their effectiveness for inserting malicious modifications, and 2) side-effects by backdoor attacks on code generation in general, i.e., impact on code quality. RTL-Breaker emphasizes the urgent need for more robust measures to safeguard against such attacks. Toward that end, we open-source our framework and all data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17569v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lakshmi Likhitha Mankali, Jitendra Bhandari, Manaar Alam, Ramesh Karri, Michail Maniatakos, Ozgur Sinanoglu, Johann Knechtel</dc:creator>
    </item>
    <item>
      <title>DeltaKWS: A 65nm 36nJ/Decision Bio-inspired Temporal-Sparsity-Aware Digital Keyword Spotting IC with 0.6V Near-Threshold SRAM</title>
      <link>https://arxiv.org/abs/2405.03905</link>
      <description>arXiv:2405.03905v2 Announce Type: replace 
Abstract: This paper introduces DeltaKWS, to the best of our knowledge, the first $\Delta$RNN-enabled fine-grained temporal sparsity-aware KWS IC for voice-controlled devices. The 65 nm prototype chip features a number of techniques to enhance performance, area, and power efficiencies, specifically: 1) a bio-inspired delta-gated recurrent neural network ($\Delta$RNN) classifier leveraging temporal similarities between neighboring feature vectors extracted from input frames and network hidden states, eliminating unnecessary operations and memory accesses; 2) an IIR BPF-based FEx that leverages mixed-precision quantization, low-cost computing structure and channel selection; 3) a 24 kB 0.6 V near-$V_\text{TH}$ weight SRAM that achieves 6.6X lower read power than the foundry-provided SRAM. From chip measurement results, we show that the DeltaKWS achieves an 11/12-class GSCD accuracy of 90.5%/89.5% respectively and energy consumption of 36 nJ/decision in 65 nm CMOS process. At 87% temporal sparsity, computing latency and energy/inference are reduced by 2.4X/3.4X, respectively. The IIR BPF-based FEx, $\Delta$RNN accelerator, and 24 kB near-$V_\text{TH}$ SRAM blocks occupy 0.084 mm$^{2}$, 0.319 mm$^{2}$, and 0.381 mm$^{2}$ respectively (0.78 mm$^{2}$ in total).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03905v2</guid>
      <category>cs.AR</category>
      <category>cs.CV</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCASAI.2024.3507694</arxiv:DOI>
      <dc:creator>Qinyu Chen, Kwantae Kim, Chang Gao, Sheng Zhou, Taekwang Jang, Tobi Delbruck, Shih-Chii Liu</dc:creator>
    </item>
    <item>
      <title>TimeFloats: Train-in-Memory with Time-Domain Floating-Point Scalar Products</title>
      <link>https://arxiv.org/abs/2409.00495</link>
      <description>arXiv:2409.00495v2 Announce Type: replace 
Abstract: In this work, we propose "TimeFloats," an efficient train-in-memory architecture that performs 8-bit floating-point scalar product operations in the time domain. While building on the compute-in-memory paradigm's integrated storage and inferential computations, TimeFloats additionally enables floating-point computations, thus facilitating DNN training within the same memory structures. Traditional compute-in-memory approaches with conventional ADCs and DACs face challenges such as higher power consumption and increased design complexity, especially at advanced CMOS nodes. In contrast, TimeFloats leverages time-domain signal processing to avoid conventional domain converters. It operates predominantly with digital building blocks, reducing power consumption and noise sensitivity while enabling high-resolution computations and easier integration with conventional digital circuits. Our simulation results demonstrate an energy efficiency of 22.1 TOPS/W while evaluating the design on 15 nm CMOS technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00495v2</guid>
      <category>cs.AR</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maeesha Binte Hashem, Benjamin Parpillon, Divake Kumar, Dinithi Jayasuria, Amit Ranjan Trivedi</dc:creator>
    </item>
    <item>
      <title>SAIM: Scalable Analog Ising Machine for Solving Quadratic Binary Optimization Problems</title>
      <link>https://arxiv.org/abs/2410.16079</link>
      <description>arXiv:2410.16079v2 Announce Type: replace 
Abstract: This paper presents a CMOS-compatible Lechner-Hauke-Zoller (LHZ)--based analog tile structure as a fundamental unit for developing scalable analog Ising machines (IMs). In the designed LHZ tile, the voltage-controlled oscillators are employed as the physical Ising spins, while for the ancillary spins, we introduce an oscillator-based circuit to emulate the constraint needed to ensure the correct functionality of the tile. We implement the proposed LHZ tile in 12nm FinFET technology using the Cadence Virtuoso. Simulation results show the proposed tile could converge to the results in about 31~ns. Also, the designed spins could operate at approximately 13~GHz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16079v2</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sasan Razmkhah, Jui-Yu Huang, Mehdi Kamal, Massoud Pedram</dc:creator>
    </item>
    <item>
      <title>Masala-CHAI: A Large-Scale SPICE Netlist Dataset for Analog Circuits by Harnessing AI</title>
      <link>https://arxiv.org/abs/2411.14299</link>
      <description>arXiv:2411.14299v2 Announce Type: replace 
Abstract: Masala-CHAI is the first fully automated framework leveraging large language models (LLMs) to generate Simulation Programs with Integrated Circuit Emphasis (SPICE) netlists. It addresses a long-standing challenge in automating netlist generation for analog circuits within circuit design automation. Automating this workflow could accelerate the creation of finetuned LLMs for analog circuit design and verification. We identify key challenges in this automation and evaluate the multi-modal capabilities of state-of-the-art LLMs, particularly GPT-4, to address these issues. We propose a three-step workflow to overcome current limitations: labeling analog circuits, prompt tuning, and netlist verification. This approach aims to create an end-to-end SPICE netlist generator from circuit schematic images, tackling the long-standing hurdle of accurate netlist generation. Our framework demonstrates significant performance improvements, tested on approximately 2,100 schematics of varying complexity. We open-source this solution for community-driven development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14299v2</guid>
      <category>cs.AR</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jitendra Bhandari, Vineet Bhat, Yuheng He, Siddharth Garg, Hamed Rahmani, Ramesh Karri</dc:creator>
    </item>
  </channel>
</rss>
