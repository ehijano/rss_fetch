<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.soc-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.soc-ph</link>
    <description>physics.soc-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.soc-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 04:08:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Identifying high-impact consumers' behavioural changes for flexibility and demand reduction in a net-zero energy system</title>
      <link>https://arxiv.org/abs/2508.04414</link>
      <description>arXiv:2508.04414v1 Announce Type: new 
Abstract: Achieving decarbonization across energy sectors requires demand-side transformation such as behavioural changes and end-use efficiency improvements to complement supply-side technological shifts. However, changing consumption patterns is challenging, and implementing efficiency measures requires time and investment, highlighting the need to prioritize strategies. We address this prioritization using a high-resolution model of the European energy system under net-zero emissions, assessing the system-wide impacts of reducing or shifting energy service demand across power, heating, transport, aviation, shipping, industry, and agriculture. Four stylised mechanisms (constant reduction, peak shaving, temporal shifting, and curtailment) that can be mapped to real-world phenomena are assessed for their impacts on system costs, electricity and heating prices, $CO_2$ price, and capacity needs. Results indicate that demand flexibility and curtailment yield the greatest benefits: shifting demand by 2 hours to align with solar output reduces system costs by 0.4%, while curtailing 3.7% of electricity demand during peak price periods cuts costs by 0.9%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04414v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Parisa Rahdan, Mirko Sch\"afer, Ana Bel\'en Crist\'obal L\'opez, Marta Victoria</dc:creator>
    </item>
    <item>
      <title>Functional mesoscale organization of complex networks</title>
      <link>https://arxiv.org/abs/2508.04562</link>
      <description>arXiv:2508.04562v1 Announce Type: new 
Abstract: The network density matrix (NDM) framework, enabling an information-theoretic and multiscale treatment of network flow, has been gaining momentum over the last decade. Benefiting from the counterparts of physical functions such as free energy and entropy, NDM's applications range from estimating how nodes influence network flows across scales the centrality of nodes at the local level to explaining the emergence of structural and functional order. Here, we introduce a generalized notion of the network internal energy $E_\tau$, where $\tau$ denotes a temporal hyperparameter allowing for multi-resolution analysis, showing how it measures the leakage of dynamical correlations from arbitrary partitions, where the minimally leaky subsystems have minimal $E_\tau$. Moreover, we analytically demonstrate that $E_\tau$ reduces to the well-known modularity function at the smallest temporal scale $\tau = 0$. We investigate this peculiar resemblance by comparing the communities minimizing $E_\tau$, with those detected by widely used methods like multiscale modularity and Markov stability. Our work provides a detailed analytical and computational picture of network generalized internal energy, and explores its effectiveness in detecting communities in synthetic and empirical networks within a unifying framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04562v1</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsham Ghavasieh, Satyaki Sikdar, Manlio De Domenico, Santo Fortunato</dc:creator>
    </item>
    <item>
      <title>Hierarchical community detection via maximum entropy partitions and the renormalization group</title>
      <link>https://arxiv.org/abs/2508.04034</link>
      <description>arXiv:2508.04034v1 Announce Type: cross 
Abstract: Identifying meaningful structure across multiple scales remains a central challenge in network science. We introduce Hierarchical Clustering Entropy (HCE), a general and model-agnostic framework for detecting informative levels in hierarchical community structures. Unlike existing approaches, HCE operates directly on dendrograms without relying on edge-level statistics. It selects resolution levels that maximize a principled trade-off between the entropy of the community size distribution and the number of communities, corresponding to scales of high structural heterogeneity. This criterion applies to dendrograms produced by a wide range of clustering algorithms and distance metrics, including modularity-based and correlation-based methods. We evaluate HCE on synthetic benchmarks with varying degrees of hierarchy, size imbalance, and noise, including LFR and both symmetric and asymmetric multiscale models, and show that it consistently identifies partitions closely aligned with ground truth. Applied to real-world networks in social and neuroscience systems, HCE reveals interpretable modular hierarchies that align with known structural and functional organizations. As a scalable and principled method, HCE offers a general, domain-independent approach to hierarchical community detection with potential applications across biological, social, and technological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04034v1</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jorge Martinez Armas</dc:creator>
    </item>
    <item>
      <title>Universal Patterns in the Blockchain: Analysis of EOAs and Smart Contracts in ERC20 Token Networks</title>
      <link>https://arxiv.org/abs/2508.04671</link>
      <description>arXiv:2508.04671v1 Announce Type: cross 
Abstract: Scaling laws offer a powerful lens to understand complex transactional behaviors in decentralized systems. This study reveals distinctive statistical signatures in the transactional dynamics of ERC20 tokens on the Ethereum blockchain by examining over 44 million token transfers between July 2017 and March 2018 (9-month period). Transactions are categorized into four types: EOA--EOA, EOA--SC, SC-EOA, and SC-SC based on whether the interacting addresses are Externally Owned Accounts (EOAs) or Smart Contracts (SCs), and analyzed across three equal periods (each of 3 months). To identify universal statistical patterns, we investigate the presence of two canonical scaling laws: power law distributions and temporal Taylor's law (TL). EOA-driven transactions exhibit consistent statistical behavior, including a near-linear relationship between trade volume and unique partners with stable power law exponents ($\gamma \approx 2.3$), and adherence to TL with scaling coefficients ($\beta \approx 2.3$). In contrast, interactions involving SCs, especially SC-SC, exhibit sublinear scaling, unstable power-law exponents, and significantly fluctuating Taylor coefficients (variation in $\beta$ to be $\Delta\beta = 0.51$). Moreover, SC-driven activity displays heavier-tailed distributions ($\gamma &lt; 2$), indicating bursty and algorithm-driven activity. These findings reveal the characteristic differences between human-controlled and automated transaction behaviors in blockchain ecosystems. By uncovering universal scaling behaviors through the integration of complex systems theory and blockchain data analytics, this work provides a principled framework for understanding the underlying mechanisms of decentralized financial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04671v1</guid>
      <category>q-fin.ST</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kundan Mukhia, SR Luwang, Md. Nurujjaman, Tanujit Chakraborty, Suman Saha, Chittaranjan Hens</dc:creator>
    </item>
    <item>
      <title>Don't Trust A Single Gerrymandering Metric</title>
      <link>https://arxiv.org/abs/2409.17186</link>
      <description>arXiv:2409.17186v2 Announce Type: replace 
Abstract: In recent years, in an effort to promote fairness in the election process, a wide variety of techniques and metrics have been proposed to determine whether a map is a partisan gerrymander. The most accessible measures, requiring easily obtained data, are metrics such as the Mean-Median Difference, Efficiency Gap, Declination, and GEO metric. But for most of these metrics, researchers have struggled to describe, given no additional information, how a value of that metric on a single map indicates the presence or absence of gerrymandering.
  Our main result is that each of these metrics is gameable when used as a single, isolated quantity to detect gerrymandering (or the lack thereof). That is, for each of the four metrics, we can find district plans for a given state with an extremely large number of Democratic-won (or Republican-won) districts while the metric value of that plan falls within a reasonable, predetermined bound. We do this by using a hill-climbing method to generate district plans that are constrained by the bounds on the metric but also maximize or nearly maximize the number of districts won by a party.
  In addition, extreme values of the Mean-Median Difference do not necessarily correspond to maps with an extreme number of districts won. Thus, the Mean- Median Difference metric is particularly misleading, as it cannot distinguish more extreme maps from less extreme maps. The other metrics are more nuanced, but when assessed on an ensemble, none perform substantially differently from simply measuring number of districts won by a fixed party.
  One clear consequence of these results is that they demonstrate the folly of specifying a priori bounds on a metric that a redistricting commission must meet in order to avoid gerrymandering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17186v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Ratliff, Stephanie Somersille, Ellen Veomett</dc:creator>
    </item>
    <item>
      <title>Dynamic models of gentrification</title>
      <link>https://arxiv.org/abs/2410.18004</link>
      <description>arXiv:2410.18004v3 Announce Type: replace 
Abstract: The phenomenon of gentrification of an urban area is characterized by the displacement of lower-income residents due to rising living costs and an influx of wealthier individuals. This study presents an agent-based model that simulates urban gentrification through the relocation of three income groups -- low, middle, and high -- driven by living costs. The model incorporates economic and sociological theories to generate realistic neighborhood transition patterns. We introduce a temporal network-based measure to track the outflow of low-income residents and the inflow of middle- and high-income residents over time. Our experiments reveal that high-income residents trigger gentrification and that our network-based measure consistently detects gentrification patterns earlier than traditional count-based methods, potentially serving as an early detection tool in real-world scenarios. Moreover, the analysis also highlights how city density promotes gentrification. This framework offers valuable insights for understanding gentrification dynamics and informing urban planning and policy decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18004v3</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1142/S0219525925400065</arxiv:DOI>
      <dc:creator>Giovanni Mauro, Nicola Pedreschi, Renaud Lambiotte, Luca Pappalardo</dc:creator>
    </item>
    <item>
      <title>Cost Functions in Economic Complexity</title>
      <link>https://arxiv.org/abs/2507.04054</link>
      <description>arXiv:2507.04054v2 Announce Type: replace 
Abstract: Economic complexity algorithms aim to uncover the hidden capabilities that drive economic systems. Here, we present a fundamental reinterpretation of two of these algorithms, the Economic Complexity Index (ECI) and the Economic Fitness and Complexity (EFC), by reformulating them as optimization problems that minimize specific cost functions. We show that ECI computation is equivalent to finding eigenvectors of the network's transition matrix by minimizing the quadratic form associated with the network's Laplacian, thus revealing its limitations in capturing the diversification of countries. For EFC, we derive a novel cost function that exploits the algorithm's intrinsic logarithmic structure and clarifies the role of its regularization parameter. Additionally, we establish the uniqueness of its solution, providing theoretical foundations for its application. This optimization-based reformulation bridges economic complexity and established frameworks in spectral theory, network science, and optimization. The theoretical insights translate into practical computational advantages: we introduce a conservative, gradient-based update rule that substantially accelerates algorithmic convergence, with potential implications for a broader class of algorithms, including the Sinkhorn-Knopp method. Beyond advancing our theoretical understanding of economic complexity indicators, this work opens new pathways for algorithmic improvements and extends applicability to general network structures beyond traditional bipartite economic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04054v2</guid>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandro Bellina, Paolo Butt\`a, Vito D. P. Servedio</dc:creator>
    </item>
  </channel>
</rss>
