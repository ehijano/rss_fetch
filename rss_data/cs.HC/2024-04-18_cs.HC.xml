<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2024 04:01:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Human-Algorithm Collaborative Bayesian Optimization for Engineering Systems</title>
      <link>https://arxiv.org/abs/2404.10949</link>
      <description>arXiv:2404.10949v1 Announce Type: new 
Abstract: Bayesian optimization has been successfully applied throughout Chemical Engineering for the optimization of functions that are expensive-to-evaluate, or where gradients are not easily obtainable. However, domain experts often possess valuable physical insights that are overlooked in fully automated decision-making approaches, necessitating the inclusion of human input. In this article we re-introduce the human back into the data-driven decision making loop by outlining an approach for collaborative Bayesian optimization. Our methodology exploits the hypothesis that humans are more efficient at making discrete choices rather than continuous ones and enables experts to influence critical early decisions. We apply high-throughput (batch) Bayesian optimization alongside discrete decision theory to enable domain experts to influence the selection of experiments. At every iteration we apply a multi-objective approach that results in a set of alternate solutions that have both high utility and are reasonably distinct. The expert then selects the desired solution for evaluation from this set, allowing for the inclusion of expert knowledge and improving accountability, whilst maintaining the advantages of Bayesian optimization. We demonstrate our approach across a number of applied and numerical case studies including bioprocess optimization and reactor geometry design, demonstrating that even in the case of an uninformed practitioner our algorithm recovers the regret of standard Bayesian optimization. Through the inclusion of continuous expert opinion, our approach enables faster convergence, and improved accountability for Bayesian optimization in engineering systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10949v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Savage, Ehecatl Antonio del Rio Chanona</dc:creator>
    </item>
    <item>
      <title>Tinker or Transfer? A Tale of Two Techniques in Teaching Visualization</title>
      <link>https://arxiv.org/abs/2404.10967</link>
      <description>arXiv:2404.10967v1 Announce Type: new 
Abstract: In education there exists a tension between two modes of learning: traditional lecture-based instruction and more tinkering-based creative learning. In this paper, we outline our efforts as two Ph.D. students (who are skilled in visualization but are not, importantly, professionally trained visualization experts) to implement creative learning activities in an information visualization course in our home department. We describe our motivation for doing so, and how what began out of necessity turned into an endeavor whose utility we strongly believe in. In implementing these activities, we received largely positive reviews from students, along with constructive feedback which helped us iteratively improve the activities. Finally, we also detail our future plans for turning this work into a formal design inquiry with students to build a new class centered entirely around creative learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10967v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Adam Hyland, Murtaza Ali</dc:creator>
    </item>
    <item>
      <title>Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions</title>
      <link>https://arxiv.org/abs/2404.11023</link>
      <description>arXiv:2404.11023v1 Announce Type: new 
Abstract: Building socially-intelligent AI agents (Social-AI) is a multidisciplinary, multimodal research goal that involves creating agents that can sense, perceive, reason about, learn from, and respond to affect, behavior, and cognition of other agents (human or artificial). Progress towards Social-AI has accelerated in the past decade across several computing communities, including natural language processing, machine learning, robotics, human-machine interaction, computer vision, and speech. Natural language processing, in particular, has been prominent in Social-AI research, as language plays a key role in constructing the social world. In this position paper, we identify a set of underlying technical challenges and open questions for researchers across computing communities to advance Social-AI. We anchor our discussion in the context of social intelligence concepts and prior progress in Social-AI research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11023v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leena Mathur, Paul Pu Liang, Louis-Philippe Morency</dc:creator>
    </item>
    <item>
      <title>Large Language Models Meet User Interfaces: The Case of Provisioning Feedback</title>
      <link>https://arxiv.org/abs/2404.11072</link>
      <description>arXiv:2404.11072v1 Announce Type: new 
Abstract: Incorporating Generative AI (GenAI) and Large Language Models (LLMs) in education can enhance teaching efficiency and enrich student learning. Current LLM usage involves conversational user interfaces (CUIs) for tasks like generating materials or providing feedback. However, this presents challenges including the need for educator expertise in AI and CUIs, ethical concerns with high-stakes decisions, and privacy risks. CUIs also struggle with complex tasks. To address these, we propose transitioning from CUIs to user-friendly applications leveraging LLMs via API calls. We present a framework for ethically incorporating GenAI into educational tools and demonstrate its application in our tool, Feedback Copilot, which provides personalized feedback on student assignments. Our evaluation shows the effectiveness of this approach, with implications for GenAI researchers, educators, and technologists. This work charts a course for the future of GenAI in education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11072v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stanislav Pozdniakov, Jonathan Brazil, Solmaz Abdi, Aneesha Bakharia, Shazia Sadiq, Dragan Gasevic, Paul Denny, Hassan Khosravi</dc:creator>
    </item>
    <item>
      <title>Do you need a DAO?</title>
      <link>https://arxiv.org/abs/2404.11076</link>
      <description>arXiv:2404.11076v1 Announce Type: new 
Abstract: Decentralized Autonomous Organizations (DAOs) have seen exponential growth and interest due to their potential to redefine organizational structure and governance. Despite this, there is a discrepancy between the ideals of autonomy and decentralization and the actual experiences of DAO stakeholders. The Information Systems (IS) literature has yet to fully explore whether DAOs are the optimal organizational choice. Addressing this gap, our research asks, "Is a DAO suitable for your organizational needs?" We derive a gated decision-making framework through a thematic review of the academic and grey literature on DAOs. Through five scenarios, the framework critically emphasizes the gaps between DAOs' theoretical capabilities and practical challenges. Our findings contribute to the IS discourse on blockchain technologies, with some ancillary contributions to the IS literature on organizational management and practitioner literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11076v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The European Conference on Information Systems (ECIS) 2024</arxiv:journal_reference>
      <dc:creator>Henrik Axelsen, Johannes Rude Jensen, Omri Ross</dc:creator>
    </item>
    <item>
      <title>Unlocking Memories with AI: Exploring the Role of AI-Generated Cues in Personal Reminiscing</title>
      <link>https://arxiv.org/abs/2404.11227</link>
      <description>arXiv:2404.11227v1 Announce Type: new 
Abstract: While technology-mediated reminiscing has been studied for decades, generating relevant cues to trigger personal reminiscing remains challenging. The potential of AI in generating relevant content across various domains has been recently recognized, yet its use in facilitating reminiscing is still less explored. This work aims to explore the use of AI in supporting the recall of personal memories associated with significant objects at home. We designed Treasurefinder, a device powered by a large language model (LLM) that generates open-ended questions based on stories stored in NFC-tagged physical objects or cards. We conducted an exploratory study with 12 participants, grouped in pairs, to observe reminiscing behaviors when using Treasurefinder. The results showed the AI-generated questions 1) supported individuals to recall the past, 2) provided new insights about the other person, and 3) encouraged reflection. Notably, the device facilitated active memory retrieval related to cherished objects that are often overlooked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11227v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613905.3650979</arxiv:DOI>
      <dc:creator>Jun Li Jeung, Janet Yi-Ching Huang</dc:creator>
    </item>
    <item>
      <title>PartiPlay: A Participatory Game Design Kit for Neurodiverse Classrooms</title>
      <link>https://arxiv.org/abs/2404.11234</link>
      <description>arXiv:2404.11234v1 Announce Type: new 
Abstract: Play is a central aspect of childhood development, with games as a vital tool to promote it. However, neurodivergent children, especially those in neurodiverse environments, are underserved by HCI games research. Most existing work takes on a top-down approach, disregarding neurodivergent interest for the majority of the design process. Co-design is often proposed as a tool to create truly accessible and inclusive gaming experiences. Nevertheless, co-designing with neurodivergent children within neurodiverse groups brings about unique challenges, such as different communication styles, sensory needs and preferences. Building upon recommendations from prior work in neurodivergent, mixed-ability, and child-led co-design, we propose a concrete participatory game design kit for neurodiverse classrooms: PartiPlay. Moreover, we present preliminary findings from an in-the-wild experiment with the said kit, showcasing its ability to create an inclusive co-design process for neurodiverse groups of children. We aim to provide actionable steps for future participatory design research with neurodiverse children.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11234v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patricia Piedade, Isabel Neto, Ana Pires, Rui Prada, Hugo Nicolau</dc:creator>
    </item>
    <item>
      <title>Ethical Concerns when Working with Mixed-Ability Groups of Children</title>
      <link>https://arxiv.org/abs/2404.11248</link>
      <description>arXiv:2404.11248v1 Announce Type: new 
Abstract: Accessibility research has gained traction, yet ethical gaps persist in the inclusion of individuals with disabilities, especially children. Inclusive research practices are essential to ensure research and design solutions cater to the needs of all individuals, regardless of their abilities. Working with children with disabilities in Human-Computer Interaction and Human-Robot Interaction presents a unique set of ethical dilemmas. These young participants often require additional care, support, and accommodations, which can fall off researchers' resources or expertise. The lack of clear guidance on navigating these challenges further aggravates the problem. To provide a base and address this issue, we adopt a critical reflective approach, evaluating our impact by analyzing two case studies involving children with disabilities in HCI/HRI research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11248v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patricia Piedade, Ana Henriques, Filipa Rocha, Isabel Neto, Hugo Nicolau</dc:creator>
    </item>
    <item>
      <title>"That's our game!" : Reflections on co-designing a robotic game with neurodiverse children</title>
      <link>https://arxiv.org/abs/2404.11252</link>
      <description>arXiv:2404.11252v1 Announce Type: new 
Abstract: Many neurodivergent (ND) children are integrated into mainstream schools alongside their neurotypical (NT) peers. However, they often face social exclusion, which may have lifelong effects. Inclusive play activities can be a strong driver of inclusion. Unfortunately, games designed for the specific needs of neurodiverse groups, those that include neurodivergent and neurotypical individuals, are scarce. Given the potential of robots as engaging devices, we led a 6-month co-design process to build an inclusive and entertaining robotic game for neurodiverse classrooms. We first interviewed neurodivergent adults and educators to identify the barriers and facilitators for including neurodivergent children in mainstream classrooms. Then, we conducted five co-design sessions, engaging four neurodiverse classrooms with 81 children (19 neurodivergent). We present a reflection on our co-design process and the resulting robotic game through the lens of Self-Determination Theory, discussing how our methodology supported the intrinsic motivations of neurodivergent children.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11252v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patricia Piedade, Isabel Neto, Ana Pires, Rui Prada, Hugo Nicolau</dc:creator>
    </item>
    <item>
      <title>AR for Sexual Violence: Maintaining Ethical Balance While Enhancing Empathy</title>
      <link>https://arxiv.org/abs/2404.11305</link>
      <description>arXiv:2404.11305v1 Announce Type: new 
Abstract: This study showcases an augmented reality (AR) experience designed to promote gender justice and increase awareness of sexual violence in Taiwan. By leveraging AR, this project overcomes the limitations of offline exhibitions on social issues by motivating the public to participate and enhancing their willingness to delve into the topic. The discussion explores how direct exposure to sexual violence can induce negative emotions and secondary trauma among users. It also suggests strategies for using AR to alleviate such issues, particularly by avoiding simulations of actual incidents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11305v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chunwei Lin</dc:creator>
    </item>
    <item>
      <title>Characterizing and modeling harms from interactions with design patterns in AI interfaces</title>
      <link>https://arxiv.org/abs/2404.11370</link>
      <description>arXiv:2404.11370v1 Announce Type: new 
Abstract: The proliferation of applications using artificial intelligence (AI) systems has led to a growing number of users interacting with these systems through sophisticated interfaces. Human-computer interaction research has long shown that interfaces shape both user behavior and user perception of technical capabilities and risks. Yet, practitioners and researchers evaluating the social and ethical risks of AI systems tend to overlook the impact of anthropomorphic, deceptive, and immersive interfaces on human-AI interactions. Here, we argue that design features of interfaces with adaptive AI systems can have cascading impacts, driven by feedback loops, which extend beyond those previously considered. We first conduct a scoping review of AI interface designs and their negative impact to extract salient themes of potentially harmful design patterns in AI interfaces. Then, we propose Design-Enhanced Control of AI systems (DECAI), a conceptual model to structure and facilitate impact assessments of AI interface designs. DECAI draws on principles from control systems theory -- a theory for the analysis and design of dynamic physical systems -- to dissect the role of the interface in human-AI systems. Through two case studies on recommendation systems and conversational language model systems, we show how DECAI can be used to evaluate AI interface designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11370v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lujain Ibrahim, Luc Rocher, Ana Valdivia</dc:creator>
    </item>
    <item>
      <title>Designing Touchscreen Menu Interfaces for In-Vehicle Infotainment Systems: the Effect of Depth and Breadth Trade-off and Task Types on Visual-Manual Distraction</title>
      <link>https://arxiv.org/abs/2404.11469</link>
      <description>arXiv:2404.11469v1 Announce Type: new 
Abstract: Multitasking with a touch screen user-interface while driving is known to impact negatively driving performance and safety. Literature shows that list scrolling interfaces generate more visual-manual distraction than structured menus and sequential navigation. Depth and breadth trade-offs for structured navigation have been studied. However, little is known on how secondary task characteristics interact with those trade-offs. In this study, we make the hypothesis that both menu's depth and task complexity interact in generating visual-manual distraction. Using a driving simulation setup, we collected telemetry and eye-tracking data to evaluate driving performance. Participants were multitasking with a mobile app, presenting a range of eight depth and breadth trade-offs under three types of secondary tasks, involving different cognitive operations (Systematic reading, Search for an item, Memorize items' state). The results confirm our hypothesis. Systematic interaction with menu items generated a visual demand that increased with menu's depth, while visual demand reach an optimum for Search and Memory tasks. We discuss implications for design: In a multitasking context, display design effectiveness must be assessed while considering menu's layout but also cognitive processes involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11469v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louveton Nicolas, McCall Rod, Engel Thomas</dc:creator>
    </item>
    <item>
      <title>Interaction Techniques for Exploratory Data Visualization on Mobile Devices</title>
      <link>https://arxiv.org/abs/2404.11602</link>
      <description>arXiv:2404.11602v1 Announce Type: new 
Abstract: The ubiquity and on-the-go availability of mobile devices makes them central to many tasks such as interpersonal communication and media consumption. However, despite the potential of mobile devices for on-demand exploratory data visualization, existing mobile interactions are difficult, often using highly custom interactions, complex gestures, or multi-modal input. We synthesize limitations from the literature and outline four motivating principles for improved mobile interaction: leverage ubiquitous modalities, prioritize discoverability, enable rapid in-context data exploration, and promote graceful recovery. We then contribute thirteen interaction candidates and conduct a formative study with twelve participants who experienced our interactions in a testbed prototype. Based on these interviews, we discuss design considerations and tradeoffs from four main themes: precise and rapid inspection, focused navigation, single-touch and fixed orientation interaction, and judicious use of motion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11602v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke S. Snyder, Ryan A. Rossi, Eunyee Koh, Jeffrey Heer, Jane Hoffswell</dc:creator>
    </item>
    <item>
      <title>Exploring Augmentation and Cognitive Strategies for AI based Synthetic Personae</title>
      <link>https://arxiv.org/abs/2404.10890</link>
      <description>arXiv:2404.10890v1 Announce Type: cross 
Abstract: Large language models (LLMs) hold potential for innovative HCI research, including the creation of synthetic personae. However, their black-box nature and propensity for hallucinations pose challenges. To address these limitations, this position paper advocates for using LLMs as data augmentation systems rather than zero-shot generators. We further propose the development of robust cognitive and memory frameworks to guide LLM responses. Initial explorations suggest that data enrichment, episodic memory, and self-reflection techniques can improve the reliability of synthetic personae and open up new avenues for HCI research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10890v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Arias Gonzalez, Steve DiPaola</dc:creator>
    </item>
    <item>
      <title>Towards a Research Community in Interpretable Reinforcement Learning: the InterpPol Workshop</title>
      <link>https://arxiv.org/abs/2404.10906</link>
      <description>arXiv:2404.10906v1 Announce Type: cross 
Abstract: Embracing the pursuit of intrinsically explainable reinforcement learning raises crucial questions: what distinguishes explainability from interpretability? Should explainable and interpretable agents be developed outside of domains where transparency is imperative? What advantages do interpretable policies offer over neural networks? How can we rigorously define and measure interpretability in policies, without user studies? What reinforcement learning paradigms,are the most suited to develop interpretable agents? Can Markov Decision Processes integrate interpretable state representations? In addition to motivate an Interpretable RL community centered around the aforementioned questions, we propose the first venue dedicated to Interpretable RL: the InterpPol Workshop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10906v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.SC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hector Kohler, Quentin Delfosse, Paul Festor, Philippe Preux</dc:creator>
    </item>
    <item>
      <title>Remote Breathing Monitoring Using LiDAR Technology</title>
      <link>https://arxiv.org/abs/2404.10970</link>
      <description>arXiv:2404.10970v1 Announce Type: cross 
Abstract: Breathing monitoring is crucial in healthcare for early detection of health issues, but traditional methods face challenges like invasiveness, privacy concerns, and limited applicability in daily settings. This paper introduces light detection and ranging (LiDAR) sensors as a remote, privacy-respecting alternative for monitoring breathing metrics, including inhalation/exhalation patterns, respiratory rates, breath depth, and detecting breathlessness. We highlight LiDARs ability to function across various postures, presenting empirical evidence of its accuracy and reliability. Our findings position LiDAR as an innovative solution in breathing monitoring, offering significant advantages over conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10970v1</guid>
      <category>eess.IV</category>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar Rinchi, Ahmad Alsharoa, Denise A. Baker</dc:creator>
    </item>
    <item>
      <title>[DC] bRight XR: How to train designers to keep on the bright side?</title>
      <link>https://arxiv.org/abs/2404.11142</link>
      <description>arXiv:2404.11142v1 Announce Type: cross 
Abstract: This research project aims to promote ethical principles among designers engaged in adaptive-XR by providing tools for self-assessment. We introduce a Design-Based Research (DBR) methodology to build bRight-XR, a framework including a heuristic evaluation matrix and based on learning theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11142v1</guid>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romain Rouyer (UPCit\'e, IDMC, PErSEUs), David Bourguignon (PErSEUs), St\'ephanie Fleck (PErSEUs)</dc:creator>
    </item>
    <item>
      <title>Using Game Engines and Machine Learning to Create Synthetic Satellite Imagery for a Tabletop Verification Exercise</title>
      <link>https://arxiv.org/abs/2404.11461</link>
      <description>arXiv:2404.11461v1 Announce Type: cross 
Abstract: Satellite imagery is regarded as a great opportunity for citizen-based monitoring of activities of interest. Relevant imagery may however not be available at sufficiently high resolution, quality, or cadence -- let alone be uniformly accessible to open-source analysts. This limits an assessment of the true long-term potential of citizen-based monitoring of nuclear activities using publicly available satellite imagery. In this article, we demonstrate how modern game engines combined with advanced machine-learning techniques can be used to generate synthetic imagery of sites of interest with the ability to choose relevant parameters upon request; these include time of day, cloud cover, season, or level of activity onsite. At the same time, resolution and off-nadir angle can be adjusted to simulate different characteristics of the satellite. While there are several possible use-cases for synthetic imagery, here we focus on its usefulness to support tabletop exercises in which simple monitoring scenarios can be examined to better understand verification capabilities enabled by new satellite constellations and very short revisit times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11461v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Johannes Hoster, Sara Al-Sayed, Felix Biessmann, Alexander Glaser, Kristian Hildebrand, Igor Moric, Tuong Vy Nguyen</dc:creator>
    </item>
    <item>
      <title>Frameworking for a Community-led Feminist Ethics</title>
      <link>https://arxiv.org/abs/2404.11514</link>
      <description>arXiv:2404.11514v1 Announce Type: cross 
Abstract: This paper introduces a relational perspective on ethics within the context of Feminist Digital Civics and community-led design. Ethics work in HCI has primarily focused on prescriptive machine ethics and bioethics principles rather than people. In response, we advocate for a community-led, processual approach to ethics, acknowledging power dynamics and local contexts. We thus propose a multidimensional adaptive model for ethics in HCI design, integrating an intersectional feminist ethical lens. This framework embraces feminist epistemologies, methods, and methodologies, fostering a reflexive practice. By weaving together situated knowledges, standpoint theory, intersectionality, participatory methods, and care ethics, our approach offers a holistic foundation for ethics in HCI, aiming to advance community-led practices and enrich the discourse surrounding ethics within this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11514v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ana O Henriques, Hugo Nicolau, Kyle Montague</dc:creator>
    </item>
    <item>
      <title>Embedding Privacy in Computational Social Science and Artificial Intelligence Research</title>
      <link>https://arxiv.org/abs/2404.11515</link>
      <description>arXiv:2404.11515v1 Announce Type: cross 
Abstract: Privacy is a human right. It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them. Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights. The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals - especially vulnerable groups - and society. We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start. This article contributes to the field by discussing the role of privacy and the primary issues that researchers working in CSS, AI, data science and related domains are likely to face. It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11515v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keenan Jones, Fatima Zahrah, Jason R. C. Nurse</dc:creator>
    </item>
    <item>
      <title>Signal vs Noise in Eye-tracking Data: Biometric Implications and Identity Information Across Frequencies</title>
      <link>https://arxiv.org/abs/2305.04413</link>
      <description>arXiv:2305.04413v2 Announce Type: replace 
Abstract: Prior research states that frequencies below 75 Hz in eye-tracking data represent the primary eye movement termed ``signal'' while those above 75 Hz are deemed ``noise''. This study examines the biometric significance of this signal-noise distinction and its privacy implications. There are important individual differences in a person's eye movement, which lead to reliable biometric performance in the ``signal'' part. Despite minimal eye-movement information in the ``noise'' recordings, there might be significant individual differences. Our results confirm the ``signal'' predominantly contains identity-specific information, yet the ``noise'' also possesses unexpected identity-specific data. This consistency holds for both short-(approx. 20 min) and long-term (approx. 1 year) biometric evaluations. Understanding the location of identity data within the eye movement spectrum is essential for privacy preservation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.04413v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3649902.3653353</arxiv:DOI>
      <dc:creator>Mehedi H. Raju, Lee Friedman, Dillon Lohr, Oleg Komogortsev</dc:creator>
    </item>
    <item>
      <title>GOLF: Goal-Oriented Long-term liFe tasks supported by human-AI collaboration</title>
      <link>https://arxiv.org/abs/2403.17089</link>
      <description>arXiv:2403.17089v2 Announce Type: replace 
Abstract: The advent of ChatGPT and similar large language models (LLMs) has revolutionized the human-AI interaction and information-seeking process. Leveraging LLMs as an alternative to search engines, users can now access summarized information tailored to their queries, significantly reducing the cognitive load associated with navigating vast information resources. This shift underscores the potential of LLMs in redefining information access paradigms. Drawing on the foundation of task-focused information retrieval and LLMs' task planning ability, this research extends the scope of LLM capabilities beyond routine task automation to support users in navigating long-term and significant life tasks. It introduces the GOLF framework (Goal-Oriented Long-term liFe tasks), which focuses on enhancing LLMs' ability to assist in significant life decisions through goal orientation and long-term planning. The methodology encompasses a comprehensive simulation study to test the framework's efficacy, followed by model and human evaluations to develop a dataset benchmark for long-term life tasks, and experiments across different models and settings. By shifting the focus from short-term tasks to the broader spectrum of long-term life goals, this research underscores the transformative potential of LLMs in enhancing human decision-making processes and task management, marking a significant step forward in the evolution of human-AI collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17089v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3626772.3657655</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2024)</arxiv:journal_reference>
      <dc:creator>Ben Wang</dc:creator>
    </item>
    <item>
      <title>Revisiting Categorical Color Perception in Scatterplots: Sequential, Diverging, and Categorical Palettes</title>
      <link>https://arxiv.org/abs/2404.03787</link>
      <description>arXiv:2404.03787v2 Announce Type: replace 
Abstract: Existing guidelines for categorical color selection are heuristic, often grounded in intuition rather than empirical studies of readers' abilities. While design conventions recommend palettes maximize hue differences, more recent exploratory findings indicate other factors, such as lightness, may play a role in effective categorical palette design. We conducted a crowdsourced experiment on mean value judgments in multi-class scatterplots using five color palette families--single-hue sequential, multi-hue sequential, perceptually-uniform multi-hue sequential, diverging, and multi-hue categorical--that differ in how they manipulate hue and lightness. Participants estimated relative mean positions in scatterplots containing 2 to 10 categories using 20 colormaps. Our results confirm heuristic guidance that hue-based categorical palettes are most effective. However, they also provide additional evidence that scalable categorical encoding relies on more than hue variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03787v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>In Proceedings of the 26th EG/VGTC Conference on Visualization (EuroVis 2024), May 27-31, 2024, Odense, Denmark</arxiv:journal_reference>
      <dc:creator>Chin Tseng, Arran Zeyu Wang, Ghulam Jilani Quadri, Danielle Albers Szafir</dc:creator>
    </item>
    <item>
      <title>Shaping Realities: Enhancing 3D Generative AI with Fabrication Constraints</title>
      <link>https://arxiv.org/abs/2404.10142</link>
      <description>arXiv:2404.10142v2 Announce Type: replace 
Abstract: Generative AI tools are becoming more prevalent in 3D modeling, enabling users to manipulate or create new models with text or images as inputs. This makes it easier for users to rapidly customize and iterate on their 3D designs and explore new creative ideas. These methods focus on the aesthetic quality of the 3D models, refining them to look similar to the prompts provided by the user. However, when creating 3D models intended for fabrication, designers need to trade-off the aesthetic qualities of a 3D model with their intended physical properties. To be functional post-fabrication, 3D models have to satisfy structural constraints informed by physical principles. Currently, such requirements are not enforced by generative AI tools. This leads to the development of aesthetically appealing, but potentially non-functional 3D geometry, that would be hard to fabricate and use in the real world. This workshop paper highlights the limitations of generative AI tools in translating digital creations into the physical world and proposes new augmentations to generative AI tools for creating physically viable 3D models. We advocate for the development of tools that manipulate or generate 3D models by considering not only the aesthetic appearance but also using physical properties as constraints. This exploration seeks to bridge the gap between digital creativity and real-world applicability, extending the creative potential of generative AI into the tangible domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10142v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faraz Faruqi, Yingtao Tian, Vrushank Phadnis, Varun Jampani, Stefanie Mueller</dc:creator>
    </item>
    <item>
      <title>Explainable Multimodal Emotion Reasoning: a Promising Way to Open-set Emotion Recognition</title>
      <link>https://arxiv.org/abs/2306.15401</link>
      <description>arXiv:2306.15401v4 Announce Type: replace-cross 
Abstract: Multimodal emotion recognition is an active research topic in artificial intelligence. Its main goal is to integrate multi-modalities to identify human emotional states. Current works generally assume accurate emotion labels for benchmark datasets and focus on developing more effective architectures. However, emotions have inherent ambiguity and subjectivity. To obtain more reliable labels, existing datasets usually restrict the label space to some basic categories, then hire multiple annotators and use majority voting to select the most likely label. However, this process may cause some correct but non-candidate or non-majority labels to be ignored. To improve reliability without ignoring subtle emotions, we propose a new task called ``\textbf{Explainable Multimodal Emotion Reasoning (EMER)}''. In contrast to traditional tasks that focus on predicting emotions, EMER takes a step further by providing explanations for these predictions. Through this task, we can extract more reliable labels since each label has a certain basis. Meanwhile, we use LLMs to disambiguate unimodal descriptions and generate more complete multimodal EMER descriptions. From them, we can extract subtle labels, providing a promising approach for open-set emotion recognition. This paper presents our initial efforts, where we introduce a new dataset, establish baselines, and define evaluation metrics. In addition, EMER can also be used as a benchmark dataset to evaluate the audio-video-text understanding capabilities of multimodal LLMs. To facilitate further research, we will make the code and data available at: https://github.com/zeroQiaoba/AffectGPT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15401v4</guid>
      <category>cs.MM</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Lian, Licai Sun, Haiyang Sun, Hao Gu, Zhuofan Wen, Siyuan Zhang, Shun Chen, Mingyu Xu, Ke Xu, Lan Chen, Jiangyan Yi, Bin Liu, Jianhua Tao</dc:creator>
    </item>
    <item>
      <title>PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment</title>
      <link>https://arxiv.org/abs/2402.08702</link>
      <description>arXiv:2402.08702v2 Announce Type: replace-cross 
Abstract: Prompt optimization aims to find the best prompt to a large language model (LLM) for a given task. LLMs have been successfully used to help find and improve prompt candidates for single-step tasks. However, realistic tasks for agents are multi-step and introduce new challenges: (1) Prompt content is likely to be more extensive and complex, making it more difficult for LLMs to analyze errors, (2) the impact of an individual step is difficult to evaluate, and (3) different people may have varied preferences about task execution. While humans struggle to optimize prompts, they are good at providing feedback about LLM outputs; we therefore introduce a new LLM-driven discrete prompt optimization framework that incorporates human-designed feedback rules to automatically offer direct suggestions for improvement. We also use an extra learned heuristic model that predicts prompt performance to efficiently sample from prompt candidates. This approach significantly outperforms both human-engineered prompts and several other prompt optimization methods across 11 representative multi-step tasks (an average 10.6%-29.3% improvement to current best methods on five LLMs respectively). We further show that the score function for tasks can be modified to better align with individual preferences. We believe our work can serve as a benchmark for automatic prompt optimization for LLM-driven multi-step tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08702v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>An Exploratory Study on Upper-Level Computing Students' Use of Large Language Models as Tools in a Semester-Long Project</title>
      <link>https://arxiv.org/abs/2403.18679</link>
      <description>arXiv:2403.18679v2 Announce Type: replace-cross 
Abstract: Background: Large Language Models (LLMs) such as ChatGPT and CoPilot are influencing software engineering practice. Software engineering educators must teach future software engineers how to use such tools well. As of yet, there have been few studies that report on the use of LLMs in the classroom. It is, therefore, important to evaluate students' perception of LLMs and possible ways of adapting the computing curriculum to these shifting paradigms.
  Purpose: The purpose of this study is to explore computing students' experiences and approaches to using LLMs during a semester-long software engineering project.
  Design/Method: We collected data from a senior-level software engineering course at Purdue University. This course uses a project-based learning (PBL) design. The students used LLMs such as ChatGPT and Copilot in their projects. A sample of these student teams were interviewed to understand (1) how they used LLMs in their projects; and (2) whether and how their perspectives on LLMs changed over the course of the semester. We analyzed the data to identify themes related to students' usage patterns and learning outcomes.
  Results/Discussion: When computing students utilize LLMs within a project, their use cases cover both technical and professional applications. In addition, these students perceive LLMs to be efficient tools in obtaining information and completion of tasks. However, there were concerns about the responsible use of LLMs without being detrimental to their own learning outcomes. Based on our findings, we recommend future research to investigate the usage of LLM's in lower-level computer engineering courses to understand whether and how LLMs can be integrated as a learning aid without hurting the learning outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18679v2</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Arie Tanay, Lexy Arinze, Siddhant S. Joshi, Kirsten A. Davis, James C. Davis</dc:creator>
    </item>
    <item>
      <title>Scaling Instructable Agents Across Many Simulated Worlds</title>
      <link>https://arxiv.org/abs/2404.10179</link>
      <description>arXiv:2404.10179v2 Announce Type: replace-cross 
Abstract: Building embodied AI systems that can follow arbitrary language instructions in any 3D environment is a key challenge for creating general AI. Accomplishing this goal requires learning to ground language in perception and embodied actions, in order to accomplish complex tasks. The Scalable, Instructable, Multiworld Agent (SIMA) project tackles this by training agents to follow free-form instructions across a diverse range of virtual 3D environments, including curated research environments as well as open-ended, commercial video games. Our goal is to develop an instructable agent that can accomplish anything a human can do in any simulated 3D environment. Our approach focuses on language-driven generality while imposing minimal assumptions. Our agents interact with environments in real-time using a generic, human-like interface: the inputs are image observations and language instructions and the outputs are keyboard-and-mouse actions. This general approach is challenging, but it allows agents to ground language across many visually complex and semantically rich environments while also allowing us to readily run agents in new environments. In this paper we describe our motivation and goal, the initial progress we have made, and promising preliminary results on several diverse research environments and a variety of commercial video games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10179v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> SIMA Team, Maria Abi Raad, Arun Ahuja, Catarina Barros, Frederic Besse, Andrew Bolt, Adrian Bolton, Bethanie Brownfield, Gavin Buttimore, Max Cant, Sarah Chakera, Stephanie C. Y. Chan, Jeff Clune, Adrian Collister, Vikki Copeman, Alex Cullum, Ishita Dasgupta, Dario de Cesare, Julia Di Trapani, Yani Donchev, Emma Dunleavy, Martin Engelcke, Ryan Faulkner, Frankie Garcia, Charles Gbadamosi, Zhitao Gong, Lucy Gonzales, Kshitij Gupta, Karol Gregor, Arne Olav Hallingstad, Tim Harley, Sam Haves, Felix Hill, Ed Hirst, Drew A. Hudson, Jony Hudson, Steph Hughes-Fitt, Danilo J. Rezende, Mimi Jasarevic, Laura Kampis, Rosemary Ke, Thomas Keck, Junkyung Kim, Oscar Knagg, Kavya Kopparapu, Andrew Lampinen, Shane Legg, Alexander Lerchner, Marjorie Limont, Yulan Liu, Maria Loks-Thompson, Joseph Marino, Kathryn Martin Cussons, Loic Matthey, Siobhan Mcloughlin, Piermaria Mendolicchio, Hamza Merzic, Anna Mitenkova, Alexandre Moufarek, Valeria Oliveira, Yanko Oliveira, Hannah Openshaw, Renke Pan, Aneesh Pappu, Alex Platonov, Ollie Purkiss, David Reichert, John Reid, Pierre Harvey Richemond, Tyson Roberts, Giles Ruscoe, Jaume Sanchez Elias, Tasha Sandars, Daniel P. Sawyer, Tim Scholtes, Guy Simmons, Daniel Slater, Hubert Soyer, Heiko Strathmann, Peter Stys, Allison C. Tam, Denis Teplyashin, Tayfun Terzi, Davide Vercelli, Bojan Vujatovic, Marcus Wainwright, Jane X. Wang, Zhengdong Wang, Daan Wierstra, Duncan Williams, Nathaniel Wong, Sarah York, Nick Young</dc:creator>
    </item>
    <item>
      <title>What are human values, and how do we align AI to them?</title>
      <link>https://arxiv.org/abs/2404.10636</link>
      <description>arXiv:2404.10636v2 Announce Type: replace-cross 
Abstract: There is an emerging consensus that we need to align AI systems with human values (Gabriel, 2020; Ji et al., 2024), but it remains unclear how to apply this to language models in practice. We split the problem of "aligning to human values" into three parts: first, eliciting values from people; second, reconciling those values into an alignment target for training ML models; and third, actually training the model. In this paper, we focus on the first two parts, and ask the question: what are "good" ways to synthesize diverse human inputs about values into a target for aligning language models? To answer this question, we first define a set of 6 criteria that we believe must be satisfied for an alignment target to shape model behavior in accordance with human values. We then propose a process for eliciting and reconciling values called Moral Graph Elicitation (MGE), which uses a large language model to interview participants about their values in particular contexts; our approach is inspired by the philosophy of values advanced by Taylor (1977), Chang (2004), and others. We trial MGE with a representative sample of 500 Americans, on 3 intentionally divisive prompts (e.g. advice about abortion). Our results demonstrate that MGE is promising for improving model alignment across all 6 criteria. For example, almost all participants (89.1%) felt well represented by the process, and (89%) thought the final moral graph was fair, even if their value wasn't voted as the wisest. Our process often results in "expert" values (e.g. values from women who have solicited abortion advice) rising to the top of the moral graph, without defining who is considered an expert in advance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10636v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Klingefjord, Ryan Lowe, Joe Edelman</dc:creator>
    </item>
  </channel>
</rss>
