<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Dec 2024 03:50:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>One-Hop Sub-Query Result Caches for Graph Database Systems</title>
      <link>https://arxiv.org/abs/2412.04698</link>
      <description>arXiv:2412.04698v1 Announce Type: new 
Abstract: This paper introduces a novel one-hop sub-query result cache for processing graph read transactions, gR-Txs, in a graph database system. The one-hop navigation is from a vertex using either its in-coming or out-going edges with selection predicates that filter edges and vertices. Its cache entry identifies a unique one-hop sub-query (key) and its result set consisting of immutable vertex ids (value). When processing a gR-Tx, the query processor identifies its sequence of individual one-hop sub-queries and looks up their results in the cache. A cache hit fetches less data from the storage manager and eliminates the requirement to process the one-hop sub-query. A cache miss populates the cache asynchronously and in a transactional manner, maintaining the separation of read and write paths of our transactional storage manager. A graph read and write transaction, gRW-Tx, identifies the impacted cache entries and either deletes or updates them. Our implementation of the cache is inside the graph query processing engine and transparent to a user application. We evaluate the cache using our eCommerce production workload and with rules that re-write graph queries to maximize the performance enhancements observed with the cache. Obtained results show the cache enhances 95th and 99th percentile of query response times by at least 2x and 1.63x, respectively. When combined with query re-writing, the enhancements are at least 2.33x and 4.48x, respectively. An interesting result is the significant performance enhancement observed by the indirect beneficiaries of the cache, gRW-Txs and gR-Txs that do not reference one-hop sub-queries. The cache frees system resources to expedite their processing significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04698v1</guid>
      <category>cs.DB</category>
      <category>cs.PF</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hieu Nguyen, Jun Li, Shahram Ghandeharizadeh</dc:creator>
    </item>
    <item>
      <title>A Unified Approach for Multi-granularity Search over Spatial Datasets</title>
      <link>https://arxiv.org/abs/2412.04805</link>
      <description>arXiv:2412.04805v1 Announce Type: new 
Abstract: There has been increased interest in data search as a means to find relevant datasets or data points in data lakes and repositories. Although approaches have been proposed to support spatial dataset search and data point search, they consider the two types of searches independently. To enable search operations ranging from the coarse-grained dataset level to the fine-grained data point level, we provide an integrated one that supports diverse query types and distance metrics. In this paper, we focus on designing a multi-granularity spatial data search system, called Spadas, that supports both dataset and data point search operations. To address the challenges of the high cost of indexing and susceptibility to outliers, we propose a unified index that can drastically improve query efficiency in various scenarios by organizing data reasonably and removing outliers in datasets. Moreover, to accelerate all data search operations, we propose a set of pruning mechanisms based on the unified index, including fast bound estimation, approximation technique with error bound, and pruning in batch techniques, to effectively filter out non-relevant datasets and points. Finally, we report the results of a detailed experimental evaluation using six spatial data repositories, achieving orders of magnitude faster than the state-of-the-art algorithms and demonstrating the effectiveness by case study. An online spatial data search system of Spadas is also implemented and made accessible to users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04805v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenzhe Yang, Sheng Wang, Shixun Huang, Yuyang Liao, Yuan Sun, Juliana Freire, Zhiyong Peng</dc:creator>
    </item>
    <item>
      <title>Budgeted Spatial Data Acquisition: When Coverage and Connectivity Matter</title>
      <link>https://arxiv.org/abs/2412.04853</link>
      <description>arXiv:2412.04853v1 Announce Type: new 
Abstract: Data is undoubtedly becoming a commodity like oil, land, and labor in the 21st century. Although there have been many successful marketplaces for data trading, the existing data marketplaces lack consideration of the case where buyers want to acquire a collection of datasets (instead of one), and the overall spatial coverage and connectivity matter. In this paper, we take the first attempt to formulate this problem as Budgeted Maximum Coverage with Connectivity Constraint (BMCC), which aims to acquire a dataset collection with the maximum spatial coverage under a limited budget while maintaining spatial connectivity. To solve the problem, we propose two approximate algorithms with detailed theoretical guarantees and time complexity analysis, followed by two acceleration strategies to further improve the efficiency of the algorithm. Experiments are conducted on five real-world spatial dataset collections to verify the efficiency and effectiveness of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04853v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenzhe Yang, Shixun Huang, Sheng Wang, Zhiyong Peng</dc:creator>
    </item>
    <item>
      <title>An Experimental Framework for Implementing Decentralized Autonomous Database Systems in Rust</title>
      <link>https://arxiv.org/abs/2412.05078</link>
      <description>arXiv:2412.05078v1 Announce Type: new 
Abstract: This paper presents an experimental framework for implementing Decentralized Autonomous Database Systems (DADBS) using the Rust programming language. As traditional centralized databases face challenges in scalability, security, and autonomy, DADBS emerge as a promising solution, using blockchain principles to create distributed, self-governing database systems. Our framework explores the practical aspects of building a DADBS, focusing on Rust's unique features that improves system reliability and performance. We evaluated our DADBS implementation across several key performance metrics: throughput, latency(read), latency(write), scalability, CPU utilization, Memory Usage and Network I/O, The average results obtained over a 24-hour period of continuous operation were 3,000 transactions/second, 75 ms, 250 ms, 55%, 2.5 GB, 100MB/s. The security analysis depicts that even with an increase in the percentage of malicious nodes, DADBS still maintains high throughput and consistency. The paper discusses key design decisions, highlighting how Rust's ownership model and concurrency features address common challenges in distributed systems. We also examine the current limitations of our approach and potential areas for future research. By providing this comprehensive overview of a Rust-based DADBS implementation, we aim to contribute to the growing body of knowledge on decentralized database architectures and their practical realization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05078v1</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakash Aryan, Radhika Khatri, Vijayakumar Balakrishnan</dc:creator>
    </item>
    <item>
      <title>Designing a Secure, Scalable, and Cost-Effective Cloud Storage Solution: A Novel Approach to Data Management using NextCloud, TrueNAS, and QEMU/KVM</title>
      <link>https://arxiv.org/abs/2412.05091</link>
      <description>arXiv:2412.05091v1 Announce Type: new 
Abstract: This paper presents a novel approach to cloud storage challenges by integrating NextCloud, TrueNAS, and QEMU/KVM. Our research demonstrates how this combination creates a robust, flexible, and economical cloud storage system suitable for various applications. We detail the architecture, highlighting TrueNAS's ZFS-based storage, QEMU/KVM's virtualization, and NextCloud's user interface. Extensive testing showssuperior data integrity and protection compared to traditional solutions. Performance benchmarks reveal high read/write speeds(up to 1.22 GB/s for sequential reads and 620 MB/s for writes) and also efficient small file handling. We demonstrate the solution's scalability under increasing workloads. Security analysis showcases effective jail isolation techniques in TrueNAS. Cost analysis indicates potential 50% reduction in total ownership cost over five years compared to commercial alternatives. This research contributes a practical, high-performance, cost-effective alternative to proprietary solutions, paving new ways for organizations to implement secure, scalable cloud storage while maintaining data control. Future work will focus on improving automated scaling and integration with emerging technologies like containerization and serverless computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05091v1</guid>
      <category>cs.DB</category>
      <category>cs.CR</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakash Aryan, Sujala Deepak Shetty</dc:creator>
    </item>
    <item>
      <title>eXpath: Explaining Knowledge Graph Link Prediction with Ontological Closed Path Rules</title>
      <link>https://arxiv.org/abs/2412.04846</link>
      <description>arXiv:2412.04846v1 Announce Type: cross 
Abstract: Link prediction (LP) is crucial for Knowledge Graphs (KG) completion but commonly suffers from interpretability issues. While several methods have been proposed to explain embedding-based LP models, they are generally limited to local explanations on KG and are deficient in providing human interpretable semantics. Based on real-world observations of the characteristics of KGs from multiple domains, we propose to explain LP models in KG with path-based explanations. An integrated framework, namely eXpath, is introduced which incorporates the concept of relation path with ontological closed path rules to enhance both the efficiency and effectiveness of LP interpretation. Notably, the eXpath explanations can be fused with other single-link explanation approaches to achieve a better overall solution. Extensive experiments across benchmark datasets and LP models demonstrate that introducing eXpath can boost the quality of resulting explanations by about 20% on two key metrics and reduce the required explanation time by 61.4%, in comparison to the best existing method. Case studies further highlight eXpath's ability to provide more semantically meaningful explanations through path-based evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04846v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Sun, Lei Shi, Yongxin Tong</dc:creator>
    </item>
    <item>
      <title>A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges</title>
      <link>https://arxiv.org/abs/2412.05208</link>
      <description>arXiv:2412.05208v1 Announce Type: cross 
Abstract: Text-to-SQL systems facilitate smooth interaction with databases by translating natural language queries into Structured Query Language (SQL), bridging the gap between non-technical users and complex database management systems. This survey provides a comprehensive overview of the evolution of AI-driven text-to-SQL systems, highlighting their foundational components, advancements in large language model (LLM) architectures, and the critical role of datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine the applications of text-to-SQL in domains like healthcare, education, and finance, emphasizing their transformative potential for improving data accessibility. Additionally, we analyze persistent challenges, including domain generalization, query optimization, support for multi-turn conversational interactions, and the limited availability of datasets tailored for NoSQL databases and dynamic real-world scenarios. To address these challenges, we outline future research directions, such as extending text-to-SQL capabilities to support NoSQL databases, designing datasets for dynamic multi-turn interactions, and optimizing systems for real-world scalability and robustness. By surveying current advancements and identifying key gaps, this paper aims to guide the next generation of research and applications in LLM-based text-to-SQL systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05208v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditi Singh, Akash Shetty, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei</dc:creator>
    </item>
    <item>
      <title>Transformers Meet Relational Databases</title>
      <link>https://arxiv.org/abs/2412.05218</link>
      <description>arXiv:2412.05218v1 Announce Type: cross 
Abstract: Transformer models have continuously expanded into all machine learning domains convertible to the underlying sequence-to-sequence representation, including tabular data. However, while ubiquitous, this representation restricts their extension to the more general case of relational databases. In this paper, we introduce a modular neural message-passing scheme that closely adheres to the formal relational model, enabling direct end-to-end learning of tabular Transformers from database storage systems. We address the challenges of appropriate learning data representation and loading, which are critical in the database setting, and compare our approach against a number of representative models from various related fields across a significantly wide range of datasets. Our results demonstrate a superior performance of this newly proposed class of neural architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05218v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Pele\v{s}ka, Gustav \v{S}\'ir</dc:creator>
    </item>
    <item>
      <title>Automated, Unsupervised, and Auto-parameterized Inference of Data Patterns and Anomaly Detection</title>
      <link>https://arxiv.org/abs/2412.05240</link>
      <description>arXiv:2412.05240v1 Announce Type: cross 
Abstract: With the advent of data-centric and machine learning (ML) systems, data quality is playing an increasingly critical role in ensuring the overall quality of software systems. Data preparation, an essential step towards high data quality, is known to be a highly effort-intensive process. Although prior studies have dealt with one of the most impacting issues, data pattern violations, these studies usually require data-specific configurations (i.e., parameterized) or use carefully curated data as learning examples (i.e., supervised), relying on domain knowledge and deep understanding of the data, or demanding significant manual effort. In this paper, we introduce RIOLU: Regex Inferencer auto-parameterized Learning with Uncleaned data. RIOLU is fully automated, automatically parameterized, and does not need labeled samples. RIOLU can generate precise patterns from datasets in various domains, with a high F1 score of 97.2%, exceeding the state-of-the-art baseline. In addition, according to our experiment on five datasets with anomalies, RIOLU can automatically estimate a data column's error rate, draw normal patterns, and predict anomalies from unlabeled data with higher performance (up to 800.4% improvement in terms of F1) than the state-of-the-art baseline, even outperforming ChatGPT in terms of both accuracy (12.3% higher F1) and efficiency (10% less inference time). A variant of RIOLU, with user guidance, can further boost its precision, with up to 37.4% improvement in terms of F1. Our evaluation in an industrial setting further demonstrates the practical benefits of RIOLU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05240v1</guid>
      <category>cs.SE</category>
      <category>cs.DB</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiaolin Qin, Heng Li, Ettore Merlo, Maxime Lamothe</dc:creator>
    </item>
    <item>
      <title>A Unifying Perspective on Succinct Data Representations</title>
      <link>https://arxiv.org/abs/2309.11663</link>
      <description>arXiv:2309.11663v2 Announce Type: replace 
Abstract: Factorized representations (FRs) are a well-known tool to succinctly represent results of join queries and have been originally defined using the named database perspective. We define FRs in the unnamed database perspective and use them to establish several new connections. First, unnamed FRs can be exponentially more succinct than named FRs, but this difference can be alleviated by imposing a disjointness condition on columns. Conversely, named FRs can also be exponentially more succinct than unnamed FRs. Second, unnamed FRs are the same as (i.e., isomorphic to) context-free grammars for languages in which each word has the same length. This tight connection allows us to transfer a wide range of results on context-free grammars to database factorization; of which we offer a selection in the paper. Third, when we generalize unnamed FRs to arbitrary sets of tuples, they become a generalization of \emph{path multiset representations}, a formalism that was recently introduced to succinctly represent sets of paths in the context of graph database query evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11663v2</guid>
      <category>cs.DB</category>
      <category>cs.FL</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benny Kimelfeld, Wim Martens, Matthias Niewerth</dc:creator>
    </item>
    <item>
      <title>Data Quality Assessment: Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2403.00526</link>
      <description>arXiv:2403.00526v2 Announce Type: replace 
Abstract: Data-oriented applications, their users, and even the law require data of high quality. Research has divided the rather vague notion of data quality into various dimensions, such as accuracy, consistency, and reputation. To achieve the goal of high data quality, many tools and techniques exist to clean and otherwise improve data. Yet, systematic research on actually assessing data quality in its dimensions is largely absent, and with it, the ability to gauge the success of any data cleaning effort.
  We propose five facets as ingredients to assess data quality: data, source, system, task, and human. Tapping each facet for data quality assessment poses its own challenges. We show how overcoming these challenges helps data quality assessment for those data quality dimensions mentioned in Europe's AI Act. Our work concludes with a proposal for a comprehensive data quality assessment framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00526v2</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sedir Mohammed, Lisa Ehrlinger, Hazar Harmouch, Felix Naumann, Divesh Srivastava</dc:creator>
    </item>
    <item>
      <title>Revolutionizing Database Q&amp;A with Large Language Models: Comprehensive Benchmark and Evaluation</title>
      <link>https://arxiv.org/abs/2409.04475</link>
      <description>arXiv:2409.04475v2 Announce Type: replace 
Abstract: The development of Large Language Models (LLMs) has revolutionized QA across various industries, including the database domain. However, there is still a lack of a comprehensive benchmark to evaluate the capabilities of different LLMs and their modular components in database QA. To this end, we introduce DQABench, the first comprehensive database QA benchmark for LLMs. DQABench features an innovative LLM-based method to automate the generation, cleaning, and rewriting of evaluation dataset, resulting in over 200,000 QA pairs in English and Chinese, separately. These QA pairs cover a wide range of database-related knowledge extracted from manuals, online communities, and database instances. This inclusion allows for an additional assessment of LLMs' Retrieval-Augmented Generation (RAG) and Tool Invocation Generation (TIG) capabilities in the database QA task. Furthermore, we propose a comprehensive LLM-based database QA testbed DQATestbed. This testbed is highly modular and scalable, with basic and advanced components such as Question Classification Routing (QCR), RAG, TIG, and Prompt Template Engineering (PTE). Moreover, DQABench provides a comprehensive evaluation pipeline that computes various metrics throughout a standardized evaluation process to ensure the accuracy and fairness of the evaluation. We use DQABench to evaluate the database QA capabilities under the proposed testbed comprehensively. The evaluation reveals findings like (i) the strengths and limitations of nine LLM-based QA bots and (ii) the performance impact and potential improvements of various service components (e.g., QCR, RAG, TIG). Our benchmark and findings will guide the future development of LLM-based database QA research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04475v2</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Zheng, Bo Li, Zhenghao Lin, Yi Luo, Xuanhe Zhou, Chen Lin, Jinsong Su, Guoliang Li, Shifu Li</dc:creator>
    </item>
  </channel>
</rss>
