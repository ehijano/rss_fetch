<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Jun 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>L'algorithme: pourquoi et comment le d\'efinir pour l'enseigner</title>
      <link>https://arxiv.org/abs/2406.04385</link>
      <description>arXiv:2406.04385v1 Announce Type: new 
Abstract: The question of the definition of what is an algorithm is recurrent. It is found in teaching, at different levels and particularly in secondary education because of the recent evolutions in high school, with immediate consequences in higher education. It is found in mediation, with the different meanings that the word "algorithm" is charged with in the media space. It is also found in research, with issues in different branches of computer science, from foundations in computability and complexity to applications in big data. Beyond the issue of definition, it is the raison d'{\^e}tre of the notion of algorithm that should be questioned: what do we want to do with it and what is at stake? It is by trying to specify this that we can identify didactic elements that are likely to help teach the algorithm, in interaction with mathematics or not, and to different audiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04385v1</guid>
      <category>cs.DS</category>
      <category>math.HO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emmanuel Beffara (MeTAH, LIG, IREM)</dc:creator>
    </item>
    <item>
      <title>A Lower Bound for Light Spanners in General Graphs</title>
      <link>https://arxiv.org/abs/2406.04459</link>
      <description>arXiv:2406.04459v1 Announce Type: new 
Abstract: A recent upper bound by Le and Solomon [STOC '23] has established that every $n$-node graph has a $(1+\varepsilon)(2k-1)$-spanner with lightness $O(\varepsilon^{-1} n^{1/k})$. This bound is optimal up to its dependence on $\varepsilon$; the remaining open problem is whether this dependence can be improved or perhaps even removed entirely.
  We show that the $\varepsilon$-dependence cannot in fact be completely removed. In the specific parameter regime where $$\varepsilon = kn^{-\frac{1}{2k-2}} &lt; \frac{1}{2k},$$ we show a lower bound of $$\Omega\left( \frac{\varepsilon^{-1/k} n^{1/k}}{k} \right).$$ An unusual feature of our lower bound is that it is conditional on the girth conjecture with parameter $k-1$ rather than $k$. We show that this implies certain technical limitations to improving our lower bound further. In particular, under the same conditional, generalizing our lower bound to all $\varepsilon$ or improving the dependence to $\varepsilon^{-1}$ are both as hard as settling the girth conjecture for all constant $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04459v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Greg Bodwin, Jeremy Flics</dc:creator>
    </item>
    <item>
      <title>Explicit Combinatoric Structures of Palindromes and Chromatic Number of Restriction Graphs</title>
      <link>https://arxiv.org/abs/2406.04507</link>
      <description>arXiv:2406.04507v1 Announce Type: new 
Abstract: The palindromic fingerprint of a string $S[1\ldots n]$ is the set $PF(S) = \{(i,j)~|~ S[i\ldots j] \textit{ is a maximal }\\ \textit{palindrome substring of } S\}$. In this work, we consider the problem of string reconstruction from a palindromic fingerprint. That is, given an input set of pairs $PF \subseteq [1\ldots n] \times [1\ldots n]$ for an integer $n$, we wish to determine if $PF$ is a valid palindromic fingerprint for a string $S$, and if it is, output a string $S$ such that $PF= PF(S)$. I et al. [SPIRE2010] showed a linear reconstruction algorithm from a palindromic fingerprint that outputs the lexicographically smallest string over a minimum alphabet. They also presented an upper bound of $\mathcal{O}(\log(n))$ for the maximal number of characters in the minimal alphabet.
  In this paper, we show tight combinatorial bounds for the palindromic fingerprint reconstruction problem. We present the string $S_k$, which is the shortest string whose fingerprint $PF(S_k)$ cannot be reconstructed using less than $k$ characters. The results additionally solve an open problem presented by I et al.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04507v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amihood Amir, Michael Itzhaki</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Priority Queues</title>
      <link>https://arxiv.org/abs/2406.04793</link>
      <description>arXiv:2406.04793v1 Announce Type: new 
Abstract: Priority queues are one of the most fundamental and widely used data structures in computer science. Their primary objective is to efficiently support the insertion of new elements with assigned priorities and the extraction of the highest priority element. In this study, we investigate the design of priority queues within the learning-augmented framework, where algorithms use potentially inaccurate predictions to enhance their worst-case performance. We examine three prediction models spanning different use cases, and show how the predictions can be leveraged to enhance the performance of priority queue operations. Moreover, we demonstrate the optimality of our solution and discuss some possible applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04793v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyad Benomar, Christian Coester</dc:creator>
    </item>
    <item>
      <title>A Near-Linear Time Approximation Algorithm for Beyond-Worst-Case Graph Clustering</title>
      <link>https://arxiv.org/abs/2406.04857</link>
      <description>arXiv:2406.04857v1 Announce Type: new 
Abstract: We consider the semi-random graph model of [Makarychev, Makarychev and Vijayaraghavan, STOC'12], where, given a random bipartite graph with $\alpha$ edges and an unknown bipartition $(A, B)$ of the vertex set, an adversary can add arbitrary edges inside each community and remove arbitrary edges from the cut $(A, B)$ (i.e. all adversarial changes are \textit{monotone} with respect to the bipartition). For this model, a polynomial time algorithm is known to approximate the Balanced Cut problem up to value $O(\alpha)$ [MMV'12] as long as the cut $(A, B)$ has size $\Omega(\alpha)$. However, it consists of slow subroutines requiring optimal solutions for logarithmically many semidefinite programs. We study the fine-grained complexity of the problem and present the first near-linear time algorithm that achieves similar performances to that of [MMV'12]. Our algorithm runs in time $O(|V(G)|^{1+o(1)} + |E(G)|^{1+o(1)})$ and finds a balanced cut of value $O(\alpha)$. Our approach appears easily extendible to related problem, such as Sparsest Cut, and also yields an near-linear time $O(1)$-approximation to Dagupta's objective function for hierarchical clustering [Dasgupta, STOC'16] for the semi-random hierarchical stochastic block model inputs of [Cohen-Addad, Kanade, Mallmann-Trenn, Mathieu, JACM'19].</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04857v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Cohen-Addad, Tommaso d'Orsi, Aida Mousavifar</dc:creator>
    </item>
    <item>
      <title>Efficient Centroid-Linkage Clustering</title>
      <link>https://arxiv.org/abs/2406.05066</link>
      <description>arXiv:2406.05066v1 Announce Type: new 
Abstract: We give an efficient algorithm for Centroid-Linkage Hierarchical Agglomerative Clustering (HAC), which computes a $c$-approximate clustering in roughly $n^{1+O(1/c^2)}$ time. We obtain our result by combining a new Centroid-Linkage HAC algorithm with a novel fully dynamic data structure for nearest neighbor search which works under adaptive updates.
  We also evaluate our algorithm empirically. By leveraging a state-of-the-art nearest-neighbor search library, we obtain a fast and accurate Centroid-Linkage HAC algorithm. Compared to an existing state-of-the-art exact baseline, our implementation maintains the clustering quality while delivering up to a $36\times$ speedup due to performing fewer distance comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05066v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MohammadHossein Bateni, Laxman Dhulipala, Willem Fletcher, Kishen N Gowda, D Ellis Hershkowitz, Rajesh Jayaram, Jakub {\L}\k{a}cki</dc:creator>
    </item>
    <item>
      <title>In-depth Analysis of Densest Subgraph Discovery in a Unified Framework</title>
      <link>https://arxiv.org/abs/2406.04738</link>
      <description>arXiv:2406.04738v1 Announce Type: cross 
Abstract: As a fundamental topic in graph mining, Densest Subgraph Discovery (DSD) has found a wide spectrum of real applications. Several DSD algorithms, including exact and approximation algorithms, have been proposed in the literature. However, these algorithms have not been systematically and comprehensively compared under the same experimental settings. In this paper, we first propose a unified framework to incorporate all DSD algorithms from a high-level perspective. We then extensively compare representative DSD algorithms over a range of graphs -- from small to billion-scale -- and examine the effectiveness of all methods. Moreover, we suggest new variants of the DSD algorithms by combining the existing techniques, which are up to 10 X faster than the state-of-the-art algorithm with the same accuracy guarantee. Finally, based on the findings, we offer promising research opportunities. We believe that a deeper understanding of the behavior of existing algorithms can provide new valuable insights for future research. The codes are released at https://anonymous.4open.science/r/DensestSubgraph-245A</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04738v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingli Zhou, Qingshuo Guo, Yi Yang, Yixiang Fang, Chenhao Ma, Laks Lakshmanan</dc:creator>
    </item>
    <item>
      <title>Multi-View Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2406.04860</link>
      <description>arXiv:2406.04860v1 Announce Type: cross 
Abstract: Graph clustering is a central topic in unsupervised learning with a multitude of practical applications. In recent years, multi-view graph clustering has gained a lot of attention for its applicability to real-world instances where one has access to multiple data sources. In this paper we formalize a new family of models, called \textit{multi-view stochastic block models} that captures this setting.
  For this model, we first study efficient algorithms that naively work on the union of multiple graphs. Then, we introduce a new efficient algorithm that provably outperforms previous approaches by analyzing the structure of each graph separately. Furthermore, we complement our results with an information-theoretic lower bound studying the limits of what can be done in this model. Finally, we corroborate our results with experimental evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04860v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Cohen-Addad, Tommaso d'Orsi, Silvio Lattanzi, Rajai Nasser</dc:creator>
    </item>
    <item>
      <title>Perturb-and-Project: Differentially Private Similarities and Marginals</title>
      <link>https://arxiv.org/abs/2406.04868</link>
      <description>arXiv:2406.04868v1 Announce Type: cross 
Abstract: We revisit the input perturbations framework for differential privacy where noise is added to the input $A\in \mathcal{S}$ and the result is then projected back to the space of admissible datasets $\mathcal{S}$. Through this framework, we first design novel efficient algorithms to privately release pair-wise cosine similarities. Second, we derive a novel algorithm to compute $k$-way marginal queries over $n$ features. Prior work could achieve comparable guarantees only for $k$ even. Furthermore, we extend our results to $t$-sparse datasets, where our efficient algorithms yields novel, stronger guarantees whenever $t\le n^{5/6}/\log n\,.$ Finally, we provide a theoretical perspective on why \textit{fast} input perturbation algorithms works well in practice. The key technical ingredients behind our results are tight sum-of-squares certificates upper bounding the Gaussian complexity of sets of solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04868v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Cohen-Addad, Tommaso d'Orsi, Alessandro Epasto, Vahab Mirrokni, Peilin Zhong</dc:creator>
    </item>
    <item>
      <title>Optimization with pattern-avoiding input</title>
      <link>https://arxiv.org/abs/2310.04236</link>
      <description>arXiv:2310.04236v2 Announce Type: replace 
Abstract: Permutation pattern-avoidance is a central concept of both enumerative and extremal combinatorics. In this paper we study the effect of permutation pattern-avoidance on the complexity of optimization problems.
  In the context of the dynamic optimality conjecture (Sleator, Tarjan, STOC 1983), Chalermsook, Goswami, Kozma, Mehlhorn, and Saranurak (FOCS 2015) conjectured that the amortized search cost of an optimal binary search tree (BST) is constant whenever the search sequence is pattern-avoiding. The best known bound to date is $2^{\alpha{(n)}(1+o(1))}$ recently obtained by Chalermsook, Pettie, and Yingchareonthawornchai (SODA 2024); here $n$ is the BST size and $\alpha(\cdot)$ the inverse-Ackermann function. In this paper we resolve the conjecture, showing a tight $O(1)$ bound. This indicates a barrier to dynamic optimality: any candidate online BST (e.g., splay trees or greedy trees) must match this optimum, but current analysis techniques only give superconstant bounds.
  More broadly, we argue that the easiness of pattern-avoiding input is a general phenomenon, not limited to BSTs or even to data structures. To illustrate this, we show that when the input avoids an arbitrary, fixed, a priori unknown pattern, one can efficiently compute a $k$-server solution of $n$ requests from a unit interval, with total cost $n^{O(1/\log k)}$, in contrast to the worst-case $\Theta(n/k)$ bound; and a traveling salesman tour of $n$ points from a unit box, of length $O(\log{n})$, in contrast to the worst-case $\Theta(\sqrt{n})$ bound; similar results hold for the euclidean minimum spanning tree, Steiner tree, and nearest-neighbor graphs.
  We show both results to be tight. Our techniques build on the Marcus-Tardos proof of the Stanley-Wilf conjecture, and on the recently emerging concept of twin-width.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04236v2</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Aram Berendsohn, L\'aszl\'o Kozma, Michal Opler</dc:creator>
    </item>
    <item>
      <title>Solving Dense Linear Systems Faster Than via Preconditioning</title>
      <link>https://arxiv.org/abs/2312.08893</link>
      <description>arXiv:2312.08893v2 Announce Type: replace 
Abstract: We give a stochastic optimization algorithm that solves a dense $n\times n$ real-valued linear system $Ax=b$, returning $\tilde x$ such that $\|A\tilde x-b\|\leq \epsilon\|b\|$ in time: $$\tilde O((n^2+nk^{\omega-1})\log1/\epsilon),$$ where $k$ is the number of singular values of $A$ larger than $O(1)$ times its smallest positive singular value, $\omega &lt; 2.372$ is the matrix multiplication exponent, and $\tilde O$ hides a poly-logarithmic in $n$ factor. When $k=O(n^{1-\theta})$ (namely, $A$ has a flat-tailed spectrum, e.g., due to noisy data or regularization), this improves on both the cost of solving the system directly, as well as on the cost of preconditioning an iterative method such as conjugate gradient. In particular, our algorithm has an $\tilde O(n^2)$ runtime when $k=O(n^{0.729})$. We further adapt this result to sparse positive semidefinite matrices and least squares regression.
  Our main algorithm can be viewed as a randomized block coordinate descent method, where the key challenge is simultaneously ensuring good convergence and fast per-iteration time. In our analysis, we use theory of majorization for elementary symmetric polynomials to establish a sharp convergence guarantee when coordinate blocks are sampled using a determinantal point process. We then use a Markov chain coupling argument to show that similar convergence can be attained with a cheaper sampling scheme, and accelerate the block coordinate descent update via matrix sketching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08893v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Jiaming Yang</dc:creator>
    </item>
    <item>
      <title>On the Number of Steps of CyclePopping in Weakly Inconsistent U(1)-Connection Graphs</title>
      <link>https://arxiv.org/abs/2404.14803</link>
      <description>arXiv:2404.14803v2 Announce Type: replace 
Abstract: A U(1)-connection graph $G$ is a graph in which each oriented edge is endowed with a unit complex number, the latter being conjugated under orientation flip. We consider cycle-rooted spanning forests (CRSFs), a particular kind of spanning subgraphs of $G$ that have recently found computational applications as randomized spectral sparsifiers. In this context, CRSFs are drawn from a determinantal measure. Under a condition on the connection, Kassel and Kenyon gave an elegant algorithm, named CyclePopping, to sample from this distribution. The algorithm is an extension of the celebrated algorithm of Wilson that uses a loop-erased random walk to sample uniform spanning trees. In this paper, we give an alternative, elementary proof of correctness of CyclePopping for CRSF sampling; we fill the gaps of a proof sketch by Kassel, who was himself inspired by Marchal's proof of the correctness of Wilson's original algorithm. One benefit of the full proof \`a la Marchal is that we obtain a concise expression for the law of the number of steps to complete the sampling procedure, shedding light on practical situations where the algorithm is expected to run fast. Furthermore, we show how to extend the proof to more general distributions over CRSFs, which are not determinantal. The correctness of CyclePopping is known even in the non-determinantal case from the work of Kassel and Kenyon, so our merit is only to provide an alternate proof. One interest of this alternate proof is again to provide the distribution of the time complexity of the algorithm, in terms of a Poisson point process on the graph loops, or equivalently as a Poisson process on pyramids of cycles, a combinatorial notion introduced by Viennot. Finally, we strive to make the connections to loop measures and combinatorial structures as explicit as possible, to provide a reference for future extensions of the algorithm and its analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14803v2</guid>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha\"el Fanuel, R\'emi Bardenet</dc:creator>
    </item>
    <item>
      <title>Engineering Semi-streaming DFS algorithms</title>
      <link>https://arxiv.org/abs/2406.03922</link>
      <description>arXiv:2406.03922v2 Announce Type: replace 
Abstract: Depth first search is a fundamental graph problem having a wide range of applications. For a graph $G=(V,E)$ having $n$ vertices and $m$ edges, the DFS tree can be computed in $O(m+n)$ using $O(m)$ space where $m=O(n^2)$. In the streaming environment, most graph problems are studied in the semi-streaming model where several passes (preferably one) are allowed over the input, allowing $O(nk)$ local space for some $k=o(n)$. Trivially, using $O(m)$ space, DFS can be computed in one pass, and using $O(n)$ space, it can be computed in $O(n)$ passes.
  Khan and Mehta [STACS19] presented several algorithms allowing trade-offs between space and passes, where $O(nk)$ space results in $O(n/k)$ passes. They also empirically analyzed their algorithm to require only a few passes in practice for even $O(n)$ space. Chang et al. [STACS20] presented an alternate proof for the same and also presented $O(\sqrt{n})$ pass algorithm requiring $O(n~poly\log n)$ space with a finer trade-off between space and passes. However, their algorithm uses complex black box algorithms, making it impractical.
  We perform an experimental analysis of the practical semi-streaming DFS algorithms. Our analysis ranges from real graphs to random graphs (uniform and power-law). We also present several heuristics to improve the state-of-the-art algorithms and study their impact. Our heuristics improve state of the art by $40-90\%$, achieving optimal one pass in almost $40-50\%$ cases (improved from zero). In random graphs, they improve from $30-90\%$, again requiring optimal one pass for even very small values of $k$. Overall, our heuristics improved the relatively complex state-of-the-art algorithm significantly, requiring merely two passes in the worst case for random graphs. Additionally, our heuristics made the relatively simpler algorithm practically usable even for very small space bounds, which was impractical earlier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03922v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kancharla Nikhilesh Bhagavan, Macharla Sri Vardhan, Madamanchi Ashok Chowdary, Shahbaz Khan</dc:creator>
    </item>
    <item>
      <title>Quantum collision circuit, quantum invariants and quantum phase estimation procedure for fluid dynamic lattice gas automata</title>
      <link>https://arxiv.org/abs/2310.07362</link>
      <description>arXiv:2310.07362v2 Announce Type: replace-cross 
Abstract: Lattice Gas Cellular Automata (LGCA) is a classical numerical method widely known and applied to simulate several physical phenomena. Among these phenomena, we find fluid flows described by the Navier-Stokes equations. We develop a quantum algorithm that allows for the simulation of fluid dynamic LGCA on a quantum computer. Furthermore, we prove the conservation of the quantities of interest, but finding more quantum invariants than expected. Finally, we develop a phase estimation procedure for detecting quantities of interest such as mass and momentum, avoiding reinitialization of the cell. In addition, we discuss a sublinear encoding of the lattice which admits a unitary streaming but constrains the collision step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07362v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>nlin.CG</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niccolo Fonio, Pierre Sagaut, Giuseppe Di Molfetta</dc:creator>
    </item>
    <item>
      <title>An Interleaving Distance for Ordered Merge Trees</title>
      <link>https://arxiv.org/abs/2312.11113</link>
      <description>arXiv:2312.11113v3 Announce Type: replace-cross 
Abstract: Merge trees are a common topological descriptor for data with a hierarchical component, such as terrains and scalar fields. The interleaving distance, in turn, is a common distance measure for comparing merge trees. However, the interleaving distance for merge trees is solely based on the hierarchical structure, and disregards any other geometrical or topological properties that might be present in the underlying data. Furthermore, the interleaving distance is NP-hard to compute. In this paper, we introduce a form of ordered merge trees that does capture intrinsic order present in the data. We further define a natural variant of the interleaving distance, the monotone interleaving distance, which is an order preserving distance measure for ordered merge trees. Analogous to the regular interleaving distance for merge trees, we show that the monotone variant has three equivalent definitions in terms of two maps, a single map, or a labelling. The labelling-based definition fairly directly leads to an efficient algorithm for computing the monotone interleaving distance, but unfortunately it computes only an approximation thereof. Instead, we discover a surprising connection between the monotone interleaving distance of ordered merge trees and the Fr\'{e}chet distance of 1D curves. As a result, the monotone interleaving distance between two ordered merge trees of total complexity $n$ can be computed exactly in $\tilde O(n^2)$ time. The connection between the monotone interleaving distance and the Fr\'{e}chet distance establishes a new bridge between the fields of computational topology/topological data analysis, where interleaving distances are studied extensively, and computational geometry, where Fr\'{e}chet distances are studied extensively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11113v3</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thijs Beurskens, Tim Ophelders, Bettina Speckmann, Kevin Verbeek</dc:creator>
    </item>
  </channel>
</rss>
