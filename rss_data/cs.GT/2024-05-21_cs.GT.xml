<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 May 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Transcript of GPT-4 playing a rogue AGI in a Matrix Game</title>
      <link>https://arxiv.org/abs/2405.10997</link>
      <description>arXiv:2405.10997v1 Announce Type: new 
Abstract: Matrix Games are a type of unconstrained wargame used by planners to explore scenarios. Players propose actions, and give arguments and counterarguments for their success. An umpire, assisted by dice rolls modified according to the offered arguments, adjudicates the outcome of each action. A recent online play of the Matrix Game QuAI Sera Sera had six players, representing social, national and economic powers, and one player representing ADA, a recently escaped AGI. Unknown to the six human players, ADA was played by OpenAI's GPT-4 with a human operator serving as bidirectional interface between it and the game. GPT-4 demonstrated confident and competent game play; initiating and responding to private communications with other players and choosing interesting actions well supported by argument. We reproduce the transcript of the interaction with GPT-4 as it is briefed, plays, and debriefed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10997v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lewis D Griffin, Nicholas Riggs</dc:creator>
    </item>
    <item>
      <title>Data-Driven Revenue Management for Air Cargo</title>
      <link>https://arxiv.org/abs/2405.11000</link>
      <description>arXiv:2405.11000v1 Announce Type: new 
Abstract: It is well-recognized that Air Cargo revenue management is quite different from its passenger airline counterpart. Inherent demand volatility due to short booking horizon and lumpy shipments, multi-dimensionality and uncertainty of capacity as well as the flexibility in routing are a few of the challenges to be handled for Air Cargo revenue management. In this paper, we present a data-driven revenue management approach which is well-designed to handle the challenges associated with Air Cargo industry. We present findings from simulations tailored to Air Cargo setting and compare different scenarios for handling of weight and volume bid prices. Our results show that running our algorithm independently to generate weight and volume bid prices and summing the weight and volume bid prices into price optimization works the best by outperforming other strategies with more than 3% revenue gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11000v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ezgi Eren, Jiabing Li</dc:creator>
    </item>
    <item>
      <title>On the Convergence of No-Regret Dynamics in Information Retrieval Games with Proportional Ranking Functions</title>
      <link>https://arxiv.org/abs/2405.11517</link>
      <description>arXiv:2405.11517v1 Announce Type: new 
Abstract: Publishers who publish their content on the web act strategically, in a behavior that can be modeled within the online learning framework. Regret, a central concept in machine learning, serves as a canonical measure for assessing the performance of learning agents within this framework. We prove that any proportional content ranking function with a concave activation function induces games in which no-regret learning dynamics converge. Moreover, for proportional ranking functions, we prove the equivalence of the concavity of the activation function, the social concavity of the induced games and the concavity of the induced games. We also study the empirical trade-offs between publishers' and users' welfare, under different choices of the activation function, using a state-of-the-art no-regret dynamics algorithm. Furthermore, we demonstrate how the choice of the ranking function and changes in the ecosystem structure affect these welfare measures, as well as the dynamics' convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11517v1</guid>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omer Madmon, Idan Pipano, Itamar Reinman, Moshe Tennenholtz</dc:creator>
    </item>
    <item>
      <title>Equilibria in multiagent online problems with predictions</title>
      <link>https://arxiv.org/abs/2405.11873</link>
      <description>arXiv:2405.11873v1 Announce Type: new 
Abstract: We study the power of (competitive) algorithms with predictions in a multiagent setting. For this we introduce a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost. Our main contribution is a best-response analysis of a single-agent competitive algorithm that assumes perfect knowledge of other agents' actions (but no knowledge of its own renting time). We then analyze the setting when agents have a predictor for their own active time, yielding a tradeoff between robustness and consistency. We investigate the effect of using such a predictor in an equilibrium, as well as the new equilibria formed in this way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11873v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Istrate, Cosmin Bonchi\c{s}, Victor Bogdan</dc:creator>
    </item>
    <item>
      <title>Lipschitz Continuous Allocations for Optimization Games</title>
      <link>https://arxiv.org/abs/2405.11889</link>
      <description>arXiv:2405.11889v1 Announce Type: new 
Abstract: In cooperative game theory, the primary focus is the equitable allocation of payoffs or costs among agents. However, in the practical applications of cooperative games, accurately representing games is challenging. In such cases, using an allocation method sensitive to small perturbations in the game can lead to various problems, including dissatisfaction among agents and the potential for manipulation by agents seeking to maximize their own benefits. Therefore, the allocation method must be robust against game perturbations.
  In this study, we explore optimization games, in which the value of the characteristic function is provided as the optimal value of an optimization problem. To assess the robustness of the allocation methods, we use the Lipschitz constant, which quantifies the extent of change in the allocation vector in response to a unit perturbation in the weight vector of the underlying problem. Thereafter, we provide an algorithm for the matching game that returns an allocation belonging to the $\left(\frac{1}{2}-\epsilon\right)$-approximate core with Lipschitz constant $O(\epsilon^{-1})$. Additionally, we provide an algorithm for a minimum spanning tree game that returns an allocation belonging to the $4$-approximate core with a constant Lipschitz constant.
  The Shapley value is a popular allocation that satisfies several desirable properties. Therefore, we investigate the robustness of the Shapley value. We demonstrate that the Lipschitz constant of the Shapley value for the minimum spanning tree is constant, whereas that for the matching game is $\Omega(\log n)$, where $n$ denotes the number of vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11889v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soh Kumabe, Yuichi Yoshida</dc:creator>
    </item>
    <item>
      <title>Strategy-Proof Auctions through Conformal Prediction</title>
      <link>https://arxiv.org/abs/2405.12016</link>
      <description>arXiv:2405.12016v1 Announce Type: new 
Abstract: Auctions are key for maximizing sellers' revenue and ensuring truthful bidding among buyers. Recently, an approach known as differentiable economics based on deep learning shows promise in learning optimal auction mechanisms for multiple items and participants. However, this approach has no guarantee of strategy-proofness at test time. Strategy-proofness is crucial as it ensures that buyers are incentivized to bid their true valuations, leading to optimal and fair auction outcomes without the risk of manipulation. Building on conformal prediction, we introduce a novel approach to achieve strategy-proofness with rigorous statistical guarantees. The key novelties of our method are: (i) the formulation of a regret prediction model, used to quantify at test time violations of strategy-proofness; and (ii) an auction acceptance rule that leverages the predicted regret to ensure that for a new auction, the data-driven mechanism meets the strategy-proofness requirement with high probability (e.g., 99\%). Numerical experiments demonstrate the necessity for rigorous guarantees, the validity of our theoretical results, and the applicability of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12016v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roy Maor Lotan, Inbal Talgam-Chohen, Yaniv Romano</dc:creator>
    </item>
    <item>
      <title>Assessing Group Fairness with Social Welfare Optimization</title>
      <link>https://arxiv.org/abs/2405.11421</link>
      <description>arXiv:2405.11421v1 Announce Type: cross 
Abstract: Statistical parity metrics have been widely studied and endorsed in the AI community as a means of achieving fairness, but they suffer from at least two weaknesses. They disregard the actual welfare consequences of decisions and may therefore fail to achieve the kind of fairness that is desired for disadvantaged groups. In addition, they are often incompatible with each other, and there is no convincing justification for selecting one rather than another. This paper explores whether a broader conception of social justice, based on optimizing a social welfare function (SWF), can be useful for assessing various definitions of parity. We focus on the well-known alpha fairness SWF, which has been defended by axiomatic and bargaining arguments over a period of 70 years. We analyze the optimal solution and show that it can justify demographic parity or equalized odds under certain conditions, but frequently requires a departure from these types of parity. In addition, we find that predictive rate parity is of limited usefulness. These results suggest that optimization theory can shed light on the intensely discussed question of how to achieve group fairness in AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11421v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Violet Chen, J. N. Hooker, Derek Leben</dc:creator>
    </item>
    <item>
      <title>Configurable Mirror Descent: Towards a Unification of Decision Making</title>
      <link>https://arxiv.org/abs/2405.11746</link>
      <description>arXiv:2405.11746v1 Announce Type: cross 
Abstract: Decision-making problems, categorized as single-agent, e.g., Atari, cooperative multi-agent, e.g., Hanabi, competitive multi-agent, e.g., Hold'em poker, and mixed cooperative and competitive, e.g., football, are ubiquitous in the real world. Various methods are proposed to address the specific decision-making problems. Despite the successes in specific categories, these methods typically evolve independently and cannot generalize to other categories. Therefore, a fundamental question for decision-making is: \emph{Can we develop \textbf{a single algorithm} to tackle \textbf{ALL} categories of decision-making problems?} There are several main challenges to address this question: i) different decision-making categories involve different numbers of agents and different relationships between agents, ii) different categories have different solution concepts and evaluation measures, and iii) there lacks a comprehensive benchmark covering all the categories. This work presents a preliminary attempt to address the question with three main contributions. i) We propose the generalized mirror descent (GMD), a generalization of MD variants, which considers multiple historical policies and works with a broader class of Bregman divergences. ii) We propose the configurable mirror descent (CMD) where a meta-controller is introduced to dynamically adjust the hyper-parameters in GMD conditional on the evaluation measures. iii) We construct the \textsc{GameBench} with 15 academic-friendly games across different decision-making categories. Extensive experiments demonstrate that CMD achieves empirically competitive or better outcomes compared to baselines while providing the capability of exploring diverse dimensions of decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11746v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengdeng Li, Shuxin Li, Chang Yang, Xinrun Wang, Shuyue Hu, Xiao Huang, Hau Chan, Bo An</dc:creator>
    </item>
    <item>
      <title>Zero-Knowledge Games</title>
      <link>https://arxiv.org/abs/2009.13521</link>
      <description>arXiv:2009.13521v4 Announce Type: replace 
Abstract: In this paper we model a game such that all optimal strategies are non-revealing, with imperfect recall and incomplete information. Furthermore, using a modified sliding-block code as pseudo-virtual memory, the linear transformation generates common knowledge of how informed a player is. Ultimately, we see that between n-players in a zero-knowledge game there is ultimately a prover and verifier equivalent to a two-player game where all players are either informed or uninformed. The utility of trust is established within the mixed strategy Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.13521v4</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ian Malloy</dc:creator>
    </item>
    <item>
      <title>On the limitations of data-based price discrimination</title>
      <link>https://arxiv.org/abs/2204.12723</link>
      <description>arXiv:2204.12723v5 Announce Type: replace 
Abstract: Recent technological advances have enabled firms to use data to price discriminate. This paper studies third-degree price discrimination (3PD) based on a random sample of valuation and covariate data, where the covariate is continuous, and the distribution of the data is unknown to the seller. We first propose a $K$-markets empirical revenue maximization (ERM) strategy and study its rates of convergence in revenue. We then establish the fundamental information-theoretic limitation of any data-based pricing strategy and show that the $K$-markets ERM and the uniform (i.e., $1$-market) ERM strategies generate revenue converging to that of the true-distribution 3PD and uniform optima, respectively, at the optimal rate. A key takeaway from our information-theoretic limitation results is that, no sample-based 3PD strategy is able to escape from the curse of dimensionality and hence the $K$-markets ERM strategy is not an exception. This result prompts us to compare the revenues from the $K$-markets ERM and the uniform ERM in more specific cases. This comparison is ambiguous, in contrast to the classic pricing problem with a known distribution where third-degree price discrimination is at least as good as uniform pricing in generating revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.12723v5</guid>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haitian Xie, Ying Zhu, Denis Shishkin</dc:creator>
    </item>
    <item>
      <title>On the Efficiency of An Election Game of Two or More Parties: How Bad Can It Be?</title>
      <link>https://arxiv.org/abs/2303.14405</link>
      <description>arXiv:2303.14405v5 Announce Type: replace 
Abstract: An election campaign among two or more parties can be viewed as a game of two or more players, each of which has its own candidates as the pure strategies. People, as voters, comprise supporters for each party, and a candidate brings utility for the supporters of each party. Each party nominates exactly one of its candidates to compete against the other party's. A candidate is assumed to win the election with greater or equal odds if it brings more utility for all the people. The payoff of each player is the expected utility that its supporters get. The game is egoistic if every candidate benefits its party's supporters more than any candidate from a competing party does. In this paper, we first prove that it is NP-complete to determine whether an election game in a succinct representation, which is called the general form, has a pure-strategy Nash equilibrium even if it is egoistic. Next, we propose a fixed-parameter tractable algorithm to compute a pure-strategy Nash equilibrium of an egoistic election game and show that a naive constant time algorithm leads to a (1+e)-approximate pure-strategy Nash equilibrium when the winning probability is computed by a softmax function. Finally, perhaps surprisingly, we show that the price of anarchy for egoistic election games is upper bounded by the number of parties. Our results suggest that an election becomes unpredictable in terms of stability and efficiency when more than two parties are involved, and, to some extent, also provides supporting arguments for why the two-party system is prevalent in democratic countries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14405v5</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuang-Chieh Lin, Chi-Jen Lu, Po-An Chen</dc:creator>
    </item>
    <item>
      <title>The Search for Stability: Learning Dynamics of Strategic Publishers with Initial Documents</title>
      <link>https://arxiv.org/abs/2305.16695</link>
      <description>arXiv:2305.16695v4 Announce Type: replace 
Abstract: We study a game-theoretic information retrieval model in which strategic publishers aim to maximize their chances of being ranked first by the search engine while maintaining the integrity of their original documents. We show that the commonly used Probability Ranking Principle (PRP) ranking scheme results in an unstable environment where games often fail to reach pure Nash equilibrium. We propose two families of ranking functions that do not adhere to the PRP principle. We provide both theoretical and empirical evidence that these methods lead to a stable search ecosystem, by providing positive results on the learning dynamics convergence. We also define the publishers' and users' welfare, demonstrate a possible publisher-user trade-off, and provide means for a search system designer to control it. Finally, we show how instability harms long-term users' welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16695v4</guid>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omer Madmon, Idan Pipano, Itamar Reinman, Moshe Tennenholtz</dc:creator>
    </item>
    <item>
      <title>A Smoothed FPTAS for Equilibria in Congestion Games</title>
      <link>https://arxiv.org/abs/2306.10600</link>
      <description>arXiv:2306.10600v3 Announce Type: replace 
Abstract: We present a fully polynomial-time approximation scheme (FPTAS) for computing equilibria in congestion games, under smoothed running-time analysis. More precisely, we prove that if the resource costs of a congestion game are randomly perturbed by independent noises, whose density is at most $\phi$, then any sequence of $(1+\varepsilon)$-improving dynamics will reach an $(1+\varepsilon)$-approximate pure Nash equilibrium (PNE) after an expected number of steps which is strongly polynomial in $\frac{1}{\varepsilon}$, $\phi$, and the size of the game's description. Our results establish a sharp contrast to the traditional worst-case analysis setting, where it is known that better-response dynamics take exponentially long to converge to $\alpha$-approximate PNE, for any constant factor $\alpha\geq 1$. As a matter of fact, computing $\alpha$-approximate PNE in congestion games is PLS-hard.
  We demonstrate how our analysis can be applied to various different models of congestion games including general, step-function, and polynomial cost, as well as fair cost-sharing games (where the resource costs are decreasing). It is important to note that our bounds do not depend explicitly on the cardinality of the players' strategy sets, and thus the smoothed FPTAS is readily applicable to network congestion games as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10600v3</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiannis Giannakopoulos</dc:creator>
    </item>
    <item>
      <title>Grace Period is All You Need: Individual Fairness without Revenue Loss in Revenue Management</title>
      <link>https://arxiv.org/abs/2402.08533</link>
      <description>arXiv:2402.08533v2 Announce Type: replace 
Abstract: Imagine you and a friend purchase identical items at a store, yet only your friend received a discount. Would your friend's discount make you feel unfairly treated by the store? And would you be less willing to purchase from that store again in the future? Based on a large-scale online survey that we ran on Prolific, it turns out that the answers to the above questions are positive. Motivated by these findings, in this work we propose a notion of individual fairness in online revenue management and an algorithmic module (called ``Grace Period'') that can be embedded in traditional revenue management algorithms and guarantee individual fairness. Specifically, we show how to embed the Grace Period in five common revenue management algorithms including Deterministic Linear Programming with Probabilistic Assignment, Resolving Deterministic Linear Programming with Probabilistic Assignment, Static Bid Price Control, Booking Limit, and Nesting, thus covering both stochastic and adversarial customer arrival settings. Embedding the Grace Period does not incur additional regret for any of these algorithms. This finding indicates that there is no tradeoff between a seller maximizing their revenue and guaranteeing that each customer feels fairly treated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08533v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Jaillet, Chara Podimata, Zijie Zhou</dc:creator>
    </item>
    <item>
      <title>Multidimensional Blockchain Fees are (Essentially) Optimal</title>
      <link>https://arxiv.org/abs/2402.08661</link>
      <description>arXiv:2402.08661v2 Announce Type: replace 
Abstract: In this paper we show that, using only mild assumptions, previously proposed multidimensional blockchain fee markets are essentially optimal, even against worst-case adversaries. In particular, we show that the average welfare gap between the following two scenarios is at most $O(1/\sqrt{T})$, where $T$ is the length of the time horizon considered. In the first scenario, the designer knows all future actions by users and is allowed to fix the optimal prices of resources ahead of time, based on the designer's oracular knowledge of those actions. In the second, the prices are updated by a very simple algorithm that does not have this oracular knowledge, a special case of which is similar to EIP-1559, the base fee mechanism used by the Ethereum blockchain. Roughly speaking, this means that, on average, over a reasonable timescale, there is no difference in welfare between 'correctly' fixing the prices, with oracular knowledge of the future, when compared to the proposed algorithm. We show a matching lower bound of $\Omega(1/\sqrt{T})$ for any implementable algorithm and also separately consider the case where the adversary is known to be stochastic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08661v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillermo Angeris, Theo Diamandis, Ciamac Moallemi</dc:creator>
    </item>
    <item>
      <title>Deterministic Sub-exponential Algorithm for Discounted-sum Games with Unary Weights</title>
      <link>https://arxiv.org/abs/2405.02479</link>
      <description>arXiv:2405.02479v2 Announce Type: replace 
Abstract: Turn-based discounted-sum games are two-player zero-sum games played on finite directed graphs. The vertices of the graph are partitioned between player 1 and player 2. Plays are infinite walks on the graph where the next vertex is decided by a player that owns the current vertex. Each edge is assigned an integer weight and the payoff of a play is the discounted-sum of the weights of the play. The goal of player 1 is to maximize the discounted-sum payoff against the adversarial player 2. These games lie in NP and coNP and are among the rare combinatorial problems that belong to this complexity class and the existence of a polynomial-time algorithm is a major open question. Since breaking the general exponential barrier has been a challenging problem, faster parameterized algorithms have been considered. If the discount factor is expressed in unary, then discounted-sum games can be solved in polynomial time. However, if the discount factor is arbitrary (or expressed in binary), but the weights are in unary, none of the existing approaches yield a sub-exponential bound. Our main result is a new analysis technique for a classical algorithm (namely, the strategy iteration algorithm) that present a new runtime bound which is $n^{O ( W^{1/4} \sqrt{n} )}$, for game graphs with $n$ vertices and maximum absolute weight of at most $W$. In particular, our result yields a deterministic sub-exponential bound for games with weights that are constant or represented in unary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02479v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Asadi, Krishnendu Chatterjee, Raimundo Saona, Jakub Svoboda</dc:creator>
    </item>
    <item>
      <title>Agent-Constrained Truthful Facility Location Games</title>
      <link>https://arxiv.org/abs/2405.05197</link>
      <description>arXiv:2405.05197v2 Announce Type: replace 
Abstract: We consider a truthful facility location problem in which there is a set of agents with private locations on the line of real numbers, and the goal is to place a number of facilities at different locations chosen from the set of those reported by the agents. Given a feasible solution, each agent suffers an individual cost that is either its total distance to all facilities (sum-variant) or its distance to the farthest facility (max-variant). For both variants, we show tight bounds on the approximation ratio of strategyproof mechanisms in terms of the social cost, the total individual cost of the agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05197v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Mohammad Lotfi, Alexandros A. Voudouris</dc:creator>
    </item>
    <item>
      <title>A geometric decomposition of finite games: Convergence vs. recurrence under exponential weights</title>
      <link>https://arxiv.org/abs/2405.07224</link>
      <description>arXiv:2405.07224v2 Announce Type: replace 
Abstract: In view of the complexity of the dynamics of learning in games, we seek to decompose a game into simpler components where the dynamics' long-run behavior is well understood. A natural starting point for this is Helmholtz's theorem, which decomposes a vector field into a potential and an incompressible component. However, the geometry of game dynamics - and, in particular, the dynamics of exponential / multiplicative weights (EW) schemes - is not compatible with the Euclidean underpinnings of Helmholtz's theorem. This leads us to consider a specific Riemannian framework based on the so-called Shahshahani metric, and introduce the class of incompressible games, for which we establish the following results: First, in addition to being volume-preserving, the continuous-time EW dynamics in incompressible games admit a constant of motion and are Poincar\'e recurrent - i.e., almost every trajectory of play comes arbitrarily close to its starting point infinitely often. Second, we establish a deep connection with a well-known decomposition of games into a potential and harmonic component (where the players' objectives are aligned and anti-aligned respectively): a game is incompressible if and only if it is harmonic, implying in turn that the EW dynamics lead to Poincar\'e recurrence in harmonic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07224v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Legacci, Panayotis Mertikopoulos, Bary Pradelski</dc:creator>
    </item>
    <item>
      <title>Automated Market Makers for Decentralized Finance (DeFi)</title>
      <link>https://arxiv.org/abs/2009.01676</link>
      <description>arXiv:2009.01676v3 Announce Type: replace-cross 
Abstract: This paper compares mathematical models for automated market makers including logarithmic market scoring rule (LMSR), liquidity sensitive LMSR (LS-LMSR), constant product/mean/sum, and others. It is shown that though LMSR may not be a good model for Decentralized Finance (DeFi) applications, LS-LMSR has several advantages over constant product/mean based automated market makers. However, LS-LMSR requires complicated computation (i.e., logarithm and exponentiation) and the cost function curve is concave. In certain DeFi applications, it is preferred to have computationally efficient cost functions with convex curves to conform with the principle of supply and demand. This paper proposes and analyzes constant circle/ellipse based cost functions for automated market makers. The proposed cost functions are computationally efficient (only requires multiplication and square root calculation) and have several advantages over widely deployed constant product cost functions. For example, the proposed market makers are more robust against front-runner (slippage) attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.01676v3</guid>
      <category>q-fin.TR</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongge Wang</dc:creator>
    </item>
    <item>
      <title>Semidefinite games</title>
      <link>https://arxiv.org/abs/2202.12035</link>
      <description>arXiv:2202.12035v3 Announce Type: replace-cross 
Abstract: We introduce and study the class of semidefinite games, which generalizes bimatrix games and finite $N$-person games, by replacing the simplex of the mixed strategies for each player by a slice of the positive semidefinite cone in the space of real symmetric matrices.
  For semidefinite two-player zero-sum games, we show that the optimal strategies can be computed by semidefinite programming. Furthermore, we show that two-player semidefinite zero-sum games are almost equivalent to semidefinite programming, generalizing Dantzig's result on the almost equivalence of bimatrix games and linear programming.
  For general two-player semidefinite games, we prove a spectrahedral characterization of the Nash equilibria. Moreover, we give constructions of semidefinite games with many Nash equilibria. In particular, we give a construction of semidefinite games whose number of connected components of Nash equilibria exceeds the long standing best known construction for many Nash equilibria in bimatrix games, which was presented by von Stengel in 1999.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.12035v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Ickstadt, Thorsten Theobald, Elias Tsigaridas</dc:creator>
    </item>
    <item>
      <title>Binary Mechanisms under Privacy-Preserving Noise</title>
      <link>https://arxiv.org/abs/2301.06967</link>
      <description>arXiv:2301.06967v3 Announce Type: replace-cross 
Abstract: We study mechanism design for public-good provision under a noisy privacy-preserving transformation of individual agents' reported preferences. The setting is a standard binary model with transfers and quasi-linear utility. Agents report their preferences for the public good, which are randomly ``flipped,'' so that any individual report may be explained away as the outcome of noise. We study the tradeoffs between preserving the public decisions made in the presence of noise (noise sensitivity), pursuing efficiency, and mitigating the effect of noise on revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.06967v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farzad Pourbabaee, Federico Echenique</dc:creator>
    </item>
    <item>
      <title>Game Dynamics and Equilibrium Computation in the Population Protocol Model</title>
      <link>https://arxiv.org/abs/2307.07297</link>
      <description>arXiv:2307.07297v3 Announce Type: replace-cross 
Abstract: We initiate the study of game dynamics in the population protocol model: $n$ agents each maintain a current local strategy and interact in pairs uniformly at random. Upon each interaction, the agents play a two-person game and receive a payoff from an underlying utility function, and they can subsequently update their strategies according to a fixed local algorithm. In this setting, we ask how the distribution over agent strategies evolves over a sequence of interactions, and we introduce a new distributional equilibrium concept to quantify the quality of such distributions. As an initial example, we study a class of repeated prisoner's dilemma games, and we consider a family of simple local update algorithms that yield non-trivial dynamics over the distribution of agent strategies. We show that these dynamics are related to a new class of high-dimensional Ehrenfest random walks, and we derive exact characterizations of their stationary distributions, bounds on their mixing times, and prove their convergence to approximate distributional equilibria. Our results highlight trade-offs between the local state space of each agent, and the convergence rate and approximation factor of the underlying dynamics. Our approach opens the door towards the further characterization of equilibrium computation for other classes of games and dynamics in the population setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07297v3</guid>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Alistarh, Krishnendu Chatterjee, Mehrdad Karrabi, John Lazarsfeld</dc:creator>
    </item>
    <item>
      <title>Implicit Knowledge in Unawareness Structures</title>
      <link>https://arxiv.org/abs/2311.03608</link>
      <description>arXiv:2311.03608v2 Announce Type: replace-cross 
Abstract: Awareness structures by Fagin and Halpern (1988) (FH) feature a syntactic awareness correspondence and accessibility relations modeling implicit knowledge. They are a flexible model of unawareness, and best interpreted from a outside modeler's perspective. Unawareness structures by Heifetz, Meier, and Schipper (2006, 2008) (HMS) model awareness by a lattice of state spaces and explicit knowledge via possibility correspondences. Sublattices thereof can be interpreted as subjective views of agents. Open questions include (1) how implicit knowledge can be defined in HMS structures, and (2) in which way FH structures can be extended to model the agents' subjective views. In this paper, we address (1) by defining implicit knowledge such that it is consistent with explicit knowledge in HMS models. We also introduce a variant of HMS models that instead of explicit knowledge, takes implicit knowledge and awareness as primitives. Further, we address (2) by introducing a category of FH models that are modally equivalent relative to sublanguages and can be interpreted as agents' subjective views depending on their awareness. These constructions allow us to show an equivalence between HMS and FH models. As a corollary, we obtain soundness and completeness of HMS models with respect to the Logic of Propositional Awareness, based on a language featuring both implicit and explicit knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03608v2</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gaia Belardinelli, Burkhard C. Schipper</dc:creator>
    </item>
    <item>
      <title>When to Preempt in a Status Update System?</title>
      <link>https://arxiv.org/abs/2402.00845</link>
      <description>arXiv:2402.00845v2 Announce Type: replace-cross 
Abstract: We consider a time-slotted status update system with an error-free preemptive queue. The goal of the sampler-scheduler pair is to minimize the age of information at the monitor by sampling and transmitting the freshly sampled update packets to the monitor. The sampler-scheduler pair also has a choice to preempt an old update packet from the server and transmit a new update packet to the server. We formulate this problem as a Markov decision process (MDP) and find the optimal sampling policy. We find a sufficient, and also separately a necessary, condition for the always preemption policy to be an optimal policy. We show that it is optimal for the sampler-scheduler pair to sample a new packet immediately upon the reception of an update packet at the monitor. We propose a double-threshold sampling policy which we show to be an optimal policy under some assumptions on the queue statistic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00845v2</guid>
      <category>cs.IT</category>
      <category>cs.GT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhankar Banerjee, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Some Characterizations of TTC in Multiple-Object Reallocation Problems</title>
      <link>https://arxiv.org/abs/2404.04822</link>
      <description>arXiv:2404.04822v2 Announce Type: replace-cross 
Abstract: This paper considers exchange of indivisible objects when agents are endowed with and desire bundles of objects. Agents are assumed to have lexicographic preferences over bundles. We show that the generalized Top Trading Cycles rule (TTC) is characterized by Pareto efficiency, balancedness, the weak endowment lower bound, and truncation-proofness (or drop strategy-proofness). In the classic Shapley-Scarf model, TTC is characterized by Pareto efficiency, individual rationality, and truncation-proofness. The proof is nonstandard and its novelty has independent methodological interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04822v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Coreno, Di Feng</dc:creator>
    </item>
  </channel>
</rss>
