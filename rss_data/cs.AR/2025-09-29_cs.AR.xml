<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Sep 2025 03:30:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Privacy-Preserving Performance Profiling of In-The-Wild GPUs</title>
      <link>https://arxiv.org/abs/2509.21762</link>
      <description>arXiv:2509.21762v1 Announce Type: new 
Abstract: GPUs are the dominant platform for many important applications today including deep learning, accelerated computing, and scientific simulation. However, as the complexity of both applications and hardware increases, GPU chip manufacturers face a significant challenge: how to gather comprehensive performance characteristics and value profiles from GPUs deployed in real-world scenarios. Such data, encompassing the types of kernels executed and the time spent in each, is crucial for optimizing chip design and enhancing application performance. Unfortunately, despite the availability of low-level tools like NSYS and NCU, current methodologies fall short, offering data collection capabilities only on an individual user basis rather than a broader, more informative fleet-wide scale. This paper takes on the problem of realizing a system that allows planet-scale real-time GPU performance profiling of low-level hardware characteristics. The three fundamental problems we solve are: i) user experience of achieving this with no slowdown; ii) preserving user privacy, so that no 3rd party is aware of what applications any user runs; iii) efficacy in showing we are able to collect data and assign it applications even when run on 1000s of GPUs. Our results simulate a 100,000 size GPU deployment, running applications from the Torchbench suite, showing our system addresses all 3 problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21762v1</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian McDougall, Michael Davies, Rahul Chatterjee, Somesh Jha, Karthikeyan Sankaralingam</dc:creator>
    </item>
    <item>
      <title>NeuroScalar: A Deep Learning Framework for Fast, Accurate, and In-the-Wild Cycle-Level Performance Prediction</title>
      <link>https://arxiv.org/abs/2509.22410</link>
      <description>arXiv:2509.22410v1 Announce Type: new 
Abstract: The evaluation of new microprocessor designs is constrained by slow, cycle-accurate simulators that rely on unrepresentative benchmark traces. This paper introduces a novel deep learning framework for high-fidelity, ``in-the-wild'' simulation on production hardware. Our core contribution is a DL model trained on microarchitecture-independent features to predict cycle-level performance for hypothetical processor designs. This unique approach allows the model to be deployed on existing silicon to evaluate future hardware. We propose a complete system featuring a lightweight hardware trace collector and a principled sampling strategy to minimize user impact. This system achieves a simulation speed of 5 MIPS on a commodity GPU, imposing a mere 0.1% performance overhead. Furthermore, our co-designed Neutrino on-chip accelerator improves performance by 85x over the GPU. We demonstrate that this framework enables accurate performance analysis and large-scale hardware A/B testing on a massive scale using real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22410v1</guid>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shayne Wadle, Yanxin Zhang, Vikas Singh, Karthikeyan Sankaralingam</dc:creator>
    </item>
    <item>
      <title>AxLLM: accelerator architecture for large language models with computation reuse capability</title>
      <link>https://arxiv.org/abs/2509.22512</link>
      <description>arXiv:2509.22512v1 Announce Type: new 
Abstract: Large language models demand massive computational power and memory resources, posing significant challenges for efficient deployment. While quantization has been widely explored to reduce model size and computation, this paper demonstrates an additional benefit: quantization increases parameter locality, creating opportunities for computation reuse. Building on this insight, we propose AxLLM, a hardware accelerator architecture designed for quantized models. Axllm introduces a novel redundancy elimination technique that caches and reuses multiplication results for repeated weight values, substantially reducing redundant operations. The architecture features dual multiply and reuse pipelines, efficiently supporting both base models and LoRA fine-tuned models without altering parameters, retraining, or requiring offline preprocessing. Experimental results show that AxLLM achieves up to 90% reduction in computations, delivering 28% lower energy consumption and a 1.7x speedup over baseline execution. These results highlight Axllm as a scalable and efficient solution for accelerating LLMs on specialized hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22512v1</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soroush Ahadi, Mehdi Modarressi, Masoud Daneshtalab</dc:creator>
    </item>
    <item>
      <title>SAHM: State-Aware Heterogeneous Multicore for Single-Thread Performance</title>
      <link>https://arxiv.org/abs/2509.22405</link>
      <description>arXiv:2509.22405v1 Announce Type: cross 
Abstract: Improving single-thread performance remains a critical challenge in modern processor design, as conventional approaches such as deeper speculation, wider pipelines, and complex out-of-order execution face diminishing returns. This work introduces SAHM-State-Aware Heterogeneous Multicore-a novel architecture that targets performance gains by exploiting fine-grained, time-varying behavioral diversity in single-threaded workloads. Through empirical characterization of performance counter data, we define 16 distinct behavioral states representing different microarchitectural demands. Rather than over-provisioning a monolithic core with all optimizations, SAHM uses a set of specialized cores tailored to specific states and migrates threads at runtime based on detected behavior. This design enables composable microarchitectural enhancements without incurring prohibitive area, power, or complexity costs.
  We evaluate SAHM in both single-threaded and multiprogrammed scenarios, demonstrating its ability to maintain core utilization while improving overall performance through intelligent state-driven scheduling. Experimental results show opportunity for 17% speed up in realistic scenarios. These speed ups are robust against high-cost migration, decreasing by less than 1%. Overall, state-aware core specialization is a new path forward for enhancing single-thread performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22405v1</guid>
      <category>cs.PF</category>
      <category>cs.AR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shayne Wadle, Karthikeyan Sankaralingam</dc:creator>
    </item>
    <item>
      <title>IPU: Flexible Hardware Introspection Units</title>
      <link>https://arxiv.org/abs/2312.13428</link>
      <description>arXiv:2312.13428v3 Announce Type: replace 
Abstract: Modern chip designs are increasingly complex, making it difficult for developers to glean meaningful insights about hardware behavior while real workloads are running. Hardware introspection aims to solve this by enabling the hardware itself to observe and report on its internal operation - especially in the field, where the chip is executing real-world software and workloads. Three key problems are now imminent that hardware introspection can solve: A/B testing of hardware in the field, obfuscated hardware, and obfuscated software which prevents chip designers from gleaning insights on in the field behavior of their chips. To this end, the goal is to enable monitoring chip hardware behavior in the field, at real-time speeds with no slowdowns, with minimal power overheads, and thereby obtain insights on chip behavior and workloads. This paper implements the system architecture for and introduces the Introspection Processing Unit (IPU) - one solution to said goal. We perform case studies exemplifying the application of hardware introspection to the three problems through an IPU and implement an RTL level prototype. Across the case studies, we show that an IPU with area overhead less than 1 percent at 7nm, and overall power consumption of less than 25 mW is able to create previously inconceivable analysis: evaluating instruction prefetchers in the field before deployment, creating per-instruction cycles stacks of arbitrary programs, and detailing fine-grained cycle-by-cycle utilization of hardware modules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13428v3</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian McDougall, Shayne Wadle, Harish Batchu, Karthikeyan Sankaralingam</dc:creator>
    </item>
    <item>
      <title>Managing Classical Processing Requirements for Quantum Error Correction</title>
      <link>https://arxiv.org/abs/2406.17995</link>
      <description>arXiv:2406.17995v3 Announce Type: replace-cross 
Abstract: Large-scale quantum computers promise transformative speedups, but their viability hinges on fast and reliable quantum error correction (QEC). At the center of QEC are decoders-classical algorithms running on hardware such as FPGAs, GPUs, or CPUs that must process error syndromes every microsecond to preserve fault-tolerance. Quantum processors, therefore, operate not in isolation, but as accelerators tightly coupled with power classical systems (conventional digital hardware like CPUs, GPUs, FPGAs that run alongside the quantum processor). A key challenge is that decoder demand fluctuates unpredictably: bursts of activity can require orders of magnitude more decoders than idle periods. Provisioning hardware for the worst case wastes resources, while provisioning for the average case risks catastrophic slowdowns. We show that this mismatch is a systems problem of capacity planning and scheduling, and propose a two-level framework that treats decoders as shared accelerators managed by the quantum operating system. Our approach reduces decoder requirements by 10-40% across fault-tolerant benchmarks, demonstrating that efficient decoder scheduling is essential to making FTQC practical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17995v3</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Satvik Maurya, Abtin Molavi, Aws Albarghouthi, Swamit Tannu</dc:creator>
    </item>
    <item>
      <title>Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation</title>
      <link>https://arxiv.org/abs/2508.00017</link>
      <description>arXiv:2508.00017v2 Announce Type: replace-cross 
Abstract: We present Generative Logic (GL), a deterministic architecture that starts from user-supplied axiomatic definitions (and, optionally, a list of simple facts for counterexample (CE) construction), written in a minimalist Mathematical Programming Language (MPL), and systematically explores their deductive neighborhood. Definitions are compiled into a distributed grid of simple Logic Blocks (LBs) that exchange messages; whenever the premises of an inference rule unify, a new fact is emitted with full provenance to its sources, yielding replayable, auditable proof graphs. A prototype software implementation instantiates the workflow on first-order Peano arithmetic. Starting only from the Peano axioms, GL enumerates conjectures, applies normalization, type, and CE filter, and automatically reconstructs machine-checkable proofs of foundational arithmetic laws, including associativity and commutativity of addition, associativity and commutativity of multiplication, and distributivity. On commodity hardware, the prover phase requires approximately 7 seconds; a complete run finishes in about 5 minutes. Generated proofs export to navigable HTML so that every inference step can be inspected independently. We outline a hardware-software co-design path toward massively parallel realizations and describe prospective integration with probabilistic models (e.g., large language models) for auto-formalization and conjecture seeding. The Python, C++, and MPL code to reproduce the Peano experiments, along with the full proof graphs in HTML as well as machine-readable text format, are available in the project's GitHub repository at github.com/Generative-Logic/GL commit 56c9233 and are permanently archived at doi:10.5281/zenodo.17206386.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00017v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolai Sergeev</dc:creator>
    </item>
  </channel>
</rss>
