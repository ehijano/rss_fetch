<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Jun 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Infinite Time Turing Machines and their Applications</title>
      <link>https://arxiv.org/abs/2506.05351</link>
      <description>arXiv:2506.05351v1 Announce Type: new 
Abstract: This work establishes a rigorous theoretical foundation for analyzing deep learning systems by leveraging Infinite Time Turing Machines (ITTMs), which extend classical computation into transfinite ordinal steps. Using ITTMs, we reinterpret modern architectures like Transformers, revealing fundamental limitations in scalability, efficiency, and interpretability. Building on these insights, we propose the Universal State Machine (USM), a novel computational paradigm designed from first principles. The USM employs a dynamic, queryable computation graph that evolves in real time, enabling modular, interpretable, and resource-efficient computation. This framework not only overcomes the inefficiencies and rigidity of current models but also lays the groundwork for scalable, generalizable artificial intelligence systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05351v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rukmal Weerawarana, Maxwell Braun</dc:creator>
    </item>
    <item>
      <title>Sorting by pile shuffles on queue-like and stack-like piles can be hard</title>
      <link>https://arxiv.org/abs/2506.05518</link>
      <description>arXiv:2506.05518v1 Announce Type: new 
Abstract: Inspired by a common technique for shuffling a deck of cards on a table without riffling, we continue the study of a prequel paper on the pile shuffle and its capabilities as a sorting device. We study two sort feasibility problems of general interest concerning pile shuffle, first introduced in the prequel. These problems are characterized by: (1) bounds on the number of sequential rounds of shuffle, and piles created in each round; (2) the use of a heterogeneous mixture of queue-like and stack-like piles, as when each round of shuffle may have a combination of face-up and face-down piles; and (3) the ability of the dealer to choose the types of piles used during each round of shuffle. We prove by a sequence of reductions from the Boolean satisfiability problem (SAT) that the more general problem is NP-Hard. We leave as an open question the complexity of its arguably more natural companion, but discuss avenues for further investigation. Our analysis leverages a novel framework, introduced herein, which equates instances of shuffle to members of a particular class of deterministic finite automata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05518v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle B. Treleaven</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Claw-Free Vertex Splitting</title>
      <link>https://arxiv.org/abs/2506.06044</link>
      <description>arXiv:2506.06044v1 Announce Type: new 
Abstract: Vertex splitting consists of taking a vertex v in a graph and replacing it with two vertices whose combined neighborhoods is the neighborhood of v. The split is said to be exclusive when these neighborhoods are disjoint. In the (Exclusive) Claw-Free Vertex Splitting problem, we are given a graph G and an integer k, and we are asked if we can find a subset of at most k vertices whose (exclusive) splitting can make G claw-free. We consider the complexity of Exclusive Claw-Free Vertex Splitting and prove it to be NP-complete in general, while admitting a polynomial-time algorithm when the input graph has maximum degree four. This result settles an open problem posed in [Firbas \&amp; Sorge, ISAAC 2024]. On the positive side, we show that Claw-Free Vertex Splitting is fixed-parameter tractable by providing a cubic-order kernel. We also show that our results can be generalized to $K_{1,c}$-Free Vertex Splitting for all $c \geq 3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06044v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faisal N. Abu-Khzam, Sergio Thoumi</dc:creator>
    </item>
    <item>
      <title>An extension of Dembo-Hammer's reduction algorithm for the 0-1 knapsack problem</title>
      <link>https://arxiv.org/abs/2506.06138</link>
      <description>arXiv:2506.06138v1 Announce Type: new 
Abstract: Dembo-Hammer's Reduction Algorithm (DHR) is one of the classical algorithms for the 0-1 Knapsack Problem (0-1 KP) and its variants, which reduces an instance of the 0-1 KP to a sub-instance of smaller size with reduction time complexity $O(n)$. We present an extension of DHR (abbreviated as EDHR), which reduces an instance of 0-1 KP to at most $n^i$ sub-instances for any positive integer $i$. In practice, $i$ can be set as needed. In particular, if we choose $i=1$ then EDHR is exactly DHR. Finally, computational experiments on randomly generated data instances demonstrate that EDHR substantially reduces the search tree size compared to CPLEX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06138v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yang Yang</dc:creator>
    </item>
    <item>
      <title>An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds</title>
      <link>https://arxiv.org/abs/2506.06259</link>
      <description>arXiv:2506.06259v1 Announce Type: cross 
Abstract: Bandeira et al. (2022) introduced the Franz-Parisi (FP) criterion for characterizing the computational hard phases in statistical detection problems. The FP criterion, based on an annealed version of the celebrated Franz-Parisi potential from statistical physics, was shown to be equivalent to low-degree polynomial (LDP) lower bounds for Gaussian additive models, thereby connecting two distinct approaches to understanding the computational hardness in statistical inference. In this paper, we propose a refined FP criterion that aims to better capture the geometric ``overlap" structure of statistical models. Our main result establishes that this optimized FP criterion is equivalent to Statistical Query (SQ) lower bounds -- another foundational framework in computational complexity of statistical inference. Crucially, this equivalence holds under a mild, verifiable assumption satisfied by a broad class of statistical models, including Gaussian additive models, planted sparse models, as well as non-Gaussian component analysis (NGCA), single-index (SI) models, and convex truncation detection settings. For instance, in the case of convex truncation tasks, the assumption is equivalent with the Gaussian correlation inequality (Royen, 2014) from convex geometry.
  In addition to the above, our equivalence not only unifies and simplifies the derivation of several known SQ lower bounds -- such as for the NGCA model (Diakonikolas et al., 2017) and the SI model (Damian et al., 2024) -- but also yields new SQ lower bounds of independent interest, including for the computational gaps in mixed sparse linear regression (Arpino et al., 2023) and convex truncation (De et al., 2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06259v1</guid>
      <category>math.ST</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.CC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Chen, Theodor Misiakiewicz, Ilias Zadik, Peiyuan Zhang</dc:creator>
    </item>
    <item>
      <title>Finitely (In)tractable Promise Constraint Satisfaction Problems</title>
      <link>https://arxiv.org/abs/2010.04618</link>
      <description>arXiv:2010.04618v2 Announce Type: replace 
Abstract: The Promise Constraint Satisfaction Problem (PCSP) is a generalization of the Constraint Satisfaction Problem (CSP) that includes approximation variants of satisfiability and graph coloring problems. Barto [LICS '19] has shown that a specific PCSP, the problem to find a valid Not-All-Equal solution to a 1-in-3-SAT instance, is not finitely tractable in that it can be solved by a trivial reduction to a tractable CSP, but such a CSP is necessarily over an infinite domain (unless P=NP). We initiate a systematic study of this phenomenon by giving a general necessary condition for finite tractability and characterizing finite tractability within a class of templates - the "basic" tractable cases in the dichotomy theorem for symmetric Boolean PCSPs allowing negations by Brakensiek and Guruswami [SODA'18].</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.04618v2</guid>
      <category>cs.CC</category>
      <category>math.LO</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kristina Asimi, Libor Barto</dc:creator>
    </item>
    <item>
      <title>Computing $p$-presentation distances is hard</title>
      <link>https://arxiv.org/abs/2403.07200</link>
      <description>arXiv:2403.07200v2 Announce Type: replace-cross 
Abstract: Recently, $p$-presentation distances for $p\in [1,\infty]$ were introduced for merge trees and multiparameter persistence modules as more sensitive variations of the respective interleaving distances ($p=\infty)$. It is well-known that computing the interleaving distance is NP-hard in both cases. We extend this result by showing that computing the $p$-presentation distance is NP-hard for all $p\in [1,\infty)$ for both merge trees and $t$-parameter persistence modules for any $t\geq 2$. Though the details differ, both proofs follow the same novel strategy, suggesting that our approach can be adapted to proving the NP-hardness of other distances based on sums or $p$-norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07200v2</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <category>math.RT</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H{\aa}vard Bakke Bjerkevik, Magnus Bakke Botnan</dc:creator>
    </item>
    <item>
      <title>Computational Limits of Low-Rank Adaptation (LoRA) Fine-Tuning for Transformer Models</title>
      <link>https://arxiv.org/abs/2406.03136</link>
      <description>arXiv:2406.03136v2 Announce Type: replace-cross 
Abstract: We study the computational limits of Low-Rank Adaptation (LoRA) for finetuning transformer-based models using fine-grained complexity theory. Our key observation is that the existence of low-rank decompositions within the gradient computation of LoRA adaptation leads to possible algorithmic speedup. This allows us to (i) identify a phase transition behavior of efficiency assuming the Strong Exponential Time Hypothesis (SETH), and (ii) prove the existence of almost linear algorithms by controlling the LoRA update computation term by term. For the former, we identify a sharp transition in the efficiency of all possible rank-$r$ LoRA update algorithms for transformers, based on specific norms resulting from the multiplications of the input sequence $X$, pretrained weights ${W^\star}$, and adapter matrices $\alpha B A/r$. Specifically, we derive a shared upper bound threshold for such norms, and show that efficient (sub-quadratic) approximation algorithms of LoRA exist only below this threshold. For the latter, we prove the existence of almost linear approximation algorithms for LoRA adaptation by utilizing the hierarchical low-rank structures of LoRA gradients and approximating the gradients with a series of chained low-rank approximations. To showcase our theory, we consider two practical scenarios: partial (e.g., only $W_V$ and $W_Q$) and full adaptations (e.g., $W_Q$, $W_V$, and $W_K$) of weights in attention heads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03136v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jerry Yao-Chieh Hu, Maojiang Su, En-Jui Kuo, Zhao Song, Han Liu</dc:creator>
    </item>
    <item>
      <title>Testing and learning structured quantum Hamiltonians</title>
      <link>https://arxiv.org/abs/2411.00082</link>
      <description>arXiv:2411.00082v2 Announce Type: replace-cross 
Abstract: We consider the problems of testing and learning an unknown $n$-qubit Hamiltonian $H$ from queries to its evolution operator $e^{-iHt}$ under the normalized Frobenius norm. We prove:
  1. Local Hamiltonians: We give a tolerant testing protocol to decide if $H$ is $\epsilon_1$-close to $k$-local or $\epsilon_2$-far from $k$-local, with $O(1/(\epsilon_2-\epsilon_1)^{4})$ queries, solving open questions posed in a recent work by Bluhm et al. For learning a $k$-local $H$ up to error $\epsilon$, we give a protocol with query complexity $\exp(O(k^2+k\log(1/\epsilon)))$ independent of $n$, by leveraging the non-commutative Bohnenblust-Hille inequality.
  2. Sparse Hamiltonians: We give a protocol to test if $H$ is $\epsilon_1$-close to being $s$-sparse (in the Pauli basis) or $\epsilon_2$-far from being $s$-sparse, with $O(s^{6}/(\epsilon_2^2-\epsilon_1^2)^{6})$ queries. For learning up to error $\epsilon$, we show that $O(s^{4}/\epsilon^{8})$ queries suffice.
  3. Learning without memory: The learning results stated above have no dependence on $n$, but require $n$-qubit quantum memory. We give subroutines that allow us to learn without memory; increasing the query complexity by a $(\log n)$-factor in the local case and an $n$-factor in the sparse case.
  4. Testing without memory: We give a new subroutine called Pauli hashing, which allows one to tolerantly test $s$-sparse Hamiltonians with $O(s^{14}/(\epsilon_2^2-\epsilon_1^2)^{18})$ queries. A key ingredient is showing that $s$-sparse Pauli channels can be tolerantly tested under the diamond norm with $O(s^2/(\epsilon_2-\epsilon_1)^6)$ queries.
  Along the way, we prove new structural theorems for local and sparse Hamiltonians. We complement our learning results with polynomially weaker lower bounds. Furthermore, our algorithms use short time evolutions and do not assume prior knowledge of the terms in the support of the Pauli spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00082v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Srinivasan Arunachalam, Arkopal Dutt, Francisco Escudero Guti\'errez</dc:creator>
    </item>
    <item>
      <title>The Jacobi Factoring Circuit: Quantum Factoring with Near-Linear Gates and Sublinear Space and Depth</title>
      <link>https://arxiv.org/abs/2412.12558</link>
      <description>arXiv:2412.12558v3 Announce Type: replace-cross 
Abstract: We present a compact quantum circuit for factoring a large class of integers, including some whose classical hardness is expected to be equivalent to RSA (but not including RSA integers themselves). Most notably, we factor $n$-bit integers of the form $P^2 Q$ with $\log Q = \Theta(n^a)$ for $a \in (2/3, 1)$ in space and depth sublinear in n (specifically, $\tilde{O}(\log Q)$) using $\tilde{O}(n)$ quantum gates; for these integers, no known classical algorithms exploit the relatively small size of $Q$ to run asymptotically faster than general-purpose factoring algorithms. To our knowledge, this is the first polynomial-time circuit to achieve sublinear qubit count for a classically-hard factoring problem. We thus believe that factoring such numbers has potential to be the most concretely efficient classically-verifiable proof of quantumness currently known.
  Our circuit builds on the quantum algorithm for squarefree decomposition discovered by Li, Peng, Du, and Suter (Nature Scientific Reports 2012), which relies on computing the Jacobi symbol in quantum superposition. The technical core of our contribution is a new space-efficient quantum algorithm to compute the Jacobi symbol of $A$ mod $B$, in the regime where $B$ is classical and much larger than $A$. Our circuit for computing the Jacobi symbol generalizes to related problems such as computing the greatest common divisor and modular inverses, and thus could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12558v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory D. Kahanamoku-Meyer, Seyoon Ragavan, Vinod Vaikuntanathan, Katherine Van Kirk</dc:creator>
    </item>
  </channel>
</rss>
