<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Jun 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement</title>
      <link>https://arxiv.org/abs/2506.20783</link>
      <description>arXiv:2506.20783v1 Announce Type: new 
Abstract: Extremely large antenna arrays (ELAAs) operating in high-frequency bands have spurred the development of near-field communication, driving advancements in beam training and signal processing design. In this work, we present a low-complexity near-field beam training scheme that fully utilizes the conventional discrete Fourier transform (DFT) codebook designed for far-field users. We begin by analyzing the received beam pattern in the near field and derive closed-form expressions for the beam width and central gain. These analytical results enable the definition of an angle-dependent, modified Rayleigh distance, which effectively distinguishes near-field and far-field user regimes. Building on the analysis, we develop a direct and computationally efficient method to estimate user distance, with a complexity of O(1), and further improve its accuracy through a simple refinement. Simulation results demonstrate significant gains in both single- and multi-user settings, with up to 2.38 dB SNR improvement over exhaustive search. To further enhance estimation accuracy, we additionally propose a maximum likelihood estimation (MLE) based refinement method, leveraging the Rician distribution of signal amplitudes and achieving accuracy close to the Cramer--Rao bound (CRB). Simulation shows the single-user and multi-user achievable rates can both approach those obtained with ideal channel state information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20783v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijun Wang, Shawn Tsai, Rama Kiran, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links</title>
      <link>https://arxiv.org/abs/2506.20798</link>
      <description>arXiv:2506.20798v1 Announce Type: new 
Abstract: Entanglement-based quantum key distribution (QKD) protocols, such as E91 and BBM92, offer strong information-theoretic security and are naturally suited for satellite-to-satellite QKD (SatQKD) links. However, implementing these protocols over long-distance inter-satellite free-space optical (FSO) channels poses critical physical-layer challenges that are not addressed in the existing literature. In particular, photon losses due to beam divergence, pointing errors, and background noise can severely degrade the key generation rate and quantum bit error rate (QBER), especially under narrow receiver field-of-view (FoV) constraints. This paper presents a comprehensive performance analysis of entanglement-based inter-satellite QKD, focusing on photon-level modeling and the impact of practical impairments. We develop analytical expressions for signal detection probabilities, background photon influence, multi-pair emissions, and QBER, incorporating key parameters such as link distance, transmitter tracking jitter, receiver misalignment, and photon pair generation rate. Simulation results reveal the nonlinear sensitivity of system performance to tracking error and FoV limitations, and highlight optimal parameter regimes that jointly maximize secret key rate while maintaining QBER below acceptable thresholds. The proposed model provides actionable design insights for reliable and efficient deployment of entanglement-based SatQKD systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20798v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Taghi Dabiri, Mazen Hasna, Saif Al-Kuwari, Khalid Qaraqe</dc:creator>
    </item>
    <item>
      <title>Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links</title>
      <link>https://arxiv.org/abs/2506.20823</link>
      <description>arXiv:2506.20823v1 Announce Type: new 
Abstract: This paper presents an efficient analytical framework for evaluating the performance of inter-satellite communication systems utilizing orbital angular momentum (OAM) beams under pointing errors. An accurate analytical model is first developed to characterize intermodal crosstalk caused by beam misalignment in OAM-based inter-satellite links. Building upon this model, we derive efficient expressions to analyze and optimize system performance in terms of bit error rate (BER). Unlike traditional Monte Carlo-based methods that are computationally intensive, the proposed approach offers accurate performance predictions. This enables a substantial decrease in computation time while maintaining high accuracy, thanks to the use of analytical expressions for both crosstalk and BER. This fast and accurate evaluation capability is particularly critical for dynamic low Earth orbit (LEO) satellite constellations, where network topology and channel conditions change rapidly, requiring real-time link adaptation. Furthermore, we systematically design and evaluate asymmetric OAM mode sets, which significantly outperform symmetric configurations in the presence of pointing errors. Our results also reveal key insights into the interaction between beam divergence, tracking accuracy, and link distance, demonstrating that the proposed framework enables real-time optimization of system parameters with high fidelity. The analytical findings are rigorously validated against extensive Monte Carlo simulations, confirming their practical applicability for high-mobility optical wireless systems such as LEO satellite networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20823v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Taghi Dabiri, Mazen Hasna</dc:creator>
    </item>
    <item>
      <title>Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications</title>
      <link>https://arxiv.org/abs/2506.20858</link>
      <description>arXiv:2506.20858v1 Announce Type: new 
Abstract: Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology has garnered significant interest as a connectivity solution for IoT applications due to its ability to offer low-cost, low-power, and long-range communications. One emerging use case of LoRa is DtS connectivity, which extends coverage to remote areas for supporting IoT operations. The satellite IoT industry mainly prefers LEO because it has lower launch costs and less path loss compared to Geostationary orbit. However, a major drawback of LEO satellites is the impact of the Doppler effect caused by their mobility. Earlier studies have confirmed that the Doppler effect significantly degrades the LoRa DtS performance. In this paper, we propose four frameworks for Doppler estimation and compensation in LoRa DtS connectivity and numerically compare the performance against the ideal scenario without the Doppler effect. Furthermore, we investigate the trade-offs among these frameworks by analyzing the interplay between spreading factor, and other key parameters related to the Doppler effect. The results provide insights into how to achieve robust LoRa configurations for DtS connectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20858v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jamil Farhat, Gianni Pasolini, Enrico Paolini, Muhammad Asad Ullah, Richard Demo Souza</dc:creator>
    </item>
    <item>
      <title>Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications</title>
      <link>https://arxiv.org/abs/2506.20863</link>
      <description>arXiv:2506.20863v1 Announce Type: new 
Abstract: Quantum computing is poised to redefine the algorithmic foundations of communication systems. While quantum superposition and entanglement enable quadratic or exponential speedups for specific problems, identifying use cases where these advantages yield engineering benefits is, however, still nontrivial. This article presents the fundamentals of quantum computing in a style familiar to the communications society, outlining the current limits of fault-tolerant quantum computing and uncovering a mathematical harmony between quantum and wireless systems, which makes the topic more enticing to wireless researchers. Based on a systematic review of pioneering and state-of-the-art studies, we distill common design trends for the research and development of quantum-accelerated communication systems and highlight lessons learned. The key insight is that classical heuristics can sharpen certain quantum parameters, underscoring the complementary strengths of classical and quantum computing. This article aims to catalyze interdisciplinary research at the frontier of quantum information processing and future communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20863v1</guid>
      <category>eess.SP</category>
      <category>quant-ph</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Naoki Ishikawa, Giuseppe Thadeu Freitas de Abreu, Petar Popovski, Robert W. Heath Jr</dc:creator>
    </item>
    <item>
      <title>Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks</title>
      <link>https://arxiv.org/abs/2506.20970</link>
      <description>arXiv:2506.20970v1 Announce Type: new 
Abstract: The rapid advancement of Internet of Things (IoT) services and the evolution toward the sixth generation (6G) have positioned unmanned aerial vehicles (UAVs) as critical enablers of low-altitude wireless networks (LAWNs). This work investigates the co-design of integrated sensing, communication, and control ($\mathbf{SC^{2}}$) for multi-UAV cooperative systems with finite blocklength (FBL) transmission. In particular, the UAVs continuously monitor the state of the field robots and transmit their observations to the robot controller to ensure stable control while cooperating to localize an unknown sensing target (ST). To this end, a weighted optimization problem is first formulated by jointly considering the control and localization performance in terms of the linear quadratic regulator (LQR) cost and the determinant of the Fisher information matrix (FIM), respectively. The resultant problem, optimizing resource allocations, the UAVs' deployment positions, and multi-user scheduling, is non-convex. To circumvent this challenge, we first derive a closed-form expression of the LQR cost with respect to other variables. Subsequently, the non-convex optimization problem is decomposed into a series of sub-problems by leveraging the alternating optimization (AO) approach, in which the difference of convex functions (DC) programming and projected gradient descent (PGD) method are employed to obtain an efficient near-optimal solution. Furthermore, the convergence and computational complexity of the proposed algorithm are thoroughly analyzed. Extensive simulation results are presented to validate the effectiveness of our proposed approach compared to the benchmark schemes and reveal the trade-off between control and sensing performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20970v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haijia Jin, Jun Wu, Weijie Yuan, Fan Liu, Yuanhao Cui</dc:creator>
    </item>
    <item>
      <title>Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays</title>
      <link>https://arxiv.org/abs/2506.21043</link>
      <description>arXiv:2506.21043v1 Announce Type: new 
Abstract: A differential microphone array (DMA) offers enhanced capabilities to obtain sharp nulls at the cost of relatively broad peaks in the beam power pattern. This can be used for applications that require nullification or attenuation of interfering sources. To the best of our knowledge, the existing literature lacks measures that directly assess the efficacy of nulls, and null-related measures have not been investigated in the context of differential microphone arrays (DMAs). This paper offers new insights about the utility of DMAs by proposing measures that characterize the nulls in their beam power patterns. We investigate the performance of differential beamformers by presenting and evaluating null-related measures namely null depth (ND) and Null Width (NW) as a function of depth level relative to the beam power pattern maxima. A study of signal quantization effects due to data acquisition for 1st, 2nd and 3rd order linear DMAs and for different beampatterns i.e. dipole, cardioid, hypercardioid and supercardioid is presented. An analytical expression for the quantized beamformed output for any general $ N^{th} $ order DMA is formulated. Simulation results of the variation of ND with number of quantization bits and the variation of NW as a function of depth are also presented and inferences are drawn. Lab experiments are conducted in a fully anechoic room to support the simulation results. The measured beampattern exhibits a pronounced null depth, confirming the effectiveness of the experimental setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21043v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shweta Pal, Arun Kumar, Monika Agrawal</dc:creator>
    </item>
    <item>
      <title>Point Cloud Environment-Based Channel Knowledge Map Construction</title>
      <link>https://arxiv.org/abs/2506.21112</link>
      <description>arXiv:2506.21112v1 Announce Type: new 
Abstract: Channel knowledge map (CKM) provides certain levels of channel state information (CSI) for an area of interest, serving as a critical enabler for environment-aware communications by reducing the overhead of frequent CSI acquisition. However, existing CKM construction schemes adopt over-simplified environment information, which significantly compromises their accuracy. To address this issue, this work proposes a joint model- and data-driven approach to construct CKM by leveraging point cloud environmental data along with a few samples of location-tagged channel information. First, we propose a novel point selector to identify subsets of point cloud that contain environmental information relevant to multipath channel gains, by constructing a set of co-focal ellipsoids based on different time of arrival (ToAs). Then, we trained a neural channel gain estimator to learn the mapping between each selected subset and its corresponding channel gain, using a real-world dataset we collected through field measurements, comprising environmental point clouds and corresponding channel data. Finally, experimental results demonstrate that: For CKM construction of power delay profile (PDP), the proposed method achieves a root mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dB achieved by the conventional ray-tracing method; for CKM construction of received power values, i.e., radio map, it achieves an RMSE of 1.04 dB, surpassing the Kriging interpolation method with an RMSE of 1.68 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21112v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yancheng Wang, Wei Guo, Guanying Chen, Ye Zhang, Shuguang Cui</dc:creator>
    </item>
    <item>
      <title>Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels</title>
      <link>https://arxiv.org/abs/2506.21123</link>
      <description>arXiv:2506.21123v1 Announce Type: new 
Abstract: Rydberg atomic sensors have been adopted for novel radio frequency (RF) measurement technique and the sensing capability for signals in multiple frequencies makes it attractive for multi-user communication. However, unlike traditional antennas where the signals in multiple frequencies are orthogonal, the received signals of atomic sensors corresponding to different energy levels will be downconverted to the baseband simultaneously, resulting in multi-user interference. Thus, in this paper, we analyze the mutual interference characteristics of two RF signals with different carrier frequencies coupling different energy levels. We introduce the joint response coefficient based on the receiver characteristics and analyze the interference of one user to another. We analyze the bit-error rate (BER) and symbol-error rate (SER) for two signals coupling two different energy levels. We also conduct experiments to validate the BER and SER results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21123v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu, Chongwu Xie, Xinyuan Yao, Kang-Da Wu, Shanchi Wu, Rui Ni, Guo-Yong Xiang, Chen Gong</dc:creator>
    </item>
    <item>
      <title>Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation</title>
      <link>https://arxiv.org/abs/2506.21208</link>
      <description>arXiv:2506.21208v1 Announce Type: new 
Abstract: Deep neural networks (DNNs) have widespread applications for optimizing resource allocation. Yet, their performance is vulnerable to distribution shifts between training and test data, say channels. In this letter, we resort to adversarial training (AT) for enhancing out-of-distribution (OOD) generalizability of DNNs trained in unsupervised manner. We reformulate AT to capture the OOD degradation, and propose a one-step gradient ascent method for AT. The proposed method is validated by optimizing hybrid precoding. Simulation results showcase the enhanced OOD performance of multiple kinds of DNNs across various channel distributions, when only Rayleigh fading channels are used for training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21208v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengjie Liu, Chenyang Yang</dc:creator>
    </item>
    <item>
      <title>Localization-Based Beam Focusing in Near-Field Communications</title>
      <link>https://arxiv.org/abs/2506.21325</link>
      <description>arXiv:2506.21325v1 Announce Type: new 
Abstract: Shifting 6G-and-beyond wireless communication systems to higher frequency bands and the utilization of massive multiple-input multiple-output arrays will extend the near-field region, affecting beamforming and user localization schemes. In this paper, we propose a localization-based beam-focusing strategy that leverages the dominant line-of-sight (LoS) propagation arising at mmWave and sub-THz frequencies. To support this approach, we analyze the 2D-MUSIC algorithm for distance estimation by examining its spectrum in simplified, tractable setups with minimal numbers of antennas and users. Lastly, we compare the proposed localization-based beam focusing, with locations estimated via 2D-MUSIC, with zero forcing with pilot-based channel estimation in terms of uplink sum spectral efficiency. Our numerical results show that the proposed method becomes more effective under LoS-dominated propagation, short coherence blocks, and strong noise power arising at high carrier frequencies and with large bandwidths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21325v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nima Mozaffarikhosravi, Prathapasinghe Dharmawansa, Italo Atzeni</dc:creator>
    </item>
    <item>
      <title>Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement</title>
      <link>https://arxiv.org/abs/2506.21375</link>
      <description>arXiv:2506.21375v1 Announce Type: new 
Abstract: This paper investigates an intelligent reflecting surface (IRS)-aided movable antenna (MA) system, where multiple IRSs cooperate with a multi-MA base station to extend wireless coverage to multiple designated target areas. The objective is to maximize the worst-case signal-to-noise ratio (SNR) across all locations within these areas through joint optimization of MA positions, IRS reflection coefficients, and transmit beamforming. To achieve this while balancing the performance-cost trade-off, we propose three coverage-enhancement schemes: the area-adaptive MA-IRS scheme, the area-adaptive MA-staIRS scheme, and the shared MA-staIRS scheme, where staIRS denotes static IRSs with reflection coefficients configured only once during installation. These schemes lead to challenging non-convex optimization problems with implicit objective functions, which are difficult to solve optimally. To address these problems, we propose a general algorithmic framework that can be applied to solve each problem efficiently albeit suboptimally. Simulation results demonstrate that: 1) the proposed MA-based schemes consistently outperform their fixed-position antenna (FPA)-based counterparts under both area-adaptive and static IRS configurations, with the area-adaptive MA-IRS scheme achieving the best worst-case SNR performance; 2) as transmit antennas are typically far fewer than IRS elements, the area-adaptive MA-staIRS scheme may underperform the baseline FPA scheme with area-adaptive IRSs in terms of the worst-case SNR, but a modest increase in antenna number can reverse this trend; 3) under a fixed total cost, the optimal MA-to-IRS-element ratio for the worst-case SNR maximization is empirically found to be proportional to the reciprocal of their unit cost ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21375v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Gao, Qingqing Wu, Weidong Mei, Guangji Chen, Wen Chen, Ziyuan Zheng</dc:creator>
    </item>
    <item>
      <title>Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG</title>
      <link>https://arxiv.org/abs/2506.20683</link>
      <description>arXiv:2506.20683v1 Announce Type: cross 
Abstract: An electrocardiogram (ECG) is a widely used, cost-effective tool for detecting electrical abnormalities in the heart. However, it cannot directly measure functional parameters, such as ventricular volumes and ejection fraction, which are crucial for assessing cardiac function. Cardiac magnetic resonance (CMR) is the gold standard for these measurements, providing detailed structural and functional insights, but is expensive and less accessible. To bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive Learning), a multimodal contrastive learning framework that enhances ECG representations by integrating spatio-temporal information from CMR. PTACL uses global patient-level contrastive loss and local temporal-level contrastive loss. The global loss aligns patient-level representations by pulling ECG and CMR embeddings from the same patient closer together, while pushing apart embeddings from different patients. Local loss enforces fine-grained temporal alignment within each patient by contrasting encoded ECG segments with corresponding encoded CMR frames. This approach enriches ECG representations with diagnostic information beyond electrical activity and transfers more insights between modalities than global alignment alone, all without introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL achieves better performance in two clinically relevant tasks: (1) retrieving patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac function parameters, such as ventricular volumes and ejection fraction. Our results highlight the potential of PTACL to enhance non-invasive cardiac diagnostics using ECG. The code is available at: https://github.com/alsalivan/ecgcmr</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20683v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Selivanov, Philip M\"uller, \"Ozg\"un Turgut, Nil Stolt-Ans\'o, Daniel R\"uckert</dc:creator>
    </item>
    <item>
      <title>Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks</title>
      <link>https://arxiv.org/abs/2506.20762</link>
      <description>arXiv:2506.20762v1 Announce Type: cross 
Abstract: In this paper, we propose a novel drift-adaptive slicing-based resource management scheme for cooperative integrated sensing and communication (ISAC) networks. Particularly, we establish two network slices to provide sensing and communication services, respectively. In the large-timescale planning for the slices, we partition the sensing region of interest (RoI) of each mobile device and reserve network resources accordingly, facilitating low-complexity distance-based sensing target assignment in small timescales. To cope with the non-stationary spatial distributions of mobile devices and sensing targets, which can result in the drift in modeling the distributions and ineffective planning decisions, we construct digital twins (DTs) of the slices. In each DT, a drift-adaptive statistical model and an emulation function are developed for the spatial distributions in the corresponding slice, which facilitates closed-form decision-making and efficient validation of a planning decision, respectively. Numerical results show that the proposed drift-adaptive slicing-based resource management scheme can increase the service satisfaction ratio by up to 18% and reduce resource consumption by up to 13.1% when compared with benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20762v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shisheng Hu, Jie Gao, Xue Qin, Conghao Zhou, Xinyu Huang, Mushu Li, Mingcheng He, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing</title>
      <link>https://arxiv.org/abs/2506.20782</link>
      <description>arXiv:2506.20782v1 Announce Type: cross 
Abstract: We present the first theoretical framework for applying spiking neural networks (SNNs) to synthetic aperture radar (SAR) interferometric phase unwrapping. Despite extensive research in both domains, our comprehensive literature review confirms that SNNs have never been applied to phase unwrapping, representing a significant gap in current methodologies. As Earth observation data volumes continue to grow exponentially (with missions like NISAR expected to generate 100PB in two years) energy-efficient processing becomes critical for sustainable data center operations. SNNs, with their event-driven computation model, offer potential energy savings of 30-100x compared to conventional approaches while maintaining comparable accuracy. We develop spike encoding schemes specifically designed for wrapped phase data, propose SNN architectures that leverage the spatial propagation nature of phase unwrapping, and provide theoretical analysis of computational complexity and convergence properties. Our framework demonstrates how the temporal dynamics inherent in SNNs can naturally model the spatial continuity constraints fundamental to phase unwrapping. This work opens a new research direction at the intersection of neuromorphic computing and SAR interferometry, offering a complementary approach to existing algorithms that could enable more sustainable large-scale InSAR processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20782v1</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Bara</dc:creator>
    </item>
    <item>
      <title>FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs</title>
      <link>https://arxiv.org/abs/2506.20810</link>
      <description>arXiv:2506.20810v1 Announce Type: cross 
Abstract: Recurrent neural networks (RNNs), particularly LSTMs, are effective for time-series tasks like sentiment analysis and short-term stock prediction. However, their computational complexity poses challenges for real-time deployment in resource constrained environments. While FPGAs offer a promising platform for energy-efficient AI acceleration, existing tools mainly target feed-forward networks, and LSTM acceleration typically requires full custom implementation. In this paper, we address this gap by leveraging the open-source and extensible FINN framework to enable the generalized deployment of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open Neural Network Exchange (ONNX) specification to model the recurrent nature of LSTM computations, enabling support for mixed quantisation within them and functional verification of LSTM-based models. Furthermore, we introduce custom transformations within the FINN compiler to map the quantised ONNX computation graph to hardware blocks from the HLS kernel library of the FINN compiler and Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM model for a mid-price stock prediction task using the widely used dataset and generating a corresponding hardware IP of the model using our flow, targeting the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator through our flow achieves a balance between performance (latency) and resource consumption, while matching (or bettering) inference accuracy of state-of-the-art models with reduced precision. We believe that the generalisable nature of the proposed flow will pave the way for resource-efficient RNN accelerator designs on FPGAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20810v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashwat Khandelwal, Jakoba Petri-Koenig, Thomas B. Preu{\ss}er, Michaela Blott, Shreejith Shanker</dc:creator>
    </item>
    <item>
      <title>Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management</title>
      <link>https://arxiv.org/abs/2506.20853</link>
      <description>arXiv:2506.20853v1 Announce Type: cross 
Abstract: The time allocation problem in multi-function cognitive radar systems focuses on the trade-off between scanning for newly emerging targets and tracking the previously detected targets. We formulate this as a multi-objective optimization problem and employ deep reinforcement learning to find Pareto-optimal solutions and compare deep deterministic policy gradient (DDPG) and soft actor-critic (SAC) algorithms. Our results demonstrate the effectiveness of both algorithms in adapting to various scenarios, with SAC showing improved stability and sample efficiency compared to DDPG. We further employ the NSGA-II algorithm to estimate an upper bound on the Pareto front of the considered problem. This work contributes to the development of more efficient and adaptive cognitive radar systems capable of balancing multiple competing objectives in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20853v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyang Lu, Subodh Kalia, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney</dc:creator>
    </item>
    <item>
      <title>Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications</title>
      <link>https://arxiv.org/abs/2506.21078</link>
      <description>arXiv:2506.21078v1 Announce Type: cross 
Abstract: Integrated sensing and communications (ISAC) is considered a key enabler to support application scenarios such as the Internet-of-Things (IoT) in which both communications and sensing play significant roles. Multi-carrier waveforms, such as orthogonal frequency division multiplexing (OFDM), have been considered as good candidates for ISAC due to their high communications data rate and good time bandwidth property for sensing. Nevertheless, their high peak-to-average-power-ratio (PAPR) values lead to either performance degradation or an increase in system complexity. This can make OFDM unsuitable for IoT applications with insufficient resources in terms of power, system complexity, hardware size or cost. This article provides IoT-centric constant modulus waveform designs that leverage the advantage of unit PAPR and thus are more suitable in resource-limited scenarios. More specifically, several single-carrier frequency and/or phase-modulated waveforms are considered. A comprehensive discussion on their radar sensing and communications performance is conducted based on performance metrics, including the radar ambiguity function, the bandwidth property, the data rate, and the communications receiver complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21078v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tian Han, Shalanika Dayarathna, Rajitha Senanayake, Peter Smith, Aryan Kaushik, Alain Mourad, Richard A. Stirling-Gallacher, Jamie Evans</dc:creator>
    </item>
    <item>
      <title>Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection</title>
      <link>https://arxiv.org/abs/2506.21093</link>
      <description>arXiv:2506.21093v1 Announce Type: cross 
Abstract: Transformers have shown potential in solving wireless communication problems, particularly via in-context learning (ICL), where models adapt to new tasks through prompts without requiring model updates. However, prior ICL-based Transformer models rely on deep architectures with many layers to achieve satisfactory performance, resulting in substantial storage and computational costs. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a CoT-enhanced shallow Transformer framework for wireless symbol detection. By introducing autoregressive latent reasoning steps within the hidden space, CHOOSE significantly improves the reasoning capacity of shallow models (1-2 layers) without increasing model depth. This design enables lightweight Transformers to achieve detection performance comparable to much deeper models, making them well-suited for deployment on resource-constrained mobile devices. Experimental results demonstrate that our approach outperforms conventional shallow Transformers and achieves performance comparable to that of deep Transformers, while maintaining storage and computational efficiency. This represents a promising direction for implementing Transformer-based algorithms in wireless receivers with limited computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21093v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Fan, Peng Wang, Jing Yang, Cong Shen</dc:creator>
    </item>
    <item>
      <title>MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification</title>
      <link>https://arxiv.org/abs/2506.21199</link>
      <description>arXiv:2506.21199v1 Announce Type: cross 
Abstract: Current medical image analysis systems are typically task-specific, requiring separate models for classification and segmentation, and lack the flexibility to support user-defined workflows. To address these challenges, we introduce MedPrompt, a unified framework that combines a few-shot prompted Large Language Model (Llama-4-17B) for high-level task planning with a modular Convolutional Neural Network (DeepFusionLab) for low-level image processing. The LLM interprets user instructions and generates structured output to dynamically route task-specific pretrained weights. This weight routing approach avoids retraining the entire framework when adding new tasks-only task-specific weights are required, enhancing scalability and deployment. We evaluated MedPrompt across 19 public datasets, covering 12 tasks spanning 5 imaging modalities. The system achieves a 97% end-to-end correctness in interpreting and executing prompt-driven instructions, with an average inference latency of 2.5 seconds, making it suitable for near real-time applications. DeepFusionLab achieves competitive segmentation accuracy (e.g., Dice 0.9856 on lungs) and strong classification performance (F1 0.9744 on tuberculosis). Overall, MedPrompt enables scalable, prompt-driven medical imaging by combining the interpretability of LLMs with the efficiency of modular CNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21199v1</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shadman Sobhan, Kazi Abrar Mahmud, Abduz Zami</dc:creator>
    </item>
    <item>
      <title>Cluster-Aware Two-Stage Method for Fast Iterative MIMO Detection in LEO Satellite Communications</title>
      <link>https://arxiv.org/abs/2506.21370</link>
      <description>arXiv:2506.21370v1 Announce Type: cross 
Abstract: In this paper, a cluster-aware two-stage multiple-input multiple-output (MIMO) detection method is proposed for direct-to-cell satellite communications. The method achieves computational efficiency by exploiting a distinctive property of satellite MIMO channels: users within the same geographical cluster exhibit highly correlated channel characteristics due to their physical proximity, which typically impedes convergence in conventional iterative MIMO detectors. The proposed method implements a two-stage strategy that first eliminates intra-cluster interference using computationally efficient small matrix inversions, then utilizes these pre-computed matrices to accelerate standard iterative MIMO detectors such as Gauss-Seidel (GS) and symmetric successive over-relaxation (SSOR) for effective inter-cluster interference cancellation. Computer simulations demonstrate that the proposed method achieves more than 12 times faster convergence under perfect channel state information. Even when accounting for channel estimation errors, the method maintains 9 times faster convergence, demonstrating its robustness and effectiveness for next-generation satellite MIMO communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21370v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiuyu Liu, Yi Ma, Qihao Peng, Rahim Tafazolli</dc:creator>
    </item>
    <item>
      <title>Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings</title>
      <link>https://arxiv.org/abs/2506.21386</link>
      <description>arXiv:2506.21386v1 Announce Type: cross 
Abstract: Arabic dialect recognition presents a significant challenge in speech technology due to the linguistic diversity of Arabic and the scarcity of large annotated datasets, particularly for underrepresented dialects. This research investigates hybrid modeling strategies that integrate classical signal processing techniques with deep learning architectures to address this problem in low-resource scenarios. Two hybrid models were developed and evaluated: (1) Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered subset of the Common Voice Arabic dataset, with dialect labels assigned based on speaker metadata. Experimental results demonstrate that the MFCC + CNN architecture achieved superior performance, with an accuracy of 91.2% and strong precision, recall, and F1-scores, significantly outperforming the Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These findings highlight the effectiveness of leveraging spectral features with convolutional models for Arabic dialect recognition, especially when working with limited labeled data. The study also identifies limitations related to dataset size, potential regional overlaps in labeling, and model optimization, providing a roadmap for future research. Recommendations for further improvement include the adoption of larger annotated corpora, integration of self-supervised learning techniques, and exploration of advanced neural architectures such as Transformers. Overall, this research establishes a strong baseline for future developments in Arabic dialect recognition within resource-constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21386v1</guid>
      <category>eess.AS</category>
      <category>cs.CL</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ghazal Al-Shwayyat, Omer Nezih Gerek</dc:creator>
    </item>
    <item>
      <title>Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform</title>
      <link>https://arxiv.org/abs/2506.21440</link>
      <description>arXiv:2506.21440v1 Announce Type: cross 
Abstract: The short-time Fourier transform (STFT) is widely used for analyzing non-stationary signals. However, its performance is highly sensitive to its parameters, and manual or heuristic tuning often yields suboptimal results. To overcome this limitation, we propose a unified differentiable formulation of the STFT that enables gradient-based optimization of its parameters. This approach addresses the limitations of traditional STFT parameter tuning methods, which often rely on computationally intensive discrete searches. It enables fine-tuning of the time-frequency representation (TFR) based on any desired criterion. Moreover, our approach integrates seamlessly with neural networks, allowing joint optimization of the STFT parameters and network weights. The efficacy of the proposed differentiable STFT in enhancing TFRs and improving performance in downstream tasks is demonstrated through experiments on both simulated and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21440v1</guid>
      <category>cs.SD</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxime Leiber, Yosra Marnissi, Axel Barrau, Sylvain Meignen, Laurent Massouli\'e</dc:creator>
    </item>
    <item>
      <title>Exploiting Spatial and Temporal Correlations in Massive MIMO Systems Operating Over Non-Stationary Aging Channels</title>
      <link>https://arxiv.org/abs/2405.07882</link>
      <description>arXiv:2405.07882v3 Announce Type: replace 
Abstract: This work investigates a multi-user, multi-antenna uplink wireless system, in which multiple users transmit signals to a base station. Prior research has explored the potential for linear growth in spectral efficiency by employing multiple transmit and receive antennas. This gain depends heavily on the quality of channel state information and the number of uncorrelated antennas. However, spatial correlations, arising from closely-spaced antennas and channel aging effects -- stemming from the difference between the channel state at pilot and data time instances -- can substantially counteract these benefits, and degrade the transmission rate, especially in non-stationary environments. To address these challenges, this work introduces a real-time beamforming framework to compensate for the spatial correlation and channel aging effects. First, a channel estimation scheme leveraging temporal channel correlations and considering mobile device velocity and antenna spacing is developed. Subsequently, an expression approximating the average spectral efficiency -- which depends on pilot spacing, pilot and data powers, and beamforming vectors -- is obtained. By maximizing this expression, optimal parameters are identified. Numerical results demonstrate the effectiveness of the proposed approach compared to prior works. Interestingly, the optimal pilot spacing remains unaffected by large-scale channel parameters and the velocities of interfering users. The impact of interference components also diminishes with an increasing number of transmit antennas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07882v3</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sajad Daei, Gabor Fodor, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Radio Map Estimation via Latent Domain Plug-and-Play Denoising</title>
      <link>https://arxiv.org/abs/2501.13472</link>
      <description>arXiv:2501.13472v2 Announce Type: replace 
Abstract: Radio map estimation (RME), also known as spectrum cartography, aims to reconstruct the strength of radio interference across different domains (e.g., space and frequency) from sparsely sampled measurements. To tackle this typical inverse problem, state-of-the-art RME methods rely on handcrafted or data-driven structural information of radio maps. However, the former often struggles to model complex radio frequency (RF) environments and the latter requires excessive training -- making it hard to quickly adapt to in situ sensing tasks. This work presents a spatio-spectral RME approach based on plug-and-play (PnP) denoising, a technique from computational imaging. The idea is to leverage the observation that the denoising operations of signals like natural images and radio maps are similar -- despite the nontrivial differences of the signals themselves. Hence, sophisticated denoisers designed for or learned from natural images can be directly employed to assist RME, avoiding using radio map data for training. Unlike conventional PnP methods that operate directly in the data domain, the proposed method exploits the underlying physical structure of radio maps and proposes an ADMM algorithm that denoises in a latent domain. This design significantly improves computational efficiency and enhances noise robustness. Theoretical aspects, e.g., recoverability of the complete radio map and convergence of the ADMM algorithm are analyzed. Synthetic and real data experiments are conducted to demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13472v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Le Xu, Lei Cheng, Junting Chen, Wenqiang Pu, Xiao Fu</dc:creator>
    </item>
    <item>
      <title>Context-Aware Doubly-Robust Semi-Supervised Learning</title>
      <link>https://arxiv.org/abs/2502.15577</link>
      <description>arXiv:2502.15577v2 Announce Type: replace 
Abstract: The widespread adoption of artificial intelligence (AI) in next-generation communication systems is challenged by the heterogeneity of traffic and network conditions, which call for the use of highly contextual, site-specific, data. A promising solution is to rely not only on real-world data, but also on synthetic pseudo-data generated by a network digital twin (NDT). However, the effectiveness of this approach hinges on the accuracy of the NDT, which can vary widely across different contexts. To address this problem, this paper introduces context-aware doubly-robust (CDR) learning, a novel semi-supervised scheme that adapts its reliance on the pseudo-data to the different levels of fidelity of the NDT across contexts. CDR is evaluated on the task of downlink beamforming where it outperforms previous state-of-the-art approaches, providing a 24% loss decrease when compared to doubly-robust (DR) semi-supervised learning in regimes with low labeled data availability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15577v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clement Ruah, Houssem Sifaou, Osvaldo Simeone, Bashir Al-Hashimi</dc:creator>
    </item>
    <item>
      <title>Coherent Track-Before-Detect</title>
      <link>https://arxiv.org/abs/2506.18177</link>
      <description>arXiv:2506.18177v2 Announce Type: replace 
Abstract: Accurately tracking an unknown and time-varying number of objects in complex environments is a significant challenge but a fundamental capability in a variety of applications, including applied ocean sciences, surveillance, autonomous driving, and wireless communications. Conventional Bayesian multiobject tracking (MOT) methods typically employ a detect-then-track (DTT) approach, where a frontend detector preprocesses raw sensor data to extract measurements for MOT. The irreversible nature of this preprocessing step can discard valuable object-related information, particularly impairing the ability to resolve weak or closely spaced objects. The track-before-detect (TBD) paradigm offers an alternative by operating directly on sensor data. However, existing TBD approaches introduce simplifications to facilitate the development of inference methods, such as assuming known signal amplitudes or conditional independence between sensor measurements given object states. These assumptions can lead to suboptimal performance and limit the applicability of the resulting TBD methods in realistic scenarios.
  This paper introduces coherent TBD based on a comprehensive signal model for sensor data. The new model accounts for sensor data correlations and amplitude fluctuations, enabling the accurate representation of the physics of the data-generating process in TBD. Coherent TBD is suitable for a wide range of problems in active and passive radar, active and passive sonar, as well as integrated sensing and communication systems. Based on a factor graph representation of the new measurement model, a scalable belief propagation (BP) method is developed to perform efficient Bayesian inference. Experimental results, performed with both synthetic and real data, demonstrate that the proposed method outperforms state-of-the-art conventional MOT methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18177v2</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingchao Liang, Florian Meyer</dc:creator>
    </item>
    <item>
      <title>ARSAR-Net: Intelligent SAR Imaging with Adaptive Regularization</title>
      <link>https://arxiv.org/abs/2506.18324</link>
      <description>arXiv:2506.18324v2 Announce Type: replace 
Abstract: Deep unfolding networks have recently emerged as a promising approach for synthetic aperture radar (SAR) imaging. However, baseline unfolding networks, typically derived from iterative reconstruction algorithms such as the alternating direction method of multipliers (ADMM), lack generalization capability across scenes, primarily because their regularizers are empirically designed rather than learned from data. In this study, we introduce a learnable regularizer into the unfolding network and propose a SAR imaging network with adaptive regularization (ARSAR-Net), which aims to generalize across heterogeneous scenes including offshore ships, islands, urban areas, and mountainous terrain. Furthermore, two variants of ARSAR-Net are developed, targeting improved imaging efficiency and reconstruction quality, respectively. Extensive validation through simulated and real-data experiments demonstrates three key advantages of ARSAR-Net: (1) a 50% increase in imaging speed over existing unfolding networks, (2) a PSNR gain of up to 2.0 dB in imaging quality, and (3) enhanced adaptability to complex scenes. These advancements establish a new paradigm for computationally efficient and generalizable SAR imaging systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18324v2</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiping Fu, Yufan Chen, Zhe Zhang, Xiaolan Qiu, Qixiang Ye</dc:creator>
    </item>
    <item>
      <title>Communicating Smartly in the Molecular Domain: Neural Networks in the Internet of Bio-Nano Things</title>
      <link>https://arxiv.org/abs/2506.20589</link>
      <description>arXiv:2506.20589v2 Announce Type: replace 
Abstract: Recent developments in the Internet of Bio-Nano Things (IoBNT) are laying the groundwork for innovative applications across the healthcare sector. Nanodevices designed to operate within the body, managed remotely via the internet, are envisioned to promptly detect and actuate on potential diseases. In this vision, an inherent challenge arises due to the limited capabilities of individual nanosensors; specifically, nanosensors must communicate with one another to collaborate as a cluster. Aiming to research the boundaries of the clustering capabilities, this survey emphasizes data-driven communication strategies in molecular communication (MC) channels as a means of linking nanosensors. Relying on the flexibility and robustness of machine learning (ML) methods to tackle the dynamic nature of MC channels, the MC research community frequently refers to neural network (NN) architectures. This interdisciplinary research field encompasses various aspects, including the use of NNs to facilitate communication in MC environments, their implementation at the nanoscale, explainable approaches for NNs, and dataset generation for training. Within this survey, we provide a comprehensive analysis of fundamental perspectives on recent trends in NN architectures for MC, the feasibility of their implementation at the nanoscale, applied explainable artificial intelligence (XAI) techniques, and the accessibility of datasets along with best practices for their generation. Additionally, we offer open-source code repositories that illustrate NN-based methods to support reproducible research for key MC scenarios. Finally, we identify emerging research challenges, such as robust NN architectures, biologically integrated NN modules, and scalable training strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20589v2</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>q-bio.OT</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jorge Torres G\'omez, Pit Hofmann, Lisa Y. Debus, Osman Tugay Ba\c{s}aran, Sebastian Lotter, Roya Khanzadeh, Stefan Angerbauer, Bige Deniz Unluturk, Sergi Abadal, Werner Haselmayr, Frank H. P. Fitzek, Robert Schober, Falko Dressler</dc:creator>
    </item>
    <item>
      <title>Mathematical Foundation of Sparsity-based Multi-snapshot Spectral Estimation</title>
      <link>https://arxiv.org/abs/2202.11189</link>
      <description>arXiv:2202.11189v3 Announce Type: replace-cross 
Abstract: In this paper, we study the spectral estimation problem of estimating the locations of a fixed number of point sources given multiple snapshots of Fourier measurements in a bounded domain. We aim to provide a mathematical foundation for sparsity-based super-resolution in such spectral estimation problems in both one- and multi-dimensional spaces. In particular, we estimate the resolution and stability of the location recovery when considering the sparsest solution under the measurement constraint, and characterize their dependence on the cut-off frequency, the noise level, the sparsity of point sources, and the incoherence of the amplitude vectors of point sources. Our estimate emphasizes the importance of the high incoherence of amplitude vectors in enhancing the resolution of multi-snapshot spectral estimation. Moreover, to the best of our knowledge, it also provides the first stability result in the super-resolution regime for the well-known sparse MMV problem in DOA estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.11189v3</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>physics.optics</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ping Liu, Sanghyeon Yu, Ola Sabet, Lucas Pelkmans, Habib Ammari</dc:creator>
    </item>
    <item>
      <title>Rapid Gyroscope Calibration: A Deep Learning Approach</title>
      <link>https://arxiv.org/abs/2409.00488</link>
      <description>arXiv:2409.00488v3 Announce Type: replace-cross 
Abstract: Low-cost gyroscope calibration is essential for ensuring the accuracy and reliability of gyroscope measurements. Stationary calibration estimates the deterministic parts of measurement errors. To this end, a common practice is to average the gyroscope readings during a predefined period and estimate the gyroscope bias. Calibration duration plays a crucial role in performance, therefore, longer periods are preferred. However, some applications require quick startup times and calibration is therefore allowed only for a short time. In this work, we focus on reducing low-cost gyroscope calibration time using deep learning methods. We propose an end-to-end convolutional neural network for the application of gyroscope calibration. We explore the possibilities of using multiple real and virtual gyroscopes to improve the calibration performance of single gyroscopes. To train and validate our approach, we recorded a dataset consisting of 186.6 hours of gyroscope readings, using 36 gyroscopes of four different brands. We also created a virtual dataset consisting of simulated gyroscope readings. The six datasets were used to evaluate our proposed approach. One of our key achievements in this work is reducing gyroscope calibration time by up to 89% using three low-cost gyroscopes. Our dataset is publicly available to allow reproducibility of our work and to increase research in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00488v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yair Stolero, Itzik Klein</dc:creator>
    </item>
    <item>
      <title>Aliasing Reduction in Neural Amp Modeling by Smoothing Activations</title>
      <link>https://arxiv.org/abs/2505.04082</link>
      <description>arXiv:2505.04082v2 Announce Type: replace-cross 
Abstract: The increasing demand for high-quality digital emulations of analog audio hardware, such as vintage tube guitar amplifiers, led to numerous works on neural network-based black-box modeling, with deep learning architectures like WaveNet showing promising results. However, a key limitation in all of these models was the aliasing artifacts stemming from nonlinear activation functions in neural networks. In this paper, we investigated novel and modified activation functions aimed at mitigating aliasing within neural amplifier models. Supporting this, we introduced a novel metric, the Aliasing-to-Signal Ratio (ASR), which quantitatively assesses the level of aliasing with high accuracy. Measuring also the conventional Error-to-Signal Ratio (ESR), we conducted studies on a range of preexisting and modern activation functions with varying stretch factors. Our findings confirmed that activation functions with smoother curves tend to achieve lower ASR values, indicating a noticeable reduction in aliasing. Notably, this improvement in aliasing reduction was achievable without a substantial increase in ESR, demonstrating the potential for high modeling accuracy with reduced aliasing in neural amp models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04082v2</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryota Sato, Julius O. Smith III</dc:creator>
    </item>
  </channel>
</rss>
